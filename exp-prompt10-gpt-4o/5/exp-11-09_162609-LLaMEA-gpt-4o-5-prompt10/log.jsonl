{"id": "c1ade3f4-56f3-4356-9950-2b4330ab1f68", "solution": "import numpy as np\n\nclass HybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Differential Mutation\n                mutant = a + self.scale_factor * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Crossover\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < self.cross_prob\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning\n            self.scale_factor = np.random.uniform(0.5, 0.9)\n            self.cross_prob = np.random.uniform(0.8, 1.0)\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "HybridEvolutionaryOptimizer", "description": "A hybrid evolutionary strategy with differential mutation and self-adaptive parameter tuning for efficient exploration and exploitation in black-box optimization.", "configspace": "", "generation": 0, "fitness": 0.4514029449074658, "feedback": "The algorithm HybridEvolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.45 with standard deviation 0.27.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8555714777366139, 0.8705543106100488, 0.8599432982440922, 0.8558027809078461, 0.8653162927193321, 0.8647044163160972, 0.8532482511742632, 0.850437238182083, 0.8491800875764055, 0.7551987785995874, 0.7625478823063998, 0.7424727794581489, 0.7293352691798023, 0.7538708511212986, 0.7399806732750263, 0.7618618400088817, 0.7871908626977857, 0.7470865794128089, 0.10875650353417154, 0.11659177090405959, 0.14822062356930688, 0.1614980679490493, 0.187901231401281, 0.1326450834409334, 0.2479087905419063, 0.34141628164215965, 0.2069945745363364, 0.1328820731685728, 0.12558892414179268, 0.13410151440884588, 0.10997603710566506, 0.12914996226375663, 0.12071467256018242, 0.1044392846561405, 0.1281768865073023, 0.11330054261529332, 0.9859418918212289, 0.9432943886176298, 0.8962003771127214, 0.9768608372467303, 0.9669825558762088, 0.9325123583680054, 0.945072300074559, 0.9800860162010485, 0.9652588047703792, 0.6411247306645218, 0.6502599935368434, 0.6197542134821712, 0.6794425716502785, 0.6202124397765947, 0.6816669711130574, 0.6594781164690665, 0.6326993297183718, 0.6392771198905488, 0.8408304232155902, 0.8653327791335507, 0.7847449092368035, 0.8415518876200998, 0.8583513180797766, 0.8370350228010366, 0.8357997800265141, 0.8315993834145514, 0.7955919971527388, 0.5395780183061745, 0.5174718970145855, 0.5464744654823114, 0.489976841468566, 0.5740345679991116, 0.5546722300915636, 0.5538020503912643, 0.5457678514670383, 0.5777972934832571, 0.48633830246688614, 0.7047193359171586, 0.5800785549187661, 0.40420404502967067, 0.49546643283750924, 0.5306278526535453, 0.5874161752182105, 0.6327334256784501, 0.5722430780157666, 0.6130491937270663, 0.6126931725571696, 0.6177767338026179, 0.5756676956603267, 0.5666226206247924, 0.5593693717531626, 0.6260524924329902, 0.6614680680332379, 0.5878474790345447, 0.685958844432324, 0.6839110968761744, 0.619449159111864, 0.6765870147291619, 0.6800201002435151, 0.5914357412006829, 0.6375866260640584, 0.6512187808531898, 0.6526931326802783, 0.3304800477588343, 0.28265063986186056, 0.18626882774620113, 0.1832392267723656, 0.24137905984181363, 0.4333884968565591, 0.19778468043365538, 0.14571749863948769, 0.3513084162013058, 0.4902258161018589, 0.49008906800050145, 0.4245586608409726, 0.50466961794387, 0.5056979683062636, 0.45721485310939547, 0.46399645440872117, 0.493030084045046, 0.4499782751170561, 0.795841442170832, 0.78695232702369, 0.7671252178944725, 0.7794645605567296, 0.7973281714287179, 0.7675626643850288, 0.8035585499235618, 0.7692694719134597, 0.7864014423906227, 0.14048466927410153, 0.10331986008681737, 0.10290374282199044, 0.1240473651932803, 0.09956850249243088, 0.09722009661090703, 0.0879150159842137, 0.10940347914296944, 0.09774409757630786, 0.42996998092970107, 0.22648763878948608, 0.19245865003909501, 0.4431367135718556, 0.1678242345110501, 0.16575002762051116, 0.15906385758696595, 0.14045642645865697, 0.15635010544395922, 0.5390433443252254, 0.49830150193959966, 0.48850763923648666, 0.45158068926212436, 0.4581426656722817, 0.4746594621746011, 0.4893413115645292, 0.48984897739140343, 0.5362521183843583, 0.43547376047390585, 0.37146324816719256, 0.3416911724393161, 0.40850676823070553, 0.34352533397564844, 0.36652580277348046, 0.35483859786722227, 0.39360669083893673, 0.4013930029885896, 0.1752284189457185, 0.21058707641560626, 0.175001595894704, 0.23591508197151057, 0.1890869403116605, 0.19237105974039792, 0.20665312596845098, 0.1902268476678849, 0.2144727466208749, 0.20392573965592797, 0.4848653929533777, 0.20621242022396546, 0.47951277642593104, 0.22798494958909088, 0.41933903407674056, 0.22741279505555345, 0.2220520753851547, 0.2004244883869265, 0.19680746275960737, 0.2058908016594655, 0.16354049446591834, 0.8129812609452188, 0.16892156017877347, 0.19387626545410508, 0.8725988118136088, 0.19596692941795768, 0.16889767981466375, 0.08242247428025873, 0.20833179588454398, 0.20278828873475363, 0.16464688891551882, 0.16141128765679114, 0.7390643237016177, 0.7919693987505079, 0.21243082382355405, 0.21202935274581203, 0.18681833744730203, 0.17399038382315668, 0.1916909958506372, 0.18161388755531693, 0.18467219578345517, 0.18738988886598196, 0.21385207809648343, 0.16880948122171702, 0.1773684291149964, 0.08369215840863631, 0.07145434808132944, 0.08198473772474357, 0.08126528586957849, 0.07564902841004295, 0.07416439735857494, 0.0794191534833153, 0.07629675205503494, 0.07072924925646384]}, "mutation_prompt": null}
{"id": "042abd7e-5e28-4d94-b350-48d204b31378", "solution": "import numpy as np\n\nclass HybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Differential Mutation\n                mutant = a + self.scale_factor * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Crossover\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < self.cross_prob\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning\n            self.scale_factor = np.random.uniform(0.5, 0.9)\n            self.cross_prob = np.random.uniform(0.8, 1.0)\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "HybridEvolutionaryOptimizer", "description": "A hybrid evolutionary strategy with differential mutation and self-adaptive parameter tuning for efficient exploration and exploitation in black-box optimization.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c1ade3f4-56f3-4356-9950-2b4330ab1f68", "metadata": {"aucs": [0.8555714777366139, 0.8705543106100488, 0.8599432982440922, 0.8558027809078461, 0.8653162927193321, 0.8647044163160972, 0.8532482511742632, 0.850437238182083, 0.8491800875764055, 0.7551987785995874, 0.7625478823063998, 0.7424727794581489, 0.7293352691798023, 0.7538708511212986, 0.7399806732750263, 0.7618618400088817, 0.7871908626977857, 0.7470865794128089, 0.10875650353417154, 0.11659177090405959, 0.14822062356930688, 0.1614980679490493, 0.187901231401281, 0.1326450834409334, 0.2479087905419063, 0.34141628164215965, 0.2069945745363364, 0.1328820731685728, 0.12558892414179268, 0.13410151440884588, 0.10997603710566506, 0.12914996226375663, 0.12071467256018242, 0.1044392846561405, 0.1281768865073023, 0.11330054261529332, 0.9859418918212289, 0.9432943886176298, 0.8962003771127214, 0.9768608372467303, 0.9669825558762088, 0.9325123583680054, 0.945072300074559, 0.9800860162010485, 0.9652588047703792, 0.6411247306645218, 0.6502599935368434, 0.6197542134821712, 0.6794425716502785, 0.6202124397765947, 0.6816669711130574, 0.6594781164690665, 0.6326993297183718, 0.6392771198905488, 0.8408304232155902, 0.8653327791335507, 0.7847449092368035, 0.8415518876200998, 0.8583513180797766, 0.8370350228010366, 0.8357997800265141, 0.8315993834145514, 0.7955919971527388, 0.5395780183061745, 0.5174718970145855, 0.5464744654823114, 0.489976841468566, 0.5740345679991116, 0.5546722300915636, 0.5538020503912643, 0.5457678514670383, 0.5777972934832571, 0.48633830246688614, 0.7047193359171586, 0.5800785549187661, 0.40420404502967067, 0.49546643283750924, 0.5306278526535453, 0.5874161752182105, 0.6327334256784501, 0.5722430780157666, 0.6130491937270663, 0.6126931725571696, 0.6177767338026179, 0.5756676956603267, 0.5666226206247924, 0.5593693717531626, 0.6260524924329902, 0.6614680680332379, 0.5878474790345447, 0.685958844432324, 0.6839110968761744, 0.619449159111864, 0.6765870147291619, 0.6800201002435151, 0.5914357412006829, 0.6375866260640584, 0.6512187808531898, 0.6526931326802783, 0.3304800477588343, 0.28265063986186056, 0.18626882774620113, 0.1832392267723656, 0.24137905984181363, 0.4333884968565591, 0.19778468043365538, 0.14571749863948769, 0.3513084162013058, 0.4902258161018589, 0.49008906800050145, 0.4245586608409726, 0.50466961794387, 0.5056979683062636, 0.45721485310939547, 0.46399645440872117, 0.493030084045046, 0.4499782751170561, 0.795841442170832, 0.78695232702369, 0.7671252178944725, 0.7794645605567296, 0.7973281714287179, 0.7675626643850288, 0.8035585499235618, 0.7692694719134597, 0.7864014423906227, 0.14048466927410153, 0.10331986008681737, 0.10290374282199044, 0.1240473651932803, 0.09956850249243088, 0.09722009661090703, 0.0879150159842137, 0.10940347914296944, 0.09774409757630786, 0.42996998092970107, 0.22648763878948608, 0.19245865003909501, 0.4431367135718556, 0.1678242345110501, 0.16575002762051116, 0.15906385758696595, 0.14045642645865697, 0.15635010544395922, 0.5390433443252254, 0.49830150193959966, 0.48850763923648666, 0.45158068926212436, 0.4581426656722817, 0.4746594621746011, 0.4893413115645292, 0.48984897739140343, 0.5362521183843583, 0.43547376047390585, 0.37146324816719256, 0.3416911724393161, 0.40850676823070553, 0.34352533397564844, 0.36652580277348046, 0.35483859786722227, 0.39360669083893673, 0.4013930029885896, 0.1752284189457185, 0.21058707641560626, 0.175001595894704, 0.23591508197151057, 0.1890869403116605, 0.19237105974039792, 0.20665312596845098, 0.1902268476678849, 0.2144727466208749, 0.20392573965592797, 0.4848653929533777, 0.20621242022396546, 0.47951277642593104, 0.22798494958909088, 0.41933903407674056, 0.22741279505555345, 0.2220520753851547, 0.2004244883869265, 0.19680746275960737, 0.2058908016594655, 0.16354049446591834, 0.8129812609452188, 0.16892156017877347, 0.19387626545410508, 0.8725988118136088, 0.19596692941795768, 0.16889767981466375, 0.08242247428025873, 0.20833179588454398, 0.20278828873475363, 0.16464688891551882, 0.16141128765679114, 0.7390643237016177, 0.7919693987505079, 0.21243082382355405, 0.21202935274581203, 0.18681833744730203, 0.17399038382315668, 0.1916909958506372, 0.18161388755531693, 0.18467219578345517, 0.18738988886598196, 0.21385207809648343, 0.16880948122171702, 0.1773684291149964, 0.08369215840863631, 0.07145434808132944, 0.08198473772474357, 0.08126528586957849, 0.07564902841004295, 0.07416439735857494, 0.0794191534833153, 0.07629675205503494, 0.07072924925646384]}, "mutation_prompt": null}
{"id": "9fe9cb3e-e145-4f5f-bfe7-3d14351a52f5", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population_size = self.initial_population_size\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n        \n        while func_evals < self.budget:\n            for i in range(population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Differential Mutation\n                mutant = a + self.scale_factor * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Adaptive Crossover\n                trial = np.copy(population[i])\n                crossover_rate = np.random.uniform(self.cross_prob - 0.05, self.cross_prob + 0.05)\n                crossover = np.random.rand(self.dim) < crossover_rate\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Dynamic population size adjustment\n            if func_evals < self.budget * 0.5:\n                population_size = min(int(1.2 * population_size), (self.budget - func_evals) // 2)\n            else:\n                population_size = max(int(0.8 * population_size), 4)\n            population = np.vstack((population, np.random.uniform(self.bounds[0], self.bounds[1], (population_size - len(population), self.dim))))\n            fitness = np.append(fitness, [func(ind) for ind in population[len(fitness):]])\n            func_evals += population_size - len(fitness)\n            fitness = fitness[:population_size]\n            population = population[:population_size]\n\n            # Self-adaptive parameter tuning\n            self.scale_factor = np.random.uniform(0.5, 0.9)\n            self.cross_prob = np.random.uniform(0.8, 1.0)\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "Enhanced Hybrid Evolutionary Optimizer with dynamic population size adjustment and adaptive crossover for improved convergence speed.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('negative dimensions are not allowed').", "error": "ValueError('negative dimensions are not allowed')", "parent_id": "c1ade3f4-56f3-4356-9950-2b4330ab1f68", "metadata": {}, "mutation_prompt": null}
{"id": "eacf2d76-a476-4cbe-be56-736e77455917", "solution": "import numpy as np\n\nclass HybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.dynamic_adjustment = 0.1  # New parameter for dynamic adjustment\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n\n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Differential Mutation\n                mutant = a + self.scale_factor * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Crossover with adaptive strategy\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + self.dynamic_adjustment * (1 - func_evals / self.budget))\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning\n            self.scale_factor = np.random.uniform(0.5, 0.9)\n            self.cross_prob = np.random.uniform(0.8, 1.0)\n            \n            # Dynamic population adjustment\n            if func_evals / self.budget > 0.5:\n                self.population_size = max(4, int(self.population_size * 0.9))\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "HybridEvolutionaryOptimizer", "description": "Enhanced Hybrid Evolutionary Optimizer with dynamic population adjustment and adaptive crossover strategies for improved convergence speed.", "configspace": "", "generation": 3, "fitness": 0.4505137738777098, "feedback": "The algorithm HybridEvolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.45 with standard deviation 0.29.", "error": "", "parent_id": "c1ade3f4-56f3-4356-9950-2b4330ab1f68", "metadata": {"aucs": [0.8467384037217696, 0.8597387472352598, 0.8566704467405203, 0.872844787544936, 0.8642076282996793, 0.8585120560936764, 0.8614576846690878, 0.8556585311508591, 0.8323706973027047, 0.7431476761456441, 0.7595642659949474, 0.7588822267629983, 0.7378249175894718, 0.7468716121741156, 0.7450675374028719, 0.7583178377706171, 0.7697412256569773, 0.7508424187983789, 0.1415913268282204, 0.11642747037527679, 0.13338126438999576, 0.1354839341829882, 0.13721786984627338, 0.10884604951202759, 0.12409960516013485, 0.173340790194777, 0.11541589186822454, 0.12749982187398023, 0.10661052578732866, 0.1210249477024734, 0.1006856591547528, 0.1323101355842815, 0.10207905069659573, 0.11345185754745146, 0.09799228597794585, 0.09788436461705075, 0.8447573123790292, 0.977129279854251, 0.963244457080516, 0.971792674417779, 0.9815223433780713, 0.8591166954740865, 0.9314933838664793, 0.9885315571713046, 0.974521820129597, 0.5557633539383838, 0.5725190096138026, 0.548564489712345, 0.634435910644046, 0.6579745991625034, 0.6060041767004577, 0.6535807789912274, 0.5806650184443869, 0.5186301441838241, 0.8604272404231995, 0.7967887696237405, 0.8313295893382935, 0.843066331261606, 0.8553770087794518, 0.8934077938987569, 0.8691307199249689, 0.8610844514714749, 0.8306044820292556, 0.43168039134945335, 0.4349220001459865, 0.43283244992580905, 0.28650459862769273, 0.45047696760961775, 0.6683409887450036, 0.3961915774829725, 0.6905203837951543, 0.6013734586585521, 0.21301589073265148, 0.3265342799402994, 0.7694436772868514, 0.3158682786716205, 0.13023825805485445, 0.34051538375403434, 0.3557818156710104, 0.3553813563833673, 0.7282125099986873, 0.7044337277293442, 0.7105496764109114, 0.6828102304995337, 0.7279203144411716, 0.7275926461567301, 0.6721565326716812, 0.686774774426957, 0.739980195504645, 0.6944655363039032, 0.7692580958505406, 0.7702945074410588, 0.7648668042882899, 0.7612126355909764, 0.7529043870637855, 0.7380797558001975, 0.7629399687863846, 0.7869396645028077, 0.7682318615622943, 0.22439302124999572, 0.3228471284545712, 0.24100689506193407, 0.6151072152833725, 0.5158288383614134, 0.4454013919516915, 0.3161051611797613, 0.19865397016121278, 0.14961645458104444, 0.4868861167207239, 0.4752956872846107, 0.49349366000777894, 0.4711250055337455, 0.49693949902593626, 0.47206611832921497, 0.4952637161968938, 0.4810426879524913, 0.46273956035216723, 0.8133366557131742, 0.8133276599257833, 0.821590479713273, 0.8427758865431827, 0.8297505513068422, 0.8254489103640423, 0.8249285148100077, 0.8424507236053704, 0.8291460645508858, 0.11473000314847759, 0.10486259747779658, 0.10419386655895668, 0.1333971772857796, 0.10105694623361738, 0.10472356767088786, 0.09503847379596742, 0.1108313272832091, 0.12349037417953856, 0.24468129750321177, 0.15069362396701558, 0.15913804337345427, 0.25679169360203613, 0.24012860827430793, 0.1730360805050286, 0.1741583488513947, 0.19086405127748463, 0.15309041505796883, 0.40449240809004006, 0.4462591558971247, 0.49606595196561254, 0.43497319426214487, 0.44006601874706286, 0.4168798262203598, 0.49514798605880705, 0.5211086849923954, 0.46388994733225475, 0.3906335570661006, 0.42640518144194306, 0.3792562823993557, 0.3914774007513748, 0.3801607385304333, 0.32449220206388707, 0.3986607569389734, 0.3960991287239528, 0.3629802414050759, 0.20254950163912622, 0.19382944529484036, 0.21787194176386115, 0.19762096237034077, 0.19652019989143155, 0.1876969432261436, 0.18806124193611895, 0.20102915815995892, 0.18117148325539356, 0.19939396132754994, 0.19068859653485548, 0.19847339278207732, 0.20296256300352356, 0.21224909240978918, 0.22899719976872734, 0.3363244458048824, 0.3038862239149561, 0.3513849927301568, 0.19714099930751405, 0.18482741173281392, 0.16247298338530358, 0.18347373488483887, 0.1730213331732786, 0.19616490326661995, 0.8208478577985354, 0.8244300328077565, 0.18672680843348533, 0.8380966069333804, 0.16759778133613212, 0.8324650370121741, 0.2044346201860351, 0.18935392404433393, 0.16680736045710165, 0.8491960259118885, 0.21230535585280264, 0.15376068888366934, 0.1757893839052358, 0.1885890713878916, 0.2121134470019097, 0.19870613867860742, 0.19745805220232715, 0.1871013487372194, 0.18341170656839656, 0.18237252920752378, 0.1765700434255103, 0.06923740467635875, 0.0793493775067885, 0.07521222134584293, 0.0930405338146385, 0.07960304630280557, 0.07471915327835055, 0.06718617912898339, 0.07234816068065231, 0.07929928924876439]}, "mutation_prompt": null}
{"id": "61e1585f-5b1a-4f3c-9bbf-5a3d94755b0a", "solution": "import numpy as np\n\nclass HybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Differential Mutation\n                mutant = a + self.scale_factor * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Crossover\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < self.cross_prob\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning\n            self.scale_factor = np.random.uniform(0.5, 0.9)\n            self.cross_prob = np.random.uniform(0.8, 1.0)\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "HybridEvolutionaryOptimizer", "description": "A hybrid evolutionary strategy with differential mutation and self-adaptive parameter tuning for efficient exploration and exploitation in black-box optimization.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c1ade3f4-56f3-4356-9950-2b4330ab1f68", "metadata": {"aucs": [0.8555714777366139, 0.8705543106100488, 0.8599432982440922, 0.8558027809078461, 0.8653162927193321, 0.8647044163160972, 0.8532482511742632, 0.850437238182083, 0.8491800875764055, 0.7551987785995874, 0.7625478823063998, 0.7424727794581489, 0.7293352691798023, 0.7538708511212986, 0.7399806732750263, 0.7618618400088817, 0.7871908626977857, 0.7470865794128089, 0.10875650353417154, 0.11659177090405959, 0.14822062356930688, 0.1614980679490493, 0.187901231401281, 0.1326450834409334, 0.2479087905419063, 0.34141628164215965, 0.2069945745363364, 0.1328820731685728, 0.12558892414179268, 0.13410151440884588, 0.10997603710566506, 0.12914996226375663, 0.12071467256018242, 0.1044392846561405, 0.1281768865073023, 0.11330054261529332, 0.9859418918212289, 0.9432943886176298, 0.8962003771127214, 0.9768608372467303, 0.9669825558762088, 0.9325123583680054, 0.945072300074559, 0.9800860162010485, 0.9652588047703792, 0.6411247306645218, 0.6502599935368434, 0.6197542134821712, 0.6794425716502785, 0.6202124397765947, 0.6816669711130574, 0.6594781164690665, 0.6326993297183718, 0.6392771198905488, 0.8408304232155902, 0.8653327791335507, 0.7847449092368035, 0.8415518876200998, 0.8583513180797766, 0.8370350228010366, 0.8357997800265141, 0.8315993834145514, 0.7955919971527388, 0.5395780183061745, 0.5174718970145855, 0.5464744654823114, 0.489976841468566, 0.5740345679991116, 0.5546722300915636, 0.5538020503912643, 0.5457678514670383, 0.5777972934832571, 0.48633830246688614, 0.7047193359171586, 0.5800785549187661, 0.40420404502967067, 0.49546643283750924, 0.5306278526535453, 0.5874161752182105, 0.6327334256784501, 0.5722430780157666, 0.6130491937270663, 0.6126931725571696, 0.6177767338026179, 0.5756676956603267, 0.5666226206247924, 0.5593693717531626, 0.6260524924329902, 0.6614680680332379, 0.5878474790345447, 0.685958844432324, 0.6839110968761744, 0.619449159111864, 0.6765870147291619, 0.6800201002435151, 0.5914357412006829, 0.6375866260640584, 0.6512187808531898, 0.6526931326802783, 0.3304800477588343, 0.28265063986186056, 0.18626882774620113, 0.1832392267723656, 0.24137905984181363, 0.4333884968565591, 0.19778468043365538, 0.14571749863948769, 0.3513084162013058, 0.4902258161018589, 0.49008906800050145, 0.4245586608409726, 0.50466961794387, 0.5056979683062636, 0.45721485310939547, 0.46399645440872117, 0.493030084045046, 0.4499782751170561, 0.795841442170832, 0.78695232702369, 0.7671252178944725, 0.7794645605567296, 0.7973281714287179, 0.7675626643850288, 0.8035585499235618, 0.7692694719134597, 0.7864014423906227, 0.14048466927410153, 0.10331986008681737, 0.10290374282199044, 0.1240473651932803, 0.09956850249243088, 0.09722009661090703, 0.0879150159842137, 0.10940347914296944, 0.09774409757630786, 0.42996998092970107, 0.22648763878948608, 0.19245865003909501, 0.4431367135718556, 0.1678242345110501, 0.16575002762051116, 0.15906385758696595, 0.14045642645865697, 0.15635010544395922, 0.5390433443252254, 0.49830150193959966, 0.48850763923648666, 0.45158068926212436, 0.4581426656722817, 0.4746594621746011, 0.4893413115645292, 0.48984897739140343, 0.5362521183843583, 0.43547376047390585, 0.37146324816719256, 0.3416911724393161, 0.40850676823070553, 0.34352533397564844, 0.36652580277348046, 0.35483859786722227, 0.39360669083893673, 0.4013930029885896, 0.1752284189457185, 0.21058707641560626, 0.175001595894704, 0.23591508197151057, 0.1890869403116605, 0.19237105974039792, 0.20665312596845098, 0.1902268476678849, 0.2144727466208749, 0.20392573965592797, 0.4848653929533777, 0.20621242022396546, 0.47951277642593104, 0.22798494958909088, 0.41933903407674056, 0.22741279505555345, 0.2220520753851547, 0.2004244883869265, 0.19680746275960737, 0.2058908016594655, 0.16354049446591834, 0.8129812609452188, 0.16892156017877347, 0.19387626545410508, 0.8725988118136088, 0.19596692941795768, 0.16889767981466375, 0.08242247428025873, 0.20833179588454398, 0.20278828873475363, 0.16464688891551882, 0.16141128765679114, 0.7390643237016177, 0.7919693987505079, 0.21243082382355405, 0.21202935274581203, 0.18681833744730203, 0.17399038382315668, 0.1916909958506372, 0.18161388755531693, 0.18467219578345517, 0.18738988886598196, 0.21385207809648343, 0.16880948122171702, 0.1773684291149964, 0.08369215840863631, 0.07145434808132944, 0.08198473772474357, 0.08126528586957849, 0.07564902841004295, 0.07416439735857494, 0.0794191534833153, 0.07629675205503494, 0.07072924925646384]}, "mutation_prompt": null}
{"id": "42311d44-fc3d-4e2b-b66e-1527c247060e", "solution": "import numpy as np\n\nclass HybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Differential Mutation\n                mutant = a + self.scale_factor * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Crossover\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < self.cross_prob\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning\n            self.scale_factor = np.random.uniform(0.5, 0.9)\n            self.cross_prob = np.random.uniform(0.8, 1.0)\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "HybridEvolutionaryOptimizer", "description": "A hybrid evolutionary strategy with differential mutation and self-adaptive parameter tuning for efficient exploration and exploitation in black-box optimization.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c1ade3f4-56f3-4356-9950-2b4330ab1f68", "metadata": {"aucs": [0.8555714777366139, 0.8705543106100488, 0.8599432982440922, 0.8558027809078461, 0.8653162927193321, 0.8647044163160972, 0.8532482511742632, 0.850437238182083, 0.8491800875764055, 0.7551987785995874, 0.7625478823063998, 0.7424727794581489, 0.7293352691798023, 0.7538708511212986, 0.7399806732750263, 0.7618618400088817, 0.7871908626977857, 0.7470865794128089, 0.10875650353417154, 0.11659177090405959, 0.14822062356930688, 0.1614980679490493, 0.187901231401281, 0.1326450834409334, 0.2479087905419063, 0.34141628164215965, 0.2069945745363364, 0.1328820731685728, 0.12558892414179268, 0.13410151440884588, 0.10997603710566506, 0.12914996226375663, 0.12071467256018242, 0.1044392846561405, 0.1281768865073023, 0.11330054261529332, 0.9859418918212289, 0.9432943886176298, 0.8962003771127214, 0.9768608372467303, 0.9669825558762088, 0.9325123583680054, 0.945072300074559, 0.9800860162010485, 0.9652588047703792, 0.6411247306645218, 0.6502599935368434, 0.6197542134821712, 0.6794425716502785, 0.6202124397765947, 0.6816669711130574, 0.6594781164690665, 0.6326993297183718, 0.6392771198905488, 0.8408304232155902, 0.8653327791335507, 0.7847449092368035, 0.8415518876200998, 0.8583513180797766, 0.8370350228010366, 0.8357997800265141, 0.8315993834145514, 0.7955919971527388, 0.5395780183061745, 0.5174718970145855, 0.5464744654823114, 0.489976841468566, 0.5740345679991116, 0.5546722300915636, 0.5538020503912643, 0.5457678514670383, 0.5777972934832571, 0.48633830246688614, 0.7047193359171586, 0.5800785549187661, 0.40420404502967067, 0.49546643283750924, 0.5306278526535453, 0.5874161752182105, 0.6327334256784501, 0.5722430780157666, 0.6130491937270663, 0.6126931725571696, 0.6177767338026179, 0.5756676956603267, 0.5666226206247924, 0.5593693717531626, 0.6260524924329902, 0.6614680680332379, 0.5878474790345447, 0.685958844432324, 0.6839110968761744, 0.619449159111864, 0.6765870147291619, 0.6800201002435151, 0.5914357412006829, 0.6375866260640584, 0.6512187808531898, 0.6526931326802783, 0.3304800477588343, 0.28265063986186056, 0.18626882774620113, 0.1832392267723656, 0.24137905984181363, 0.4333884968565591, 0.19778468043365538, 0.14571749863948769, 0.3513084162013058, 0.4902258161018589, 0.49008906800050145, 0.4245586608409726, 0.50466961794387, 0.5056979683062636, 0.45721485310939547, 0.46399645440872117, 0.493030084045046, 0.4499782751170561, 0.795841442170832, 0.78695232702369, 0.7671252178944725, 0.7794645605567296, 0.7973281714287179, 0.7675626643850288, 0.8035585499235618, 0.7692694719134597, 0.7864014423906227, 0.14048466927410153, 0.10331986008681737, 0.10290374282199044, 0.1240473651932803, 0.09956850249243088, 0.09722009661090703, 0.0879150159842137, 0.10940347914296944, 0.09774409757630786, 0.42996998092970107, 0.22648763878948608, 0.19245865003909501, 0.4431367135718556, 0.1678242345110501, 0.16575002762051116, 0.15906385758696595, 0.14045642645865697, 0.15635010544395922, 0.5390433443252254, 0.49830150193959966, 0.48850763923648666, 0.45158068926212436, 0.4581426656722817, 0.4746594621746011, 0.4893413115645292, 0.48984897739140343, 0.5362521183843583, 0.43547376047390585, 0.37146324816719256, 0.3416911724393161, 0.40850676823070553, 0.34352533397564844, 0.36652580277348046, 0.35483859786722227, 0.39360669083893673, 0.4013930029885896, 0.1752284189457185, 0.21058707641560626, 0.175001595894704, 0.23591508197151057, 0.1890869403116605, 0.19237105974039792, 0.20665312596845098, 0.1902268476678849, 0.2144727466208749, 0.20392573965592797, 0.4848653929533777, 0.20621242022396546, 0.47951277642593104, 0.22798494958909088, 0.41933903407674056, 0.22741279505555345, 0.2220520753851547, 0.2004244883869265, 0.19680746275960737, 0.2058908016594655, 0.16354049446591834, 0.8129812609452188, 0.16892156017877347, 0.19387626545410508, 0.8725988118136088, 0.19596692941795768, 0.16889767981466375, 0.08242247428025873, 0.20833179588454398, 0.20278828873475363, 0.16464688891551882, 0.16141128765679114, 0.7390643237016177, 0.7919693987505079, 0.21243082382355405, 0.21202935274581203, 0.18681833744730203, 0.17399038382315668, 0.1916909958506372, 0.18161388755531693, 0.18467219578345517, 0.18738988886598196, 0.21385207809648343, 0.16880948122171702, 0.1773684291149964, 0.08369215840863631, 0.07145434808132944, 0.08198473772474357, 0.08126528586957849, 0.07564902841004295, 0.07416439735857494, 0.0794191534833153, 0.07629675205503494, 0.07072924925646384]}, "mutation_prompt": null}
{"id": "a4477f81-6ac7-4c52-b6ea-1dc9862140cd", "solution": "import numpy as np\n\nclass HybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Differential Mutation\n                mutant = a + self.scale_factor * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Crossover\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < self.cross_prob\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning\n            self.scale_factor = np.random.uniform(0.5, 0.9)\n            self.cross_prob = np.random.uniform(0.8, 1.0)\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "HybridEvolutionaryOptimizer", "description": "A hybrid evolutionary strategy with differential mutation and self-adaptive parameter tuning for efficient exploration and exploitation in black-box optimization.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c1ade3f4-56f3-4356-9950-2b4330ab1f68", "metadata": {"aucs": [0.8555714777366139, 0.8705543106100488, 0.8599432982440922, 0.8558027809078461, 0.8653162927193321, 0.8647044163160972, 0.8532482511742632, 0.850437238182083, 0.8491800875764055, 0.7551987785995874, 0.7625478823063998, 0.7424727794581489, 0.7293352691798023, 0.7538708511212986, 0.7399806732750263, 0.7618618400088817, 0.7871908626977857, 0.7470865794128089, 0.10875650353417154, 0.11659177090405959, 0.14822062356930688, 0.1614980679490493, 0.187901231401281, 0.1326450834409334, 0.2479087905419063, 0.34141628164215965, 0.2069945745363364, 0.1328820731685728, 0.12558892414179268, 0.13410151440884588, 0.10997603710566506, 0.12914996226375663, 0.12071467256018242, 0.1044392846561405, 0.1281768865073023, 0.11330054261529332, 0.9859418918212289, 0.9432943886176298, 0.8962003771127214, 0.9768608372467303, 0.9669825558762088, 0.9325123583680054, 0.945072300074559, 0.9800860162010485, 0.9652588047703792, 0.6411247306645218, 0.6502599935368434, 0.6197542134821712, 0.6794425716502785, 0.6202124397765947, 0.6816669711130574, 0.6594781164690665, 0.6326993297183718, 0.6392771198905488, 0.8408304232155902, 0.8653327791335507, 0.7847449092368035, 0.8415518876200998, 0.8583513180797766, 0.8370350228010366, 0.8357997800265141, 0.8315993834145514, 0.7955919971527388, 0.5395780183061745, 0.5174718970145855, 0.5464744654823114, 0.489976841468566, 0.5740345679991116, 0.5546722300915636, 0.5538020503912643, 0.5457678514670383, 0.5777972934832571, 0.48633830246688614, 0.7047193359171586, 0.5800785549187661, 0.40420404502967067, 0.49546643283750924, 0.5306278526535453, 0.5874161752182105, 0.6327334256784501, 0.5722430780157666, 0.6130491937270663, 0.6126931725571696, 0.6177767338026179, 0.5756676956603267, 0.5666226206247924, 0.5593693717531626, 0.6260524924329902, 0.6614680680332379, 0.5878474790345447, 0.685958844432324, 0.6839110968761744, 0.619449159111864, 0.6765870147291619, 0.6800201002435151, 0.5914357412006829, 0.6375866260640584, 0.6512187808531898, 0.6526931326802783, 0.3304800477588343, 0.28265063986186056, 0.18626882774620113, 0.1832392267723656, 0.24137905984181363, 0.4333884968565591, 0.19778468043365538, 0.14571749863948769, 0.3513084162013058, 0.4902258161018589, 0.49008906800050145, 0.4245586608409726, 0.50466961794387, 0.5056979683062636, 0.45721485310939547, 0.46399645440872117, 0.493030084045046, 0.4499782751170561, 0.795841442170832, 0.78695232702369, 0.7671252178944725, 0.7794645605567296, 0.7973281714287179, 0.7675626643850288, 0.8035585499235618, 0.7692694719134597, 0.7864014423906227, 0.14048466927410153, 0.10331986008681737, 0.10290374282199044, 0.1240473651932803, 0.09956850249243088, 0.09722009661090703, 0.0879150159842137, 0.10940347914296944, 0.09774409757630786, 0.42996998092970107, 0.22648763878948608, 0.19245865003909501, 0.4431367135718556, 0.1678242345110501, 0.16575002762051116, 0.15906385758696595, 0.14045642645865697, 0.15635010544395922, 0.5390433443252254, 0.49830150193959966, 0.48850763923648666, 0.45158068926212436, 0.4581426656722817, 0.4746594621746011, 0.4893413115645292, 0.48984897739140343, 0.5362521183843583, 0.43547376047390585, 0.37146324816719256, 0.3416911724393161, 0.40850676823070553, 0.34352533397564844, 0.36652580277348046, 0.35483859786722227, 0.39360669083893673, 0.4013930029885896, 0.1752284189457185, 0.21058707641560626, 0.175001595894704, 0.23591508197151057, 0.1890869403116605, 0.19237105974039792, 0.20665312596845098, 0.1902268476678849, 0.2144727466208749, 0.20392573965592797, 0.4848653929533777, 0.20621242022396546, 0.47951277642593104, 0.22798494958909088, 0.41933903407674056, 0.22741279505555345, 0.2220520753851547, 0.2004244883869265, 0.19680746275960737, 0.2058908016594655, 0.16354049446591834, 0.8129812609452188, 0.16892156017877347, 0.19387626545410508, 0.8725988118136088, 0.19596692941795768, 0.16889767981466375, 0.08242247428025873, 0.20833179588454398, 0.20278828873475363, 0.16464688891551882, 0.16141128765679114, 0.7390643237016177, 0.7919693987505079, 0.21243082382355405, 0.21202935274581203, 0.18681833744730203, 0.17399038382315668, 0.1916909958506372, 0.18161388755531693, 0.18467219578345517, 0.18738988886598196, 0.21385207809648343, 0.16880948122171702, 0.1773684291149964, 0.08369215840863631, 0.07145434808132944, 0.08198473772474357, 0.08126528586957849, 0.07564902841004295, 0.07416439735857494, 0.0794191534833153, 0.07629675205503494, 0.07072924925646384]}, "mutation_prompt": null}
{"id": "79cf9fbb-7676-43fc-a51d-bb302087da4e", "solution": "import numpy as np\n\nclass HybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Differential Mutation\n                mutant = a + self.scale_factor * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Crossover\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < self.cross_prob\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning\n            self.scale_factor = np.random.uniform(0.5, 0.9)\n            self.cross_prob = np.random.uniform(0.8, 1.0)\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "HybridEvolutionaryOptimizer", "description": "A hybrid evolutionary strategy with differential mutation and self-adaptive parameter tuning for efficient exploration and exploitation in black-box optimization.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c1ade3f4-56f3-4356-9950-2b4330ab1f68", "metadata": {"aucs": [0.8555714777366139, 0.8705543106100488, 0.8599432982440922, 0.8558027809078461, 0.8653162927193321, 0.8647044163160972, 0.8532482511742632, 0.850437238182083, 0.8491800875764055, 0.7551987785995874, 0.7625478823063998, 0.7424727794581489, 0.7293352691798023, 0.7538708511212986, 0.7399806732750263, 0.7618618400088817, 0.7871908626977857, 0.7470865794128089, 0.10875650353417154, 0.11659177090405959, 0.14822062356930688, 0.1614980679490493, 0.187901231401281, 0.1326450834409334, 0.2479087905419063, 0.34141628164215965, 0.2069945745363364, 0.1328820731685728, 0.12558892414179268, 0.13410151440884588, 0.10997603710566506, 0.12914996226375663, 0.12071467256018242, 0.1044392846561405, 0.1281768865073023, 0.11330054261529332, 0.9859418918212289, 0.9432943886176298, 0.8962003771127214, 0.9768608372467303, 0.9669825558762088, 0.9325123583680054, 0.945072300074559, 0.9800860162010485, 0.9652588047703792, 0.6411247306645218, 0.6502599935368434, 0.6197542134821712, 0.6794425716502785, 0.6202124397765947, 0.6816669711130574, 0.6594781164690665, 0.6326993297183718, 0.6392771198905488, 0.8408304232155902, 0.8653327791335507, 0.7847449092368035, 0.8415518876200998, 0.8583513180797766, 0.8370350228010366, 0.8357997800265141, 0.8315993834145514, 0.7955919971527388, 0.5395780183061745, 0.5174718970145855, 0.5464744654823114, 0.489976841468566, 0.5740345679991116, 0.5546722300915636, 0.5538020503912643, 0.5457678514670383, 0.5777972934832571, 0.48633830246688614, 0.7047193359171586, 0.5800785549187661, 0.40420404502967067, 0.49546643283750924, 0.5306278526535453, 0.5874161752182105, 0.6327334256784501, 0.5722430780157666, 0.6130491937270663, 0.6126931725571696, 0.6177767338026179, 0.5756676956603267, 0.5666226206247924, 0.5593693717531626, 0.6260524924329902, 0.6614680680332379, 0.5878474790345447, 0.685958844432324, 0.6839110968761744, 0.619449159111864, 0.6765870147291619, 0.6800201002435151, 0.5914357412006829, 0.6375866260640584, 0.6512187808531898, 0.6526931326802783, 0.3304800477588343, 0.28265063986186056, 0.18626882774620113, 0.1832392267723656, 0.24137905984181363, 0.4333884968565591, 0.19778468043365538, 0.14571749863948769, 0.3513084162013058, 0.4902258161018589, 0.49008906800050145, 0.4245586608409726, 0.50466961794387, 0.5056979683062636, 0.45721485310939547, 0.46399645440872117, 0.493030084045046, 0.4499782751170561, 0.795841442170832, 0.78695232702369, 0.7671252178944725, 0.7794645605567296, 0.7973281714287179, 0.7675626643850288, 0.8035585499235618, 0.7692694719134597, 0.7864014423906227, 0.14048466927410153, 0.10331986008681737, 0.10290374282199044, 0.1240473651932803, 0.09956850249243088, 0.09722009661090703, 0.0879150159842137, 0.10940347914296944, 0.09774409757630786, 0.42996998092970107, 0.22648763878948608, 0.19245865003909501, 0.4431367135718556, 0.1678242345110501, 0.16575002762051116, 0.15906385758696595, 0.14045642645865697, 0.15635010544395922, 0.5390433443252254, 0.49830150193959966, 0.48850763923648666, 0.45158068926212436, 0.4581426656722817, 0.4746594621746011, 0.4893413115645292, 0.48984897739140343, 0.5362521183843583, 0.43547376047390585, 0.37146324816719256, 0.3416911724393161, 0.40850676823070553, 0.34352533397564844, 0.36652580277348046, 0.35483859786722227, 0.39360669083893673, 0.4013930029885896, 0.1752284189457185, 0.21058707641560626, 0.175001595894704, 0.23591508197151057, 0.1890869403116605, 0.19237105974039792, 0.20665312596845098, 0.1902268476678849, 0.2144727466208749, 0.20392573965592797, 0.4848653929533777, 0.20621242022396546, 0.47951277642593104, 0.22798494958909088, 0.41933903407674056, 0.22741279505555345, 0.2220520753851547, 0.2004244883869265, 0.19680746275960737, 0.2058908016594655, 0.16354049446591834, 0.8129812609452188, 0.16892156017877347, 0.19387626545410508, 0.8725988118136088, 0.19596692941795768, 0.16889767981466375, 0.08242247428025873, 0.20833179588454398, 0.20278828873475363, 0.16464688891551882, 0.16141128765679114, 0.7390643237016177, 0.7919693987505079, 0.21243082382355405, 0.21202935274581203, 0.18681833744730203, 0.17399038382315668, 0.1916909958506372, 0.18161388755531693, 0.18467219578345517, 0.18738988886598196, 0.21385207809648343, 0.16880948122171702, 0.1773684291149964, 0.08369215840863631, 0.07145434808132944, 0.08198473772474357, 0.08126528586957849, 0.07564902841004295, 0.07416439735857494, 0.0794191534833153, 0.07629675205503494, 0.07072924925646384]}, "mutation_prompt": null}
{"id": "eb4c854f-2f36-433d-9dba-c2587fa2c350", "solution": "import numpy as np\n\nclass HybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Differential Mutation\n                mutant = a + self.scale_factor * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Crossover\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < self.cross_prob\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning\n            self.scale_factor = np.random.uniform(0.5, 0.9)\n            self.cross_prob = np.random.uniform(0.8, 1.0)\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "HybridEvolutionaryOptimizer", "description": "A hybrid evolutionary strategy with differential mutation and self-adaptive parameter tuning for efficient exploration and exploitation in black-box optimization.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c1ade3f4-56f3-4356-9950-2b4330ab1f68", "metadata": {"aucs": [0.8555714777366139, 0.8705543106100488, 0.8599432982440922, 0.8558027809078461, 0.8653162927193321, 0.8647044163160972, 0.8532482511742632, 0.850437238182083, 0.8491800875764055, 0.7551987785995874, 0.7625478823063998, 0.7424727794581489, 0.7293352691798023, 0.7538708511212986, 0.7399806732750263, 0.7618618400088817, 0.7871908626977857, 0.7470865794128089, 0.10875650353417154, 0.11659177090405959, 0.14822062356930688, 0.1614980679490493, 0.187901231401281, 0.1326450834409334, 0.2479087905419063, 0.34141628164215965, 0.2069945745363364, 0.1328820731685728, 0.12558892414179268, 0.13410151440884588, 0.10997603710566506, 0.12914996226375663, 0.12071467256018242, 0.1044392846561405, 0.1281768865073023, 0.11330054261529332, 0.9859418918212289, 0.9432943886176298, 0.8962003771127214, 0.9768608372467303, 0.9669825558762088, 0.9325123583680054, 0.945072300074559, 0.9800860162010485, 0.9652588047703792, 0.6411247306645218, 0.6502599935368434, 0.6197542134821712, 0.6794425716502785, 0.6202124397765947, 0.6816669711130574, 0.6594781164690665, 0.6326993297183718, 0.6392771198905488, 0.8408304232155902, 0.8653327791335507, 0.7847449092368035, 0.8415518876200998, 0.8583513180797766, 0.8370350228010366, 0.8357997800265141, 0.8315993834145514, 0.7955919971527388, 0.5395780183061745, 0.5174718970145855, 0.5464744654823114, 0.489976841468566, 0.5740345679991116, 0.5546722300915636, 0.5538020503912643, 0.5457678514670383, 0.5777972934832571, 0.48633830246688614, 0.7047193359171586, 0.5800785549187661, 0.40420404502967067, 0.49546643283750924, 0.5306278526535453, 0.5874161752182105, 0.6327334256784501, 0.5722430780157666, 0.6130491937270663, 0.6126931725571696, 0.6177767338026179, 0.5756676956603267, 0.5666226206247924, 0.5593693717531626, 0.6260524924329902, 0.6614680680332379, 0.5878474790345447, 0.685958844432324, 0.6839110968761744, 0.619449159111864, 0.6765870147291619, 0.6800201002435151, 0.5914357412006829, 0.6375866260640584, 0.6512187808531898, 0.6526931326802783, 0.3304800477588343, 0.28265063986186056, 0.18626882774620113, 0.1832392267723656, 0.24137905984181363, 0.4333884968565591, 0.19778468043365538, 0.14571749863948769, 0.3513084162013058, 0.4902258161018589, 0.49008906800050145, 0.4245586608409726, 0.50466961794387, 0.5056979683062636, 0.45721485310939547, 0.46399645440872117, 0.493030084045046, 0.4499782751170561, 0.795841442170832, 0.78695232702369, 0.7671252178944725, 0.7794645605567296, 0.7973281714287179, 0.7675626643850288, 0.8035585499235618, 0.7692694719134597, 0.7864014423906227, 0.14048466927410153, 0.10331986008681737, 0.10290374282199044, 0.1240473651932803, 0.09956850249243088, 0.09722009661090703, 0.0879150159842137, 0.10940347914296944, 0.09774409757630786, 0.42996998092970107, 0.22648763878948608, 0.19245865003909501, 0.4431367135718556, 0.1678242345110501, 0.16575002762051116, 0.15906385758696595, 0.14045642645865697, 0.15635010544395922, 0.5390433443252254, 0.49830150193959966, 0.48850763923648666, 0.45158068926212436, 0.4581426656722817, 0.4746594621746011, 0.4893413115645292, 0.48984897739140343, 0.5362521183843583, 0.43547376047390585, 0.37146324816719256, 0.3416911724393161, 0.40850676823070553, 0.34352533397564844, 0.36652580277348046, 0.35483859786722227, 0.39360669083893673, 0.4013930029885896, 0.1752284189457185, 0.21058707641560626, 0.175001595894704, 0.23591508197151057, 0.1890869403116605, 0.19237105974039792, 0.20665312596845098, 0.1902268476678849, 0.2144727466208749, 0.20392573965592797, 0.4848653929533777, 0.20621242022396546, 0.47951277642593104, 0.22798494958909088, 0.41933903407674056, 0.22741279505555345, 0.2220520753851547, 0.2004244883869265, 0.19680746275960737, 0.2058908016594655, 0.16354049446591834, 0.8129812609452188, 0.16892156017877347, 0.19387626545410508, 0.8725988118136088, 0.19596692941795768, 0.16889767981466375, 0.08242247428025873, 0.20833179588454398, 0.20278828873475363, 0.16464688891551882, 0.16141128765679114, 0.7390643237016177, 0.7919693987505079, 0.21243082382355405, 0.21202935274581203, 0.18681833744730203, 0.17399038382315668, 0.1916909958506372, 0.18161388755531693, 0.18467219578345517, 0.18738988886598196, 0.21385207809648343, 0.16880948122171702, 0.1773684291149964, 0.08369215840863631, 0.07145434808132944, 0.08198473772474357, 0.08126528586957849, 0.07564902841004295, 0.07416439735857494, 0.0794191534833153, 0.07629675205503494, 0.07072924925646384]}, "mutation_prompt": null}
{"id": "4b4a3183-ee24-427f-8e10-6cb5383175ff", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.population_shrink_factor = 0.95\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.initial_population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.initial_population_size\n        population_size = self.initial_population_size\n\n        while func_evals < self.budget:\n            for i in range(population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Differential Mutation\n                mutant = a + self.scale_factor * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Crossover\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < self.cross_prob\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Adaptive population resizing\n            population_size = int(population_size * self.population_shrink_factor)\n            population = population[:population_size]\n            fitness = fitness[:population_size]\n\n            # Dynamic crossover probability adjustment\n            self.cross_prob = 0.9 - 0.7 * (func_evals / self.budget)\n\n            # Self-adaptive parameter tuning\n            self.scale_factor = np.random.uniform(0.5, 0.9)\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "Enhanced Hybrid Evolutionary Optimizer with adaptive population resizing and dynamic crossover rate adjustment for faster convergence.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: ValueError(\"Cannot take a larger sample than population when 'replace=False'\").", "error": "ValueError(\"Cannot take a larger sample than population when 'replace=False'\")", "parent_id": "c1ade3f4-56f3-4356-9950-2b4330ab1f68", "metadata": {}, "mutation_prompt": null}
{"id": "79e08871-3c30-4b15-8fc5-db7c1b0319f6", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.dynamic_population = True  # Adaptive population size\n        self.elite_fraction = 0.1  # Fraction of top performers\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n\n        while func_evals < self.budget:\n            if self.dynamic_population and func_evals < self.budget / 2:\n                # Dynamically adjust population size early on\n                self.population_size = min(self.population_size + 1, int(20 + 15 * np.log(self.dim)))\n                population = np.vstack((population, np.random.uniform(self.bounds[0], self.bounds[1], (1, self.dim))))\n                fitness = np.append(fitness, func(population[-1]))\n                func_evals += 1\n\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Differential Mutation\n                mutant = a + self.scale_factor * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Crossover\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < self.cross_prob\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning with focus on top performers\n            elite_count = int(np.ceil(self.elite_fraction * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            self.scale_factor = np.mean([np.random.uniform(0.5, 0.9) for _ in elite_indices])\n            self.cross_prob = np.mean([np.random.uniform(0.8, 1.0) for _ in elite_indices])\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "Enhanced Hybrid Evolutionary Optimizer with adaptive population size and dynamic parameter adjustment to improve convergence speed and solution quality.", "configspace": "", "generation": 10, "fitness": 0.3345975026686467, "feedback": "The algorithm EnhancedHybridEvolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.24.", "error": "", "parent_id": "c1ade3f4-56f3-4356-9950-2b4330ab1f68", "metadata": {"aucs": [0.7380852353966272, 0.7562920880630016, 0.7447123273432794, 0.7684307322229222, 0.7526440265098958, 0.7541648433656208, 0.7565913716304344, 0.7435324659668563, 0.7424626883439629, 0.572898222130094, 0.5490132054327495, 0.5826307097585892, 0.5519093610231636, 0.5639983362797977, 0.562930969465079, 0.5861588167237866, 0.5655517298027608, 0.5684589650162831, 0.0864576580288946, 0.11586142458862836, 0.1021700648916376, 0.09341818191984963, 0.09151904076151696, 0.11036205615090533, 0.10584023501816975, 0.10058729401765598, 0.0977299062718201, 0.09705298595005063, 0.09612720339712066, 0.08411028731973724, 0.10005236600333223, 0.08763287711858136, 0.08125105422098844, 0.09200709368049464, 0.0992482018174714, 0.09258594218303318, 0.9450060299123768, 0.9736775679518609, 0.9731520930075027, 0.9800456605127208, 0.9799169203847091, 0.967403541054911, 0.9781410660143814, 0.9798452402136226, 0.9600871946825562, 0.3638335655792241, 0.4029585585552906, 0.39780750888941396, 0.39784304607477883, 0.40695052391931363, 0.3926585246858304, 0.3836325491574918, 0.40456099513642796, 0.38637598124233774, 0.729532422220056, 0.6588371875459069, 0.7450629215039466, 0.6937854893582487, 0.6881920048092591, 0.7347974030430167, 0.7018848655253904, 0.6822032315487707, 0.6687772061710806, 0.2836521807768769, 0.32072728742306356, 0.3028912500302452, 0.29850220336357114, 0.2880420928803271, 0.27911129837833837, 0.26901466871190516, 0.2742832920881838, 0.381932917966994, 0.4752302473710902, 0.0320598849436885, 0.3328627838329411, 0.2651616917721876, 0.2990495747886037, 0.2761969248907016, 0.35711817183939143, 0.3384746902390545, 0.3260079326298996, 0.2406988018233065, 0.2878853307936565, 0.24676703696869484, 0.24292799626265815, 0.290160794878611, 0.2140851406695431, 0.2482023432113557, 0.25980750643341977, 0.2779431605745094, 0.41257485378591396, 0.37094523461984064, 0.38277578421108094, 0.4289872434095917, 0.3992820661809944, 0.38782869384611174, 0.4474691421528534, 0.4049741117118496, 0.3975559579584549, 0.13489977914370466, 0.051616624687833235, 0.12254191814993942, 0.08210969741641494, 0.10847779226581056, 0.10536809595014274, 0.11054622491723964, 0.1681366792380612, 0.11415173822231972, 0.23898700651739524, 0.24470633050916457, 0.20928250757641453, 0.2540272046330838, 0.257059494514305, 0.2500895733278954, 0.25508868398835916, 0.2701009323193586, 0.2532810535254876, 0.6239672596490804, 0.6096410486213681, 0.6129413201864728, 0.6141563798512197, 0.5942159569515386, 0.5828571500696007, 0.6052940344059932, 0.6072416060886288, 0.6288008815337153, 0.08894371698740655, 0.09900535802830124, 0.10000932960912634, 0.10334237031512117, 0.09757812605699179, 0.10810839505050718, 0.09201409734587729, 0.0788954810523268, 0.08447306654796027, 0.13475117917119828, 0.13579650600689563, 0.1843794482426332, 0.15160133073302817, 0.15090793679401426, 0.17159604280011187, 0.12897255456526568, 0.16781603078042096, 0.16090113983623267, 0.32754369841939224, 0.307271957308638, 0.3140066104115946, 0.3426179357266951, 0.3436862366323169, 0.30201218320058587, 0.3413147856163826, 0.3790386340508981, 0.3468478020708806, 0.24310302469412415, 0.2591606300302658, 0.2511360736574153, 0.24859453754237593, 0.2326775269756376, 0.22990129707096219, 0.2538721232234715, 0.2790688269884357, 0.2803222499622703, 0.19005781496742824, 0.17250338136406607, 0.17847838586543074, 0.18829143162786777, 0.23638606548378605, 0.20179088818932722, 0.1872097824986627, 0.1939987809855398, 0.18797717968465633, 0.18107332059637016, 0.1835953639218716, 0.20961025020548718, 0.18426070633002523, 0.18684509000457483, 0.18438957240317844, 0.1786214050781475, 0.19467041011851105, 0.1909482804796676, 0.16829741516973995, 0.7038640183273005, 0.15245803410820247, 0.17994212822962252, 0.19281235168311806, 0.17306621715350468, 0.7376213557461933, 0.17472747466963479, 0.45993668309706803, 0.16384443567345897, 0.20459678729350894, 0.20218689202690354, 0.15788746654734986, 0.19897312938037237, 0.5031421462997105, 0.8351324269664784, 0.7997646814250678, 0.7596117606103611, 0.19003545991410697, 0.17769087567832575, 0.18187041681895622, 0.18841471501815255, 0.18171796563204023, 0.19090460349465987, 0.17672485895534196, 0.18686201236973643, 0.17706677616495892, 0.07946100687901303, 0.0716408058723248, 0.0831203659711931, 0.0782560608880638, 0.07004631984480802, 0.07272224945619077, 0.08205121915913516, 0.06828652081570141, 0.07412005158172974]}, "mutation_prompt": null}
{"id": "6fa279be-1767-470f-bda7-b5086b999320", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor)\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning\n            self.scale_factor = np.random.uniform(0.6, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.85, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with adaptive differential mutation and dynamic crossover to improve exploration and convergence speed.", "configspace": "", "generation": 11, "fitness": 0.45440628759124957, "feedback": "The algorithm ImprovedHybridEvolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.45 with standard deviation 0.27.", "error": "", "parent_id": "c1ade3f4-56f3-4356-9950-2b4330ab1f68", "metadata": {"aucs": [0.825271308868495, 0.8428562615295943, 0.8426625620263116, 0.8338708356204272, 0.8503446132560646, 0.8533812003271036, 0.8380760541245388, 0.8183630669908136, 0.8420271450471732, 0.7086853159064155, 0.7396069105138292, 0.7602038680842589, 0.7323295436843005, 0.7366153944846856, 0.7106020482318696, 0.718036720391436, 0.7320309437956423, 0.7399472732068899, 0.10050037556080604, 0.12056820281654723, 0.11790742708612945, 0.10810100118285704, 0.09540903694559943, 0.11945223318427667, 0.16861351363204835, 0.13881787718018546, 0.11617563204535197, 0.11941732034884989, 0.11537215430067116, 0.10417659619313091, 0.1898982997198737, 0.10425093675056474, 0.11308425337932637, 0.11822865118672854, 0.17368298710943453, 0.1416507573591811, 0.9772200223208363, 0.9605157954294056, 0.9698961302235226, 0.9548992771122515, 0.9585392523517984, 0.9568946664494513, 0.9453426073012882, 0.9453074450553327, 0.9696797397539388, 0.6099818761559822, 0.6259642700208095, 0.6279249698435632, 0.6250382463363402, 0.6503314667048186, 0.577313838243521, 0.6360962553392986, 0.6396505088269324, 0.6585682316581949, 0.7979813519339483, 0.8140936547009936, 0.8233674594803781, 0.8000725342930506, 0.8301729328475332, 0.8172819002914907, 0.8261712281128872, 0.8230261521199056, 0.7958892886037937, 0.5998328779517017, 0.5856039456328322, 0.6423524312814166, 0.5487347043545969, 0.5377205546292183, 0.6198981758598103, 0.6327768174977519, 0.5364468349899949, 0.5949939429256261, 0.5996842334915555, 0.5154932707406408, 0.5813131354836566, 0.6130549556137426, 0.5813932946990845, 0.5111854030880189, 0.5478409024818174, 0.5529651129813227, 0.5971762926772167, 0.5922374365401037, 0.5613558097715612, 0.590288944963572, 0.5616869773946163, 0.5781535422343277, 0.5840458611014829, 0.6241519321867655, 0.594661729954099, 0.6147826103511655, 0.6858347471633415, 0.6435280317073684, 0.6775386398738334, 0.6721825310578738, 0.656630018011745, 0.6823972629619932, 0.7417454624012845, 0.6920765556986207, 0.7036722344065016, 0.3339259168390225, 0.28548238347509136, 0.3699793692953084, 0.489838644328657, 0.5072507351905968, 0.4338904830580954, 0.3452229130875957, 0.17220507937260665, 0.14940873507014496, 0.48852192594208665, 0.46196367121245574, 0.4564070343900706, 0.4861584979419501, 0.43638377493033087, 0.4385439067112785, 0.486382308944443, 0.4971074949998934, 0.45227985579885155, 0.7915215499287558, 0.7685530154010431, 0.8003542291011886, 0.7957798925478587, 0.7842877533997992, 0.7860893471055231, 0.7683026035787064, 0.793757682990629, 0.7807780440423455, 0.09116993306969312, 0.11598806720921018, 0.08056896148033321, 0.10548092985022961, 0.14747320854022494, 0.11371317895035138, 0.10624295801950068, 0.10023515112062864, 0.09803569988903182, 0.15864492729216673, 0.24666361609437548, 0.14353638761779552, 0.16828367208469697, 0.2989565752808566, 0.1581731048090882, 0.17618274545597779, 0.16017207055616622, 0.13916650241338702, 0.4407275555873804, 0.4315706540511579, 0.4679246514721085, 0.44504992660408693, 0.42348524380708785, 0.4813780469113451, 0.502002619996262, 0.4834021462637602, 0.46678689580970356, 0.40876811315480854, 0.31499831336112694, 0.33877659432558316, 0.38582739620954765, 0.3621974192728492, 0.3248264453981755, 0.3686471322096395, 0.3976434605742364, 0.38660371383250614, 0.19180516142864878, 0.1881074510804428, 0.20574555717212684, 0.1714365143677169, 0.18088302557315417, 0.1997286965919256, 0.18674692954462924, 0.202834583015002, 0.19105328675825206, 0.3039814115105216, 0.20085941461610113, 0.20872774728567833, 0.4016169507796613, 0.5647567798632083, 0.21796566168269604, 0.26751408658020004, 0.4733019798252064, 0.195471442201127, 0.1698371642808152, 0.8228793616370091, 0.21056662241253643, 0.8622802926542299, 0.184849304347111, 0.1843641179281127, 0.1646676663498864, 0.787544444225702, 0.8235973356417357, 0.152087068684591, 0.1663988958662458, 0.20760054474394196, 0.2020392761995895, 0.7612598373901736, 0.7351024411123432, 0.2116997086142942, 0.21019033846531354, 0.19345932926678822, 0.17849131900400061, 0.17988287885215137, 0.17816820814887357, 0.17495652970472397, 0.1500319992125434, 0.1696033618039523, 0.18590666174299908, 0.17895526958891173, 0.17996979361264187, 0.08074055756647247, 0.08489884324544161, 0.07083655874461636, 0.07836045123715363, 0.08048892441349687, 0.07767100174633434, 0.0836134274416045, 0.07376461736476525, 0.07989978158015587]}, "mutation_prompt": null}
{"id": "8d988d28-c050-4771-8d5d-35d82a7f56e7", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor)\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning\n            self.scale_factor = np.random.uniform(0.6, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.85, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with adaptive differential mutation and dynamic crossover to improve exploration and convergence speed.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "6fa279be-1767-470f-bda7-b5086b999320", "metadata": {"aucs": [0.825271308868495, 0.8428562615295943, 0.8426625620263116, 0.8338708356204272, 0.8503446132560646, 0.8533812003271036, 0.8380760541245388, 0.8183630669908136, 0.8420271450471732, 0.7086853159064155, 0.7396069105138292, 0.7602038680842589, 0.7323295436843005, 0.7366153944846856, 0.7106020482318696, 0.718036720391436, 0.7320309437956423, 0.7399472732068899, 0.10050037556080604, 0.12056820281654723, 0.11790742708612945, 0.10810100118285704, 0.09540903694559943, 0.11945223318427667, 0.16861351363204835, 0.13881787718018546, 0.11617563204535197, 0.11941732034884989, 0.11537215430067116, 0.10417659619313091, 0.1898982997198737, 0.10425093675056474, 0.11308425337932637, 0.11822865118672854, 0.17368298710943453, 0.1416507573591811, 0.9772200223208363, 0.9605157954294056, 0.9698961302235226, 0.9548992771122515, 0.9585392523517984, 0.9568946664494513, 0.9453426073012882, 0.9453074450553327, 0.9696797397539388, 0.6099818761559822, 0.6259642700208095, 0.6279249698435632, 0.6250382463363402, 0.6503314667048186, 0.577313838243521, 0.6360962553392986, 0.6396505088269324, 0.6585682316581949, 0.7979813519339483, 0.8140936547009936, 0.8233674594803781, 0.8000725342930506, 0.8301729328475332, 0.8172819002914907, 0.8261712281128872, 0.8230261521199056, 0.7958892886037937, 0.5998328779517017, 0.5856039456328322, 0.6423524312814166, 0.5487347043545969, 0.5377205546292183, 0.6198981758598103, 0.6327768174977519, 0.5364468349899949, 0.5949939429256261, 0.5996842334915555, 0.5154932707406408, 0.5813131354836566, 0.6130549556137426, 0.5813932946990845, 0.5111854030880189, 0.5478409024818174, 0.5529651129813227, 0.5971762926772167, 0.5922374365401037, 0.5613558097715612, 0.590288944963572, 0.5616869773946163, 0.5781535422343277, 0.5840458611014829, 0.6241519321867655, 0.594661729954099, 0.6147826103511655, 0.6858347471633415, 0.6435280317073684, 0.6775386398738334, 0.6721825310578738, 0.656630018011745, 0.6823972629619932, 0.7417454624012845, 0.6920765556986207, 0.7036722344065016, 0.3339259168390225, 0.28548238347509136, 0.3699793692953084, 0.489838644328657, 0.5072507351905968, 0.4338904830580954, 0.3452229130875957, 0.17220507937260665, 0.14940873507014496, 0.48852192594208665, 0.46196367121245574, 0.4564070343900706, 0.4861584979419501, 0.43638377493033087, 0.4385439067112785, 0.486382308944443, 0.4971074949998934, 0.45227985579885155, 0.7915215499287558, 0.7685530154010431, 0.8003542291011886, 0.7957798925478587, 0.7842877533997992, 0.7860893471055231, 0.7683026035787064, 0.793757682990629, 0.7807780440423455, 0.09116993306969312, 0.11598806720921018, 0.08056896148033321, 0.10548092985022961, 0.14747320854022494, 0.11371317895035138, 0.10624295801950068, 0.10023515112062864, 0.09803569988903182, 0.15864492729216673, 0.24666361609437548, 0.14353638761779552, 0.16828367208469697, 0.2989565752808566, 0.1581731048090882, 0.17618274545597779, 0.16017207055616622, 0.13916650241338702, 0.4407275555873804, 0.4315706540511579, 0.4679246514721085, 0.44504992660408693, 0.42348524380708785, 0.4813780469113451, 0.502002619996262, 0.4834021462637602, 0.46678689580970356, 0.40876811315480854, 0.31499831336112694, 0.33877659432558316, 0.38582739620954765, 0.3621974192728492, 0.3248264453981755, 0.3686471322096395, 0.3976434605742364, 0.38660371383250614, 0.19180516142864878, 0.1881074510804428, 0.20574555717212684, 0.1714365143677169, 0.18088302557315417, 0.1997286965919256, 0.18674692954462924, 0.202834583015002, 0.19105328675825206, 0.3039814115105216, 0.20085941461610113, 0.20872774728567833, 0.4016169507796613, 0.5647567798632083, 0.21796566168269604, 0.26751408658020004, 0.4733019798252064, 0.195471442201127, 0.1698371642808152, 0.8228793616370091, 0.21056662241253643, 0.8622802926542299, 0.184849304347111, 0.1843641179281127, 0.1646676663498864, 0.787544444225702, 0.8235973356417357, 0.152087068684591, 0.1663988958662458, 0.20760054474394196, 0.2020392761995895, 0.7612598373901736, 0.7351024411123432, 0.2116997086142942, 0.21019033846531354, 0.19345932926678822, 0.17849131900400061, 0.17988287885215137, 0.17816820814887357, 0.17495652970472397, 0.1500319992125434, 0.1696033618039523, 0.18590666174299908, 0.17895526958891173, 0.17996979361264187, 0.08074055756647247, 0.08489884324544161, 0.07083655874461636, 0.07836045123715363, 0.08048892441349687, 0.07767100174633434, 0.0836134274416045, 0.07376461736476525, 0.07989978158015587]}, "mutation_prompt": null}
{"id": "b6098975-6e7d-45c0-b585-cbd06c4ec49f", "solution": "# Description: Enhanced adaptation through strategic diversity injection and periodic best individual propagation.\n# Code:\nimport numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.injection_interval = 50  # New parameter for diversity injection\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        generation = 0\n\n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor)\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Periodic best individual propagation\n            if generation % self.injection_interval == 0:\n                best_idx = np.argmin(fitness)\n                for j in range(self.population_size):\n                    if j != best_idx:\n                        population[j] = population[best_idx] + np.random.normal(0, 0.1, self.dim)\n                        population[j] = np.clip(population[j], self.bounds[0], self.bounds[1])\n                        fitness[j] = func(population[j])\n                        func_evals += 1\n                        if func_evals >= self.budget:\n                            break\n\n            # Self-adaptive parameter tuning\n            self.scale_factor = np.random.uniform(0.6, 0.85)\n            self.cross_prob = np.random.uniform(0.85, 1.0)\n\n            generation += 1\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "Enhanced adaptation through strategic diversity injection and periodic best individual propagation.", "configspace": "", "generation": 13, "fitness": 0.32138161734813264, "feedback": "The algorithm ImprovedHybridEvolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.24.", "error": "", "parent_id": "6fa279be-1767-470f-bda7-b5086b999320", "metadata": {"aucs": [0.6877126484406959, 0.7096900744670118, 0.707402335660833, 0.7128284871563229, 0.6846694091698274, 0.7032693482766366, 0.6970662815563731, 0.7002880744426877, 0.713663628439284, 0.37842778065008287, 0.3683942576864304, 0.3788200343609155, 0.362988612330276, 0.30058030093675703, 0.36782737151788203, 0.3726916751339986, 0.33341542581095207, 0.3724598902571895, 0.12423594541074168, 0.05172327784178965, 0.12282557532877947, 0.029977940616582432, 0.034991068082281696, 0.06740616263025534, 0.047440679688579235, 0.07362529568306908, 0.07466927029938886, 0.020756344547490868, 0.11044876008034243, 0.05245307692727985, 0.15087790356388775, 0.0972098595526466, 0.01563010584931268, 0.06350402716421122, 0.11434375262812524, 0.09365498733300615, 0.90994651839888, 0.9420934071852127, 0.9242373829006639, 0.9215162737079006, 0.9340420359881685, 0.8934952424660931, 0.9043331722105463, 0.9048856660521752, 0.9401290428874185, 0.3834704081180166, 0.4304332807850174, 0.37797464902511113, 0.3842531072357921, 0.3610293725683408, 0.37990779489724114, 0.4330807129947011, 0.38516718267553174, 0.38800150397030664, 0.8665244901273726, 0.7546655824178177, 0.8264924178947256, 0.8729896060770364, 0.864825230786167, 0.8431793252257064, 0.7308542164161892, 0.8081825216198204, 0.8411256890153433, 0.4049553171137886, 0.3683457613802461, 0.29760877016265463, 0.3134972253630979, 0.3755787424877842, 0.37832142725868634, 0.4013571629024315, 0.38942965810054764, 0.33897317133582094, 0.36773019074432656, 0.1203835682532397, 0.34904236337647876, 0.30758337802495805, 0.3138098210962118, 0.3470959692347697, 0.35332731075158863, 0.33104688208044786, 0.39502916903274765, 0.20530558821315603, 0.22867170310160567, 0.22337224420495227, 0.3303258386832246, 0.27175713567601223, 0.22134075572743073, 0.2998197799219482, 0.264294385471328, 0.1928479855882942, 0.45726323023098625, 0.3927560095117214, 0.43182903280435314, 0.40569596313531975, 0.3874001805490388, 0.48576910589734745, 0.40814287647650394, 0.40350739963762905, 0.37876658188488177, 0.08873914998138555, 0.12056933966401007, 0.07178431024002863, 0.13996222774896327, 0.16231815171903086, 0.11527391303784007, 0.12334397027749888, 0.11493052649820168, 0.07597674705474766, 0.21415868819571837, 0.20983533059166715, 0.23349549922181412, 0.22623239082453717, 0.18276179190961817, 0.22380432368659753, 0.23236955766349643, 0.21783690739013928, 0.2164499782960464, 0.5593372213310969, 0.5548691220789623, 0.576662180393603, 0.5913525285926373, 0.5672343881810646, 0.5479277474538373, 0.5930168920384773, 0.5303069171974402, 0.5565428444159175, 0.06775609796264703, 0.1157838234500912, 0.1048055906422034, 0.09465155325004693, 0.1304005000450783, 0.12387966357882962, 0.019760964342941056, 0.040455424748306545, 0.08430298898770472, 0.2536045455091377, 0.2341063771662858, 0.2975988014704368, 0.47888013254127526, 0.44064672671620964, 0.46291806458921714, 0.4830662260176851, 0.3913425893286143, 0.14337829846555228, 0.12735713801065085, 0.20990238162928154, 0.18390297246781628, 0.22717534119029692, 0.22401659721494704, 0.3571447076015878, 0.2499446136907667, 0.36956670550848625, 0.18833663625188657, 0.10255566140853012, 0.18348240975118768, 0.275532949076871, 0.21863306086008283, 0.09925137808515117, 0.30067644273854555, 0.255021491829841, 0.31121836692789406, 0.29930411601648066, 0.20344975622736738, 0.21603474434746617, 0.18819914108535152, 0.2326067259682678, 0.18453981663943797, 0.17166123307582215, 0.21444060514339758, 0.21760904870300846, 0.22540062276873718, 0.22273541102762284, 0.24700353335538927, 0.24788770044968855, 0.5361966906988807, 0.24095367031541093, 0.21599050811098142, 0.2147032794723822, 0.20582925721223544, 0.21815621934982565, 0.1668360840228008, 0.9265986401908531, 0.1542859307963621, 0.17601367500844478, 0.2014697590139165, 0.1761152606019718, 0.09978816386178346, 0.169126879835806, 0.2108721786127271, 0.08228462653490021, 0.1568840396923038, 0.1672964201703353, 0.7992305863740041, 0.16786842271223523, 0.2109164770616988, 0.21024806676661334, 0.10457372275341825, 0.16647953980966101, 0.1842695465376475, 0.17427776778309212, 0.19139510665528625, 0.20146986496442254, 0.18809937548716282, 0.18562578080189873, 0.18159065393029195, 0.18819170045655553, 0.18681371738917096, 0.10721690482951729, 0.06028878241415281, 0.08439982649079159, 0.08595606264475841, 0.08822643265559815, 0.08576997205446502, 0.07753955651713662, 0.07449149653822329, 0.07827918793364219]}, "mutation_prompt": null}
{"id": "4253ea43-1f73-452b-b8b7-d2fe4b03d301", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Enhanced Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                scale = self.scale_factor * np.random.normal(1.0, 0.1)  # New stochastic scaling\n                mutant = a + (scale + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Stochastic Crossover\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor)\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning\n            self.scale_factor = np.random.uniform(0.65, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.85, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer with enhanced adaptive mutation strategies and stochastic crossover to further accelerate convergence.", "configspace": "", "generation": 14, "fitness": 0.4392003614934148, "feedback": "The algorithm ImprovedHybridEvolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.44 with standard deviation 0.28.", "error": "", "parent_id": "6fa279be-1767-470f-bda7-b5086b999320", "metadata": {"aucs": [0.8429751252362754, 0.8230124946023102, 0.8195069703231335, 0.8436824603218182, 0.8360088396669261, 0.8385668370713806, 0.8361326663752834, 0.8319013698785314, 0.8403405102052697, 0.7474249551536609, 0.7256062637347551, 0.7108772772725378, 0.694868973856614, 0.7042842770963438, 0.7454915715872878, 0.7238315045125385, 0.7397365742832462, 0.7602083898354801, 0.1094882087616812, 0.11646439278092546, 0.12359211533193681, 0.11714782323876793, 0.17575055571034304, 0.13927308818601614, 0.10530692128679897, 0.10746536755511715, 0.23039251154097762, 0.1308385758173295, 0.10458047325455921, 0.11554190682026366, 0.10067702773225029, 0.1185813329900588, 0.11193890459269473, 0.12255958089857832, 0.12641608924199554, 0.10628687680339044, 0.9378534722033749, 0.9456551851592564, 0.9458020232175615, 0.9431664935552129, 0.9235948690437082, 0.9156023386477825, 0.9571627295034216, 0.9418011182324467, 0.9523032893365834, 0.5784749849816773, 0.5869656006437955, 0.5822705267885262, 0.5872899913614833, 0.58217838175402, 0.6133690778331635, 0.5722315127398119, 0.6375789534835752, 0.6384583967338988, 0.7978429060381105, 0.8313267042515231, 0.8301441108902367, 0.8389972583575349, 0.8193699956763112, 0.7993839557749391, 0.8053699698428227, 0.7902260039219905, 0.8477136722426448, 0.4637609229294428, 0.6430365607204056, 0.58025358309758, 0.5511799234766455, 0.5684451517937097, 0.1280399090543769, 0.5807854146334619, 0.5371197402088175, 0.6120570293959298, 0.12068121690749378, 0.6048374084688022, 0.009974974668416348, 0.5991894292241283, 0.556167772214372, 0.5555166098576934, 0.5482879351408411, 0.5591144137238628, 0.49082982998158775, 0.5473936615240778, 0.5529261715545173, 0.5818827771285675, 0.5428210609593225, 0.5653483470008702, 0.5424619096850967, 0.5913997355156325, 0.6078755132636235, 0.5498668378124167, 0.6729771267860278, 0.6568532168351127, 0.6962929003368956, 0.6414841967980618, 0.6167259356415427, 0.6229872234209419, 0.6862187992569241, 0.6865538332029316, 0.671106940134901, 0.2630398987895325, 0.1374768806057144, 0.36917500281788607, 0.47493855023616505, 0.44936390808655535, 0.4642399125045895, 0.15930967250920003, 0.29362483332627987, 0.1447412972922819, 0.4309759753019665, 0.44235115721278284, 0.4240628941262845, 0.4171408488654913, 0.4691742861023427, 0.44994285274756296, 0.45750169567619636, 0.4189018433331255, 0.41387439220221234, 0.7846161606197066, 0.7810434236444418, 0.7902148284839839, 0.7827509525844802, 0.7703567222417878, 0.7780220131956095, 0.7803793187818635, 0.7491990840301243, 0.7535076910328745, 0.10030627682675564, 0.1005959272278174, 0.09642998738365716, 0.0940477144983295, 0.10449342998625777, 0.10095909522659952, 0.10273484459740034, 0.07761498139444467, 0.09813630710241372, 0.14755457408842065, 0.1371326434056317, 0.4352916736137612, 0.2570143183902657, 0.14842952661663933, 0.13596687305238864, 0.16227514121371078, 0.14266289715317437, 0.20377043322869282, 0.4173358253046685, 0.41417523418436053, 0.43139328695887147, 0.4097422802528292, 0.4404120464087379, 0.4233207599198945, 0.4880562802192824, 0.47540407138686147, 0.41094637962922853, 0.3754694968085799, 0.3827135165150859, 0.3361956493390016, 0.37686043664709257, 0.35097428388160756, 0.32108191493835936, 0.3236640000552067, 0.3608447812248192, 0.33826618428499866, 0.1948142974109165, 0.20016533065762887, 0.1866501943766744, 0.19027541414294802, 0.2088297565086935, 0.1921143796943564, 0.17917665583197218, 0.18175700749962387, 0.18483735950147873, 0.21766912146820228, 0.18800920443821778, 0.2085458178610916, 0.2402252845009718, 0.267458490566695, 0.458662274939183, 0.17447769358745613, 0.3599596142650999, 0.2634103841834099, 0.8313461325199676, 0.15257760886813887, 0.1834707771408678, 0.18759987001298872, 0.1938080331487223, 0.17340752327860232, 0.1655780555774543, 0.1935321105639759, 0.8348794228315575, 0.8290618089206638, 0.15437816987014263, 0.8138748324297864, 0.8457149006794877, 0.20746419731513033, 0.7481718078429296, 0.20916723651045654, 0.19096196156100076, 0.7937655885927846, 0.17927599021683005, 0.19830837823790493, 0.17008219509781353, 0.19764953608205016, 0.18183267210319332, 0.20186214448201656, 0.18582582290837013, 0.1999562612926501, 0.17987912383002425, 0.07983660329511733, 0.07719184931659329, 0.07860922525599456, 0.07404738050807103, 0.08320348061399874, 0.09215092006860559, 0.07867819151568001, 0.07598766372353039, 0.0835568074854578]}, "mutation_prompt": null}
{"id": "5a01f37c-ff71-4e9d-8264-17a3a29b1289", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor)\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning\n            self.scale_factor = np.random.uniform(0.6, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.85, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with adaptive differential mutation and dynamic crossover to improve exploration and convergence speed.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "6fa279be-1767-470f-bda7-b5086b999320", "metadata": {"aucs": [0.825271308868495, 0.8428562615295943, 0.8426625620263116, 0.8338708356204272, 0.8503446132560646, 0.8533812003271036, 0.8380760541245388, 0.8183630669908136, 0.8420271450471732, 0.7086853159064155, 0.7396069105138292, 0.7602038680842589, 0.7323295436843005, 0.7366153944846856, 0.7106020482318696, 0.718036720391436, 0.7320309437956423, 0.7399472732068899, 0.10050037556080604, 0.12056820281654723, 0.11790742708612945, 0.10810100118285704, 0.09540903694559943, 0.11945223318427667, 0.16861351363204835, 0.13881787718018546, 0.11617563204535197, 0.11941732034884989, 0.11537215430067116, 0.10417659619313091, 0.1898982997198737, 0.10425093675056474, 0.11308425337932637, 0.11822865118672854, 0.17368298710943453, 0.1416507573591811, 0.9772200223208363, 0.9605157954294056, 0.9698961302235226, 0.9548992771122515, 0.9585392523517984, 0.9568946664494513, 0.9453426073012882, 0.9453074450553327, 0.9696797397539388, 0.6099818761559822, 0.6259642700208095, 0.6279249698435632, 0.6250382463363402, 0.6503314667048186, 0.577313838243521, 0.6360962553392986, 0.6396505088269324, 0.6585682316581949, 0.7979813519339483, 0.8140936547009936, 0.8233674594803781, 0.8000725342930506, 0.8301729328475332, 0.8172819002914907, 0.8261712281128872, 0.8230261521199056, 0.7958892886037937, 0.5998328779517017, 0.5856039456328322, 0.6423524312814166, 0.5487347043545969, 0.5377205546292183, 0.6198981758598103, 0.6327768174977519, 0.5364468349899949, 0.5949939429256261, 0.5996842334915555, 0.5154932707406408, 0.5813131354836566, 0.6130549556137426, 0.5813932946990845, 0.5111854030880189, 0.5478409024818174, 0.5529651129813227, 0.5971762926772167, 0.5922374365401037, 0.5613558097715612, 0.590288944963572, 0.5616869773946163, 0.5781535422343277, 0.5840458611014829, 0.6241519321867655, 0.594661729954099, 0.6147826103511655, 0.6858347471633415, 0.6435280317073684, 0.6775386398738334, 0.6721825310578738, 0.656630018011745, 0.6823972629619932, 0.7417454624012845, 0.6920765556986207, 0.7036722344065016, 0.3339259168390225, 0.28548238347509136, 0.3699793692953084, 0.489838644328657, 0.5072507351905968, 0.4338904830580954, 0.3452229130875957, 0.17220507937260665, 0.14940873507014496, 0.48852192594208665, 0.46196367121245574, 0.4564070343900706, 0.4861584979419501, 0.43638377493033087, 0.4385439067112785, 0.486382308944443, 0.4971074949998934, 0.45227985579885155, 0.7915215499287558, 0.7685530154010431, 0.8003542291011886, 0.7957798925478587, 0.7842877533997992, 0.7860893471055231, 0.7683026035787064, 0.793757682990629, 0.7807780440423455, 0.09116993306969312, 0.11598806720921018, 0.08056896148033321, 0.10548092985022961, 0.14747320854022494, 0.11371317895035138, 0.10624295801950068, 0.10023515112062864, 0.09803569988903182, 0.15864492729216673, 0.24666361609437548, 0.14353638761779552, 0.16828367208469697, 0.2989565752808566, 0.1581731048090882, 0.17618274545597779, 0.16017207055616622, 0.13916650241338702, 0.4407275555873804, 0.4315706540511579, 0.4679246514721085, 0.44504992660408693, 0.42348524380708785, 0.4813780469113451, 0.502002619996262, 0.4834021462637602, 0.46678689580970356, 0.40876811315480854, 0.31499831336112694, 0.33877659432558316, 0.38582739620954765, 0.3621974192728492, 0.3248264453981755, 0.3686471322096395, 0.3976434605742364, 0.38660371383250614, 0.19180516142864878, 0.1881074510804428, 0.20574555717212684, 0.1714365143677169, 0.18088302557315417, 0.1997286965919256, 0.18674692954462924, 0.202834583015002, 0.19105328675825206, 0.3039814115105216, 0.20085941461610113, 0.20872774728567833, 0.4016169507796613, 0.5647567798632083, 0.21796566168269604, 0.26751408658020004, 0.4733019798252064, 0.195471442201127, 0.1698371642808152, 0.8228793616370091, 0.21056662241253643, 0.8622802926542299, 0.184849304347111, 0.1843641179281127, 0.1646676663498864, 0.787544444225702, 0.8235973356417357, 0.152087068684591, 0.1663988958662458, 0.20760054474394196, 0.2020392761995895, 0.7612598373901736, 0.7351024411123432, 0.2116997086142942, 0.21019033846531354, 0.19345932926678822, 0.17849131900400061, 0.17988287885215137, 0.17816820814887357, 0.17495652970472397, 0.1500319992125434, 0.1696033618039523, 0.18590666174299908, 0.17895526958891173, 0.17996979361264187, 0.08074055756647247, 0.08489884324544161, 0.07083655874461636, 0.07836045123715363, 0.08048892441349687, 0.07767100174633434, 0.0836134274416045, 0.07376461736476525, 0.07989978158015587]}, "mutation_prompt": null}
{"id": "95740c76-df33-48ea-9d59-c776514c0f84", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor)\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning\n            self.scale_factor = np.random.uniform(0.6, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.85, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with adaptive differential mutation and dynamic crossover to improve exploration and convergence speed.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "6fa279be-1767-470f-bda7-b5086b999320", "metadata": {"aucs": [0.825271308868495, 0.8428562615295943, 0.8426625620263116, 0.8338708356204272, 0.8503446132560646, 0.8533812003271036, 0.8380760541245388, 0.8183630669908136, 0.8420271450471732, 0.7086853159064155, 0.7396069105138292, 0.7602038680842589, 0.7323295436843005, 0.7366153944846856, 0.7106020482318696, 0.718036720391436, 0.7320309437956423, 0.7399472732068899, 0.10050037556080604, 0.12056820281654723, 0.11790742708612945, 0.10810100118285704, 0.09540903694559943, 0.11945223318427667, 0.16861351363204835, 0.13881787718018546, 0.11617563204535197, 0.11941732034884989, 0.11537215430067116, 0.10417659619313091, 0.1898982997198737, 0.10425093675056474, 0.11308425337932637, 0.11822865118672854, 0.17368298710943453, 0.1416507573591811, 0.9772200223208363, 0.9605157954294056, 0.9698961302235226, 0.9548992771122515, 0.9585392523517984, 0.9568946664494513, 0.9453426073012882, 0.9453074450553327, 0.9696797397539388, 0.6099818761559822, 0.6259642700208095, 0.6279249698435632, 0.6250382463363402, 0.6503314667048186, 0.577313838243521, 0.6360962553392986, 0.6396505088269324, 0.6585682316581949, 0.7979813519339483, 0.8140936547009936, 0.8233674594803781, 0.8000725342930506, 0.8301729328475332, 0.8172819002914907, 0.8261712281128872, 0.8230261521199056, 0.7958892886037937, 0.5998328779517017, 0.5856039456328322, 0.6423524312814166, 0.5487347043545969, 0.5377205546292183, 0.6198981758598103, 0.6327768174977519, 0.5364468349899949, 0.5949939429256261, 0.5996842334915555, 0.5154932707406408, 0.5813131354836566, 0.6130549556137426, 0.5813932946990845, 0.5111854030880189, 0.5478409024818174, 0.5529651129813227, 0.5971762926772167, 0.5922374365401037, 0.5613558097715612, 0.590288944963572, 0.5616869773946163, 0.5781535422343277, 0.5840458611014829, 0.6241519321867655, 0.594661729954099, 0.6147826103511655, 0.6858347471633415, 0.6435280317073684, 0.6775386398738334, 0.6721825310578738, 0.656630018011745, 0.6823972629619932, 0.7417454624012845, 0.6920765556986207, 0.7036722344065016, 0.3339259168390225, 0.28548238347509136, 0.3699793692953084, 0.489838644328657, 0.5072507351905968, 0.4338904830580954, 0.3452229130875957, 0.17220507937260665, 0.14940873507014496, 0.48852192594208665, 0.46196367121245574, 0.4564070343900706, 0.4861584979419501, 0.43638377493033087, 0.4385439067112785, 0.486382308944443, 0.4971074949998934, 0.45227985579885155, 0.7915215499287558, 0.7685530154010431, 0.8003542291011886, 0.7957798925478587, 0.7842877533997992, 0.7860893471055231, 0.7683026035787064, 0.793757682990629, 0.7807780440423455, 0.09116993306969312, 0.11598806720921018, 0.08056896148033321, 0.10548092985022961, 0.14747320854022494, 0.11371317895035138, 0.10624295801950068, 0.10023515112062864, 0.09803569988903182, 0.15864492729216673, 0.24666361609437548, 0.14353638761779552, 0.16828367208469697, 0.2989565752808566, 0.1581731048090882, 0.17618274545597779, 0.16017207055616622, 0.13916650241338702, 0.4407275555873804, 0.4315706540511579, 0.4679246514721085, 0.44504992660408693, 0.42348524380708785, 0.4813780469113451, 0.502002619996262, 0.4834021462637602, 0.46678689580970356, 0.40876811315480854, 0.31499831336112694, 0.33877659432558316, 0.38582739620954765, 0.3621974192728492, 0.3248264453981755, 0.3686471322096395, 0.3976434605742364, 0.38660371383250614, 0.19180516142864878, 0.1881074510804428, 0.20574555717212684, 0.1714365143677169, 0.18088302557315417, 0.1997286965919256, 0.18674692954462924, 0.202834583015002, 0.19105328675825206, 0.3039814115105216, 0.20085941461610113, 0.20872774728567833, 0.4016169507796613, 0.5647567798632083, 0.21796566168269604, 0.26751408658020004, 0.4733019798252064, 0.195471442201127, 0.1698371642808152, 0.8228793616370091, 0.21056662241253643, 0.8622802926542299, 0.184849304347111, 0.1843641179281127, 0.1646676663498864, 0.787544444225702, 0.8235973356417357, 0.152087068684591, 0.1663988958662458, 0.20760054474394196, 0.2020392761995895, 0.7612598373901736, 0.7351024411123432, 0.2116997086142942, 0.21019033846531354, 0.19345932926678822, 0.17849131900400061, 0.17988287885215137, 0.17816820814887357, 0.17495652970472397, 0.1500319992125434, 0.1696033618039523, 0.18590666174299908, 0.17895526958891173, 0.17996979361264187, 0.08074055756647247, 0.08489884324544161, 0.07083655874461636, 0.07836045123715363, 0.08048892441349687, 0.07767100174633434, 0.0836134274416045, 0.07376461736476525, 0.07989978158015587]}, "mutation_prompt": null}
{"id": "a7764b13-edf2-402d-9df4-0d8f69e35762", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor)\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning\n            self.scale_factor = np.random.uniform(0.6, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.85, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with adaptive differential mutation and dynamic crossover to improve exploration and convergence speed.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "6fa279be-1767-470f-bda7-b5086b999320", "metadata": {"aucs": [0.825271308868495, 0.8428562615295943, 0.8426625620263116, 0.8338708356204272, 0.8503446132560646, 0.8533812003271036, 0.8380760541245388, 0.8183630669908136, 0.8420271450471732, 0.7086853159064155, 0.7396069105138292, 0.7602038680842589, 0.7323295436843005, 0.7366153944846856, 0.7106020482318696, 0.718036720391436, 0.7320309437956423, 0.7399472732068899, 0.10050037556080604, 0.12056820281654723, 0.11790742708612945, 0.10810100118285704, 0.09540903694559943, 0.11945223318427667, 0.16861351363204835, 0.13881787718018546, 0.11617563204535197, 0.11941732034884989, 0.11537215430067116, 0.10417659619313091, 0.1898982997198737, 0.10425093675056474, 0.11308425337932637, 0.11822865118672854, 0.17368298710943453, 0.1416507573591811, 0.9772200223208363, 0.9605157954294056, 0.9698961302235226, 0.9548992771122515, 0.9585392523517984, 0.9568946664494513, 0.9453426073012882, 0.9453074450553327, 0.9696797397539388, 0.6099818761559822, 0.6259642700208095, 0.6279249698435632, 0.6250382463363402, 0.6503314667048186, 0.577313838243521, 0.6360962553392986, 0.6396505088269324, 0.6585682316581949, 0.7979813519339483, 0.8140936547009936, 0.8233674594803781, 0.8000725342930506, 0.8301729328475332, 0.8172819002914907, 0.8261712281128872, 0.8230261521199056, 0.7958892886037937, 0.5998328779517017, 0.5856039456328322, 0.6423524312814166, 0.5487347043545969, 0.5377205546292183, 0.6198981758598103, 0.6327768174977519, 0.5364468349899949, 0.5949939429256261, 0.5996842334915555, 0.5154932707406408, 0.5813131354836566, 0.6130549556137426, 0.5813932946990845, 0.5111854030880189, 0.5478409024818174, 0.5529651129813227, 0.5971762926772167, 0.5922374365401037, 0.5613558097715612, 0.590288944963572, 0.5616869773946163, 0.5781535422343277, 0.5840458611014829, 0.6241519321867655, 0.594661729954099, 0.6147826103511655, 0.6858347471633415, 0.6435280317073684, 0.6775386398738334, 0.6721825310578738, 0.656630018011745, 0.6823972629619932, 0.7417454624012845, 0.6920765556986207, 0.7036722344065016, 0.3339259168390225, 0.28548238347509136, 0.3699793692953084, 0.489838644328657, 0.5072507351905968, 0.4338904830580954, 0.3452229130875957, 0.17220507937260665, 0.14940873507014496, 0.48852192594208665, 0.46196367121245574, 0.4564070343900706, 0.4861584979419501, 0.43638377493033087, 0.4385439067112785, 0.486382308944443, 0.4971074949998934, 0.45227985579885155, 0.7915215499287558, 0.7685530154010431, 0.8003542291011886, 0.7957798925478587, 0.7842877533997992, 0.7860893471055231, 0.7683026035787064, 0.793757682990629, 0.7807780440423455, 0.09116993306969312, 0.11598806720921018, 0.08056896148033321, 0.10548092985022961, 0.14747320854022494, 0.11371317895035138, 0.10624295801950068, 0.10023515112062864, 0.09803569988903182, 0.15864492729216673, 0.24666361609437548, 0.14353638761779552, 0.16828367208469697, 0.2989565752808566, 0.1581731048090882, 0.17618274545597779, 0.16017207055616622, 0.13916650241338702, 0.4407275555873804, 0.4315706540511579, 0.4679246514721085, 0.44504992660408693, 0.42348524380708785, 0.4813780469113451, 0.502002619996262, 0.4834021462637602, 0.46678689580970356, 0.40876811315480854, 0.31499831336112694, 0.33877659432558316, 0.38582739620954765, 0.3621974192728492, 0.3248264453981755, 0.3686471322096395, 0.3976434605742364, 0.38660371383250614, 0.19180516142864878, 0.1881074510804428, 0.20574555717212684, 0.1714365143677169, 0.18088302557315417, 0.1997286965919256, 0.18674692954462924, 0.202834583015002, 0.19105328675825206, 0.3039814115105216, 0.20085941461610113, 0.20872774728567833, 0.4016169507796613, 0.5647567798632083, 0.21796566168269604, 0.26751408658020004, 0.4733019798252064, 0.195471442201127, 0.1698371642808152, 0.8228793616370091, 0.21056662241253643, 0.8622802926542299, 0.184849304347111, 0.1843641179281127, 0.1646676663498864, 0.787544444225702, 0.8235973356417357, 0.152087068684591, 0.1663988958662458, 0.20760054474394196, 0.2020392761995895, 0.7612598373901736, 0.7351024411123432, 0.2116997086142942, 0.21019033846531354, 0.19345932926678822, 0.17849131900400061, 0.17988287885215137, 0.17816820814887357, 0.17495652970472397, 0.1500319992125434, 0.1696033618039523, 0.18590666174299908, 0.17895526958891173, 0.17996979361264187, 0.08074055756647247, 0.08489884324544161, 0.07083655874461636, 0.07836045123715363, 0.08048892441349687, 0.07767100174633434, 0.0836134274416045, 0.07376461736476525, 0.07989978158015587]}, "mutation_prompt": null}
{"id": "ca9ce2f8-f73c-4f87-8c26-553549e5b7b7", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor)\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning\n            self.scale_factor = np.random.uniform(0.6, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.85, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with adaptive differential mutation and dynamic crossover to improve exploration and convergence speed.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "6fa279be-1767-470f-bda7-b5086b999320", "metadata": {"aucs": [0.825271308868495, 0.8428562615295943, 0.8426625620263116, 0.8338708356204272, 0.8503446132560646, 0.8533812003271036, 0.8380760541245388, 0.8183630669908136, 0.8420271450471732, 0.7086853159064155, 0.7396069105138292, 0.7602038680842589, 0.7323295436843005, 0.7366153944846856, 0.7106020482318696, 0.718036720391436, 0.7320309437956423, 0.7399472732068899, 0.10050037556080604, 0.12056820281654723, 0.11790742708612945, 0.10810100118285704, 0.09540903694559943, 0.11945223318427667, 0.16861351363204835, 0.13881787718018546, 0.11617563204535197, 0.11941732034884989, 0.11537215430067116, 0.10417659619313091, 0.1898982997198737, 0.10425093675056474, 0.11308425337932637, 0.11822865118672854, 0.17368298710943453, 0.1416507573591811, 0.9772200223208363, 0.9605157954294056, 0.9698961302235226, 0.9548992771122515, 0.9585392523517984, 0.9568946664494513, 0.9453426073012882, 0.9453074450553327, 0.9696797397539388, 0.6099818761559822, 0.6259642700208095, 0.6279249698435632, 0.6250382463363402, 0.6503314667048186, 0.577313838243521, 0.6360962553392986, 0.6396505088269324, 0.6585682316581949, 0.7979813519339483, 0.8140936547009936, 0.8233674594803781, 0.8000725342930506, 0.8301729328475332, 0.8172819002914907, 0.8261712281128872, 0.8230261521199056, 0.7958892886037937, 0.5998328779517017, 0.5856039456328322, 0.6423524312814166, 0.5487347043545969, 0.5377205546292183, 0.6198981758598103, 0.6327768174977519, 0.5364468349899949, 0.5949939429256261, 0.5996842334915555, 0.5154932707406408, 0.5813131354836566, 0.6130549556137426, 0.5813932946990845, 0.5111854030880189, 0.5478409024818174, 0.5529651129813227, 0.5971762926772167, 0.5922374365401037, 0.5613558097715612, 0.590288944963572, 0.5616869773946163, 0.5781535422343277, 0.5840458611014829, 0.6241519321867655, 0.594661729954099, 0.6147826103511655, 0.6858347471633415, 0.6435280317073684, 0.6775386398738334, 0.6721825310578738, 0.656630018011745, 0.6823972629619932, 0.7417454624012845, 0.6920765556986207, 0.7036722344065016, 0.3339259168390225, 0.28548238347509136, 0.3699793692953084, 0.489838644328657, 0.5072507351905968, 0.4338904830580954, 0.3452229130875957, 0.17220507937260665, 0.14940873507014496, 0.48852192594208665, 0.46196367121245574, 0.4564070343900706, 0.4861584979419501, 0.43638377493033087, 0.4385439067112785, 0.486382308944443, 0.4971074949998934, 0.45227985579885155, 0.7915215499287558, 0.7685530154010431, 0.8003542291011886, 0.7957798925478587, 0.7842877533997992, 0.7860893471055231, 0.7683026035787064, 0.793757682990629, 0.7807780440423455, 0.09116993306969312, 0.11598806720921018, 0.08056896148033321, 0.10548092985022961, 0.14747320854022494, 0.11371317895035138, 0.10624295801950068, 0.10023515112062864, 0.09803569988903182, 0.15864492729216673, 0.24666361609437548, 0.14353638761779552, 0.16828367208469697, 0.2989565752808566, 0.1581731048090882, 0.17618274545597779, 0.16017207055616622, 0.13916650241338702, 0.4407275555873804, 0.4315706540511579, 0.4679246514721085, 0.44504992660408693, 0.42348524380708785, 0.4813780469113451, 0.502002619996262, 0.4834021462637602, 0.46678689580970356, 0.40876811315480854, 0.31499831336112694, 0.33877659432558316, 0.38582739620954765, 0.3621974192728492, 0.3248264453981755, 0.3686471322096395, 0.3976434605742364, 0.38660371383250614, 0.19180516142864878, 0.1881074510804428, 0.20574555717212684, 0.1714365143677169, 0.18088302557315417, 0.1997286965919256, 0.18674692954462924, 0.202834583015002, 0.19105328675825206, 0.3039814115105216, 0.20085941461610113, 0.20872774728567833, 0.4016169507796613, 0.5647567798632083, 0.21796566168269604, 0.26751408658020004, 0.4733019798252064, 0.195471442201127, 0.1698371642808152, 0.8228793616370091, 0.21056662241253643, 0.8622802926542299, 0.184849304347111, 0.1843641179281127, 0.1646676663498864, 0.787544444225702, 0.8235973356417357, 0.152087068684591, 0.1663988958662458, 0.20760054474394196, 0.2020392761995895, 0.7612598373901736, 0.7351024411123432, 0.2116997086142942, 0.21019033846531354, 0.19345932926678822, 0.17849131900400061, 0.17988287885215137, 0.17816820814887357, 0.17495652970472397, 0.1500319992125434, 0.1696033618039523, 0.18590666174299908, 0.17895526958891173, 0.17996979361264187, 0.08074055756647247, 0.08489884324544161, 0.07083655874461636, 0.07836045123715363, 0.08048892441349687, 0.07767100174633434, 0.0836134274416045, 0.07376461736476525, 0.07989978158015587]}, "mutation_prompt": null}
{"id": "bf3be3a7-1727-49cd-9fe7-549060d4a58a", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.local_search_prob = 0.1  # New parameter for local search\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor)\n                trial[crossover] = mutant[crossover]\n\n                # Local Search Intensification\n                if np.random.rand() < self.local_search_prob:\n                    neighborhood = population[np.random.choice(idxs, 2, replace=False)]\n                    local_search_point = neighborhood.mean(axis=0)\n                    local_search_point = np.clip(local_search_point + 0.1 * np.random.randn(self.dim), self.bounds[0], self.bounds[1])\n                    local_search_fitness = func(local_search_point)\n                    func_evals += 1\n                    if local_search_fitness < trial_fitness:\n                        trial = local_search_point\n                        trial_fitness = local_search_fitness\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning\n            self.scale_factor = np.random.uniform(0.6, 0.85)\n            self.cross_prob = np.random.uniform(0.85, 1.0)\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer introducing local search intensification and dynamic neighborhood adjustment to improve convergence speed.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'trial_fitness' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'trial_fitness' referenced before assignment\")", "parent_id": "6fa279be-1767-470f-bda7-b5086b999320", "metadata": {}, "mutation_prompt": null}
{"id": "570794e9-9191-4f1d-ab4f-f9bf9a009dea", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n                \n                # Enhanced Diversity Strategy\n                if np.random.rand() < 0.2:\n                    mutant += np.random.normal(0, 0.1, self.dim)  # Small random perturbation\n                \n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor)\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Refined Self-adaptive Parameter Tuning\n            self.scale_factor = np.random.uniform(0.65, 0.85)\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer with scaled adaptation and diversity enhancement for improved convergence speed.", "configspace": "", "generation": 20, "fitness": 0.4186372277035155, "feedback": "The algorithm ImprovedHybridEvolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.42 with standard deviation 0.26.", "error": "", "parent_id": "6fa279be-1767-470f-bda7-b5086b999320", "metadata": {"aucs": [0.8040174283426161, 0.8068305190084173, 0.8098828046186688, 0.8454839053649081, 0.8015914692687678, 0.8162919308402586, 0.8161189937491778, 0.8212416849174552, 0.8099571700959662, 0.652148078849601, 0.6878459087911593, 0.631597761039372, 0.675151020863956, 0.6725287900362877, 0.6478173882141348, 0.6656317324744492, 0.6417862424231345, 0.663187387959598, 0.10244148220634941, 0.1262767741978188, 0.14672841058269004, 0.10488731472384571, 0.11286185903740753, 0.10373431705112601, 0.12708778256622988, 0.13894550478624512, 0.12605246783450474, 0.09048802110700149, 0.10711453961567763, 0.10034530681204545, 0.09898195399972809, 0.1113463090437039, 0.10806272079533608, 0.12221994628683386, 0.10274078374354356, 0.10354824574968591, 0.9449691304620649, 0.9440262609498222, 0.9807844130208239, 0.9493799693276245, 0.938625153618836, 0.9863872466002735, 0.9656311081222236, 0.9583124787467457, 0.9309554580127197, 0.5587028103322964, 0.5346735749019182, 0.5634313911853898, 0.5154196632616034, 0.5499303109801184, 0.5229731702365943, 0.5424406002580586, 0.5026829927834269, 0.590746985995486, 0.8492141052446205, 0.783341161572193, 0.747686135131156, 0.8335294814275984, 0.7682219292323385, 0.7871681879441939, 0.7926841831631073, 0.7725405289119858, 0.8126981801620943, 0.5757723156837476, 0.5573435523774651, 0.5393571369462592, 0.41769440354693066, 0.4447816210032449, 0.5008998098953631, 0.5002994620661304, 0.5242286318073446, 0.5015296069711663, 0.548099777675445, 0.6437906078616796, 0.49343280139473233, 0.5271666611363854, 0.4721546049023757, 0.40757399113204296, 0.49468258824436584, 0.4261594944634377, 0.5488687455205357, 0.5195888330615097, 0.5084250430712696, 0.5353299593698435, 0.47829036599963215, 0.5149114908215713, 0.507755218016409, 0.5447687353430432, 0.5855336840162666, 0.5059966305704706, 0.6319379271270249, 0.5913187385037277, 0.5792822170566498, 0.5973428592368233, 0.576111561418849, 0.6182491880539616, 0.6839682590071938, 0.6540055960379687, 0.653972967341408, 0.28082594437301345, 0.14235221613158133, 0.3356964430577285, 0.378549650046061, 0.22193905343715237, 0.24543028594600824, 0.18667080548194426, 0.17527885603881443, 0.2504000465838073, 0.34068329045143997, 0.36586488314298293, 0.36667919552616135, 0.3796218396397508, 0.35336852479088554, 0.3878586801028079, 0.3878109992990342, 0.366166146445126, 0.3489135383915828, 0.7551986838298874, 0.732274304610804, 0.7726035039449194, 0.766232090618539, 0.7387647462108262, 0.7158369273973655, 0.7497229393978325, 0.7456059973138933, 0.7423168314113455, 0.10055684352497885, 0.12676021215277855, 0.09531046780345864, 0.10691157944955121, 0.10931208424511119, 0.10465135440375994, 0.12076743239528354, 0.11509170351804754, 0.0996050824053486, 0.1866238717396167, 0.3387513319471773, 0.326463279780972, 0.2603058842433307, 0.21013304477491201, 0.1899784021234805, 0.31795910822027496, 0.5133963231240041, 0.2965051557929158, 0.39654710991729425, 0.3624734038744333, 0.4119627193148422, 0.39906027438325054, 0.3646184882078243, 0.38876166084819797, 0.4111849118608859, 0.39618865351950305, 0.42176940043908306, 0.2939743504765383, 0.3135302185086709, 0.35174684004766055, 0.31555125365670145, 0.29844457105352584, 0.29740808291593135, 0.3591187714169777, 0.33057461819419565, 0.34672615581109845, 0.17287693676223803, 0.203458306393969, 0.19415504010551876, 0.19196936329680336, 0.1976930520735417, 0.21322309453525345, 0.2028830724894879, 0.19424510318054844, 0.18268960695081338, 0.30369169272864116, 0.35979136853975235, 0.19770514219393198, 0.21015875270083528, 0.39395252053846264, 0.2181498905431225, 0.19568861435993856, 0.18155494359156343, 0.2086935170296249, 0.19923484543082615, 0.8555813938900719, 0.153178377808866, 0.20291976950602908, 0.1865362350678368, 0.17686460516858804, 0.8384604614794001, 0.17289974044061762, 0.8154689205977773, 0.16557734704818527, 0.7652242131727749, 0.12562849869145742, 0.7105825901567855, 0.20142929757053463, 0.1513214532374232, 0.20883303330801573, 0.2111414896812469, 0.21041300298988597, 0.1718391623727592, 0.20124356562930923, 0.17924602236064524, 0.17021835892617887, 0.1821841232518051, 0.20984058240129344, 0.17929010196191209, 0.18923759277181873, 0.19468722179080689, 0.07294945469849168, 0.07366069465159286, 0.08158326125670179, 0.08666282227408029, 0.07858021548835492, 0.07019415033537446, 0.07101173623095669, 0.0898401746628067, 0.09734992465589565]}, "mutation_prompt": null}
{"id": "6a8366de-2a22-445b-9d84-e9341393112e", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor)\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning\n            self.scale_factor = np.random.uniform(0.6, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.85, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with adaptive differential mutation and dynamic crossover to improve exploration and convergence speed.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "6fa279be-1767-470f-bda7-b5086b999320", "metadata": {"aucs": [0.825271308868495, 0.8428562615295943, 0.8426625620263116, 0.8338708356204272, 0.8503446132560646, 0.8533812003271036, 0.8380760541245388, 0.8183630669908136, 0.8420271450471732, 0.7086853159064155, 0.7396069105138292, 0.7602038680842589, 0.7323295436843005, 0.7366153944846856, 0.7106020482318696, 0.718036720391436, 0.7320309437956423, 0.7399472732068899, 0.10050037556080604, 0.12056820281654723, 0.11790742708612945, 0.10810100118285704, 0.09540903694559943, 0.11945223318427667, 0.16861351363204835, 0.13881787718018546, 0.11617563204535197, 0.11941732034884989, 0.11537215430067116, 0.10417659619313091, 0.1898982997198737, 0.10425093675056474, 0.11308425337932637, 0.11822865118672854, 0.17368298710943453, 0.1416507573591811, 0.9772200223208363, 0.9605157954294056, 0.9698961302235226, 0.9548992771122515, 0.9585392523517984, 0.9568946664494513, 0.9453426073012882, 0.9453074450553327, 0.9696797397539388, 0.6099818761559822, 0.6259642700208095, 0.6279249698435632, 0.6250382463363402, 0.6503314667048186, 0.577313838243521, 0.6360962553392986, 0.6396505088269324, 0.6585682316581949, 0.7979813519339483, 0.8140936547009936, 0.8233674594803781, 0.8000725342930506, 0.8301729328475332, 0.8172819002914907, 0.8261712281128872, 0.8230261521199056, 0.7958892886037937, 0.5998328779517017, 0.5856039456328322, 0.6423524312814166, 0.5487347043545969, 0.5377205546292183, 0.6198981758598103, 0.6327768174977519, 0.5364468349899949, 0.5949939429256261, 0.5996842334915555, 0.5154932707406408, 0.5813131354836566, 0.6130549556137426, 0.5813932946990845, 0.5111854030880189, 0.5478409024818174, 0.5529651129813227, 0.5971762926772167, 0.5922374365401037, 0.5613558097715612, 0.590288944963572, 0.5616869773946163, 0.5781535422343277, 0.5840458611014829, 0.6241519321867655, 0.594661729954099, 0.6147826103511655, 0.6858347471633415, 0.6435280317073684, 0.6775386398738334, 0.6721825310578738, 0.656630018011745, 0.6823972629619932, 0.7417454624012845, 0.6920765556986207, 0.7036722344065016, 0.3339259168390225, 0.28548238347509136, 0.3699793692953084, 0.489838644328657, 0.5072507351905968, 0.4338904830580954, 0.3452229130875957, 0.17220507937260665, 0.14940873507014496, 0.48852192594208665, 0.46196367121245574, 0.4564070343900706, 0.4861584979419501, 0.43638377493033087, 0.4385439067112785, 0.486382308944443, 0.4971074949998934, 0.45227985579885155, 0.7915215499287558, 0.7685530154010431, 0.8003542291011886, 0.7957798925478587, 0.7842877533997992, 0.7860893471055231, 0.7683026035787064, 0.793757682990629, 0.7807780440423455, 0.09116993306969312, 0.11598806720921018, 0.08056896148033321, 0.10548092985022961, 0.14747320854022494, 0.11371317895035138, 0.10624295801950068, 0.10023515112062864, 0.09803569988903182, 0.15864492729216673, 0.24666361609437548, 0.14353638761779552, 0.16828367208469697, 0.2989565752808566, 0.1581731048090882, 0.17618274545597779, 0.16017207055616622, 0.13916650241338702, 0.4407275555873804, 0.4315706540511579, 0.4679246514721085, 0.44504992660408693, 0.42348524380708785, 0.4813780469113451, 0.502002619996262, 0.4834021462637602, 0.46678689580970356, 0.40876811315480854, 0.31499831336112694, 0.33877659432558316, 0.38582739620954765, 0.3621974192728492, 0.3248264453981755, 0.3686471322096395, 0.3976434605742364, 0.38660371383250614, 0.19180516142864878, 0.1881074510804428, 0.20574555717212684, 0.1714365143677169, 0.18088302557315417, 0.1997286965919256, 0.18674692954462924, 0.202834583015002, 0.19105328675825206, 0.3039814115105216, 0.20085941461610113, 0.20872774728567833, 0.4016169507796613, 0.5647567798632083, 0.21796566168269604, 0.26751408658020004, 0.4733019798252064, 0.195471442201127, 0.1698371642808152, 0.8228793616370091, 0.21056662241253643, 0.8622802926542299, 0.184849304347111, 0.1843641179281127, 0.1646676663498864, 0.787544444225702, 0.8235973356417357, 0.152087068684591, 0.1663988958662458, 0.20760054474394196, 0.2020392761995895, 0.7612598373901736, 0.7351024411123432, 0.2116997086142942, 0.21019033846531354, 0.19345932926678822, 0.17849131900400061, 0.17988287885215137, 0.17816820814887357, 0.17495652970472397, 0.1500319992125434, 0.1696033618039523, 0.18590666174299908, 0.17895526958891173, 0.17996979361264187, 0.08074055756647247, 0.08489884324544161, 0.07083655874461636, 0.07836045123715363, 0.08048892441349687, 0.07767100174633434, 0.0836134274416045, 0.07376461736476525, 0.07989978158015587]}, "mutation_prompt": null}
{"id": "83948369-f2c9-49d5-84c3-a04335d2d202", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor)\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning\n            self.scale_factor = np.random.uniform(0.6, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.85, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with adaptive differential mutation and dynamic crossover to improve exploration and convergence speed.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "6fa279be-1767-470f-bda7-b5086b999320", "metadata": {"aucs": [0.825271308868495, 0.8428562615295943, 0.8426625620263116, 0.8338708356204272, 0.8503446132560646, 0.8533812003271036, 0.8380760541245388, 0.8183630669908136, 0.8420271450471732, 0.7086853159064155, 0.7396069105138292, 0.7602038680842589, 0.7323295436843005, 0.7366153944846856, 0.7106020482318696, 0.718036720391436, 0.7320309437956423, 0.7399472732068899, 0.10050037556080604, 0.12056820281654723, 0.11790742708612945, 0.10810100118285704, 0.09540903694559943, 0.11945223318427667, 0.16861351363204835, 0.13881787718018546, 0.11617563204535197, 0.11941732034884989, 0.11537215430067116, 0.10417659619313091, 0.1898982997198737, 0.10425093675056474, 0.11308425337932637, 0.11822865118672854, 0.17368298710943453, 0.1416507573591811, 0.9772200223208363, 0.9605157954294056, 0.9698961302235226, 0.9548992771122515, 0.9585392523517984, 0.9568946664494513, 0.9453426073012882, 0.9453074450553327, 0.9696797397539388, 0.6099818761559822, 0.6259642700208095, 0.6279249698435632, 0.6250382463363402, 0.6503314667048186, 0.577313838243521, 0.6360962553392986, 0.6396505088269324, 0.6585682316581949, 0.7979813519339483, 0.8140936547009936, 0.8233674594803781, 0.8000725342930506, 0.8301729328475332, 0.8172819002914907, 0.8261712281128872, 0.8230261521199056, 0.7958892886037937, 0.5998328779517017, 0.5856039456328322, 0.6423524312814166, 0.5487347043545969, 0.5377205546292183, 0.6198981758598103, 0.6327768174977519, 0.5364468349899949, 0.5949939429256261, 0.5996842334915555, 0.5154932707406408, 0.5813131354836566, 0.6130549556137426, 0.5813932946990845, 0.5111854030880189, 0.5478409024818174, 0.5529651129813227, 0.5971762926772167, 0.5922374365401037, 0.5613558097715612, 0.590288944963572, 0.5616869773946163, 0.5781535422343277, 0.5840458611014829, 0.6241519321867655, 0.594661729954099, 0.6147826103511655, 0.6858347471633415, 0.6435280317073684, 0.6775386398738334, 0.6721825310578738, 0.656630018011745, 0.6823972629619932, 0.7417454624012845, 0.6920765556986207, 0.7036722344065016, 0.3339259168390225, 0.28548238347509136, 0.3699793692953084, 0.489838644328657, 0.5072507351905968, 0.4338904830580954, 0.3452229130875957, 0.17220507937260665, 0.14940873507014496, 0.48852192594208665, 0.46196367121245574, 0.4564070343900706, 0.4861584979419501, 0.43638377493033087, 0.4385439067112785, 0.486382308944443, 0.4971074949998934, 0.45227985579885155, 0.7915215499287558, 0.7685530154010431, 0.8003542291011886, 0.7957798925478587, 0.7842877533997992, 0.7860893471055231, 0.7683026035787064, 0.793757682990629, 0.7807780440423455, 0.09116993306969312, 0.11598806720921018, 0.08056896148033321, 0.10548092985022961, 0.14747320854022494, 0.11371317895035138, 0.10624295801950068, 0.10023515112062864, 0.09803569988903182, 0.15864492729216673, 0.24666361609437548, 0.14353638761779552, 0.16828367208469697, 0.2989565752808566, 0.1581731048090882, 0.17618274545597779, 0.16017207055616622, 0.13916650241338702, 0.4407275555873804, 0.4315706540511579, 0.4679246514721085, 0.44504992660408693, 0.42348524380708785, 0.4813780469113451, 0.502002619996262, 0.4834021462637602, 0.46678689580970356, 0.40876811315480854, 0.31499831336112694, 0.33877659432558316, 0.38582739620954765, 0.3621974192728492, 0.3248264453981755, 0.3686471322096395, 0.3976434605742364, 0.38660371383250614, 0.19180516142864878, 0.1881074510804428, 0.20574555717212684, 0.1714365143677169, 0.18088302557315417, 0.1997286965919256, 0.18674692954462924, 0.202834583015002, 0.19105328675825206, 0.3039814115105216, 0.20085941461610113, 0.20872774728567833, 0.4016169507796613, 0.5647567798632083, 0.21796566168269604, 0.26751408658020004, 0.4733019798252064, 0.195471442201127, 0.1698371642808152, 0.8228793616370091, 0.21056662241253643, 0.8622802926542299, 0.184849304347111, 0.1843641179281127, 0.1646676663498864, 0.787544444225702, 0.8235973356417357, 0.152087068684591, 0.1663988958662458, 0.20760054474394196, 0.2020392761995895, 0.7612598373901736, 0.7351024411123432, 0.2116997086142942, 0.21019033846531354, 0.19345932926678822, 0.17849131900400061, 0.17988287885215137, 0.17816820814887357, 0.17495652970472397, 0.1500319992125434, 0.1696033618039523, 0.18590666174299908, 0.17895526958891173, 0.17996979361264187, 0.08074055756647247, 0.08489884324544161, 0.07083655874461636, 0.07836045123715363, 0.08048892441349687, 0.07767100174633434, 0.0836134274416045, 0.07376461736476525, 0.07989978158015587]}, "mutation_prompt": null}
{"id": "ed631ad2-e5c8-45a2-a466-53c76692d6e6", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor)\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning\n            self.scale_factor = np.random.uniform(0.6, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.85, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with adaptive differential mutation and dynamic crossover to improve exploration and convergence speed.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "6fa279be-1767-470f-bda7-b5086b999320", "metadata": {"aucs": [0.825271308868495, 0.8428562615295943, 0.8426625620263116, 0.8338708356204272, 0.8503446132560646, 0.8533812003271036, 0.8380760541245388, 0.8183630669908136, 0.8420271450471732, 0.7086853159064155, 0.7396069105138292, 0.7602038680842589, 0.7323295436843005, 0.7366153944846856, 0.7106020482318696, 0.718036720391436, 0.7320309437956423, 0.7399472732068899, 0.10050037556080604, 0.12056820281654723, 0.11790742708612945, 0.10810100118285704, 0.09540903694559943, 0.11945223318427667, 0.16861351363204835, 0.13881787718018546, 0.11617563204535197, 0.11941732034884989, 0.11537215430067116, 0.10417659619313091, 0.1898982997198737, 0.10425093675056474, 0.11308425337932637, 0.11822865118672854, 0.17368298710943453, 0.1416507573591811, 0.9772200223208363, 0.9605157954294056, 0.9698961302235226, 0.9548992771122515, 0.9585392523517984, 0.9568946664494513, 0.9453426073012882, 0.9453074450553327, 0.9696797397539388, 0.6099818761559822, 0.6259642700208095, 0.6279249698435632, 0.6250382463363402, 0.6503314667048186, 0.577313838243521, 0.6360962553392986, 0.6396505088269324, 0.6585682316581949, 0.7979813519339483, 0.8140936547009936, 0.8233674594803781, 0.8000725342930506, 0.8301729328475332, 0.8172819002914907, 0.8261712281128872, 0.8230261521199056, 0.7958892886037937, 0.5998328779517017, 0.5856039456328322, 0.6423524312814166, 0.5487347043545969, 0.5377205546292183, 0.6198981758598103, 0.6327768174977519, 0.5364468349899949, 0.5949939429256261, 0.5996842334915555, 0.5154932707406408, 0.5813131354836566, 0.6130549556137426, 0.5813932946990845, 0.5111854030880189, 0.5478409024818174, 0.5529651129813227, 0.5971762926772167, 0.5922374365401037, 0.5613558097715612, 0.590288944963572, 0.5616869773946163, 0.5781535422343277, 0.5840458611014829, 0.6241519321867655, 0.594661729954099, 0.6147826103511655, 0.6858347471633415, 0.6435280317073684, 0.6775386398738334, 0.6721825310578738, 0.656630018011745, 0.6823972629619932, 0.7417454624012845, 0.6920765556986207, 0.7036722344065016, 0.3339259168390225, 0.28548238347509136, 0.3699793692953084, 0.489838644328657, 0.5072507351905968, 0.4338904830580954, 0.3452229130875957, 0.17220507937260665, 0.14940873507014496, 0.48852192594208665, 0.46196367121245574, 0.4564070343900706, 0.4861584979419501, 0.43638377493033087, 0.4385439067112785, 0.486382308944443, 0.4971074949998934, 0.45227985579885155, 0.7915215499287558, 0.7685530154010431, 0.8003542291011886, 0.7957798925478587, 0.7842877533997992, 0.7860893471055231, 0.7683026035787064, 0.793757682990629, 0.7807780440423455, 0.09116993306969312, 0.11598806720921018, 0.08056896148033321, 0.10548092985022961, 0.14747320854022494, 0.11371317895035138, 0.10624295801950068, 0.10023515112062864, 0.09803569988903182, 0.15864492729216673, 0.24666361609437548, 0.14353638761779552, 0.16828367208469697, 0.2989565752808566, 0.1581731048090882, 0.17618274545597779, 0.16017207055616622, 0.13916650241338702, 0.4407275555873804, 0.4315706540511579, 0.4679246514721085, 0.44504992660408693, 0.42348524380708785, 0.4813780469113451, 0.502002619996262, 0.4834021462637602, 0.46678689580970356, 0.40876811315480854, 0.31499831336112694, 0.33877659432558316, 0.38582739620954765, 0.3621974192728492, 0.3248264453981755, 0.3686471322096395, 0.3976434605742364, 0.38660371383250614, 0.19180516142864878, 0.1881074510804428, 0.20574555717212684, 0.1714365143677169, 0.18088302557315417, 0.1997286965919256, 0.18674692954462924, 0.202834583015002, 0.19105328675825206, 0.3039814115105216, 0.20085941461610113, 0.20872774728567833, 0.4016169507796613, 0.5647567798632083, 0.21796566168269604, 0.26751408658020004, 0.4733019798252064, 0.195471442201127, 0.1698371642808152, 0.8228793616370091, 0.21056662241253643, 0.8622802926542299, 0.184849304347111, 0.1843641179281127, 0.1646676663498864, 0.787544444225702, 0.8235973356417357, 0.152087068684591, 0.1663988958662458, 0.20760054474394196, 0.2020392761995895, 0.7612598373901736, 0.7351024411123432, 0.2116997086142942, 0.21019033846531354, 0.19345932926678822, 0.17849131900400061, 0.17988287885215137, 0.17816820814887357, 0.17495652970472397, 0.1500319992125434, 0.1696033618039523, 0.18590666174299908, 0.17895526958891173, 0.17996979361264187, 0.08074055756647247, 0.08489884324544161, 0.07083655874461636, 0.07836045123715363, 0.08048892441349687, 0.07767100174633434, 0.0836134274416045, 0.07376461736476525, 0.07989978158015587]}, "mutation_prompt": null}
{"id": "861cd3e5-fef8-4d90-a5d1-b5c310a7510e", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Refined Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover with enhanced probability adaptation\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.1))\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning with more granular adjustments\n            self.scale_factor = np.random.uniform(0.65, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.88, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with refined adaptive mutation and crossover strategies to improve convergence efficiency.", "configspace": "", "generation": 24, "fitness": 0.45940873607428556, "feedback": "The algorithm ImprovedHybridEvolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.46 with standard deviation 0.28.", "error": "", "parent_id": "6fa279be-1767-470f-bda7-b5086b999320", "metadata": {"aucs": [0.822419785938898, 0.8199714546643329, 0.8414894141977063, 0.8430091771653526, 0.8593885836191024, 0.8487231796708052, 0.8367890364383294, 0.8302523382030463, 0.8293736847039304, 0.6900526707292051, 0.729827418174816, 0.7165636142714544, 0.7210593429287958, 0.7066488819727987, 0.73925793568504, 0.7290705693599189, 0.7228033402871135, 0.7062545396178945, 0.1276970958927961, 0.10836103147880471, 0.10584430366771846, 0.3699480834266704, 0.14078795992086013, 0.11173662417811558, 0.24405632789960074, 0.1979650359645696, 0.11807834733719214, 0.09487999780108625, 0.12368899362754915, 0.1075596948214832, 0.13173357002036357, 0.09980875650657273, 0.11640007866229085, 0.1278981270616787, 0.12028358906634584, 0.12155953374756501, 0.9267733553648255, 0.8780210526035417, 0.9728814299618388, 0.9627363618388612, 0.9068972901895733, 0.9753106988533982, 0.950121428753759, 0.9613290656568141, 0.9730778020274361, 0.6217127761634991, 0.5898663642757915, 0.6498912945803319, 0.5908153910909509, 0.6029460563973829, 0.601656570202229, 0.5726798590248927, 0.5981797797944681, 0.610924263252564, 0.8272794955422078, 0.7839572083705488, 0.8292962044243667, 0.8387891564677299, 0.8155388282714626, 0.8237694981028187, 0.8208478301223947, 0.8030835718841802, 0.8302702542657152, 0.6115389342871294, 0.6505395783882206, 0.6010719361145394, 0.6201992295121656, 0.5474925340891813, 0.12496363056790527, 0.6172883917916766, 0.5800103510803774, 0.6178082965572207, 0.5198145289921565, 0.01669045686983861, 0.537493623059079, 0.5574622518931232, 0.583907273603204, 0.6325076991684645, 0.6040173477737164, 0.5772205189597104, 0.4477021493834583, 0.5951745198118525, 0.5751254750305228, 0.611168261060888, 0.6095156079537748, 0.5613895288278088, 0.653165236812457, 0.578010382898307, 0.5906344030858592, 0.5734038836895186, 0.6973248370362327, 0.6690598036518844, 0.6847305193213178, 0.7061685940428326, 0.7127427735436558, 0.6956403853904165, 0.7256654724870555, 0.6974935332756751, 0.6800657796012706, 0.26886888297261247, 0.2567298455899326, 0.1978498023786025, 0.4711096272090417, 0.4616923459558898, 0.33646622305502594, 0.3003209734846265, 0.2923859164690722, 0.2917522917795389, 0.4407450260626149, 0.47750354188731814, 0.44573651789588875, 0.46007102069606187, 0.4623265148506259, 0.4698450507558254, 0.4983374796651274, 0.4651038353049999, 0.4906097444919848, 0.7939959747146519, 0.7512639921384054, 0.8024278744310025, 0.7655647590715289, 0.7860141525136092, 0.7469872082840403, 0.7837308674550727, 0.7867152501597141, 0.7814435476452145, 0.10731152787756348, 0.11531064980216776, 0.13327898151509088, 0.0845459419935578, 0.1129017830272383, 0.10799288264697948, 0.09026607095640027, 0.09242354853904122, 0.11414610931447933, 0.14859750401177263, 0.16993161980945604, 0.21808791662555005, 0.17893340336430485, 0.20673396640031128, 0.17514927217005238, 0.21812932372262783, 0.1816380653821965, 0.1969196835645982, 0.4445529723727534, 0.42052418256371293, 0.4832803672599898, 0.434256993835186, 0.45321080811656955, 0.43851286281310375, 0.47433954584356, 0.44995204167902425, 0.4907650783321168, 0.36028806305334393, 0.3637094622146594, 0.2797815375835401, 0.339563147640781, 0.3282683863725553, 0.33629759002845827, 0.38231494403451727, 0.36727042862318426, 0.40476782964212854, 0.19355751934158139, 0.222651046201242, 0.20008507149009302, 0.24076494486116384, 0.1823909733253869, 0.23823667947716676, 0.18896336916398737, 0.1775488692840156, 0.19825657499372007, 0.31328935485711895, 0.24978833520335753, 0.5467031594247906, 0.22580931177013186, 0.3068491624219365, 0.20701222076673953, 0.20878834757163556, 0.26504852465161, 0.19381349682665883, 0.8488604691570416, 0.17137799400702514, 0.17022881054803018, 0.8712490731729117, 0.2056317133448773, 0.775756989121672, 0.16335836936746595, 0.17793760622496502, 0.8524947927571764, 0.8179025205290024, 0.7358647696051241, 0.8190914110923364, 0.201869625298709, 0.16556880117395845, 0.7141282873355854, 0.2071428842442561, 0.8635935380607013, 0.791471704067155, 0.18662858002296845, 0.186359167637123, 0.19667438813877036, 0.18593125007449574, 0.16702174357922817, 0.17072242613914146, 0.18406270829058735, 0.1883483385411402, 0.21088470591522512, 0.08556516989537444, 0.08019225669858099, 0.08286134945626689, 0.07496979065675446, 0.0850600782588915, 0.0735401347951864, 0.07636235899990385, 0.07709528013485212, 0.07326544861438689]}, "mutation_prompt": null}
{"id": "4088754a-67a7-4ef4-8999-039c66faca1f", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Refined Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover with enhanced probability adaptation\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.1))\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning with more granular adjustments\n            self.scale_factor = np.random.uniform(0.65, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.88, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with refined adaptive mutation and crossover strategies to improve convergence efficiency.", "configspace": "", "generation": 25, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "861cd3e5-fef8-4d90-a5d1-b5c310a7510e", "metadata": {"aucs": [0.822419785938898, 0.8199714546643329, 0.8414894141977063, 0.8430091771653526, 0.8593885836191024, 0.8487231796708052, 0.8367890364383294, 0.8302523382030463, 0.8293736847039304, 0.6900526707292051, 0.729827418174816, 0.7165636142714544, 0.7210593429287958, 0.7066488819727987, 0.73925793568504, 0.7290705693599189, 0.7228033402871135, 0.7062545396178945, 0.1276970958927961, 0.10836103147880471, 0.10584430366771846, 0.3699480834266704, 0.14078795992086013, 0.11173662417811558, 0.24405632789960074, 0.1979650359645696, 0.11807834733719214, 0.09487999780108625, 0.12368899362754915, 0.1075596948214832, 0.13173357002036357, 0.09980875650657273, 0.11640007866229085, 0.1278981270616787, 0.12028358906634584, 0.12155953374756501, 0.9267733553648255, 0.8780210526035417, 0.9728814299618388, 0.9627363618388612, 0.9068972901895733, 0.9753106988533982, 0.950121428753759, 0.9613290656568141, 0.9730778020274361, 0.6217127761634991, 0.5898663642757915, 0.6498912945803319, 0.5908153910909509, 0.6029460563973829, 0.601656570202229, 0.5726798590248927, 0.5981797797944681, 0.610924263252564, 0.8272794955422078, 0.7839572083705488, 0.8292962044243667, 0.8387891564677299, 0.8155388282714626, 0.8237694981028187, 0.8208478301223947, 0.8030835718841802, 0.8302702542657152, 0.6115389342871294, 0.6505395783882206, 0.6010719361145394, 0.6201992295121656, 0.5474925340891813, 0.12496363056790527, 0.6172883917916766, 0.5800103510803774, 0.6178082965572207, 0.5198145289921565, 0.01669045686983861, 0.537493623059079, 0.5574622518931232, 0.583907273603204, 0.6325076991684645, 0.6040173477737164, 0.5772205189597104, 0.4477021493834583, 0.5951745198118525, 0.5751254750305228, 0.611168261060888, 0.6095156079537748, 0.5613895288278088, 0.653165236812457, 0.578010382898307, 0.5906344030858592, 0.5734038836895186, 0.6973248370362327, 0.6690598036518844, 0.6847305193213178, 0.7061685940428326, 0.7127427735436558, 0.6956403853904165, 0.7256654724870555, 0.6974935332756751, 0.6800657796012706, 0.26886888297261247, 0.2567298455899326, 0.1978498023786025, 0.4711096272090417, 0.4616923459558898, 0.33646622305502594, 0.3003209734846265, 0.2923859164690722, 0.2917522917795389, 0.4407450260626149, 0.47750354188731814, 0.44573651789588875, 0.46007102069606187, 0.4623265148506259, 0.4698450507558254, 0.4983374796651274, 0.4651038353049999, 0.4906097444919848, 0.7939959747146519, 0.7512639921384054, 0.8024278744310025, 0.7655647590715289, 0.7860141525136092, 0.7469872082840403, 0.7837308674550727, 0.7867152501597141, 0.7814435476452145, 0.10731152787756348, 0.11531064980216776, 0.13327898151509088, 0.0845459419935578, 0.1129017830272383, 0.10799288264697948, 0.09026607095640027, 0.09242354853904122, 0.11414610931447933, 0.14859750401177263, 0.16993161980945604, 0.21808791662555005, 0.17893340336430485, 0.20673396640031128, 0.17514927217005238, 0.21812932372262783, 0.1816380653821965, 0.1969196835645982, 0.4445529723727534, 0.42052418256371293, 0.4832803672599898, 0.434256993835186, 0.45321080811656955, 0.43851286281310375, 0.47433954584356, 0.44995204167902425, 0.4907650783321168, 0.36028806305334393, 0.3637094622146594, 0.2797815375835401, 0.339563147640781, 0.3282683863725553, 0.33629759002845827, 0.38231494403451727, 0.36727042862318426, 0.40476782964212854, 0.19355751934158139, 0.222651046201242, 0.20008507149009302, 0.24076494486116384, 0.1823909733253869, 0.23823667947716676, 0.18896336916398737, 0.1775488692840156, 0.19825657499372007, 0.31328935485711895, 0.24978833520335753, 0.5467031594247906, 0.22580931177013186, 0.3068491624219365, 0.20701222076673953, 0.20878834757163556, 0.26504852465161, 0.19381349682665883, 0.8488604691570416, 0.17137799400702514, 0.17022881054803018, 0.8712490731729117, 0.2056317133448773, 0.775756989121672, 0.16335836936746595, 0.17793760622496502, 0.8524947927571764, 0.8179025205290024, 0.7358647696051241, 0.8190914110923364, 0.201869625298709, 0.16556880117395845, 0.7141282873355854, 0.2071428842442561, 0.8635935380607013, 0.791471704067155, 0.18662858002296845, 0.186359167637123, 0.19667438813877036, 0.18593125007449574, 0.16702174357922817, 0.17072242613914146, 0.18406270829058735, 0.1883483385411402, 0.21088470591522512, 0.08556516989537444, 0.08019225669858099, 0.08286134945626689, 0.07496979065675446, 0.0850600782588915, 0.0735401347951864, 0.07636235899990385, 0.07709528013485212, 0.07326544861438689]}, "mutation_prompt": null}
{"id": "d0fd6a41-f681-4d67-9bcc-d482c7896c9f", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Refined Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover with enhanced probability adaptation\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.1))\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning with more granular adjustments\n            self.scale_factor = np.random.uniform(0.65, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.88, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with refined adaptive mutation and crossover strategies to improve convergence efficiency.", "configspace": "", "generation": 25, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "861cd3e5-fef8-4d90-a5d1-b5c310a7510e", "metadata": {"aucs": [0.822419785938898, 0.8199714546643329, 0.8414894141977063, 0.8430091771653526, 0.8593885836191024, 0.8487231796708052, 0.8367890364383294, 0.8302523382030463, 0.8293736847039304, 0.6900526707292051, 0.729827418174816, 0.7165636142714544, 0.7210593429287958, 0.7066488819727987, 0.73925793568504, 0.7290705693599189, 0.7228033402871135, 0.7062545396178945, 0.1276970958927961, 0.10836103147880471, 0.10584430366771846, 0.3699480834266704, 0.14078795992086013, 0.11173662417811558, 0.24405632789960074, 0.1979650359645696, 0.11807834733719214, 0.09487999780108625, 0.12368899362754915, 0.1075596948214832, 0.13173357002036357, 0.09980875650657273, 0.11640007866229085, 0.1278981270616787, 0.12028358906634584, 0.12155953374756501, 0.9267733553648255, 0.8780210526035417, 0.9728814299618388, 0.9627363618388612, 0.9068972901895733, 0.9753106988533982, 0.950121428753759, 0.9613290656568141, 0.9730778020274361, 0.6217127761634991, 0.5898663642757915, 0.6498912945803319, 0.5908153910909509, 0.6029460563973829, 0.601656570202229, 0.5726798590248927, 0.5981797797944681, 0.610924263252564, 0.8272794955422078, 0.7839572083705488, 0.8292962044243667, 0.8387891564677299, 0.8155388282714626, 0.8237694981028187, 0.8208478301223947, 0.8030835718841802, 0.8302702542657152, 0.6115389342871294, 0.6505395783882206, 0.6010719361145394, 0.6201992295121656, 0.5474925340891813, 0.12496363056790527, 0.6172883917916766, 0.5800103510803774, 0.6178082965572207, 0.5198145289921565, 0.01669045686983861, 0.537493623059079, 0.5574622518931232, 0.583907273603204, 0.6325076991684645, 0.6040173477737164, 0.5772205189597104, 0.4477021493834583, 0.5951745198118525, 0.5751254750305228, 0.611168261060888, 0.6095156079537748, 0.5613895288278088, 0.653165236812457, 0.578010382898307, 0.5906344030858592, 0.5734038836895186, 0.6973248370362327, 0.6690598036518844, 0.6847305193213178, 0.7061685940428326, 0.7127427735436558, 0.6956403853904165, 0.7256654724870555, 0.6974935332756751, 0.6800657796012706, 0.26886888297261247, 0.2567298455899326, 0.1978498023786025, 0.4711096272090417, 0.4616923459558898, 0.33646622305502594, 0.3003209734846265, 0.2923859164690722, 0.2917522917795389, 0.4407450260626149, 0.47750354188731814, 0.44573651789588875, 0.46007102069606187, 0.4623265148506259, 0.4698450507558254, 0.4983374796651274, 0.4651038353049999, 0.4906097444919848, 0.7939959747146519, 0.7512639921384054, 0.8024278744310025, 0.7655647590715289, 0.7860141525136092, 0.7469872082840403, 0.7837308674550727, 0.7867152501597141, 0.7814435476452145, 0.10731152787756348, 0.11531064980216776, 0.13327898151509088, 0.0845459419935578, 0.1129017830272383, 0.10799288264697948, 0.09026607095640027, 0.09242354853904122, 0.11414610931447933, 0.14859750401177263, 0.16993161980945604, 0.21808791662555005, 0.17893340336430485, 0.20673396640031128, 0.17514927217005238, 0.21812932372262783, 0.1816380653821965, 0.1969196835645982, 0.4445529723727534, 0.42052418256371293, 0.4832803672599898, 0.434256993835186, 0.45321080811656955, 0.43851286281310375, 0.47433954584356, 0.44995204167902425, 0.4907650783321168, 0.36028806305334393, 0.3637094622146594, 0.2797815375835401, 0.339563147640781, 0.3282683863725553, 0.33629759002845827, 0.38231494403451727, 0.36727042862318426, 0.40476782964212854, 0.19355751934158139, 0.222651046201242, 0.20008507149009302, 0.24076494486116384, 0.1823909733253869, 0.23823667947716676, 0.18896336916398737, 0.1775488692840156, 0.19825657499372007, 0.31328935485711895, 0.24978833520335753, 0.5467031594247906, 0.22580931177013186, 0.3068491624219365, 0.20701222076673953, 0.20878834757163556, 0.26504852465161, 0.19381349682665883, 0.8488604691570416, 0.17137799400702514, 0.17022881054803018, 0.8712490731729117, 0.2056317133448773, 0.775756989121672, 0.16335836936746595, 0.17793760622496502, 0.8524947927571764, 0.8179025205290024, 0.7358647696051241, 0.8190914110923364, 0.201869625298709, 0.16556880117395845, 0.7141282873355854, 0.2071428842442561, 0.8635935380607013, 0.791471704067155, 0.18662858002296845, 0.186359167637123, 0.19667438813877036, 0.18593125007449574, 0.16702174357922817, 0.17072242613914146, 0.18406270829058735, 0.1883483385411402, 0.21088470591522512, 0.08556516989537444, 0.08019225669858099, 0.08286134945626689, 0.07496979065675446, 0.0850600782588915, 0.0735401347951864, 0.07636235899990385, 0.07709528013485212, 0.07326544861438689]}, "mutation_prompt": null}
{"id": "5c77a2b4-b55b-46f6-bf8e-a33f5a4d4835", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Refined Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover with enhanced probability adaptation\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.1))\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning with more granular adjustments\n            self.scale_factor = np.random.uniform(0.65, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.88, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with refined adaptive mutation and crossover strategies to improve convergence efficiency.", "configspace": "", "generation": 25, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "861cd3e5-fef8-4d90-a5d1-b5c310a7510e", "metadata": {"aucs": [0.822419785938898, 0.8199714546643329, 0.8414894141977063, 0.8430091771653526, 0.8593885836191024, 0.8487231796708052, 0.8367890364383294, 0.8302523382030463, 0.8293736847039304, 0.6900526707292051, 0.729827418174816, 0.7165636142714544, 0.7210593429287958, 0.7066488819727987, 0.73925793568504, 0.7290705693599189, 0.7228033402871135, 0.7062545396178945, 0.1276970958927961, 0.10836103147880471, 0.10584430366771846, 0.3699480834266704, 0.14078795992086013, 0.11173662417811558, 0.24405632789960074, 0.1979650359645696, 0.11807834733719214, 0.09487999780108625, 0.12368899362754915, 0.1075596948214832, 0.13173357002036357, 0.09980875650657273, 0.11640007866229085, 0.1278981270616787, 0.12028358906634584, 0.12155953374756501, 0.9267733553648255, 0.8780210526035417, 0.9728814299618388, 0.9627363618388612, 0.9068972901895733, 0.9753106988533982, 0.950121428753759, 0.9613290656568141, 0.9730778020274361, 0.6217127761634991, 0.5898663642757915, 0.6498912945803319, 0.5908153910909509, 0.6029460563973829, 0.601656570202229, 0.5726798590248927, 0.5981797797944681, 0.610924263252564, 0.8272794955422078, 0.7839572083705488, 0.8292962044243667, 0.8387891564677299, 0.8155388282714626, 0.8237694981028187, 0.8208478301223947, 0.8030835718841802, 0.8302702542657152, 0.6115389342871294, 0.6505395783882206, 0.6010719361145394, 0.6201992295121656, 0.5474925340891813, 0.12496363056790527, 0.6172883917916766, 0.5800103510803774, 0.6178082965572207, 0.5198145289921565, 0.01669045686983861, 0.537493623059079, 0.5574622518931232, 0.583907273603204, 0.6325076991684645, 0.6040173477737164, 0.5772205189597104, 0.4477021493834583, 0.5951745198118525, 0.5751254750305228, 0.611168261060888, 0.6095156079537748, 0.5613895288278088, 0.653165236812457, 0.578010382898307, 0.5906344030858592, 0.5734038836895186, 0.6973248370362327, 0.6690598036518844, 0.6847305193213178, 0.7061685940428326, 0.7127427735436558, 0.6956403853904165, 0.7256654724870555, 0.6974935332756751, 0.6800657796012706, 0.26886888297261247, 0.2567298455899326, 0.1978498023786025, 0.4711096272090417, 0.4616923459558898, 0.33646622305502594, 0.3003209734846265, 0.2923859164690722, 0.2917522917795389, 0.4407450260626149, 0.47750354188731814, 0.44573651789588875, 0.46007102069606187, 0.4623265148506259, 0.4698450507558254, 0.4983374796651274, 0.4651038353049999, 0.4906097444919848, 0.7939959747146519, 0.7512639921384054, 0.8024278744310025, 0.7655647590715289, 0.7860141525136092, 0.7469872082840403, 0.7837308674550727, 0.7867152501597141, 0.7814435476452145, 0.10731152787756348, 0.11531064980216776, 0.13327898151509088, 0.0845459419935578, 0.1129017830272383, 0.10799288264697948, 0.09026607095640027, 0.09242354853904122, 0.11414610931447933, 0.14859750401177263, 0.16993161980945604, 0.21808791662555005, 0.17893340336430485, 0.20673396640031128, 0.17514927217005238, 0.21812932372262783, 0.1816380653821965, 0.1969196835645982, 0.4445529723727534, 0.42052418256371293, 0.4832803672599898, 0.434256993835186, 0.45321080811656955, 0.43851286281310375, 0.47433954584356, 0.44995204167902425, 0.4907650783321168, 0.36028806305334393, 0.3637094622146594, 0.2797815375835401, 0.339563147640781, 0.3282683863725553, 0.33629759002845827, 0.38231494403451727, 0.36727042862318426, 0.40476782964212854, 0.19355751934158139, 0.222651046201242, 0.20008507149009302, 0.24076494486116384, 0.1823909733253869, 0.23823667947716676, 0.18896336916398737, 0.1775488692840156, 0.19825657499372007, 0.31328935485711895, 0.24978833520335753, 0.5467031594247906, 0.22580931177013186, 0.3068491624219365, 0.20701222076673953, 0.20878834757163556, 0.26504852465161, 0.19381349682665883, 0.8488604691570416, 0.17137799400702514, 0.17022881054803018, 0.8712490731729117, 0.2056317133448773, 0.775756989121672, 0.16335836936746595, 0.17793760622496502, 0.8524947927571764, 0.8179025205290024, 0.7358647696051241, 0.8190914110923364, 0.201869625298709, 0.16556880117395845, 0.7141282873355854, 0.2071428842442561, 0.8635935380607013, 0.791471704067155, 0.18662858002296845, 0.186359167637123, 0.19667438813877036, 0.18593125007449574, 0.16702174357922817, 0.17072242613914146, 0.18406270829058735, 0.1883483385411402, 0.21088470591522512, 0.08556516989537444, 0.08019225669858099, 0.08286134945626689, 0.07496979065675446, 0.0850600782588915, 0.0735401347951864, 0.07636235899990385, 0.07709528013485212, 0.07326544861438689]}, "mutation_prompt": null}
{"id": "bcea2f57-6d35-4ec5-b20a-9ccbe73c830b", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Refined Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover with enhanced probability adaptation\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.1))\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning with more granular adjustments\n            self.scale_factor = np.random.uniform(0.65, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.88, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with refined adaptive mutation and crossover strategies to improve convergence efficiency.", "configspace": "", "generation": 25, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "861cd3e5-fef8-4d90-a5d1-b5c310a7510e", "metadata": {"aucs": [0.822419785938898, 0.8199714546643329, 0.8414894141977063, 0.8430091771653526, 0.8593885836191024, 0.8487231796708052, 0.8367890364383294, 0.8302523382030463, 0.8293736847039304, 0.6900526707292051, 0.729827418174816, 0.7165636142714544, 0.7210593429287958, 0.7066488819727987, 0.73925793568504, 0.7290705693599189, 0.7228033402871135, 0.7062545396178945, 0.1276970958927961, 0.10836103147880471, 0.10584430366771846, 0.3699480834266704, 0.14078795992086013, 0.11173662417811558, 0.24405632789960074, 0.1979650359645696, 0.11807834733719214, 0.09487999780108625, 0.12368899362754915, 0.1075596948214832, 0.13173357002036357, 0.09980875650657273, 0.11640007866229085, 0.1278981270616787, 0.12028358906634584, 0.12155953374756501, 0.9267733553648255, 0.8780210526035417, 0.9728814299618388, 0.9627363618388612, 0.9068972901895733, 0.9753106988533982, 0.950121428753759, 0.9613290656568141, 0.9730778020274361, 0.6217127761634991, 0.5898663642757915, 0.6498912945803319, 0.5908153910909509, 0.6029460563973829, 0.601656570202229, 0.5726798590248927, 0.5981797797944681, 0.610924263252564, 0.8272794955422078, 0.7839572083705488, 0.8292962044243667, 0.8387891564677299, 0.8155388282714626, 0.8237694981028187, 0.8208478301223947, 0.8030835718841802, 0.8302702542657152, 0.6115389342871294, 0.6505395783882206, 0.6010719361145394, 0.6201992295121656, 0.5474925340891813, 0.12496363056790527, 0.6172883917916766, 0.5800103510803774, 0.6178082965572207, 0.5198145289921565, 0.01669045686983861, 0.537493623059079, 0.5574622518931232, 0.583907273603204, 0.6325076991684645, 0.6040173477737164, 0.5772205189597104, 0.4477021493834583, 0.5951745198118525, 0.5751254750305228, 0.611168261060888, 0.6095156079537748, 0.5613895288278088, 0.653165236812457, 0.578010382898307, 0.5906344030858592, 0.5734038836895186, 0.6973248370362327, 0.6690598036518844, 0.6847305193213178, 0.7061685940428326, 0.7127427735436558, 0.6956403853904165, 0.7256654724870555, 0.6974935332756751, 0.6800657796012706, 0.26886888297261247, 0.2567298455899326, 0.1978498023786025, 0.4711096272090417, 0.4616923459558898, 0.33646622305502594, 0.3003209734846265, 0.2923859164690722, 0.2917522917795389, 0.4407450260626149, 0.47750354188731814, 0.44573651789588875, 0.46007102069606187, 0.4623265148506259, 0.4698450507558254, 0.4983374796651274, 0.4651038353049999, 0.4906097444919848, 0.7939959747146519, 0.7512639921384054, 0.8024278744310025, 0.7655647590715289, 0.7860141525136092, 0.7469872082840403, 0.7837308674550727, 0.7867152501597141, 0.7814435476452145, 0.10731152787756348, 0.11531064980216776, 0.13327898151509088, 0.0845459419935578, 0.1129017830272383, 0.10799288264697948, 0.09026607095640027, 0.09242354853904122, 0.11414610931447933, 0.14859750401177263, 0.16993161980945604, 0.21808791662555005, 0.17893340336430485, 0.20673396640031128, 0.17514927217005238, 0.21812932372262783, 0.1816380653821965, 0.1969196835645982, 0.4445529723727534, 0.42052418256371293, 0.4832803672599898, 0.434256993835186, 0.45321080811656955, 0.43851286281310375, 0.47433954584356, 0.44995204167902425, 0.4907650783321168, 0.36028806305334393, 0.3637094622146594, 0.2797815375835401, 0.339563147640781, 0.3282683863725553, 0.33629759002845827, 0.38231494403451727, 0.36727042862318426, 0.40476782964212854, 0.19355751934158139, 0.222651046201242, 0.20008507149009302, 0.24076494486116384, 0.1823909733253869, 0.23823667947716676, 0.18896336916398737, 0.1775488692840156, 0.19825657499372007, 0.31328935485711895, 0.24978833520335753, 0.5467031594247906, 0.22580931177013186, 0.3068491624219365, 0.20701222076673953, 0.20878834757163556, 0.26504852465161, 0.19381349682665883, 0.8488604691570416, 0.17137799400702514, 0.17022881054803018, 0.8712490731729117, 0.2056317133448773, 0.775756989121672, 0.16335836936746595, 0.17793760622496502, 0.8524947927571764, 0.8179025205290024, 0.7358647696051241, 0.8190914110923364, 0.201869625298709, 0.16556880117395845, 0.7141282873355854, 0.2071428842442561, 0.8635935380607013, 0.791471704067155, 0.18662858002296845, 0.186359167637123, 0.19667438813877036, 0.18593125007449574, 0.16702174357922817, 0.17072242613914146, 0.18406270829058735, 0.1883483385411402, 0.21088470591522512, 0.08556516989537444, 0.08019225669858099, 0.08286134945626689, 0.07496979065675446, 0.0850600782588915, 0.0735401347951864, 0.07636235899990385, 0.07709528013485212, 0.07326544861438689]}, "mutation_prompt": null}
{"id": "5ea7429a-be2b-4bcf-90bb-7200a0b2c303", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Refined Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover with enhanced probability adaptation\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.1))\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning with more granular adjustments\n            self.scale_factor = np.random.uniform(0.65, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.88, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with refined adaptive mutation and crossover strategies to improve convergence efficiency.", "configspace": "", "generation": 25, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "861cd3e5-fef8-4d90-a5d1-b5c310a7510e", "metadata": {"aucs": [0.822419785938898, 0.8199714546643329, 0.8414894141977063, 0.8430091771653526, 0.8593885836191024, 0.8487231796708052, 0.8367890364383294, 0.8302523382030463, 0.8293736847039304, 0.6900526707292051, 0.729827418174816, 0.7165636142714544, 0.7210593429287958, 0.7066488819727987, 0.73925793568504, 0.7290705693599189, 0.7228033402871135, 0.7062545396178945, 0.1276970958927961, 0.10836103147880471, 0.10584430366771846, 0.3699480834266704, 0.14078795992086013, 0.11173662417811558, 0.24405632789960074, 0.1979650359645696, 0.11807834733719214, 0.09487999780108625, 0.12368899362754915, 0.1075596948214832, 0.13173357002036357, 0.09980875650657273, 0.11640007866229085, 0.1278981270616787, 0.12028358906634584, 0.12155953374756501, 0.9267733553648255, 0.8780210526035417, 0.9728814299618388, 0.9627363618388612, 0.9068972901895733, 0.9753106988533982, 0.950121428753759, 0.9613290656568141, 0.9730778020274361, 0.6217127761634991, 0.5898663642757915, 0.6498912945803319, 0.5908153910909509, 0.6029460563973829, 0.601656570202229, 0.5726798590248927, 0.5981797797944681, 0.610924263252564, 0.8272794955422078, 0.7839572083705488, 0.8292962044243667, 0.8387891564677299, 0.8155388282714626, 0.8237694981028187, 0.8208478301223947, 0.8030835718841802, 0.8302702542657152, 0.6115389342871294, 0.6505395783882206, 0.6010719361145394, 0.6201992295121656, 0.5474925340891813, 0.12496363056790527, 0.6172883917916766, 0.5800103510803774, 0.6178082965572207, 0.5198145289921565, 0.01669045686983861, 0.537493623059079, 0.5574622518931232, 0.583907273603204, 0.6325076991684645, 0.6040173477737164, 0.5772205189597104, 0.4477021493834583, 0.5951745198118525, 0.5751254750305228, 0.611168261060888, 0.6095156079537748, 0.5613895288278088, 0.653165236812457, 0.578010382898307, 0.5906344030858592, 0.5734038836895186, 0.6973248370362327, 0.6690598036518844, 0.6847305193213178, 0.7061685940428326, 0.7127427735436558, 0.6956403853904165, 0.7256654724870555, 0.6974935332756751, 0.6800657796012706, 0.26886888297261247, 0.2567298455899326, 0.1978498023786025, 0.4711096272090417, 0.4616923459558898, 0.33646622305502594, 0.3003209734846265, 0.2923859164690722, 0.2917522917795389, 0.4407450260626149, 0.47750354188731814, 0.44573651789588875, 0.46007102069606187, 0.4623265148506259, 0.4698450507558254, 0.4983374796651274, 0.4651038353049999, 0.4906097444919848, 0.7939959747146519, 0.7512639921384054, 0.8024278744310025, 0.7655647590715289, 0.7860141525136092, 0.7469872082840403, 0.7837308674550727, 0.7867152501597141, 0.7814435476452145, 0.10731152787756348, 0.11531064980216776, 0.13327898151509088, 0.0845459419935578, 0.1129017830272383, 0.10799288264697948, 0.09026607095640027, 0.09242354853904122, 0.11414610931447933, 0.14859750401177263, 0.16993161980945604, 0.21808791662555005, 0.17893340336430485, 0.20673396640031128, 0.17514927217005238, 0.21812932372262783, 0.1816380653821965, 0.1969196835645982, 0.4445529723727534, 0.42052418256371293, 0.4832803672599898, 0.434256993835186, 0.45321080811656955, 0.43851286281310375, 0.47433954584356, 0.44995204167902425, 0.4907650783321168, 0.36028806305334393, 0.3637094622146594, 0.2797815375835401, 0.339563147640781, 0.3282683863725553, 0.33629759002845827, 0.38231494403451727, 0.36727042862318426, 0.40476782964212854, 0.19355751934158139, 0.222651046201242, 0.20008507149009302, 0.24076494486116384, 0.1823909733253869, 0.23823667947716676, 0.18896336916398737, 0.1775488692840156, 0.19825657499372007, 0.31328935485711895, 0.24978833520335753, 0.5467031594247906, 0.22580931177013186, 0.3068491624219365, 0.20701222076673953, 0.20878834757163556, 0.26504852465161, 0.19381349682665883, 0.8488604691570416, 0.17137799400702514, 0.17022881054803018, 0.8712490731729117, 0.2056317133448773, 0.775756989121672, 0.16335836936746595, 0.17793760622496502, 0.8524947927571764, 0.8179025205290024, 0.7358647696051241, 0.8190914110923364, 0.201869625298709, 0.16556880117395845, 0.7141282873355854, 0.2071428842442561, 0.8635935380607013, 0.791471704067155, 0.18662858002296845, 0.186359167637123, 0.19667438813877036, 0.18593125007449574, 0.16702174357922817, 0.17072242613914146, 0.18406270829058735, 0.1883483385411402, 0.21088470591522512, 0.08556516989537444, 0.08019225669858099, 0.08286134945626689, 0.07496979065675446, 0.0850600782588915, 0.0735401347951864, 0.07636235899990385, 0.07709528013485212, 0.07326544861438689]}, "mutation_prompt": null}
{"id": "18bbcb05-2cfd-4d0f-b6b3-04efe56289c5", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Refined Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover with enhanced probability adaptation\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.1))\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning with more granular adjustments\n            self.scale_factor = np.random.uniform(0.65, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.88, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with refined adaptive mutation and crossover strategies to improve convergence efficiency.", "configspace": "", "generation": 25, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "861cd3e5-fef8-4d90-a5d1-b5c310a7510e", "metadata": {"aucs": [0.822419785938898, 0.8199714546643329, 0.8414894141977063, 0.8430091771653526, 0.8593885836191024, 0.8487231796708052, 0.8367890364383294, 0.8302523382030463, 0.8293736847039304, 0.6900526707292051, 0.729827418174816, 0.7165636142714544, 0.7210593429287958, 0.7066488819727987, 0.73925793568504, 0.7290705693599189, 0.7228033402871135, 0.7062545396178945, 0.1276970958927961, 0.10836103147880471, 0.10584430366771846, 0.3699480834266704, 0.14078795992086013, 0.11173662417811558, 0.24405632789960074, 0.1979650359645696, 0.11807834733719214, 0.09487999780108625, 0.12368899362754915, 0.1075596948214832, 0.13173357002036357, 0.09980875650657273, 0.11640007866229085, 0.1278981270616787, 0.12028358906634584, 0.12155953374756501, 0.9267733553648255, 0.8780210526035417, 0.9728814299618388, 0.9627363618388612, 0.9068972901895733, 0.9753106988533982, 0.950121428753759, 0.9613290656568141, 0.9730778020274361, 0.6217127761634991, 0.5898663642757915, 0.6498912945803319, 0.5908153910909509, 0.6029460563973829, 0.601656570202229, 0.5726798590248927, 0.5981797797944681, 0.610924263252564, 0.8272794955422078, 0.7839572083705488, 0.8292962044243667, 0.8387891564677299, 0.8155388282714626, 0.8237694981028187, 0.8208478301223947, 0.8030835718841802, 0.8302702542657152, 0.6115389342871294, 0.6505395783882206, 0.6010719361145394, 0.6201992295121656, 0.5474925340891813, 0.12496363056790527, 0.6172883917916766, 0.5800103510803774, 0.6178082965572207, 0.5198145289921565, 0.01669045686983861, 0.537493623059079, 0.5574622518931232, 0.583907273603204, 0.6325076991684645, 0.6040173477737164, 0.5772205189597104, 0.4477021493834583, 0.5951745198118525, 0.5751254750305228, 0.611168261060888, 0.6095156079537748, 0.5613895288278088, 0.653165236812457, 0.578010382898307, 0.5906344030858592, 0.5734038836895186, 0.6973248370362327, 0.6690598036518844, 0.6847305193213178, 0.7061685940428326, 0.7127427735436558, 0.6956403853904165, 0.7256654724870555, 0.6974935332756751, 0.6800657796012706, 0.26886888297261247, 0.2567298455899326, 0.1978498023786025, 0.4711096272090417, 0.4616923459558898, 0.33646622305502594, 0.3003209734846265, 0.2923859164690722, 0.2917522917795389, 0.4407450260626149, 0.47750354188731814, 0.44573651789588875, 0.46007102069606187, 0.4623265148506259, 0.4698450507558254, 0.4983374796651274, 0.4651038353049999, 0.4906097444919848, 0.7939959747146519, 0.7512639921384054, 0.8024278744310025, 0.7655647590715289, 0.7860141525136092, 0.7469872082840403, 0.7837308674550727, 0.7867152501597141, 0.7814435476452145, 0.10731152787756348, 0.11531064980216776, 0.13327898151509088, 0.0845459419935578, 0.1129017830272383, 0.10799288264697948, 0.09026607095640027, 0.09242354853904122, 0.11414610931447933, 0.14859750401177263, 0.16993161980945604, 0.21808791662555005, 0.17893340336430485, 0.20673396640031128, 0.17514927217005238, 0.21812932372262783, 0.1816380653821965, 0.1969196835645982, 0.4445529723727534, 0.42052418256371293, 0.4832803672599898, 0.434256993835186, 0.45321080811656955, 0.43851286281310375, 0.47433954584356, 0.44995204167902425, 0.4907650783321168, 0.36028806305334393, 0.3637094622146594, 0.2797815375835401, 0.339563147640781, 0.3282683863725553, 0.33629759002845827, 0.38231494403451727, 0.36727042862318426, 0.40476782964212854, 0.19355751934158139, 0.222651046201242, 0.20008507149009302, 0.24076494486116384, 0.1823909733253869, 0.23823667947716676, 0.18896336916398737, 0.1775488692840156, 0.19825657499372007, 0.31328935485711895, 0.24978833520335753, 0.5467031594247906, 0.22580931177013186, 0.3068491624219365, 0.20701222076673953, 0.20878834757163556, 0.26504852465161, 0.19381349682665883, 0.8488604691570416, 0.17137799400702514, 0.17022881054803018, 0.8712490731729117, 0.2056317133448773, 0.775756989121672, 0.16335836936746595, 0.17793760622496502, 0.8524947927571764, 0.8179025205290024, 0.7358647696051241, 0.8190914110923364, 0.201869625298709, 0.16556880117395845, 0.7141282873355854, 0.2071428842442561, 0.8635935380607013, 0.791471704067155, 0.18662858002296845, 0.186359167637123, 0.19667438813877036, 0.18593125007449574, 0.16702174357922817, 0.17072242613914146, 0.18406270829058735, 0.1883483385411402, 0.21088470591522512, 0.08556516989537444, 0.08019225669858099, 0.08286134945626689, 0.07496979065675446, 0.0850600782588915, 0.0735401347951864, 0.07636235899990385, 0.07709528013485212, 0.07326544861438689]}, "mutation_prompt": null}
{"id": "d205053c-7e62-44d6-89a9-9b1c85188ddd", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Refined Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover with enhanced probability adaptation\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.1))\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning with more granular adjustments\n            self.scale_factor = np.random.uniform(0.65, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.88, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with refined adaptive mutation and crossover strategies to improve convergence efficiency.", "configspace": "", "generation": 25, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "861cd3e5-fef8-4d90-a5d1-b5c310a7510e", "metadata": {"aucs": [0.822419785938898, 0.8199714546643329, 0.8414894141977063, 0.8430091771653526, 0.8593885836191024, 0.8487231796708052, 0.8367890364383294, 0.8302523382030463, 0.8293736847039304, 0.6900526707292051, 0.729827418174816, 0.7165636142714544, 0.7210593429287958, 0.7066488819727987, 0.73925793568504, 0.7290705693599189, 0.7228033402871135, 0.7062545396178945, 0.1276970958927961, 0.10836103147880471, 0.10584430366771846, 0.3699480834266704, 0.14078795992086013, 0.11173662417811558, 0.24405632789960074, 0.1979650359645696, 0.11807834733719214, 0.09487999780108625, 0.12368899362754915, 0.1075596948214832, 0.13173357002036357, 0.09980875650657273, 0.11640007866229085, 0.1278981270616787, 0.12028358906634584, 0.12155953374756501, 0.9267733553648255, 0.8780210526035417, 0.9728814299618388, 0.9627363618388612, 0.9068972901895733, 0.9753106988533982, 0.950121428753759, 0.9613290656568141, 0.9730778020274361, 0.6217127761634991, 0.5898663642757915, 0.6498912945803319, 0.5908153910909509, 0.6029460563973829, 0.601656570202229, 0.5726798590248927, 0.5981797797944681, 0.610924263252564, 0.8272794955422078, 0.7839572083705488, 0.8292962044243667, 0.8387891564677299, 0.8155388282714626, 0.8237694981028187, 0.8208478301223947, 0.8030835718841802, 0.8302702542657152, 0.6115389342871294, 0.6505395783882206, 0.6010719361145394, 0.6201992295121656, 0.5474925340891813, 0.12496363056790527, 0.6172883917916766, 0.5800103510803774, 0.6178082965572207, 0.5198145289921565, 0.01669045686983861, 0.537493623059079, 0.5574622518931232, 0.583907273603204, 0.6325076991684645, 0.6040173477737164, 0.5772205189597104, 0.4477021493834583, 0.5951745198118525, 0.5751254750305228, 0.611168261060888, 0.6095156079537748, 0.5613895288278088, 0.653165236812457, 0.578010382898307, 0.5906344030858592, 0.5734038836895186, 0.6973248370362327, 0.6690598036518844, 0.6847305193213178, 0.7061685940428326, 0.7127427735436558, 0.6956403853904165, 0.7256654724870555, 0.6974935332756751, 0.6800657796012706, 0.26886888297261247, 0.2567298455899326, 0.1978498023786025, 0.4711096272090417, 0.4616923459558898, 0.33646622305502594, 0.3003209734846265, 0.2923859164690722, 0.2917522917795389, 0.4407450260626149, 0.47750354188731814, 0.44573651789588875, 0.46007102069606187, 0.4623265148506259, 0.4698450507558254, 0.4983374796651274, 0.4651038353049999, 0.4906097444919848, 0.7939959747146519, 0.7512639921384054, 0.8024278744310025, 0.7655647590715289, 0.7860141525136092, 0.7469872082840403, 0.7837308674550727, 0.7867152501597141, 0.7814435476452145, 0.10731152787756348, 0.11531064980216776, 0.13327898151509088, 0.0845459419935578, 0.1129017830272383, 0.10799288264697948, 0.09026607095640027, 0.09242354853904122, 0.11414610931447933, 0.14859750401177263, 0.16993161980945604, 0.21808791662555005, 0.17893340336430485, 0.20673396640031128, 0.17514927217005238, 0.21812932372262783, 0.1816380653821965, 0.1969196835645982, 0.4445529723727534, 0.42052418256371293, 0.4832803672599898, 0.434256993835186, 0.45321080811656955, 0.43851286281310375, 0.47433954584356, 0.44995204167902425, 0.4907650783321168, 0.36028806305334393, 0.3637094622146594, 0.2797815375835401, 0.339563147640781, 0.3282683863725553, 0.33629759002845827, 0.38231494403451727, 0.36727042862318426, 0.40476782964212854, 0.19355751934158139, 0.222651046201242, 0.20008507149009302, 0.24076494486116384, 0.1823909733253869, 0.23823667947716676, 0.18896336916398737, 0.1775488692840156, 0.19825657499372007, 0.31328935485711895, 0.24978833520335753, 0.5467031594247906, 0.22580931177013186, 0.3068491624219365, 0.20701222076673953, 0.20878834757163556, 0.26504852465161, 0.19381349682665883, 0.8488604691570416, 0.17137799400702514, 0.17022881054803018, 0.8712490731729117, 0.2056317133448773, 0.775756989121672, 0.16335836936746595, 0.17793760622496502, 0.8524947927571764, 0.8179025205290024, 0.7358647696051241, 0.8190914110923364, 0.201869625298709, 0.16556880117395845, 0.7141282873355854, 0.2071428842442561, 0.8635935380607013, 0.791471704067155, 0.18662858002296845, 0.186359167637123, 0.19667438813877036, 0.18593125007449574, 0.16702174357922817, 0.17072242613914146, 0.18406270829058735, 0.1883483385411402, 0.21088470591522512, 0.08556516989537444, 0.08019225669858099, 0.08286134945626689, 0.07496979065675446, 0.0850600782588915, 0.0735401347951864, 0.07636235899990385, 0.07709528013485212, 0.07326544861438689]}, "mutation_prompt": null}
{"id": "bd1e5964-c080-49fc-a3e9-523b3355d2d2", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Refined Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover with enhanced probability adaptation\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.1))\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning with more granular adjustments\n            self.scale_factor = np.random.uniform(0.65, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.88, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with refined adaptive mutation and crossover strategies to improve convergence efficiency.", "configspace": "", "generation": 25, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "861cd3e5-fef8-4d90-a5d1-b5c310a7510e", "metadata": {"aucs": [0.822419785938898, 0.8199714546643329, 0.8414894141977063, 0.8430091771653526, 0.8593885836191024, 0.8487231796708052, 0.8367890364383294, 0.8302523382030463, 0.8293736847039304, 0.6900526707292051, 0.729827418174816, 0.7165636142714544, 0.7210593429287958, 0.7066488819727987, 0.73925793568504, 0.7290705693599189, 0.7228033402871135, 0.7062545396178945, 0.1276970958927961, 0.10836103147880471, 0.10584430366771846, 0.3699480834266704, 0.14078795992086013, 0.11173662417811558, 0.24405632789960074, 0.1979650359645696, 0.11807834733719214, 0.09487999780108625, 0.12368899362754915, 0.1075596948214832, 0.13173357002036357, 0.09980875650657273, 0.11640007866229085, 0.1278981270616787, 0.12028358906634584, 0.12155953374756501, 0.9267733553648255, 0.8780210526035417, 0.9728814299618388, 0.9627363618388612, 0.9068972901895733, 0.9753106988533982, 0.950121428753759, 0.9613290656568141, 0.9730778020274361, 0.6217127761634991, 0.5898663642757915, 0.6498912945803319, 0.5908153910909509, 0.6029460563973829, 0.601656570202229, 0.5726798590248927, 0.5981797797944681, 0.610924263252564, 0.8272794955422078, 0.7839572083705488, 0.8292962044243667, 0.8387891564677299, 0.8155388282714626, 0.8237694981028187, 0.8208478301223947, 0.8030835718841802, 0.8302702542657152, 0.6115389342871294, 0.6505395783882206, 0.6010719361145394, 0.6201992295121656, 0.5474925340891813, 0.12496363056790527, 0.6172883917916766, 0.5800103510803774, 0.6178082965572207, 0.5198145289921565, 0.01669045686983861, 0.537493623059079, 0.5574622518931232, 0.583907273603204, 0.6325076991684645, 0.6040173477737164, 0.5772205189597104, 0.4477021493834583, 0.5951745198118525, 0.5751254750305228, 0.611168261060888, 0.6095156079537748, 0.5613895288278088, 0.653165236812457, 0.578010382898307, 0.5906344030858592, 0.5734038836895186, 0.6973248370362327, 0.6690598036518844, 0.6847305193213178, 0.7061685940428326, 0.7127427735436558, 0.6956403853904165, 0.7256654724870555, 0.6974935332756751, 0.6800657796012706, 0.26886888297261247, 0.2567298455899326, 0.1978498023786025, 0.4711096272090417, 0.4616923459558898, 0.33646622305502594, 0.3003209734846265, 0.2923859164690722, 0.2917522917795389, 0.4407450260626149, 0.47750354188731814, 0.44573651789588875, 0.46007102069606187, 0.4623265148506259, 0.4698450507558254, 0.4983374796651274, 0.4651038353049999, 0.4906097444919848, 0.7939959747146519, 0.7512639921384054, 0.8024278744310025, 0.7655647590715289, 0.7860141525136092, 0.7469872082840403, 0.7837308674550727, 0.7867152501597141, 0.7814435476452145, 0.10731152787756348, 0.11531064980216776, 0.13327898151509088, 0.0845459419935578, 0.1129017830272383, 0.10799288264697948, 0.09026607095640027, 0.09242354853904122, 0.11414610931447933, 0.14859750401177263, 0.16993161980945604, 0.21808791662555005, 0.17893340336430485, 0.20673396640031128, 0.17514927217005238, 0.21812932372262783, 0.1816380653821965, 0.1969196835645982, 0.4445529723727534, 0.42052418256371293, 0.4832803672599898, 0.434256993835186, 0.45321080811656955, 0.43851286281310375, 0.47433954584356, 0.44995204167902425, 0.4907650783321168, 0.36028806305334393, 0.3637094622146594, 0.2797815375835401, 0.339563147640781, 0.3282683863725553, 0.33629759002845827, 0.38231494403451727, 0.36727042862318426, 0.40476782964212854, 0.19355751934158139, 0.222651046201242, 0.20008507149009302, 0.24076494486116384, 0.1823909733253869, 0.23823667947716676, 0.18896336916398737, 0.1775488692840156, 0.19825657499372007, 0.31328935485711895, 0.24978833520335753, 0.5467031594247906, 0.22580931177013186, 0.3068491624219365, 0.20701222076673953, 0.20878834757163556, 0.26504852465161, 0.19381349682665883, 0.8488604691570416, 0.17137799400702514, 0.17022881054803018, 0.8712490731729117, 0.2056317133448773, 0.775756989121672, 0.16335836936746595, 0.17793760622496502, 0.8524947927571764, 0.8179025205290024, 0.7358647696051241, 0.8190914110923364, 0.201869625298709, 0.16556880117395845, 0.7141282873355854, 0.2071428842442561, 0.8635935380607013, 0.791471704067155, 0.18662858002296845, 0.186359167637123, 0.19667438813877036, 0.18593125007449574, 0.16702174357922817, 0.17072242613914146, 0.18406270829058735, 0.1883483385411402, 0.21088470591522512, 0.08556516989537444, 0.08019225669858099, 0.08286134945626689, 0.07496979065675446, 0.0850600782588915, 0.0735401347951864, 0.07636235899990385, 0.07709528013485212, 0.07326544861438689]}, "mutation_prompt": null}
{"id": "99bc1de4-fa63-47ef-b07d-28e805679fda", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Refined Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover with enhanced probability adaptation\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.1))\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning with more granular adjustments\n            self.scale_factor = np.random.uniform(0.65, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.88, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with refined adaptive mutation and crossover strategies to improve convergence efficiency.", "configspace": "", "generation": 25, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "861cd3e5-fef8-4d90-a5d1-b5c310a7510e", "metadata": {"aucs": [0.822419785938898, 0.8199714546643329, 0.8414894141977063, 0.8430091771653526, 0.8593885836191024, 0.8487231796708052, 0.8367890364383294, 0.8302523382030463, 0.8293736847039304, 0.6900526707292051, 0.729827418174816, 0.7165636142714544, 0.7210593429287958, 0.7066488819727987, 0.73925793568504, 0.7290705693599189, 0.7228033402871135, 0.7062545396178945, 0.1276970958927961, 0.10836103147880471, 0.10584430366771846, 0.3699480834266704, 0.14078795992086013, 0.11173662417811558, 0.24405632789960074, 0.1979650359645696, 0.11807834733719214, 0.09487999780108625, 0.12368899362754915, 0.1075596948214832, 0.13173357002036357, 0.09980875650657273, 0.11640007866229085, 0.1278981270616787, 0.12028358906634584, 0.12155953374756501, 0.9267733553648255, 0.8780210526035417, 0.9728814299618388, 0.9627363618388612, 0.9068972901895733, 0.9753106988533982, 0.950121428753759, 0.9613290656568141, 0.9730778020274361, 0.6217127761634991, 0.5898663642757915, 0.6498912945803319, 0.5908153910909509, 0.6029460563973829, 0.601656570202229, 0.5726798590248927, 0.5981797797944681, 0.610924263252564, 0.8272794955422078, 0.7839572083705488, 0.8292962044243667, 0.8387891564677299, 0.8155388282714626, 0.8237694981028187, 0.8208478301223947, 0.8030835718841802, 0.8302702542657152, 0.6115389342871294, 0.6505395783882206, 0.6010719361145394, 0.6201992295121656, 0.5474925340891813, 0.12496363056790527, 0.6172883917916766, 0.5800103510803774, 0.6178082965572207, 0.5198145289921565, 0.01669045686983861, 0.537493623059079, 0.5574622518931232, 0.583907273603204, 0.6325076991684645, 0.6040173477737164, 0.5772205189597104, 0.4477021493834583, 0.5951745198118525, 0.5751254750305228, 0.611168261060888, 0.6095156079537748, 0.5613895288278088, 0.653165236812457, 0.578010382898307, 0.5906344030858592, 0.5734038836895186, 0.6973248370362327, 0.6690598036518844, 0.6847305193213178, 0.7061685940428326, 0.7127427735436558, 0.6956403853904165, 0.7256654724870555, 0.6974935332756751, 0.6800657796012706, 0.26886888297261247, 0.2567298455899326, 0.1978498023786025, 0.4711096272090417, 0.4616923459558898, 0.33646622305502594, 0.3003209734846265, 0.2923859164690722, 0.2917522917795389, 0.4407450260626149, 0.47750354188731814, 0.44573651789588875, 0.46007102069606187, 0.4623265148506259, 0.4698450507558254, 0.4983374796651274, 0.4651038353049999, 0.4906097444919848, 0.7939959747146519, 0.7512639921384054, 0.8024278744310025, 0.7655647590715289, 0.7860141525136092, 0.7469872082840403, 0.7837308674550727, 0.7867152501597141, 0.7814435476452145, 0.10731152787756348, 0.11531064980216776, 0.13327898151509088, 0.0845459419935578, 0.1129017830272383, 0.10799288264697948, 0.09026607095640027, 0.09242354853904122, 0.11414610931447933, 0.14859750401177263, 0.16993161980945604, 0.21808791662555005, 0.17893340336430485, 0.20673396640031128, 0.17514927217005238, 0.21812932372262783, 0.1816380653821965, 0.1969196835645982, 0.4445529723727534, 0.42052418256371293, 0.4832803672599898, 0.434256993835186, 0.45321080811656955, 0.43851286281310375, 0.47433954584356, 0.44995204167902425, 0.4907650783321168, 0.36028806305334393, 0.3637094622146594, 0.2797815375835401, 0.339563147640781, 0.3282683863725553, 0.33629759002845827, 0.38231494403451727, 0.36727042862318426, 0.40476782964212854, 0.19355751934158139, 0.222651046201242, 0.20008507149009302, 0.24076494486116384, 0.1823909733253869, 0.23823667947716676, 0.18896336916398737, 0.1775488692840156, 0.19825657499372007, 0.31328935485711895, 0.24978833520335753, 0.5467031594247906, 0.22580931177013186, 0.3068491624219365, 0.20701222076673953, 0.20878834757163556, 0.26504852465161, 0.19381349682665883, 0.8488604691570416, 0.17137799400702514, 0.17022881054803018, 0.8712490731729117, 0.2056317133448773, 0.775756989121672, 0.16335836936746595, 0.17793760622496502, 0.8524947927571764, 0.8179025205290024, 0.7358647696051241, 0.8190914110923364, 0.201869625298709, 0.16556880117395845, 0.7141282873355854, 0.2071428842442561, 0.8635935380607013, 0.791471704067155, 0.18662858002296845, 0.186359167637123, 0.19667438813877036, 0.18593125007449574, 0.16702174357922817, 0.17072242613914146, 0.18406270829058735, 0.1883483385411402, 0.21088470591522512, 0.08556516989537444, 0.08019225669858099, 0.08286134945626689, 0.07496979065675446, 0.0850600782588915, 0.0735401347951864, 0.07636235899990385, 0.07709528013485212, 0.07326544861438689]}, "mutation_prompt": null}
{"id": "048240ad-bebb-4ebe-bc50-bd8927795376", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Refined Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover with enhanced probability adaptation\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.1))\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning with more granular adjustments\n            self.scale_factor = np.random.uniform(0.65, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.88, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with refined adaptive mutation and crossover strategies to improve convergence efficiency.", "configspace": "", "generation": 25, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "861cd3e5-fef8-4d90-a5d1-b5c310a7510e", "metadata": {"aucs": [0.822419785938898, 0.8199714546643329, 0.8414894141977063, 0.8430091771653526, 0.8593885836191024, 0.8487231796708052, 0.8367890364383294, 0.8302523382030463, 0.8293736847039304, 0.6900526707292051, 0.729827418174816, 0.7165636142714544, 0.7210593429287958, 0.7066488819727987, 0.73925793568504, 0.7290705693599189, 0.7228033402871135, 0.7062545396178945, 0.1276970958927961, 0.10836103147880471, 0.10584430366771846, 0.3699480834266704, 0.14078795992086013, 0.11173662417811558, 0.24405632789960074, 0.1979650359645696, 0.11807834733719214, 0.09487999780108625, 0.12368899362754915, 0.1075596948214832, 0.13173357002036357, 0.09980875650657273, 0.11640007866229085, 0.1278981270616787, 0.12028358906634584, 0.12155953374756501, 0.9267733553648255, 0.8780210526035417, 0.9728814299618388, 0.9627363618388612, 0.9068972901895733, 0.9753106988533982, 0.950121428753759, 0.9613290656568141, 0.9730778020274361, 0.6217127761634991, 0.5898663642757915, 0.6498912945803319, 0.5908153910909509, 0.6029460563973829, 0.601656570202229, 0.5726798590248927, 0.5981797797944681, 0.610924263252564, 0.8272794955422078, 0.7839572083705488, 0.8292962044243667, 0.8387891564677299, 0.8155388282714626, 0.8237694981028187, 0.8208478301223947, 0.8030835718841802, 0.8302702542657152, 0.6115389342871294, 0.6505395783882206, 0.6010719361145394, 0.6201992295121656, 0.5474925340891813, 0.12496363056790527, 0.6172883917916766, 0.5800103510803774, 0.6178082965572207, 0.5198145289921565, 0.01669045686983861, 0.537493623059079, 0.5574622518931232, 0.583907273603204, 0.6325076991684645, 0.6040173477737164, 0.5772205189597104, 0.4477021493834583, 0.5951745198118525, 0.5751254750305228, 0.611168261060888, 0.6095156079537748, 0.5613895288278088, 0.653165236812457, 0.578010382898307, 0.5906344030858592, 0.5734038836895186, 0.6973248370362327, 0.6690598036518844, 0.6847305193213178, 0.7061685940428326, 0.7127427735436558, 0.6956403853904165, 0.7256654724870555, 0.6974935332756751, 0.6800657796012706, 0.26886888297261247, 0.2567298455899326, 0.1978498023786025, 0.4711096272090417, 0.4616923459558898, 0.33646622305502594, 0.3003209734846265, 0.2923859164690722, 0.2917522917795389, 0.4407450260626149, 0.47750354188731814, 0.44573651789588875, 0.46007102069606187, 0.4623265148506259, 0.4698450507558254, 0.4983374796651274, 0.4651038353049999, 0.4906097444919848, 0.7939959747146519, 0.7512639921384054, 0.8024278744310025, 0.7655647590715289, 0.7860141525136092, 0.7469872082840403, 0.7837308674550727, 0.7867152501597141, 0.7814435476452145, 0.10731152787756348, 0.11531064980216776, 0.13327898151509088, 0.0845459419935578, 0.1129017830272383, 0.10799288264697948, 0.09026607095640027, 0.09242354853904122, 0.11414610931447933, 0.14859750401177263, 0.16993161980945604, 0.21808791662555005, 0.17893340336430485, 0.20673396640031128, 0.17514927217005238, 0.21812932372262783, 0.1816380653821965, 0.1969196835645982, 0.4445529723727534, 0.42052418256371293, 0.4832803672599898, 0.434256993835186, 0.45321080811656955, 0.43851286281310375, 0.47433954584356, 0.44995204167902425, 0.4907650783321168, 0.36028806305334393, 0.3637094622146594, 0.2797815375835401, 0.339563147640781, 0.3282683863725553, 0.33629759002845827, 0.38231494403451727, 0.36727042862318426, 0.40476782964212854, 0.19355751934158139, 0.222651046201242, 0.20008507149009302, 0.24076494486116384, 0.1823909733253869, 0.23823667947716676, 0.18896336916398737, 0.1775488692840156, 0.19825657499372007, 0.31328935485711895, 0.24978833520335753, 0.5467031594247906, 0.22580931177013186, 0.3068491624219365, 0.20701222076673953, 0.20878834757163556, 0.26504852465161, 0.19381349682665883, 0.8488604691570416, 0.17137799400702514, 0.17022881054803018, 0.8712490731729117, 0.2056317133448773, 0.775756989121672, 0.16335836936746595, 0.17793760622496502, 0.8524947927571764, 0.8179025205290024, 0.7358647696051241, 0.8190914110923364, 0.201869625298709, 0.16556880117395845, 0.7141282873355854, 0.2071428842442561, 0.8635935380607013, 0.791471704067155, 0.18662858002296845, 0.186359167637123, 0.19667438813877036, 0.18593125007449574, 0.16702174357922817, 0.17072242613914146, 0.18406270829058735, 0.1883483385411402, 0.21088470591522512, 0.08556516989537444, 0.08019225669858099, 0.08286134945626689, 0.07496979065675446, 0.0850600782588915, 0.0735401347951864, 0.07636235899990385, 0.07709528013485212, 0.07326544861438689]}, "mutation_prompt": null}
{"id": "39a30726-5bde-4013-9a23-b8072dcc5651", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Refined Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover with enhanced probability adaptation\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.1))\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning with more granular adjustments\n            self.scale_factor = np.random.uniform(0.65, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.88, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with refined adaptive mutation and crossover strategies to improve convergence efficiency.", "configspace": "", "generation": 25, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "861cd3e5-fef8-4d90-a5d1-b5c310a7510e", "metadata": {"aucs": [0.822419785938898, 0.8199714546643329, 0.8414894141977063, 0.8430091771653526, 0.8593885836191024, 0.8487231796708052, 0.8367890364383294, 0.8302523382030463, 0.8293736847039304, 0.6900526707292051, 0.729827418174816, 0.7165636142714544, 0.7210593429287958, 0.7066488819727987, 0.73925793568504, 0.7290705693599189, 0.7228033402871135, 0.7062545396178945, 0.1276970958927961, 0.10836103147880471, 0.10584430366771846, 0.3699480834266704, 0.14078795992086013, 0.11173662417811558, 0.24405632789960074, 0.1979650359645696, 0.11807834733719214, 0.09487999780108625, 0.12368899362754915, 0.1075596948214832, 0.13173357002036357, 0.09980875650657273, 0.11640007866229085, 0.1278981270616787, 0.12028358906634584, 0.12155953374756501, 0.9267733553648255, 0.8780210526035417, 0.9728814299618388, 0.9627363618388612, 0.9068972901895733, 0.9753106988533982, 0.950121428753759, 0.9613290656568141, 0.9730778020274361, 0.6217127761634991, 0.5898663642757915, 0.6498912945803319, 0.5908153910909509, 0.6029460563973829, 0.601656570202229, 0.5726798590248927, 0.5981797797944681, 0.610924263252564, 0.8272794955422078, 0.7839572083705488, 0.8292962044243667, 0.8387891564677299, 0.8155388282714626, 0.8237694981028187, 0.8208478301223947, 0.8030835718841802, 0.8302702542657152, 0.6115389342871294, 0.6505395783882206, 0.6010719361145394, 0.6201992295121656, 0.5474925340891813, 0.12496363056790527, 0.6172883917916766, 0.5800103510803774, 0.6178082965572207, 0.5198145289921565, 0.01669045686983861, 0.537493623059079, 0.5574622518931232, 0.583907273603204, 0.6325076991684645, 0.6040173477737164, 0.5772205189597104, 0.4477021493834583, 0.5951745198118525, 0.5751254750305228, 0.611168261060888, 0.6095156079537748, 0.5613895288278088, 0.653165236812457, 0.578010382898307, 0.5906344030858592, 0.5734038836895186, 0.6973248370362327, 0.6690598036518844, 0.6847305193213178, 0.7061685940428326, 0.7127427735436558, 0.6956403853904165, 0.7256654724870555, 0.6974935332756751, 0.6800657796012706, 0.26886888297261247, 0.2567298455899326, 0.1978498023786025, 0.4711096272090417, 0.4616923459558898, 0.33646622305502594, 0.3003209734846265, 0.2923859164690722, 0.2917522917795389, 0.4407450260626149, 0.47750354188731814, 0.44573651789588875, 0.46007102069606187, 0.4623265148506259, 0.4698450507558254, 0.4983374796651274, 0.4651038353049999, 0.4906097444919848, 0.7939959747146519, 0.7512639921384054, 0.8024278744310025, 0.7655647590715289, 0.7860141525136092, 0.7469872082840403, 0.7837308674550727, 0.7867152501597141, 0.7814435476452145, 0.10731152787756348, 0.11531064980216776, 0.13327898151509088, 0.0845459419935578, 0.1129017830272383, 0.10799288264697948, 0.09026607095640027, 0.09242354853904122, 0.11414610931447933, 0.14859750401177263, 0.16993161980945604, 0.21808791662555005, 0.17893340336430485, 0.20673396640031128, 0.17514927217005238, 0.21812932372262783, 0.1816380653821965, 0.1969196835645982, 0.4445529723727534, 0.42052418256371293, 0.4832803672599898, 0.434256993835186, 0.45321080811656955, 0.43851286281310375, 0.47433954584356, 0.44995204167902425, 0.4907650783321168, 0.36028806305334393, 0.3637094622146594, 0.2797815375835401, 0.339563147640781, 0.3282683863725553, 0.33629759002845827, 0.38231494403451727, 0.36727042862318426, 0.40476782964212854, 0.19355751934158139, 0.222651046201242, 0.20008507149009302, 0.24076494486116384, 0.1823909733253869, 0.23823667947716676, 0.18896336916398737, 0.1775488692840156, 0.19825657499372007, 0.31328935485711895, 0.24978833520335753, 0.5467031594247906, 0.22580931177013186, 0.3068491624219365, 0.20701222076673953, 0.20878834757163556, 0.26504852465161, 0.19381349682665883, 0.8488604691570416, 0.17137799400702514, 0.17022881054803018, 0.8712490731729117, 0.2056317133448773, 0.775756989121672, 0.16335836936746595, 0.17793760622496502, 0.8524947927571764, 0.8179025205290024, 0.7358647696051241, 0.8190914110923364, 0.201869625298709, 0.16556880117395845, 0.7141282873355854, 0.2071428842442561, 0.8635935380607013, 0.791471704067155, 0.18662858002296845, 0.186359167637123, 0.19667438813877036, 0.18593125007449574, 0.16702174357922817, 0.17072242613914146, 0.18406270829058735, 0.1883483385411402, 0.21088470591522512, 0.08556516989537444, 0.08019225669858099, 0.08286134945626689, 0.07496979065675446, 0.0850600782588915, 0.0735401347951864, 0.07636235899990385, 0.07709528013485212, 0.07326544861438689]}, "mutation_prompt": null}
{"id": "a2d12114-5ca6-4471-9f8a-5da4987ba456", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Refined Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover with enhanced probability adaptation\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.1))\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning with more granular adjustments\n            self.scale_factor = np.random.uniform(0.65, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.88, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with refined adaptive mutation and crossover strategies to improve convergence efficiency.", "configspace": "", "generation": 25, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "861cd3e5-fef8-4d90-a5d1-b5c310a7510e", "metadata": {"aucs": [0.822419785938898, 0.8199714546643329, 0.8414894141977063, 0.8430091771653526, 0.8593885836191024, 0.8487231796708052, 0.8367890364383294, 0.8302523382030463, 0.8293736847039304, 0.6900526707292051, 0.729827418174816, 0.7165636142714544, 0.7210593429287958, 0.7066488819727987, 0.73925793568504, 0.7290705693599189, 0.7228033402871135, 0.7062545396178945, 0.1276970958927961, 0.10836103147880471, 0.10584430366771846, 0.3699480834266704, 0.14078795992086013, 0.11173662417811558, 0.24405632789960074, 0.1979650359645696, 0.11807834733719214, 0.09487999780108625, 0.12368899362754915, 0.1075596948214832, 0.13173357002036357, 0.09980875650657273, 0.11640007866229085, 0.1278981270616787, 0.12028358906634584, 0.12155953374756501, 0.9267733553648255, 0.8780210526035417, 0.9728814299618388, 0.9627363618388612, 0.9068972901895733, 0.9753106988533982, 0.950121428753759, 0.9613290656568141, 0.9730778020274361, 0.6217127761634991, 0.5898663642757915, 0.6498912945803319, 0.5908153910909509, 0.6029460563973829, 0.601656570202229, 0.5726798590248927, 0.5981797797944681, 0.610924263252564, 0.8272794955422078, 0.7839572083705488, 0.8292962044243667, 0.8387891564677299, 0.8155388282714626, 0.8237694981028187, 0.8208478301223947, 0.8030835718841802, 0.8302702542657152, 0.6115389342871294, 0.6505395783882206, 0.6010719361145394, 0.6201992295121656, 0.5474925340891813, 0.12496363056790527, 0.6172883917916766, 0.5800103510803774, 0.6178082965572207, 0.5198145289921565, 0.01669045686983861, 0.537493623059079, 0.5574622518931232, 0.583907273603204, 0.6325076991684645, 0.6040173477737164, 0.5772205189597104, 0.4477021493834583, 0.5951745198118525, 0.5751254750305228, 0.611168261060888, 0.6095156079537748, 0.5613895288278088, 0.653165236812457, 0.578010382898307, 0.5906344030858592, 0.5734038836895186, 0.6973248370362327, 0.6690598036518844, 0.6847305193213178, 0.7061685940428326, 0.7127427735436558, 0.6956403853904165, 0.7256654724870555, 0.6974935332756751, 0.6800657796012706, 0.26886888297261247, 0.2567298455899326, 0.1978498023786025, 0.4711096272090417, 0.4616923459558898, 0.33646622305502594, 0.3003209734846265, 0.2923859164690722, 0.2917522917795389, 0.4407450260626149, 0.47750354188731814, 0.44573651789588875, 0.46007102069606187, 0.4623265148506259, 0.4698450507558254, 0.4983374796651274, 0.4651038353049999, 0.4906097444919848, 0.7939959747146519, 0.7512639921384054, 0.8024278744310025, 0.7655647590715289, 0.7860141525136092, 0.7469872082840403, 0.7837308674550727, 0.7867152501597141, 0.7814435476452145, 0.10731152787756348, 0.11531064980216776, 0.13327898151509088, 0.0845459419935578, 0.1129017830272383, 0.10799288264697948, 0.09026607095640027, 0.09242354853904122, 0.11414610931447933, 0.14859750401177263, 0.16993161980945604, 0.21808791662555005, 0.17893340336430485, 0.20673396640031128, 0.17514927217005238, 0.21812932372262783, 0.1816380653821965, 0.1969196835645982, 0.4445529723727534, 0.42052418256371293, 0.4832803672599898, 0.434256993835186, 0.45321080811656955, 0.43851286281310375, 0.47433954584356, 0.44995204167902425, 0.4907650783321168, 0.36028806305334393, 0.3637094622146594, 0.2797815375835401, 0.339563147640781, 0.3282683863725553, 0.33629759002845827, 0.38231494403451727, 0.36727042862318426, 0.40476782964212854, 0.19355751934158139, 0.222651046201242, 0.20008507149009302, 0.24076494486116384, 0.1823909733253869, 0.23823667947716676, 0.18896336916398737, 0.1775488692840156, 0.19825657499372007, 0.31328935485711895, 0.24978833520335753, 0.5467031594247906, 0.22580931177013186, 0.3068491624219365, 0.20701222076673953, 0.20878834757163556, 0.26504852465161, 0.19381349682665883, 0.8488604691570416, 0.17137799400702514, 0.17022881054803018, 0.8712490731729117, 0.2056317133448773, 0.775756989121672, 0.16335836936746595, 0.17793760622496502, 0.8524947927571764, 0.8179025205290024, 0.7358647696051241, 0.8190914110923364, 0.201869625298709, 0.16556880117395845, 0.7141282873355854, 0.2071428842442561, 0.8635935380607013, 0.791471704067155, 0.18662858002296845, 0.186359167637123, 0.19667438813877036, 0.18593125007449574, 0.16702174357922817, 0.17072242613914146, 0.18406270829058735, 0.1883483385411402, 0.21088470591522512, 0.08556516989537444, 0.08019225669858099, 0.08286134945626689, 0.07496979065675446, 0.0850600782588915, 0.0735401347951864, 0.07636235899990385, 0.07709528013485212, 0.07326544861438689]}, "mutation_prompt": null}
{"id": "c3f468ec-3289-4f56-929c-7cfe9e6efc12", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Refined Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover with enhanced probability adaptation\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.1))\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning with more granular adjustments\n            self.scale_factor = np.random.uniform(0.65, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.88, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with refined adaptive mutation and crossover strategies to improve convergence efficiency.", "configspace": "", "generation": 25, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "861cd3e5-fef8-4d90-a5d1-b5c310a7510e", "metadata": {"aucs": [0.822419785938898, 0.8199714546643329, 0.8414894141977063, 0.8430091771653526, 0.8593885836191024, 0.8487231796708052, 0.8367890364383294, 0.8302523382030463, 0.8293736847039304, 0.6900526707292051, 0.729827418174816, 0.7165636142714544, 0.7210593429287958, 0.7066488819727987, 0.73925793568504, 0.7290705693599189, 0.7228033402871135, 0.7062545396178945, 0.1276970958927961, 0.10836103147880471, 0.10584430366771846, 0.3699480834266704, 0.14078795992086013, 0.11173662417811558, 0.24405632789960074, 0.1979650359645696, 0.11807834733719214, 0.09487999780108625, 0.12368899362754915, 0.1075596948214832, 0.13173357002036357, 0.09980875650657273, 0.11640007866229085, 0.1278981270616787, 0.12028358906634584, 0.12155953374756501, 0.9267733553648255, 0.8780210526035417, 0.9728814299618388, 0.9627363618388612, 0.9068972901895733, 0.9753106988533982, 0.950121428753759, 0.9613290656568141, 0.9730778020274361, 0.6217127761634991, 0.5898663642757915, 0.6498912945803319, 0.5908153910909509, 0.6029460563973829, 0.601656570202229, 0.5726798590248927, 0.5981797797944681, 0.610924263252564, 0.8272794955422078, 0.7839572083705488, 0.8292962044243667, 0.8387891564677299, 0.8155388282714626, 0.8237694981028187, 0.8208478301223947, 0.8030835718841802, 0.8302702542657152, 0.6115389342871294, 0.6505395783882206, 0.6010719361145394, 0.6201992295121656, 0.5474925340891813, 0.12496363056790527, 0.6172883917916766, 0.5800103510803774, 0.6178082965572207, 0.5198145289921565, 0.01669045686983861, 0.537493623059079, 0.5574622518931232, 0.583907273603204, 0.6325076991684645, 0.6040173477737164, 0.5772205189597104, 0.4477021493834583, 0.5951745198118525, 0.5751254750305228, 0.611168261060888, 0.6095156079537748, 0.5613895288278088, 0.653165236812457, 0.578010382898307, 0.5906344030858592, 0.5734038836895186, 0.6973248370362327, 0.6690598036518844, 0.6847305193213178, 0.7061685940428326, 0.7127427735436558, 0.6956403853904165, 0.7256654724870555, 0.6974935332756751, 0.6800657796012706, 0.26886888297261247, 0.2567298455899326, 0.1978498023786025, 0.4711096272090417, 0.4616923459558898, 0.33646622305502594, 0.3003209734846265, 0.2923859164690722, 0.2917522917795389, 0.4407450260626149, 0.47750354188731814, 0.44573651789588875, 0.46007102069606187, 0.4623265148506259, 0.4698450507558254, 0.4983374796651274, 0.4651038353049999, 0.4906097444919848, 0.7939959747146519, 0.7512639921384054, 0.8024278744310025, 0.7655647590715289, 0.7860141525136092, 0.7469872082840403, 0.7837308674550727, 0.7867152501597141, 0.7814435476452145, 0.10731152787756348, 0.11531064980216776, 0.13327898151509088, 0.0845459419935578, 0.1129017830272383, 0.10799288264697948, 0.09026607095640027, 0.09242354853904122, 0.11414610931447933, 0.14859750401177263, 0.16993161980945604, 0.21808791662555005, 0.17893340336430485, 0.20673396640031128, 0.17514927217005238, 0.21812932372262783, 0.1816380653821965, 0.1969196835645982, 0.4445529723727534, 0.42052418256371293, 0.4832803672599898, 0.434256993835186, 0.45321080811656955, 0.43851286281310375, 0.47433954584356, 0.44995204167902425, 0.4907650783321168, 0.36028806305334393, 0.3637094622146594, 0.2797815375835401, 0.339563147640781, 0.3282683863725553, 0.33629759002845827, 0.38231494403451727, 0.36727042862318426, 0.40476782964212854, 0.19355751934158139, 0.222651046201242, 0.20008507149009302, 0.24076494486116384, 0.1823909733253869, 0.23823667947716676, 0.18896336916398737, 0.1775488692840156, 0.19825657499372007, 0.31328935485711895, 0.24978833520335753, 0.5467031594247906, 0.22580931177013186, 0.3068491624219365, 0.20701222076673953, 0.20878834757163556, 0.26504852465161, 0.19381349682665883, 0.8488604691570416, 0.17137799400702514, 0.17022881054803018, 0.8712490731729117, 0.2056317133448773, 0.775756989121672, 0.16335836936746595, 0.17793760622496502, 0.8524947927571764, 0.8179025205290024, 0.7358647696051241, 0.8190914110923364, 0.201869625298709, 0.16556880117395845, 0.7141282873355854, 0.2071428842442561, 0.8635935380607013, 0.791471704067155, 0.18662858002296845, 0.186359167637123, 0.19667438813877036, 0.18593125007449574, 0.16702174357922817, 0.17072242613914146, 0.18406270829058735, 0.1883483385411402, 0.21088470591522512, 0.08556516989537444, 0.08019225669858099, 0.08286134945626689, 0.07496979065675446, 0.0850600782588915, 0.0735401347951864, 0.07636235899990385, 0.07709528013485212, 0.07326544861438689]}, "mutation_prompt": null}
{"id": "2c5f589a-7515-40d6-903e-78f9d9414386", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Refined Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover with enhanced probability adaptation\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.1))\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning with more granular adjustments\n            self.scale_factor = np.random.uniform(0.65, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.88, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with refined adaptive mutation and crossover strategies to improve convergence efficiency.", "configspace": "", "generation": 25, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "861cd3e5-fef8-4d90-a5d1-b5c310a7510e", "metadata": {"aucs": [0.822419785938898, 0.8199714546643329, 0.8414894141977063, 0.8430091771653526, 0.8593885836191024, 0.8487231796708052, 0.8367890364383294, 0.8302523382030463, 0.8293736847039304, 0.6900526707292051, 0.729827418174816, 0.7165636142714544, 0.7210593429287958, 0.7066488819727987, 0.73925793568504, 0.7290705693599189, 0.7228033402871135, 0.7062545396178945, 0.1276970958927961, 0.10836103147880471, 0.10584430366771846, 0.3699480834266704, 0.14078795992086013, 0.11173662417811558, 0.24405632789960074, 0.1979650359645696, 0.11807834733719214, 0.09487999780108625, 0.12368899362754915, 0.1075596948214832, 0.13173357002036357, 0.09980875650657273, 0.11640007866229085, 0.1278981270616787, 0.12028358906634584, 0.12155953374756501, 0.9267733553648255, 0.8780210526035417, 0.9728814299618388, 0.9627363618388612, 0.9068972901895733, 0.9753106988533982, 0.950121428753759, 0.9613290656568141, 0.9730778020274361, 0.6217127761634991, 0.5898663642757915, 0.6498912945803319, 0.5908153910909509, 0.6029460563973829, 0.601656570202229, 0.5726798590248927, 0.5981797797944681, 0.610924263252564, 0.8272794955422078, 0.7839572083705488, 0.8292962044243667, 0.8387891564677299, 0.8155388282714626, 0.8237694981028187, 0.8208478301223947, 0.8030835718841802, 0.8302702542657152, 0.6115389342871294, 0.6505395783882206, 0.6010719361145394, 0.6201992295121656, 0.5474925340891813, 0.12496363056790527, 0.6172883917916766, 0.5800103510803774, 0.6178082965572207, 0.5198145289921565, 0.01669045686983861, 0.537493623059079, 0.5574622518931232, 0.583907273603204, 0.6325076991684645, 0.6040173477737164, 0.5772205189597104, 0.4477021493834583, 0.5951745198118525, 0.5751254750305228, 0.611168261060888, 0.6095156079537748, 0.5613895288278088, 0.653165236812457, 0.578010382898307, 0.5906344030858592, 0.5734038836895186, 0.6973248370362327, 0.6690598036518844, 0.6847305193213178, 0.7061685940428326, 0.7127427735436558, 0.6956403853904165, 0.7256654724870555, 0.6974935332756751, 0.6800657796012706, 0.26886888297261247, 0.2567298455899326, 0.1978498023786025, 0.4711096272090417, 0.4616923459558898, 0.33646622305502594, 0.3003209734846265, 0.2923859164690722, 0.2917522917795389, 0.4407450260626149, 0.47750354188731814, 0.44573651789588875, 0.46007102069606187, 0.4623265148506259, 0.4698450507558254, 0.4983374796651274, 0.4651038353049999, 0.4906097444919848, 0.7939959747146519, 0.7512639921384054, 0.8024278744310025, 0.7655647590715289, 0.7860141525136092, 0.7469872082840403, 0.7837308674550727, 0.7867152501597141, 0.7814435476452145, 0.10731152787756348, 0.11531064980216776, 0.13327898151509088, 0.0845459419935578, 0.1129017830272383, 0.10799288264697948, 0.09026607095640027, 0.09242354853904122, 0.11414610931447933, 0.14859750401177263, 0.16993161980945604, 0.21808791662555005, 0.17893340336430485, 0.20673396640031128, 0.17514927217005238, 0.21812932372262783, 0.1816380653821965, 0.1969196835645982, 0.4445529723727534, 0.42052418256371293, 0.4832803672599898, 0.434256993835186, 0.45321080811656955, 0.43851286281310375, 0.47433954584356, 0.44995204167902425, 0.4907650783321168, 0.36028806305334393, 0.3637094622146594, 0.2797815375835401, 0.339563147640781, 0.3282683863725553, 0.33629759002845827, 0.38231494403451727, 0.36727042862318426, 0.40476782964212854, 0.19355751934158139, 0.222651046201242, 0.20008507149009302, 0.24076494486116384, 0.1823909733253869, 0.23823667947716676, 0.18896336916398737, 0.1775488692840156, 0.19825657499372007, 0.31328935485711895, 0.24978833520335753, 0.5467031594247906, 0.22580931177013186, 0.3068491624219365, 0.20701222076673953, 0.20878834757163556, 0.26504852465161, 0.19381349682665883, 0.8488604691570416, 0.17137799400702514, 0.17022881054803018, 0.8712490731729117, 0.2056317133448773, 0.775756989121672, 0.16335836936746595, 0.17793760622496502, 0.8524947927571764, 0.8179025205290024, 0.7358647696051241, 0.8190914110923364, 0.201869625298709, 0.16556880117395845, 0.7141282873355854, 0.2071428842442561, 0.8635935380607013, 0.791471704067155, 0.18662858002296845, 0.186359167637123, 0.19667438813877036, 0.18593125007449574, 0.16702174357922817, 0.17072242613914146, 0.18406270829058735, 0.1883483385411402, 0.21088470591522512, 0.08556516989537444, 0.08019225669858099, 0.08286134945626689, 0.07496979065675446, 0.0850600782588915, 0.0735401347951864, 0.07636235899990385, 0.07709528013485212, 0.07326544861438689]}, "mutation_prompt": null}
{"id": "8161d2b1-4d32-4cb7-8a01-2c31e7176382", "solution": "import numpy as np\n\nclass EnhancedAdaptiveEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 + int(8 * np.log(self.dim))  # Slightly adjusted population size\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85  # Adjusted scale factor for more aggressive mutations\n        self.cross_prob = 0.95  # Increased cross probability for diverse trials\n        self.adaptation_rate = 0.07  # Adjusted adaptation rate for quicker parameter tuning\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Refined Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover with enhanced probability adaptation\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor)\n                trial[crossover] = mutant[crossover]\n\n                # Selection with strategic elitism\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Self-adaptive parameter tuning with more granular adjustments\n            self.scale_factor = np.random.uniform(0.75, 0.9)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.92, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        return best_solution, best_fitness", "name": "EnhancedAdaptiveEvolutionaryOptimizer", "description": "Enhanced Adaptive Evolutionary Strategy with dynamic parameter tuning and strategic elitism for improved convergence speed.", "configspace": "", "generation": 39, "fitness": 0.4382260764822525, "feedback": "The algorithm EnhancedAdaptiveEvolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.44 with standard deviation 0.27.", "error": "", "parent_id": "861cd3e5-fef8-4d90-a5d1-b5c310a7510e", "metadata": {"aucs": [0.7929232464681278, 0.7936744134865032, 0.8191520590959208, 0.8358161529971332, 0.8222276420922241, 0.8455111450445962, 0.822957665100936, 0.8033801310480292, 0.8044356363593161, 0.690905660634922, 0.7000571523525346, 0.6855609451991178, 0.7124800613178729, 0.7132750692829687, 0.6821612045669332, 0.6694593396847902, 0.6776637568491295, 0.6918780620140947, 0.12231794017683884, 0.11831073198241415, 0.10950050597103378, 0.11922361517127267, 0.12086614016753061, 0.1144755902864989, 0.09901732917743433, 0.11088429140748779, 0.44158052384763646, 0.14632910320638226, 0.13148546378886328, 0.10395255438757578, 0.1256845186490394, 0.12792796479009938, 0.14062237839633307, 0.1331783179158731, 0.13253710296558396, 0.12125305079001814, 0.9801551498718207, 0.9485449648529777, 0.9641012721972293, 0.9767733711679207, 0.9767504368002193, 0.9452626442497429, 0.9610137677105403, 0.9820633355033531, 0.9211601126691205, 0.5533532789389457, 0.5551119221574115, 0.5528497392195375, 0.5248865474019909, 0.6597450744870454, 0.5465479870264458, 0.5639538919118549, 0.5748497317026446, 0.5615276380874896, 0.8006781090484273, 0.8158718053678391, 0.7594357241685328, 0.8248828619470996, 0.8010432348381513, 0.7176329723991179, 0.8493512856955199, 0.7622368334469769, 0.8174009285130022, 0.5710166458940957, 0.5809653076568173, 0.5595732717219053, 0.5837423256513694, 0.4601967260977796, 0.4541786788956357, 0.4892042082954473, 0.47652597233179084, 0.5776008740932185, 0.6242153213865529, 0.010022509293240223, 0.5569087852013866, 0.6191926416719309, 0.5493051536866977, 0.6112026382287603, 0.5913186311199596, 0.5605729290538024, 0.6071792427957082, 0.6043510734498624, 0.5527909482570962, 0.5733931868882118, 0.6155371473750495, 0.5643887306707058, 0.535737649752849, 0.5894160172190845, 0.6030425373112143, 0.5394218230471035, 0.7439125172552385, 0.6871290434780143, 0.6434701999772451, 0.663986723601355, 0.63174418247455, 0.6508667603318665, 0.6823540050459602, 0.6878836127853802, 0.6469971044729746, 0.2222052439234109, 0.14879842474937865, 0.271641444048221, 0.423168223257151, 0.4717052244199502, 0.3431652722172256, 0.3536875708471765, 0.2594913493663128, 0.2966819672048998, 0.44462314427976346, 0.42071103984611513, 0.45381266799271447, 0.42316059829712116, 0.4081913537308619, 0.45811256816879453, 0.45044893646305484, 0.4565823968838283, 0.43454085483628224, 0.7625726807268873, 0.7440408329462773, 0.7433279247317028, 0.768405193587413, 0.7458459914072098, 0.7647327924366523, 0.7747196336327863, 0.7202232477722544, 0.7572186525497724, 0.11031434634193571, 0.12201648420461475, 0.12145066140794647, 0.0934719082999309, 0.12868490074021466, 0.20809633041561704, 0.09124693150420649, 0.09395789203110472, 0.1341432274115434, 0.16050474895998035, 0.15019053955767614, 0.5600460993695926, 0.2028572271198017, 0.26868847250129446, 0.14147713448356136, 0.210541443635468, 0.18539616763864974, 0.15684040688042855, 0.3715366971416899, 0.4473902746889419, 0.4015649888650704, 0.38341226345791246, 0.3664928433608622, 0.3960717120559627, 0.4184230934437202, 0.4308217255463126, 0.40360743823816514, 0.35720924760459716, 0.33606459290102897, 0.36443386876432904, 0.35799548999675135, 0.31558715401795057, 0.3216633611674715, 0.36410997923883204, 0.34698058292178435, 0.3369209154374153, 0.18908118138237628, 0.1941248893177081, 0.1742662422323259, 0.17650623039705804, 0.19023206846796015, 0.21834026516597782, 0.19168771855237188, 0.17447997143035665, 0.24794538967042767, 0.20777883356286708, 0.21502508408260979, 0.3994595258686393, 0.20092098431934668, 0.21390319419975035, 0.5903320667341974, 0.4545245652475636, 0.20008797404627277, 0.2986952144601749, 0.20386343673263707, 0.7859296973405743, 0.1528241962960657, 0.8448453908697232, 0.17442055626623298, 0.8567177549281912, 0.16096134966610698, 0.16398205836345459, 0.7003711103318502, 0.164974132411133, 0.1662301033074025, 0.1262309527338621, 0.19752762888297926, 0.748088724483547, 0.8000096332700531, 0.1534638144663839, 0.12728152916453783, 0.2068311304060021, 0.16544118457740464, 0.15952924791989676, 0.19131416743615026, 0.18289618749945658, 0.18322059352266873, 0.20008679177315913, 0.19859151974499656, 0.17216869198163454, 0.16674494830031494, 0.07454373185233742, 0.07494052039164667, 0.08514374070391495, 0.0725292918278061, 0.07500844264506612, 0.08034934186971254, 0.08636540397855663, 0.07885031288222055, 0.07594120600139664]}, "mutation_prompt": null}
{"id": "f4f14b48-2982-4bd2-a260-ab7a097c1dfe", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Refined Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover with enhanced probability adaptation\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.1))\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning with more granular adjustments\n            self.scale_factor = np.random.uniform(0.65, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.88, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with refined adaptive mutation and crossover strategies to improve convergence efficiency.", "configspace": "", "generation": 25, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "861cd3e5-fef8-4d90-a5d1-b5c310a7510e", "metadata": {"aucs": [0.822419785938898, 0.8199714546643329, 0.8414894141977063, 0.8430091771653526, 0.8593885836191024, 0.8487231796708052, 0.8367890364383294, 0.8302523382030463, 0.8293736847039304, 0.6900526707292051, 0.729827418174816, 0.7165636142714544, 0.7210593429287958, 0.7066488819727987, 0.73925793568504, 0.7290705693599189, 0.7228033402871135, 0.7062545396178945, 0.1276970958927961, 0.10836103147880471, 0.10584430366771846, 0.3699480834266704, 0.14078795992086013, 0.11173662417811558, 0.24405632789960074, 0.1979650359645696, 0.11807834733719214, 0.09487999780108625, 0.12368899362754915, 0.1075596948214832, 0.13173357002036357, 0.09980875650657273, 0.11640007866229085, 0.1278981270616787, 0.12028358906634584, 0.12155953374756501, 0.9267733553648255, 0.8780210526035417, 0.9728814299618388, 0.9627363618388612, 0.9068972901895733, 0.9753106988533982, 0.950121428753759, 0.9613290656568141, 0.9730778020274361, 0.6217127761634991, 0.5898663642757915, 0.6498912945803319, 0.5908153910909509, 0.6029460563973829, 0.601656570202229, 0.5726798590248927, 0.5981797797944681, 0.610924263252564, 0.8272794955422078, 0.7839572083705488, 0.8292962044243667, 0.8387891564677299, 0.8155388282714626, 0.8237694981028187, 0.8208478301223947, 0.8030835718841802, 0.8302702542657152, 0.6115389342871294, 0.6505395783882206, 0.6010719361145394, 0.6201992295121656, 0.5474925340891813, 0.12496363056790527, 0.6172883917916766, 0.5800103510803774, 0.6178082965572207, 0.5198145289921565, 0.01669045686983861, 0.537493623059079, 0.5574622518931232, 0.583907273603204, 0.6325076991684645, 0.6040173477737164, 0.5772205189597104, 0.4477021493834583, 0.5951745198118525, 0.5751254750305228, 0.611168261060888, 0.6095156079537748, 0.5613895288278088, 0.653165236812457, 0.578010382898307, 0.5906344030858592, 0.5734038836895186, 0.6973248370362327, 0.6690598036518844, 0.6847305193213178, 0.7061685940428326, 0.7127427735436558, 0.6956403853904165, 0.7256654724870555, 0.6974935332756751, 0.6800657796012706, 0.26886888297261247, 0.2567298455899326, 0.1978498023786025, 0.4711096272090417, 0.4616923459558898, 0.33646622305502594, 0.3003209734846265, 0.2923859164690722, 0.2917522917795389, 0.4407450260626149, 0.47750354188731814, 0.44573651789588875, 0.46007102069606187, 0.4623265148506259, 0.4698450507558254, 0.4983374796651274, 0.4651038353049999, 0.4906097444919848, 0.7939959747146519, 0.7512639921384054, 0.8024278744310025, 0.7655647590715289, 0.7860141525136092, 0.7469872082840403, 0.7837308674550727, 0.7867152501597141, 0.7814435476452145, 0.10731152787756348, 0.11531064980216776, 0.13327898151509088, 0.0845459419935578, 0.1129017830272383, 0.10799288264697948, 0.09026607095640027, 0.09242354853904122, 0.11414610931447933, 0.14859750401177263, 0.16993161980945604, 0.21808791662555005, 0.17893340336430485, 0.20673396640031128, 0.17514927217005238, 0.21812932372262783, 0.1816380653821965, 0.1969196835645982, 0.4445529723727534, 0.42052418256371293, 0.4832803672599898, 0.434256993835186, 0.45321080811656955, 0.43851286281310375, 0.47433954584356, 0.44995204167902425, 0.4907650783321168, 0.36028806305334393, 0.3637094622146594, 0.2797815375835401, 0.339563147640781, 0.3282683863725553, 0.33629759002845827, 0.38231494403451727, 0.36727042862318426, 0.40476782964212854, 0.19355751934158139, 0.222651046201242, 0.20008507149009302, 0.24076494486116384, 0.1823909733253869, 0.23823667947716676, 0.18896336916398737, 0.1775488692840156, 0.19825657499372007, 0.31328935485711895, 0.24978833520335753, 0.5467031594247906, 0.22580931177013186, 0.3068491624219365, 0.20701222076673953, 0.20878834757163556, 0.26504852465161, 0.19381349682665883, 0.8488604691570416, 0.17137799400702514, 0.17022881054803018, 0.8712490731729117, 0.2056317133448773, 0.775756989121672, 0.16335836936746595, 0.17793760622496502, 0.8524947927571764, 0.8179025205290024, 0.7358647696051241, 0.8190914110923364, 0.201869625298709, 0.16556880117395845, 0.7141282873355854, 0.2071428842442561, 0.8635935380607013, 0.791471704067155, 0.18662858002296845, 0.186359167637123, 0.19667438813877036, 0.18593125007449574, 0.16702174357922817, 0.17072242613914146, 0.18406270829058735, 0.1883483385411402, 0.21088470591522512, 0.08556516989537444, 0.08019225669858099, 0.08286134945626689, 0.07496979065675446, 0.0850600782588915, 0.0735401347951864, 0.07636235899990385, 0.07709528013485212, 0.07326544861438689]}, "mutation_prompt": null}
{"id": "b6128b07-66cb-4fb7-b3e3-83a0f4633a03", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Refined Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover with enhanced probability adaptation\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.1))\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning with more granular adjustments\n            self.scale_factor = np.random.uniform(0.65, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.88, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with refined adaptive mutation and crossover strategies to improve convergence efficiency.", "configspace": "", "generation": 25, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "861cd3e5-fef8-4d90-a5d1-b5c310a7510e", "metadata": {"aucs": [0.822419785938898, 0.8199714546643329, 0.8414894141977063, 0.8430091771653526, 0.8593885836191024, 0.8487231796708052, 0.8367890364383294, 0.8302523382030463, 0.8293736847039304, 0.6900526707292051, 0.729827418174816, 0.7165636142714544, 0.7210593429287958, 0.7066488819727987, 0.73925793568504, 0.7290705693599189, 0.7228033402871135, 0.7062545396178945, 0.1276970958927961, 0.10836103147880471, 0.10584430366771846, 0.3699480834266704, 0.14078795992086013, 0.11173662417811558, 0.24405632789960074, 0.1979650359645696, 0.11807834733719214, 0.09487999780108625, 0.12368899362754915, 0.1075596948214832, 0.13173357002036357, 0.09980875650657273, 0.11640007866229085, 0.1278981270616787, 0.12028358906634584, 0.12155953374756501, 0.9267733553648255, 0.8780210526035417, 0.9728814299618388, 0.9627363618388612, 0.9068972901895733, 0.9753106988533982, 0.950121428753759, 0.9613290656568141, 0.9730778020274361, 0.6217127761634991, 0.5898663642757915, 0.6498912945803319, 0.5908153910909509, 0.6029460563973829, 0.601656570202229, 0.5726798590248927, 0.5981797797944681, 0.610924263252564, 0.8272794955422078, 0.7839572083705488, 0.8292962044243667, 0.8387891564677299, 0.8155388282714626, 0.8237694981028187, 0.8208478301223947, 0.8030835718841802, 0.8302702542657152, 0.6115389342871294, 0.6505395783882206, 0.6010719361145394, 0.6201992295121656, 0.5474925340891813, 0.12496363056790527, 0.6172883917916766, 0.5800103510803774, 0.6178082965572207, 0.5198145289921565, 0.01669045686983861, 0.537493623059079, 0.5574622518931232, 0.583907273603204, 0.6325076991684645, 0.6040173477737164, 0.5772205189597104, 0.4477021493834583, 0.5951745198118525, 0.5751254750305228, 0.611168261060888, 0.6095156079537748, 0.5613895288278088, 0.653165236812457, 0.578010382898307, 0.5906344030858592, 0.5734038836895186, 0.6973248370362327, 0.6690598036518844, 0.6847305193213178, 0.7061685940428326, 0.7127427735436558, 0.6956403853904165, 0.7256654724870555, 0.6974935332756751, 0.6800657796012706, 0.26886888297261247, 0.2567298455899326, 0.1978498023786025, 0.4711096272090417, 0.4616923459558898, 0.33646622305502594, 0.3003209734846265, 0.2923859164690722, 0.2917522917795389, 0.4407450260626149, 0.47750354188731814, 0.44573651789588875, 0.46007102069606187, 0.4623265148506259, 0.4698450507558254, 0.4983374796651274, 0.4651038353049999, 0.4906097444919848, 0.7939959747146519, 0.7512639921384054, 0.8024278744310025, 0.7655647590715289, 0.7860141525136092, 0.7469872082840403, 0.7837308674550727, 0.7867152501597141, 0.7814435476452145, 0.10731152787756348, 0.11531064980216776, 0.13327898151509088, 0.0845459419935578, 0.1129017830272383, 0.10799288264697948, 0.09026607095640027, 0.09242354853904122, 0.11414610931447933, 0.14859750401177263, 0.16993161980945604, 0.21808791662555005, 0.17893340336430485, 0.20673396640031128, 0.17514927217005238, 0.21812932372262783, 0.1816380653821965, 0.1969196835645982, 0.4445529723727534, 0.42052418256371293, 0.4832803672599898, 0.434256993835186, 0.45321080811656955, 0.43851286281310375, 0.47433954584356, 0.44995204167902425, 0.4907650783321168, 0.36028806305334393, 0.3637094622146594, 0.2797815375835401, 0.339563147640781, 0.3282683863725553, 0.33629759002845827, 0.38231494403451727, 0.36727042862318426, 0.40476782964212854, 0.19355751934158139, 0.222651046201242, 0.20008507149009302, 0.24076494486116384, 0.1823909733253869, 0.23823667947716676, 0.18896336916398737, 0.1775488692840156, 0.19825657499372007, 0.31328935485711895, 0.24978833520335753, 0.5467031594247906, 0.22580931177013186, 0.3068491624219365, 0.20701222076673953, 0.20878834757163556, 0.26504852465161, 0.19381349682665883, 0.8488604691570416, 0.17137799400702514, 0.17022881054803018, 0.8712490731729117, 0.2056317133448773, 0.775756989121672, 0.16335836936746595, 0.17793760622496502, 0.8524947927571764, 0.8179025205290024, 0.7358647696051241, 0.8190914110923364, 0.201869625298709, 0.16556880117395845, 0.7141282873355854, 0.2071428842442561, 0.8635935380607013, 0.791471704067155, 0.18662858002296845, 0.186359167637123, 0.19667438813877036, 0.18593125007449574, 0.16702174357922817, 0.17072242613914146, 0.18406270829058735, 0.1883483385411402, 0.21088470591522512, 0.08556516989537444, 0.08019225669858099, 0.08286134945626689, 0.07496979065675446, 0.0850600782588915, 0.0735401347951864, 0.07636235899990385, 0.07709528013485212, 0.07326544861438689]}, "mutation_prompt": null}
{"id": "32fd73e5-9c17-4c4a-9e84-2c01564dfb59", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Refined Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover with enhanced probability adaptation\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.1))\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning with more granular adjustments\n            self.scale_factor = np.random.uniform(0.65, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.88, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with refined adaptive mutation and crossover strategies to improve convergence efficiency.", "configspace": "", "generation": 25, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "861cd3e5-fef8-4d90-a5d1-b5c310a7510e", "metadata": {"aucs": [0.822419785938898, 0.8199714546643329, 0.8414894141977063, 0.8430091771653526, 0.8593885836191024, 0.8487231796708052, 0.8367890364383294, 0.8302523382030463, 0.8293736847039304, 0.6900526707292051, 0.729827418174816, 0.7165636142714544, 0.7210593429287958, 0.7066488819727987, 0.73925793568504, 0.7290705693599189, 0.7228033402871135, 0.7062545396178945, 0.1276970958927961, 0.10836103147880471, 0.10584430366771846, 0.3699480834266704, 0.14078795992086013, 0.11173662417811558, 0.24405632789960074, 0.1979650359645696, 0.11807834733719214, 0.09487999780108625, 0.12368899362754915, 0.1075596948214832, 0.13173357002036357, 0.09980875650657273, 0.11640007866229085, 0.1278981270616787, 0.12028358906634584, 0.12155953374756501, 0.9267733553648255, 0.8780210526035417, 0.9728814299618388, 0.9627363618388612, 0.9068972901895733, 0.9753106988533982, 0.950121428753759, 0.9613290656568141, 0.9730778020274361, 0.6217127761634991, 0.5898663642757915, 0.6498912945803319, 0.5908153910909509, 0.6029460563973829, 0.601656570202229, 0.5726798590248927, 0.5981797797944681, 0.610924263252564, 0.8272794955422078, 0.7839572083705488, 0.8292962044243667, 0.8387891564677299, 0.8155388282714626, 0.8237694981028187, 0.8208478301223947, 0.8030835718841802, 0.8302702542657152, 0.6115389342871294, 0.6505395783882206, 0.6010719361145394, 0.6201992295121656, 0.5474925340891813, 0.12496363056790527, 0.6172883917916766, 0.5800103510803774, 0.6178082965572207, 0.5198145289921565, 0.01669045686983861, 0.537493623059079, 0.5574622518931232, 0.583907273603204, 0.6325076991684645, 0.6040173477737164, 0.5772205189597104, 0.4477021493834583, 0.5951745198118525, 0.5751254750305228, 0.611168261060888, 0.6095156079537748, 0.5613895288278088, 0.653165236812457, 0.578010382898307, 0.5906344030858592, 0.5734038836895186, 0.6973248370362327, 0.6690598036518844, 0.6847305193213178, 0.7061685940428326, 0.7127427735436558, 0.6956403853904165, 0.7256654724870555, 0.6974935332756751, 0.6800657796012706, 0.26886888297261247, 0.2567298455899326, 0.1978498023786025, 0.4711096272090417, 0.4616923459558898, 0.33646622305502594, 0.3003209734846265, 0.2923859164690722, 0.2917522917795389, 0.4407450260626149, 0.47750354188731814, 0.44573651789588875, 0.46007102069606187, 0.4623265148506259, 0.4698450507558254, 0.4983374796651274, 0.4651038353049999, 0.4906097444919848, 0.7939959747146519, 0.7512639921384054, 0.8024278744310025, 0.7655647590715289, 0.7860141525136092, 0.7469872082840403, 0.7837308674550727, 0.7867152501597141, 0.7814435476452145, 0.10731152787756348, 0.11531064980216776, 0.13327898151509088, 0.0845459419935578, 0.1129017830272383, 0.10799288264697948, 0.09026607095640027, 0.09242354853904122, 0.11414610931447933, 0.14859750401177263, 0.16993161980945604, 0.21808791662555005, 0.17893340336430485, 0.20673396640031128, 0.17514927217005238, 0.21812932372262783, 0.1816380653821965, 0.1969196835645982, 0.4445529723727534, 0.42052418256371293, 0.4832803672599898, 0.434256993835186, 0.45321080811656955, 0.43851286281310375, 0.47433954584356, 0.44995204167902425, 0.4907650783321168, 0.36028806305334393, 0.3637094622146594, 0.2797815375835401, 0.339563147640781, 0.3282683863725553, 0.33629759002845827, 0.38231494403451727, 0.36727042862318426, 0.40476782964212854, 0.19355751934158139, 0.222651046201242, 0.20008507149009302, 0.24076494486116384, 0.1823909733253869, 0.23823667947716676, 0.18896336916398737, 0.1775488692840156, 0.19825657499372007, 0.31328935485711895, 0.24978833520335753, 0.5467031594247906, 0.22580931177013186, 0.3068491624219365, 0.20701222076673953, 0.20878834757163556, 0.26504852465161, 0.19381349682665883, 0.8488604691570416, 0.17137799400702514, 0.17022881054803018, 0.8712490731729117, 0.2056317133448773, 0.775756989121672, 0.16335836936746595, 0.17793760622496502, 0.8524947927571764, 0.8179025205290024, 0.7358647696051241, 0.8190914110923364, 0.201869625298709, 0.16556880117395845, 0.7141282873355854, 0.2071428842442561, 0.8635935380607013, 0.791471704067155, 0.18662858002296845, 0.186359167637123, 0.19667438813877036, 0.18593125007449574, 0.16702174357922817, 0.17072242613914146, 0.18406270829058735, 0.1883483385411402, 0.21088470591522512, 0.08556516989537444, 0.08019225669858099, 0.08286134945626689, 0.07496979065675446, 0.0850600782588915, 0.0735401347951864, 0.07636235899990385, 0.07709528013485212, 0.07326544861438689]}, "mutation_prompt": null}
{"id": "30e8dc12-4a77-455a-b165-618e2447b97f", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Refined Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover with enhanced probability adaptation\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.1))\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning with more granular adjustments\n            self.scale_factor = np.random.uniform(0.65, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.88, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with refined adaptive mutation and crossover strategies to improve convergence efficiency.", "configspace": "", "generation": 25, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "861cd3e5-fef8-4d90-a5d1-b5c310a7510e", "metadata": {"aucs": [0.822419785938898, 0.8199714546643329, 0.8414894141977063, 0.8430091771653526, 0.8593885836191024, 0.8487231796708052, 0.8367890364383294, 0.8302523382030463, 0.8293736847039304, 0.6900526707292051, 0.729827418174816, 0.7165636142714544, 0.7210593429287958, 0.7066488819727987, 0.73925793568504, 0.7290705693599189, 0.7228033402871135, 0.7062545396178945, 0.1276970958927961, 0.10836103147880471, 0.10584430366771846, 0.3699480834266704, 0.14078795992086013, 0.11173662417811558, 0.24405632789960074, 0.1979650359645696, 0.11807834733719214, 0.09487999780108625, 0.12368899362754915, 0.1075596948214832, 0.13173357002036357, 0.09980875650657273, 0.11640007866229085, 0.1278981270616787, 0.12028358906634584, 0.12155953374756501, 0.9267733553648255, 0.8780210526035417, 0.9728814299618388, 0.9627363618388612, 0.9068972901895733, 0.9753106988533982, 0.950121428753759, 0.9613290656568141, 0.9730778020274361, 0.6217127761634991, 0.5898663642757915, 0.6498912945803319, 0.5908153910909509, 0.6029460563973829, 0.601656570202229, 0.5726798590248927, 0.5981797797944681, 0.610924263252564, 0.8272794955422078, 0.7839572083705488, 0.8292962044243667, 0.8387891564677299, 0.8155388282714626, 0.8237694981028187, 0.8208478301223947, 0.8030835718841802, 0.8302702542657152, 0.6115389342871294, 0.6505395783882206, 0.6010719361145394, 0.6201992295121656, 0.5474925340891813, 0.12496363056790527, 0.6172883917916766, 0.5800103510803774, 0.6178082965572207, 0.5198145289921565, 0.01669045686983861, 0.537493623059079, 0.5574622518931232, 0.583907273603204, 0.6325076991684645, 0.6040173477737164, 0.5772205189597104, 0.4477021493834583, 0.5951745198118525, 0.5751254750305228, 0.611168261060888, 0.6095156079537748, 0.5613895288278088, 0.653165236812457, 0.578010382898307, 0.5906344030858592, 0.5734038836895186, 0.6973248370362327, 0.6690598036518844, 0.6847305193213178, 0.7061685940428326, 0.7127427735436558, 0.6956403853904165, 0.7256654724870555, 0.6974935332756751, 0.6800657796012706, 0.26886888297261247, 0.2567298455899326, 0.1978498023786025, 0.4711096272090417, 0.4616923459558898, 0.33646622305502594, 0.3003209734846265, 0.2923859164690722, 0.2917522917795389, 0.4407450260626149, 0.47750354188731814, 0.44573651789588875, 0.46007102069606187, 0.4623265148506259, 0.4698450507558254, 0.4983374796651274, 0.4651038353049999, 0.4906097444919848, 0.7939959747146519, 0.7512639921384054, 0.8024278744310025, 0.7655647590715289, 0.7860141525136092, 0.7469872082840403, 0.7837308674550727, 0.7867152501597141, 0.7814435476452145, 0.10731152787756348, 0.11531064980216776, 0.13327898151509088, 0.0845459419935578, 0.1129017830272383, 0.10799288264697948, 0.09026607095640027, 0.09242354853904122, 0.11414610931447933, 0.14859750401177263, 0.16993161980945604, 0.21808791662555005, 0.17893340336430485, 0.20673396640031128, 0.17514927217005238, 0.21812932372262783, 0.1816380653821965, 0.1969196835645982, 0.4445529723727534, 0.42052418256371293, 0.4832803672599898, 0.434256993835186, 0.45321080811656955, 0.43851286281310375, 0.47433954584356, 0.44995204167902425, 0.4907650783321168, 0.36028806305334393, 0.3637094622146594, 0.2797815375835401, 0.339563147640781, 0.3282683863725553, 0.33629759002845827, 0.38231494403451727, 0.36727042862318426, 0.40476782964212854, 0.19355751934158139, 0.222651046201242, 0.20008507149009302, 0.24076494486116384, 0.1823909733253869, 0.23823667947716676, 0.18896336916398737, 0.1775488692840156, 0.19825657499372007, 0.31328935485711895, 0.24978833520335753, 0.5467031594247906, 0.22580931177013186, 0.3068491624219365, 0.20701222076673953, 0.20878834757163556, 0.26504852465161, 0.19381349682665883, 0.8488604691570416, 0.17137799400702514, 0.17022881054803018, 0.8712490731729117, 0.2056317133448773, 0.775756989121672, 0.16335836936746595, 0.17793760622496502, 0.8524947927571764, 0.8179025205290024, 0.7358647696051241, 0.8190914110923364, 0.201869625298709, 0.16556880117395845, 0.7141282873355854, 0.2071428842442561, 0.8635935380607013, 0.791471704067155, 0.18662858002296845, 0.186359167637123, 0.19667438813877036, 0.18593125007449574, 0.16702174357922817, 0.17072242613914146, 0.18406270829058735, 0.1883483385411402, 0.21088470591522512, 0.08556516989537444, 0.08019225669858099, 0.08286134945626689, 0.07496979065675446, 0.0850600782588915, 0.0735401347951864, 0.07636235899990385, 0.07709528013485212, 0.07326544861438689]}, "mutation_prompt": null}
{"id": "2f3aaeff-f7e7-4202-b541-f1ec941ec760", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Refined Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover with enhanced probability adaptation\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.1))\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning with more granular adjustments\n            self.scale_factor = np.random.uniform(0.65, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.88, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with refined adaptive mutation and crossover strategies to improve convergence efficiency.", "configspace": "", "generation": 25, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "861cd3e5-fef8-4d90-a5d1-b5c310a7510e", "metadata": {"aucs": [0.822419785938898, 0.8199714546643329, 0.8414894141977063, 0.8430091771653526, 0.8593885836191024, 0.8487231796708052, 0.8367890364383294, 0.8302523382030463, 0.8293736847039304, 0.6900526707292051, 0.729827418174816, 0.7165636142714544, 0.7210593429287958, 0.7066488819727987, 0.73925793568504, 0.7290705693599189, 0.7228033402871135, 0.7062545396178945, 0.1276970958927961, 0.10836103147880471, 0.10584430366771846, 0.3699480834266704, 0.14078795992086013, 0.11173662417811558, 0.24405632789960074, 0.1979650359645696, 0.11807834733719214, 0.09487999780108625, 0.12368899362754915, 0.1075596948214832, 0.13173357002036357, 0.09980875650657273, 0.11640007866229085, 0.1278981270616787, 0.12028358906634584, 0.12155953374756501, 0.9267733553648255, 0.8780210526035417, 0.9728814299618388, 0.9627363618388612, 0.9068972901895733, 0.9753106988533982, 0.950121428753759, 0.9613290656568141, 0.9730778020274361, 0.6217127761634991, 0.5898663642757915, 0.6498912945803319, 0.5908153910909509, 0.6029460563973829, 0.601656570202229, 0.5726798590248927, 0.5981797797944681, 0.610924263252564, 0.8272794955422078, 0.7839572083705488, 0.8292962044243667, 0.8387891564677299, 0.8155388282714626, 0.8237694981028187, 0.8208478301223947, 0.8030835718841802, 0.8302702542657152, 0.6115389342871294, 0.6505395783882206, 0.6010719361145394, 0.6201992295121656, 0.5474925340891813, 0.12496363056790527, 0.6172883917916766, 0.5800103510803774, 0.6178082965572207, 0.5198145289921565, 0.01669045686983861, 0.537493623059079, 0.5574622518931232, 0.583907273603204, 0.6325076991684645, 0.6040173477737164, 0.5772205189597104, 0.4477021493834583, 0.5951745198118525, 0.5751254750305228, 0.611168261060888, 0.6095156079537748, 0.5613895288278088, 0.653165236812457, 0.578010382898307, 0.5906344030858592, 0.5734038836895186, 0.6973248370362327, 0.6690598036518844, 0.6847305193213178, 0.7061685940428326, 0.7127427735436558, 0.6956403853904165, 0.7256654724870555, 0.6974935332756751, 0.6800657796012706, 0.26886888297261247, 0.2567298455899326, 0.1978498023786025, 0.4711096272090417, 0.4616923459558898, 0.33646622305502594, 0.3003209734846265, 0.2923859164690722, 0.2917522917795389, 0.4407450260626149, 0.47750354188731814, 0.44573651789588875, 0.46007102069606187, 0.4623265148506259, 0.4698450507558254, 0.4983374796651274, 0.4651038353049999, 0.4906097444919848, 0.7939959747146519, 0.7512639921384054, 0.8024278744310025, 0.7655647590715289, 0.7860141525136092, 0.7469872082840403, 0.7837308674550727, 0.7867152501597141, 0.7814435476452145, 0.10731152787756348, 0.11531064980216776, 0.13327898151509088, 0.0845459419935578, 0.1129017830272383, 0.10799288264697948, 0.09026607095640027, 0.09242354853904122, 0.11414610931447933, 0.14859750401177263, 0.16993161980945604, 0.21808791662555005, 0.17893340336430485, 0.20673396640031128, 0.17514927217005238, 0.21812932372262783, 0.1816380653821965, 0.1969196835645982, 0.4445529723727534, 0.42052418256371293, 0.4832803672599898, 0.434256993835186, 0.45321080811656955, 0.43851286281310375, 0.47433954584356, 0.44995204167902425, 0.4907650783321168, 0.36028806305334393, 0.3637094622146594, 0.2797815375835401, 0.339563147640781, 0.3282683863725553, 0.33629759002845827, 0.38231494403451727, 0.36727042862318426, 0.40476782964212854, 0.19355751934158139, 0.222651046201242, 0.20008507149009302, 0.24076494486116384, 0.1823909733253869, 0.23823667947716676, 0.18896336916398737, 0.1775488692840156, 0.19825657499372007, 0.31328935485711895, 0.24978833520335753, 0.5467031594247906, 0.22580931177013186, 0.3068491624219365, 0.20701222076673953, 0.20878834757163556, 0.26504852465161, 0.19381349682665883, 0.8488604691570416, 0.17137799400702514, 0.17022881054803018, 0.8712490731729117, 0.2056317133448773, 0.775756989121672, 0.16335836936746595, 0.17793760622496502, 0.8524947927571764, 0.8179025205290024, 0.7358647696051241, 0.8190914110923364, 0.201869625298709, 0.16556880117395845, 0.7141282873355854, 0.2071428842442561, 0.8635935380607013, 0.791471704067155, 0.18662858002296845, 0.186359167637123, 0.19667438813877036, 0.18593125007449574, 0.16702174357922817, 0.17072242613914146, 0.18406270829058735, 0.1883483385411402, 0.21088470591522512, 0.08556516989537444, 0.08019225669858099, 0.08286134945626689, 0.07496979065675446, 0.0850600782588915, 0.0735401347951864, 0.07636235899990385, 0.07709528013485212, 0.07326544861438689]}, "mutation_prompt": null}
{"id": "49ee5cc6-ee91-4bfe-8ad7-89a6f0714145", "solution": "import numpy as np\n\nclass RefinedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.75\n        self.cross_prob = 0.85\n        self.adaptation_rate = 0.07  # Adjusted adaptation rate\n        self.population_size = self.initial_population_size\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        stagnation_counter = 0\n        \n        while func_evals < self.budget:\n            if stagnation_counter > 5:  # Adaptive population resizing\n                new_individuals = np.random.uniform(self.bounds[0], self.bounds[1], (2, self.dim))\n                population = np.vstack((population, new_individuals))\n                fitness = np.append(fitness, [func(ind) for ind in new_individuals])\n                func_evals += 2\n                self.population_size += 2\n                stagnation_counter = 0\n            \n            prev_best_fitness = np.min(fitness)\n            \n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Refined Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover with enhanced probability adaptation\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.1))\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Check for convergence stagnation\n            current_best_fitness = np.min(fitness)\n            if np.isclose(current_best_fitness, prev_best_fitness, rtol=1e-4):\n                stagnation_counter += 1\n            else:\n                stagnation_counter = 0\n\n            # Self-adaptive parameter tuning with more granular adjustments\n            self.scale_factor = np.random.uniform(0.7, 0.8)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.83, 0.9)   # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "RefinedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer with adaptive population sizing and enhanced feedback mechanisms for accelerated convergence.", "configspace": "", "generation": 45, "fitness": 0.3241830692912234, "feedback": "The algorithm RefinedHybridEvolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.25.", "error": "", "parent_id": "861cd3e5-fef8-4d90-a5d1-b5c310a7510e", "metadata": {"aucs": [0.775458944085444, 0.752348799800437, 0.8262137489445383, 0.7815295554063224, 0.7712054019067572, 0.7644239102602859, 0.7988821378944, 0.805433906997099, 0.7645257526956416, 0.6533410747477126, 0.6333769739560148, 0.6313522904883879, 0.6393295445255196, 0.6483135479401104, 0.6079350152064849, 0.5942926636699517, 0.649623102943657, 0.6348627005832301, 0.11335107309709924, 0.11438974145126268, 0.095784152685359, 0.10386868712673547, 0.10218946922218197, 0.09246201364115236, 0.11181939536363694, 0.10849451417794065, 0.13235739731717644, 0.08987266217001255, 0.09338582558711606, 0.09543228729882869, 0.08925896068139627, 0.10509376925776615, 0.10258012928229143, 0.10594872943043154, 0.08991615935299324, 0.10606098954336829, 0.9679784930582417, 0.9651934735455825, 0.9425936099950097, 0.9820266711103264, 0.9356760707770252, 0.9852083335818689, 0.9598419152333285, 0.9662153178051082, 0.9823741280247739, 0.43764778106859825, 0.4158473450775453, 0.3796687199693568, 0.4240153045295386, 0.42697199141073183, 0.34163613817564287, 0.37939476998162713, 0.39264973834700945, 0.40316903337211163, 0.6373431573029464, 0.6655136361238955, 0.5438726725141713, 0.7371946793729642, 0.7437706773964565, 0.7838644480290627, 0.6541651567189302, 0.6301795874709524, 0.7695500080440676, 0.22384228332991063, 0.2788496063962659, 0.24569780952072529, 0.3201531935137776, 0.29150876665812986, 0.23655326646432617, 0.2957867438030123, 0.32766324046660367, 0.3179201292360373, 0.11928831355395086, 0.25307226289690066, 0.32966559529183537, 0.30272615074109166, 0.3186094718486733, 0.28627474300520317, 0.30678548952343054, 0.3042406892753544, 0.2767588130110141, 0.1768575480302177, 0.19139443224442676, 0.10938218952644019, 0.24203541183122912, 0.21789452262229836, 0.19823097736206896, 0.18289831784170696, 0.21137614006986782, 0.18511055325715065, 0.2778386485105925, 0.2656851227227658, 0.2849776223562607, 0.3051536156616088, 0.18987094711434538, 0.286434845486077, 0.31957927652487794, 0.333084344821181, 0.3323665290030029, 0.07693531027989697, 0.0631954702124704, 0.1115038671099714, 0.051860165047584283, 0.10535209368383236, 0.03159049369927358, 0.04488375907578479, 0.11323970614152568, 0.07124080012487644, 0.1692014498517057, 0.1849180395794231, 0.21750801697474487, 0.24620553271592038, 0.2563902798820834, 0.2394865305109023, 0.19703635121228635, 0.20656163400933292, 0.17981667807541268, 0.5670525479803084, 0.5542088882658098, 0.5541771143416205, 0.5802257986126275, 0.5664673990949325, 0.5838441117002895, 0.5906949807205544, 0.5735711233827883, 0.6131446729529515, 0.07563903637006064, 0.08395028874621968, 0.1020319471513822, 0.0842421230105238, 0.07987759526617078, 0.08994859750308082, 0.0859767666361384, 0.09800694889785211, 0.08983992378774253, 0.13041213761873405, 0.15520066041771674, 0.15170851665853025, 0.137891878796914, 0.14255901689567485, 0.16218155166430748, 0.17131519512588889, 0.1751897210351302, 0.15389275121060364, 0.2999433376742766, 0.31984865773453264, 0.3059707616976307, 0.3193067506577356, 0.32379346743876947, 0.2927516624360206, 0.33404469890921173, 0.35024751530625964, 0.3567481105606788, 0.24535118404149425, 0.22244693109442948, 0.22336514929187712, 0.23425574159137574, 0.2510621475588337, 0.23259697131315704, 0.25285985117059584, 0.23750562776414263, 0.2571512535249646, 0.1896879341479838, 0.1737567624752785, 0.16659190475200758, 0.1851508288118492, 0.1818725580505849, 0.1806971156349142, 0.18097475348346437, 0.19649451537247986, 0.17753390309073547, 0.17998853860069086, 0.18210046928011914, 0.17820983764731113, 0.18604801796965187, 0.17372027460940576, 0.19212303818954612, 0.1905212878367203, 0.18531209625162115, 0.1744903007804176, 0.7823973127628644, 0.1818794052467525, 0.7901509260138642, 0.7433583899087346, 0.5684900478130368, 0.18279967575874156, 0.5492124624650567, 0.20144761025233515, 0.20447883299423408, 0.6652179890460679, 0.19589958185736345, 0.20375587472621126, 0.1962624730323651, 0.44106917527071043, 0.16529081477716923, 0.20620287524370107, 0.5656974731131243, 0.2076071757948409, 0.1800486354386467, 0.18470978578135477, 0.18823217346649235, 0.20160944162924077, 0.17939758741368772, 0.1770755771840743, 0.18151955359077943, 0.18130669946429667, 0.17701238106307682, 0.07112553412866796, 0.07623800979181417, 0.07039658798636572, 0.08356998672077698, 0.08980018551773261, 0.07311391033572778, 0.07581187037283199, 0.07182072935631201, 0.07098929250488017]}, "mutation_prompt": null}
{"id": "3b441172-d3c4-4ada-b64a-358694e80069", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Refined Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover with enhanced probability adaptation\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.1))\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning with more granular adjustments\n            self.scale_factor = np.random.uniform(0.65, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.88, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with refined adaptive mutation and crossover strategies to improve convergence efficiency.", "configspace": "", "generation": 25, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "861cd3e5-fef8-4d90-a5d1-b5c310a7510e", "metadata": {"aucs": [0.822419785938898, 0.8199714546643329, 0.8414894141977063, 0.8430091771653526, 0.8593885836191024, 0.8487231796708052, 0.8367890364383294, 0.8302523382030463, 0.8293736847039304, 0.6900526707292051, 0.729827418174816, 0.7165636142714544, 0.7210593429287958, 0.7066488819727987, 0.73925793568504, 0.7290705693599189, 0.7228033402871135, 0.7062545396178945, 0.1276970958927961, 0.10836103147880471, 0.10584430366771846, 0.3699480834266704, 0.14078795992086013, 0.11173662417811558, 0.24405632789960074, 0.1979650359645696, 0.11807834733719214, 0.09487999780108625, 0.12368899362754915, 0.1075596948214832, 0.13173357002036357, 0.09980875650657273, 0.11640007866229085, 0.1278981270616787, 0.12028358906634584, 0.12155953374756501, 0.9267733553648255, 0.8780210526035417, 0.9728814299618388, 0.9627363618388612, 0.9068972901895733, 0.9753106988533982, 0.950121428753759, 0.9613290656568141, 0.9730778020274361, 0.6217127761634991, 0.5898663642757915, 0.6498912945803319, 0.5908153910909509, 0.6029460563973829, 0.601656570202229, 0.5726798590248927, 0.5981797797944681, 0.610924263252564, 0.8272794955422078, 0.7839572083705488, 0.8292962044243667, 0.8387891564677299, 0.8155388282714626, 0.8237694981028187, 0.8208478301223947, 0.8030835718841802, 0.8302702542657152, 0.6115389342871294, 0.6505395783882206, 0.6010719361145394, 0.6201992295121656, 0.5474925340891813, 0.12496363056790527, 0.6172883917916766, 0.5800103510803774, 0.6178082965572207, 0.5198145289921565, 0.01669045686983861, 0.537493623059079, 0.5574622518931232, 0.583907273603204, 0.6325076991684645, 0.6040173477737164, 0.5772205189597104, 0.4477021493834583, 0.5951745198118525, 0.5751254750305228, 0.611168261060888, 0.6095156079537748, 0.5613895288278088, 0.653165236812457, 0.578010382898307, 0.5906344030858592, 0.5734038836895186, 0.6973248370362327, 0.6690598036518844, 0.6847305193213178, 0.7061685940428326, 0.7127427735436558, 0.6956403853904165, 0.7256654724870555, 0.6974935332756751, 0.6800657796012706, 0.26886888297261247, 0.2567298455899326, 0.1978498023786025, 0.4711096272090417, 0.4616923459558898, 0.33646622305502594, 0.3003209734846265, 0.2923859164690722, 0.2917522917795389, 0.4407450260626149, 0.47750354188731814, 0.44573651789588875, 0.46007102069606187, 0.4623265148506259, 0.4698450507558254, 0.4983374796651274, 0.4651038353049999, 0.4906097444919848, 0.7939959747146519, 0.7512639921384054, 0.8024278744310025, 0.7655647590715289, 0.7860141525136092, 0.7469872082840403, 0.7837308674550727, 0.7867152501597141, 0.7814435476452145, 0.10731152787756348, 0.11531064980216776, 0.13327898151509088, 0.0845459419935578, 0.1129017830272383, 0.10799288264697948, 0.09026607095640027, 0.09242354853904122, 0.11414610931447933, 0.14859750401177263, 0.16993161980945604, 0.21808791662555005, 0.17893340336430485, 0.20673396640031128, 0.17514927217005238, 0.21812932372262783, 0.1816380653821965, 0.1969196835645982, 0.4445529723727534, 0.42052418256371293, 0.4832803672599898, 0.434256993835186, 0.45321080811656955, 0.43851286281310375, 0.47433954584356, 0.44995204167902425, 0.4907650783321168, 0.36028806305334393, 0.3637094622146594, 0.2797815375835401, 0.339563147640781, 0.3282683863725553, 0.33629759002845827, 0.38231494403451727, 0.36727042862318426, 0.40476782964212854, 0.19355751934158139, 0.222651046201242, 0.20008507149009302, 0.24076494486116384, 0.1823909733253869, 0.23823667947716676, 0.18896336916398737, 0.1775488692840156, 0.19825657499372007, 0.31328935485711895, 0.24978833520335753, 0.5467031594247906, 0.22580931177013186, 0.3068491624219365, 0.20701222076673953, 0.20878834757163556, 0.26504852465161, 0.19381349682665883, 0.8488604691570416, 0.17137799400702514, 0.17022881054803018, 0.8712490731729117, 0.2056317133448773, 0.775756989121672, 0.16335836936746595, 0.17793760622496502, 0.8524947927571764, 0.8179025205290024, 0.7358647696051241, 0.8190914110923364, 0.201869625298709, 0.16556880117395845, 0.7141282873355854, 0.2071428842442561, 0.8635935380607013, 0.791471704067155, 0.18662858002296845, 0.186359167637123, 0.19667438813877036, 0.18593125007449574, 0.16702174357922817, 0.17072242613914146, 0.18406270829058735, 0.1883483385411402, 0.21088470591522512, 0.08556516989537444, 0.08019225669858099, 0.08286134945626689, 0.07496979065675446, 0.0850600782588915, 0.0735401347951864, 0.07636235899990385, 0.07709528013485212, 0.07326544861438689]}, "mutation_prompt": null}
{"id": "2bfaef24-9088-4552-b9e8-32f603c16153", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Refined Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover with enhanced probability adaptation\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.1))\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning with more granular adjustments\n            self.scale_factor = np.random.uniform(0.65, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.88, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with refined adaptive mutation and crossover strategies to improve convergence efficiency.", "configspace": "", "generation": 25, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "861cd3e5-fef8-4d90-a5d1-b5c310a7510e", "metadata": {"aucs": [0.822419785938898, 0.8199714546643329, 0.8414894141977063, 0.8430091771653526, 0.8593885836191024, 0.8487231796708052, 0.8367890364383294, 0.8302523382030463, 0.8293736847039304, 0.6900526707292051, 0.729827418174816, 0.7165636142714544, 0.7210593429287958, 0.7066488819727987, 0.73925793568504, 0.7290705693599189, 0.7228033402871135, 0.7062545396178945, 0.1276970958927961, 0.10836103147880471, 0.10584430366771846, 0.3699480834266704, 0.14078795992086013, 0.11173662417811558, 0.24405632789960074, 0.1979650359645696, 0.11807834733719214, 0.09487999780108625, 0.12368899362754915, 0.1075596948214832, 0.13173357002036357, 0.09980875650657273, 0.11640007866229085, 0.1278981270616787, 0.12028358906634584, 0.12155953374756501, 0.9267733553648255, 0.8780210526035417, 0.9728814299618388, 0.9627363618388612, 0.9068972901895733, 0.9753106988533982, 0.950121428753759, 0.9613290656568141, 0.9730778020274361, 0.6217127761634991, 0.5898663642757915, 0.6498912945803319, 0.5908153910909509, 0.6029460563973829, 0.601656570202229, 0.5726798590248927, 0.5981797797944681, 0.610924263252564, 0.8272794955422078, 0.7839572083705488, 0.8292962044243667, 0.8387891564677299, 0.8155388282714626, 0.8237694981028187, 0.8208478301223947, 0.8030835718841802, 0.8302702542657152, 0.6115389342871294, 0.6505395783882206, 0.6010719361145394, 0.6201992295121656, 0.5474925340891813, 0.12496363056790527, 0.6172883917916766, 0.5800103510803774, 0.6178082965572207, 0.5198145289921565, 0.01669045686983861, 0.537493623059079, 0.5574622518931232, 0.583907273603204, 0.6325076991684645, 0.6040173477737164, 0.5772205189597104, 0.4477021493834583, 0.5951745198118525, 0.5751254750305228, 0.611168261060888, 0.6095156079537748, 0.5613895288278088, 0.653165236812457, 0.578010382898307, 0.5906344030858592, 0.5734038836895186, 0.6973248370362327, 0.6690598036518844, 0.6847305193213178, 0.7061685940428326, 0.7127427735436558, 0.6956403853904165, 0.7256654724870555, 0.6974935332756751, 0.6800657796012706, 0.26886888297261247, 0.2567298455899326, 0.1978498023786025, 0.4711096272090417, 0.4616923459558898, 0.33646622305502594, 0.3003209734846265, 0.2923859164690722, 0.2917522917795389, 0.4407450260626149, 0.47750354188731814, 0.44573651789588875, 0.46007102069606187, 0.4623265148506259, 0.4698450507558254, 0.4983374796651274, 0.4651038353049999, 0.4906097444919848, 0.7939959747146519, 0.7512639921384054, 0.8024278744310025, 0.7655647590715289, 0.7860141525136092, 0.7469872082840403, 0.7837308674550727, 0.7867152501597141, 0.7814435476452145, 0.10731152787756348, 0.11531064980216776, 0.13327898151509088, 0.0845459419935578, 0.1129017830272383, 0.10799288264697948, 0.09026607095640027, 0.09242354853904122, 0.11414610931447933, 0.14859750401177263, 0.16993161980945604, 0.21808791662555005, 0.17893340336430485, 0.20673396640031128, 0.17514927217005238, 0.21812932372262783, 0.1816380653821965, 0.1969196835645982, 0.4445529723727534, 0.42052418256371293, 0.4832803672599898, 0.434256993835186, 0.45321080811656955, 0.43851286281310375, 0.47433954584356, 0.44995204167902425, 0.4907650783321168, 0.36028806305334393, 0.3637094622146594, 0.2797815375835401, 0.339563147640781, 0.3282683863725553, 0.33629759002845827, 0.38231494403451727, 0.36727042862318426, 0.40476782964212854, 0.19355751934158139, 0.222651046201242, 0.20008507149009302, 0.24076494486116384, 0.1823909733253869, 0.23823667947716676, 0.18896336916398737, 0.1775488692840156, 0.19825657499372007, 0.31328935485711895, 0.24978833520335753, 0.5467031594247906, 0.22580931177013186, 0.3068491624219365, 0.20701222076673953, 0.20878834757163556, 0.26504852465161, 0.19381349682665883, 0.8488604691570416, 0.17137799400702514, 0.17022881054803018, 0.8712490731729117, 0.2056317133448773, 0.775756989121672, 0.16335836936746595, 0.17793760622496502, 0.8524947927571764, 0.8179025205290024, 0.7358647696051241, 0.8190914110923364, 0.201869625298709, 0.16556880117395845, 0.7141282873355854, 0.2071428842442561, 0.8635935380607013, 0.791471704067155, 0.18662858002296845, 0.186359167637123, 0.19667438813877036, 0.18593125007449574, 0.16702174357922817, 0.17072242613914146, 0.18406270829058735, 0.1883483385411402, 0.21088470591522512, 0.08556516989537444, 0.08019225669858099, 0.08286134945626689, 0.07496979065675446, 0.0850600782588915, 0.0735401347951864, 0.07636235899990385, 0.07709528013485212, 0.07326544861438689]}, "mutation_prompt": null}
{"id": "f06037bc-ac1a-4597-af70-3b0fa75cda1a", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Refined Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover with enhanced probability adaptation\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.1))\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning with more granular adjustments\n            self.scale_factor = np.random.uniform(0.65, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.88, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with refined adaptive mutation and crossover strategies to improve convergence efficiency.", "configspace": "", "generation": 25, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "861cd3e5-fef8-4d90-a5d1-b5c310a7510e", "metadata": {"aucs": [0.822419785938898, 0.8199714546643329, 0.8414894141977063, 0.8430091771653526, 0.8593885836191024, 0.8487231796708052, 0.8367890364383294, 0.8302523382030463, 0.8293736847039304, 0.6900526707292051, 0.729827418174816, 0.7165636142714544, 0.7210593429287958, 0.7066488819727987, 0.73925793568504, 0.7290705693599189, 0.7228033402871135, 0.7062545396178945, 0.1276970958927961, 0.10836103147880471, 0.10584430366771846, 0.3699480834266704, 0.14078795992086013, 0.11173662417811558, 0.24405632789960074, 0.1979650359645696, 0.11807834733719214, 0.09487999780108625, 0.12368899362754915, 0.1075596948214832, 0.13173357002036357, 0.09980875650657273, 0.11640007866229085, 0.1278981270616787, 0.12028358906634584, 0.12155953374756501, 0.9267733553648255, 0.8780210526035417, 0.9728814299618388, 0.9627363618388612, 0.9068972901895733, 0.9753106988533982, 0.950121428753759, 0.9613290656568141, 0.9730778020274361, 0.6217127761634991, 0.5898663642757915, 0.6498912945803319, 0.5908153910909509, 0.6029460563973829, 0.601656570202229, 0.5726798590248927, 0.5981797797944681, 0.610924263252564, 0.8272794955422078, 0.7839572083705488, 0.8292962044243667, 0.8387891564677299, 0.8155388282714626, 0.8237694981028187, 0.8208478301223947, 0.8030835718841802, 0.8302702542657152, 0.6115389342871294, 0.6505395783882206, 0.6010719361145394, 0.6201992295121656, 0.5474925340891813, 0.12496363056790527, 0.6172883917916766, 0.5800103510803774, 0.6178082965572207, 0.5198145289921565, 0.01669045686983861, 0.537493623059079, 0.5574622518931232, 0.583907273603204, 0.6325076991684645, 0.6040173477737164, 0.5772205189597104, 0.4477021493834583, 0.5951745198118525, 0.5751254750305228, 0.611168261060888, 0.6095156079537748, 0.5613895288278088, 0.653165236812457, 0.578010382898307, 0.5906344030858592, 0.5734038836895186, 0.6973248370362327, 0.6690598036518844, 0.6847305193213178, 0.7061685940428326, 0.7127427735436558, 0.6956403853904165, 0.7256654724870555, 0.6974935332756751, 0.6800657796012706, 0.26886888297261247, 0.2567298455899326, 0.1978498023786025, 0.4711096272090417, 0.4616923459558898, 0.33646622305502594, 0.3003209734846265, 0.2923859164690722, 0.2917522917795389, 0.4407450260626149, 0.47750354188731814, 0.44573651789588875, 0.46007102069606187, 0.4623265148506259, 0.4698450507558254, 0.4983374796651274, 0.4651038353049999, 0.4906097444919848, 0.7939959747146519, 0.7512639921384054, 0.8024278744310025, 0.7655647590715289, 0.7860141525136092, 0.7469872082840403, 0.7837308674550727, 0.7867152501597141, 0.7814435476452145, 0.10731152787756348, 0.11531064980216776, 0.13327898151509088, 0.0845459419935578, 0.1129017830272383, 0.10799288264697948, 0.09026607095640027, 0.09242354853904122, 0.11414610931447933, 0.14859750401177263, 0.16993161980945604, 0.21808791662555005, 0.17893340336430485, 0.20673396640031128, 0.17514927217005238, 0.21812932372262783, 0.1816380653821965, 0.1969196835645982, 0.4445529723727534, 0.42052418256371293, 0.4832803672599898, 0.434256993835186, 0.45321080811656955, 0.43851286281310375, 0.47433954584356, 0.44995204167902425, 0.4907650783321168, 0.36028806305334393, 0.3637094622146594, 0.2797815375835401, 0.339563147640781, 0.3282683863725553, 0.33629759002845827, 0.38231494403451727, 0.36727042862318426, 0.40476782964212854, 0.19355751934158139, 0.222651046201242, 0.20008507149009302, 0.24076494486116384, 0.1823909733253869, 0.23823667947716676, 0.18896336916398737, 0.1775488692840156, 0.19825657499372007, 0.31328935485711895, 0.24978833520335753, 0.5467031594247906, 0.22580931177013186, 0.3068491624219365, 0.20701222076673953, 0.20878834757163556, 0.26504852465161, 0.19381349682665883, 0.8488604691570416, 0.17137799400702514, 0.17022881054803018, 0.8712490731729117, 0.2056317133448773, 0.775756989121672, 0.16335836936746595, 0.17793760622496502, 0.8524947927571764, 0.8179025205290024, 0.7358647696051241, 0.8190914110923364, 0.201869625298709, 0.16556880117395845, 0.7141282873355854, 0.2071428842442561, 0.8635935380607013, 0.791471704067155, 0.18662858002296845, 0.186359167637123, 0.19667438813877036, 0.18593125007449574, 0.16702174357922817, 0.17072242613914146, 0.18406270829058735, 0.1883483385411402, 0.21088470591522512, 0.08556516989537444, 0.08019225669858099, 0.08286134945626689, 0.07496979065675446, 0.0850600782588915, 0.0735401347951864, 0.07636235899990385, 0.07709528013485212, 0.07326544861438689]}, "mutation_prompt": null}
{"id": "cbc52bb2-174b-4ecc-b83b-3308e8316413", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Refined Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover with enhanced probability adaptation\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.1))\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning with more granular adjustments\n            self.scale_factor = np.random.uniform(0.65, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.88, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with refined adaptive mutation and crossover strategies to improve convergence efficiency.", "configspace": "", "generation": 25, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "861cd3e5-fef8-4d90-a5d1-b5c310a7510e", "metadata": {"aucs": [0.822419785938898, 0.8199714546643329, 0.8414894141977063, 0.8430091771653526, 0.8593885836191024, 0.8487231796708052, 0.8367890364383294, 0.8302523382030463, 0.8293736847039304, 0.6900526707292051, 0.729827418174816, 0.7165636142714544, 0.7210593429287958, 0.7066488819727987, 0.73925793568504, 0.7290705693599189, 0.7228033402871135, 0.7062545396178945, 0.1276970958927961, 0.10836103147880471, 0.10584430366771846, 0.3699480834266704, 0.14078795992086013, 0.11173662417811558, 0.24405632789960074, 0.1979650359645696, 0.11807834733719214, 0.09487999780108625, 0.12368899362754915, 0.1075596948214832, 0.13173357002036357, 0.09980875650657273, 0.11640007866229085, 0.1278981270616787, 0.12028358906634584, 0.12155953374756501, 0.9267733553648255, 0.8780210526035417, 0.9728814299618388, 0.9627363618388612, 0.9068972901895733, 0.9753106988533982, 0.950121428753759, 0.9613290656568141, 0.9730778020274361, 0.6217127761634991, 0.5898663642757915, 0.6498912945803319, 0.5908153910909509, 0.6029460563973829, 0.601656570202229, 0.5726798590248927, 0.5981797797944681, 0.610924263252564, 0.8272794955422078, 0.7839572083705488, 0.8292962044243667, 0.8387891564677299, 0.8155388282714626, 0.8237694981028187, 0.8208478301223947, 0.8030835718841802, 0.8302702542657152, 0.6115389342871294, 0.6505395783882206, 0.6010719361145394, 0.6201992295121656, 0.5474925340891813, 0.12496363056790527, 0.6172883917916766, 0.5800103510803774, 0.6178082965572207, 0.5198145289921565, 0.01669045686983861, 0.537493623059079, 0.5574622518931232, 0.583907273603204, 0.6325076991684645, 0.6040173477737164, 0.5772205189597104, 0.4477021493834583, 0.5951745198118525, 0.5751254750305228, 0.611168261060888, 0.6095156079537748, 0.5613895288278088, 0.653165236812457, 0.578010382898307, 0.5906344030858592, 0.5734038836895186, 0.6973248370362327, 0.6690598036518844, 0.6847305193213178, 0.7061685940428326, 0.7127427735436558, 0.6956403853904165, 0.7256654724870555, 0.6974935332756751, 0.6800657796012706, 0.26886888297261247, 0.2567298455899326, 0.1978498023786025, 0.4711096272090417, 0.4616923459558898, 0.33646622305502594, 0.3003209734846265, 0.2923859164690722, 0.2917522917795389, 0.4407450260626149, 0.47750354188731814, 0.44573651789588875, 0.46007102069606187, 0.4623265148506259, 0.4698450507558254, 0.4983374796651274, 0.4651038353049999, 0.4906097444919848, 0.7939959747146519, 0.7512639921384054, 0.8024278744310025, 0.7655647590715289, 0.7860141525136092, 0.7469872082840403, 0.7837308674550727, 0.7867152501597141, 0.7814435476452145, 0.10731152787756348, 0.11531064980216776, 0.13327898151509088, 0.0845459419935578, 0.1129017830272383, 0.10799288264697948, 0.09026607095640027, 0.09242354853904122, 0.11414610931447933, 0.14859750401177263, 0.16993161980945604, 0.21808791662555005, 0.17893340336430485, 0.20673396640031128, 0.17514927217005238, 0.21812932372262783, 0.1816380653821965, 0.1969196835645982, 0.4445529723727534, 0.42052418256371293, 0.4832803672599898, 0.434256993835186, 0.45321080811656955, 0.43851286281310375, 0.47433954584356, 0.44995204167902425, 0.4907650783321168, 0.36028806305334393, 0.3637094622146594, 0.2797815375835401, 0.339563147640781, 0.3282683863725553, 0.33629759002845827, 0.38231494403451727, 0.36727042862318426, 0.40476782964212854, 0.19355751934158139, 0.222651046201242, 0.20008507149009302, 0.24076494486116384, 0.1823909733253869, 0.23823667947716676, 0.18896336916398737, 0.1775488692840156, 0.19825657499372007, 0.31328935485711895, 0.24978833520335753, 0.5467031594247906, 0.22580931177013186, 0.3068491624219365, 0.20701222076673953, 0.20878834757163556, 0.26504852465161, 0.19381349682665883, 0.8488604691570416, 0.17137799400702514, 0.17022881054803018, 0.8712490731729117, 0.2056317133448773, 0.775756989121672, 0.16335836936746595, 0.17793760622496502, 0.8524947927571764, 0.8179025205290024, 0.7358647696051241, 0.8190914110923364, 0.201869625298709, 0.16556880117395845, 0.7141282873355854, 0.2071428842442561, 0.8635935380607013, 0.791471704067155, 0.18662858002296845, 0.186359167637123, 0.19667438813877036, 0.18593125007449574, 0.16702174357922817, 0.17072242613914146, 0.18406270829058735, 0.1883483385411402, 0.21088470591522512, 0.08556516989537444, 0.08019225669858099, 0.08286134945626689, 0.07496979065675446, 0.0850600782588915, 0.0735401347951864, 0.07636235899990385, 0.07709528013485212, 0.07326544861438689]}, "mutation_prompt": null}
{"id": "8208fe86-02e4-48f6-a1ea-2ec11cb7472d", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Refined Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover with enhanced probability adaptation\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.1))\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning with more granular adjustments\n            self.scale_factor = np.random.uniform(0.65, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.88, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with refined adaptive mutation and crossover strategies to improve convergence efficiency.", "configspace": "", "generation": 25, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "861cd3e5-fef8-4d90-a5d1-b5c310a7510e", "metadata": {"aucs": [0.822419785938898, 0.8199714546643329, 0.8414894141977063, 0.8430091771653526, 0.8593885836191024, 0.8487231796708052, 0.8367890364383294, 0.8302523382030463, 0.8293736847039304, 0.6900526707292051, 0.729827418174816, 0.7165636142714544, 0.7210593429287958, 0.7066488819727987, 0.73925793568504, 0.7290705693599189, 0.7228033402871135, 0.7062545396178945, 0.1276970958927961, 0.10836103147880471, 0.10584430366771846, 0.3699480834266704, 0.14078795992086013, 0.11173662417811558, 0.24405632789960074, 0.1979650359645696, 0.11807834733719214, 0.09487999780108625, 0.12368899362754915, 0.1075596948214832, 0.13173357002036357, 0.09980875650657273, 0.11640007866229085, 0.1278981270616787, 0.12028358906634584, 0.12155953374756501, 0.9267733553648255, 0.8780210526035417, 0.9728814299618388, 0.9627363618388612, 0.9068972901895733, 0.9753106988533982, 0.950121428753759, 0.9613290656568141, 0.9730778020274361, 0.6217127761634991, 0.5898663642757915, 0.6498912945803319, 0.5908153910909509, 0.6029460563973829, 0.601656570202229, 0.5726798590248927, 0.5981797797944681, 0.610924263252564, 0.8272794955422078, 0.7839572083705488, 0.8292962044243667, 0.8387891564677299, 0.8155388282714626, 0.8237694981028187, 0.8208478301223947, 0.8030835718841802, 0.8302702542657152, 0.6115389342871294, 0.6505395783882206, 0.6010719361145394, 0.6201992295121656, 0.5474925340891813, 0.12496363056790527, 0.6172883917916766, 0.5800103510803774, 0.6178082965572207, 0.5198145289921565, 0.01669045686983861, 0.537493623059079, 0.5574622518931232, 0.583907273603204, 0.6325076991684645, 0.6040173477737164, 0.5772205189597104, 0.4477021493834583, 0.5951745198118525, 0.5751254750305228, 0.611168261060888, 0.6095156079537748, 0.5613895288278088, 0.653165236812457, 0.578010382898307, 0.5906344030858592, 0.5734038836895186, 0.6973248370362327, 0.6690598036518844, 0.6847305193213178, 0.7061685940428326, 0.7127427735436558, 0.6956403853904165, 0.7256654724870555, 0.6974935332756751, 0.6800657796012706, 0.26886888297261247, 0.2567298455899326, 0.1978498023786025, 0.4711096272090417, 0.4616923459558898, 0.33646622305502594, 0.3003209734846265, 0.2923859164690722, 0.2917522917795389, 0.4407450260626149, 0.47750354188731814, 0.44573651789588875, 0.46007102069606187, 0.4623265148506259, 0.4698450507558254, 0.4983374796651274, 0.4651038353049999, 0.4906097444919848, 0.7939959747146519, 0.7512639921384054, 0.8024278744310025, 0.7655647590715289, 0.7860141525136092, 0.7469872082840403, 0.7837308674550727, 0.7867152501597141, 0.7814435476452145, 0.10731152787756348, 0.11531064980216776, 0.13327898151509088, 0.0845459419935578, 0.1129017830272383, 0.10799288264697948, 0.09026607095640027, 0.09242354853904122, 0.11414610931447933, 0.14859750401177263, 0.16993161980945604, 0.21808791662555005, 0.17893340336430485, 0.20673396640031128, 0.17514927217005238, 0.21812932372262783, 0.1816380653821965, 0.1969196835645982, 0.4445529723727534, 0.42052418256371293, 0.4832803672599898, 0.434256993835186, 0.45321080811656955, 0.43851286281310375, 0.47433954584356, 0.44995204167902425, 0.4907650783321168, 0.36028806305334393, 0.3637094622146594, 0.2797815375835401, 0.339563147640781, 0.3282683863725553, 0.33629759002845827, 0.38231494403451727, 0.36727042862318426, 0.40476782964212854, 0.19355751934158139, 0.222651046201242, 0.20008507149009302, 0.24076494486116384, 0.1823909733253869, 0.23823667947716676, 0.18896336916398737, 0.1775488692840156, 0.19825657499372007, 0.31328935485711895, 0.24978833520335753, 0.5467031594247906, 0.22580931177013186, 0.3068491624219365, 0.20701222076673953, 0.20878834757163556, 0.26504852465161, 0.19381349682665883, 0.8488604691570416, 0.17137799400702514, 0.17022881054803018, 0.8712490731729117, 0.2056317133448773, 0.775756989121672, 0.16335836936746595, 0.17793760622496502, 0.8524947927571764, 0.8179025205290024, 0.7358647696051241, 0.8190914110923364, 0.201869625298709, 0.16556880117395845, 0.7141282873355854, 0.2071428842442561, 0.8635935380607013, 0.791471704067155, 0.18662858002296845, 0.186359167637123, 0.19667438813877036, 0.18593125007449574, 0.16702174357922817, 0.17072242613914146, 0.18406270829058735, 0.1883483385411402, 0.21088470591522512, 0.08556516989537444, 0.08019225669858099, 0.08286134945626689, 0.07496979065675446, 0.0850600782588915, 0.0735401347951864, 0.07636235899990385, 0.07709528013485212, 0.07326544861438689]}, "mutation_prompt": null}
{"id": "6d2b2c46-715d-4797-a417-6a8f1ac4df62", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Refined Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover with enhanced probability adaptation\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.1))\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning with more granular adjustments\n            self.scale_factor = np.random.uniform(0.65, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.88, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with refined adaptive mutation and crossover strategies to improve convergence efficiency.", "configspace": "", "generation": 25, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "861cd3e5-fef8-4d90-a5d1-b5c310a7510e", "metadata": {"aucs": [0.822419785938898, 0.8199714546643329, 0.8414894141977063, 0.8430091771653526, 0.8593885836191024, 0.8487231796708052, 0.8367890364383294, 0.8302523382030463, 0.8293736847039304, 0.6900526707292051, 0.729827418174816, 0.7165636142714544, 0.7210593429287958, 0.7066488819727987, 0.73925793568504, 0.7290705693599189, 0.7228033402871135, 0.7062545396178945, 0.1276970958927961, 0.10836103147880471, 0.10584430366771846, 0.3699480834266704, 0.14078795992086013, 0.11173662417811558, 0.24405632789960074, 0.1979650359645696, 0.11807834733719214, 0.09487999780108625, 0.12368899362754915, 0.1075596948214832, 0.13173357002036357, 0.09980875650657273, 0.11640007866229085, 0.1278981270616787, 0.12028358906634584, 0.12155953374756501, 0.9267733553648255, 0.8780210526035417, 0.9728814299618388, 0.9627363618388612, 0.9068972901895733, 0.9753106988533982, 0.950121428753759, 0.9613290656568141, 0.9730778020274361, 0.6217127761634991, 0.5898663642757915, 0.6498912945803319, 0.5908153910909509, 0.6029460563973829, 0.601656570202229, 0.5726798590248927, 0.5981797797944681, 0.610924263252564, 0.8272794955422078, 0.7839572083705488, 0.8292962044243667, 0.8387891564677299, 0.8155388282714626, 0.8237694981028187, 0.8208478301223947, 0.8030835718841802, 0.8302702542657152, 0.6115389342871294, 0.6505395783882206, 0.6010719361145394, 0.6201992295121656, 0.5474925340891813, 0.12496363056790527, 0.6172883917916766, 0.5800103510803774, 0.6178082965572207, 0.5198145289921565, 0.01669045686983861, 0.537493623059079, 0.5574622518931232, 0.583907273603204, 0.6325076991684645, 0.6040173477737164, 0.5772205189597104, 0.4477021493834583, 0.5951745198118525, 0.5751254750305228, 0.611168261060888, 0.6095156079537748, 0.5613895288278088, 0.653165236812457, 0.578010382898307, 0.5906344030858592, 0.5734038836895186, 0.6973248370362327, 0.6690598036518844, 0.6847305193213178, 0.7061685940428326, 0.7127427735436558, 0.6956403853904165, 0.7256654724870555, 0.6974935332756751, 0.6800657796012706, 0.26886888297261247, 0.2567298455899326, 0.1978498023786025, 0.4711096272090417, 0.4616923459558898, 0.33646622305502594, 0.3003209734846265, 0.2923859164690722, 0.2917522917795389, 0.4407450260626149, 0.47750354188731814, 0.44573651789588875, 0.46007102069606187, 0.4623265148506259, 0.4698450507558254, 0.4983374796651274, 0.4651038353049999, 0.4906097444919848, 0.7939959747146519, 0.7512639921384054, 0.8024278744310025, 0.7655647590715289, 0.7860141525136092, 0.7469872082840403, 0.7837308674550727, 0.7867152501597141, 0.7814435476452145, 0.10731152787756348, 0.11531064980216776, 0.13327898151509088, 0.0845459419935578, 0.1129017830272383, 0.10799288264697948, 0.09026607095640027, 0.09242354853904122, 0.11414610931447933, 0.14859750401177263, 0.16993161980945604, 0.21808791662555005, 0.17893340336430485, 0.20673396640031128, 0.17514927217005238, 0.21812932372262783, 0.1816380653821965, 0.1969196835645982, 0.4445529723727534, 0.42052418256371293, 0.4832803672599898, 0.434256993835186, 0.45321080811656955, 0.43851286281310375, 0.47433954584356, 0.44995204167902425, 0.4907650783321168, 0.36028806305334393, 0.3637094622146594, 0.2797815375835401, 0.339563147640781, 0.3282683863725553, 0.33629759002845827, 0.38231494403451727, 0.36727042862318426, 0.40476782964212854, 0.19355751934158139, 0.222651046201242, 0.20008507149009302, 0.24076494486116384, 0.1823909733253869, 0.23823667947716676, 0.18896336916398737, 0.1775488692840156, 0.19825657499372007, 0.31328935485711895, 0.24978833520335753, 0.5467031594247906, 0.22580931177013186, 0.3068491624219365, 0.20701222076673953, 0.20878834757163556, 0.26504852465161, 0.19381349682665883, 0.8488604691570416, 0.17137799400702514, 0.17022881054803018, 0.8712490731729117, 0.2056317133448773, 0.775756989121672, 0.16335836936746595, 0.17793760622496502, 0.8524947927571764, 0.8179025205290024, 0.7358647696051241, 0.8190914110923364, 0.201869625298709, 0.16556880117395845, 0.7141282873355854, 0.2071428842442561, 0.8635935380607013, 0.791471704067155, 0.18662858002296845, 0.186359167637123, 0.19667438813877036, 0.18593125007449574, 0.16702174357922817, 0.17072242613914146, 0.18406270829058735, 0.1883483385411402, 0.21088470591522512, 0.08556516989537444, 0.08019225669858099, 0.08286134945626689, 0.07496979065675446, 0.0850600782588915, 0.0735401347951864, 0.07636235899990385, 0.07709528013485212, 0.07326544861438689]}, "mutation_prompt": null}
{"id": "3adacaf3-0093-414a-bddb-ade66618cd55", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.elitism_rate = 0.2  # New parameter for elitism\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        while func_evals < self.budget:\n            # Ensure a portion of the best solutions are retained (elitism)\n            num_elites = int(self.elitism_rate * self.population_size)\n            elite_indices = np.argsort(fitness)[:num_elites]\n            elites = population[elite_indices]\n\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Dynamic Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Enhanced Crossover with dynamic probability\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.1))\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Replace worst individuals with elites to preserve good solutions\n            worst_indices = np.argsort(fitness)[-num_elites:]\n            population[worst_indices] = elites\n            fitness[worst_indices] = [func(ind) for ind in elites]\n            func_evals += num_elites\n\n            # Self-adaptive parameter tuning with more granular adjustments\n            self.scale_factor = np.random.uniform(0.65, 0.85)\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n        # Return the best found solution\n        return best_solution, best_fitness", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An advanced hybrid evolutionary optimizer leveraging dynamic parameter adjustment and adaptive elitism to expedite convergence towards optimal solutions.", "configspace": "", "generation": 52, "fitness": 0.2443237739914392, "feedback": "The algorithm ImprovedHybridEvolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.26.", "error": "", "parent_id": "861cd3e5-fef8-4d90-a5d1-b5c310a7510e", "metadata": {"aucs": [0.8383684357144523, 0.905033746607372, 0.8671771536743662, 0.8786264016139986, 0.8908162545758033, 0.902832602040301, 0.8160814212577555, 0.6881154955176599, 0.916304295150606, 0.182909651090718, 0.04403958635122873, 0.7649478006751991, 0.760280295223306, 0.5873127178100697, 0.11269034886918294, 0.7789032794226206, 0.4936361389978069, 0.15484761717437667, 0.10697769990986394, 0.11311296095507828, 0.06475055556318499, 0.05730767182536145, 0.1022872958566784, 0.06927934765601274, 0.172377571310235, 0.1010893917540705, 0.03776474177218847, 0.10564015826952178, 0.05023166608121832, 0.05092739488381137, 0.08666438150134748, 0.10215280152315187, 0.06404363403673563, 0.0587599370911297, 0.057305848857539976, 0.07727499365523349, 0.9637852361390356, 0.9425659124939652, 0.952923664923826, 0.9569861563020283, 0.9228631551088102, 0.9535575959017228, 0.9819680822007438, 0.9553276939120334, 0.836254171395641, 0.5160412297054999, 0.06721518609708987, 0.04830870425407707, 0.2697686674012292, 0.1522424919845946, 0.1416292921329737, 0.32650102983985974, 0.4571027150159813, 0.31059906899609635, 0.1603922488584505, 0.16100257553492392, 0.2753850636465215, 0.21484979652286817, 0.3040796413638812, 0.3365996860885595, 0.23647748656593137, 0.23585008977042932, 0.22823105919744213, 0.10065317009017616, 0.1940788210526493, 0.15206222454992568, 0.17515939117753365, 0.13421163031633054, 0.13254027047484085, 0.1836645950101552, 0.2381054227371856, 0.15581486901871955, 0.15994379183233542, 0.00998032453963238, 0.02237772006787031, 0.14237068465563174, 0.14471124456398032, 0.19474125097257933, 0.2225394457251615, 0.10660752575885524, 0.21932306029349868, 9.999999999998899e-05, 0.07820797119407874, 0.03030592932466658, 0.02696511222234821, 9.999999999998899e-05, 9.999999999998899e-05, 0.047774910781717916, 0.1174080277732713, 0.011781351143597352, 0.1503849082179597, 0.04913322937458309, 0.05091179660776601, 0.08800247296544272, 0.14501593794902823, 0.010602077733438131, 0.17507460472838976, 0.08499006462956482, 0.050288004374922424, 0.06287892516159377, 0.10426866693520809, 0.05215392882787473, 0.21580615604063058, 0.22560689793531208, 0.10744278387756312, 0.2834390162898679, 0.10839124959404578, 9.999999999998899e-05, 0.03971238598058335, 0.08895084098549344, 0.09438707004704361, 0.22451240566174058, 0.29858100230728346, 0.09098912011733284, 0.2412662505452846, 0.1868471372711531, 0.2555498391383426, 0.48419200979421184, 0.6291708629642683, 0.5269005663805538, 0.4802663410439527, 0.18174475444851035, 0.562106946765681, 0.6156777770701993, 0.5299513268193394, 0.5492696479379053, 0.14217700957613455, 0.0820760724429247, 0.1428383027522685, 0.0746915860783598, 0.06808002620197118, 0.10241788657336326, 0.08756646829833259, 0.12295790014295704, 0.04289228689332647, 0.1183574901262271, 0.18654720574767025, 0.10767863297673086, 0.15081807206975884, 0.11271314900869989, 0.07898073486697921, 0.11122560881090271, 0.08340064429027882, 0.1397760432431573, 0.1851313500635633, 0.1896394110016203, 0.2191957539359075, 0.31478693459168483, 0.1867658269542688, 0.3743857577597459, 0.25058910975017434, 0.17377774300845283, 0.2073238676556166, 0.11374423622047125, 0.22176227485923072, 0.19646612665009955, 0.17852158398365736, 0.24540948760968717, 0.11668283379037037, 0.10936185538600607, 0.11207475683563661, 0.15333514104605583, 0.13057391130422769, 0.13160554794297696, 0.13345086981233123, 0.16512908227266276, 0.16220855687285363, 0.1454462694631904, 0.12245976138762271, 0.1441403794205065, 0.13387165753108876, 0.20524129302783167, 0.20575523141036978, 0.1579330446955839, 0.19876896964626223, 0.16918097614956729, 0.1930965743500095, 0.15854515439051375, 0.16863366626948573, 0.15881577393405644, 0.9067734976760387, 0.07466602457976645, 0.13007672696403183, 0.17238418798397837, 0.1207914665021157, 0.19801257204535083, 0.09953606984198138, 0.16816454635296507, 0.8389776472037423, 0.14842725909366494, 0.155899368488724, 0.15502660945052704, 0.464151377132512, 0.5204052161983894, 0.08236928455591375, 0.16567159187880975, 0.12780314191870434, 0.930293898453018, 0.1493747106234654, 0.16028977993794813, 0.1511166226001195, 0.14928715412795757, 0.15915986342056587, 0.14573062136941262, 0.14969714796693134, 0.1478268923486803, 0.14921270860549596, 0.034312024426326526, 0.06840432804491925, 0.04802070195449737, 0.07198736810945316, 0.08937339104779729, 0.0475319795025303, 0.05195403386921793, 0.05951574654378056, 0.07712898282588121]}, "mutation_prompt": null}
{"id": "edf98bf9-8562-479b-9c9f-9742e823e823", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Refined Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover with enhanced probability adaptation\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.1))\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning with more granular adjustments\n            self.scale_factor = np.random.uniform(0.65, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.88, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with refined adaptive mutation and crossover strategies to improve convergence efficiency.", "configspace": "", "generation": 25, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "861cd3e5-fef8-4d90-a5d1-b5c310a7510e", "metadata": {"aucs": [0.822419785938898, 0.8199714546643329, 0.8414894141977063, 0.8430091771653526, 0.8593885836191024, 0.8487231796708052, 0.8367890364383294, 0.8302523382030463, 0.8293736847039304, 0.6900526707292051, 0.729827418174816, 0.7165636142714544, 0.7210593429287958, 0.7066488819727987, 0.73925793568504, 0.7290705693599189, 0.7228033402871135, 0.7062545396178945, 0.1276970958927961, 0.10836103147880471, 0.10584430366771846, 0.3699480834266704, 0.14078795992086013, 0.11173662417811558, 0.24405632789960074, 0.1979650359645696, 0.11807834733719214, 0.09487999780108625, 0.12368899362754915, 0.1075596948214832, 0.13173357002036357, 0.09980875650657273, 0.11640007866229085, 0.1278981270616787, 0.12028358906634584, 0.12155953374756501, 0.9267733553648255, 0.8780210526035417, 0.9728814299618388, 0.9627363618388612, 0.9068972901895733, 0.9753106988533982, 0.950121428753759, 0.9613290656568141, 0.9730778020274361, 0.6217127761634991, 0.5898663642757915, 0.6498912945803319, 0.5908153910909509, 0.6029460563973829, 0.601656570202229, 0.5726798590248927, 0.5981797797944681, 0.610924263252564, 0.8272794955422078, 0.7839572083705488, 0.8292962044243667, 0.8387891564677299, 0.8155388282714626, 0.8237694981028187, 0.8208478301223947, 0.8030835718841802, 0.8302702542657152, 0.6115389342871294, 0.6505395783882206, 0.6010719361145394, 0.6201992295121656, 0.5474925340891813, 0.12496363056790527, 0.6172883917916766, 0.5800103510803774, 0.6178082965572207, 0.5198145289921565, 0.01669045686983861, 0.537493623059079, 0.5574622518931232, 0.583907273603204, 0.6325076991684645, 0.6040173477737164, 0.5772205189597104, 0.4477021493834583, 0.5951745198118525, 0.5751254750305228, 0.611168261060888, 0.6095156079537748, 0.5613895288278088, 0.653165236812457, 0.578010382898307, 0.5906344030858592, 0.5734038836895186, 0.6973248370362327, 0.6690598036518844, 0.6847305193213178, 0.7061685940428326, 0.7127427735436558, 0.6956403853904165, 0.7256654724870555, 0.6974935332756751, 0.6800657796012706, 0.26886888297261247, 0.2567298455899326, 0.1978498023786025, 0.4711096272090417, 0.4616923459558898, 0.33646622305502594, 0.3003209734846265, 0.2923859164690722, 0.2917522917795389, 0.4407450260626149, 0.47750354188731814, 0.44573651789588875, 0.46007102069606187, 0.4623265148506259, 0.4698450507558254, 0.4983374796651274, 0.4651038353049999, 0.4906097444919848, 0.7939959747146519, 0.7512639921384054, 0.8024278744310025, 0.7655647590715289, 0.7860141525136092, 0.7469872082840403, 0.7837308674550727, 0.7867152501597141, 0.7814435476452145, 0.10731152787756348, 0.11531064980216776, 0.13327898151509088, 0.0845459419935578, 0.1129017830272383, 0.10799288264697948, 0.09026607095640027, 0.09242354853904122, 0.11414610931447933, 0.14859750401177263, 0.16993161980945604, 0.21808791662555005, 0.17893340336430485, 0.20673396640031128, 0.17514927217005238, 0.21812932372262783, 0.1816380653821965, 0.1969196835645982, 0.4445529723727534, 0.42052418256371293, 0.4832803672599898, 0.434256993835186, 0.45321080811656955, 0.43851286281310375, 0.47433954584356, 0.44995204167902425, 0.4907650783321168, 0.36028806305334393, 0.3637094622146594, 0.2797815375835401, 0.339563147640781, 0.3282683863725553, 0.33629759002845827, 0.38231494403451727, 0.36727042862318426, 0.40476782964212854, 0.19355751934158139, 0.222651046201242, 0.20008507149009302, 0.24076494486116384, 0.1823909733253869, 0.23823667947716676, 0.18896336916398737, 0.1775488692840156, 0.19825657499372007, 0.31328935485711895, 0.24978833520335753, 0.5467031594247906, 0.22580931177013186, 0.3068491624219365, 0.20701222076673953, 0.20878834757163556, 0.26504852465161, 0.19381349682665883, 0.8488604691570416, 0.17137799400702514, 0.17022881054803018, 0.8712490731729117, 0.2056317133448773, 0.775756989121672, 0.16335836936746595, 0.17793760622496502, 0.8524947927571764, 0.8179025205290024, 0.7358647696051241, 0.8190914110923364, 0.201869625298709, 0.16556880117395845, 0.7141282873355854, 0.2071428842442561, 0.8635935380607013, 0.791471704067155, 0.18662858002296845, 0.186359167637123, 0.19667438813877036, 0.18593125007449574, 0.16702174357922817, 0.17072242613914146, 0.18406270829058735, 0.1883483385411402, 0.21088470591522512, 0.08556516989537444, 0.08019225669858099, 0.08286134945626689, 0.07496979065675446, 0.0850600782588915, 0.0735401347951864, 0.07636235899990385, 0.07709528013485212, 0.07326544861438689]}, "mutation_prompt": null}
{"id": "15f7bfbe-8875-4686-8ffa-782db39c8da1", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Refined Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover with enhanced probability adaptation\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.1))\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning with more granular adjustments\n            self.scale_factor = np.random.uniform(0.65, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.88, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with refined adaptive mutation and crossover strategies to improve convergence efficiency.", "configspace": "", "generation": 25, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "861cd3e5-fef8-4d90-a5d1-b5c310a7510e", "metadata": {"aucs": [0.822419785938898, 0.8199714546643329, 0.8414894141977063, 0.8430091771653526, 0.8593885836191024, 0.8487231796708052, 0.8367890364383294, 0.8302523382030463, 0.8293736847039304, 0.6900526707292051, 0.729827418174816, 0.7165636142714544, 0.7210593429287958, 0.7066488819727987, 0.73925793568504, 0.7290705693599189, 0.7228033402871135, 0.7062545396178945, 0.1276970958927961, 0.10836103147880471, 0.10584430366771846, 0.3699480834266704, 0.14078795992086013, 0.11173662417811558, 0.24405632789960074, 0.1979650359645696, 0.11807834733719214, 0.09487999780108625, 0.12368899362754915, 0.1075596948214832, 0.13173357002036357, 0.09980875650657273, 0.11640007866229085, 0.1278981270616787, 0.12028358906634584, 0.12155953374756501, 0.9267733553648255, 0.8780210526035417, 0.9728814299618388, 0.9627363618388612, 0.9068972901895733, 0.9753106988533982, 0.950121428753759, 0.9613290656568141, 0.9730778020274361, 0.6217127761634991, 0.5898663642757915, 0.6498912945803319, 0.5908153910909509, 0.6029460563973829, 0.601656570202229, 0.5726798590248927, 0.5981797797944681, 0.610924263252564, 0.8272794955422078, 0.7839572083705488, 0.8292962044243667, 0.8387891564677299, 0.8155388282714626, 0.8237694981028187, 0.8208478301223947, 0.8030835718841802, 0.8302702542657152, 0.6115389342871294, 0.6505395783882206, 0.6010719361145394, 0.6201992295121656, 0.5474925340891813, 0.12496363056790527, 0.6172883917916766, 0.5800103510803774, 0.6178082965572207, 0.5198145289921565, 0.01669045686983861, 0.537493623059079, 0.5574622518931232, 0.583907273603204, 0.6325076991684645, 0.6040173477737164, 0.5772205189597104, 0.4477021493834583, 0.5951745198118525, 0.5751254750305228, 0.611168261060888, 0.6095156079537748, 0.5613895288278088, 0.653165236812457, 0.578010382898307, 0.5906344030858592, 0.5734038836895186, 0.6973248370362327, 0.6690598036518844, 0.6847305193213178, 0.7061685940428326, 0.7127427735436558, 0.6956403853904165, 0.7256654724870555, 0.6974935332756751, 0.6800657796012706, 0.26886888297261247, 0.2567298455899326, 0.1978498023786025, 0.4711096272090417, 0.4616923459558898, 0.33646622305502594, 0.3003209734846265, 0.2923859164690722, 0.2917522917795389, 0.4407450260626149, 0.47750354188731814, 0.44573651789588875, 0.46007102069606187, 0.4623265148506259, 0.4698450507558254, 0.4983374796651274, 0.4651038353049999, 0.4906097444919848, 0.7939959747146519, 0.7512639921384054, 0.8024278744310025, 0.7655647590715289, 0.7860141525136092, 0.7469872082840403, 0.7837308674550727, 0.7867152501597141, 0.7814435476452145, 0.10731152787756348, 0.11531064980216776, 0.13327898151509088, 0.0845459419935578, 0.1129017830272383, 0.10799288264697948, 0.09026607095640027, 0.09242354853904122, 0.11414610931447933, 0.14859750401177263, 0.16993161980945604, 0.21808791662555005, 0.17893340336430485, 0.20673396640031128, 0.17514927217005238, 0.21812932372262783, 0.1816380653821965, 0.1969196835645982, 0.4445529723727534, 0.42052418256371293, 0.4832803672599898, 0.434256993835186, 0.45321080811656955, 0.43851286281310375, 0.47433954584356, 0.44995204167902425, 0.4907650783321168, 0.36028806305334393, 0.3637094622146594, 0.2797815375835401, 0.339563147640781, 0.3282683863725553, 0.33629759002845827, 0.38231494403451727, 0.36727042862318426, 0.40476782964212854, 0.19355751934158139, 0.222651046201242, 0.20008507149009302, 0.24076494486116384, 0.1823909733253869, 0.23823667947716676, 0.18896336916398737, 0.1775488692840156, 0.19825657499372007, 0.31328935485711895, 0.24978833520335753, 0.5467031594247906, 0.22580931177013186, 0.3068491624219365, 0.20701222076673953, 0.20878834757163556, 0.26504852465161, 0.19381349682665883, 0.8488604691570416, 0.17137799400702514, 0.17022881054803018, 0.8712490731729117, 0.2056317133448773, 0.775756989121672, 0.16335836936746595, 0.17793760622496502, 0.8524947927571764, 0.8179025205290024, 0.7358647696051241, 0.8190914110923364, 0.201869625298709, 0.16556880117395845, 0.7141282873355854, 0.2071428842442561, 0.8635935380607013, 0.791471704067155, 0.18662858002296845, 0.186359167637123, 0.19667438813877036, 0.18593125007449574, 0.16702174357922817, 0.17072242613914146, 0.18406270829058735, 0.1883483385411402, 0.21088470591522512, 0.08556516989537444, 0.08019225669858099, 0.08286134945626689, 0.07496979065675446, 0.0850600782588915, 0.0735401347951864, 0.07636235899990385, 0.07709528013485212, 0.07326544861438689]}, "mutation_prompt": null}
{"id": "05e9642a-e345-46e5-9025-bb6b1ada98fa", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Refined Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover with enhanced probability adaptation\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.1))\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning with more granular adjustments\n            self.scale_factor = np.random.uniform(0.65, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.88, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with refined adaptive mutation and crossover strategies to improve convergence efficiency.", "configspace": "", "generation": 25, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "861cd3e5-fef8-4d90-a5d1-b5c310a7510e", "metadata": {"aucs": [0.822419785938898, 0.8199714546643329, 0.8414894141977063, 0.8430091771653526, 0.8593885836191024, 0.8487231796708052, 0.8367890364383294, 0.8302523382030463, 0.8293736847039304, 0.6900526707292051, 0.729827418174816, 0.7165636142714544, 0.7210593429287958, 0.7066488819727987, 0.73925793568504, 0.7290705693599189, 0.7228033402871135, 0.7062545396178945, 0.1276970958927961, 0.10836103147880471, 0.10584430366771846, 0.3699480834266704, 0.14078795992086013, 0.11173662417811558, 0.24405632789960074, 0.1979650359645696, 0.11807834733719214, 0.09487999780108625, 0.12368899362754915, 0.1075596948214832, 0.13173357002036357, 0.09980875650657273, 0.11640007866229085, 0.1278981270616787, 0.12028358906634584, 0.12155953374756501, 0.9267733553648255, 0.8780210526035417, 0.9728814299618388, 0.9627363618388612, 0.9068972901895733, 0.9753106988533982, 0.950121428753759, 0.9613290656568141, 0.9730778020274361, 0.6217127761634991, 0.5898663642757915, 0.6498912945803319, 0.5908153910909509, 0.6029460563973829, 0.601656570202229, 0.5726798590248927, 0.5981797797944681, 0.610924263252564, 0.8272794955422078, 0.7839572083705488, 0.8292962044243667, 0.8387891564677299, 0.8155388282714626, 0.8237694981028187, 0.8208478301223947, 0.8030835718841802, 0.8302702542657152, 0.6115389342871294, 0.6505395783882206, 0.6010719361145394, 0.6201992295121656, 0.5474925340891813, 0.12496363056790527, 0.6172883917916766, 0.5800103510803774, 0.6178082965572207, 0.5198145289921565, 0.01669045686983861, 0.537493623059079, 0.5574622518931232, 0.583907273603204, 0.6325076991684645, 0.6040173477737164, 0.5772205189597104, 0.4477021493834583, 0.5951745198118525, 0.5751254750305228, 0.611168261060888, 0.6095156079537748, 0.5613895288278088, 0.653165236812457, 0.578010382898307, 0.5906344030858592, 0.5734038836895186, 0.6973248370362327, 0.6690598036518844, 0.6847305193213178, 0.7061685940428326, 0.7127427735436558, 0.6956403853904165, 0.7256654724870555, 0.6974935332756751, 0.6800657796012706, 0.26886888297261247, 0.2567298455899326, 0.1978498023786025, 0.4711096272090417, 0.4616923459558898, 0.33646622305502594, 0.3003209734846265, 0.2923859164690722, 0.2917522917795389, 0.4407450260626149, 0.47750354188731814, 0.44573651789588875, 0.46007102069606187, 0.4623265148506259, 0.4698450507558254, 0.4983374796651274, 0.4651038353049999, 0.4906097444919848, 0.7939959747146519, 0.7512639921384054, 0.8024278744310025, 0.7655647590715289, 0.7860141525136092, 0.7469872082840403, 0.7837308674550727, 0.7867152501597141, 0.7814435476452145, 0.10731152787756348, 0.11531064980216776, 0.13327898151509088, 0.0845459419935578, 0.1129017830272383, 0.10799288264697948, 0.09026607095640027, 0.09242354853904122, 0.11414610931447933, 0.14859750401177263, 0.16993161980945604, 0.21808791662555005, 0.17893340336430485, 0.20673396640031128, 0.17514927217005238, 0.21812932372262783, 0.1816380653821965, 0.1969196835645982, 0.4445529723727534, 0.42052418256371293, 0.4832803672599898, 0.434256993835186, 0.45321080811656955, 0.43851286281310375, 0.47433954584356, 0.44995204167902425, 0.4907650783321168, 0.36028806305334393, 0.3637094622146594, 0.2797815375835401, 0.339563147640781, 0.3282683863725553, 0.33629759002845827, 0.38231494403451727, 0.36727042862318426, 0.40476782964212854, 0.19355751934158139, 0.222651046201242, 0.20008507149009302, 0.24076494486116384, 0.1823909733253869, 0.23823667947716676, 0.18896336916398737, 0.1775488692840156, 0.19825657499372007, 0.31328935485711895, 0.24978833520335753, 0.5467031594247906, 0.22580931177013186, 0.3068491624219365, 0.20701222076673953, 0.20878834757163556, 0.26504852465161, 0.19381349682665883, 0.8488604691570416, 0.17137799400702514, 0.17022881054803018, 0.8712490731729117, 0.2056317133448773, 0.775756989121672, 0.16335836936746595, 0.17793760622496502, 0.8524947927571764, 0.8179025205290024, 0.7358647696051241, 0.8190914110923364, 0.201869625298709, 0.16556880117395845, 0.7141282873355854, 0.2071428842442561, 0.8635935380607013, 0.791471704067155, 0.18662858002296845, 0.186359167637123, 0.19667438813877036, 0.18593125007449574, 0.16702174357922817, 0.17072242613914146, 0.18406270829058735, 0.1883483385411402, 0.21088470591522512, 0.08556516989537444, 0.08019225669858099, 0.08286134945626689, 0.07496979065675446, 0.0850600782588915, 0.0735401347951864, 0.07636235899990385, 0.07709528013485212, 0.07326544861438689]}, "mutation_prompt": null}
{"id": "8da8d8c3-e373-4fb4-9c59-df285bb40b0b", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05  # New parameter for adaptive changes\n        \n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                # Mutation: choose three random indices different from i\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Refined Adaptive Differential Mutation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                mutant = a + (self.scale_factor + adapt_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                # Dynamic Crossover with enhanced probability adaptation\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.1))\n                trial[crossover] = mutant[crossover]\n\n                # Selection\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Self-adaptive parameter tuning with more granular adjustments\n            self.scale_factor = np.random.uniform(0.65, 0.85)  # Slight adjustment\n            self.cross_prob = np.random.uniform(0.88, 1.0)    # Slight adjustment\n\n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced hybrid evolutionary optimizer with refined adaptive mutation and crossover strategies to improve convergence efficiency.", "configspace": "", "generation": 25, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "861cd3e5-fef8-4d90-a5d1-b5c310a7510e", "metadata": {"aucs": [0.822419785938898, 0.8199714546643329, 0.8414894141977063, 0.8430091771653526, 0.8593885836191024, 0.8487231796708052, 0.8367890364383294, 0.8302523382030463, 0.8293736847039304, 0.6900526707292051, 0.729827418174816, 0.7165636142714544, 0.7210593429287958, 0.7066488819727987, 0.73925793568504, 0.7290705693599189, 0.7228033402871135, 0.7062545396178945, 0.1276970958927961, 0.10836103147880471, 0.10584430366771846, 0.3699480834266704, 0.14078795992086013, 0.11173662417811558, 0.24405632789960074, 0.1979650359645696, 0.11807834733719214, 0.09487999780108625, 0.12368899362754915, 0.1075596948214832, 0.13173357002036357, 0.09980875650657273, 0.11640007866229085, 0.1278981270616787, 0.12028358906634584, 0.12155953374756501, 0.9267733553648255, 0.8780210526035417, 0.9728814299618388, 0.9627363618388612, 0.9068972901895733, 0.9753106988533982, 0.950121428753759, 0.9613290656568141, 0.9730778020274361, 0.6217127761634991, 0.5898663642757915, 0.6498912945803319, 0.5908153910909509, 0.6029460563973829, 0.601656570202229, 0.5726798590248927, 0.5981797797944681, 0.610924263252564, 0.8272794955422078, 0.7839572083705488, 0.8292962044243667, 0.8387891564677299, 0.8155388282714626, 0.8237694981028187, 0.8208478301223947, 0.8030835718841802, 0.8302702542657152, 0.6115389342871294, 0.6505395783882206, 0.6010719361145394, 0.6201992295121656, 0.5474925340891813, 0.12496363056790527, 0.6172883917916766, 0.5800103510803774, 0.6178082965572207, 0.5198145289921565, 0.01669045686983861, 0.537493623059079, 0.5574622518931232, 0.583907273603204, 0.6325076991684645, 0.6040173477737164, 0.5772205189597104, 0.4477021493834583, 0.5951745198118525, 0.5751254750305228, 0.611168261060888, 0.6095156079537748, 0.5613895288278088, 0.653165236812457, 0.578010382898307, 0.5906344030858592, 0.5734038836895186, 0.6973248370362327, 0.6690598036518844, 0.6847305193213178, 0.7061685940428326, 0.7127427735436558, 0.6956403853904165, 0.7256654724870555, 0.6974935332756751, 0.6800657796012706, 0.26886888297261247, 0.2567298455899326, 0.1978498023786025, 0.4711096272090417, 0.4616923459558898, 0.33646622305502594, 0.3003209734846265, 0.2923859164690722, 0.2917522917795389, 0.4407450260626149, 0.47750354188731814, 0.44573651789588875, 0.46007102069606187, 0.4623265148506259, 0.4698450507558254, 0.4983374796651274, 0.4651038353049999, 0.4906097444919848, 0.7939959747146519, 0.7512639921384054, 0.8024278744310025, 0.7655647590715289, 0.7860141525136092, 0.7469872082840403, 0.7837308674550727, 0.7867152501597141, 0.7814435476452145, 0.10731152787756348, 0.11531064980216776, 0.13327898151509088, 0.0845459419935578, 0.1129017830272383, 0.10799288264697948, 0.09026607095640027, 0.09242354853904122, 0.11414610931447933, 0.14859750401177263, 0.16993161980945604, 0.21808791662555005, 0.17893340336430485, 0.20673396640031128, 0.17514927217005238, 0.21812932372262783, 0.1816380653821965, 0.1969196835645982, 0.4445529723727534, 0.42052418256371293, 0.4832803672599898, 0.434256993835186, 0.45321080811656955, 0.43851286281310375, 0.47433954584356, 0.44995204167902425, 0.4907650783321168, 0.36028806305334393, 0.3637094622146594, 0.2797815375835401, 0.339563147640781, 0.3282683863725553, 0.33629759002845827, 0.38231494403451727, 0.36727042862318426, 0.40476782964212854, 0.19355751934158139, 0.222651046201242, 0.20008507149009302, 0.24076494486116384, 0.1823909733253869, 0.23823667947716676, 0.18896336916398737, 0.1775488692840156, 0.19825657499372007, 0.31328935485711895, 0.24978833520335753, 0.5467031594247906, 0.22580931177013186, 0.3068491624219365, 0.20701222076673953, 0.20878834757163556, 0.26504852465161, 0.19381349682665883, 0.8488604691570416, 0.17137799400702514, 0.17022881054803018, 0.8712490731729117, 0.2056317133448773, 0.775756989121672, 0.16335836936746595, 0.17793760622496502, 0.8524947927571764, 0.8179025205290024, 0.7358647696051241, 0.8190914110923364, 0.201869625298709, 0.16556880117395845, 0.7141282873355854, 0.2071428842442561, 0.8635935380607013, 0.791471704067155, 0.18662858002296845, 0.186359167637123, 0.19667438813877036, 0.18593125007449574, 0.16702174357922817, 0.17072242613914146, 0.18406270829058735, 0.1883483385411402, 0.21088470591522512, 0.08556516989537444, 0.08019225669858099, 0.08286134945626689, 0.07496979065675446, 0.0850600782588915, 0.0735401347951864, 0.07636235899990385, 0.07709528013485212, 0.07326544861438689]}, "mutation_prompt": null}
{"id": "21fe365f-f74d-4cad-982f-d34920338682", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85  # Increased initial scale factor for exploration\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2  # New parameter to balance exploration and exploitation\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.7, 0.85)\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer with dynamic exploration-exploitation balance and adaptive mutation enhancements for improved convergence speed.", "configspace": "", "generation": 57, "fitness": 0.48861017159730047, "feedback": "The algorithm EnhancedHybridEvolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.49 with standard deviation 0.28.", "error": "", "parent_id": "861cd3e5-fef8-4d90-a5d1-b5c310a7510e", "metadata": {"aucs": [0.855172362762411, 0.8659220062066514, 0.8637095763143072, 0.8684988538912858, 0.8706178808280751, 0.8751219187668274, 0.875735912251711, 0.885371256709463, 0.8758475010261377, 0.7897606772692076, 0.7780464349312769, 0.7624645084216468, 0.790407854606426, 0.7684057734533948, 0.7577109760176526, 0.7463787822833655, 0.7635591696458801, 0.779950701825359, 0.13747259024931702, 0.17055399530404325, 0.10616000006249326, 0.1054032523020253, 0.09860999203547127, 0.1492505945832061, 0.13335637946585543, 0.17177438431859848, 0.13050905674168511, 0.12194495847323028, 0.10146753381107443, 0.12917549606342704, 0.09420335672677227, 0.11375308881847501, 0.15008416491683807, 0.13767435057858823, 0.11576480629799935, 0.1288823478391028, 0.923616252156499, 0.9332626390541685, 0.938880057085812, 0.9569887426622138, 0.965427221297927, 0.9546026869304383, 0.9564207320607586, 0.9179055589109922, 0.9596409617365361, 0.6799231502956886, 0.6228315181907147, 0.6053077427826508, 0.643633539398441, 0.6454159831097687, 0.6594364776109957, 0.631077911470128, 0.6268580537351958, 0.6605426909472558, 0.8738257379897179, 0.856710039802895, 0.8528781296374323, 0.8745713666194754, 0.8723434837413657, 0.8649739958849774, 0.8430124741409125, 0.8534555458270078, 0.8270341744551444, 0.551609459177163, 0.6482143574659887, 0.6614293324084707, 0.6270736700295976, 0.6204393695553585, 0.7290196604281876, 0.5295222584265555, 0.6848937949327776, 0.6093807291259528, 0.5465871851585957, 0.4904294373669038, 0.3946434652820141, 0.6080634587822529, 0.5095203797813246, 0.5660126831435907, 0.565944899087218, 0.6275651600885951, 0.6601593986255824, 0.6815124455687847, 0.6854782027332962, 0.6837219132887977, 0.6919529395951656, 0.6662903194597756, 0.6739183325345197, 0.65822892108458, 0.664930023254529, 0.6535756775119573, 0.7392823068939017, 0.7606036896234012, 0.7366869729255578, 0.7567829085685326, 0.7565024511641978, 0.7422584293751445, 0.7414979218067919, 0.7895831302138768, 0.7506469026429001, 0.30000960624512785, 0.24762357706142113, 0.3644720772137978, 0.535693056038617, 0.25791088630295056, 0.5635676852911893, 0.411931198692415, 0.38074161349804125, 0.25527312128765856, 0.5196475226986133, 0.49754361755002785, 0.5619986287546577, 0.5513970794512073, 0.5140282507326093, 0.5540378543456437, 0.5567276713407624, 0.48309762896091235, 0.5926462818682783, 0.8292316049554413, 0.8040513681872443, 0.8231935820366749, 0.8204589686524565, 0.8347687689102576, 0.8283266882051368, 0.8240075686093223, 0.8119240453212864, 0.8478159671843553, 0.08471603955940465, 0.3269841909688398, 0.15584601958897926, 0.11946357558329346, 0.3135240296628693, 0.10580123910878647, 0.09906976740325169, 0.09333877826716819, 0.11331074715137834, 0.5154384242785006, 0.1803933474093794, 0.13860169662543853, 0.14837852583895927, 0.1674644578945137, 0.17496579937812673, 0.15331341602347348, 0.24947180259253354, 0.182268737549234, 0.5005475397078184, 0.4811407806137462, 0.5377490758421786, 0.4867492420791786, 0.47820616455337817, 0.48736033498544773, 0.5242773046718501, 0.5566141040541208, 0.5427556727632223, 0.3896049525718689, 0.41282700043680387, 0.42158935101037176, 0.40232756243805645, 0.38652903995092525, 0.38638984348144334, 0.40047031823279766, 0.45695157847683643, 0.4069924652942214, 0.19933732654038117, 0.18606894657419026, 0.1673109473458444, 0.216324927810446, 0.19287814885471466, 0.1834506894129444, 0.18836828764373648, 0.19333976771871386, 0.20323648161897667, 0.23640093830712194, 0.2199459491448139, 0.19488160744504957, 0.21346316747808358, 0.5834111239602295, 0.5474039843918898, 0.6400349897232377, 0.6421359954798118, 0.22280323530908253, 0.1718399849181258, 0.18627685918462045, 0.16164795410939348, 0.8656755749455405, 0.20396844494786914, 0.8257571772650467, 0.20358013983404077, 0.7674193301061665, 0.18330540067054635, 0.1553301798026454, 0.16839318394936542, 0.8025939547242359, 0.20788461803011848, 0.7147711167660822, 0.836414744094142, 0.7948373782477776, 0.12659423940961168, 0.8558619002585786, 0.18868553146758382, 0.2003710379036382, 0.1779633789611531, 0.1867325129591343, 0.21877009451217122, 0.1851188699205697, 0.18538773835269862, 0.18705575881167003, 0.16899127761440813, 0.077243001792072, 0.0792303244840199, 0.08746923025707387, 0.07112272177183443, 0.07311984198393673, 0.08259774318144808, 0.08036078786819523, 0.06537377928504606, 0.0744343419763247]}, "mutation_prompt": null}
{"id": "589e501f-25d2-476e-b226-42a445885584", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85  # Increased initial scale factor for exploration\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2  # New parameter to balance exploration and exploitation\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.7, 0.85)\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer with dynamic exploration-exploitation balance and adaptive mutation enhancements for improved convergence speed.", "configspace": "", "generation": 58, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.855172362762411, 0.8659220062066514, 0.8637095763143072, 0.8684988538912858, 0.8706178808280751, 0.8751219187668274, 0.875735912251711, 0.885371256709463, 0.8758475010261377, 0.7897606772692076, 0.7780464349312769, 0.7624645084216468, 0.790407854606426, 0.7684057734533948, 0.7577109760176526, 0.7463787822833655, 0.7635591696458801, 0.779950701825359, 0.13747259024931702, 0.17055399530404325, 0.10616000006249326, 0.1054032523020253, 0.09860999203547127, 0.1492505945832061, 0.13335637946585543, 0.17177438431859848, 0.13050905674168511, 0.12194495847323028, 0.10146753381107443, 0.12917549606342704, 0.09420335672677227, 0.11375308881847501, 0.15008416491683807, 0.13767435057858823, 0.11576480629799935, 0.1288823478391028, 0.923616252156499, 0.9332626390541685, 0.938880057085812, 0.9569887426622138, 0.965427221297927, 0.9546026869304383, 0.9564207320607586, 0.9179055589109922, 0.9596409617365361, 0.6799231502956886, 0.6228315181907147, 0.6053077427826508, 0.643633539398441, 0.6454159831097687, 0.6594364776109957, 0.631077911470128, 0.6268580537351958, 0.6605426909472558, 0.8738257379897179, 0.856710039802895, 0.8528781296374323, 0.8745713666194754, 0.8723434837413657, 0.8649739958849774, 0.8430124741409125, 0.8534555458270078, 0.8270341744551444, 0.551609459177163, 0.6482143574659887, 0.6614293324084707, 0.6270736700295976, 0.6204393695553585, 0.7290196604281876, 0.5295222584265555, 0.6848937949327776, 0.6093807291259528, 0.5465871851585957, 0.4904294373669038, 0.3946434652820141, 0.6080634587822529, 0.5095203797813246, 0.5660126831435907, 0.565944899087218, 0.6275651600885951, 0.6601593986255824, 0.6815124455687847, 0.6854782027332962, 0.6837219132887977, 0.6919529395951656, 0.6662903194597756, 0.6739183325345197, 0.65822892108458, 0.664930023254529, 0.6535756775119573, 0.7392823068939017, 0.7606036896234012, 0.7366869729255578, 0.7567829085685326, 0.7565024511641978, 0.7422584293751445, 0.7414979218067919, 0.7895831302138768, 0.7506469026429001, 0.30000960624512785, 0.24762357706142113, 0.3644720772137978, 0.535693056038617, 0.25791088630295056, 0.5635676852911893, 0.411931198692415, 0.38074161349804125, 0.25527312128765856, 0.5196475226986133, 0.49754361755002785, 0.5619986287546577, 0.5513970794512073, 0.5140282507326093, 0.5540378543456437, 0.5567276713407624, 0.48309762896091235, 0.5926462818682783, 0.8292316049554413, 0.8040513681872443, 0.8231935820366749, 0.8204589686524565, 0.8347687689102576, 0.8283266882051368, 0.8240075686093223, 0.8119240453212864, 0.8478159671843553, 0.08471603955940465, 0.3269841909688398, 0.15584601958897926, 0.11946357558329346, 0.3135240296628693, 0.10580123910878647, 0.09906976740325169, 0.09333877826716819, 0.11331074715137834, 0.5154384242785006, 0.1803933474093794, 0.13860169662543853, 0.14837852583895927, 0.1674644578945137, 0.17496579937812673, 0.15331341602347348, 0.24947180259253354, 0.182268737549234, 0.5005475397078184, 0.4811407806137462, 0.5377490758421786, 0.4867492420791786, 0.47820616455337817, 0.48736033498544773, 0.5242773046718501, 0.5566141040541208, 0.5427556727632223, 0.3896049525718689, 0.41282700043680387, 0.42158935101037176, 0.40232756243805645, 0.38652903995092525, 0.38638984348144334, 0.40047031823279766, 0.45695157847683643, 0.4069924652942214, 0.19933732654038117, 0.18606894657419026, 0.1673109473458444, 0.216324927810446, 0.19287814885471466, 0.1834506894129444, 0.18836828764373648, 0.19333976771871386, 0.20323648161897667, 0.23640093830712194, 0.2199459491448139, 0.19488160744504957, 0.21346316747808358, 0.5834111239602295, 0.5474039843918898, 0.6400349897232377, 0.6421359954798118, 0.22280323530908253, 0.1718399849181258, 0.18627685918462045, 0.16164795410939348, 0.8656755749455405, 0.20396844494786914, 0.8257571772650467, 0.20358013983404077, 0.7674193301061665, 0.18330540067054635, 0.1553301798026454, 0.16839318394936542, 0.8025939547242359, 0.20788461803011848, 0.7147711167660822, 0.836414744094142, 0.7948373782477776, 0.12659423940961168, 0.8558619002585786, 0.18868553146758382, 0.2003710379036382, 0.1779633789611531, 0.1867325129591343, 0.21877009451217122, 0.1851188699205697, 0.18538773835269862, 0.18705575881167003, 0.16899127761440813, 0.077243001792072, 0.0792303244840199, 0.08746923025707387, 0.07112272177183443, 0.07311984198393673, 0.08259774318144808, 0.08036078786819523, 0.06537377928504606, 0.0744343419763247]}, "mutation_prompt": null}
{"id": "f851ec61-d929-46ab-9d2f-9ebb53b19c18", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85  # Increased initial scale factor for exploration\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2  # New parameter to balance exploration and exploitation\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.7, 0.85)\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer with dynamic exploration-exploitation balance and adaptive mutation enhancements for improved convergence speed.", "configspace": "", "generation": 58, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.855172362762411, 0.8659220062066514, 0.8637095763143072, 0.8684988538912858, 0.8706178808280751, 0.8751219187668274, 0.875735912251711, 0.885371256709463, 0.8758475010261377, 0.7897606772692076, 0.7780464349312769, 0.7624645084216468, 0.790407854606426, 0.7684057734533948, 0.7577109760176526, 0.7463787822833655, 0.7635591696458801, 0.779950701825359, 0.13747259024931702, 0.17055399530404325, 0.10616000006249326, 0.1054032523020253, 0.09860999203547127, 0.1492505945832061, 0.13335637946585543, 0.17177438431859848, 0.13050905674168511, 0.12194495847323028, 0.10146753381107443, 0.12917549606342704, 0.09420335672677227, 0.11375308881847501, 0.15008416491683807, 0.13767435057858823, 0.11576480629799935, 0.1288823478391028, 0.923616252156499, 0.9332626390541685, 0.938880057085812, 0.9569887426622138, 0.965427221297927, 0.9546026869304383, 0.9564207320607586, 0.9179055589109922, 0.9596409617365361, 0.6799231502956886, 0.6228315181907147, 0.6053077427826508, 0.643633539398441, 0.6454159831097687, 0.6594364776109957, 0.631077911470128, 0.6268580537351958, 0.6605426909472558, 0.8738257379897179, 0.856710039802895, 0.8528781296374323, 0.8745713666194754, 0.8723434837413657, 0.8649739958849774, 0.8430124741409125, 0.8534555458270078, 0.8270341744551444, 0.551609459177163, 0.6482143574659887, 0.6614293324084707, 0.6270736700295976, 0.6204393695553585, 0.7290196604281876, 0.5295222584265555, 0.6848937949327776, 0.6093807291259528, 0.5465871851585957, 0.4904294373669038, 0.3946434652820141, 0.6080634587822529, 0.5095203797813246, 0.5660126831435907, 0.565944899087218, 0.6275651600885951, 0.6601593986255824, 0.6815124455687847, 0.6854782027332962, 0.6837219132887977, 0.6919529395951656, 0.6662903194597756, 0.6739183325345197, 0.65822892108458, 0.664930023254529, 0.6535756775119573, 0.7392823068939017, 0.7606036896234012, 0.7366869729255578, 0.7567829085685326, 0.7565024511641978, 0.7422584293751445, 0.7414979218067919, 0.7895831302138768, 0.7506469026429001, 0.30000960624512785, 0.24762357706142113, 0.3644720772137978, 0.535693056038617, 0.25791088630295056, 0.5635676852911893, 0.411931198692415, 0.38074161349804125, 0.25527312128765856, 0.5196475226986133, 0.49754361755002785, 0.5619986287546577, 0.5513970794512073, 0.5140282507326093, 0.5540378543456437, 0.5567276713407624, 0.48309762896091235, 0.5926462818682783, 0.8292316049554413, 0.8040513681872443, 0.8231935820366749, 0.8204589686524565, 0.8347687689102576, 0.8283266882051368, 0.8240075686093223, 0.8119240453212864, 0.8478159671843553, 0.08471603955940465, 0.3269841909688398, 0.15584601958897926, 0.11946357558329346, 0.3135240296628693, 0.10580123910878647, 0.09906976740325169, 0.09333877826716819, 0.11331074715137834, 0.5154384242785006, 0.1803933474093794, 0.13860169662543853, 0.14837852583895927, 0.1674644578945137, 0.17496579937812673, 0.15331341602347348, 0.24947180259253354, 0.182268737549234, 0.5005475397078184, 0.4811407806137462, 0.5377490758421786, 0.4867492420791786, 0.47820616455337817, 0.48736033498544773, 0.5242773046718501, 0.5566141040541208, 0.5427556727632223, 0.3896049525718689, 0.41282700043680387, 0.42158935101037176, 0.40232756243805645, 0.38652903995092525, 0.38638984348144334, 0.40047031823279766, 0.45695157847683643, 0.4069924652942214, 0.19933732654038117, 0.18606894657419026, 0.1673109473458444, 0.216324927810446, 0.19287814885471466, 0.1834506894129444, 0.18836828764373648, 0.19333976771871386, 0.20323648161897667, 0.23640093830712194, 0.2199459491448139, 0.19488160744504957, 0.21346316747808358, 0.5834111239602295, 0.5474039843918898, 0.6400349897232377, 0.6421359954798118, 0.22280323530908253, 0.1718399849181258, 0.18627685918462045, 0.16164795410939348, 0.8656755749455405, 0.20396844494786914, 0.8257571772650467, 0.20358013983404077, 0.7674193301061665, 0.18330540067054635, 0.1553301798026454, 0.16839318394936542, 0.8025939547242359, 0.20788461803011848, 0.7147711167660822, 0.836414744094142, 0.7948373782477776, 0.12659423940961168, 0.8558619002585786, 0.18868553146758382, 0.2003710379036382, 0.1779633789611531, 0.1867325129591343, 0.21877009451217122, 0.1851188699205697, 0.18538773835269862, 0.18705575881167003, 0.16899127761440813, 0.077243001792072, 0.0792303244840199, 0.08746923025707387, 0.07112272177183443, 0.07311984198393673, 0.08259774318144808, 0.08036078786819523, 0.06537377928504606, 0.0744343419763247]}, "mutation_prompt": null}
{"id": "706602dd-db3d-4077-80d5-260f05c51ee6", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85  # Increased initial scale factor for exploration\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2  # New parameter to balance exploration and exploitation\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.7, 0.85)\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer with dynamic exploration-exploitation balance and adaptive mutation enhancements for improved convergence speed.", "configspace": "", "generation": 58, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.855172362762411, 0.8659220062066514, 0.8637095763143072, 0.8684988538912858, 0.8706178808280751, 0.8751219187668274, 0.875735912251711, 0.885371256709463, 0.8758475010261377, 0.7897606772692076, 0.7780464349312769, 0.7624645084216468, 0.790407854606426, 0.7684057734533948, 0.7577109760176526, 0.7463787822833655, 0.7635591696458801, 0.779950701825359, 0.13747259024931702, 0.17055399530404325, 0.10616000006249326, 0.1054032523020253, 0.09860999203547127, 0.1492505945832061, 0.13335637946585543, 0.17177438431859848, 0.13050905674168511, 0.12194495847323028, 0.10146753381107443, 0.12917549606342704, 0.09420335672677227, 0.11375308881847501, 0.15008416491683807, 0.13767435057858823, 0.11576480629799935, 0.1288823478391028, 0.923616252156499, 0.9332626390541685, 0.938880057085812, 0.9569887426622138, 0.965427221297927, 0.9546026869304383, 0.9564207320607586, 0.9179055589109922, 0.9596409617365361, 0.6799231502956886, 0.6228315181907147, 0.6053077427826508, 0.643633539398441, 0.6454159831097687, 0.6594364776109957, 0.631077911470128, 0.6268580537351958, 0.6605426909472558, 0.8738257379897179, 0.856710039802895, 0.8528781296374323, 0.8745713666194754, 0.8723434837413657, 0.8649739958849774, 0.8430124741409125, 0.8534555458270078, 0.8270341744551444, 0.551609459177163, 0.6482143574659887, 0.6614293324084707, 0.6270736700295976, 0.6204393695553585, 0.7290196604281876, 0.5295222584265555, 0.6848937949327776, 0.6093807291259528, 0.5465871851585957, 0.4904294373669038, 0.3946434652820141, 0.6080634587822529, 0.5095203797813246, 0.5660126831435907, 0.565944899087218, 0.6275651600885951, 0.6601593986255824, 0.6815124455687847, 0.6854782027332962, 0.6837219132887977, 0.6919529395951656, 0.6662903194597756, 0.6739183325345197, 0.65822892108458, 0.664930023254529, 0.6535756775119573, 0.7392823068939017, 0.7606036896234012, 0.7366869729255578, 0.7567829085685326, 0.7565024511641978, 0.7422584293751445, 0.7414979218067919, 0.7895831302138768, 0.7506469026429001, 0.30000960624512785, 0.24762357706142113, 0.3644720772137978, 0.535693056038617, 0.25791088630295056, 0.5635676852911893, 0.411931198692415, 0.38074161349804125, 0.25527312128765856, 0.5196475226986133, 0.49754361755002785, 0.5619986287546577, 0.5513970794512073, 0.5140282507326093, 0.5540378543456437, 0.5567276713407624, 0.48309762896091235, 0.5926462818682783, 0.8292316049554413, 0.8040513681872443, 0.8231935820366749, 0.8204589686524565, 0.8347687689102576, 0.8283266882051368, 0.8240075686093223, 0.8119240453212864, 0.8478159671843553, 0.08471603955940465, 0.3269841909688398, 0.15584601958897926, 0.11946357558329346, 0.3135240296628693, 0.10580123910878647, 0.09906976740325169, 0.09333877826716819, 0.11331074715137834, 0.5154384242785006, 0.1803933474093794, 0.13860169662543853, 0.14837852583895927, 0.1674644578945137, 0.17496579937812673, 0.15331341602347348, 0.24947180259253354, 0.182268737549234, 0.5005475397078184, 0.4811407806137462, 0.5377490758421786, 0.4867492420791786, 0.47820616455337817, 0.48736033498544773, 0.5242773046718501, 0.5566141040541208, 0.5427556727632223, 0.3896049525718689, 0.41282700043680387, 0.42158935101037176, 0.40232756243805645, 0.38652903995092525, 0.38638984348144334, 0.40047031823279766, 0.45695157847683643, 0.4069924652942214, 0.19933732654038117, 0.18606894657419026, 0.1673109473458444, 0.216324927810446, 0.19287814885471466, 0.1834506894129444, 0.18836828764373648, 0.19333976771871386, 0.20323648161897667, 0.23640093830712194, 0.2199459491448139, 0.19488160744504957, 0.21346316747808358, 0.5834111239602295, 0.5474039843918898, 0.6400349897232377, 0.6421359954798118, 0.22280323530908253, 0.1718399849181258, 0.18627685918462045, 0.16164795410939348, 0.8656755749455405, 0.20396844494786914, 0.8257571772650467, 0.20358013983404077, 0.7674193301061665, 0.18330540067054635, 0.1553301798026454, 0.16839318394936542, 0.8025939547242359, 0.20788461803011848, 0.7147711167660822, 0.836414744094142, 0.7948373782477776, 0.12659423940961168, 0.8558619002585786, 0.18868553146758382, 0.2003710379036382, 0.1779633789611531, 0.1867325129591343, 0.21877009451217122, 0.1851188699205697, 0.18538773835269862, 0.18705575881167003, 0.16899127761440813, 0.077243001792072, 0.0792303244840199, 0.08746923025707387, 0.07112272177183443, 0.07311984198393673, 0.08259774318144808, 0.08036078786819523, 0.06537377928504606, 0.0744343419763247]}, "mutation_prompt": null}
{"id": "e6552b49-73aa-4598-be12-d386c43a2b1f", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85  # Increased initial scale factor for exploration\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2  # New parameter to balance exploration and exploitation\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.7, 0.85)\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer with dynamic exploration-exploitation balance and adaptive mutation enhancements for improved convergence speed.", "configspace": "", "generation": 58, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.855172362762411, 0.8659220062066514, 0.8637095763143072, 0.8684988538912858, 0.8706178808280751, 0.8751219187668274, 0.875735912251711, 0.885371256709463, 0.8758475010261377, 0.7897606772692076, 0.7780464349312769, 0.7624645084216468, 0.790407854606426, 0.7684057734533948, 0.7577109760176526, 0.7463787822833655, 0.7635591696458801, 0.779950701825359, 0.13747259024931702, 0.17055399530404325, 0.10616000006249326, 0.1054032523020253, 0.09860999203547127, 0.1492505945832061, 0.13335637946585543, 0.17177438431859848, 0.13050905674168511, 0.12194495847323028, 0.10146753381107443, 0.12917549606342704, 0.09420335672677227, 0.11375308881847501, 0.15008416491683807, 0.13767435057858823, 0.11576480629799935, 0.1288823478391028, 0.923616252156499, 0.9332626390541685, 0.938880057085812, 0.9569887426622138, 0.965427221297927, 0.9546026869304383, 0.9564207320607586, 0.9179055589109922, 0.9596409617365361, 0.6799231502956886, 0.6228315181907147, 0.6053077427826508, 0.643633539398441, 0.6454159831097687, 0.6594364776109957, 0.631077911470128, 0.6268580537351958, 0.6605426909472558, 0.8738257379897179, 0.856710039802895, 0.8528781296374323, 0.8745713666194754, 0.8723434837413657, 0.8649739958849774, 0.8430124741409125, 0.8534555458270078, 0.8270341744551444, 0.551609459177163, 0.6482143574659887, 0.6614293324084707, 0.6270736700295976, 0.6204393695553585, 0.7290196604281876, 0.5295222584265555, 0.6848937949327776, 0.6093807291259528, 0.5465871851585957, 0.4904294373669038, 0.3946434652820141, 0.6080634587822529, 0.5095203797813246, 0.5660126831435907, 0.565944899087218, 0.6275651600885951, 0.6601593986255824, 0.6815124455687847, 0.6854782027332962, 0.6837219132887977, 0.6919529395951656, 0.6662903194597756, 0.6739183325345197, 0.65822892108458, 0.664930023254529, 0.6535756775119573, 0.7392823068939017, 0.7606036896234012, 0.7366869729255578, 0.7567829085685326, 0.7565024511641978, 0.7422584293751445, 0.7414979218067919, 0.7895831302138768, 0.7506469026429001, 0.30000960624512785, 0.24762357706142113, 0.3644720772137978, 0.535693056038617, 0.25791088630295056, 0.5635676852911893, 0.411931198692415, 0.38074161349804125, 0.25527312128765856, 0.5196475226986133, 0.49754361755002785, 0.5619986287546577, 0.5513970794512073, 0.5140282507326093, 0.5540378543456437, 0.5567276713407624, 0.48309762896091235, 0.5926462818682783, 0.8292316049554413, 0.8040513681872443, 0.8231935820366749, 0.8204589686524565, 0.8347687689102576, 0.8283266882051368, 0.8240075686093223, 0.8119240453212864, 0.8478159671843553, 0.08471603955940465, 0.3269841909688398, 0.15584601958897926, 0.11946357558329346, 0.3135240296628693, 0.10580123910878647, 0.09906976740325169, 0.09333877826716819, 0.11331074715137834, 0.5154384242785006, 0.1803933474093794, 0.13860169662543853, 0.14837852583895927, 0.1674644578945137, 0.17496579937812673, 0.15331341602347348, 0.24947180259253354, 0.182268737549234, 0.5005475397078184, 0.4811407806137462, 0.5377490758421786, 0.4867492420791786, 0.47820616455337817, 0.48736033498544773, 0.5242773046718501, 0.5566141040541208, 0.5427556727632223, 0.3896049525718689, 0.41282700043680387, 0.42158935101037176, 0.40232756243805645, 0.38652903995092525, 0.38638984348144334, 0.40047031823279766, 0.45695157847683643, 0.4069924652942214, 0.19933732654038117, 0.18606894657419026, 0.1673109473458444, 0.216324927810446, 0.19287814885471466, 0.1834506894129444, 0.18836828764373648, 0.19333976771871386, 0.20323648161897667, 0.23640093830712194, 0.2199459491448139, 0.19488160744504957, 0.21346316747808358, 0.5834111239602295, 0.5474039843918898, 0.6400349897232377, 0.6421359954798118, 0.22280323530908253, 0.1718399849181258, 0.18627685918462045, 0.16164795410939348, 0.8656755749455405, 0.20396844494786914, 0.8257571772650467, 0.20358013983404077, 0.7674193301061665, 0.18330540067054635, 0.1553301798026454, 0.16839318394936542, 0.8025939547242359, 0.20788461803011848, 0.7147711167660822, 0.836414744094142, 0.7948373782477776, 0.12659423940961168, 0.8558619002585786, 0.18868553146758382, 0.2003710379036382, 0.1779633789611531, 0.1867325129591343, 0.21877009451217122, 0.1851188699205697, 0.18538773835269862, 0.18705575881167003, 0.16899127761440813, 0.077243001792072, 0.0792303244840199, 0.08746923025707387, 0.07112272177183443, 0.07311984198393673, 0.08259774318144808, 0.08036078786819523, 0.06537377928504606, 0.0744343419763247]}, "mutation_prompt": null}
{"id": "b1c10581-2bf2-4d4c-9a61-a416d2693793", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85  # Increased initial scale factor for exploration\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2  # New parameter to balance exploration and exploitation\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.7, 0.85)\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer with dynamic exploration-exploitation balance and adaptive mutation enhancements for improved convergence speed.", "configspace": "", "generation": 58, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.855172362762411, 0.8659220062066514, 0.8637095763143072, 0.8684988538912858, 0.8706178808280751, 0.8751219187668274, 0.875735912251711, 0.885371256709463, 0.8758475010261377, 0.7897606772692076, 0.7780464349312769, 0.7624645084216468, 0.790407854606426, 0.7684057734533948, 0.7577109760176526, 0.7463787822833655, 0.7635591696458801, 0.779950701825359, 0.13747259024931702, 0.17055399530404325, 0.10616000006249326, 0.1054032523020253, 0.09860999203547127, 0.1492505945832061, 0.13335637946585543, 0.17177438431859848, 0.13050905674168511, 0.12194495847323028, 0.10146753381107443, 0.12917549606342704, 0.09420335672677227, 0.11375308881847501, 0.15008416491683807, 0.13767435057858823, 0.11576480629799935, 0.1288823478391028, 0.923616252156499, 0.9332626390541685, 0.938880057085812, 0.9569887426622138, 0.965427221297927, 0.9546026869304383, 0.9564207320607586, 0.9179055589109922, 0.9596409617365361, 0.6799231502956886, 0.6228315181907147, 0.6053077427826508, 0.643633539398441, 0.6454159831097687, 0.6594364776109957, 0.631077911470128, 0.6268580537351958, 0.6605426909472558, 0.8738257379897179, 0.856710039802895, 0.8528781296374323, 0.8745713666194754, 0.8723434837413657, 0.8649739958849774, 0.8430124741409125, 0.8534555458270078, 0.8270341744551444, 0.551609459177163, 0.6482143574659887, 0.6614293324084707, 0.6270736700295976, 0.6204393695553585, 0.7290196604281876, 0.5295222584265555, 0.6848937949327776, 0.6093807291259528, 0.5465871851585957, 0.4904294373669038, 0.3946434652820141, 0.6080634587822529, 0.5095203797813246, 0.5660126831435907, 0.565944899087218, 0.6275651600885951, 0.6601593986255824, 0.6815124455687847, 0.6854782027332962, 0.6837219132887977, 0.6919529395951656, 0.6662903194597756, 0.6739183325345197, 0.65822892108458, 0.664930023254529, 0.6535756775119573, 0.7392823068939017, 0.7606036896234012, 0.7366869729255578, 0.7567829085685326, 0.7565024511641978, 0.7422584293751445, 0.7414979218067919, 0.7895831302138768, 0.7506469026429001, 0.30000960624512785, 0.24762357706142113, 0.3644720772137978, 0.535693056038617, 0.25791088630295056, 0.5635676852911893, 0.411931198692415, 0.38074161349804125, 0.25527312128765856, 0.5196475226986133, 0.49754361755002785, 0.5619986287546577, 0.5513970794512073, 0.5140282507326093, 0.5540378543456437, 0.5567276713407624, 0.48309762896091235, 0.5926462818682783, 0.8292316049554413, 0.8040513681872443, 0.8231935820366749, 0.8204589686524565, 0.8347687689102576, 0.8283266882051368, 0.8240075686093223, 0.8119240453212864, 0.8478159671843553, 0.08471603955940465, 0.3269841909688398, 0.15584601958897926, 0.11946357558329346, 0.3135240296628693, 0.10580123910878647, 0.09906976740325169, 0.09333877826716819, 0.11331074715137834, 0.5154384242785006, 0.1803933474093794, 0.13860169662543853, 0.14837852583895927, 0.1674644578945137, 0.17496579937812673, 0.15331341602347348, 0.24947180259253354, 0.182268737549234, 0.5005475397078184, 0.4811407806137462, 0.5377490758421786, 0.4867492420791786, 0.47820616455337817, 0.48736033498544773, 0.5242773046718501, 0.5566141040541208, 0.5427556727632223, 0.3896049525718689, 0.41282700043680387, 0.42158935101037176, 0.40232756243805645, 0.38652903995092525, 0.38638984348144334, 0.40047031823279766, 0.45695157847683643, 0.4069924652942214, 0.19933732654038117, 0.18606894657419026, 0.1673109473458444, 0.216324927810446, 0.19287814885471466, 0.1834506894129444, 0.18836828764373648, 0.19333976771871386, 0.20323648161897667, 0.23640093830712194, 0.2199459491448139, 0.19488160744504957, 0.21346316747808358, 0.5834111239602295, 0.5474039843918898, 0.6400349897232377, 0.6421359954798118, 0.22280323530908253, 0.1718399849181258, 0.18627685918462045, 0.16164795410939348, 0.8656755749455405, 0.20396844494786914, 0.8257571772650467, 0.20358013983404077, 0.7674193301061665, 0.18330540067054635, 0.1553301798026454, 0.16839318394936542, 0.8025939547242359, 0.20788461803011848, 0.7147711167660822, 0.836414744094142, 0.7948373782477776, 0.12659423940961168, 0.8558619002585786, 0.18868553146758382, 0.2003710379036382, 0.1779633789611531, 0.1867325129591343, 0.21877009451217122, 0.1851188699205697, 0.18538773835269862, 0.18705575881167003, 0.16899127761440813, 0.077243001792072, 0.0792303244840199, 0.08746923025707387, 0.07112272177183443, 0.07311984198393673, 0.08259774318144808, 0.08036078786819523, 0.06537377928504606, 0.0744343419763247]}, "mutation_prompt": null}
{"id": "c1dfd159-b1bb-4991-bd43-48e3951c2528", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2\n\n    def __call__(self, func):\n        population_size = self.initial_population_size\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n        \n        while func_evals < self.budget:\n            for i in range(population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                dynamic_scale = self.scale_factor + adapt_factor + exploit_factor\n                mutant = a + dynamic_scale * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.75, 0.85)\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n            if np.std(fitness) < 1e-5:\n                population_size = max(4, int(population_size * 0.9))\n                idxs = np.argsort(fitness)[:population_size]\n                population = population[idxs]\n                fitness = fitness[idxs]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "Introducing adaptive population size and dynamic scaling for enhanced convergence in evolutionary optimization.", "configspace": "", "generation": 63, "fitness": 0.4481545324679971, "feedback": "The algorithm EnhancedHybridEvolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.45 with standard deviation 0.26.", "error": "", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.7591366240424189, 0.7191634528499051, 0.7530262463356798, 0.7853977343697462, 0.7437178114497279, 0.7318194971990171, 0.7731672799589469, 0.8540527669315999, 0.8697018932738729, 0.6560265371616691, 0.697092803577104, 0.6591138922553432, 0.6741883534009283, 0.6872179355650614, 0.6450465844729386, 0.7288150418416466, 0.7026526270352207, 0.7040811987753292, 0.30185734074173187, 0.12099471734788636, 0.4178097205504093, 0.11187691039671466, 0.22837302295251216, 0.11560699110155492, 0.3110167098833152, 0.12713104229202488, 0.10543735080031946, 0.1276738851257947, 0.1293555026596439, 0.1023230970043515, 0.07968298502901183, 0.12008879527382943, 0.11787559714098683, 0.12805852380900162, 0.11818675362168651, 0.13332290247431888, 0.9213248737879473, 0.9384779281150003, 0.9733314901400756, 0.9463470498361665, 0.8976048755614546, 0.9694520208302937, 0.9606112248551955, 0.9073103875546006, 0.9425100401139099, 0.5094203067461138, 0.553119465521946, 0.5635988205641966, 0.5318275883398423, 0.5594453192502529, 0.5405576382931361, 0.5762248152652292, 0.5138912216835897, 0.5247612383890775, 0.8386251519294347, 0.84169075920645, 0.8559432158732282, 0.8855958824670307, 0.8570626239586063, 0.849174529094838, 0.872839946808524, 0.8497648270131168, 0.8493125288330671, 0.38439925984803314, 0.582320279291457, 0.5806991699484153, 0.5559837719371453, 0.5763746959532414, 0.5060759104484964, 0.5064554389440904, 0.5312556952404182, 0.5415685646477859, 0.6774198019037516, 0.5033067887043043, 0.12187866406224801, 0.5759170765277909, 0.6087068724033486, 0.5211097933205346, 0.5535184335489431, 0.5820396832679388, 0.5910679317617993, 0.5876341140979918, 0.5340096803562014, 0.5806009551699655, 0.6007032064314028, 0.6061704019439376, 0.5544296349709787, 0.5779595954046258, 0.571151357918284, 0.5712727584119472, 0.6293266683453815, 0.6479694279990809, 0.6079315018939062, 0.6582694286682712, 0.6107556868044957, 0.5884332278125537, 0.6838900482147171, 0.6489942336682429, 0.6215434744276489, 0.24826828485872365, 0.18935452235551697, 0.3550954020818573, 0.46721754393207293, 0.40111575713800784, 0.5131775665236491, 0.39274671960958807, 0.13806895138875208, 0.36091739346045815, 0.4598152908027964, 0.48850676278479654, 0.4962680888490145, 0.48655510660619417, 0.47483872879943734, 0.523258427956264, 0.460814972435731, 0.4997309199207506, 0.4643605291152191, 0.7171534388807059, 0.6866923080319315, 0.7638334247714953, 0.684567069798145, 0.7256302580829839, 0.698376321797496, 0.6435197737346527, 0.6764288415675792, 0.7244270861084824, 0.09760446912466758, 0.0976128975967182, 0.1252618587660469, 0.10266479739278311, 0.11012946101538468, 0.1069321798817291, 0.07729905560407191, 0.09023870311170212, 0.09220668206935967, 0.12947918967765815, 0.15047045282675808, 0.1828923258943279, 0.17676245345499408, 0.17538952063148883, 0.15909746288439308, 0.22624874034724884, 0.18529302751665822, 0.14645422634147487, 0.4211529087246547, 0.48395321851195217, 0.44134586092915706, 0.491111525541548, 0.4481128044837277, 0.48619283128577084, 0.5188022183000354, 0.5294301866401606, 0.4874372921018869, 0.39174263950815147, 0.3734840941391231, 0.417391842269179, 0.3930425519997637, 0.3466024371827585, 0.41429609618289054, 0.39853247095789934, 0.4236824092541226, 0.3859397110220212, 0.1844507052570391, 0.18911470231312988, 0.207070819824675, 0.22092518254970006, 0.22033394731552214, 0.2251483435253573, 0.18327578108060782, 0.190394815752015, 0.19966114470483454, 0.3251329954184158, 0.25984187642828616, 0.4702693293843033, 0.2266698876828086, 0.25311196630611943, 0.21170285805940747, 0.44913569494057404, 0.22090295136931082, 0.21889334042967945, 0.17153380776880545, 0.8463629313577337, 0.8845224031599015, 0.8660085486651501, 0.18485403016055946, 0.18294528603371585, 0.20211315847782418, 0.7256180075045789, 0.8656535501261862, 0.15486237435785133, 0.20877914447404677, 0.851561924653529, 0.20739875954225284, 0.8145551808318163, 0.16419523197553865, 0.15337316360353193, 0.126564482129363, 0.8648132390651657, 0.18117027322286416, 0.1884395567819075, 0.2035885966190759, 0.1929868611327522, 0.18763190978988853, 0.1813876566371042, 0.18215221768270262, 0.17457076903642776, 0.1932697495061082, 0.0706528620335386, 0.07332380246307835, 0.0811150974990631, 0.08545757892274619, 0.07415618112395805, 0.075986281351487, 0.07933402116235544, 0.07595182434260983, 0.09236297995285025]}, "mutation_prompt": null}
{"id": "cdc593e3-03b1-481c-8ab1-fd8987524fea", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85  # Increased initial scale factor for exploration\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2  # New parameter to balance exploration and exploitation\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.7, 0.85)\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer with dynamic exploration-exploitation balance and adaptive mutation enhancements for improved convergence speed.", "configspace": "", "generation": 58, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.855172362762411, 0.8659220062066514, 0.8637095763143072, 0.8684988538912858, 0.8706178808280751, 0.8751219187668274, 0.875735912251711, 0.885371256709463, 0.8758475010261377, 0.7897606772692076, 0.7780464349312769, 0.7624645084216468, 0.790407854606426, 0.7684057734533948, 0.7577109760176526, 0.7463787822833655, 0.7635591696458801, 0.779950701825359, 0.13747259024931702, 0.17055399530404325, 0.10616000006249326, 0.1054032523020253, 0.09860999203547127, 0.1492505945832061, 0.13335637946585543, 0.17177438431859848, 0.13050905674168511, 0.12194495847323028, 0.10146753381107443, 0.12917549606342704, 0.09420335672677227, 0.11375308881847501, 0.15008416491683807, 0.13767435057858823, 0.11576480629799935, 0.1288823478391028, 0.923616252156499, 0.9332626390541685, 0.938880057085812, 0.9569887426622138, 0.965427221297927, 0.9546026869304383, 0.9564207320607586, 0.9179055589109922, 0.9596409617365361, 0.6799231502956886, 0.6228315181907147, 0.6053077427826508, 0.643633539398441, 0.6454159831097687, 0.6594364776109957, 0.631077911470128, 0.6268580537351958, 0.6605426909472558, 0.8738257379897179, 0.856710039802895, 0.8528781296374323, 0.8745713666194754, 0.8723434837413657, 0.8649739958849774, 0.8430124741409125, 0.8534555458270078, 0.8270341744551444, 0.551609459177163, 0.6482143574659887, 0.6614293324084707, 0.6270736700295976, 0.6204393695553585, 0.7290196604281876, 0.5295222584265555, 0.6848937949327776, 0.6093807291259528, 0.5465871851585957, 0.4904294373669038, 0.3946434652820141, 0.6080634587822529, 0.5095203797813246, 0.5660126831435907, 0.565944899087218, 0.6275651600885951, 0.6601593986255824, 0.6815124455687847, 0.6854782027332962, 0.6837219132887977, 0.6919529395951656, 0.6662903194597756, 0.6739183325345197, 0.65822892108458, 0.664930023254529, 0.6535756775119573, 0.7392823068939017, 0.7606036896234012, 0.7366869729255578, 0.7567829085685326, 0.7565024511641978, 0.7422584293751445, 0.7414979218067919, 0.7895831302138768, 0.7506469026429001, 0.30000960624512785, 0.24762357706142113, 0.3644720772137978, 0.535693056038617, 0.25791088630295056, 0.5635676852911893, 0.411931198692415, 0.38074161349804125, 0.25527312128765856, 0.5196475226986133, 0.49754361755002785, 0.5619986287546577, 0.5513970794512073, 0.5140282507326093, 0.5540378543456437, 0.5567276713407624, 0.48309762896091235, 0.5926462818682783, 0.8292316049554413, 0.8040513681872443, 0.8231935820366749, 0.8204589686524565, 0.8347687689102576, 0.8283266882051368, 0.8240075686093223, 0.8119240453212864, 0.8478159671843553, 0.08471603955940465, 0.3269841909688398, 0.15584601958897926, 0.11946357558329346, 0.3135240296628693, 0.10580123910878647, 0.09906976740325169, 0.09333877826716819, 0.11331074715137834, 0.5154384242785006, 0.1803933474093794, 0.13860169662543853, 0.14837852583895927, 0.1674644578945137, 0.17496579937812673, 0.15331341602347348, 0.24947180259253354, 0.182268737549234, 0.5005475397078184, 0.4811407806137462, 0.5377490758421786, 0.4867492420791786, 0.47820616455337817, 0.48736033498544773, 0.5242773046718501, 0.5566141040541208, 0.5427556727632223, 0.3896049525718689, 0.41282700043680387, 0.42158935101037176, 0.40232756243805645, 0.38652903995092525, 0.38638984348144334, 0.40047031823279766, 0.45695157847683643, 0.4069924652942214, 0.19933732654038117, 0.18606894657419026, 0.1673109473458444, 0.216324927810446, 0.19287814885471466, 0.1834506894129444, 0.18836828764373648, 0.19333976771871386, 0.20323648161897667, 0.23640093830712194, 0.2199459491448139, 0.19488160744504957, 0.21346316747808358, 0.5834111239602295, 0.5474039843918898, 0.6400349897232377, 0.6421359954798118, 0.22280323530908253, 0.1718399849181258, 0.18627685918462045, 0.16164795410939348, 0.8656755749455405, 0.20396844494786914, 0.8257571772650467, 0.20358013983404077, 0.7674193301061665, 0.18330540067054635, 0.1553301798026454, 0.16839318394936542, 0.8025939547242359, 0.20788461803011848, 0.7147711167660822, 0.836414744094142, 0.7948373782477776, 0.12659423940961168, 0.8558619002585786, 0.18868553146758382, 0.2003710379036382, 0.1779633789611531, 0.1867325129591343, 0.21877009451217122, 0.1851188699205697, 0.18538773835269862, 0.18705575881167003, 0.16899127761440813, 0.077243001792072, 0.0792303244840199, 0.08746923025707387, 0.07112272177183443, 0.07311984198393673, 0.08259774318144808, 0.08036078786819523, 0.06537377928504606, 0.0744343419763247]}, "mutation_prompt": null}
{"id": "6e0d2a0a-8829-442f-bc2e-71219175dfb1", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85  # Increased initial scale factor for exploration\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2  # New parameter to balance exploration and exploitation\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.7, 0.85)\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer with dynamic exploration-exploitation balance and adaptive mutation enhancements for improved convergence speed.", "configspace": "", "generation": 58, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.855172362762411, 0.8659220062066514, 0.8637095763143072, 0.8684988538912858, 0.8706178808280751, 0.8751219187668274, 0.875735912251711, 0.885371256709463, 0.8758475010261377, 0.7897606772692076, 0.7780464349312769, 0.7624645084216468, 0.790407854606426, 0.7684057734533948, 0.7577109760176526, 0.7463787822833655, 0.7635591696458801, 0.779950701825359, 0.13747259024931702, 0.17055399530404325, 0.10616000006249326, 0.1054032523020253, 0.09860999203547127, 0.1492505945832061, 0.13335637946585543, 0.17177438431859848, 0.13050905674168511, 0.12194495847323028, 0.10146753381107443, 0.12917549606342704, 0.09420335672677227, 0.11375308881847501, 0.15008416491683807, 0.13767435057858823, 0.11576480629799935, 0.1288823478391028, 0.923616252156499, 0.9332626390541685, 0.938880057085812, 0.9569887426622138, 0.965427221297927, 0.9546026869304383, 0.9564207320607586, 0.9179055589109922, 0.9596409617365361, 0.6799231502956886, 0.6228315181907147, 0.6053077427826508, 0.643633539398441, 0.6454159831097687, 0.6594364776109957, 0.631077911470128, 0.6268580537351958, 0.6605426909472558, 0.8738257379897179, 0.856710039802895, 0.8528781296374323, 0.8745713666194754, 0.8723434837413657, 0.8649739958849774, 0.8430124741409125, 0.8534555458270078, 0.8270341744551444, 0.551609459177163, 0.6482143574659887, 0.6614293324084707, 0.6270736700295976, 0.6204393695553585, 0.7290196604281876, 0.5295222584265555, 0.6848937949327776, 0.6093807291259528, 0.5465871851585957, 0.4904294373669038, 0.3946434652820141, 0.6080634587822529, 0.5095203797813246, 0.5660126831435907, 0.565944899087218, 0.6275651600885951, 0.6601593986255824, 0.6815124455687847, 0.6854782027332962, 0.6837219132887977, 0.6919529395951656, 0.6662903194597756, 0.6739183325345197, 0.65822892108458, 0.664930023254529, 0.6535756775119573, 0.7392823068939017, 0.7606036896234012, 0.7366869729255578, 0.7567829085685326, 0.7565024511641978, 0.7422584293751445, 0.7414979218067919, 0.7895831302138768, 0.7506469026429001, 0.30000960624512785, 0.24762357706142113, 0.3644720772137978, 0.535693056038617, 0.25791088630295056, 0.5635676852911893, 0.411931198692415, 0.38074161349804125, 0.25527312128765856, 0.5196475226986133, 0.49754361755002785, 0.5619986287546577, 0.5513970794512073, 0.5140282507326093, 0.5540378543456437, 0.5567276713407624, 0.48309762896091235, 0.5926462818682783, 0.8292316049554413, 0.8040513681872443, 0.8231935820366749, 0.8204589686524565, 0.8347687689102576, 0.8283266882051368, 0.8240075686093223, 0.8119240453212864, 0.8478159671843553, 0.08471603955940465, 0.3269841909688398, 0.15584601958897926, 0.11946357558329346, 0.3135240296628693, 0.10580123910878647, 0.09906976740325169, 0.09333877826716819, 0.11331074715137834, 0.5154384242785006, 0.1803933474093794, 0.13860169662543853, 0.14837852583895927, 0.1674644578945137, 0.17496579937812673, 0.15331341602347348, 0.24947180259253354, 0.182268737549234, 0.5005475397078184, 0.4811407806137462, 0.5377490758421786, 0.4867492420791786, 0.47820616455337817, 0.48736033498544773, 0.5242773046718501, 0.5566141040541208, 0.5427556727632223, 0.3896049525718689, 0.41282700043680387, 0.42158935101037176, 0.40232756243805645, 0.38652903995092525, 0.38638984348144334, 0.40047031823279766, 0.45695157847683643, 0.4069924652942214, 0.19933732654038117, 0.18606894657419026, 0.1673109473458444, 0.216324927810446, 0.19287814885471466, 0.1834506894129444, 0.18836828764373648, 0.19333976771871386, 0.20323648161897667, 0.23640093830712194, 0.2199459491448139, 0.19488160744504957, 0.21346316747808358, 0.5834111239602295, 0.5474039843918898, 0.6400349897232377, 0.6421359954798118, 0.22280323530908253, 0.1718399849181258, 0.18627685918462045, 0.16164795410939348, 0.8656755749455405, 0.20396844494786914, 0.8257571772650467, 0.20358013983404077, 0.7674193301061665, 0.18330540067054635, 0.1553301798026454, 0.16839318394936542, 0.8025939547242359, 0.20788461803011848, 0.7147711167660822, 0.836414744094142, 0.7948373782477776, 0.12659423940961168, 0.8558619002585786, 0.18868553146758382, 0.2003710379036382, 0.1779633789611531, 0.1867325129591343, 0.21877009451217122, 0.1851188699205697, 0.18538773835269862, 0.18705575881167003, 0.16899127761440813, 0.077243001792072, 0.0792303244840199, 0.08746923025707387, 0.07112272177183443, 0.07311984198393673, 0.08259774318144808, 0.08036078786819523, 0.06537377928504606, 0.0744343419763247]}, "mutation_prompt": null}
{"id": "729a8d96-a271-4cae-a8d6-acbfd50a0ce8", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2\n\n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            global_best_idx = np.argmin(fitness)\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                herd_influence = 0.1 * (population[global_best_idx] - population[i])  # New herd behavior influence\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c) + herd_influence\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.75, 0.85)  # Slightly adjust range for diversity\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedAdaptiveHybridOptimizer", "description": "EnhancedAdaptiveHybridOptimizer with dynamic herd behavior and adaptive individual scaling for accelerated convergence.", "configspace": "", "generation": 66, "fitness": 0.45496187219988693, "feedback": "The algorithm EnhancedAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.45 with standard deviation 0.29.", "error": "", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.855961826808073, 0.8501141374691916, 0.8495443050175703, 0.8609968623325142, 0.8496031028060362, 0.8690388777872047, 0.8581258448323716, 0.8525296797922877, 0.8745604240245998, 0.7276173666045244, 0.746779658420136, 0.7589405226612845, 0.7742248693815348, 0.7459532945128775, 0.7756040836445406, 0.7487126381757282, 0.7642570492180187, 0.7658281458387776, 0.09953302125294927, 0.12019244995079137, 0.10593255773075594, 0.09806739782407681, 0.10514970832668191, 0.11645370689543366, 0.10601248423607779, 0.09644874610296084, 0.10774819335026298, 0.11744499874247938, 0.10613833787919646, 0.10689289448663764, 0.10720147525564205, 0.09076369047928123, 0.10474882582930245, 0.09417815574643851, 0.10782740889741127, 0.08443815440018754, 0.962379272462952, 0.9423953617919475, 0.9566924296250457, 0.9279416639084496, 0.9740380105523131, 0.9669647964338517, 0.970947208765886, 0.9521946111183426, 0.9854315039939494, 0.6621178885282875, 0.6605261609547397, 0.660055060231461, 0.6701831977657208, 0.6542787425654095, 0.6412346955375896, 0.6493692134454072, 0.6540522561942018, 0.6502503923166754, 0.7989921529828132, 0.8240498371670912, 0.8517653354791755, 0.8054562735365227, 0.8738434685746007, 0.8292204751527166, 0.825761441148724, 0.7872209179722194, 0.8354673534669144, 0.6071963577042716, 0.6174051040814427, 0.659969790434339, 0.630592095803573, 0.5644800430861291, 0.5811110952720664, 0.4438553844688232, 0.726817797822185, 0.6623932744871881, 0.5411822267902433, 0.5125530520266636, 0.5395801213501503, 0.5427554276201028, 0.6156754277137017, 0.5593743142711822, 0.6013484943565544, 0.6321926615565586, 0.5769252574771389, 0.6941852655583659, 0.6070512089224318, 0.6467869545474196, 0.6777655315838838, 0.6057784639796344, 0.62899593621186, 0.6133004047212733, 0.6421444852178575, 0.6806024065170304, 0.7268877979198258, 0.6964979262167512, 0.7156011081438829, 0.7013777667264463, 0.7289524781486642, 0.7020894193519609, 0.7386741008829749, 0.730116180191942, 0.7208164862130636, 0.14942396790893175, 0.42689918199139854, 0.37460641987278287, 0.5454421989380487, 0.21632424909829706, 0.3049748483599799, 0.3636165181567904, 0.3832883111342855, 0.22037970141036456, 0.47695629746014057, 0.46862188045509023, 0.5216414885655016, 0.5266803177078803, 0.5043139643855186, 0.5233757451874002, 0.48121068249612087, 0.04823274897465146, 0.5131138278924428, 0.8242552295928276, 0.7902514940974559, 0.7973398775761156, 0.8258102506598717, 0.7889110881079936, 0.8017325581308498, 0.7971217852695829, 0.7809154685879792, 0.8105026408736171, 0.0977192154303348, 0.10898842882775917, 0.0994233021121832, 0.10212175608934759, 0.10050971595277702, 0.10992873196545083, 0.09116174252044007, 0.09408935687379183, 0.11007356762047571, 0.1444643499113163, 0.14572423580415694, 0.1469001503070665, 0.13307721540259532, 0.256125199396923, 0.13063613076717862, 0.1882735880709293, 0.1434501405865587, 0.16235834412824168, 0.457325231987455, 0.4886996135715964, 0.48748401754041326, 0.4873419353952495, 0.468026490320531, 0.45796157912074564, 0.44661311111939117, 0.463812574380598, 0.4812000522641836, 0.3837214304335784, 0.3471050439622534, 0.3916485626240678, 0.34412863291492135, 0.3551609014197544, 0.40759506656000266, 0.3750170515359218, 0.3921164945564619, 0.36418138854996707, 0.1763539780092055, 0.22666073109300255, 0.20499453891621056, 0.2115388952800552, 0.1907523597949049, 0.21330572010851367, 0.19115656346379384, 0.1866756084849167, 0.19551198876375042, 0.1795853286255238, 0.20838089887546496, 0.1775726314571502, 0.2649827752813422, 0.2170096384223379, 0.17932534457827465, 0.1845417508834939, 0.17443976809069917, 0.18338225370360117, 0.1695562884106666, 0.19199051164667658, 0.8615339836297246, 0.6361481401775886, 0.17678106132146643, 0.8812979276334059, 0.6703325216505948, 0.1943532936477127, 0.8150490792486111, 0.154548153046973, 0.20911548052100482, 0.30943925607844125, 0.20855002139137746, 0.7464000170631582, 0.16467241216671102, 0.12715701499870924, 0.12789240617344255, 0.21011746427774092, 0.20391859900764542, 0.17422916352081097, 0.17983711066744013, 0.19455831138129054, 0.17972058930212065, 0.17381088278234025, 0.19180560987576856, 0.17960799466659738, 0.19387768440633657, 0.07687902663174939, 0.07859532159419413, 0.0735639617774666, 0.08111099557018975, 0.07719706267686, 0.08612043146901871, 0.07397777281198636, 0.07319007258724908, 0.07912443884931086]}, "mutation_prompt": null}
{"id": "21a7089a-c3cb-45d8-86f8-ee9881a7d3d1", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85  # Increased initial scale factor for exploration\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2  # New parameter to balance exploration and exploitation\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.7, 0.85)\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer with dynamic exploration-exploitation balance and adaptive mutation enhancements for improved convergence speed.", "configspace": "", "generation": 58, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.855172362762411, 0.8659220062066514, 0.8637095763143072, 0.8684988538912858, 0.8706178808280751, 0.8751219187668274, 0.875735912251711, 0.885371256709463, 0.8758475010261377, 0.7897606772692076, 0.7780464349312769, 0.7624645084216468, 0.790407854606426, 0.7684057734533948, 0.7577109760176526, 0.7463787822833655, 0.7635591696458801, 0.779950701825359, 0.13747259024931702, 0.17055399530404325, 0.10616000006249326, 0.1054032523020253, 0.09860999203547127, 0.1492505945832061, 0.13335637946585543, 0.17177438431859848, 0.13050905674168511, 0.12194495847323028, 0.10146753381107443, 0.12917549606342704, 0.09420335672677227, 0.11375308881847501, 0.15008416491683807, 0.13767435057858823, 0.11576480629799935, 0.1288823478391028, 0.923616252156499, 0.9332626390541685, 0.938880057085812, 0.9569887426622138, 0.965427221297927, 0.9546026869304383, 0.9564207320607586, 0.9179055589109922, 0.9596409617365361, 0.6799231502956886, 0.6228315181907147, 0.6053077427826508, 0.643633539398441, 0.6454159831097687, 0.6594364776109957, 0.631077911470128, 0.6268580537351958, 0.6605426909472558, 0.8738257379897179, 0.856710039802895, 0.8528781296374323, 0.8745713666194754, 0.8723434837413657, 0.8649739958849774, 0.8430124741409125, 0.8534555458270078, 0.8270341744551444, 0.551609459177163, 0.6482143574659887, 0.6614293324084707, 0.6270736700295976, 0.6204393695553585, 0.7290196604281876, 0.5295222584265555, 0.6848937949327776, 0.6093807291259528, 0.5465871851585957, 0.4904294373669038, 0.3946434652820141, 0.6080634587822529, 0.5095203797813246, 0.5660126831435907, 0.565944899087218, 0.6275651600885951, 0.6601593986255824, 0.6815124455687847, 0.6854782027332962, 0.6837219132887977, 0.6919529395951656, 0.6662903194597756, 0.6739183325345197, 0.65822892108458, 0.664930023254529, 0.6535756775119573, 0.7392823068939017, 0.7606036896234012, 0.7366869729255578, 0.7567829085685326, 0.7565024511641978, 0.7422584293751445, 0.7414979218067919, 0.7895831302138768, 0.7506469026429001, 0.30000960624512785, 0.24762357706142113, 0.3644720772137978, 0.535693056038617, 0.25791088630295056, 0.5635676852911893, 0.411931198692415, 0.38074161349804125, 0.25527312128765856, 0.5196475226986133, 0.49754361755002785, 0.5619986287546577, 0.5513970794512073, 0.5140282507326093, 0.5540378543456437, 0.5567276713407624, 0.48309762896091235, 0.5926462818682783, 0.8292316049554413, 0.8040513681872443, 0.8231935820366749, 0.8204589686524565, 0.8347687689102576, 0.8283266882051368, 0.8240075686093223, 0.8119240453212864, 0.8478159671843553, 0.08471603955940465, 0.3269841909688398, 0.15584601958897926, 0.11946357558329346, 0.3135240296628693, 0.10580123910878647, 0.09906976740325169, 0.09333877826716819, 0.11331074715137834, 0.5154384242785006, 0.1803933474093794, 0.13860169662543853, 0.14837852583895927, 0.1674644578945137, 0.17496579937812673, 0.15331341602347348, 0.24947180259253354, 0.182268737549234, 0.5005475397078184, 0.4811407806137462, 0.5377490758421786, 0.4867492420791786, 0.47820616455337817, 0.48736033498544773, 0.5242773046718501, 0.5566141040541208, 0.5427556727632223, 0.3896049525718689, 0.41282700043680387, 0.42158935101037176, 0.40232756243805645, 0.38652903995092525, 0.38638984348144334, 0.40047031823279766, 0.45695157847683643, 0.4069924652942214, 0.19933732654038117, 0.18606894657419026, 0.1673109473458444, 0.216324927810446, 0.19287814885471466, 0.1834506894129444, 0.18836828764373648, 0.19333976771871386, 0.20323648161897667, 0.23640093830712194, 0.2199459491448139, 0.19488160744504957, 0.21346316747808358, 0.5834111239602295, 0.5474039843918898, 0.6400349897232377, 0.6421359954798118, 0.22280323530908253, 0.1718399849181258, 0.18627685918462045, 0.16164795410939348, 0.8656755749455405, 0.20396844494786914, 0.8257571772650467, 0.20358013983404077, 0.7674193301061665, 0.18330540067054635, 0.1553301798026454, 0.16839318394936542, 0.8025939547242359, 0.20788461803011848, 0.7147711167660822, 0.836414744094142, 0.7948373782477776, 0.12659423940961168, 0.8558619002585786, 0.18868553146758382, 0.2003710379036382, 0.1779633789611531, 0.1867325129591343, 0.21877009451217122, 0.1851188699205697, 0.18538773835269862, 0.18705575881167003, 0.16899127761440813, 0.077243001792072, 0.0792303244840199, 0.08746923025707387, 0.07112272177183443, 0.07311984198393673, 0.08259774318144808, 0.08036078786819523, 0.06537377928504606, 0.0744343419763247]}, "mutation_prompt": null}
{"id": "d89c1302-85a5-463a-b925-44a9e00b2000", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85  # Increased initial scale factor for exploration\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2  # New parameter to balance exploration and exploitation\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.7, 0.85)\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer with dynamic exploration-exploitation balance and adaptive mutation enhancements for improved convergence speed.", "configspace": "", "generation": 58, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.855172362762411, 0.8659220062066514, 0.8637095763143072, 0.8684988538912858, 0.8706178808280751, 0.8751219187668274, 0.875735912251711, 0.885371256709463, 0.8758475010261377, 0.7897606772692076, 0.7780464349312769, 0.7624645084216468, 0.790407854606426, 0.7684057734533948, 0.7577109760176526, 0.7463787822833655, 0.7635591696458801, 0.779950701825359, 0.13747259024931702, 0.17055399530404325, 0.10616000006249326, 0.1054032523020253, 0.09860999203547127, 0.1492505945832061, 0.13335637946585543, 0.17177438431859848, 0.13050905674168511, 0.12194495847323028, 0.10146753381107443, 0.12917549606342704, 0.09420335672677227, 0.11375308881847501, 0.15008416491683807, 0.13767435057858823, 0.11576480629799935, 0.1288823478391028, 0.923616252156499, 0.9332626390541685, 0.938880057085812, 0.9569887426622138, 0.965427221297927, 0.9546026869304383, 0.9564207320607586, 0.9179055589109922, 0.9596409617365361, 0.6799231502956886, 0.6228315181907147, 0.6053077427826508, 0.643633539398441, 0.6454159831097687, 0.6594364776109957, 0.631077911470128, 0.6268580537351958, 0.6605426909472558, 0.8738257379897179, 0.856710039802895, 0.8528781296374323, 0.8745713666194754, 0.8723434837413657, 0.8649739958849774, 0.8430124741409125, 0.8534555458270078, 0.8270341744551444, 0.551609459177163, 0.6482143574659887, 0.6614293324084707, 0.6270736700295976, 0.6204393695553585, 0.7290196604281876, 0.5295222584265555, 0.6848937949327776, 0.6093807291259528, 0.5465871851585957, 0.4904294373669038, 0.3946434652820141, 0.6080634587822529, 0.5095203797813246, 0.5660126831435907, 0.565944899087218, 0.6275651600885951, 0.6601593986255824, 0.6815124455687847, 0.6854782027332962, 0.6837219132887977, 0.6919529395951656, 0.6662903194597756, 0.6739183325345197, 0.65822892108458, 0.664930023254529, 0.6535756775119573, 0.7392823068939017, 0.7606036896234012, 0.7366869729255578, 0.7567829085685326, 0.7565024511641978, 0.7422584293751445, 0.7414979218067919, 0.7895831302138768, 0.7506469026429001, 0.30000960624512785, 0.24762357706142113, 0.3644720772137978, 0.535693056038617, 0.25791088630295056, 0.5635676852911893, 0.411931198692415, 0.38074161349804125, 0.25527312128765856, 0.5196475226986133, 0.49754361755002785, 0.5619986287546577, 0.5513970794512073, 0.5140282507326093, 0.5540378543456437, 0.5567276713407624, 0.48309762896091235, 0.5926462818682783, 0.8292316049554413, 0.8040513681872443, 0.8231935820366749, 0.8204589686524565, 0.8347687689102576, 0.8283266882051368, 0.8240075686093223, 0.8119240453212864, 0.8478159671843553, 0.08471603955940465, 0.3269841909688398, 0.15584601958897926, 0.11946357558329346, 0.3135240296628693, 0.10580123910878647, 0.09906976740325169, 0.09333877826716819, 0.11331074715137834, 0.5154384242785006, 0.1803933474093794, 0.13860169662543853, 0.14837852583895927, 0.1674644578945137, 0.17496579937812673, 0.15331341602347348, 0.24947180259253354, 0.182268737549234, 0.5005475397078184, 0.4811407806137462, 0.5377490758421786, 0.4867492420791786, 0.47820616455337817, 0.48736033498544773, 0.5242773046718501, 0.5566141040541208, 0.5427556727632223, 0.3896049525718689, 0.41282700043680387, 0.42158935101037176, 0.40232756243805645, 0.38652903995092525, 0.38638984348144334, 0.40047031823279766, 0.45695157847683643, 0.4069924652942214, 0.19933732654038117, 0.18606894657419026, 0.1673109473458444, 0.216324927810446, 0.19287814885471466, 0.1834506894129444, 0.18836828764373648, 0.19333976771871386, 0.20323648161897667, 0.23640093830712194, 0.2199459491448139, 0.19488160744504957, 0.21346316747808358, 0.5834111239602295, 0.5474039843918898, 0.6400349897232377, 0.6421359954798118, 0.22280323530908253, 0.1718399849181258, 0.18627685918462045, 0.16164795410939348, 0.8656755749455405, 0.20396844494786914, 0.8257571772650467, 0.20358013983404077, 0.7674193301061665, 0.18330540067054635, 0.1553301798026454, 0.16839318394936542, 0.8025939547242359, 0.20788461803011848, 0.7147711167660822, 0.836414744094142, 0.7948373782477776, 0.12659423940961168, 0.8558619002585786, 0.18868553146758382, 0.2003710379036382, 0.1779633789611531, 0.1867325129591343, 0.21877009451217122, 0.1851188699205697, 0.18538773835269862, 0.18705575881167003, 0.16899127761440813, 0.077243001792072, 0.0792303244840199, 0.08746923025707387, 0.07112272177183443, 0.07311984198393673, 0.08259774318144808, 0.08036078786819523, 0.06537377928504606, 0.0744343419763247]}, "mutation_prompt": null}
{"id": "018adec3-a7e0-4be6-a718-292cdbee9247", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8  # Slightly adjusted for balance\n        self.cross_prob = 0.95  # Slightly increased for better diversity\n        self.adaptation_rate = 0.1  # Increased adaptation rate\n        self.exploit_factor = 0.25  # Enhanced exploitation factor\n        self.replacement_factor = 0.2  # New parameter for diversity\n\n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n\n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                elif np.random.rand() < self.replacement_factor:\n                    population[i] = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    fitness[i] = func(population[i])\n                    func_evals += 1\n\n            self.scale_factor = np.random.uniform(0.75, 0.8)\n            self.cross_prob = np.random.uniform(0.9, 0.95)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer with enhanced diversity mechanisms and adaptive parameter tuning for accelerated convergence.", "configspace": "", "generation": 69, "fitness": 0.14186902629445197, "feedback": "The algorithm ImprovedHybridEvolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.19.", "error": "", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.24852772968507775, 0.21055375984798197, 0.24610415399540586, 0.239512471426799, 0.2814684040621589, 0.244570131432565, 0.2648766312144023, 0.25896509326724504, 0.24010803709796336, 0.0074714523787233755, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.056246839173706764, 0.06933787329691565, 0.060660709718793226, 0.07330711063731066, 0.05434796481063531, 0.05453805360901587, 0.056911904460304696, 0.054693997828775154, 0.059459464460460354, 0.04145493489672991, 0.03676544591939057, 0.05657789262377155, 0.07721078206636289, 0.03740829020994463, 0.0513715154509895, 0.044588366459544115, 0.04657620274561891, 0.031148975629431752, 0.9847535824909015, 0.9821465872691635, 0.9787026201086232, 0.983911629094215, 0.9857921848782932, 0.979442154564525, 0.9633306169168121, 0.9802342373592301, 0.9614724676652391, 0.0873188236174417, 0.09791233600937665, 0.10918506188919497, 0.08934496691979055, 0.08090890840236753, 0.08164132176879024, 0.10323994348055543, 0.0926733236981232, 0.10076268037352143, 0.18414890837634423, 0.169408420171969, 0.16051051620696177, 0.14637722155360167, 0.18629830070563358, 0.175700748440051, 0.14642412839146912, 0.15022782362443887, 0.16972870122171513, 0.005458068565200258, 0.04939070071607077, 0.01341871946752693, 0.05647223533536416, 0.024487032913723117, 0.039982158801452394, 0.05164826581025661, 0.011353116211231251, 0.027230501268618035, 0.03544455442600103, 0.03385805478720827, 0.046190958302022245, 0.04818114432676135, 0.03491635737885024, 0.01041194581745053, 0.03227865440480038, 0.03483978271358734, 0.023773048048114864, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05076726766834294, 0.06606982267823658, 0.0529844585166338, 0.05778630248055483, 0.09285227632392856, 0.08692858308272133, 0.07998017409521363, 0.07600159268149365, 0.047565033456600236, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01521286926597365, 0.006531802884853777, 0.019665047702097427, 0.006478481396945068, 0.003998160502736159, 0.0014424043862374392, 0.025097454329751412, 0.021892693237012262, 0.019608027883461943, 0.22167477064952668, 0.253671448348758, 0.2304197536677559, 0.2225698762690994, 0.23643137222501487, 0.250339172747044, 0.25735238871592214, 0.23095430438460784, 0.2201025790984631, 0.07228861642017115, 0.06763243148809839, 0.059774507488035145, 0.07372382673341671, 0.06567384281131106, 0.08365310603118814, 0.056252984059455, 0.049908520962642755, 0.06253336238535667, 0.14910986423429817, 0.13676543042516265, 0.15299268280175438, 0.14096601931596342, 0.15013555448144456, 0.15227512723414616, 0.11847503680294336, 0.13623325354308347, 0.13528309458254262, 0.20232788516563693, 0.18152882616602695, 0.18251237027053735, 0.17473533539503228, 0.1868919479073078, 0.16722098613353897, 0.1849306701305301, 0.18646121669679672, 0.1928547989125674, 0.1274927209269605, 0.13465498247887042, 0.11487139877415087, 0.11371661300913782, 0.11802445678816764, 0.12258595077691681, 0.13389108636137848, 0.12066579178711379, 0.11534897398570065, 0.16144614565218085, 0.1706803630746757, 0.16550722471344015, 0.17823549950991657, 0.17509286130809976, 0.16400600236695284, 0.1569128502354331, 0.17703644647177919, 0.1763790854037106, 0.15662649359158953, 0.16072550777834982, 0.15408030110143023, 0.1722961604087926, 0.15832744288183276, 0.14952795379924533, 0.15309997814052334, 0.15919906784579585, 0.15623357871194532, 0.1711523503225022, 0.17572883730353062, 0.1601770477747665, 0.17832633238182172, 0.21631044689224466, 0.19113249721695558, 0.1517745790304973, 0.16702276186025233, 0.16482994859483002, 0.18109315880919763, 0.16101332625224518, 0.1622855368735474, 0.15156654838294503, 0.15730702424171672, 0.13787958399256317, 0.19766275040275327, 0.19661407008868714, 0.15702304214957674, 0.18463769687465714, 0.19237108152765248, 0.20258321127039958, 0.18535217803645743, 0.17883063583123515, 0.18826590674064692, 0.19847186618278678, 0.18974108652270327, 0.18430908061544338, 0.0629308797853475, 0.05392790306311146, 0.06375268845261339, 0.056967357653609385, 0.05450611041507181, 0.04929514373025978, 0.05816885809263206, 0.052154986504872936, 0.06606110769081175]}, "mutation_prompt": null}
{"id": "f52e378f-56f2-4813-9a8a-e910c32cbacb", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85  # Increased initial scale factor for exploration\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2  # New parameter to balance exploration and exploitation\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.7, 0.85)\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer with dynamic exploration-exploitation balance and adaptive mutation enhancements for improved convergence speed.", "configspace": "", "generation": 58, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.855172362762411, 0.8659220062066514, 0.8637095763143072, 0.8684988538912858, 0.8706178808280751, 0.8751219187668274, 0.875735912251711, 0.885371256709463, 0.8758475010261377, 0.7897606772692076, 0.7780464349312769, 0.7624645084216468, 0.790407854606426, 0.7684057734533948, 0.7577109760176526, 0.7463787822833655, 0.7635591696458801, 0.779950701825359, 0.13747259024931702, 0.17055399530404325, 0.10616000006249326, 0.1054032523020253, 0.09860999203547127, 0.1492505945832061, 0.13335637946585543, 0.17177438431859848, 0.13050905674168511, 0.12194495847323028, 0.10146753381107443, 0.12917549606342704, 0.09420335672677227, 0.11375308881847501, 0.15008416491683807, 0.13767435057858823, 0.11576480629799935, 0.1288823478391028, 0.923616252156499, 0.9332626390541685, 0.938880057085812, 0.9569887426622138, 0.965427221297927, 0.9546026869304383, 0.9564207320607586, 0.9179055589109922, 0.9596409617365361, 0.6799231502956886, 0.6228315181907147, 0.6053077427826508, 0.643633539398441, 0.6454159831097687, 0.6594364776109957, 0.631077911470128, 0.6268580537351958, 0.6605426909472558, 0.8738257379897179, 0.856710039802895, 0.8528781296374323, 0.8745713666194754, 0.8723434837413657, 0.8649739958849774, 0.8430124741409125, 0.8534555458270078, 0.8270341744551444, 0.551609459177163, 0.6482143574659887, 0.6614293324084707, 0.6270736700295976, 0.6204393695553585, 0.7290196604281876, 0.5295222584265555, 0.6848937949327776, 0.6093807291259528, 0.5465871851585957, 0.4904294373669038, 0.3946434652820141, 0.6080634587822529, 0.5095203797813246, 0.5660126831435907, 0.565944899087218, 0.6275651600885951, 0.6601593986255824, 0.6815124455687847, 0.6854782027332962, 0.6837219132887977, 0.6919529395951656, 0.6662903194597756, 0.6739183325345197, 0.65822892108458, 0.664930023254529, 0.6535756775119573, 0.7392823068939017, 0.7606036896234012, 0.7366869729255578, 0.7567829085685326, 0.7565024511641978, 0.7422584293751445, 0.7414979218067919, 0.7895831302138768, 0.7506469026429001, 0.30000960624512785, 0.24762357706142113, 0.3644720772137978, 0.535693056038617, 0.25791088630295056, 0.5635676852911893, 0.411931198692415, 0.38074161349804125, 0.25527312128765856, 0.5196475226986133, 0.49754361755002785, 0.5619986287546577, 0.5513970794512073, 0.5140282507326093, 0.5540378543456437, 0.5567276713407624, 0.48309762896091235, 0.5926462818682783, 0.8292316049554413, 0.8040513681872443, 0.8231935820366749, 0.8204589686524565, 0.8347687689102576, 0.8283266882051368, 0.8240075686093223, 0.8119240453212864, 0.8478159671843553, 0.08471603955940465, 0.3269841909688398, 0.15584601958897926, 0.11946357558329346, 0.3135240296628693, 0.10580123910878647, 0.09906976740325169, 0.09333877826716819, 0.11331074715137834, 0.5154384242785006, 0.1803933474093794, 0.13860169662543853, 0.14837852583895927, 0.1674644578945137, 0.17496579937812673, 0.15331341602347348, 0.24947180259253354, 0.182268737549234, 0.5005475397078184, 0.4811407806137462, 0.5377490758421786, 0.4867492420791786, 0.47820616455337817, 0.48736033498544773, 0.5242773046718501, 0.5566141040541208, 0.5427556727632223, 0.3896049525718689, 0.41282700043680387, 0.42158935101037176, 0.40232756243805645, 0.38652903995092525, 0.38638984348144334, 0.40047031823279766, 0.45695157847683643, 0.4069924652942214, 0.19933732654038117, 0.18606894657419026, 0.1673109473458444, 0.216324927810446, 0.19287814885471466, 0.1834506894129444, 0.18836828764373648, 0.19333976771871386, 0.20323648161897667, 0.23640093830712194, 0.2199459491448139, 0.19488160744504957, 0.21346316747808358, 0.5834111239602295, 0.5474039843918898, 0.6400349897232377, 0.6421359954798118, 0.22280323530908253, 0.1718399849181258, 0.18627685918462045, 0.16164795410939348, 0.8656755749455405, 0.20396844494786914, 0.8257571772650467, 0.20358013983404077, 0.7674193301061665, 0.18330540067054635, 0.1553301798026454, 0.16839318394936542, 0.8025939547242359, 0.20788461803011848, 0.7147711167660822, 0.836414744094142, 0.7948373782477776, 0.12659423940961168, 0.8558619002585786, 0.18868553146758382, 0.2003710379036382, 0.1779633789611531, 0.1867325129591343, 0.21877009451217122, 0.1851188699205697, 0.18538773835269862, 0.18705575881167003, 0.16899127761440813, 0.077243001792072, 0.0792303244840199, 0.08746923025707387, 0.07112272177183443, 0.07311984198393673, 0.08259774318144808, 0.08036078786819523, 0.06537377928504606, 0.0744343419763247]}, "mutation_prompt": null}
{"id": "78ede4ed-aa81-4bdf-a0c2-ec7bed210f16", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85  # Increased initial scale factor for exploration\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2  # New parameter to balance exploration and exploitation\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.7, 0.85)\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer with dynamic exploration-exploitation balance and adaptive mutation enhancements for improved convergence speed.", "configspace": "", "generation": 58, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.855172362762411, 0.8659220062066514, 0.8637095763143072, 0.8684988538912858, 0.8706178808280751, 0.8751219187668274, 0.875735912251711, 0.885371256709463, 0.8758475010261377, 0.7897606772692076, 0.7780464349312769, 0.7624645084216468, 0.790407854606426, 0.7684057734533948, 0.7577109760176526, 0.7463787822833655, 0.7635591696458801, 0.779950701825359, 0.13747259024931702, 0.17055399530404325, 0.10616000006249326, 0.1054032523020253, 0.09860999203547127, 0.1492505945832061, 0.13335637946585543, 0.17177438431859848, 0.13050905674168511, 0.12194495847323028, 0.10146753381107443, 0.12917549606342704, 0.09420335672677227, 0.11375308881847501, 0.15008416491683807, 0.13767435057858823, 0.11576480629799935, 0.1288823478391028, 0.923616252156499, 0.9332626390541685, 0.938880057085812, 0.9569887426622138, 0.965427221297927, 0.9546026869304383, 0.9564207320607586, 0.9179055589109922, 0.9596409617365361, 0.6799231502956886, 0.6228315181907147, 0.6053077427826508, 0.643633539398441, 0.6454159831097687, 0.6594364776109957, 0.631077911470128, 0.6268580537351958, 0.6605426909472558, 0.8738257379897179, 0.856710039802895, 0.8528781296374323, 0.8745713666194754, 0.8723434837413657, 0.8649739958849774, 0.8430124741409125, 0.8534555458270078, 0.8270341744551444, 0.551609459177163, 0.6482143574659887, 0.6614293324084707, 0.6270736700295976, 0.6204393695553585, 0.7290196604281876, 0.5295222584265555, 0.6848937949327776, 0.6093807291259528, 0.5465871851585957, 0.4904294373669038, 0.3946434652820141, 0.6080634587822529, 0.5095203797813246, 0.5660126831435907, 0.565944899087218, 0.6275651600885951, 0.6601593986255824, 0.6815124455687847, 0.6854782027332962, 0.6837219132887977, 0.6919529395951656, 0.6662903194597756, 0.6739183325345197, 0.65822892108458, 0.664930023254529, 0.6535756775119573, 0.7392823068939017, 0.7606036896234012, 0.7366869729255578, 0.7567829085685326, 0.7565024511641978, 0.7422584293751445, 0.7414979218067919, 0.7895831302138768, 0.7506469026429001, 0.30000960624512785, 0.24762357706142113, 0.3644720772137978, 0.535693056038617, 0.25791088630295056, 0.5635676852911893, 0.411931198692415, 0.38074161349804125, 0.25527312128765856, 0.5196475226986133, 0.49754361755002785, 0.5619986287546577, 0.5513970794512073, 0.5140282507326093, 0.5540378543456437, 0.5567276713407624, 0.48309762896091235, 0.5926462818682783, 0.8292316049554413, 0.8040513681872443, 0.8231935820366749, 0.8204589686524565, 0.8347687689102576, 0.8283266882051368, 0.8240075686093223, 0.8119240453212864, 0.8478159671843553, 0.08471603955940465, 0.3269841909688398, 0.15584601958897926, 0.11946357558329346, 0.3135240296628693, 0.10580123910878647, 0.09906976740325169, 0.09333877826716819, 0.11331074715137834, 0.5154384242785006, 0.1803933474093794, 0.13860169662543853, 0.14837852583895927, 0.1674644578945137, 0.17496579937812673, 0.15331341602347348, 0.24947180259253354, 0.182268737549234, 0.5005475397078184, 0.4811407806137462, 0.5377490758421786, 0.4867492420791786, 0.47820616455337817, 0.48736033498544773, 0.5242773046718501, 0.5566141040541208, 0.5427556727632223, 0.3896049525718689, 0.41282700043680387, 0.42158935101037176, 0.40232756243805645, 0.38652903995092525, 0.38638984348144334, 0.40047031823279766, 0.45695157847683643, 0.4069924652942214, 0.19933732654038117, 0.18606894657419026, 0.1673109473458444, 0.216324927810446, 0.19287814885471466, 0.1834506894129444, 0.18836828764373648, 0.19333976771871386, 0.20323648161897667, 0.23640093830712194, 0.2199459491448139, 0.19488160744504957, 0.21346316747808358, 0.5834111239602295, 0.5474039843918898, 0.6400349897232377, 0.6421359954798118, 0.22280323530908253, 0.1718399849181258, 0.18627685918462045, 0.16164795410939348, 0.8656755749455405, 0.20396844494786914, 0.8257571772650467, 0.20358013983404077, 0.7674193301061665, 0.18330540067054635, 0.1553301798026454, 0.16839318394936542, 0.8025939547242359, 0.20788461803011848, 0.7147711167660822, 0.836414744094142, 0.7948373782477776, 0.12659423940961168, 0.8558619002585786, 0.18868553146758382, 0.2003710379036382, 0.1779633789611531, 0.1867325129591343, 0.21877009451217122, 0.1851188699205697, 0.18538773835269862, 0.18705575881167003, 0.16899127761440813, 0.077243001792072, 0.0792303244840199, 0.08746923025707387, 0.07112272177183443, 0.07311984198393673, 0.08259774318144808, 0.08036078786819523, 0.06537377928504606, 0.0744343419763247]}, "mutation_prompt": null}
{"id": "990a1b50-37d4-4678-b1d3-ce2c3e6fc835", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85  # Increased initial scale factor for exploration\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2  # New parameter to balance exploration and exploitation\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.7, 0.85)\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer with dynamic exploration-exploitation balance and adaptive mutation enhancements for improved convergence speed.", "configspace": "", "generation": 58, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.855172362762411, 0.8659220062066514, 0.8637095763143072, 0.8684988538912858, 0.8706178808280751, 0.8751219187668274, 0.875735912251711, 0.885371256709463, 0.8758475010261377, 0.7897606772692076, 0.7780464349312769, 0.7624645084216468, 0.790407854606426, 0.7684057734533948, 0.7577109760176526, 0.7463787822833655, 0.7635591696458801, 0.779950701825359, 0.13747259024931702, 0.17055399530404325, 0.10616000006249326, 0.1054032523020253, 0.09860999203547127, 0.1492505945832061, 0.13335637946585543, 0.17177438431859848, 0.13050905674168511, 0.12194495847323028, 0.10146753381107443, 0.12917549606342704, 0.09420335672677227, 0.11375308881847501, 0.15008416491683807, 0.13767435057858823, 0.11576480629799935, 0.1288823478391028, 0.923616252156499, 0.9332626390541685, 0.938880057085812, 0.9569887426622138, 0.965427221297927, 0.9546026869304383, 0.9564207320607586, 0.9179055589109922, 0.9596409617365361, 0.6799231502956886, 0.6228315181907147, 0.6053077427826508, 0.643633539398441, 0.6454159831097687, 0.6594364776109957, 0.631077911470128, 0.6268580537351958, 0.6605426909472558, 0.8738257379897179, 0.856710039802895, 0.8528781296374323, 0.8745713666194754, 0.8723434837413657, 0.8649739958849774, 0.8430124741409125, 0.8534555458270078, 0.8270341744551444, 0.551609459177163, 0.6482143574659887, 0.6614293324084707, 0.6270736700295976, 0.6204393695553585, 0.7290196604281876, 0.5295222584265555, 0.6848937949327776, 0.6093807291259528, 0.5465871851585957, 0.4904294373669038, 0.3946434652820141, 0.6080634587822529, 0.5095203797813246, 0.5660126831435907, 0.565944899087218, 0.6275651600885951, 0.6601593986255824, 0.6815124455687847, 0.6854782027332962, 0.6837219132887977, 0.6919529395951656, 0.6662903194597756, 0.6739183325345197, 0.65822892108458, 0.664930023254529, 0.6535756775119573, 0.7392823068939017, 0.7606036896234012, 0.7366869729255578, 0.7567829085685326, 0.7565024511641978, 0.7422584293751445, 0.7414979218067919, 0.7895831302138768, 0.7506469026429001, 0.30000960624512785, 0.24762357706142113, 0.3644720772137978, 0.535693056038617, 0.25791088630295056, 0.5635676852911893, 0.411931198692415, 0.38074161349804125, 0.25527312128765856, 0.5196475226986133, 0.49754361755002785, 0.5619986287546577, 0.5513970794512073, 0.5140282507326093, 0.5540378543456437, 0.5567276713407624, 0.48309762896091235, 0.5926462818682783, 0.8292316049554413, 0.8040513681872443, 0.8231935820366749, 0.8204589686524565, 0.8347687689102576, 0.8283266882051368, 0.8240075686093223, 0.8119240453212864, 0.8478159671843553, 0.08471603955940465, 0.3269841909688398, 0.15584601958897926, 0.11946357558329346, 0.3135240296628693, 0.10580123910878647, 0.09906976740325169, 0.09333877826716819, 0.11331074715137834, 0.5154384242785006, 0.1803933474093794, 0.13860169662543853, 0.14837852583895927, 0.1674644578945137, 0.17496579937812673, 0.15331341602347348, 0.24947180259253354, 0.182268737549234, 0.5005475397078184, 0.4811407806137462, 0.5377490758421786, 0.4867492420791786, 0.47820616455337817, 0.48736033498544773, 0.5242773046718501, 0.5566141040541208, 0.5427556727632223, 0.3896049525718689, 0.41282700043680387, 0.42158935101037176, 0.40232756243805645, 0.38652903995092525, 0.38638984348144334, 0.40047031823279766, 0.45695157847683643, 0.4069924652942214, 0.19933732654038117, 0.18606894657419026, 0.1673109473458444, 0.216324927810446, 0.19287814885471466, 0.1834506894129444, 0.18836828764373648, 0.19333976771871386, 0.20323648161897667, 0.23640093830712194, 0.2199459491448139, 0.19488160744504957, 0.21346316747808358, 0.5834111239602295, 0.5474039843918898, 0.6400349897232377, 0.6421359954798118, 0.22280323530908253, 0.1718399849181258, 0.18627685918462045, 0.16164795410939348, 0.8656755749455405, 0.20396844494786914, 0.8257571772650467, 0.20358013983404077, 0.7674193301061665, 0.18330540067054635, 0.1553301798026454, 0.16839318394936542, 0.8025939547242359, 0.20788461803011848, 0.7147711167660822, 0.836414744094142, 0.7948373782477776, 0.12659423940961168, 0.8558619002585786, 0.18868553146758382, 0.2003710379036382, 0.1779633789611531, 0.1867325129591343, 0.21877009451217122, 0.1851188699205697, 0.18538773835269862, 0.18705575881167003, 0.16899127761440813, 0.077243001792072, 0.0792303244840199, 0.08746923025707387, 0.07112272177183443, 0.07311984198393673, 0.08259774318144808, 0.08036078786819523, 0.06537377928504606, 0.0744343419763247]}, "mutation_prompt": null}
{"id": "8e4269ea-7fa1-44cc-8d96-adabd18a6c36", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8  # Adjusted scale factor for better balance\n        self.cross_prob = 0.85\n        self.adaptation_rate = 0.07  # Slight increase in adaptation rate\n        self.exploit_factor = 0.15  # Adjusted parameter for exploration-exploitation balance\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.median(fitness) - fitness[i]) / np.std(fitness))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                adaptive_cross_prob = self.cross_prob + adapt_factor * np.random.uniform(0.88, 1.05)\n                crossover = np.random.rand(self.dim) < adaptive_cross_prob\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.75, 0.8)\n            self.cross_prob = np.random.uniform(0.85, 0.95)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution algorithm with refined adaptive mutation and adaptive crossover rates for improved convergence efficiency.", "configspace": "", "generation": 73, "fitness": 0.45377996654210934, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.45 with standard deviation 0.28.", "error": "", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.8436978947117728, 0.8660203338358119, 0.8599136850091386, 0.8684421964605757, 0.8572638996480377, 0.8693047772622895, 0.8493479966159239, 0.8637426639431267, 0.8578282217889628, 0.7742429807529168, 0.7519343328670889, 0.7603523854134537, 0.764922475604173, 0.7499742851372243, 0.7522158008037675, 0.7672743984785334, 0.7410386418681166, 0.7384154595536959, 0.19401413202309847, 0.1605882234275252, 0.1481545580733098, 0.13703558857463982, 0.14906538489126375, 0.29206101444259513, 0.17186517960143777, 0.1162098102518605, 0.10917142497923382, 0.119809717280007, 0.121808141718457, 0.11852753662515025, 0.13132081588190847, 0.11218733034390715, 0.13535622000964453, 0.11148570404566471, 0.13622884774297583, 0.19298853482358047, 0.9637923456775545, 0.9743038409419005, 0.9297632303264143, 0.9775949670090299, 0.965979597611938, 0.9793191754459831, 0.962773217003965, 0.9438161645528517, 0.9727050867213476, 0.5971271816776504, 0.6093650474548535, 0.6352196061701059, 0.6097750997790433, 0.6234563648947149, 0.6442298362713066, 0.6566399411266736, 0.6290967459145878, 0.6657938313269898, 0.8224993375712997, 0.8388705164760287, 0.8369359763749986, 0.8689214265361703, 0.8521863048403939, 0.8103191322184425, 0.8076646610283643, 0.849860357802162, 0.7689902199510771, 0.6177408767434702, 0.6152522183296028, 0.5391869751552945, 0.5012081763989273, 0.5965005091345859, 0.5862564043201665, 0.5970911552867315, 0.5800705220919005, 0.6629677948111752, 0.40862200746388955, 0.12574911710887793, 0.6124467426142979, 0.579760120447311, 0.5477420533123971, 0.5514256825223722, 0.47987894570027945, 0.5915107086868592, 0.5388124548995411, 0.5725840051474966, 0.5717100349187452, 0.5869647607209083, 0.5926903200320104, 0.5233413583742812, 0.5729916147065892, 0.556240734345191, 0.520201770846688, 0.563069695563489, 0.6980153223330242, 0.6220212946738997, 0.7289165156685249, 0.6952037076295711, 0.6543233856984756, 0.5423184475393169, 0.6927571754843207, 0.6960400167892887, 0.677962483060308, 0.2108166558365938, 0.16114817136735093, 0.1347610593684916, 0.4239396396913514, 0.49814521519784427, 0.4266976589207614, 0.16293892002874277, 0.18821082620581087, 0.19785972363549353, 0.42649630700876473, 0.4248005906593272, 0.3840862897104361, 0.4056597890252771, 0.406100566078026, 0.43990675534438617, 0.394686134571813, 0.41007802091220924, 0.4220785231607481, 0.7842450864531987, 0.7601214406280278, 0.7957164582657961, 0.7830152599391254, 0.7854682919852087, 0.7849595465443804, 0.7896811548086216, 0.7699646264287973, 0.7566037219927588, 0.10314146632788257, 0.15732729925380717, 0.10351341051950624, 0.12307737331380864, 0.09248432247701643, 0.11941461332863967, 0.09794187903022755, 0.14556669815822965, 0.10866749897403094, 0.15610317915102534, 0.15301298103870864, 0.1928246239816518, 0.1445569464644756, 0.18786545204257932, 0.148541229951467, 0.21258868932098962, 0.17420462881095622, 0.18185803378410836, 0.4424442339389483, 0.4645477030600801, 0.4583107159952654, 0.41512207667300305, 0.4610936422117189, 0.4677641724283861, 0.47747612314694965, 0.4791503955715205, 0.4999022372687907, 0.3483203619666626, 0.34667237541663054, 0.3556115741020778, 0.3438795119133392, 0.34876625444921294, 0.3070395102226311, 0.3372339417258784, 0.3711607163188878, 0.3771267965105639, 0.20286645275154558, 0.174907116596557, 0.17843741856224038, 0.1777047685126656, 0.17560119599828283, 0.19595068388008097, 0.18794246880326737, 0.17554532417307478, 0.19299542786523538, 0.36045090715777883, 0.5617875747934266, 0.42233290233163223, 0.40954621036030436, 0.37588965936583185, 0.4727175226393674, 0.19420216847102478, 0.4646581662517473, 0.495969352336167, 0.17135214960840928, 0.7569375936800614, 0.8421030231129196, 0.18363318977462728, 0.8100958380116625, 0.1649781306734125, 0.13845330192975602, 0.18201500632437073, 0.7905899747274844, 0.7275945177454086, 0.20151105409799985, 0.7831441039669712, 0.766637677662444, 0.19893883146456925, 0.1647012083086471, 0.21128298136954904, 0.12891528014619658, 0.15324196793014166, 0.182496653044801, 0.18281059185619886, 0.19001551523112603, 0.17609672356005535, 0.1970092469196072, 0.18989846718569192, 0.21112527577753848, 0.18555267729289848, 0.18288223125503955, 0.08155040332252161, 0.06885654986306722, 0.07548040365625153, 0.07823765329555099, 0.0827681629368553, 0.0751897908269713, 0.0741581531984411, 0.08741695381998671, 0.07641215029263004]}, "mutation_prompt": null}
{"id": "4e82ad4d-cc0e-4891-bf07-24526ad1c5eb", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizerV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            mean_fitness = np.mean(fitness)\n            std_fitness = np.std(fitness)\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(mean_fitness - fitness[i]) / std_fitness)\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            diversity = np.mean(np.std(population, axis=0))\n            self.scale_factor = np.random.uniform(0.75, 0.85) * (1 + diversity)\n            self.cross_prob = np.random.uniform(0.88, 1.0) * (1 - diversity)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizerV2", "description": "Enhanced Hybrid Evolutionary Optimizer with adaptive crossover and scale factor adjustments leveraging fitness diversity for improved convergence.", "configspace": "", "generation": 74, "fitness": 0.04508967942243715, "feedback": "The algorithm EnhancedHybridEvolutionaryOptimizerV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.05.", "error": "", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.09800381043785622, 0.12030361490479735, 0.13856275014467523, 0.08952233024927114, 0.062138895920524906, 0.11800854400807625, 0.0815538205986579, 0.11635301091791839, 0.1515136840110366, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01467079663371329, 0.005375109906600173, 0.02665529416199386, 0.0012186513362246743, 0.012801303288210497, 0.018248263482334326, 0.015163904768393355, 0.010674738340807233, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06282723858512695, 0.04219942533172094, 0.04361151007575137, 0.0727166110130627, 0.05222538147216205, 0.05631656630193138, 0.10537223772208781, 0.048986754550083944, 0.04555275648068857, 0.014725626162050642, 9.999999999998899e-05, 0.04851838352249649, 9.999999999998899e-05, 0.026485878153417852, 9.999999999998899e-05, 9.999999999998899e-05, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.03775594762470191, 0.052233822106523387, 0.0667108215001172, 0.02725496812965944, 0.018166091921444805, 0.026279303607937843, 0.05931056463008866, 0.00990846602666351, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.010611962599993197, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1774807602710825, 0.13879659513922615, 0.14838054695461433, 0.11624952661047916, 0.09708865527373767, 0.10554951200990836, 0.1240568991094797, 0.11479707755773161, 0.1210557193025883, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.014021567856152273, 0.00087074670492715, 0.01759993274736349, 0.0033279038767659586, 0.009739888724669465, 0.0267656688986897, 0.07037543064596374, 0.08500946006938725, 0.08726795478736071, 0.09855305120349966, 0.10852972522114013, 0.05643121168494414, 0.08808199726801991, 0.05671393358747501, 0.07726393575557644, 0.10131672290949412, 0.10211029386788484, 0.14352810184653642, 0.13800672315110074, 0.09261918780562917, 0.1025140421398899, 0.12028165949079228, 0.17377774300845283, 0.11363346445524236, 0.04729378690247321, 0.034008147686441226, 0.05463654710198407, 0.0796369052953303, 0.06406947898089654, 0.06342850570876157, 0.0837317855149382, 0.09386031173166853, 0.06412526395900253, 0.11379419476835517, 0.07258336876764393, 0.13345086981233123, 0.10289055837941885, 0.09771900511419429, 0.111356532484439, 0.12245976138762271, 0.08571719487894569, 0.1261963614278906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13735159099776062, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10065386339932103, 0.07466602457976645, 0.08167024703901915, 0.12834243141131696, 0.1207914665021157, 0.08777423265619488, 0.07245568600050101, 0.09643604708838482, 0.0764731646628487, 0.03824121102611444, 0.10051730792859848, 0.05899961635361195, 0.0506857903344724, 0.043618072786101414, 0.08825791414782957, 0.04690376827171172, 0.07724356095009077, 0.05733479502336536, 0.13480174570059533, 0.14810101195775383, 0.14763022729669195, 0.12069347526700402, 0.1472857784240741, 0.12465113207635137, 0.14969714796693134, 0.1369741521653034, 0.14689007985489466, 0.01527536865754242, 0.02266807262548698, 0.031393493129599714, 0.027015293023570086, 0.018487330591705486, 0.020045516730027746, 0.048786416104792396, 0.011938467362492489, 0.01745630416284416]}, "mutation_prompt": null}
{"id": "147826b0-a0c5-4144-9304-c10097327f63", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85  # Increased initial scale factor for exploration\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2  # New parameter to balance exploration and exploitation\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.7, 0.85)\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer with dynamic exploration-exploitation balance and adaptive mutation enhancements for improved convergence speed.", "configspace": "", "generation": 58, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.855172362762411, 0.8659220062066514, 0.8637095763143072, 0.8684988538912858, 0.8706178808280751, 0.8751219187668274, 0.875735912251711, 0.885371256709463, 0.8758475010261377, 0.7897606772692076, 0.7780464349312769, 0.7624645084216468, 0.790407854606426, 0.7684057734533948, 0.7577109760176526, 0.7463787822833655, 0.7635591696458801, 0.779950701825359, 0.13747259024931702, 0.17055399530404325, 0.10616000006249326, 0.1054032523020253, 0.09860999203547127, 0.1492505945832061, 0.13335637946585543, 0.17177438431859848, 0.13050905674168511, 0.12194495847323028, 0.10146753381107443, 0.12917549606342704, 0.09420335672677227, 0.11375308881847501, 0.15008416491683807, 0.13767435057858823, 0.11576480629799935, 0.1288823478391028, 0.923616252156499, 0.9332626390541685, 0.938880057085812, 0.9569887426622138, 0.965427221297927, 0.9546026869304383, 0.9564207320607586, 0.9179055589109922, 0.9596409617365361, 0.6799231502956886, 0.6228315181907147, 0.6053077427826508, 0.643633539398441, 0.6454159831097687, 0.6594364776109957, 0.631077911470128, 0.6268580537351958, 0.6605426909472558, 0.8738257379897179, 0.856710039802895, 0.8528781296374323, 0.8745713666194754, 0.8723434837413657, 0.8649739958849774, 0.8430124741409125, 0.8534555458270078, 0.8270341744551444, 0.551609459177163, 0.6482143574659887, 0.6614293324084707, 0.6270736700295976, 0.6204393695553585, 0.7290196604281876, 0.5295222584265555, 0.6848937949327776, 0.6093807291259528, 0.5465871851585957, 0.4904294373669038, 0.3946434652820141, 0.6080634587822529, 0.5095203797813246, 0.5660126831435907, 0.565944899087218, 0.6275651600885951, 0.6601593986255824, 0.6815124455687847, 0.6854782027332962, 0.6837219132887977, 0.6919529395951656, 0.6662903194597756, 0.6739183325345197, 0.65822892108458, 0.664930023254529, 0.6535756775119573, 0.7392823068939017, 0.7606036896234012, 0.7366869729255578, 0.7567829085685326, 0.7565024511641978, 0.7422584293751445, 0.7414979218067919, 0.7895831302138768, 0.7506469026429001, 0.30000960624512785, 0.24762357706142113, 0.3644720772137978, 0.535693056038617, 0.25791088630295056, 0.5635676852911893, 0.411931198692415, 0.38074161349804125, 0.25527312128765856, 0.5196475226986133, 0.49754361755002785, 0.5619986287546577, 0.5513970794512073, 0.5140282507326093, 0.5540378543456437, 0.5567276713407624, 0.48309762896091235, 0.5926462818682783, 0.8292316049554413, 0.8040513681872443, 0.8231935820366749, 0.8204589686524565, 0.8347687689102576, 0.8283266882051368, 0.8240075686093223, 0.8119240453212864, 0.8478159671843553, 0.08471603955940465, 0.3269841909688398, 0.15584601958897926, 0.11946357558329346, 0.3135240296628693, 0.10580123910878647, 0.09906976740325169, 0.09333877826716819, 0.11331074715137834, 0.5154384242785006, 0.1803933474093794, 0.13860169662543853, 0.14837852583895927, 0.1674644578945137, 0.17496579937812673, 0.15331341602347348, 0.24947180259253354, 0.182268737549234, 0.5005475397078184, 0.4811407806137462, 0.5377490758421786, 0.4867492420791786, 0.47820616455337817, 0.48736033498544773, 0.5242773046718501, 0.5566141040541208, 0.5427556727632223, 0.3896049525718689, 0.41282700043680387, 0.42158935101037176, 0.40232756243805645, 0.38652903995092525, 0.38638984348144334, 0.40047031823279766, 0.45695157847683643, 0.4069924652942214, 0.19933732654038117, 0.18606894657419026, 0.1673109473458444, 0.216324927810446, 0.19287814885471466, 0.1834506894129444, 0.18836828764373648, 0.19333976771871386, 0.20323648161897667, 0.23640093830712194, 0.2199459491448139, 0.19488160744504957, 0.21346316747808358, 0.5834111239602295, 0.5474039843918898, 0.6400349897232377, 0.6421359954798118, 0.22280323530908253, 0.1718399849181258, 0.18627685918462045, 0.16164795410939348, 0.8656755749455405, 0.20396844494786914, 0.8257571772650467, 0.20358013983404077, 0.7674193301061665, 0.18330540067054635, 0.1553301798026454, 0.16839318394936542, 0.8025939547242359, 0.20788461803011848, 0.7147711167660822, 0.836414744094142, 0.7948373782477776, 0.12659423940961168, 0.8558619002585786, 0.18868553146758382, 0.2003710379036382, 0.1779633789611531, 0.1867325129591343, 0.21877009451217122, 0.1851188699205697, 0.18538773835269862, 0.18705575881167003, 0.16899127761440813, 0.077243001792072, 0.0792303244840199, 0.08746923025707387, 0.07112272177183443, 0.07311984198393673, 0.08259774318144808, 0.08036078786819523, 0.06537377928504606, 0.0744343419763247]}, "mutation_prompt": null}
{"id": "2a88f229-edc8-491b-aaf6-20edba00b487", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85  # Increased initial scale factor for exploration\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2  # New parameter to balance exploration and exploitation\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.7, 0.85)\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer with dynamic exploration-exploitation balance and adaptive mutation enhancements for improved convergence speed.", "configspace": "", "generation": 58, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.855172362762411, 0.8659220062066514, 0.8637095763143072, 0.8684988538912858, 0.8706178808280751, 0.8751219187668274, 0.875735912251711, 0.885371256709463, 0.8758475010261377, 0.7897606772692076, 0.7780464349312769, 0.7624645084216468, 0.790407854606426, 0.7684057734533948, 0.7577109760176526, 0.7463787822833655, 0.7635591696458801, 0.779950701825359, 0.13747259024931702, 0.17055399530404325, 0.10616000006249326, 0.1054032523020253, 0.09860999203547127, 0.1492505945832061, 0.13335637946585543, 0.17177438431859848, 0.13050905674168511, 0.12194495847323028, 0.10146753381107443, 0.12917549606342704, 0.09420335672677227, 0.11375308881847501, 0.15008416491683807, 0.13767435057858823, 0.11576480629799935, 0.1288823478391028, 0.923616252156499, 0.9332626390541685, 0.938880057085812, 0.9569887426622138, 0.965427221297927, 0.9546026869304383, 0.9564207320607586, 0.9179055589109922, 0.9596409617365361, 0.6799231502956886, 0.6228315181907147, 0.6053077427826508, 0.643633539398441, 0.6454159831097687, 0.6594364776109957, 0.631077911470128, 0.6268580537351958, 0.6605426909472558, 0.8738257379897179, 0.856710039802895, 0.8528781296374323, 0.8745713666194754, 0.8723434837413657, 0.8649739958849774, 0.8430124741409125, 0.8534555458270078, 0.8270341744551444, 0.551609459177163, 0.6482143574659887, 0.6614293324084707, 0.6270736700295976, 0.6204393695553585, 0.7290196604281876, 0.5295222584265555, 0.6848937949327776, 0.6093807291259528, 0.5465871851585957, 0.4904294373669038, 0.3946434652820141, 0.6080634587822529, 0.5095203797813246, 0.5660126831435907, 0.565944899087218, 0.6275651600885951, 0.6601593986255824, 0.6815124455687847, 0.6854782027332962, 0.6837219132887977, 0.6919529395951656, 0.6662903194597756, 0.6739183325345197, 0.65822892108458, 0.664930023254529, 0.6535756775119573, 0.7392823068939017, 0.7606036896234012, 0.7366869729255578, 0.7567829085685326, 0.7565024511641978, 0.7422584293751445, 0.7414979218067919, 0.7895831302138768, 0.7506469026429001, 0.30000960624512785, 0.24762357706142113, 0.3644720772137978, 0.535693056038617, 0.25791088630295056, 0.5635676852911893, 0.411931198692415, 0.38074161349804125, 0.25527312128765856, 0.5196475226986133, 0.49754361755002785, 0.5619986287546577, 0.5513970794512073, 0.5140282507326093, 0.5540378543456437, 0.5567276713407624, 0.48309762896091235, 0.5926462818682783, 0.8292316049554413, 0.8040513681872443, 0.8231935820366749, 0.8204589686524565, 0.8347687689102576, 0.8283266882051368, 0.8240075686093223, 0.8119240453212864, 0.8478159671843553, 0.08471603955940465, 0.3269841909688398, 0.15584601958897926, 0.11946357558329346, 0.3135240296628693, 0.10580123910878647, 0.09906976740325169, 0.09333877826716819, 0.11331074715137834, 0.5154384242785006, 0.1803933474093794, 0.13860169662543853, 0.14837852583895927, 0.1674644578945137, 0.17496579937812673, 0.15331341602347348, 0.24947180259253354, 0.182268737549234, 0.5005475397078184, 0.4811407806137462, 0.5377490758421786, 0.4867492420791786, 0.47820616455337817, 0.48736033498544773, 0.5242773046718501, 0.5566141040541208, 0.5427556727632223, 0.3896049525718689, 0.41282700043680387, 0.42158935101037176, 0.40232756243805645, 0.38652903995092525, 0.38638984348144334, 0.40047031823279766, 0.45695157847683643, 0.4069924652942214, 0.19933732654038117, 0.18606894657419026, 0.1673109473458444, 0.216324927810446, 0.19287814885471466, 0.1834506894129444, 0.18836828764373648, 0.19333976771871386, 0.20323648161897667, 0.23640093830712194, 0.2199459491448139, 0.19488160744504957, 0.21346316747808358, 0.5834111239602295, 0.5474039843918898, 0.6400349897232377, 0.6421359954798118, 0.22280323530908253, 0.1718399849181258, 0.18627685918462045, 0.16164795410939348, 0.8656755749455405, 0.20396844494786914, 0.8257571772650467, 0.20358013983404077, 0.7674193301061665, 0.18330540067054635, 0.1553301798026454, 0.16839318394936542, 0.8025939547242359, 0.20788461803011848, 0.7147711167660822, 0.836414744094142, 0.7948373782477776, 0.12659423940961168, 0.8558619002585786, 0.18868553146758382, 0.2003710379036382, 0.1779633789611531, 0.1867325129591343, 0.21877009451217122, 0.1851188699205697, 0.18538773835269862, 0.18705575881167003, 0.16899127761440813, 0.077243001792072, 0.0792303244840199, 0.08746923025707387, 0.07112272177183443, 0.07311984198393673, 0.08259774318144808, 0.08036078786819523, 0.06537377928504606, 0.0744343419763247]}, "mutation_prompt": null}
{"id": "9039702f-f387-4ec2-9f77-9ab0ecea0408", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85  # Increased initial scale factor for exploration\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2  # New parameter to balance exploration and exploitation\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.7, 0.85)\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer with dynamic exploration-exploitation balance and adaptive mutation enhancements for improved convergence speed.", "configspace": "", "generation": 58, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.855172362762411, 0.8659220062066514, 0.8637095763143072, 0.8684988538912858, 0.8706178808280751, 0.8751219187668274, 0.875735912251711, 0.885371256709463, 0.8758475010261377, 0.7897606772692076, 0.7780464349312769, 0.7624645084216468, 0.790407854606426, 0.7684057734533948, 0.7577109760176526, 0.7463787822833655, 0.7635591696458801, 0.779950701825359, 0.13747259024931702, 0.17055399530404325, 0.10616000006249326, 0.1054032523020253, 0.09860999203547127, 0.1492505945832061, 0.13335637946585543, 0.17177438431859848, 0.13050905674168511, 0.12194495847323028, 0.10146753381107443, 0.12917549606342704, 0.09420335672677227, 0.11375308881847501, 0.15008416491683807, 0.13767435057858823, 0.11576480629799935, 0.1288823478391028, 0.923616252156499, 0.9332626390541685, 0.938880057085812, 0.9569887426622138, 0.965427221297927, 0.9546026869304383, 0.9564207320607586, 0.9179055589109922, 0.9596409617365361, 0.6799231502956886, 0.6228315181907147, 0.6053077427826508, 0.643633539398441, 0.6454159831097687, 0.6594364776109957, 0.631077911470128, 0.6268580537351958, 0.6605426909472558, 0.8738257379897179, 0.856710039802895, 0.8528781296374323, 0.8745713666194754, 0.8723434837413657, 0.8649739958849774, 0.8430124741409125, 0.8534555458270078, 0.8270341744551444, 0.551609459177163, 0.6482143574659887, 0.6614293324084707, 0.6270736700295976, 0.6204393695553585, 0.7290196604281876, 0.5295222584265555, 0.6848937949327776, 0.6093807291259528, 0.5465871851585957, 0.4904294373669038, 0.3946434652820141, 0.6080634587822529, 0.5095203797813246, 0.5660126831435907, 0.565944899087218, 0.6275651600885951, 0.6601593986255824, 0.6815124455687847, 0.6854782027332962, 0.6837219132887977, 0.6919529395951656, 0.6662903194597756, 0.6739183325345197, 0.65822892108458, 0.664930023254529, 0.6535756775119573, 0.7392823068939017, 0.7606036896234012, 0.7366869729255578, 0.7567829085685326, 0.7565024511641978, 0.7422584293751445, 0.7414979218067919, 0.7895831302138768, 0.7506469026429001, 0.30000960624512785, 0.24762357706142113, 0.3644720772137978, 0.535693056038617, 0.25791088630295056, 0.5635676852911893, 0.411931198692415, 0.38074161349804125, 0.25527312128765856, 0.5196475226986133, 0.49754361755002785, 0.5619986287546577, 0.5513970794512073, 0.5140282507326093, 0.5540378543456437, 0.5567276713407624, 0.48309762896091235, 0.5926462818682783, 0.8292316049554413, 0.8040513681872443, 0.8231935820366749, 0.8204589686524565, 0.8347687689102576, 0.8283266882051368, 0.8240075686093223, 0.8119240453212864, 0.8478159671843553, 0.08471603955940465, 0.3269841909688398, 0.15584601958897926, 0.11946357558329346, 0.3135240296628693, 0.10580123910878647, 0.09906976740325169, 0.09333877826716819, 0.11331074715137834, 0.5154384242785006, 0.1803933474093794, 0.13860169662543853, 0.14837852583895927, 0.1674644578945137, 0.17496579937812673, 0.15331341602347348, 0.24947180259253354, 0.182268737549234, 0.5005475397078184, 0.4811407806137462, 0.5377490758421786, 0.4867492420791786, 0.47820616455337817, 0.48736033498544773, 0.5242773046718501, 0.5566141040541208, 0.5427556727632223, 0.3896049525718689, 0.41282700043680387, 0.42158935101037176, 0.40232756243805645, 0.38652903995092525, 0.38638984348144334, 0.40047031823279766, 0.45695157847683643, 0.4069924652942214, 0.19933732654038117, 0.18606894657419026, 0.1673109473458444, 0.216324927810446, 0.19287814885471466, 0.1834506894129444, 0.18836828764373648, 0.19333976771871386, 0.20323648161897667, 0.23640093830712194, 0.2199459491448139, 0.19488160744504957, 0.21346316747808358, 0.5834111239602295, 0.5474039843918898, 0.6400349897232377, 0.6421359954798118, 0.22280323530908253, 0.1718399849181258, 0.18627685918462045, 0.16164795410939348, 0.8656755749455405, 0.20396844494786914, 0.8257571772650467, 0.20358013983404077, 0.7674193301061665, 0.18330540067054635, 0.1553301798026454, 0.16839318394936542, 0.8025939547242359, 0.20788461803011848, 0.7147711167660822, 0.836414744094142, 0.7948373782477776, 0.12659423940961168, 0.8558619002585786, 0.18868553146758382, 0.2003710379036382, 0.1779633789611531, 0.1867325129591343, 0.21877009451217122, 0.1851188699205697, 0.18538773835269862, 0.18705575881167003, 0.16899127761440813, 0.077243001792072, 0.0792303244840199, 0.08746923025707387, 0.07112272177183443, 0.07311984198393673, 0.08259774318144808, 0.08036078786819523, 0.06537377928504606, 0.0744343419763247]}, "mutation_prompt": null}
{"id": "e559559c-00b3-4df7-9a2e-b000370fdb53", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85  # Increased initial scale factor for exploration\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2  # New parameter to balance exploration and exploitation\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.7, 0.85)\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer with dynamic exploration-exploitation balance and adaptive mutation enhancements for improved convergence speed.", "configspace": "", "generation": 58, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.855172362762411, 0.8659220062066514, 0.8637095763143072, 0.8684988538912858, 0.8706178808280751, 0.8751219187668274, 0.875735912251711, 0.885371256709463, 0.8758475010261377, 0.7897606772692076, 0.7780464349312769, 0.7624645084216468, 0.790407854606426, 0.7684057734533948, 0.7577109760176526, 0.7463787822833655, 0.7635591696458801, 0.779950701825359, 0.13747259024931702, 0.17055399530404325, 0.10616000006249326, 0.1054032523020253, 0.09860999203547127, 0.1492505945832061, 0.13335637946585543, 0.17177438431859848, 0.13050905674168511, 0.12194495847323028, 0.10146753381107443, 0.12917549606342704, 0.09420335672677227, 0.11375308881847501, 0.15008416491683807, 0.13767435057858823, 0.11576480629799935, 0.1288823478391028, 0.923616252156499, 0.9332626390541685, 0.938880057085812, 0.9569887426622138, 0.965427221297927, 0.9546026869304383, 0.9564207320607586, 0.9179055589109922, 0.9596409617365361, 0.6799231502956886, 0.6228315181907147, 0.6053077427826508, 0.643633539398441, 0.6454159831097687, 0.6594364776109957, 0.631077911470128, 0.6268580537351958, 0.6605426909472558, 0.8738257379897179, 0.856710039802895, 0.8528781296374323, 0.8745713666194754, 0.8723434837413657, 0.8649739958849774, 0.8430124741409125, 0.8534555458270078, 0.8270341744551444, 0.551609459177163, 0.6482143574659887, 0.6614293324084707, 0.6270736700295976, 0.6204393695553585, 0.7290196604281876, 0.5295222584265555, 0.6848937949327776, 0.6093807291259528, 0.5465871851585957, 0.4904294373669038, 0.3946434652820141, 0.6080634587822529, 0.5095203797813246, 0.5660126831435907, 0.565944899087218, 0.6275651600885951, 0.6601593986255824, 0.6815124455687847, 0.6854782027332962, 0.6837219132887977, 0.6919529395951656, 0.6662903194597756, 0.6739183325345197, 0.65822892108458, 0.664930023254529, 0.6535756775119573, 0.7392823068939017, 0.7606036896234012, 0.7366869729255578, 0.7567829085685326, 0.7565024511641978, 0.7422584293751445, 0.7414979218067919, 0.7895831302138768, 0.7506469026429001, 0.30000960624512785, 0.24762357706142113, 0.3644720772137978, 0.535693056038617, 0.25791088630295056, 0.5635676852911893, 0.411931198692415, 0.38074161349804125, 0.25527312128765856, 0.5196475226986133, 0.49754361755002785, 0.5619986287546577, 0.5513970794512073, 0.5140282507326093, 0.5540378543456437, 0.5567276713407624, 0.48309762896091235, 0.5926462818682783, 0.8292316049554413, 0.8040513681872443, 0.8231935820366749, 0.8204589686524565, 0.8347687689102576, 0.8283266882051368, 0.8240075686093223, 0.8119240453212864, 0.8478159671843553, 0.08471603955940465, 0.3269841909688398, 0.15584601958897926, 0.11946357558329346, 0.3135240296628693, 0.10580123910878647, 0.09906976740325169, 0.09333877826716819, 0.11331074715137834, 0.5154384242785006, 0.1803933474093794, 0.13860169662543853, 0.14837852583895927, 0.1674644578945137, 0.17496579937812673, 0.15331341602347348, 0.24947180259253354, 0.182268737549234, 0.5005475397078184, 0.4811407806137462, 0.5377490758421786, 0.4867492420791786, 0.47820616455337817, 0.48736033498544773, 0.5242773046718501, 0.5566141040541208, 0.5427556727632223, 0.3896049525718689, 0.41282700043680387, 0.42158935101037176, 0.40232756243805645, 0.38652903995092525, 0.38638984348144334, 0.40047031823279766, 0.45695157847683643, 0.4069924652942214, 0.19933732654038117, 0.18606894657419026, 0.1673109473458444, 0.216324927810446, 0.19287814885471466, 0.1834506894129444, 0.18836828764373648, 0.19333976771871386, 0.20323648161897667, 0.23640093830712194, 0.2199459491448139, 0.19488160744504957, 0.21346316747808358, 0.5834111239602295, 0.5474039843918898, 0.6400349897232377, 0.6421359954798118, 0.22280323530908253, 0.1718399849181258, 0.18627685918462045, 0.16164795410939348, 0.8656755749455405, 0.20396844494786914, 0.8257571772650467, 0.20358013983404077, 0.7674193301061665, 0.18330540067054635, 0.1553301798026454, 0.16839318394936542, 0.8025939547242359, 0.20788461803011848, 0.7147711167660822, 0.836414744094142, 0.7948373782477776, 0.12659423940961168, 0.8558619002585786, 0.18868553146758382, 0.2003710379036382, 0.1779633789611531, 0.1867325129591343, 0.21877009451217122, 0.1851188699205697, 0.18538773835269862, 0.18705575881167003, 0.16899127761440813, 0.077243001792072, 0.0792303244840199, 0.08746923025707387, 0.07112272177183443, 0.07311984198393673, 0.08259774318144808, 0.08036078786819523, 0.06537377928504606, 0.0744343419763247]}, "mutation_prompt": null}
{"id": "4bab3212-7d49-437d-9ea6-275f607e8b63", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85  # Increased initial scale factor for exploration\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2  # New parameter to balance exploration and exploitation\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.7, 0.85)\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer with dynamic exploration-exploitation balance and adaptive mutation enhancements for improved convergence speed.", "configspace": "", "generation": 58, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.855172362762411, 0.8659220062066514, 0.8637095763143072, 0.8684988538912858, 0.8706178808280751, 0.8751219187668274, 0.875735912251711, 0.885371256709463, 0.8758475010261377, 0.7897606772692076, 0.7780464349312769, 0.7624645084216468, 0.790407854606426, 0.7684057734533948, 0.7577109760176526, 0.7463787822833655, 0.7635591696458801, 0.779950701825359, 0.13747259024931702, 0.17055399530404325, 0.10616000006249326, 0.1054032523020253, 0.09860999203547127, 0.1492505945832061, 0.13335637946585543, 0.17177438431859848, 0.13050905674168511, 0.12194495847323028, 0.10146753381107443, 0.12917549606342704, 0.09420335672677227, 0.11375308881847501, 0.15008416491683807, 0.13767435057858823, 0.11576480629799935, 0.1288823478391028, 0.923616252156499, 0.9332626390541685, 0.938880057085812, 0.9569887426622138, 0.965427221297927, 0.9546026869304383, 0.9564207320607586, 0.9179055589109922, 0.9596409617365361, 0.6799231502956886, 0.6228315181907147, 0.6053077427826508, 0.643633539398441, 0.6454159831097687, 0.6594364776109957, 0.631077911470128, 0.6268580537351958, 0.6605426909472558, 0.8738257379897179, 0.856710039802895, 0.8528781296374323, 0.8745713666194754, 0.8723434837413657, 0.8649739958849774, 0.8430124741409125, 0.8534555458270078, 0.8270341744551444, 0.551609459177163, 0.6482143574659887, 0.6614293324084707, 0.6270736700295976, 0.6204393695553585, 0.7290196604281876, 0.5295222584265555, 0.6848937949327776, 0.6093807291259528, 0.5465871851585957, 0.4904294373669038, 0.3946434652820141, 0.6080634587822529, 0.5095203797813246, 0.5660126831435907, 0.565944899087218, 0.6275651600885951, 0.6601593986255824, 0.6815124455687847, 0.6854782027332962, 0.6837219132887977, 0.6919529395951656, 0.6662903194597756, 0.6739183325345197, 0.65822892108458, 0.664930023254529, 0.6535756775119573, 0.7392823068939017, 0.7606036896234012, 0.7366869729255578, 0.7567829085685326, 0.7565024511641978, 0.7422584293751445, 0.7414979218067919, 0.7895831302138768, 0.7506469026429001, 0.30000960624512785, 0.24762357706142113, 0.3644720772137978, 0.535693056038617, 0.25791088630295056, 0.5635676852911893, 0.411931198692415, 0.38074161349804125, 0.25527312128765856, 0.5196475226986133, 0.49754361755002785, 0.5619986287546577, 0.5513970794512073, 0.5140282507326093, 0.5540378543456437, 0.5567276713407624, 0.48309762896091235, 0.5926462818682783, 0.8292316049554413, 0.8040513681872443, 0.8231935820366749, 0.8204589686524565, 0.8347687689102576, 0.8283266882051368, 0.8240075686093223, 0.8119240453212864, 0.8478159671843553, 0.08471603955940465, 0.3269841909688398, 0.15584601958897926, 0.11946357558329346, 0.3135240296628693, 0.10580123910878647, 0.09906976740325169, 0.09333877826716819, 0.11331074715137834, 0.5154384242785006, 0.1803933474093794, 0.13860169662543853, 0.14837852583895927, 0.1674644578945137, 0.17496579937812673, 0.15331341602347348, 0.24947180259253354, 0.182268737549234, 0.5005475397078184, 0.4811407806137462, 0.5377490758421786, 0.4867492420791786, 0.47820616455337817, 0.48736033498544773, 0.5242773046718501, 0.5566141040541208, 0.5427556727632223, 0.3896049525718689, 0.41282700043680387, 0.42158935101037176, 0.40232756243805645, 0.38652903995092525, 0.38638984348144334, 0.40047031823279766, 0.45695157847683643, 0.4069924652942214, 0.19933732654038117, 0.18606894657419026, 0.1673109473458444, 0.216324927810446, 0.19287814885471466, 0.1834506894129444, 0.18836828764373648, 0.19333976771871386, 0.20323648161897667, 0.23640093830712194, 0.2199459491448139, 0.19488160744504957, 0.21346316747808358, 0.5834111239602295, 0.5474039843918898, 0.6400349897232377, 0.6421359954798118, 0.22280323530908253, 0.1718399849181258, 0.18627685918462045, 0.16164795410939348, 0.8656755749455405, 0.20396844494786914, 0.8257571772650467, 0.20358013983404077, 0.7674193301061665, 0.18330540067054635, 0.1553301798026454, 0.16839318394936542, 0.8025939547242359, 0.20788461803011848, 0.7147711167660822, 0.836414744094142, 0.7948373782477776, 0.12659423940961168, 0.8558619002585786, 0.18868553146758382, 0.2003710379036382, 0.1779633789611531, 0.1867325129591343, 0.21877009451217122, 0.1851188699205697, 0.18538773835269862, 0.18705575881167003, 0.16899127761440813, 0.077243001792072, 0.0792303244840199, 0.08746923025707387, 0.07112272177183443, 0.07311984198393673, 0.08259774318144808, 0.08036078786819523, 0.06537377928504606, 0.0744343419763247]}, "mutation_prompt": null}
{"id": "62551a15-aba7-41b6-92b5-94e34ab7059f", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85  # Increased initial scale factor for exploration\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2  # New parameter to balance exploration and exploitation\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.7, 0.85)\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer with dynamic exploration-exploitation balance and adaptive mutation enhancements for improved convergence speed.", "configspace": "", "generation": 58, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.855172362762411, 0.8659220062066514, 0.8637095763143072, 0.8684988538912858, 0.8706178808280751, 0.8751219187668274, 0.875735912251711, 0.885371256709463, 0.8758475010261377, 0.7897606772692076, 0.7780464349312769, 0.7624645084216468, 0.790407854606426, 0.7684057734533948, 0.7577109760176526, 0.7463787822833655, 0.7635591696458801, 0.779950701825359, 0.13747259024931702, 0.17055399530404325, 0.10616000006249326, 0.1054032523020253, 0.09860999203547127, 0.1492505945832061, 0.13335637946585543, 0.17177438431859848, 0.13050905674168511, 0.12194495847323028, 0.10146753381107443, 0.12917549606342704, 0.09420335672677227, 0.11375308881847501, 0.15008416491683807, 0.13767435057858823, 0.11576480629799935, 0.1288823478391028, 0.923616252156499, 0.9332626390541685, 0.938880057085812, 0.9569887426622138, 0.965427221297927, 0.9546026869304383, 0.9564207320607586, 0.9179055589109922, 0.9596409617365361, 0.6799231502956886, 0.6228315181907147, 0.6053077427826508, 0.643633539398441, 0.6454159831097687, 0.6594364776109957, 0.631077911470128, 0.6268580537351958, 0.6605426909472558, 0.8738257379897179, 0.856710039802895, 0.8528781296374323, 0.8745713666194754, 0.8723434837413657, 0.8649739958849774, 0.8430124741409125, 0.8534555458270078, 0.8270341744551444, 0.551609459177163, 0.6482143574659887, 0.6614293324084707, 0.6270736700295976, 0.6204393695553585, 0.7290196604281876, 0.5295222584265555, 0.6848937949327776, 0.6093807291259528, 0.5465871851585957, 0.4904294373669038, 0.3946434652820141, 0.6080634587822529, 0.5095203797813246, 0.5660126831435907, 0.565944899087218, 0.6275651600885951, 0.6601593986255824, 0.6815124455687847, 0.6854782027332962, 0.6837219132887977, 0.6919529395951656, 0.6662903194597756, 0.6739183325345197, 0.65822892108458, 0.664930023254529, 0.6535756775119573, 0.7392823068939017, 0.7606036896234012, 0.7366869729255578, 0.7567829085685326, 0.7565024511641978, 0.7422584293751445, 0.7414979218067919, 0.7895831302138768, 0.7506469026429001, 0.30000960624512785, 0.24762357706142113, 0.3644720772137978, 0.535693056038617, 0.25791088630295056, 0.5635676852911893, 0.411931198692415, 0.38074161349804125, 0.25527312128765856, 0.5196475226986133, 0.49754361755002785, 0.5619986287546577, 0.5513970794512073, 0.5140282507326093, 0.5540378543456437, 0.5567276713407624, 0.48309762896091235, 0.5926462818682783, 0.8292316049554413, 0.8040513681872443, 0.8231935820366749, 0.8204589686524565, 0.8347687689102576, 0.8283266882051368, 0.8240075686093223, 0.8119240453212864, 0.8478159671843553, 0.08471603955940465, 0.3269841909688398, 0.15584601958897926, 0.11946357558329346, 0.3135240296628693, 0.10580123910878647, 0.09906976740325169, 0.09333877826716819, 0.11331074715137834, 0.5154384242785006, 0.1803933474093794, 0.13860169662543853, 0.14837852583895927, 0.1674644578945137, 0.17496579937812673, 0.15331341602347348, 0.24947180259253354, 0.182268737549234, 0.5005475397078184, 0.4811407806137462, 0.5377490758421786, 0.4867492420791786, 0.47820616455337817, 0.48736033498544773, 0.5242773046718501, 0.5566141040541208, 0.5427556727632223, 0.3896049525718689, 0.41282700043680387, 0.42158935101037176, 0.40232756243805645, 0.38652903995092525, 0.38638984348144334, 0.40047031823279766, 0.45695157847683643, 0.4069924652942214, 0.19933732654038117, 0.18606894657419026, 0.1673109473458444, 0.216324927810446, 0.19287814885471466, 0.1834506894129444, 0.18836828764373648, 0.19333976771871386, 0.20323648161897667, 0.23640093830712194, 0.2199459491448139, 0.19488160744504957, 0.21346316747808358, 0.5834111239602295, 0.5474039843918898, 0.6400349897232377, 0.6421359954798118, 0.22280323530908253, 0.1718399849181258, 0.18627685918462045, 0.16164795410939348, 0.8656755749455405, 0.20396844494786914, 0.8257571772650467, 0.20358013983404077, 0.7674193301061665, 0.18330540067054635, 0.1553301798026454, 0.16839318394936542, 0.8025939547242359, 0.20788461803011848, 0.7147711167660822, 0.836414744094142, 0.7948373782477776, 0.12659423940961168, 0.8558619002585786, 0.18868553146758382, 0.2003710379036382, 0.1779633789611531, 0.1867325129591343, 0.21877009451217122, 0.1851188699205697, 0.18538773835269862, 0.18705575881167003, 0.16899127761440813, 0.077243001792072, 0.0792303244840199, 0.08746923025707387, 0.07112272177183443, 0.07311984198393673, 0.08259774318144808, 0.08036078786819523, 0.06537377928504606, 0.0744343419763247]}, "mutation_prompt": null}
{"id": "8c52f627-61f3-436d-b43a-a4673b352b67", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85  # Increased initial scale factor for exploration\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2  # New parameter to balance exploration and exploitation\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.7, 0.85)\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer with dynamic exploration-exploitation balance and adaptive mutation enhancements for improved convergence speed.", "configspace": "", "generation": 58, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.855172362762411, 0.8659220062066514, 0.8637095763143072, 0.8684988538912858, 0.8706178808280751, 0.8751219187668274, 0.875735912251711, 0.885371256709463, 0.8758475010261377, 0.7897606772692076, 0.7780464349312769, 0.7624645084216468, 0.790407854606426, 0.7684057734533948, 0.7577109760176526, 0.7463787822833655, 0.7635591696458801, 0.779950701825359, 0.13747259024931702, 0.17055399530404325, 0.10616000006249326, 0.1054032523020253, 0.09860999203547127, 0.1492505945832061, 0.13335637946585543, 0.17177438431859848, 0.13050905674168511, 0.12194495847323028, 0.10146753381107443, 0.12917549606342704, 0.09420335672677227, 0.11375308881847501, 0.15008416491683807, 0.13767435057858823, 0.11576480629799935, 0.1288823478391028, 0.923616252156499, 0.9332626390541685, 0.938880057085812, 0.9569887426622138, 0.965427221297927, 0.9546026869304383, 0.9564207320607586, 0.9179055589109922, 0.9596409617365361, 0.6799231502956886, 0.6228315181907147, 0.6053077427826508, 0.643633539398441, 0.6454159831097687, 0.6594364776109957, 0.631077911470128, 0.6268580537351958, 0.6605426909472558, 0.8738257379897179, 0.856710039802895, 0.8528781296374323, 0.8745713666194754, 0.8723434837413657, 0.8649739958849774, 0.8430124741409125, 0.8534555458270078, 0.8270341744551444, 0.551609459177163, 0.6482143574659887, 0.6614293324084707, 0.6270736700295976, 0.6204393695553585, 0.7290196604281876, 0.5295222584265555, 0.6848937949327776, 0.6093807291259528, 0.5465871851585957, 0.4904294373669038, 0.3946434652820141, 0.6080634587822529, 0.5095203797813246, 0.5660126831435907, 0.565944899087218, 0.6275651600885951, 0.6601593986255824, 0.6815124455687847, 0.6854782027332962, 0.6837219132887977, 0.6919529395951656, 0.6662903194597756, 0.6739183325345197, 0.65822892108458, 0.664930023254529, 0.6535756775119573, 0.7392823068939017, 0.7606036896234012, 0.7366869729255578, 0.7567829085685326, 0.7565024511641978, 0.7422584293751445, 0.7414979218067919, 0.7895831302138768, 0.7506469026429001, 0.30000960624512785, 0.24762357706142113, 0.3644720772137978, 0.535693056038617, 0.25791088630295056, 0.5635676852911893, 0.411931198692415, 0.38074161349804125, 0.25527312128765856, 0.5196475226986133, 0.49754361755002785, 0.5619986287546577, 0.5513970794512073, 0.5140282507326093, 0.5540378543456437, 0.5567276713407624, 0.48309762896091235, 0.5926462818682783, 0.8292316049554413, 0.8040513681872443, 0.8231935820366749, 0.8204589686524565, 0.8347687689102576, 0.8283266882051368, 0.8240075686093223, 0.8119240453212864, 0.8478159671843553, 0.08471603955940465, 0.3269841909688398, 0.15584601958897926, 0.11946357558329346, 0.3135240296628693, 0.10580123910878647, 0.09906976740325169, 0.09333877826716819, 0.11331074715137834, 0.5154384242785006, 0.1803933474093794, 0.13860169662543853, 0.14837852583895927, 0.1674644578945137, 0.17496579937812673, 0.15331341602347348, 0.24947180259253354, 0.182268737549234, 0.5005475397078184, 0.4811407806137462, 0.5377490758421786, 0.4867492420791786, 0.47820616455337817, 0.48736033498544773, 0.5242773046718501, 0.5566141040541208, 0.5427556727632223, 0.3896049525718689, 0.41282700043680387, 0.42158935101037176, 0.40232756243805645, 0.38652903995092525, 0.38638984348144334, 0.40047031823279766, 0.45695157847683643, 0.4069924652942214, 0.19933732654038117, 0.18606894657419026, 0.1673109473458444, 0.216324927810446, 0.19287814885471466, 0.1834506894129444, 0.18836828764373648, 0.19333976771871386, 0.20323648161897667, 0.23640093830712194, 0.2199459491448139, 0.19488160744504957, 0.21346316747808358, 0.5834111239602295, 0.5474039843918898, 0.6400349897232377, 0.6421359954798118, 0.22280323530908253, 0.1718399849181258, 0.18627685918462045, 0.16164795410939348, 0.8656755749455405, 0.20396844494786914, 0.8257571772650467, 0.20358013983404077, 0.7674193301061665, 0.18330540067054635, 0.1553301798026454, 0.16839318394936542, 0.8025939547242359, 0.20788461803011848, 0.7147711167660822, 0.836414744094142, 0.7948373782477776, 0.12659423940961168, 0.8558619002585786, 0.18868553146758382, 0.2003710379036382, 0.1779633789611531, 0.1867325129591343, 0.21877009451217122, 0.1851188699205697, 0.18538773835269862, 0.18705575881167003, 0.16899127761440813, 0.077243001792072, 0.0792303244840199, 0.08746923025707387, 0.07112272177183443, 0.07311984198393673, 0.08259774318144808, 0.08036078786819523, 0.06537377928504606, 0.0744343419763247]}, "mutation_prompt": null}
{"id": "8b421f0d-bde9-4713-8531-110e80e8f338", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85  # Increased initial scale factor for exploration\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2  # New parameter to balance exploration and exploitation\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.7, 0.85)\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer with dynamic exploration-exploitation balance and adaptive mutation enhancements for improved convergence speed.", "configspace": "", "generation": 58, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.855172362762411, 0.8659220062066514, 0.8637095763143072, 0.8684988538912858, 0.8706178808280751, 0.8751219187668274, 0.875735912251711, 0.885371256709463, 0.8758475010261377, 0.7897606772692076, 0.7780464349312769, 0.7624645084216468, 0.790407854606426, 0.7684057734533948, 0.7577109760176526, 0.7463787822833655, 0.7635591696458801, 0.779950701825359, 0.13747259024931702, 0.17055399530404325, 0.10616000006249326, 0.1054032523020253, 0.09860999203547127, 0.1492505945832061, 0.13335637946585543, 0.17177438431859848, 0.13050905674168511, 0.12194495847323028, 0.10146753381107443, 0.12917549606342704, 0.09420335672677227, 0.11375308881847501, 0.15008416491683807, 0.13767435057858823, 0.11576480629799935, 0.1288823478391028, 0.923616252156499, 0.9332626390541685, 0.938880057085812, 0.9569887426622138, 0.965427221297927, 0.9546026869304383, 0.9564207320607586, 0.9179055589109922, 0.9596409617365361, 0.6799231502956886, 0.6228315181907147, 0.6053077427826508, 0.643633539398441, 0.6454159831097687, 0.6594364776109957, 0.631077911470128, 0.6268580537351958, 0.6605426909472558, 0.8738257379897179, 0.856710039802895, 0.8528781296374323, 0.8745713666194754, 0.8723434837413657, 0.8649739958849774, 0.8430124741409125, 0.8534555458270078, 0.8270341744551444, 0.551609459177163, 0.6482143574659887, 0.6614293324084707, 0.6270736700295976, 0.6204393695553585, 0.7290196604281876, 0.5295222584265555, 0.6848937949327776, 0.6093807291259528, 0.5465871851585957, 0.4904294373669038, 0.3946434652820141, 0.6080634587822529, 0.5095203797813246, 0.5660126831435907, 0.565944899087218, 0.6275651600885951, 0.6601593986255824, 0.6815124455687847, 0.6854782027332962, 0.6837219132887977, 0.6919529395951656, 0.6662903194597756, 0.6739183325345197, 0.65822892108458, 0.664930023254529, 0.6535756775119573, 0.7392823068939017, 0.7606036896234012, 0.7366869729255578, 0.7567829085685326, 0.7565024511641978, 0.7422584293751445, 0.7414979218067919, 0.7895831302138768, 0.7506469026429001, 0.30000960624512785, 0.24762357706142113, 0.3644720772137978, 0.535693056038617, 0.25791088630295056, 0.5635676852911893, 0.411931198692415, 0.38074161349804125, 0.25527312128765856, 0.5196475226986133, 0.49754361755002785, 0.5619986287546577, 0.5513970794512073, 0.5140282507326093, 0.5540378543456437, 0.5567276713407624, 0.48309762896091235, 0.5926462818682783, 0.8292316049554413, 0.8040513681872443, 0.8231935820366749, 0.8204589686524565, 0.8347687689102576, 0.8283266882051368, 0.8240075686093223, 0.8119240453212864, 0.8478159671843553, 0.08471603955940465, 0.3269841909688398, 0.15584601958897926, 0.11946357558329346, 0.3135240296628693, 0.10580123910878647, 0.09906976740325169, 0.09333877826716819, 0.11331074715137834, 0.5154384242785006, 0.1803933474093794, 0.13860169662543853, 0.14837852583895927, 0.1674644578945137, 0.17496579937812673, 0.15331341602347348, 0.24947180259253354, 0.182268737549234, 0.5005475397078184, 0.4811407806137462, 0.5377490758421786, 0.4867492420791786, 0.47820616455337817, 0.48736033498544773, 0.5242773046718501, 0.5566141040541208, 0.5427556727632223, 0.3896049525718689, 0.41282700043680387, 0.42158935101037176, 0.40232756243805645, 0.38652903995092525, 0.38638984348144334, 0.40047031823279766, 0.45695157847683643, 0.4069924652942214, 0.19933732654038117, 0.18606894657419026, 0.1673109473458444, 0.216324927810446, 0.19287814885471466, 0.1834506894129444, 0.18836828764373648, 0.19333976771871386, 0.20323648161897667, 0.23640093830712194, 0.2199459491448139, 0.19488160744504957, 0.21346316747808358, 0.5834111239602295, 0.5474039843918898, 0.6400349897232377, 0.6421359954798118, 0.22280323530908253, 0.1718399849181258, 0.18627685918462045, 0.16164795410939348, 0.8656755749455405, 0.20396844494786914, 0.8257571772650467, 0.20358013983404077, 0.7674193301061665, 0.18330540067054635, 0.1553301798026454, 0.16839318394936542, 0.8025939547242359, 0.20788461803011848, 0.7147711167660822, 0.836414744094142, 0.7948373782477776, 0.12659423940961168, 0.8558619002585786, 0.18868553146758382, 0.2003710379036382, 0.1779633789611531, 0.1867325129591343, 0.21877009451217122, 0.1851188699205697, 0.18538773835269862, 0.18705575881167003, 0.16899127761440813, 0.077243001792072, 0.0792303244840199, 0.08746923025707387, 0.07112272177183443, 0.07311984198393673, 0.08259774318144808, 0.08036078786819523, 0.06537377928504606, 0.0744343419763247]}, "mutation_prompt": null}
{"id": "5bc1692c-62e1-4a7a-9f7a-82289cea35c3", "solution": "import numpy as np\n\nclass EnhancedAdaptiveMutationOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.82  # Slightly reduced for controlled exploration\n        self.cross_prob = 0.92  # Slightly increased for better exploitation\n        self.adaptation_rate = 0.04  # Adjusted adaptation rate\n        self.exploit_factor = 0.22  # Adjusted for improved balance\n\n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n\n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.72, 0.82)  # Narrowed range for more stability\n            self.cross_prob = np.random.uniform(0.9, 0.98)  # Narrowed range for more consistent crossover\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedAdaptiveMutationOptimizer", "description": "EnhancedAdaptiveMutationOptimizer: An improved evolutionary algorithm with refined adaptive mutation strategy and dynamic parameter tuning for efficient convergence.", "configspace": "", "generation": 83, "fitness": 0.4814074163607579, "feedback": "The algorithm EnhancedAdaptiveMutationOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.48 with standard deviation 0.29.", "error": "", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.8726967957409952, 0.8641783263178913, 0.8830320368275935, 0.8857137647129292, 0.8621027856664413, 0.863975341806371, 0.8867430422953724, 0.8551244780586689, 0.8788610609872696, 0.7613788322087089, 0.7688968127980871, 0.7949611360717632, 0.8017305627313359, 0.7610047963439306, 0.7844985860603524, 0.7891886993868428, 0.7718926634957203, 0.7978881976105887, 0.11822658684361609, 0.13946338237848455, 0.12216776509767735, 0.11349212324242286, 0.1840542386788926, 0.11507810330120849, 0.10399319432950649, 0.12951048015666633, 0.1379076100996779, 0.11606062102330927, 0.12018124178060374, 0.13441200981823953, 0.11672052283755652, 0.10463536255691108, 0.1499820137919976, 0.11052907533730771, 0.1269906295939276, 0.1322130070877836, 0.9285446709597297, 0.9297461693850472, 0.895776339785191, 0.9455826494309224, 0.8924205267887086, 0.9519872204158095, 0.981943319950623, 0.9517234205199875, 0.919113629778487, 0.6687380542661837, 0.636617547095168, 0.6534363841615758, 0.660261551111795, 0.6367025629703039, 0.641063621746703, 0.6730181087768635, 0.64922972237086, 0.6340750278164361, 0.85707303701827, 0.811807952231689, 0.8302742668786716, 0.862839608474181, 0.874546890284466, 0.8497809720950485, 0.8492100414636652, 0.886260517008685, 0.8652013073273658, 0.34174613765438644, 0.4923200997866999, 0.18509626026760229, 0.6368198854044016, 0.552582328904714, 0.48213851598723134, 0.6028315973739768, 0.5892340633741571, 0.4160046255726122, 0.6751726482609203, 0.009927337853740004, 0.04521549003862768, 0.5894938213636384, 0.41764571002470563, 0.661349610525928, 0.4735362191389043, 0.6391536534071252, 0.5021851221667899, 0.6667604986209457, 0.6511805579301644, 0.6712848762816965, 0.6896942968670843, 0.6401933630104228, 0.6670064004620685, 0.7026446286312447, 0.7114632803926878, 0.6936908974232696, 0.7650846095970294, 0.7602320543459304, 0.7717666005122917, 0.7254520730508031, 0.7073073601821623, 0.7606006878527533, 0.7553283850550259, 0.7742058624778585, 0.7656862082716472, 0.3106787499081285, 0.14718351279485598, 0.4832088432623898, 0.5910079020133143, 0.23949276781206674, 0.5821217827625995, 0.3533722457220909, 0.22808640919208312, 0.26302371323797336, 0.5566423033555186, 0.5425815355455661, 0.5394486381805417, 0.5363171736609962, 0.5675356648550394, 0.6021268668003934, 0.5860349854914446, 0.5724840540244729, 0.5232101514252876, 0.8171110360225504, 0.8134350338590015, 0.8174911296646736, 0.8197891901881634, 0.8160039213482195, 0.8068095493399533, 0.8351222802006566, 0.7985691772621121, 0.8278156664958086, 0.12656323770787936, 0.11106089976121314, 0.11747507092349407, 0.10468753720901935, 0.14915657377901703, 0.11382232061156605, 0.10822682524485283, 0.11453827544419515, 0.12152291997064235, 0.2010383967595899, 0.14702287932934055, 0.1876424412018931, 0.16214024608830335, 0.14859412206201705, 0.12450924571044508, 0.1795734938019834, 0.27165099183298513, 0.1875259850682195, 0.4441531597898857, 0.4758448277311259, 0.49836370151745235, 0.49545162927142294, 0.48567140858828695, 0.5315865269266826, 0.5449103601699945, 0.537932584721263, 0.51941321757749, 0.4336231227940951, 0.44233450273314334, 0.4424513060115026, 0.3950585878383214, 0.39050867971118064, 0.384366115989732, 0.4436420146712956, 0.434162093413601, 0.48541318908862063, 0.19574073474280052, 0.20081645610772436, 0.19810056377305374, 0.19489938642009308, 0.20132438153153853, 0.19569049209351963, 0.22120436969501456, 0.19089745469483388, 0.19487938456723009, 0.30332950068002396, 0.3274239429084931, 0.23168746697864007, 0.4555586865820026, 0.2291549109919121, 0.2270848771444337, 0.4937824412431099, 0.46685488239757744, 0.20567535530899161, 0.8848019240726643, 0.8341627258157315, 0.17069702047922142, 0.8755803851446328, 0.18464631688584798, 0.7647862965550222, 0.8249275180306924, 0.16929678836978168, 0.18572053176128123, 0.8389781629285544, 0.8406022498477616, 0.8792852997976385, 0.2026594825478012, 0.16242367344212794, 0.16414792909698372, 0.2074618357975222, 0.9014905380514968, 0.8760129653687864, 0.17627426833597803, 0.17949628647887694, 0.18426669399331486, 0.1778264853178032, 0.15824468796790914, 0.18382290903908294, 0.19095485763887954, 0.17566971007686205, 0.1784820630390257, 0.07744305187372535, 0.08406444480436026, 0.0922886413792734, 0.07983564049068859, 0.08154972373846725, 0.07956774877155381, 0.08521673004916719, 0.08407954310821553, 0.08629196522798666]}, "mutation_prompt": null}
{"id": "01edbd44-fd5f-4fb5-a9c0-d481b2330086", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85  # Increased initial scale factor for exploration\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2  # New parameter to balance exploration and exploitation\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.7, 0.85)\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer with dynamic exploration-exploitation balance and adaptive mutation enhancements for improved convergence speed.", "configspace": "", "generation": 58, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.855172362762411, 0.8659220062066514, 0.8637095763143072, 0.8684988538912858, 0.8706178808280751, 0.8751219187668274, 0.875735912251711, 0.885371256709463, 0.8758475010261377, 0.7897606772692076, 0.7780464349312769, 0.7624645084216468, 0.790407854606426, 0.7684057734533948, 0.7577109760176526, 0.7463787822833655, 0.7635591696458801, 0.779950701825359, 0.13747259024931702, 0.17055399530404325, 0.10616000006249326, 0.1054032523020253, 0.09860999203547127, 0.1492505945832061, 0.13335637946585543, 0.17177438431859848, 0.13050905674168511, 0.12194495847323028, 0.10146753381107443, 0.12917549606342704, 0.09420335672677227, 0.11375308881847501, 0.15008416491683807, 0.13767435057858823, 0.11576480629799935, 0.1288823478391028, 0.923616252156499, 0.9332626390541685, 0.938880057085812, 0.9569887426622138, 0.965427221297927, 0.9546026869304383, 0.9564207320607586, 0.9179055589109922, 0.9596409617365361, 0.6799231502956886, 0.6228315181907147, 0.6053077427826508, 0.643633539398441, 0.6454159831097687, 0.6594364776109957, 0.631077911470128, 0.6268580537351958, 0.6605426909472558, 0.8738257379897179, 0.856710039802895, 0.8528781296374323, 0.8745713666194754, 0.8723434837413657, 0.8649739958849774, 0.8430124741409125, 0.8534555458270078, 0.8270341744551444, 0.551609459177163, 0.6482143574659887, 0.6614293324084707, 0.6270736700295976, 0.6204393695553585, 0.7290196604281876, 0.5295222584265555, 0.6848937949327776, 0.6093807291259528, 0.5465871851585957, 0.4904294373669038, 0.3946434652820141, 0.6080634587822529, 0.5095203797813246, 0.5660126831435907, 0.565944899087218, 0.6275651600885951, 0.6601593986255824, 0.6815124455687847, 0.6854782027332962, 0.6837219132887977, 0.6919529395951656, 0.6662903194597756, 0.6739183325345197, 0.65822892108458, 0.664930023254529, 0.6535756775119573, 0.7392823068939017, 0.7606036896234012, 0.7366869729255578, 0.7567829085685326, 0.7565024511641978, 0.7422584293751445, 0.7414979218067919, 0.7895831302138768, 0.7506469026429001, 0.30000960624512785, 0.24762357706142113, 0.3644720772137978, 0.535693056038617, 0.25791088630295056, 0.5635676852911893, 0.411931198692415, 0.38074161349804125, 0.25527312128765856, 0.5196475226986133, 0.49754361755002785, 0.5619986287546577, 0.5513970794512073, 0.5140282507326093, 0.5540378543456437, 0.5567276713407624, 0.48309762896091235, 0.5926462818682783, 0.8292316049554413, 0.8040513681872443, 0.8231935820366749, 0.8204589686524565, 0.8347687689102576, 0.8283266882051368, 0.8240075686093223, 0.8119240453212864, 0.8478159671843553, 0.08471603955940465, 0.3269841909688398, 0.15584601958897926, 0.11946357558329346, 0.3135240296628693, 0.10580123910878647, 0.09906976740325169, 0.09333877826716819, 0.11331074715137834, 0.5154384242785006, 0.1803933474093794, 0.13860169662543853, 0.14837852583895927, 0.1674644578945137, 0.17496579937812673, 0.15331341602347348, 0.24947180259253354, 0.182268737549234, 0.5005475397078184, 0.4811407806137462, 0.5377490758421786, 0.4867492420791786, 0.47820616455337817, 0.48736033498544773, 0.5242773046718501, 0.5566141040541208, 0.5427556727632223, 0.3896049525718689, 0.41282700043680387, 0.42158935101037176, 0.40232756243805645, 0.38652903995092525, 0.38638984348144334, 0.40047031823279766, 0.45695157847683643, 0.4069924652942214, 0.19933732654038117, 0.18606894657419026, 0.1673109473458444, 0.216324927810446, 0.19287814885471466, 0.1834506894129444, 0.18836828764373648, 0.19333976771871386, 0.20323648161897667, 0.23640093830712194, 0.2199459491448139, 0.19488160744504957, 0.21346316747808358, 0.5834111239602295, 0.5474039843918898, 0.6400349897232377, 0.6421359954798118, 0.22280323530908253, 0.1718399849181258, 0.18627685918462045, 0.16164795410939348, 0.8656755749455405, 0.20396844494786914, 0.8257571772650467, 0.20358013983404077, 0.7674193301061665, 0.18330540067054635, 0.1553301798026454, 0.16839318394936542, 0.8025939547242359, 0.20788461803011848, 0.7147711167660822, 0.836414744094142, 0.7948373782477776, 0.12659423940961168, 0.8558619002585786, 0.18868553146758382, 0.2003710379036382, 0.1779633789611531, 0.1867325129591343, 0.21877009451217122, 0.1851188699205697, 0.18538773835269862, 0.18705575881167003, 0.16899127761440813, 0.077243001792072, 0.0792303244840199, 0.08746923025707387, 0.07112272177183443, 0.07311984198393673, 0.08259774318144808, 0.08036078786819523, 0.06537377928504606, 0.0744343419763247]}, "mutation_prompt": null}
{"id": "32456e81-7947-4ba8-8e1e-6ec2d115b182", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85  # Increased initial scale factor for exploration\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2  # New parameter to balance exploration and exploitation\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.7, 0.85)\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer with dynamic exploration-exploitation balance and adaptive mutation enhancements for improved convergence speed.", "configspace": "", "generation": 58, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.855172362762411, 0.8659220062066514, 0.8637095763143072, 0.8684988538912858, 0.8706178808280751, 0.8751219187668274, 0.875735912251711, 0.885371256709463, 0.8758475010261377, 0.7897606772692076, 0.7780464349312769, 0.7624645084216468, 0.790407854606426, 0.7684057734533948, 0.7577109760176526, 0.7463787822833655, 0.7635591696458801, 0.779950701825359, 0.13747259024931702, 0.17055399530404325, 0.10616000006249326, 0.1054032523020253, 0.09860999203547127, 0.1492505945832061, 0.13335637946585543, 0.17177438431859848, 0.13050905674168511, 0.12194495847323028, 0.10146753381107443, 0.12917549606342704, 0.09420335672677227, 0.11375308881847501, 0.15008416491683807, 0.13767435057858823, 0.11576480629799935, 0.1288823478391028, 0.923616252156499, 0.9332626390541685, 0.938880057085812, 0.9569887426622138, 0.965427221297927, 0.9546026869304383, 0.9564207320607586, 0.9179055589109922, 0.9596409617365361, 0.6799231502956886, 0.6228315181907147, 0.6053077427826508, 0.643633539398441, 0.6454159831097687, 0.6594364776109957, 0.631077911470128, 0.6268580537351958, 0.6605426909472558, 0.8738257379897179, 0.856710039802895, 0.8528781296374323, 0.8745713666194754, 0.8723434837413657, 0.8649739958849774, 0.8430124741409125, 0.8534555458270078, 0.8270341744551444, 0.551609459177163, 0.6482143574659887, 0.6614293324084707, 0.6270736700295976, 0.6204393695553585, 0.7290196604281876, 0.5295222584265555, 0.6848937949327776, 0.6093807291259528, 0.5465871851585957, 0.4904294373669038, 0.3946434652820141, 0.6080634587822529, 0.5095203797813246, 0.5660126831435907, 0.565944899087218, 0.6275651600885951, 0.6601593986255824, 0.6815124455687847, 0.6854782027332962, 0.6837219132887977, 0.6919529395951656, 0.6662903194597756, 0.6739183325345197, 0.65822892108458, 0.664930023254529, 0.6535756775119573, 0.7392823068939017, 0.7606036896234012, 0.7366869729255578, 0.7567829085685326, 0.7565024511641978, 0.7422584293751445, 0.7414979218067919, 0.7895831302138768, 0.7506469026429001, 0.30000960624512785, 0.24762357706142113, 0.3644720772137978, 0.535693056038617, 0.25791088630295056, 0.5635676852911893, 0.411931198692415, 0.38074161349804125, 0.25527312128765856, 0.5196475226986133, 0.49754361755002785, 0.5619986287546577, 0.5513970794512073, 0.5140282507326093, 0.5540378543456437, 0.5567276713407624, 0.48309762896091235, 0.5926462818682783, 0.8292316049554413, 0.8040513681872443, 0.8231935820366749, 0.8204589686524565, 0.8347687689102576, 0.8283266882051368, 0.8240075686093223, 0.8119240453212864, 0.8478159671843553, 0.08471603955940465, 0.3269841909688398, 0.15584601958897926, 0.11946357558329346, 0.3135240296628693, 0.10580123910878647, 0.09906976740325169, 0.09333877826716819, 0.11331074715137834, 0.5154384242785006, 0.1803933474093794, 0.13860169662543853, 0.14837852583895927, 0.1674644578945137, 0.17496579937812673, 0.15331341602347348, 0.24947180259253354, 0.182268737549234, 0.5005475397078184, 0.4811407806137462, 0.5377490758421786, 0.4867492420791786, 0.47820616455337817, 0.48736033498544773, 0.5242773046718501, 0.5566141040541208, 0.5427556727632223, 0.3896049525718689, 0.41282700043680387, 0.42158935101037176, 0.40232756243805645, 0.38652903995092525, 0.38638984348144334, 0.40047031823279766, 0.45695157847683643, 0.4069924652942214, 0.19933732654038117, 0.18606894657419026, 0.1673109473458444, 0.216324927810446, 0.19287814885471466, 0.1834506894129444, 0.18836828764373648, 0.19333976771871386, 0.20323648161897667, 0.23640093830712194, 0.2199459491448139, 0.19488160744504957, 0.21346316747808358, 0.5834111239602295, 0.5474039843918898, 0.6400349897232377, 0.6421359954798118, 0.22280323530908253, 0.1718399849181258, 0.18627685918462045, 0.16164795410939348, 0.8656755749455405, 0.20396844494786914, 0.8257571772650467, 0.20358013983404077, 0.7674193301061665, 0.18330540067054635, 0.1553301798026454, 0.16839318394936542, 0.8025939547242359, 0.20788461803011848, 0.7147711167660822, 0.836414744094142, 0.7948373782477776, 0.12659423940961168, 0.8558619002585786, 0.18868553146758382, 0.2003710379036382, 0.1779633789611531, 0.1867325129591343, 0.21877009451217122, 0.1851188699205697, 0.18538773835269862, 0.18705575881167003, 0.16899127761440813, 0.077243001792072, 0.0792303244840199, 0.08746923025707387, 0.07112272177183443, 0.07311984198393673, 0.08259774318144808, 0.08036078786819523, 0.06537377928504606, 0.0744343419763247]}, "mutation_prompt": null}
{"id": "cfb6c825-df0f-40df-8279-e2b06af19e57", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85  # Increased initial scale factor for exploration\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2  # New parameter to balance exploration and exploitation\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.7, 0.85)\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer with dynamic exploration-exploitation balance and adaptive mutation enhancements for improved convergence speed.", "configspace": "", "generation": 58, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.855172362762411, 0.8659220062066514, 0.8637095763143072, 0.8684988538912858, 0.8706178808280751, 0.8751219187668274, 0.875735912251711, 0.885371256709463, 0.8758475010261377, 0.7897606772692076, 0.7780464349312769, 0.7624645084216468, 0.790407854606426, 0.7684057734533948, 0.7577109760176526, 0.7463787822833655, 0.7635591696458801, 0.779950701825359, 0.13747259024931702, 0.17055399530404325, 0.10616000006249326, 0.1054032523020253, 0.09860999203547127, 0.1492505945832061, 0.13335637946585543, 0.17177438431859848, 0.13050905674168511, 0.12194495847323028, 0.10146753381107443, 0.12917549606342704, 0.09420335672677227, 0.11375308881847501, 0.15008416491683807, 0.13767435057858823, 0.11576480629799935, 0.1288823478391028, 0.923616252156499, 0.9332626390541685, 0.938880057085812, 0.9569887426622138, 0.965427221297927, 0.9546026869304383, 0.9564207320607586, 0.9179055589109922, 0.9596409617365361, 0.6799231502956886, 0.6228315181907147, 0.6053077427826508, 0.643633539398441, 0.6454159831097687, 0.6594364776109957, 0.631077911470128, 0.6268580537351958, 0.6605426909472558, 0.8738257379897179, 0.856710039802895, 0.8528781296374323, 0.8745713666194754, 0.8723434837413657, 0.8649739958849774, 0.8430124741409125, 0.8534555458270078, 0.8270341744551444, 0.551609459177163, 0.6482143574659887, 0.6614293324084707, 0.6270736700295976, 0.6204393695553585, 0.7290196604281876, 0.5295222584265555, 0.6848937949327776, 0.6093807291259528, 0.5465871851585957, 0.4904294373669038, 0.3946434652820141, 0.6080634587822529, 0.5095203797813246, 0.5660126831435907, 0.565944899087218, 0.6275651600885951, 0.6601593986255824, 0.6815124455687847, 0.6854782027332962, 0.6837219132887977, 0.6919529395951656, 0.6662903194597756, 0.6739183325345197, 0.65822892108458, 0.664930023254529, 0.6535756775119573, 0.7392823068939017, 0.7606036896234012, 0.7366869729255578, 0.7567829085685326, 0.7565024511641978, 0.7422584293751445, 0.7414979218067919, 0.7895831302138768, 0.7506469026429001, 0.30000960624512785, 0.24762357706142113, 0.3644720772137978, 0.535693056038617, 0.25791088630295056, 0.5635676852911893, 0.411931198692415, 0.38074161349804125, 0.25527312128765856, 0.5196475226986133, 0.49754361755002785, 0.5619986287546577, 0.5513970794512073, 0.5140282507326093, 0.5540378543456437, 0.5567276713407624, 0.48309762896091235, 0.5926462818682783, 0.8292316049554413, 0.8040513681872443, 0.8231935820366749, 0.8204589686524565, 0.8347687689102576, 0.8283266882051368, 0.8240075686093223, 0.8119240453212864, 0.8478159671843553, 0.08471603955940465, 0.3269841909688398, 0.15584601958897926, 0.11946357558329346, 0.3135240296628693, 0.10580123910878647, 0.09906976740325169, 0.09333877826716819, 0.11331074715137834, 0.5154384242785006, 0.1803933474093794, 0.13860169662543853, 0.14837852583895927, 0.1674644578945137, 0.17496579937812673, 0.15331341602347348, 0.24947180259253354, 0.182268737549234, 0.5005475397078184, 0.4811407806137462, 0.5377490758421786, 0.4867492420791786, 0.47820616455337817, 0.48736033498544773, 0.5242773046718501, 0.5566141040541208, 0.5427556727632223, 0.3896049525718689, 0.41282700043680387, 0.42158935101037176, 0.40232756243805645, 0.38652903995092525, 0.38638984348144334, 0.40047031823279766, 0.45695157847683643, 0.4069924652942214, 0.19933732654038117, 0.18606894657419026, 0.1673109473458444, 0.216324927810446, 0.19287814885471466, 0.1834506894129444, 0.18836828764373648, 0.19333976771871386, 0.20323648161897667, 0.23640093830712194, 0.2199459491448139, 0.19488160744504957, 0.21346316747808358, 0.5834111239602295, 0.5474039843918898, 0.6400349897232377, 0.6421359954798118, 0.22280323530908253, 0.1718399849181258, 0.18627685918462045, 0.16164795410939348, 0.8656755749455405, 0.20396844494786914, 0.8257571772650467, 0.20358013983404077, 0.7674193301061665, 0.18330540067054635, 0.1553301798026454, 0.16839318394936542, 0.8025939547242359, 0.20788461803011848, 0.7147711167660822, 0.836414744094142, 0.7948373782477776, 0.12659423940961168, 0.8558619002585786, 0.18868553146758382, 0.2003710379036382, 0.1779633789611531, 0.1867325129591343, 0.21877009451217122, 0.1851188699205697, 0.18538773835269862, 0.18705575881167003, 0.16899127761440813, 0.077243001792072, 0.0792303244840199, 0.08746923025707387, 0.07112272177183443, 0.07311984198393673, 0.08259774318144808, 0.08036078786819523, 0.06537377928504606, 0.0744343419763247]}, "mutation_prompt": null}
{"id": "69bc4bca-8fb4-4261-9e19-b2df98d3e579", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85  # Increased initial scale factor for exploration\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2  # New parameter to balance exploration and exploitation\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.7, 0.85)\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer with dynamic exploration-exploitation balance and adaptive mutation enhancements for improved convergence speed.", "configspace": "", "generation": 58, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.855172362762411, 0.8659220062066514, 0.8637095763143072, 0.8684988538912858, 0.8706178808280751, 0.8751219187668274, 0.875735912251711, 0.885371256709463, 0.8758475010261377, 0.7897606772692076, 0.7780464349312769, 0.7624645084216468, 0.790407854606426, 0.7684057734533948, 0.7577109760176526, 0.7463787822833655, 0.7635591696458801, 0.779950701825359, 0.13747259024931702, 0.17055399530404325, 0.10616000006249326, 0.1054032523020253, 0.09860999203547127, 0.1492505945832061, 0.13335637946585543, 0.17177438431859848, 0.13050905674168511, 0.12194495847323028, 0.10146753381107443, 0.12917549606342704, 0.09420335672677227, 0.11375308881847501, 0.15008416491683807, 0.13767435057858823, 0.11576480629799935, 0.1288823478391028, 0.923616252156499, 0.9332626390541685, 0.938880057085812, 0.9569887426622138, 0.965427221297927, 0.9546026869304383, 0.9564207320607586, 0.9179055589109922, 0.9596409617365361, 0.6799231502956886, 0.6228315181907147, 0.6053077427826508, 0.643633539398441, 0.6454159831097687, 0.6594364776109957, 0.631077911470128, 0.6268580537351958, 0.6605426909472558, 0.8738257379897179, 0.856710039802895, 0.8528781296374323, 0.8745713666194754, 0.8723434837413657, 0.8649739958849774, 0.8430124741409125, 0.8534555458270078, 0.8270341744551444, 0.551609459177163, 0.6482143574659887, 0.6614293324084707, 0.6270736700295976, 0.6204393695553585, 0.7290196604281876, 0.5295222584265555, 0.6848937949327776, 0.6093807291259528, 0.5465871851585957, 0.4904294373669038, 0.3946434652820141, 0.6080634587822529, 0.5095203797813246, 0.5660126831435907, 0.565944899087218, 0.6275651600885951, 0.6601593986255824, 0.6815124455687847, 0.6854782027332962, 0.6837219132887977, 0.6919529395951656, 0.6662903194597756, 0.6739183325345197, 0.65822892108458, 0.664930023254529, 0.6535756775119573, 0.7392823068939017, 0.7606036896234012, 0.7366869729255578, 0.7567829085685326, 0.7565024511641978, 0.7422584293751445, 0.7414979218067919, 0.7895831302138768, 0.7506469026429001, 0.30000960624512785, 0.24762357706142113, 0.3644720772137978, 0.535693056038617, 0.25791088630295056, 0.5635676852911893, 0.411931198692415, 0.38074161349804125, 0.25527312128765856, 0.5196475226986133, 0.49754361755002785, 0.5619986287546577, 0.5513970794512073, 0.5140282507326093, 0.5540378543456437, 0.5567276713407624, 0.48309762896091235, 0.5926462818682783, 0.8292316049554413, 0.8040513681872443, 0.8231935820366749, 0.8204589686524565, 0.8347687689102576, 0.8283266882051368, 0.8240075686093223, 0.8119240453212864, 0.8478159671843553, 0.08471603955940465, 0.3269841909688398, 0.15584601958897926, 0.11946357558329346, 0.3135240296628693, 0.10580123910878647, 0.09906976740325169, 0.09333877826716819, 0.11331074715137834, 0.5154384242785006, 0.1803933474093794, 0.13860169662543853, 0.14837852583895927, 0.1674644578945137, 0.17496579937812673, 0.15331341602347348, 0.24947180259253354, 0.182268737549234, 0.5005475397078184, 0.4811407806137462, 0.5377490758421786, 0.4867492420791786, 0.47820616455337817, 0.48736033498544773, 0.5242773046718501, 0.5566141040541208, 0.5427556727632223, 0.3896049525718689, 0.41282700043680387, 0.42158935101037176, 0.40232756243805645, 0.38652903995092525, 0.38638984348144334, 0.40047031823279766, 0.45695157847683643, 0.4069924652942214, 0.19933732654038117, 0.18606894657419026, 0.1673109473458444, 0.216324927810446, 0.19287814885471466, 0.1834506894129444, 0.18836828764373648, 0.19333976771871386, 0.20323648161897667, 0.23640093830712194, 0.2199459491448139, 0.19488160744504957, 0.21346316747808358, 0.5834111239602295, 0.5474039843918898, 0.6400349897232377, 0.6421359954798118, 0.22280323530908253, 0.1718399849181258, 0.18627685918462045, 0.16164795410939348, 0.8656755749455405, 0.20396844494786914, 0.8257571772650467, 0.20358013983404077, 0.7674193301061665, 0.18330540067054635, 0.1553301798026454, 0.16839318394936542, 0.8025939547242359, 0.20788461803011848, 0.7147711167660822, 0.836414744094142, 0.7948373782477776, 0.12659423940961168, 0.8558619002585786, 0.18868553146758382, 0.2003710379036382, 0.1779633789611531, 0.1867325129591343, 0.21877009451217122, 0.1851188699205697, 0.18538773835269862, 0.18705575881167003, 0.16899127761440813, 0.077243001792072, 0.0792303244840199, 0.08746923025707387, 0.07112272177183443, 0.07311984198393673, 0.08259774318144808, 0.08036078786819523, 0.06537377928504606, 0.0744343419763247]}, "mutation_prompt": null}
{"id": "c7364a72-c72d-4469-b99a-32241c2bf82e", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85  # Increased initial scale factor for exploration\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2  # New parameter to balance exploration and exploitation\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.7, 0.85)\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer with dynamic exploration-exploitation balance and adaptive mutation enhancements for improved convergence speed.", "configspace": "", "generation": 58, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.855172362762411, 0.8659220062066514, 0.8637095763143072, 0.8684988538912858, 0.8706178808280751, 0.8751219187668274, 0.875735912251711, 0.885371256709463, 0.8758475010261377, 0.7897606772692076, 0.7780464349312769, 0.7624645084216468, 0.790407854606426, 0.7684057734533948, 0.7577109760176526, 0.7463787822833655, 0.7635591696458801, 0.779950701825359, 0.13747259024931702, 0.17055399530404325, 0.10616000006249326, 0.1054032523020253, 0.09860999203547127, 0.1492505945832061, 0.13335637946585543, 0.17177438431859848, 0.13050905674168511, 0.12194495847323028, 0.10146753381107443, 0.12917549606342704, 0.09420335672677227, 0.11375308881847501, 0.15008416491683807, 0.13767435057858823, 0.11576480629799935, 0.1288823478391028, 0.923616252156499, 0.9332626390541685, 0.938880057085812, 0.9569887426622138, 0.965427221297927, 0.9546026869304383, 0.9564207320607586, 0.9179055589109922, 0.9596409617365361, 0.6799231502956886, 0.6228315181907147, 0.6053077427826508, 0.643633539398441, 0.6454159831097687, 0.6594364776109957, 0.631077911470128, 0.6268580537351958, 0.6605426909472558, 0.8738257379897179, 0.856710039802895, 0.8528781296374323, 0.8745713666194754, 0.8723434837413657, 0.8649739958849774, 0.8430124741409125, 0.8534555458270078, 0.8270341744551444, 0.551609459177163, 0.6482143574659887, 0.6614293324084707, 0.6270736700295976, 0.6204393695553585, 0.7290196604281876, 0.5295222584265555, 0.6848937949327776, 0.6093807291259528, 0.5465871851585957, 0.4904294373669038, 0.3946434652820141, 0.6080634587822529, 0.5095203797813246, 0.5660126831435907, 0.565944899087218, 0.6275651600885951, 0.6601593986255824, 0.6815124455687847, 0.6854782027332962, 0.6837219132887977, 0.6919529395951656, 0.6662903194597756, 0.6739183325345197, 0.65822892108458, 0.664930023254529, 0.6535756775119573, 0.7392823068939017, 0.7606036896234012, 0.7366869729255578, 0.7567829085685326, 0.7565024511641978, 0.7422584293751445, 0.7414979218067919, 0.7895831302138768, 0.7506469026429001, 0.30000960624512785, 0.24762357706142113, 0.3644720772137978, 0.535693056038617, 0.25791088630295056, 0.5635676852911893, 0.411931198692415, 0.38074161349804125, 0.25527312128765856, 0.5196475226986133, 0.49754361755002785, 0.5619986287546577, 0.5513970794512073, 0.5140282507326093, 0.5540378543456437, 0.5567276713407624, 0.48309762896091235, 0.5926462818682783, 0.8292316049554413, 0.8040513681872443, 0.8231935820366749, 0.8204589686524565, 0.8347687689102576, 0.8283266882051368, 0.8240075686093223, 0.8119240453212864, 0.8478159671843553, 0.08471603955940465, 0.3269841909688398, 0.15584601958897926, 0.11946357558329346, 0.3135240296628693, 0.10580123910878647, 0.09906976740325169, 0.09333877826716819, 0.11331074715137834, 0.5154384242785006, 0.1803933474093794, 0.13860169662543853, 0.14837852583895927, 0.1674644578945137, 0.17496579937812673, 0.15331341602347348, 0.24947180259253354, 0.182268737549234, 0.5005475397078184, 0.4811407806137462, 0.5377490758421786, 0.4867492420791786, 0.47820616455337817, 0.48736033498544773, 0.5242773046718501, 0.5566141040541208, 0.5427556727632223, 0.3896049525718689, 0.41282700043680387, 0.42158935101037176, 0.40232756243805645, 0.38652903995092525, 0.38638984348144334, 0.40047031823279766, 0.45695157847683643, 0.4069924652942214, 0.19933732654038117, 0.18606894657419026, 0.1673109473458444, 0.216324927810446, 0.19287814885471466, 0.1834506894129444, 0.18836828764373648, 0.19333976771871386, 0.20323648161897667, 0.23640093830712194, 0.2199459491448139, 0.19488160744504957, 0.21346316747808358, 0.5834111239602295, 0.5474039843918898, 0.6400349897232377, 0.6421359954798118, 0.22280323530908253, 0.1718399849181258, 0.18627685918462045, 0.16164795410939348, 0.8656755749455405, 0.20396844494786914, 0.8257571772650467, 0.20358013983404077, 0.7674193301061665, 0.18330540067054635, 0.1553301798026454, 0.16839318394936542, 0.8025939547242359, 0.20788461803011848, 0.7147711167660822, 0.836414744094142, 0.7948373782477776, 0.12659423940961168, 0.8558619002585786, 0.18868553146758382, 0.2003710379036382, 0.1779633789611531, 0.1867325129591343, 0.21877009451217122, 0.1851188699205697, 0.18538773835269862, 0.18705575881167003, 0.16899127761440813, 0.077243001792072, 0.0792303244840199, 0.08746923025707387, 0.07112272177183443, 0.07311984198393673, 0.08259774318144808, 0.08036078786819523, 0.06537377928504606, 0.0744343419763247]}, "mutation_prompt": null}
{"id": "4921736f-52d0-4e05-be23-03053008c402", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / (np.std(fitness) + 1e-9))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor)\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            diversity = np.std(population, axis=0).mean()\n            self.scale_factor = np.random.uniform(0.7, 0.85) * (1.0 + 0.5 * diversity)\n            self.cross_prob = np.random.uniform(0.88, 1.0) * (1.0 - 0.5 * diversity)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "Enhanced differential evolution with dynamic parameter adjustment for improved exploration and convergence.", "configspace": "", "generation": 89, "fitness": 0.04265634413366982, "feedback": "The algorithm EnhancedHybridEvolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.05.", "error": "", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.07960169599829481, 0.12019489354570301, 0.09169502728636048, 0.08952233024927114, 0.10081559755750091, 0.07709668639236078, 0.1130737788513616, 0.07431300570909605, 0.13938069165453293, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01467079663371329, 0.005375109906600173, 0.010643411704069683, 0.015138892188330644, 0.03944197723996001, 0.018248263482334326, 9.999999999998899e-05, 0.010674738340807233, 9.999999999998899e-05, 9.999999999998899e-05, 0.004278156031116698, 0.01959972157639278, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0496902684458117, 0.0764207318216813, 0.05201624587153508, 0.05673817440658946, 0.08070730439784801, 0.04617891003242802, 0.0638860334912611, 0.05924582599150108, 0.04906955506060895, 9.999999999998899e-05, 9.999999999998899e-05, 0.012123204335733662, 9.999999999998899e-05, 0.00031549654350837564, 9.999999999998899e-05, 9.999999999998899e-05, 0.011293333694524565, 0.0011659611748046084, 0.10027683525177622, 0.03775594762470191, 0.052233822106523387, 0.0667108215001172, 0.02725496812965944, 9.999999999998899e-05, 0.04452255909290448, 0.05931056463008866, 0.012101411288544806, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1180312912103163, 0.13879659513922615, 0.14838054695461433, 0.10904147305811496, 0.1208852020365685, 0.09580441870675127, 0.1240568991094797, 0.09813905381914123, 0.1210557193025883, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006101769545772684, 9.999999999998899e-05, 0.01759993274736349, 0.00044560991905961966, 9.999999999998899e-05, 0.0267656688986897, 0.07037543064596374, 0.08536085957726136, 0.059328965068867756, 0.09855305120349966, 0.10852972522114013, 0.05749383798124841, 0.08808199726801991, 0.05671393358747501, 0.07726393575557644, 0.09606267484187503, 0.1236791622480492, 0.14352810184653642, 0.13800672315110074, 0.11210986007058432, 0.1025140421398899, 0.12028165949079228, 0.17377774300845283, 0.11363346445524236, 0.03791056846418561, 0.04113238236437067, 0.05463654710198407, 0.056957211629895754, 0.0685153509636166, 0.06342850570876157, 0.0837317855149382, 0.09386031173166853, 0.06412526395900253, 0.0916346253723066, 0.11265122169124497, 0.13345086981233123, 0.10289055837941885, 0.08883940427375181, 0.10164506690472042, 0.12245976138762271, 0.08179810958793099, 0.1261963614278906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06423200958298092, 0.12245317797387067, 0.08167024703901915, 0.06718871428537254, 0.1207914665021157, 0.06661401029160186, 0.07245568600050101, 0.09643604708838482, 0.0693612576838919, 0.03824121102611444, 0.10051730792859848, 0.06187188832952162, 0.0506857903344724, 0.09535009720595566, 0.05170719224855025, 0.05647920829917075, 0.04019044166964181, 0.04143420019681854, 0.13480174570059533, 0.16326401040962768, 0.14763022729669195, 0.12227370752691169, 0.12410988590570471, 0.13696181871230417, 0.14969714796693134, 0.12327067442044737, 0.14689007985489466, 0.04351757481356344, 0.015916393435176368, 0.031393493129599714, 0.027015293023570086, 0.018487330591705486, 0.020045516730027746, 0.012882686472221794, 0.012230485508419209, 0.01745630416284416]}, "mutation_prompt": null}
{"id": "3cdf9770-8787-4371-9eee-afa3a67ac9b7", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2\n        self.selection_pressure = 0.15  # New parameter to control selection pressure\n\n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / (np.std(fitness) + 1e-8))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Introduce competitive selection\n            elite_idx = np.argsort(fitness)[:int(self.population_size * self.selection_pressure)]\n            population = np.append(population[elite_idx], population[np.random.choice(elite_idx, self.population_size - len(elite_idx))], axis=0)\n            fitness = np.array([func(ind) for ind in population])\n            func_evals += self.population_size - len(elite_idx)\n\n            self.scale_factor = np.random.uniform(0.7, 0.85)\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "Introducing competitive selection and diversity-enhancing mechanisms to boost convergence speed in the evolutionary optimization process.", "configspace": "", "generation": 90, "fitness": 0.06901554921883997, "feedback": "The algorithm EnhancedHybridEvolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.06.", "error": "", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.1266278972219046, 0.14741075078909383, 0.20370710532454372, 0.10417753152507025, 0.09906254918822055, 0.14891595250044942, 0.11710606346549446, 0.2355316667544436, 0.18368201833227682, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.039462446906304516, 0.02113314912512776, 0.008826394693726591, 0.05146910916491598, 0.024831941257669632, 0.08003500756917692, 0.029543673210175814, 0.05985421608231278, 0.03136127410220757, 0.017932841958281487, 0.0287202254012211, 0.0030586642786986085, 0.02949450931546327, 0.030646061620620668, 0.04330076770378377, 0.013442620033246033, 0.021132535405897213, 9.999999999998899e-05, 0.07954121012160031, 0.06918347912886713, 0.07632533477146386, 0.09967049843640652, 0.052225381471341814, 0.07094113956562997, 0.16417493486199874, 0.07956550236848847, 0.06815944183193734, 0.036156684582606013, 9.999999999998899e-05, 0.04890361139421184, 0.03155037201073341, 0.02564756978473337, 0.0021448856032824093, 0.14960050360940857, 0.05526340878519842, 0.09107756625779839, 0.1217141715294503, 0.10954829924612075, 0.08522842863435853, 0.17413652936750657, 0.09925156617357223, 0.02458146225643143, 0.09701061836905789, 0.10021670287471696, 0.16652370850214515, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06806811785926004, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.044528239950027415, 9.999999999998899e-05, 9.999999999998899e-05, 0.03519686747022899, 9.999999999998899e-05, 0.008140170892235954, 9.999999999998899e-05, 0.06115475175367413, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.22079078458873758, 0.19215896071103267, 0.18997420475319282, 0.16865740378485994, 0.12789603150686601, 0.13790697721033762, 0.17184704026252984, 0.15299734924197816, 0.1898440076252914, 0.03256989733298232, 0.0402427751352048, 0.02502179462357146, 0.040423531658986045, 0.04648295282056569, 0.048967915986678046, 0.04913942914338021, 0.05847482767432688, 0.03042598544952213, 0.08974032845212021, 0.08210542755179318, 0.07795699896472597, 0.09855305120349966, 0.10852972522114013, 0.07975299423210669, 0.13172791585996546, 0.05852084401435165, 0.07726393575557644, 0.10413864200976419, 0.12900448459720992, 0.16240675307095698, 0.1681075471076081, 0.14693721475471888, 0.1733933617069986, 0.1944053720416612, 0.17377774300845283, 0.1552197840806575, 0.08863166077860463, 0.11243253189638691, 0.08779953913034255, 0.09385697662392611, 0.09765502485154998, 0.11433745799853745, 0.0837317855149382, 0.11129702841564426, 0.0911319055626596, 0.15129013326857044, 0.12286197783208463, 0.17819360344238389, 0.12986917011724763, 0.11383047263872847, 0.13459313940673545, 0.12717521017908073, 0.13642521761250614, 0.1269326405672344, 0.1660537158388341, 9.999999999998899e-05, 0.13723467837069636, 0.14729906821228866, 0.1569927201732808, 0.13997941136305203, 9.999999999998899e-05, 0.16856776338945023, 0.13880215325910283, 0.10065386338580451, 0.07466602457976645, 0.10464438920045704, 0.13743094804534617, 0.17014535199947423, 0.08519136468100008, 0.08159743619488413, 0.09643604708838482, 0.16285307414032746, 0.057616120413310656, 0.10051730792859848, 0.16734724653925748, 0.0506857903344724, 0.04406134136991435, 0.07007987735377752, 0.0777459010099274, 0.06270323481011075, 0.1182456341520507, 0.13480174570059533, 0.14810101692195332, 0.14763022729669195, 0.12027610738837102, 0.11533688485268212, 0.12469006822816753, 0.14969714796693134, 0.13096047505405828, 0.15175245943596438, 0.043933500922223145, 0.03212142694843645, 0.031393493129599714, 0.041294836808509205, 0.03316847442665949, 0.04698918255910489, 0.04565713842726815, 0.026034564806138638, 0.026461815187177495]}, "mutation_prompt": null}
{"id": "fb0af1c5-8515-4a00-b5da-4fd7c1efd1e0", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8  # Slightly reduced initial scale factor for more control\n        self.cross_prob = 0.92  # Slightly increased for better exploration\n        self.adaptation_rate = 0.06  # Increased adaptation rate for faster adjustment\n        self.exploit_factor = 0.25  # Enhanced exploitation factor for refined balance\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                \n                # Improved adaptive strategy for more nuanced adaptation\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.median(fitness) - fitness[i]) / (np.std(fitness) + 1e-9))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                # Enhanced crossover strategy with more variability\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.1))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Adaptive parameters are fine-tuned for improved dynamics\n            self.scale_factor = np.random.uniform(0.75, 0.8)\n            self.cross_prob = np.random.uniform(0.9, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "A hybrid evolutionary optimizer with refined adaptive mutation and crossover strategies for enhanced convergence and balance.", "configspace": "", "generation": 91, "fitness": 0.48502132484394445, "feedback": "The algorithm EnhancedHybridEvolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.49 with standard deviation 0.29.", "error": "", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.8606523928865937, 0.8737733358721071, 0.864734122796924, 0.872134331144601, 0.8699424601742715, 0.8757914866371469, 0.8954716184671259, 0.8936442774334614, 0.8820111002746968, 0.7709102920056385, 0.7607174573001501, 0.7587398093933893, 0.7958692653649434, 0.7822363253302769, 0.7960281370972543, 0.7932389597540077, 0.7833473667687503, 0.7940795627959951, 0.3555587389385422, 0.11226125742194493, 0.1597534314235194, 0.12879717248788003, 0.1381461444983928, 0.13049125623152613, 0.1784064488376751, 0.14538013630045354, 0.292668359382809, 0.11445562687834154, 0.12141802112196243, 0.1096505683850344, 0.1548572473642189, 0.1382520064709155, 0.11920834298106875, 0.11336977909416257, 0.1265722264993614, 0.253456325035912, 0.9484782713502592, 0.9401544809009539, 0.9291096525175598, 0.8743931907652107, 0.934197181874425, 0.9624575232608299, 0.9293037300908987, 0.9671082640115145, 0.9587773585079006, 0.6779761342235187, 0.6355407026663953, 0.6788439478499225, 0.6835375268653789, 0.647729182199319, 0.6379593303652547, 0.6644450661120849, 0.6981456325720607, 0.6472530348990724, 0.8784275260298988, 0.8649383312339203, 0.8129870237808601, 0.8923205139905174, 0.874708933312236, 0.3728327331204443, 0.8839099359520338, 0.8947466504616695, 0.8468010685006369, 0.40235609368505765, 0.13085881318283865, 0.42918448607700144, 0.6206337086344218, 0.3658461481168954, 0.13396048390397386, 0.6231327231670523, 0.6573897740242178, 0.13194422314183518, 0.5577521773755556, 0.4481822150796879, 0.550992809498775, 0.5948876751146359, 0.6123124213690772, 0.6940921759711111, 0.5765715810176884, 0.5936195298241503, 0.6580176903317247, 0.7312576091120562, 0.7181403306909998, 0.5830990564331755, 0.45799637922139935, 0.710531581338697, 0.7287711578378908, 0.7295349962671354, 0.7156810349169667, 0.6919203791976374, 0.7540181684723809, 0.7760549717521823, 0.7594070428997571, 0.7465952828379073, 0.7387264917651332, 0.7577990892306561, 0.7787065435249765, 0.7562530608594186, 0.7714706251806571, 0.406978794414363, 0.15701246529771085, 0.2281331100139643, 0.24815422950937627, 0.6127155291789192, 0.580914186917007, 0.34733738185420393, 0.1420642525749516, 0.37648111393927164, 0.5827760504904007, 0.5774391433469066, 0.5518928130967609, 0.6063938822288611, 0.5670658939038654, 0.5753183903440391, 0.6237531383118947, 0.5573271095259125, 0.5653609012100291, 0.8348071308540894, 0.8390220219577527, 0.8520371302431364, 0.844370622490301, 0.8260319247754495, 0.8486893970709815, 0.8354616135758796, 0.8071441228999506, 0.8415925858131038, 0.13061794851488917, 0.10160642855568625, 0.11823595672738707, 0.13969650575388604, 0.15489582711849492, 0.12462577030328503, 0.1205510826772912, 0.1170165105985147, 0.11631209767202255, 0.18177513391329847, 0.20136651747279943, 0.16728374597960993, 0.1724500679124008, 0.24434907535887784, 0.2822574081436564, 0.24913699288560376, 0.38747431621295214, 0.25264820170478586, 0.5385894950105148, 0.4708653033595295, 0.49684113066064683, 0.5206646189064355, 0.5055523322514006, 0.5142811780848873, 0.6144594419113634, 0.5530702230490792, 0.5802457858991039, 0.47228392763248395, 0.3906988755968015, 0.42735385499191036, 0.42502001850099536, 0.43279419563016697, 0.409877638006379, 0.41467459832456743, 0.4432314241691835, 0.5298694002595967, 0.18633578790665473, 0.1964906311578143, 0.19265443115859826, 0.1891635964088434, 0.18802729253834594, 0.1864807899892298, 0.19317666969295189, 0.17041429748573012, 0.20600976911932922, 0.4771254401427981, 0.23901875058688993, 0.22206640700456814, 0.679463458168338, 0.22425788061068175, 0.19227315219841667, 0.32660845019942075, 0.21278085194752927, 0.46783065683949376, 0.1715457957840374, 0.17122708926947272, 0.20632591887494522, 0.8539388482170553, 0.1985553970381868, 0.18294380830790635, 0.8496709015040295, 0.7925932990563032, 0.18121520098726474, 0.1541299359812507, 0.1679543548668978, 0.8386060194158367, 0.8560881981863169, 0.16414804454889131, 0.8394854234602912, 0.1990415841404216, 0.8147840278059347, 0.8698503900236059, 0.17751501165094252, 0.19262573968817265, 0.1845169577297836, 0.18464197969472518, 0.18776892731542283, 0.2107773831755314, 0.1912624599110324, 0.1792349299218433, 0.169107455430339, 0.076595606149231, 0.09048874125899298, 0.09017776692507506, 0.08171071105571792, 0.072939523820865, 0.08007000627223337, 0.08207200259803615, 0.08264178366076247, 0.08842181449888609]}, "mutation_prompt": null}
{"id": "da98fe20-c903-4327-8a6a-14ef062ca83d", "solution": "import numpy as np\n\nclass ImprovedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2\n        self.diversification_factor = 0.1  # New parameter to enhance population diversity\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / (np.std(fitness) + 1e-8))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c) + self.diversification_factor * np.random.normal(size=self.dim)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.75, 0.85)  # Narrower range for scale factor adjustment\n            self.cross_prob = np.random.uniform(0.88, 0.98)  # Slightly adjusted crossover probability range\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ImprovedHybridEvolutionaryOptimizer", "description": "An enhanced evolutionary algorithm introducing dynamic mutation scaling and increased diversity mechanisms for improved convergence.", "configspace": "", "generation": 92, "fitness": 0.23524626741761484, "feedback": "The algorithm ImprovedHybridEvolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.20.", "error": "", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.46545126080574395, 0.46846636246483275, 0.47523743325105194, 0.45856725400399845, 0.48543051348521826, 0.473987733307345, 0.4594327620130566, 0.4766068428158198, 0.46766795136526385, 0.09470544778386081, 0.09844781662772728, 0.058553366033972654, 0.0845056569571685, 0.08063483715337971, 0.05072712781006994, 0.07960309017857747, 0.06804675282827288, 0.07358613478705889, 0.10196386497642229, 0.10811612945425908, 0.0935709848433588, 0.11122359241848412, 0.09905224888938302, 0.13620430623759383, 0.1219301426642152, 0.10653120207777433, 0.09949225912649762, 0.09775447656032499, 0.1112373236481039, 0.10444480868453998, 0.09766867030822302, 0.09554998377756929, 0.1080517601563199, 0.095295247398416, 0.09590211992964703, 0.09682250012124005, 0.9592531416486287, 0.9466774810653945, 0.9646543639920748, 0.9558205629908674, 0.9439573720003749, 0.9584785421193593, 0.945425010795273, 0.9846870287816273, 0.9802491728872124, 0.3058464461898076, 0.2957251473734813, 0.3127456327907392, 0.31011078993863883, 0.29223706442587405, 0.29517531918667617, 0.2935538332648324, 0.3033327520589717, 0.2892639471963121, 0.36165832177916946, 0.3443988592553049, 0.5133183173003484, 0.3633704014065855, 0.381758159478393, 0.35975822040320127, 0.4923613659281624, 0.5077403060104602, 0.3518360928710609, 0.18776863287358547, 0.17121831166245305, 0.19378882206663284, 0.16851985472687592, 0.18807009526229357, 0.19112676054736044, 0.18435099546870604, 0.17596615243839164, 0.1769754054407997, 0.18276047588114697, 0.1806367765939645, 0.1706147889509695, 0.16605840872359423, 0.17128817218231018, 0.1814821846143957, 0.15407294023369045, 0.17057257996374742, 0.1826911285857189, 0.07526838345194642, 0.0325800734469085, 0.07550711945265443, 0.05301476114015169, 0.03570111407879284, 0.040450109347872076, 0.028943008933824732, 0.04273403677722232, 0.007929630953564137, 0.12433963609537912, 0.1228282564948231, 0.1037688132070409, 0.13360973309545265, 0.1028136649323953, 0.08163276834557143, 0.10918206907497952, 0.09700366770319047, 0.11825900436069547, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12392873774748481, 0.10287841545408849, 0.1132246336281334, 0.105971433561999, 0.12099798014107654, 0.10749915570112567, 0.12291049882238969, 0.10716713481413676, 0.1159232115967026, 0.4234477981930048, 0.47255162814084495, 0.414218415976516, 0.43433081440007526, 0.42752358044963756, 0.42548827168284686, 0.41159929358367975, 0.40923442594190385, 0.4093940963842607, 0.10613034784711894, 0.09372944835938779, 0.1020021526710001, 0.09014331293254418, 0.09041413463534465, 0.10244644635145028, 0.11221731812962354, 0.09408353469298603, 0.09195334902069552, 0.21291189461883298, 0.21146888452167845, 0.1915278153618024, 0.23299160038927935, 0.2512512306478183, 0.1393915228691036, 0.21344916311072848, 0.2488367169378357, 0.16040864839935243, 0.29775177080688275, 0.2937288990866288, 0.28147715001743556, 0.29502747567222987, 0.2944120778561228, 0.2833271091505971, 0.3064981734407959, 0.3040735616744865, 0.30052472171956435, 0.2369621000153629, 0.2247139408673643, 0.2510099183762131, 0.23373808428478726, 0.225884901739148, 0.20428955025255469, 0.2289040262617491, 0.22998586700686985, 0.23223300078133147, 0.18374049500179046, 0.2018694100290187, 0.20285048483156787, 0.195244417067151, 0.20121011936233413, 0.18409233287476012, 0.20296607306538195, 0.19206467987704434, 0.20923274226957767, 0.24335632250958128, 0.20703401979308222, 0.17440862310956162, 0.18501462231844057, 0.18625813876140485, 0.18529124235803263, 0.1815732015978183, 0.19124312016188671, 0.18551706199850648, 0.182085315936248, 0.16266918413205333, 0.15231669655592595, 0.17544762498786237, 0.18421304019890727, 0.6221271411438021, 0.5133166298871414, 0.6485982772099936, 0.5761466088167415, 0.16661527992291159, 0.20788694708553335, 0.4593916566200811, 0.5197718171804298, 0.5156982639652308, 0.5835522583298485, 0.12632389734933003, 0.2106579493210644, 0.2076130023790802, 0.18657350436244824, 0.1810992951177871, 0.19340873134963843, 0.19345982769746273, 0.18871042696781437, 0.18156887408491162, 0.19121684552187768, 0.18284035892408435, 0.19241882366770968, 0.07390232161597776, 0.07317049751813554, 0.08904296515154309, 0.07814017697740072, 0.07039125657120182, 0.07098332357022663, 0.07239802245178906, 0.07143250294439951, 0.0785559777819328]}, "mutation_prompt": null}
{"id": "16f381bf-c583-41f5-a85d-e7c076c9a2f1", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85  # Increased initial scale factor for exploration\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2  # New parameter to balance exploration and exploitation\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.7, 0.85)\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer with dynamic exploration-exploitation balance and adaptive mutation enhancements for improved convergence speed.", "configspace": "", "generation": 58, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.855172362762411, 0.8659220062066514, 0.8637095763143072, 0.8684988538912858, 0.8706178808280751, 0.8751219187668274, 0.875735912251711, 0.885371256709463, 0.8758475010261377, 0.7897606772692076, 0.7780464349312769, 0.7624645084216468, 0.790407854606426, 0.7684057734533948, 0.7577109760176526, 0.7463787822833655, 0.7635591696458801, 0.779950701825359, 0.13747259024931702, 0.17055399530404325, 0.10616000006249326, 0.1054032523020253, 0.09860999203547127, 0.1492505945832061, 0.13335637946585543, 0.17177438431859848, 0.13050905674168511, 0.12194495847323028, 0.10146753381107443, 0.12917549606342704, 0.09420335672677227, 0.11375308881847501, 0.15008416491683807, 0.13767435057858823, 0.11576480629799935, 0.1288823478391028, 0.923616252156499, 0.9332626390541685, 0.938880057085812, 0.9569887426622138, 0.965427221297927, 0.9546026869304383, 0.9564207320607586, 0.9179055589109922, 0.9596409617365361, 0.6799231502956886, 0.6228315181907147, 0.6053077427826508, 0.643633539398441, 0.6454159831097687, 0.6594364776109957, 0.631077911470128, 0.6268580537351958, 0.6605426909472558, 0.8738257379897179, 0.856710039802895, 0.8528781296374323, 0.8745713666194754, 0.8723434837413657, 0.8649739958849774, 0.8430124741409125, 0.8534555458270078, 0.8270341744551444, 0.551609459177163, 0.6482143574659887, 0.6614293324084707, 0.6270736700295976, 0.6204393695553585, 0.7290196604281876, 0.5295222584265555, 0.6848937949327776, 0.6093807291259528, 0.5465871851585957, 0.4904294373669038, 0.3946434652820141, 0.6080634587822529, 0.5095203797813246, 0.5660126831435907, 0.565944899087218, 0.6275651600885951, 0.6601593986255824, 0.6815124455687847, 0.6854782027332962, 0.6837219132887977, 0.6919529395951656, 0.6662903194597756, 0.6739183325345197, 0.65822892108458, 0.664930023254529, 0.6535756775119573, 0.7392823068939017, 0.7606036896234012, 0.7366869729255578, 0.7567829085685326, 0.7565024511641978, 0.7422584293751445, 0.7414979218067919, 0.7895831302138768, 0.7506469026429001, 0.30000960624512785, 0.24762357706142113, 0.3644720772137978, 0.535693056038617, 0.25791088630295056, 0.5635676852911893, 0.411931198692415, 0.38074161349804125, 0.25527312128765856, 0.5196475226986133, 0.49754361755002785, 0.5619986287546577, 0.5513970794512073, 0.5140282507326093, 0.5540378543456437, 0.5567276713407624, 0.48309762896091235, 0.5926462818682783, 0.8292316049554413, 0.8040513681872443, 0.8231935820366749, 0.8204589686524565, 0.8347687689102576, 0.8283266882051368, 0.8240075686093223, 0.8119240453212864, 0.8478159671843553, 0.08471603955940465, 0.3269841909688398, 0.15584601958897926, 0.11946357558329346, 0.3135240296628693, 0.10580123910878647, 0.09906976740325169, 0.09333877826716819, 0.11331074715137834, 0.5154384242785006, 0.1803933474093794, 0.13860169662543853, 0.14837852583895927, 0.1674644578945137, 0.17496579937812673, 0.15331341602347348, 0.24947180259253354, 0.182268737549234, 0.5005475397078184, 0.4811407806137462, 0.5377490758421786, 0.4867492420791786, 0.47820616455337817, 0.48736033498544773, 0.5242773046718501, 0.5566141040541208, 0.5427556727632223, 0.3896049525718689, 0.41282700043680387, 0.42158935101037176, 0.40232756243805645, 0.38652903995092525, 0.38638984348144334, 0.40047031823279766, 0.45695157847683643, 0.4069924652942214, 0.19933732654038117, 0.18606894657419026, 0.1673109473458444, 0.216324927810446, 0.19287814885471466, 0.1834506894129444, 0.18836828764373648, 0.19333976771871386, 0.20323648161897667, 0.23640093830712194, 0.2199459491448139, 0.19488160744504957, 0.21346316747808358, 0.5834111239602295, 0.5474039843918898, 0.6400349897232377, 0.6421359954798118, 0.22280323530908253, 0.1718399849181258, 0.18627685918462045, 0.16164795410939348, 0.8656755749455405, 0.20396844494786914, 0.8257571772650467, 0.20358013983404077, 0.7674193301061665, 0.18330540067054635, 0.1553301798026454, 0.16839318394936542, 0.8025939547242359, 0.20788461803011848, 0.7147711167660822, 0.836414744094142, 0.7948373782477776, 0.12659423940961168, 0.8558619002585786, 0.18868553146758382, 0.2003710379036382, 0.1779633789611531, 0.1867325129591343, 0.21877009451217122, 0.1851188699205697, 0.18538773835269862, 0.18705575881167003, 0.16899127761440813, 0.077243001792072, 0.0792303244840199, 0.08746923025707387, 0.07112272177183443, 0.07311984198393673, 0.08259774318144808, 0.08036078786819523, 0.06537377928504606, 0.0744343419763247]}, "mutation_prompt": null}
{"id": "7d390694-3d85-44e7-b3bf-fc110246d6dc", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85  # Increased initial scale factor for exploration\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2  # New parameter to balance exploration and exploitation\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.7, 0.85)\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer with dynamic exploration-exploitation balance and adaptive mutation enhancements for improved convergence speed.", "configspace": "", "generation": 58, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.855172362762411, 0.8659220062066514, 0.8637095763143072, 0.8684988538912858, 0.8706178808280751, 0.8751219187668274, 0.875735912251711, 0.885371256709463, 0.8758475010261377, 0.7897606772692076, 0.7780464349312769, 0.7624645084216468, 0.790407854606426, 0.7684057734533948, 0.7577109760176526, 0.7463787822833655, 0.7635591696458801, 0.779950701825359, 0.13747259024931702, 0.17055399530404325, 0.10616000006249326, 0.1054032523020253, 0.09860999203547127, 0.1492505945832061, 0.13335637946585543, 0.17177438431859848, 0.13050905674168511, 0.12194495847323028, 0.10146753381107443, 0.12917549606342704, 0.09420335672677227, 0.11375308881847501, 0.15008416491683807, 0.13767435057858823, 0.11576480629799935, 0.1288823478391028, 0.923616252156499, 0.9332626390541685, 0.938880057085812, 0.9569887426622138, 0.965427221297927, 0.9546026869304383, 0.9564207320607586, 0.9179055589109922, 0.9596409617365361, 0.6799231502956886, 0.6228315181907147, 0.6053077427826508, 0.643633539398441, 0.6454159831097687, 0.6594364776109957, 0.631077911470128, 0.6268580537351958, 0.6605426909472558, 0.8738257379897179, 0.856710039802895, 0.8528781296374323, 0.8745713666194754, 0.8723434837413657, 0.8649739958849774, 0.8430124741409125, 0.8534555458270078, 0.8270341744551444, 0.551609459177163, 0.6482143574659887, 0.6614293324084707, 0.6270736700295976, 0.6204393695553585, 0.7290196604281876, 0.5295222584265555, 0.6848937949327776, 0.6093807291259528, 0.5465871851585957, 0.4904294373669038, 0.3946434652820141, 0.6080634587822529, 0.5095203797813246, 0.5660126831435907, 0.565944899087218, 0.6275651600885951, 0.6601593986255824, 0.6815124455687847, 0.6854782027332962, 0.6837219132887977, 0.6919529395951656, 0.6662903194597756, 0.6739183325345197, 0.65822892108458, 0.664930023254529, 0.6535756775119573, 0.7392823068939017, 0.7606036896234012, 0.7366869729255578, 0.7567829085685326, 0.7565024511641978, 0.7422584293751445, 0.7414979218067919, 0.7895831302138768, 0.7506469026429001, 0.30000960624512785, 0.24762357706142113, 0.3644720772137978, 0.535693056038617, 0.25791088630295056, 0.5635676852911893, 0.411931198692415, 0.38074161349804125, 0.25527312128765856, 0.5196475226986133, 0.49754361755002785, 0.5619986287546577, 0.5513970794512073, 0.5140282507326093, 0.5540378543456437, 0.5567276713407624, 0.48309762896091235, 0.5926462818682783, 0.8292316049554413, 0.8040513681872443, 0.8231935820366749, 0.8204589686524565, 0.8347687689102576, 0.8283266882051368, 0.8240075686093223, 0.8119240453212864, 0.8478159671843553, 0.08471603955940465, 0.3269841909688398, 0.15584601958897926, 0.11946357558329346, 0.3135240296628693, 0.10580123910878647, 0.09906976740325169, 0.09333877826716819, 0.11331074715137834, 0.5154384242785006, 0.1803933474093794, 0.13860169662543853, 0.14837852583895927, 0.1674644578945137, 0.17496579937812673, 0.15331341602347348, 0.24947180259253354, 0.182268737549234, 0.5005475397078184, 0.4811407806137462, 0.5377490758421786, 0.4867492420791786, 0.47820616455337817, 0.48736033498544773, 0.5242773046718501, 0.5566141040541208, 0.5427556727632223, 0.3896049525718689, 0.41282700043680387, 0.42158935101037176, 0.40232756243805645, 0.38652903995092525, 0.38638984348144334, 0.40047031823279766, 0.45695157847683643, 0.4069924652942214, 0.19933732654038117, 0.18606894657419026, 0.1673109473458444, 0.216324927810446, 0.19287814885471466, 0.1834506894129444, 0.18836828764373648, 0.19333976771871386, 0.20323648161897667, 0.23640093830712194, 0.2199459491448139, 0.19488160744504957, 0.21346316747808358, 0.5834111239602295, 0.5474039843918898, 0.6400349897232377, 0.6421359954798118, 0.22280323530908253, 0.1718399849181258, 0.18627685918462045, 0.16164795410939348, 0.8656755749455405, 0.20396844494786914, 0.8257571772650467, 0.20358013983404077, 0.7674193301061665, 0.18330540067054635, 0.1553301798026454, 0.16839318394936542, 0.8025939547242359, 0.20788461803011848, 0.7147711167660822, 0.836414744094142, 0.7948373782477776, 0.12659423940961168, 0.8558619002585786, 0.18868553146758382, 0.2003710379036382, 0.1779633789611531, 0.1867325129591343, 0.21877009451217122, 0.1851188699205697, 0.18538773835269862, 0.18705575881167003, 0.16899127761440813, 0.077243001792072, 0.0792303244840199, 0.08746923025707387, 0.07112272177183443, 0.07311984198393673, 0.08259774318144808, 0.08036078786819523, 0.06537377928504606, 0.0744343419763247]}, "mutation_prompt": null}
{"id": "80531766-115e-4fd0-9a46-d377794179c7", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85  # Increased initial scale factor for exploration\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2  # New parameter to balance exploration and exploitation\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.7, 0.85)\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer with dynamic exploration-exploitation balance and adaptive mutation enhancements for improved convergence speed.", "configspace": "", "generation": 58, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.855172362762411, 0.8659220062066514, 0.8637095763143072, 0.8684988538912858, 0.8706178808280751, 0.8751219187668274, 0.875735912251711, 0.885371256709463, 0.8758475010261377, 0.7897606772692076, 0.7780464349312769, 0.7624645084216468, 0.790407854606426, 0.7684057734533948, 0.7577109760176526, 0.7463787822833655, 0.7635591696458801, 0.779950701825359, 0.13747259024931702, 0.17055399530404325, 0.10616000006249326, 0.1054032523020253, 0.09860999203547127, 0.1492505945832061, 0.13335637946585543, 0.17177438431859848, 0.13050905674168511, 0.12194495847323028, 0.10146753381107443, 0.12917549606342704, 0.09420335672677227, 0.11375308881847501, 0.15008416491683807, 0.13767435057858823, 0.11576480629799935, 0.1288823478391028, 0.923616252156499, 0.9332626390541685, 0.938880057085812, 0.9569887426622138, 0.965427221297927, 0.9546026869304383, 0.9564207320607586, 0.9179055589109922, 0.9596409617365361, 0.6799231502956886, 0.6228315181907147, 0.6053077427826508, 0.643633539398441, 0.6454159831097687, 0.6594364776109957, 0.631077911470128, 0.6268580537351958, 0.6605426909472558, 0.8738257379897179, 0.856710039802895, 0.8528781296374323, 0.8745713666194754, 0.8723434837413657, 0.8649739958849774, 0.8430124741409125, 0.8534555458270078, 0.8270341744551444, 0.551609459177163, 0.6482143574659887, 0.6614293324084707, 0.6270736700295976, 0.6204393695553585, 0.7290196604281876, 0.5295222584265555, 0.6848937949327776, 0.6093807291259528, 0.5465871851585957, 0.4904294373669038, 0.3946434652820141, 0.6080634587822529, 0.5095203797813246, 0.5660126831435907, 0.565944899087218, 0.6275651600885951, 0.6601593986255824, 0.6815124455687847, 0.6854782027332962, 0.6837219132887977, 0.6919529395951656, 0.6662903194597756, 0.6739183325345197, 0.65822892108458, 0.664930023254529, 0.6535756775119573, 0.7392823068939017, 0.7606036896234012, 0.7366869729255578, 0.7567829085685326, 0.7565024511641978, 0.7422584293751445, 0.7414979218067919, 0.7895831302138768, 0.7506469026429001, 0.30000960624512785, 0.24762357706142113, 0.3644720772137978, 0.535693056038617, 0.25791088630295056, 0.5635676852911893, 0.411931198692415, 0.38074161349804125, 0.25527312128765856, 0.5196475226986133, 0.49754361755002785, 0.5619986287546577, 0.5513970794512073, 0.5140282507326093, 0.5540378543456437, 0.5567276713407624, 0.48309762896091235, 0.5926462818682783, 0.8292316049554413, 0.8040513681872443, 0.8231935820366749, 0.8204589686524565, 0.8347687689102576, 0.8283266882051368, 0.8240075686093223, 0.8119240453212864, 0.8478159671843553, 0.08471603955940465, 0.3269841909688398, 0.15584601958897926, 0.11946357558329346, 0.3135240296628693, 0.10580123910878647, 0.09906976740325169, 0.09333877826716819, 0.11331074715137834, 0.5154384242785006, 0.1803933474093794, 0.13860169662543853, 0.14837852583895927, 0.1674644578945137, 0.17496579937812673, 0.15331341602347348, 0.24947180259253354, 0.182268737549234, 0.5005475397078184, 0.4811407806137462, 0.5377490758421786, 0.4867492420791786, 0.47820616455337817, 0.48736033498544773, 0.5242773046718501, 0.5566141040541208, 0.5427556727632223, 0.3896049525718689, 0.41282700043680387, 0.42158935101037176, 0.40232756243805645, 0.38652903995092525, 0.38638984348144334, 0.40047031823279766, 0.45695157847683643, 0.4069924652942214, 0.19933732654038117, 0.18606894657419026, 0.1673109473458444, 0.216324927810446, 0.19287814885471466, 0.1834506894129444, 0.18836828764373648, 0.19333976771871386, 0.20323648161897667, 0.23640093830712194, 0.2199459491448139, 0.19488160744504957, 0.21346316747808358, 0.5834111239602295, 0.5474039843918898, 0.6400349897232377, 0.6421359954798118, 0.22280323530908253, 0.1718399849181258, 0.18627685918462045, 0.16164795410939348, 0.8656755749455405, 0.20396844494786914, 0.8257571772650467, 0.20358013983404077, 0.7674193301061665, 0.18330540067054635, 0.1553301798026454, 0.16839318394936542, 0.8025939547242359, 0.20788461803011848, 0.7147711167660822, 0.836414744094142, 0.7948373782477776, 0.12659423940961168, 0.8558619002585786, 0.18868553146758382, 0.2003710379036382, 0.1779633789611531, 0.1867325129591343, 0.21877009451217122, 0.1851188699205697, 0.18538773835269862, 0.18705575881167003, 0.16899127761440813, 0.077243001792072, 0.0792303244840199, 0.08746923025707387, 0.07112272177183443, 0.07311984198393673, 0.08259774318144808, 0.08036078786819523, 0.06537377928504606, 0.0744343419763247]}, "mutation_prompt": null}
{"id": "82c93359-062e-49f0-98ca-581cb0625b57", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85  # Increased initial scale factor for exploration\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2  # New parameter to balance exploration and exploitation\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.7, 0.85)\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer with dynamic exploration-exploitation balance and adaptive mutation enhancements for improved convergence speed.", "configspace": "", "generation": 58, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.855172362762411, 0.8659220062066514, 0.8637095763143072, 0.8684988538912858, 0.8706178808280751, 0.8751219187668274, 0.875735912251711, 0.885371256709463, 0.8758475010261377, 0.7897606772692076, 0.7780464349312769, 0.7624645084216468, 0.790407854606426, 0.7684057734533948, 0.7577109760176526, 0.7463787822833655, 0.7635591696458801, 0.779950701825359, 0.13747259024931702, 0.17055399530404325, 0.10616000006249326, 0.1054032523020253, 0.09860999203547127, 0.1492505945832061, 0.13335637946585543, 0.17177438431859848, 0.13050905674168511, 0.12194495847323028, 0.10146753381107443, 0.12917549606342704, 0.09420335672677227, 0.11375308881847501, 0.15008416491683807, 0.13767435057858823, 0.11576480629799935, 0.1288823478391028, 0.923616252156499, 0.9332626390541685, 0.938880057085812, 0.9569887426622138, 0.965427221297927, 0.9546026869304383, 0.9564207320607586, 0.9179055589109922, 0.9596409617365361, 0.6799231502956886, 0.6228315181907147, 0.6053077427826508, 0.643633539398441, 0.6454159831097687, 0.6594364776109957, 0.631077911470128, 0.6268580537351958, 0.6605426909472558, 0.8738257379897179, 0.856710039802895, 0.8528781296374323, 0.8745713666194754, 0.8723434837413657, 0.8649739958849774, 0.8430124741409125, 0.8534555458270078, 0.8270341744551444, 0.551609459177163, 0.6482143574659887, 0.6614293324084707, 0.6270736700295976, 0.6204393695553585, 0.7290196604281876, 0.5295222584265555, 0.6848937949327776, 0.6093807291259528, 0.5465871851585957, 0.4904294373669038, 0.3946434652820141, 0.6080634587822529, 0.5095203797813246, 0.5660126831435907, 0.565944899087218, 0.6275651600885951, 0.6601593986255824, 0.6815124455687847, 0.6854782027332962, 0.6837219132887977, 0.6919529395951656, 0.6662903194597756, 0.6739183325345197, 0.65822892108458, 0.664930023254529, 0.6535756775119573, 0.7392823068939017, 0.7606036896234012, 0.7366869729255578, 0.7567829085685326, 0.7565024511641978, 0.7422584293751445, 0.7414979218067919, 0.7895831302138768, 0.7506469026429001, 0.30000960624512785, 0.24762357706142113, 0.3644720772137978, 0.535693056038617, 0.25791088630295056, 0.5635676852911893, 0.411931198692415, 0.38074161349804125, 0.25527312128765856, 0.5196475226986133, 0.49754361755002785, 0.5619986287546577, 0.5513970794512073, 0.5140282507326093, 0.5540378543456437, 0.5567276713407624, 0.48309762896091235, 0.5926462818682783, 0.8292316049554413, 0.8040513681872443, 0.8231935820366749, 0.8204589686524565, 0.8347687689102576, 0.8283266882051368, 0.8240075686093223, 0.8119240453212864, 0.8478159671843553, 0.08471603955940465, 0.3269841909688398, 0.15584601958897926, 0.11946357558329346, 0.3135240296628693, 0.10580123910878647, 0.09906976740325169, 0.09333877826716819, 0.11331074715137834, 0.5154384242785006, 0.1803933474093794, 0.13860169662543853, 0.14837852583895927, 0.1674644578945137, 0.17496579937812673, 0.15331341602347348, 0.24947180259253354, 0.182268737549234, 0.5005475397078184, 0.4811407806137462, 0.5377490758421786, 0.4867492420791786, 0.47820616455337817, 0.48736033498544773, 0.5242773046718501, 0.5566141040541208, 0.5427556727632223, 0.3896049525718689, 0.41282700043680387, 0.42158935101037176, 0.40232756243805645, 0.38652903995092525, 0.38638984348144334, 0.40047031823279766, 0.45695157847683643, 0.4069924652942214, 0.19933732654038117, 0.18606894657419026, 0.1673109473458444, 0.216324927810446, 0.19287814885471466, 0.1834506894129444, 0.18836828764373648, 0.19333976771871386, 0.20323648161897667, 0.23640093830712194, 0.2199459491448139, 0.19488160744504957, 0.21346316747808358, 0.5834111239602295, 0.5474039843918898, 0.6400349897232377, 0.6421359954798118, 0.22280323530908253, 0.1718399849181258, 0.18627685918462045, 0.16164795410939348, 0.8656755749455405, 0.20396844494786914, 0.8257571772650467, 0.20358013983404077, 0.7674193301061665, 0.18330540067054635, 0.1553301798026454, 0.16839318394936542, 0.8025939547242359, 0.20788461803011848, 0.7147711167660822, 0.836414744094142, 0.7948373782477776, 0.12659423940961168, 0.8558619002585786, 0.18868553146758382, 0.2003710379036382, 0.1779633789611531, 0.1867325129591343, 0.21877009451217122, 0.1851188699205697, 0.18538773835269862, 0.18705575881167003, 0.16899127761440813, 0.077243001792072, 0.0792303244840199, 0.08746923025707387, 0.07112272177183443, 0.07311984198393673, 0.08259774318144808, 0.08036078786819523, 0.06537377928504606, 0.0744343419763247]}, "mutation_prompt": null}
{"id": "4c679c72-27f8-4476-ab6f-a7ed4f24b897", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85  # Increased initial scale factor for exploration\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2  # New parameter to balance exploration and exploitation\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.7, 0.85)\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer with dynamic exploration-exploitation balance and adaptive mutation enhancements for improved convergence speed.", "configspace": "", "generation": 58, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.855172362762411, 0.8659220062066514, 0.8637095763143072, 0.8684988538912858, 0.8706178808280751, 0.8751219187668274, 0.875735912251711, 0.885371256709463, 0.8758475010261377, 0.7897606772692076, 0.7780464349312769, 0.7624645084216468, 0.790407854606426, 0.7684057734533948, 0.7577109760176526, 0.7463787822833655, 0.7635591696458801, 0.779950701825359, 0.13747259024931702, 0.17055399530404325, 0.10616000006249326, 0.1054032523020253, 0.09860999203547127, 0.1492505945832061, 0.13335637946585543, 0.17177438431859848, 0.13050905674168511, 0.12194495847323028, 0.10146753381107443, 0.12917549606342704, 0.09420335672677227, 0.11375308881847501, 0.15008416491683807, 0.13767435057858823, 0.11576480629799935, 0.1288823478391028, 0.923616252156499, 0.9332626390541685, 0.938880057085812, 0.9569887426622138, 0.965427221297927, 0.9546026869304383, 0.9564207320607586, 0.9179055589109922, 0.9596409617365361, 0.6799231502956886, 0.6228315181907147, 0.6053077427826508, 0.643633539398441, 0.6454159831097687, 0.6594364776109957, 0.631077911470128, 0.6268580537351958, 0.6605426909472558, 0.8738257379897179, 0.856710039802895, 0.8528781296374323, 0.8745713666194754, 0.8723434837413657, 0.8649739958849774, 0.8430124741409125, 0.8534555458270078, 0.8270341744551444, 0.551609459177163, 0.6482143574659887, 0.6614293324084707, 0.6270736700295976, 0.6204393695553585, 0.7290196604281876, 0.5295222584265555, 0.6848937949327776, 0.6093807291259528, 0.5465871851585957, 0.4904294373669038, 0.3946434652820141, 0.6080634587822529, 0.5095203797813246, 0.5660126831435907, 0.565944899087218, 0.6275651600885951, 0.6601593986255824, 0.6815124455687847, 0.6854782027332962, 0.6837219132887977, 0.6919529395951656, 0.6662903194597756, 0.6739183325345197, 0.65822892108458, 0.664930023254529, 0.6535756775119573, 0.7392823068939017, 0.7606036896234012, 0.7366869729255578, 0.7567829085685326, 0.7565024511641978, 0.7422584293751445, 0.7414979218067919, 0.7895831302138768, 0.7506469026429001, 0.30000960624512785, 0.24762357706142113, 0.3644720772137978, 0.535693056038617, 0.25791088630295056, 0.5635676852911893, 0.411931198692415, 0.38074161349804125, 0.25527312128765856, 0.5196475226986133, 0.49754361755002785, 0.5619986287546577, 0.5513970794512073, 0.5140282507326093, 0.5540378543456437, 0.5567276713407624, 0.48309762896091235, 0.5926462818682783, 0.8292316049554413, 0.8040513681872443, 0.8231935820366749, 0.8204589686524565, 0.8347687689102576, 0.8283266882051368, 0.8240075686093223, 0.8119240453212864, 0.8478159671843553, 0.08471603955940465, 0.3269841909688398, 0.15584601958897926, 0.11946357558329346, 0.3135240296628693, 0.10580123910878647, 0.09906976740325169, 0.09333877826716819, 0.11331074715137834, 0.5154384242785006, 0.1803933474093794, 0.13860169662543853, 0.14837852583895927, 0.1674644578945137, 0.17496579937812673, 0.15331341602347348, 0.24947180259253354, 0.182268737549234, 0.5005475397078184, 0.4811407806137462, 0.5377490758421786, 0.4867492420791786, 0.47820616455337817, 0.48736033498544773, 0.5242773046718501, 0.5566141040541208, 0.5427556727632223, 0.3896049525718689, 0.41282700043680387, 0.42158935101037176, 0.40232756243805645, 0.38652903995092525, 0.38638984348144334, 0.40047031823279766, 0.45695157847683643, 0.4069924652942214, 0.19933732654038117, 0.18606894657419026, 0.1673109473458444, 0.216324927810446, 0.19287814885471466, 0.1834506894129444, 0.18836828764373648, 0.19333976771871386, 0.20323648161897667, 0.23640093830712194, 0.2199459491448139, 0.19488160744504957, 0.21346316747808358, 0.5834111239602295, 0.5474039843918898, 0.6400349897232377, 0.6421359954798118, 0.22280323530908253, 0.1718399849181258, 0.18627685918462045, 0.16164795410939348, 0.8656755749455405, 0.20396844494786914, 0.8257571772650467, 0.20358013983404077, 0.7674193301061665, 0.18330540067054635, 0.1553301798026454, 0.16839318394936542, 0.8025939547242359, 0.20788461803011848, 0.7147711167660822, 0.836414744094142, 0.7948373782477776, 0.12659423940961168, 0.8558619002585786, 0.18868553146758382, 0.2003710379036382, 0.1779633789611531, 0.1867325129591343, 0.21877009451217122, 0.1851188699205697, 0.18538773835269862, 0.18705575881167003, 0.16899127761440813, 0.077243001792072, 0.0792303244840199, 0.08746923025707387, 0.07112272177183443, 0.07311984198393673, 0.08259774318144808, 0.08036078786819523, 0.06537377928504606, 0.0744343419763247]}, "mutation_prompt": null}
{"id": "06b8981a-00a8-4d9f-8314-ca9c734744fb", "solution": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.85  # Increased initial scale factor for exploration\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.2  # New parameter to balance exploration and exploitation\n        \n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n        \n        while func_evals < self.budget:\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.scale_factor = np.random.uniform(0.7, 0.85)\n            self.cross_prob = np.random.uniform(0.88, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedHybridEvolutionaryOptimizer", "description": "A refined hybrid evolutionary optimizer with dynamic exploration-exploitation balance and adaptive mutation enhancements for improved convergence speed.", "configspace": "", "generation": 58, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.855172362762411, 0.8659220062066514, 0.8637095763143072, 0.8684988538912858, 0.8706178808280751, 0.8751219187668274, 0.875735912251711, 0.885371256709463, 0.8758475010261377, 0.7897606772692076, 0.7780464349312769, 0.7624645084216468, 0.790407854606426, 0.7684057734533948, 0.7577109760176526, 0.7463787822833655, 0.7635591696458801, 0.779950701825359, 0.13747259024931702, 0.17055399530404325, 0.10616000006249326, 0.1054032523020253, 0.09860999203547127, 0.1492505945832061, 0.13335637946585543, 0.17177438431859848, 0.13050905674168511, 0.12194495847323028, 0.10146753381107443, 0.12917549606342704, 0.09420335672677227, 0.11375308881847501, 0.15008416491683807, 0.13767435057858823, 0.11576480629799935, 0.1288823478391028, 0.923616252156499, 0.9332626390541685, 0.938880057085812, 0.9569887426622138, 0.965427221297927, 0.9546026869304383, 0.9564207320607586, 0.9179055589109922, 0.9596409617365361, 0.6799231502956886, 0.6228315181907147, 0.6053077427826508, 0.643633539398441, 0.6454159831097687, 0.6594364776109957, 0.631077911470128, 0.6268580537351958, 0.6605426909472558, 0.8738257379897179, 0.856710039802895, 0.8528781296374323, 0.8745713666194754, 0.8723434837413657, 0.8649739958849774, 0.8430124741409125, 0.8534555458270078, 0.8270341744551444, 0.551609459177163, 0.6482143574659887, 0.6614293324084707, 0.6270736700295976, 0.6204393695553585, 0.7290196604281876, 0.5295222584265555, 0.6848937949327776, 0.6093807291259528, 0.5465871851585957, 0.4904294373669038, 0.3946434652820141, 0.6080634587822529, 0.5095203797813246, 0.5660126831435907, 0.565944899087218, 0.6275651600885951, 0.6601593986255824, 0.6815124455687847, 0.6854782027332962, 0.6837219132887977, 0.6919529395951656, 0.6662903194597756, 0.6739183325345197, 0.65822892108458, 0.664930023254529, 0.6535756775119573, 0.7392823068939017, 0.7606036896234012, 0.7366869729255578, 0.7567829085685326, 0.7565024511641978, 0.7422584293751445, 0.7414979218067919, 0.7895831302138768, 0.7506469026429001, 0.30000960624512785, 0.24762357706142113, 0.3644720772137978, 0.535693056038617, 0.25791088630295056, 0.5635676852911893, 0.411931198692415, 0.38074161349804125, 0.25527312128765856, 0.5196475226986133, 0.49754361755002785, 0.5619986287546577, 0.5513970794512073, 0.5140282507326093, 0.5540378543456437, 0.5567276713407624, 0.48309762896091235, 0.5926462818682783, 0.8292316049554413, 0.8040513681872443, 0.8231935820366749, 0.8204589686524565, 0.8347687689102576, 0.8283266882051368, 0.8240075686093223, 0.8119240453212864, 0.8478159671843553, 0.08471603955940465, 0.3269841909688398, 0.15584601958897926, 0.11946357558329346, 0.3135240296628693, 0.10580123910878647, 0.09906976740325169, 0.09333877826716819, 0.11331074715137834, 0.5154384242785006, 0.1803933474093794, 0.13860169662543853, 0.14837852583895927, 0.1674644578945137, 0.17496579937812673, 0.15331341602347348, 0.24947180259253354, 0.182268737549234, 0.5005475397078184, 0.4811407806137462, 0.5377490758421786, 0.4867492420791786, 0.47820616455337817, 0.48736033498544773, 0.5242773046718501, 0.5566141040541208, 0.5427556727632223, 0.3896049525718689, 0.41282700043680387, 0.42158935101037176, 0.40232756243805645, 0.38652903995092525, 0.38638984348144334, 0.40047031823279766, 0.45695157847683643, 0.4069924652942214, 0.19933732654038117, 0.18606894657419026, 0.1673109473458444, 0.216324927810446, 0.19287814885471466, 0.1834506894129444, 0.18836828764373648, 0.19333976771871386, 0.20323648161897667, 0.23640093830712194, 0.2199459491448139, 0.19488160744504957, 0.21346316747808358, 0.5834111239602295, 0.5474039843918898, 0.6400349897232377, 0.6421359954798118, 0.22280323530908253, 0.1718399849181258, 0.18627685918462045, 0.16164795410939348, 0.8656755749455405, 0.20396844494786914, 0.8257571772650467, 0.20358013983404077, 0.7674193301061665, 0.18330540067054635, 0.1553301798026454, 0.16839318394936542, 0.8025939547242359, 0.20788461803011848, 0.7147711167660822, 0.836414744094142, 0.7948373782477776, 0.12659423940961168, 0.8558619002585786, 0.18868553146758382, 0.2003710379036382, 0.1779633789611531, 0.1867325129591343, 0.21877009451217122, 0.1851188699205697, 0.18538773835269862, 0.18705575881167003, 0.16899127761440813, 0.077243001792072, 0.0792303244840199, 0.08746923025707387, 0.07112272177183443, 0.07311984198393673, 0.08259774318144808, 0.08036078786819523, 0.06537377928504606, 0.0744343419763247]}, "mutation_prompt": null}
{"id": "8c014c27-614f-49f5-8239-25f4d7a75daf", "solution": "import numpy as np\n\nclass EnhancedExplorationExploitationDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(10 * np.log(self.dim))\n        self.bounds = (-5.0, 5.0)\n        self.scale_factor = 0.8  # Adjusted scale factor for improved balance\n        self.cross_prob = 0.9\n        self.adaptation_rate = 0.05\n        self.exploit_factor = 0.25  # Fine-tuned to enhance convergence\n        self.elite_portion = 0.1  # Fraction of elite individuals\n\n    def __call__(self, func):\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = self.population_size\n\n        while func_evals < self.budget:\n            elite_count = max(1, int(self.population_size * self.elite_portion))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = population[elite_indices]\n\n            for i in range(self.population_size):\n                if func_evals >= self.budget:\n                    break\n\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                if np.random.rand() < 0.5:\n                    a, b, c = elite_population[np.random.choice(elite_count, 3, replace=True)]\n                else:\n                    a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                adapt_factor = self.adaptation_rate * (np.random.rand() - 0.5)\n                exploit_factor = self.exploit_factor * (0.5 - np.abs(np.mean(fitness) - fitness[i]) / np.std(fitness))\n                mutant = a + (self.scale_factor + adapt_factor + exploit_factor) * (b - c)\n                mutant = np.clip(mutant, self.bounds[0], self.bounds[1])\n\n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < (self.cross_prob + adapt_factor * np.random.uniform(0.9, 1.05))\n                trial[crossover] = mutant[crossover]\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Dynamic adaptation of crossover probability\n            self.cross_prob = np.random.uniform(0.88, 0.95)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "EnhancedExplorationExploitationDE", "description": "EnhancedExploration-ExploitationDE: An improved differential evolution algorithm with refined adaptation mechanisms and dynamic parameter tuning for accelerated convergence.", "configspace": "", "generation": 99, "fitness": 0.12921563568158498, "feedback": "The algorithm EnhancedExplorationExploitationDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.18.", "error": "", "parent_id": "21fe365f-f74d-4cad-982f-d34920338682", "metadata": {"aucs": [0.2945895639166354, 0.1673940546654782, 0.43724176454555885, 0.40856074499474015, 0.22412941807434095, 0.47716867966764165, 0.46528605509176413, 0.37974166060811065, 0.4044720173032954, 9.999999999998899e-05, 0.0, 9.999999999998899e-05, 9.999999999998899e-05, 0.2339905364735616, 9.999999999998899e-05, 9.999999999998899e-05, 0.0, 9.999999999998899e-05, 0.04027024883538566, 0.03552223020266754, 0.03179797781450666, 0.0751565235383086, 0.05158538658012768, 0.07260406472357861, 0.056228358957931435, 0.07155765708089579, 0.06008799969573231, 0.01328676813384777, 0.024437765391110422, 0.028800496330226633, 0.07155472595627321, 0.010297736474070507, 0.0316855158557835, 0.049646325776244504, 0.04864534632185136, 0.04697605398081728, 0.939970874430339, 0.9557351240618661, 0.9794324924270855, 0.9845167185176487, 0.0949687323316557, 0.9723432481897505, 0.967494867729717, 0.959761192607243, 0.1927798875001594, 0.00968937350417598, 0.06109989662774806, 0.05299123769391245, 0.039188149462170085, 0.05849953459608592, 0.09807930015557098, 0.17338589568169394, 0.015241879077731557, 0.05370554646310577, 0.11152022118794924, 0.0790015317292484, 0.09662961508220103, 0.15897183475962107, 0.12141397445329094, 0.17995074223431073, 0.09483400175792189, 0.10868033711909897, 0.14065158945239253, 0.1219931723417208, 0.002198565154247989, 0.1416681928287502, 0.061861280748021774, 9.999999999998899e-05, 9.999999999998899e-05, 0.0, 9.999999999998899e-05, 0.0457319785114465, 0.0442455965903904, 0.13115657665271263, 0.10821875543385628, 9.999999999998899e-05, 0.2325630562322697, 0.12653554483050322, 0.0, 0.02071595886953348, 0.15143453047587185, 9.999999999998899e-05, 9.999999999998899e-05, 0.0, 9.999999999998899e-05, 9.999999999998899e-05, 0.0, 0.0, 9.999999999998899e-05, 9.999999999998899e-05, 0.0, 9.999999999998899e-05, 0.024021176766648722, 9.999999999998899e-05, 9.999999999998899e-05, 0.004680992194838085, 0.0444722239139419, 0.04672796175240024, 0.05229368022360814, 9.999999999998899e-05, 0.0, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0, 9.999999999998899e-05, 0.0, 0.04665334110764885, 0.027522736738035958, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.012112283969320958, 0.09333026944741818, 0.08343215783446178, 9.999999999998899e-05, 0.3224238411268803, 0.32160088279233634, 0.4937558353580547, 0.2118188942906427, 0.28036240919194877, 0.2129334499466886, 0.1871076374760242, 0.13674138465777796, 0.264073627356205, 0.041357207347212155, 0.07012205507615599, 0.05416743041131156, 0.07566928662170636, 0.059903245830144614, 0.036447575125307274, 0.044623801919066675, 0.046548278245968855, 0.0659163879844269, 0.11950926313085997, 0.10321336311683549, 0.07987747791122801, 0.1448046403261566, 0.1515327111308914, 0.1299408647886241, 0.13027492996497914, 0.08063368606640031, 0.10916564839442089, 0.19809420755113627, 0.1718390206753302, 0.14352810184653642, 0.1408970060256548, 0.1312000064119242, 0.18265019138493532, 0.16387447094923047, 0.20951320053623157, 0.13442794359949584, 0.07982250293173765, 0.13831353991459638, 0.09320837618622024, 0.1240701167292213, 0.06602922444998172, 0.12558490897859598, 0.09558323408398306, 0.11383818411896496, 0.13593085920505088, 0.1466538999955619, 0.16423879280271636, 0.13336421106438556, 0.16782923770091107, 0.16769841678440411, 0.14441054439791567, 0.12424732287535478, 0.146635499837236, 0.13555895417280006, 0.1658166793250302, 0.05421442815562494, 0.16372292786403375, 0.19779219026589878, 0.16689305921792297, 0.19094074125848248, 0.18314533543035827, 0.15978885899105566, 0.20043193750342447, 0.10163835284141165, 0.14335868814577735, 0.11931913694385499, 0.16906877791470343, 0.1969971031236164, 0.1170256741135206, 0.09076705817715103, 0.10886921178340292, 0.11407884483467245, 0.15414712025573285, 0.10051730792859848, 0.1068627511756649, 0.13549170062613014, 0.16805456982034428, 0.15000155867024545, 0.0741951298670851, 0.09764179147622853, 0.11139929393024772, 0.13480174570059533, 0.1605305451187471, 0.1475449842687161, 0.16053248341540038, 0.1730425095470488, 0.15559889334616073, 0.14961211855402434, 0.16893934840384295, 0.14680476350940785, 0.04982228819757051, 0.015916393435176368, 0.03190583157903315, 0.02691798931623457, 0.046328321132860784, 0.08260132966820055, 0.03613945737419999, 0.04172917400210485, 0.04633760177261992]}, "mutation_prompt": null}

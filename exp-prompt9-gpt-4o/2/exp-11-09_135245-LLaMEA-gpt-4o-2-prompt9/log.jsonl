{"id": "e28f2c63-325a-48c4-b145-49b053219955", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            # Update velocity and position\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                # Move particle\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                # Simulated annealing acceptance criterion\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= (self.temp_end / self.temp_init) ** (evaluations / self.budget)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Hybrid Particle Swarm Optimization with Simulated Annealing to balance exploration and exploitation in dynamic search spaces.", "configspace": "", "generation": 0, "fitness": 0.18760365637148368, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.20.", "error": "", "parent_id": null, "metadata": {"aucs": [0.4353881024270818, 0.4353881024270818, 0.4353881024270818, 0.42890374321372127, 0.42890374321372127, 0.42890374321372127, 0.4218788015562289, 0.4218788015562289, 0.4218788015562289, 0.06631580180747476, 0.06631580180747476, 0.06631580180747476, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0932482372088812, 0.0932482372088812, 0.0932482372088812, 0.07967859825755719, 0.07967859825755719, 0.07967859825755719, 0.08317895627488014, 0.08317895627488014, 0.08317895627488014, 0.058147276150137595, 0.058147276150137595, 0.058147276150137595, 0.07628818179705088, 0.07628818179705088, 0.07628818179705088, 0.0809217185922555, 0.0809217185922555, 0.0809217185922555, 0.8876405575067255, 0.8876405575067255, 0.8876405575067255, 0.9000130038418845, 0.9000130038418845, 0.9000130038418845, 0.8948467075023355, 0.8948467075023355, 0.8948467075023355, 0.0885808898436824, 0.0885808898436824, 0.0885808898436824, 0.15207720937047997, 0.15207720937047997, 0.15207720937047997, 0.10853804030624636, 0.10853804030624636, 0.10853804030624636, 0.1719991683982507, 0.1719991683982507, 0.1719991683982507, 0.15704257623042484, 0.15704257623042484, 0.15704257623042484, 0.22959974617291168, 0.22959974617291168, 0.22959974617291168, 0.10906397010596225, 0.10906397010596225, 0.10906397010596225, 0.00735412516186118, 0.00735412516186118, 0.00735412516186118, 0.11691827978160219, 0.11691827978160219, 0.11691827978160219, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12035649143936866, 0.12035649143936866, 0.12035649143936866, 0.10129856141192539, 0.10129856141192539, 0.10129856141192539, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06748908313766044, 0.06748908313766044, 0.06748908313766044, 0.0507801398408958, 0.0507801398408958, 0.0507801398408958, 0.06351299428119928, 0.06351299428119928, 0.06351299428119928, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06263944964837387, 0.06263944964837387, 0.06263944964837387, 0.04826925818467698, 0.04826925818467698, 0.04826925818467698, 0.021850134056124793, 0.021850134056124793, 0.021850134056124793, 0.3051664986245174, 0.3051664986245174, 0.3051664986245174, 0.4415591998279137, 0.4415591998279137, 0.4415591998279137, 0.3976104412537571, 0.3976104412537571, 0.3976104412537571, 0.07512768963166705, 0.07512768963166705, 0.07512768963166705, 0.07293984299138423, 0.07293984299138423, 0.07293984299138423, 0.09195501691145747, 0.09195501691145747, 0.09195501691145747, 0.1337339796195891, 0.1337339796195891, 0.1337339796195891, 0.15818295770566415, 0.15818295770566415, 0.15818295770566415, 0.23358445294520747, 0.23358445294520747, 0.23358445294520747, 0.24879841017140847, 0.24879841017140847, 0.24879841017140847, 0.2938567952043222, 0.2938567952043222, 0.2938567952043222, 0.2543092159503987, 0.2543092159503987, 0.2543092159503987, 0.18798897209915078, 0.18798897209915078, 0.18798897209915078, 0.18974505675778108, 0.18974505675778108, 0.18974505675778108, 0.21632568462919266, 0.21632568462919266, 0.21632568462919266, 0.20059944934720542, 0.20059944934720542, 0.20059944934720542, 0.19973268086786733, 0.19973268086786733, 0.19973268086786733, 0.21686938935904632, 0.21686938935904632, 0.21686938935904632, 0.15492500186398372, 0.15492500186398372, 0.15492500186398372, 0.17320624816791041, 0.17320624816791041, 0.17320624816791041, 0.17862085178763176, 0.17862085178763176, 0.17862085178763176, 0.6024196535977672, 0.6024196535977672, 0.6024196535977672, 0.15612036352293357, 0.15612036352293357, 0.15612036352293357, 0.6433407809880174, 0.6433407809880174, 0.6433407809880174, 0.3656743608679488, 0.3656743608679488, 0.3656743608679488, 0.20551040698795564, 0.20551040698795564, 0.20551040698795564, 0.1531700862750358, 0.1531700862750358, 0.1531700862750358, 0.1778574952429779, 0.1778574952429779, 0.1778574952429779, 0.17938086146116672, 0.17938086146116672, 0.17938086146116672, 0.18884024058121474, 0.18884024058121474, 0.18884024058121474, 0.09402868967036926, 0.09402868967036926, 0.09402868967036926, 0.062413896015494186, 0.062413896015494186, 0.062413896015494186, 0.069148784311027, 0.069148784311027, 0.069148784311027]}, "mutation_prompt": null}
{"id": "c0cb5757-6de4-4d06-9b13-e771364c7d6d", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            # Update velocity and position\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                # Move particle\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                # Simulated annealing acceptance criterion\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= (self.temp_end / self.temp_init) ** (evaluations / self.budget)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Hybrid Particle Swarm Optimization with Simulated Annealing to balance exploration and exploitation in dynamic search spaces.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e28f2c63-325a-48c4-b145-49b053219955", "metadata": {"aucs": [0.4353881024270818, 0.4353881024270818, 0.4353881024270818, 0.42890374321372127, 0.42890374321372127, 0.42890374321372127, 0.4218788015562289, 0.4218788015562289, 0.4218788015562289, 0.06631580180747476, 0.06631580180747476, 0.06631580180747476, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0932482372088812, 0.0932482372088812, 0.0932482372088812, 0.07967859825755719, 0.07967859825755719, 0.07967859825755719, 0.08317895627488014, 0.08317895627488014, 0.08317895627488014, 0.058147276150137595, 0.058147276150137595, 0.058147276150137595, 0.07628818179705088, 0.07628818179705088, 0.07628818179705088, 0.0809217185922555, 0.0809217185922555, 0.0809217185922555, 0.8876405575067255, 0.8876405575067255, 0.8876405575067255, 0.9000130038418845, 0.9000130038418845, 0.9000130038418845, 0.8948467075023355, 0.8948467075023355, 0.8948467075023355, 0.0885808898436824, 0.0885808898436824, 0.0885808898436824, 0.15207720937047997, 0.15207720937047997, 0.15207720937047997, 0.10853804030624636, 0.10853804030624636, 0.10853804030624636, 0.1719991683982507, 0.1719991683982507, 0.1719991683982507, 0.15704257623042484, 0.15704257623042484, 0.15704257623042484, 0.22959974617291168, 0.22959974617291168, 0.22959974617291168, 0.10906397010596225, 0.10906397010596225, 0.10906397010596225, 0.00735412516186118, 0.00735412516186118, 0.00735412516186118, 0.11691827978160219, 0.11691827978160219, 0.11691827978160219, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12035649143936866, 0.12035649143936866, 0.12035649143936866, 0.10129856141192539, 0.10129856141192539, 0.10129856141192539, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06748908313766044, 0.06748908313766044, 0.06748908313766044, 0.0507801398408958, 0.0507801398408958, 0.0507801398408958, 0.06351299428119928, 0.06351299428119928, 0.06351299428119928, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06263944964837387, 0.06263944964837387, 0.06263944964837387, 0.04826925818467698, 0.04826925818467698, 0.04826925818467698, 0.021850134056124793, 0.021850134056124793, 0.021850134056124793, 0.3051664986245174, 0.3051664986245174, 0.3051664986245174, 0.4415591998279137, 0.4415591998279137, 0.4415591998279137, 0.3976104412537571, 0.3976104412537571, 0.3976104412537571, 0.07512768963166705, 0.07512768963166705, 0.07512768963166705, 0.07293984299138423, 0.07293984299138423, 0.07293984299138423, 0.09195501691145747, 0.09195501691145747, 0.09195501691145747, 0.1337339796195891, 0.1337339796195891, 0.1337339796195891, 0.15818295770566415, 0.15818295770566415, 0.15818295770566415, 0.23358445294520747, 0.23358445294520747, 0.23358445294520747, 0.24879841017140847, 0.24879841017140847, 0.24879841017140847, 0.2938567952043222, 0.2938567952043222, 0.2938567952043222, 0.2543092159503987, 0.2543092159503987, 0.2543092159503987, 0.18798897209915078, 0.18798897209915078, 0.18798897209915078, 0.18974505675778108, 0.18974505675778108, 0.18974505675778108, 0.21632568462919266, 0.21632568462919266, 0.21632568462919266, 0.20059944934720542, 0.20059944934720542, 0.20059944934720542, 0.19973268086786733, 0.19973268086786733, 0.19973268086786733, 0.21686938935904632, 0.21686938935904632, 0.21686938935904632, 0.15492500186398372, 0.15492500186398372, 0.15492500186398372, 0.17320624816791041, 0.17320624816791041, 0.17320624816791041, 0.17862085178763176, 0.17862085178763176, 0.17862085178763176, 0.6024196535977672, 0.6024196535977672, 0.6024196535977672, 0.15612036352293357, 0.15612036352293357, 0.15612036352293357, 0.6433407809880174, 0.6433407809880174, 0.6433407809880174, 0.3656743608679488, 0.3656743608679488, 0.3656743608679488, 0.20551040698795564, 0.20551040698795564, 0.20551040698795564, 0.1531700862750358, 0.1531700862750358, 0.1531700862750358, 0.1778574952429779, 0.1778574952429779, 0.1778574952429779, 0.17938086146116672, 0.17938086146116672, 0.17938086146116672, 0.18884024058121474, 0.18884024058121474, 0.18884024058121474, 0.09402868967036926, 0.09402868967036926, 0.09402868967036926, 0.062413896015494186, 0.062413896015494186, 0.062413896015494186, 0.069148784311027, 0.069148784311027, 0.069148784311027]}, "mutation_prompt": null}
{"id": "e39a1f1a-ede7-476b-bba7-8dbbf69c5a77", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            # Update velocity and position\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                # Move particle\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                # Simulated annealing acceptance criterion\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= (self.temp_end / self.temp_init) ** (evaluations / self.budget)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Hybrid Particle Swarm Optimization with Simulated Annealing to balance exploration and exploitation in dynamic search spaces.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e28f2c63-325a-48c4-b145-49b053219955", "metadata": {"aucs": [0.4353881024270818, 0.4353881024270818, 0.4353881024270818, 0.42890374321372127, 0.42890374321372127, 0.42890374321372127, 0.4218788015562289, 0.4218788015562289, 0.4218788015562289, 0.06631580180747476, 0.06631580180747476, 0.06631580180747476, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0932482372088812, 0.0932482372088812, 0.0932482372088812, 0.07967859825755719, 0.07967859825755719, 0.07967859825755719, 0.08317895627488014, 0.08317895627488014, 0.08317895627488014, 0.058147276150137595, 0.058147276150137595, 0.058147276150137595, 0.07628818179705088, 0.07628818179705088, 0.07628818179705088, 0.0809217185922555, 0.0809217185922555, 0.0809217185922555, 0.8876405575067255, 0.8876405575067255, 0.8876405575067255, 0.9000130038418845, 0.9000130038418845, 0.9000130038418845, 0.8948467075023355, 0.8948467075023355, 0.8948467075023355, 0.0885808898436824, 0.0885808898436824, 0.0885808898436824, 0.15207720937047997, 0.15207720937047997, 0.15207720937047997, 0.10853804030624636, 0.10853804030624636, 0.10853804030624636, 0.1719991683982507, 0.1719991683982507, 0.1719991683982507, 0.15704257623042484, 0.15704257623042484, 0.15704257623042484, 0.22959974617291168, 0.22959974617291168, 0.22959974617291168, 0.10906397010596225, 0.10906397010596225, 0.10906397010596225, 0.00735412516186118, 0.00735412516186118, 0.00735412516186118, 0.11691827978160219, 0.11691827978160219, 0.11691827978160219, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12035649143936866, 0.12035649143936866, 0.12035649143936866, 0.10129856141192539, 0.10129856141192539, 0.10129856141192539, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06748908313766044, 0.06748908313766044, 0.06748908313766044, 0.0507801398408958, 0.0507801398408958, 0.0507801398408958, 0.06351299428119928, 0.06351299428119928, 0.06351299428119928, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06263944964837387, 0.06263944964837387, 0.06263944964837387, 0.04826925818467698, 0.04826925818467698, 0.04826925818467698, 0.021850134056124793, 0.021850134056124793, 0.021850134056124793, 0.3051664986245174, 0.3051664986245174, 0.3051664986245174, 0.4415591998279137, 0.4415591998279137, 0.4415591998279137, 0.3976104412537571, 0.3976104412537571, 0.3976104412537571, 0.07512768963166705, 0.07512768963166705, 0.07512768963166705, 0.07293984299138423, 0.07293984299138423, 0.07293984299138423, 0.09195501691145747, 0.09195501691145747, 0.09195501691145747, 0.1337339796195891, 0.1337339796195891, 0.1337339796195891, 0.15818295770566415, 0.15818295770566415, 0.15818295770566415, 0.23358445294520747, 0.23358445294520747, 0.23358445294520747, 0.24879841017140847, 0.24879841017140847, 0.24879841017140847, 0.2938567952043222, 0.2938567952043222, 0.2938567952043222, 0.2543092159503987, 0.2543092159503987, 0.2543092159503987, 0.18798897209915078, 0.18798897209915078, 0.18798897209915078, 0.18974505675778108, 0.18974505675778108, 0.18974505675778108, 0.21632568462919266, 0.21632568462919266, 0.21632568462919266, 0.20059944934720542, 0.20059944934720542, 0.20059944934720542, 0.19973268086786733, 0.19973268086786733, 0.19973268086786733, 0.21686938935904632, 0.21686938935904632, 0.21686938935904632, 0.15492500186398372, 0.15492500186398372, 0.15492500186398372, 0.17320624816791041, 0.17320624816791041, 0.17320624816791041, 0.17862085178763176, 0.17862085178763176, 0.17862085178763176, 0.6024196535977672, 0.6024196535977672, 0.6024196535977672, 0.15612036352293357, 0.15612036352293357, 0.15612036352293357, 0.6433407809880174, 0.6433407809880174, 0.6433407809880174, 0.3656743608679488, 0.3656743608679488, 0.3656743608679488, 0.20551040698795564, 0.20551040698795564, 0.20551040698795564, 0.1531700862750358, 0.1531700862750358, 0.1531700862750358, 0.1778574952429779, 0.1778574952429779, 0.1778574952429779, 0.17938086146116672, 0.17938086146116672, 0.17938086146116672, 0.18884024058121474, 0.18884024058121474, 0.18884024058121474, 0.09402868967036926, 0.09402868967036926, 0.09402868967036926, 0.062413896015494186, 0.062413896015494186, 0.062413896015494186, 0.069148784311027, 0.069148784311027, 0.069148784311027]}, "mutation_prompt": null}
{"id": "9d7f956f-94ec-47b1-b7c8-5003d088e0ed", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.95  # New adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            # Update velocity and position\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                # Move particle\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                # Simulated annealing acceptance criterion\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            # Adaptive cooling schedule\n            temperature *= self.adaptive_factor\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced Hybrid PSO with Adaptive Cooling Rate for Improved Convergence.", "configspace": "", "generation": 3, "fitness": 0.20928877789736364, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.21.", "error": "", "parent_id": "e28f2c63-325a-48c4-b145-49b053219955", "metadata": {"aucs": [0.4982228470037898, 0.4982228470037898, 0.4982228470037898, 0.48442469624301643, 0.48442469624301643, 0.48442469624301643, 0.48899954048018224, 0.48899954048018224, 0.48899954048018224, 0.06631580180747476, 0.06631580180747476, 0.06631580180747476, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09945002763323751, 0.09945002763323751, 0.09945002763323751, 0.08473108341914426, 0.08473108341914426, 0.08473108341914426, 0.09660830673881282, 0.09660830673881282, 0.09660830673881282, 0.06267904194512908, 0.06267904194512908, 0.06267904194512908, 0.07987822869131056, 0.07987822869131056, 0.07987822869131056, 0.07677416735619358, 0.07677416735619358, 0.07677416735619358, 0.874963159521666, 0.874963159521666, 0.874963159521666, 0.9039517329257112, 0.9039517329257112, 0.9039517329257112, 0.8926337327210349, 0.8926337327210349, 0.8926337327210349, 0.061814022980902106, 0.061814022980902106, 0.061814022980902106, 0.1317310016766141, 0.1317310016766141, 0.1317310016766141, 0.18233986654599477, 0.18233986654599477, 0.18233986654599477, 0.20997743863285012, 0.20997743863285012, 0.20997743863285012, 0.1583872372315076, 0.1583872372315076, 0.1583872372315076, 0.3054045703176653, 0.3054045703176653, 0.3054045703176653, 0.11252056616303141, 0.11252056616303141, 0.11252056616303141, 0.08166014624169093, 0.08166014624169093, 0.08166014624169093, 0.10481697182686744, 0.10481697182686744, 0.10481697182686744, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1369197228743888, 0.1369197228743888, 0.1369197228743888, 0.09583759726635976, 0.09583759726635976, 0.09583759726635976, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06748908313766044, 0.06748908313766044, 0.06748908313766044, 0.0507801398408958, 0.0507801398408958, 0.0507801398408958, 0.06351299428119928, 0.06351299428119928, 0.06351299428119928, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02692828232055, 0.02692828232055, 0.02692828232055, 0.02280720434104133, 0.02280720434104133, 0.02280720434104133, 0.04302569279344026, 0.04302569279344026, 0.04302569279344026, 0.4225045794432817, 0.4225045794432817, 0.4225045794432817, 0.42816726627376434, 0.42816726627376434, 0.42816726627376434, 0.46244987988533437, 0.46244987988533437, 0.46244987988533437, 0.06904236455148316, 0.06904236455148316, 0.06904236455148316, 0.08477942434010477, 0.08477942434010477, 0.08477942434010477, 0.07275419117391124, 0.07275419117391124, 0.07275419117391124, 0.17401189042519694, 0.17401189042519694, 0.17401189042519694, 0.23075039876053216, 0.23075039876053216, 0.23075039876053216, 0.24066111185075978, 0.24066111185075978, 0.24066111185075978, 0.31644771379576464, 0.31644771379576464, 0.31644771379576464, 0.31007330235755504, 0.31007330235755504, 0.31007330235755504, 0.2988175412264963, 0.2988175412264963, 0.2988175412264963, 0.24871542822280768, 0.24871542822280768, 0.24871542822280768, 0.20288947374347022, 0.20288947374347022, 0.20288947374347022, 0.22381014982765124, 0.22381014982765124, 0.22381014982765124, 0.21345091937965166, 0.21345091937965166, 0.21345091937965166, 0.23881285437909294, 0.23881285437909294, 0.23881285437909294, 0.19910376177898892, 0.19910376177898892, 0.19910376177898892, 0.20144395887791733, 0.20144395887791733, 0.20144395887791733, 0.18302547887081722, 0.18302547887081722, 0.18302547887081722, 0.1937085635919319, 0.1937085635919319, 0.1937085635919319, 0.7121077717369879, 0.7121077717369879, 0.7121077717369879, 0.15554640514452023, 0.15554640514452023, 0.15554640514452023, 0.7111069741807247, 0.7111069741807247, 0.7111069741807247, 0.36978410253793836, 0.36978410253793836, 0.36978410253793836, 0.20486271749410445, 0.20486271749410445, 0.20486271749410445, 0.48049721795116074, 0.48049721795116074, 0.48049721795116074, 0.17978774964728295, 0.17978774964728295, 0.17978774964728295, 0.20047426613099828, 0.20047426613099828, 0.20047426613099828, 0.1935618653742749, 0.1935618653742749, 0.1935618653742749, 0.12289513848401545, 0.12289513848401545, 0.12289513848401545, 0.09104716217091313, 0.09104716217091313, 0.09104716217091313, 0.065215480041384, 0.065215480041384, 0.065215480041384]}, "mutation_prompt": null}
{"id": "ca4f5e04-4670-47fa-a01d-b8c718d8c2ea", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.95\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            # Dynamic inertia weight adjustment\n            inertia_weight = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n            \n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            # Update velocity and position\n            for i in range(self.swarm_size):\n                inertia = inertia_weight * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                # Move particle\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                # Simulated annealing acceptance criterion\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            # Adaptive cooling schedule\n            temperature *= self.adaptive_factor\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Hybrid PSO with Dynamic Inertia Weight Adjustment for Accelerated Convergence.", "configspace": "", "generation": 4, "fitness": 0.20340847713235502, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.21.", "error": "", "parent_id": "9d7f956f-94ec-47b1-b7c8-5003d088e0ed", "metadata": {"aucs": [0.5261679253248388, 0.5261679253248388, 0.5261679253248388, 0.543900941151183, 0.543900941151183, 0.543900941151183, 0.5396753628560617, 0.5396753628560617, 0.5396753628560617, 0.021324775403943175, 0.021324775403943175, 0.021324775403943175, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06861939368826464, 0.06861939368826464, 0.06861939368826464, 0.07631349092023754, 0.07631349092023754, 0.07631349092023754, 0.09135819443573623, 0.09135819443573623, 0.09135819443573623, 0.10565964526956473, 0.10565964526956473, 0.10565964526956473, 0.056662561919534005, 0.056662561919534005, 0.056662561919534005, 0.06963171515509625, 0.06963171515509625, 0.06963171515509625, 0.8529185221688906, 0.8529185221688906, 0.8529185221688906, 0.9109735505983466, 0.9109735505983466, 0.9109735505983466, 0.8884877530376816, 0.8884877530376816, 0.8884877530376816, 0.16614741444276404, 0.16614741444276404, 0.16614741444276404, 0.14567414997355044, 0.14567414997355044, 0.14567414997355044, 0.14247161521213114, 0.14247161521213114, 0.14247161521213114, 0.20565772307192987, 0.20565772307192987, 0.20565772307192987, 0.19170352470849517, 0.19170352470849517, 0.19170352470849517, 0.14259843918514958, 0.14259843918514958, 0.14259843918514958, 0.12905523363944083, 0.12905523363944083, 0.12905523363944083, 0.12331088957481584, 0.12331088957481584, 0.12331088957481584, 0.08045298230597253, 0.08045298230597253, 0.08045298230597253, 0.08761246480918472, 0.08761246480918472, 0.08761246480918472, 0.10506195283056241, 0.10506195283056241, 0.10506195283056241, 0.16130740694826584, 0.16130740694826584, 0.16130740694826584, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.037639713035494404, 0.037639713035494404, 0.037639713035494404, 0.014789507812202118, 0.014789507812202118, 0.014789507812202118, 0.05668062804907126, 0.05668062804907126, 0.05668062804907126, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06351029087870852, 0.06351029087870852, 0.06351029087870852, 0.015788671892981276, 0.015788671892981276, 0.015788671892981276, 0.034487198782673145, 0.034487198782673145, 0.034487198782673145, 0.413475839687116, 0.413475839687116, 0.413475839687116, 0.42312783430130474, 0.42312783430130474, 0.42312783430130474, 0.4242691024739095, 0.4242691024739095, 0.4242691024739095, 0.08331687232762275, 0.08331687232762275, 0.08331687232762275, 0.08393729736120425, 0.08393729736120425, 0.08393729736120425, 0.0823890340908614, 0.0823890340908614, 0.0823890340908614, 0.20418606386303217, 0.20418606386303217, 0.20418606386303217, 0.15169393302811418, 0.15169393302811418, 0.15169393302811418, 0.18982898794966463, 0.18982898794966463, 0.18982898794966463, 0.23834894975243903, 0.23834894975243903, 0.23834894975243903, 0.3118317209784264, 0.3118317209784264, 0.3118317209784264, 0.3065989474671138, 0.3065989474671138, 0.3065989474671138, 0.21322156151842686, 0.21322156151842686, 0.21322156151842686, 0.2579975591008853, 0.2579975591008853, 0.2579975591008853, 0.21137357698293857, 0.21137357698293857, 0.21137357698293857, 0.19681628162244913, 0.19681628162244913, 0.19681628162244913, 0.18267816237022005, 0.18267816237022005, 0.18267816237022005, 0.21454282047312168, 0.21454282047312168, 0.21454282047312168, 0.19452238665093669, 0.19452238665093669, 0.19452238665093669, 0.171386689916614, 0.171386689916614, 0.171386689916614, 0.16231029644686623, 0.16231029644686623, 0.16231029644686623, 0.6462111544089595, 0.6462111544089595, 0.6462111544089595, 0.16239823349561888, 0.16239823349561888, 0.16239823349561888, 0.6187023665375986, 0.6187023665375986, 0.6187023665375986, 0.43923915260167024, 0.43923915260167024, 0.43923915260167024, 0.20199917160637293, 0.20199917160637293, 0.20199917160637293, 0.39483491810114035, 0.39483491810114035, 0.39483491810114035, 0.19890007403395216, 0.19890007403395216, 0.19890007403395216, 0.18698315402473853, 0.18698315402473853, 0.18698315402473853, 0.1797399882603944, 0.1797399882603944, 0.1797399882603944, 0.08494069303081375, 0.08494069303081375, 0.08494069303081375, 0.08422221178568945, 0.08422221178568945, 0.08422221178568945, 0.07294167819657271, 0.07294167819657271, 0.07294167819657271]}, "mutation_prompt": null}
{"id": "7bfd4cb1-1eda-4ee8-bd13-5e3a6960e263", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.95  # New adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            # Update velocity and position\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                # Move particle\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                # Simulated annealing acceptance criterion\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            # Adaptive cooling schedule\n            temperature *= self.adaptive_factor\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced Hybrid PSO with Adaptive Cooling Rate for Improved Convergence.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "9d7f956f-94ec-47b1-b7c8-5003d088e0ed", "metadata": {"aucs": [0.4982228470037898, 0.4982228470037898, 0.4982228470037898, 0.48442469624301643, 0.48442469624301643, 0.48442469624301643, 0.48899954048018224, 0.48899954048018224, 0.48899954048018224, 0.06631580180747476, 0.06631580180747476, 0.06631580180747476, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09945002763323751, 0.09945002763323751, 0.09945002763323751, 0.08473108341914426, 0.08473108341914426, 0.08473108341914426, 0.09660830673881282, 0.09660830673881282, 0.09660830673881282, 0.06267904194512908, 0.06267904194512908, 0.06267904194512908, 0.07987822869131056, 0.07987822869131056, 0.07987822869131056, 0.07677416735619358, 0.07677416735619358, 0.07677416735619358, 0.874963159521666, 0.874963159521666, 0.874963159521666, 0.9039517329257112, 0.9039517329257112, 0.9039517329257112, 0.8926337327210349, 0.8926337327210349, 0.8926337327210349, 0.061814022980902106, 0.061814022980902106, 0.061814022980902106, 0.1317310016766141, 0.1317310016766141, 0.1317310016766141, 0.18233986654599477, 0.18233986654599477, 0.18233986654599477, 0.20997743863285012, 0.20997743863285012, 0.20997743863285012, 0.1583872372315076, 0.1583872372315076, 0.1583872372315076, 0.3054045703176653, 0.3054045703176653, 0.3054045703176653, 0.11252056616303141, 0.11252056616303141, 0.11252056616303141, 0.08166014624169093, 0.08166014624169093, 0.08166014624169093, 0.10481697182686744, 0.10481697182686744, 0.10481697182686744, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1369197228743888, 0.1369197228743888, 0.1369197228743888, 0.09583759726635976, 0.09583759726635976, 0.09583759726635976, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06748908313766044, 0.06748908313766044, 0.06748908313766044, 0.0507801398408958, 0.0507801398408958, 0.0507801398408958, 0.06351299428119928, 0.06351299428119928, 0.06351299428119928, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02692828232055, 0.02692828232055, 0.02692828232055, 0.02280720434104133, 0.02280720434104133, 0.02280720434104133, 0.04302569279344026, 0.04302569279344026, 0.04302569279344026, 0.4225045794432817, 0.4225045794432817, 0.4225045794432817, 0.42816726627376434, 0.42816726627376434, 0.42816726627376434, 0.46244987988533437, 0.46244987988533437, 0.46244987988533437, 0.06904236455148316, 0.06904236455148316, 0.06904236455148316, 0.08477942434010477, 0.08477942434010477, 0.08477942434010477, 0.07275419117391124, 0.07275419117391124, 0.07275419117391124, 0.17401189042519694, 0.17401189042519694, 0.17401189042519694, 0.23075039876053216, 0.23075039876053216, 0.23075039876053216, 0.24066111185075978, 0.24066111185075978, 0.24066111185075978, 0.31644771379576464, 0.31644771379576464, 0.31644771379576464, 0.31007330235755504, 0.31007330235755504, 0.31007330235755504, 0.2988175412264963, 0.2988175412264963, 0.2988175412264963, 0.24871542822280768, 0.24871542822280768, 0.24871542822280768, 0.20288947374347022, 0.20288947374347022, 0.20288947374347022, 0.22381014982765124, 0.22381014982765124, 0.22381014982765124, 0.21345091937965166, 0.21345091937965166, 0.21345091937965166, 0.23881285437909294, 0.23881285437909294, 0.23881285437909294, 0.19910376177898892, 0.19910376177898892, 0.19910376177898892, 0.20144395887791733, 0.20144395887791733, 0.20144395887791733, 0.18302547887081722, 0.18302547887081722, 0.18302547887081722, 0.1937085635919319, 0.1937085635919319, 0.1937085635919319, 0.7121077717369879, 0.7121077717369879, 0.7121077717369879, 0.15554640514452023, 0.15554640514452023, 0.15554640514452023, 0.7111069741807247, 0.7111069741807247, 0.7111069741807247, 0.36978410253793836, 0.36978410253793836, 0.36978410253793836, 0.20486271749410445, 0.20486271749410445, 0.20486271749410445, 0.48049721795116074, 0.48049721795116074, 0.48049721795116074, 0.17978774964728295, 0.17978774964728295, 0.17978774964728295, 0.20047426613099828, 0.20047426613099828, 0.20047426613099828, 0.1935618653742749, 0.1935618653742749, 0.1935618653742749, 0.12289513848401545, 0.12289513848401545, 0.12289513848401545, 0.09104716217091313, 0.09104716217091313, 0.09104716217091313, 0.065215480041384, 0.065215480041384, 0.065215480041384]}, "mutation_prompt": null}
{"id": "606a68d6-0002-468b-9fb9-2f9a85de18e7", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.95  # New adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            # Update velocity and position\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                # Move particle\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                # Simulated annealing acceptance criterion\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            # Adaptive cooling schedule\n            temperature *= self.adaptive_factor\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced Hybrid PSO with Adaptive Cooling Rate for Improved Convergence.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "9d7f956f-94ec-47b1-b7c8-5003d088e0ed", "metadata": {"aucs": [0.4982228470037898, 0.4982228470037898, 0.4982228470037898, 0.48442469624301643, 0.48442469624301643, 0.48442469624301643, 0.48899954048018224, 0.48899954048018224, 0.48899954048018224, 0.06631580180747476, 0.06631580180747476, 0.06631580180747476, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09945002763323751, 0.09945002763323751, 0.09945002763323751, 0.08473108341914426, 0.08473108341914426, 0.08473108341914426, 0.09660830673881282, 0.09660830673881282, 0.09660830673881282, 0.06267904194512908, 0.06267904194512908, 0.06267904194512908, 0.07987822869131056, 0.07987822869131056, 0.07987822869131056, 0.07677416735619358, 0.07677416735619358, 0.07677416735619358, 0.874963159521666, 0.874963159521666, 0.874963159521666, 0.9039517329257112, 0.9039517329257112, 0.9039517329257112, 0.8926337327210349, 0.8926337327210349, 0.8926337327210349, 0.061814022980902106, 0.061814022980902106, 0.061814022980902106, 0.1317310016766141, 0.1317310016766141, 0.1317310016766141, 0.18233986654599477, 0.18233986654599477, 0.18233986654599477, 0.20997743863285012, 0.20997743863285012, 0.20997743863285012, 0.1583872372315076, 0.1583872372315076, 0.1583872372315076, 0.3054045703176653, 0.3054045703176653, 0.3054045703176653, 0.11252056616303141, 0.11252056616303141, 0.11252056616303141, 0.08166014624169093, 0.08166014624169093, 0.08166014624169093, 0.10481697182686744, 0.10481697182686744, 0.10481697182686744, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1369197228743888, 0.1369197228743888, 0.1369197228743888, 0.09583759726635976, 0.09583759726635976, 0.09583759726635976, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06748908313766044, 0.06748908313766044, 0.06748908313766044, 0.0507801398408958, 0.0507801398408958, 0.0507801398408958, 0.06351299428119928, 0.06351299428119928, 0.06351299428119928, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02692828232055, 0.02692828232055, 0.02692828232055, 0.02280720434104133, 0.02280720434104133, 0.02280720434104133, 0.04302569279344026, 0.04302569279344026, 0.04302569279344026, 0.4225045794432817, 0.4225045794432817, 0.4225045794432817, 0.42816726627376434, 0.42816726627376434, 0.42816726627376434, 0.46244987988533437, 0.46244987988533437, 0.46244987988533437, 0.06904236455148316, 0.06904236455148316, 0.06904236455148316, 0.08477942434010477, 0.08477942434010477, 0.08477942434010477, 0.07275419117391124, 0.07275419117391124, 0.07275419117391124, 0.17401189042519694, 0.17401189042519694, 0.17401189042519694, 0.23075039876053216, 0.23075039876053216, 0.23075039876053216, 0.24066111185075978, 0.24066111185075978, 0.24066111185075978, 0.31644771379576464, 0.31644771379576464, 0.31644771379576464, 0.31007330235755504, 0.31007330235755504, 0.31007330235755504, 0.2988175412264963, 0.2988175412264963, 0.2988175412264963, 0.24871542822280768, 0.24871542822280768, 0.24871542822280768, 0.20288947374347022, 0.20288947374347022, 0.20288947374347022, 0.22381014982765124, 0.22381014982765124, 0.22381014982765124, 0.21345091937965166, 0.21345091937965166, 0.21345091937965166, 0.23881285437909294, 0.23881285437909294, 0.23881285437909294, 0.19910376177898892, 0.19910376177898892, 0.19910376177898892, 0.20144395887791733, 0.20144395887791733, 0.20144395887791733, 0.18302547887081722, 0.18302547887081722, 0.18302547887081722, 0.1937085635919319, 0.1937085635919319, 0.1937085635919319, 0.7121077717369879, 0.7121077717369879, 0.7121077717369879, 0.15554640514452023, 0.15554640514452023, 0.15554640514452023, 0.7111069741807247, 0.7111069741807247, 0.7111069741807247, 0.36978410253793836, 0.36978410253793836, 0.36978410253793836, 0.20486271749410445, 0.20486271749410445, 0.20486271749410445, 0.48049721795116074, 0.48049721795116074, 0.48049721795116074, 0.17978774964728295, 0.17978774964728295, 0.17978774964728295, 0.20047426613099828, 0.20047426613099828, 0.20047426613099828, 0.1935618653742749, 0.1935618653742749, 0.1935618653742749, 0.12289513848401545, 0.12289513848401545, 0.12289513848401545, 0.09104716217091313, 0.09104716217091313, 0.09104716217091313, 0.065215480041384, 0.065215480041384, 0.065215480041384]}, "mutation_prompt": null}
{"id": "61d40f92-bbf7-4754-ba54-d46ae23091cd", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.95\n        self.momentum = 0.9  # New momentum factor for velocity update\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = self.momentum * velocities[i] + inertia + cognitive + social  # Apply momentum\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Improved Hybrid PSO with Momentum-based Velocity for Enhanced Convergence.", "configspace": "", "generation": 7, "fitness": 0.14034608604906693, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.18.", "error": "", "parent_id": "9d7f956f-94ec-47b1-b7c8-5003d088e0ed", "metadata": {"aucs": [0.26017554358827055, 0.26017554358827055, 0.26017554358827055, 0.21810012022266734, 0.21810012022266734, 0.21810012022266734, 0.24253954138116052, 0.24253954138116052, 0.24253954138116052, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07102440993112413, 0.07102440993112413, 0.07102440993112413, 0.057292093973828506, 0.057292093973828506, 0.057292093973828506, 0.0702892474451392, 0.0702892474451392, 0.0702892474451392, 0.06331167698929163, 0.06331167698929163, 0.06331167698929163, 0.05609295418532945, 0.05609295418532945, 0.05609295418532945, 0.03758298844434449, 0.03758298844434449, 0.03758298844434449, 0.9172163986474121, 0.9172163986474121, 0.9172163986474121, 0.9366623486389736, 0.9366623486389736, 0.9366623486389736, 0.9102105331201015, 0.9102105331201015, 0.9102105331201015, 0.11017196440502863, 0.11017196440502863, 0.11017196440502863, 0.10474786938680358, 0.10474786938680358, 0.10474786938680358, 0.0863840031891252, 0.0863840031891252, 0.0863840031891252, 0.15329940932735264, 0.15329940932735264, 0.15329940932735264, 0.16160872536954052, 0.16160872536954052, 0.16160872536954052, 0.12463008254716201, 0.12463008254716201, 0.12463008254716201, 0.028490444478718735, 0.028490444478718735, 0.028490444478718735, 0.02452829878231244, 0.02452829878231244, 0.02452829878231244, 0.026838537904662174, 0.026838537904662174, 0.026838537904662174, 0.05916489855735452, 0.05916489855735452, 0.05916489855735452, 0.03394627537057748, 0.03394627537057748, 0.03394627537057748, 0.033390685277104426, 0.033390685277104426, 0.033390685277104426, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04359001198636159, 0.04359001198636159, 0.04359001198636159, 0.037567669562445505, 0.037567669562445505, 0.037567669562445505, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003207809500997416, 0.003207809500997416, 0.003207809500997416, 0.004451916070396855, 0.004451916070396855, 0.004451916070396855, 0.0009050941839252591, 0.0009050941839252591, 0.0009050941839252591, 0.24904169561894507, 0.24904169561894507, 0.24904169561894507, 0.24308485229484655, 0.24308485229484655, 0.24308485229484655, 0.2558560398012619, 0.2558560398012619, 0.2558560398012619, 0.05658460575270752, 0.05658460575270752, 0.05658460575270752, 0.08464773363091505, 0.08464773363091505, 0.08464773363091505, 0.06735510781716547, 0.06735510781716547, 0.06735510781716547, 0.12318443481084873, 0.12318443481084873, 0.12318443481084873, 0.11487479715076565, 0.11487479715076565, 0.11487479715076565, 0.12339012583312237, 0.12339012583312237, 0.12339012583312237, 0.20901136543226406, 0.20901136543226406, 0.20901136543226406, 0.19323103264733532, 0.19323103264733532, 0.19323103264733532, 0.19140438886385314, 0.19140438886385314, 0.19140438886385314, 0.13598010108813174, 0.13598010108813174, 0.13598010108813174, 0.15360262465834718, 0.15360262465834718, 0.15360262465834718, 0.13382134394678358, 0.13382134394678358, 0.13382134394678358, 0.20134285141979003, 0.20134285141979003, 0.20134285141979003, 0.176965091083363, 0.176965091083363, 0.176965091083363, 0.20278862508691764, 0.20278862508691764, 0.20278862508691764, 0.12372486315507303, 0.12372486315507303, 0.12372486315507303, 0.15334342688730818, 0.15334342688730818, 0.15334342688730818, 0.13479676698427234, 0.13479676698427234, 0.13479676698427234, 0.1670165683705931, 0.1670165683705931, 0.1670165683705931, 0.2684635785717817, 0.2684635785717817, 0.2684635785717817, 0.12461998368799088, 0.12461998368799088, 0.12461998368799088, 0.2326446928932303, 0.2326446928932303, 0.2326446928932303, 0.1985786990823396, 0.1985786990823396, 0.1985786990823396, 0.14249241406971302, 0.14249241406971302, 0.14249241406971302, 0.1857177573484673, 0.1857177573484673, 0.1857177573484673, 0.18658090322336718, 0.18658090322336718, 0.18658090322336718, 0.17643489486537878, 0.17643489486537878, 0.17643489486537878, 0.07263682957741513, 0.07263682957741513, 0.07263682957741513, 0.07764686059594528, 0.07764686059594528, 0.07764686059594528, 0.0656315868150652, 0.0656315868150652, 0.0656315868150652]}, "mutation_prompt": null}
{"id": "bba009bd-716f-4e4e-a2f4-a41040fa3c5b", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.95  # New adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            # Update velocity and position\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                # Move particle\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                # Simulated annealing acceptance criterion\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            # Adaptive cooling schedule\n            temperature *= self.adaptive_factor\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced Hybrid PSO with Adaptive Cooling Rate for Improved Convergence.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "9d7f956f-94ec-47b1-b7c8-5003d088e0ed", "metadata": {"aucs": [0.4982228470037898, 0.4982228470037898, 0.4982228470037898, 0.48442469624301643, 0.48442469624301643, 0.48442469624301643, 0.48899954048018224, 0.48899954048018224, 0.48899954048018224, 0.06631580180747476, 0.06631580180747476, 0.06631580180747476, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09945002763323751, 0.09945002763323751, 0.09945002763323751, 0.08473108341914426, 0.08473108341914426, 0.08473108341914426, 0.09660830673881282, 0.09660830673881282, 0.09660830673881282, 0.06267904194512908, 0.06267904194512908, 0.06267904194512908, 0.07987822869131056, 0.07987822869131056, 0.07987822869131056, 0.07677416735619358, 0.07677416735619358, 0.07677416735619358, 0.874963159521666, 0.874963159521666, 0.874963159521666, 0.9039517329257112, 0.9039517329257112, 0.9039517329257112, 0.8926337327210349, 0.8926337327210349, 0.8926337327210349, 0.061814022980902106, 0.061814022980902106, 0.061814022980902106, 0.1317310016766141, 0.1317310016766141, 0.1317310016766141, 0.18233986654599477, 0.18233986654599477, 0.18233986654599477, 0.20997743863285012, 0.20997743863285012, 0.20997743863285012, 0.1583872372315076, 0.1583872372315076, 0.1583872372315076, 0.3054045703176653, 0.3054045703176653, 0.3054045703176653, 0.11252056616303141, 0.11252056616303141, 0.11252056616303141, 0.08166014624169093, 0.08166014624169093, 0.08166014624169093, 0.10481697182686744, 0.10481697182686744, 0.10481697182686744, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1369197228743888, 0.1369197228743888, 0.1369197228743888, 0.09583759726635976, 0.09583759726635976, 0.09583759726635976, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06748908313766044, 0.06748908313766044, 0.06748908313766044, 0.0507801398408958, 0.0507801398408958, 0.0507801398408958, 0.06351299428119928, 0.06351299428119928, 0.06351299428119928, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02692828232055, 0.02692828232055, 0.02692828232055, 0.02280720434104133, 0.02280720434104133, 0.02280720434104133, 0.04302569279344026, 0.04302569279344026, 0.04302569279344026, 0.4225045794432817, 0.4225045794432817, 0.4225045794432817, 0.42816726627376434, 0.42816726627376434, 0.42816726627376434, 0.46244987988533437, 0.46244987988533437, 0.46244987988533437, 0.06904236455148316, 0.06904236455148316, 0.06904236455148316, 0.08477942434010477, 0.08477942434010477, 0.08477942434010477, 0.07275419117391124, 0.07275419117391124, 0.07275419117391124, 0.17401189042519694, 0.17401189042519694, 0.17401189042519694, 0.23075039876053216, 0.23075039876053216, 0.23075039876053216, 0.24066111185075978, 0.24066111185075978, 0.24066111185075978, 0.31644771379576464, 0.31644771379576464, 0.31644771379576464, 0.31007330235755504, 0.31007330235755504, 0.31007330235755504, 0.2988175412264963, 0.2988175412264963, 0.2988175412264963, 0.24871542822280768, 0.24871542822280768, 0.24871542822280768, 0.20288947374347022, 0.20288947374347022, 0.20288947374347022, 0.22381014982765124, 0.22381014982765124, 0.22381014982765124, 0.21345091937965166, 0.21345091937965166, 0.21345091937965166, 0.23881285437909294, 0.23881285437909294, 0.23881285437909294, 0.19910376177898892, 0.19910376177898892, 0.19910376177898892, 0.20144395887791733, 0.20144395887791733, 0.20144395887791733, 0.18302547887081722, 0.18302547887081722, 0.18302547887081722, 0.1937085635919319, 0.1937085635919319, 0.1937085635919319, 0.7121077717369879, 0.7121077717369879, 0.7121077717369879, 0.15554640514452023, 0.15554640514452023, 0.15554640514452023, 0.7111069741807247, 0.7111069741807247, 0.7111069741807247, 0.36978410253793836, 0.36978410253793836, 0.36978410253793836, 0.20486271749410445, 0.20486271749410445, 0.20486271749410445, 0.48049721795116074, 0.48049721795116074, 0.48049721795116074, 0.17978774964728295, 0.17978774964728295, 0.17978774964728295, 0.20047426613099828, 0.20047426613099828, 0.20047426613099828, 0.1935618653742749, 0.1935618653742749, 0.1935618653742749, 0.12289513848401545, 0.12289513848401545, 0.12289513848401545, 0.09104716217091313, 0.09104716217091313, 0.09104716217091313, 0.065215480041384, 0.065215480041384, 0.065215480041384]}, "mutation_prompt": null}
{"id": "e0f6670c-264d-46ec-8861-a17782775bdf", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.9  # Adjusted initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.95  # New adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            # Update velocity and position\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                # Move particle\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                # Simulated annealing acceptance criterion\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            # Adaptive cooling schedule\n            temperature *= self.adaptive_factor\n\n            # Adaptive inertia weight\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "An enhanced PSO-SA optimizer with an improved balance between exploration and exploitation using adaptive inertia weight adjustment.", "configspace": "", "generation": 9, "fitness": 0.22300286117038115, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.23.", "error": "", "parent_id": "9d7f956f-94ec-47b1-b7c8-5003d088e0ed", "metadata": {"aucs": [0.6782647470792136, 0.6782647470792136, 0.6782647470792136, 0.6510620026916942, 0.6510620026916942, 0.6510620026916942, 0.6307662893010079, 0.6307662893010079, 0.6307662893010079, 0.05540475876260609, 0.05540475876260609, 0.05540475876260609, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01448574992938989, 0.01448574992938989, 0.01448574992938989, 0.09502846657201225, 0.09502846657201225, 0.09502846657201225, 0.0984190369503456, 0.0984190369503456, 0.0984190369503456, 0.13080427528685945, 0.13080427528685945, 0.13080427528685945, 0.073673847260183, 0.073673847260183, 0.073673847260183, 0.05739882526973683, 0.05739882526973683, 0.05739882526973683, 0.07794004265815979, 0.07794004265815979, 0.07794004265815979, 0.8525402858757739, 0.8525402858757739, 0.8525402858757739, 0.9114141382313873, 0.9114141382313873, 0.9114141382313873, 0.8850647317060869, 0.8850647317060869, 0.8850647317060869, 0.2171888195131806, 0.2171888195131806, 0.2171888195131806, 0.13116807101889227, 0.13116807101889227, 0.13116807101889227, 0.2072827847199925, 0.2072827847199925, 0.2072827847199925, 0.2139576603012453, 0.2139576603012453, 0.2139576603012453, 0.1571805014521238, 0.1571805014521238, 0.1571805014521238, 0.3048371907230467, 0.3048371907230467, 0.3048371907230467, 0.09213223331845144, 0.09213223331845144, 0.09213223331845144, 0.08981510009688898, 0.08981510009688898, 0.08981510009688898, 0.10607229217830427, 0.10607229217830427, 0.10607229217830427, 0.060920354018421885, 0.060920354018421885, 0.060920354018421885, 0.08479455500229305, 0.08479455500229305, 0.08479455500229305, 0.06180700910541692, 0.06180700910541692, 0.06180700910541692, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05761638572361749, 0.05761638572361749, 0.05761638572361749, 0.018114331716615584, 0.018114331716615584, 0.018114331716615584, 0.06399645503600315, 0.06399645503600315, 0.06399645503600315, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07319458700471948, 0.07319458700471948, 0.07319458700471948, 0.02800626687419594, 0.02800626687419594, 0.02800626687419594, 0.04304900736273831, 0.04304900736273831, 0.04304900736273831, 0.4645646844442144, 0.4645646844442144, 0.4645646844442144, 0.454150747587446, 0.454150747587446, 0.454150747587446, 0.4821512698573891, 0.4821512698573891, 0.4821512698573891, 0.07360090595713464, 0.07360090595713464, 0.07360090595713464, 0.08875960234614544, 0.08875960234614544, 0.08875960234614544, 0.15553736061881096, 0.15553736061881096, 0.15553736061881096, 0.19567324730641666, 0.19567324730641666, 0.19567324730641666, 0.1700859289979919, 0.1700859289979919, 0.1700859289979919, 0.14966476025823616, 0.14966476025823616, 0.14966476025823616, 0.3353929290925436, 0.3353929290925436, 0.3353929290925436, 0.3183330547963904, 0.3183330547963904, 0.3183330547963904, 0.39844986593988374, 0.39844986593988374, 0.39844986593988374, 0.17264269441154667, 0.17264269441154667, 0.17264269441154667, 0.24121874041684, 0.24121874041684, 0.24121874041684, 0.11482486493351407, 0.11482486493351407, 0.11482486493351407, 0.20148531950814963, 0.20148531950814963, 0.20148531950814963, 0.21381408454744788, 0.21381408454744788, 0.21381408454744788, 0.2133353228214887, 0.2133353228214887, 0.2133353228214887, 0.1661838921499299, 0.1661838921499299, 0.1661838921499299, 0.18103521242015663, 0.18103521242015663, 0.18103521242015663, 0.16968008604690454, 0.16968008604690454, 0.16968008604690454, 0.7392109410027312, 0.7392109410027312, 0.7392109410027312, 0.15952107399436977, 0.15952107399436977, 0.15952107399436977, 0.7213749726382364, 0.7213749726382364, 0.7213749726382364, 0.6605482523795295, 0.6605482523795295, 0.6605482523795295, 0.20689908243842314, 0.20689908243842314, 0.20689908243842314, 0.5743480096964131, 0.5743480096964131, 0.5743480096964131, 0.1727123003890545, 0.1727123003890545, 0.1727123003890545, 0.17582310925204714, 0.17582310925204714, 0.17582310925204714, 0.19410393862905817, 0.19410393862905817, 0.19410393862905817, 0.08966238783469793, 0.08966238783469793, 0.08966238783469793, 0.08583251425472538, 0.08583251425472538, 0.08583251425472538, 0.09148404455896886, 0.09148404455896886, 0.09148404455896886]}, "mutation_prompt": null}
{"id": "05ad7416-7b73-429e-8740-dfb3e1e42d93", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.9  # Adjusted initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.95  # New adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            # Update velocity and position\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                # Move particle\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                # Simulated annealing acceptance criterion\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            # Adaptive cooling schedule\n            temperature *= self.adaptive_factor\n\n            # Adaptive inertia weight\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "An enhanced PSO-SA optimizer with an improved balance between exploration and exploitation using adaptive inertia weight adjustment.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e0f6670c-264d-46ec-8861-a17782775bdf", "metadata": {"aucs": [0.6782647470792136, 0.6782647470792136, 0.6782647470792136, 0.6510620026916942, 0.6510620026916942, 0.6510620026916942, 0.6307662893010079, 0.6307662893010079, 0.6307662893010079, 0.05540475876260609, 0.05540475876260609, 0.05540475876260609, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01448574992938989, 0.01448574992938989, 0.01448574992938989, 0.09502846657201225, 0.09502846657201225, 0.09502846657201225, 0.0984190369503456, 0.0984190369503456, 0.0984190369503456, 0.13080427528685945, 0.13080427528685945, 0.13080427528685945, 0.073673847260183, 0.073673847260183, 0.073673847260183, 0.05739882526973683, 0.05739882526973683, 0.05739882526973683, 0.07794004265815979, 0.07794004265815979, 0.07794004265815979, 0.8525402858757739, 0.8525402858757739, 0.8525402858757739, 0.9114141382313873, 0.9114141382313873, 0.9114141382313873, 0.8850647317060869, 0.8850647317060869, 0.8850647317060869, 0.2171888195131806, 0.2171888195131806, 0.2171888195131806, 0.13116807101889227, 0.13116807101889227, 0.13116807101889227, 0.2072827847199925, 0.2072827847199925, 0.2072827847199925, 0.2139576603012453, 0.2139576603012453, 0.2139576603012453, 0.1571805014521238, 0.1571805014521238, 0.1571805014521238, 0.3048371907230467, 0.3048371907230467, 0.3048371907230467, 0.09213223331845144, 0.09213223331845144, 0.09213223331845144, 0.08981510009688898, 0.08981510009688898, 0.08981510009688898, 0.10607229217830427, 0.10607229217830427, 0.10607229217830427, 0.060920354018421885, 0.060920354018421885, 0.060920354018421885, 0.08479455500229305, 0.08479455500229305, 0.08479455500229305, 0.06180700910541692, 0.06180700910541692, 0.06180700910541692, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05761638572361749, 0.05761638572361749, 0.05761638572361749, 0.018114331716615584, 0.018114331716615584, 0.018114331716615584, 0.06399645503600315, 0.06399645503600315, 0.06399645503600315, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07319458700471948, 0.07319458700471948, 0.07319458700471948, 0.02800626687419594, 0.02800626687419594, 0.02800626687419594, 0.04304900736273831, 0.04304900736273831, 0.04304900736273831, 0.4645646844442144, 0.4645646844442144, 0.4645646844442144, 0.454150747587446, 0.454150747587446, 0.454150747587446, 0.4821512698573891, 0.4821512698573891, 0.4821512698573891, 0.07360090595713464, 0.07360090595713464, 0.07360090595713464, 0.08875960234614544, 0.08875960234614544, 0.08875960234614544, 0.15553736061881096, 0.15553736061881096, 0.15553736061881096, 0.19567324730641666, 0.19567324730641666, 0.19567324730641666, 0.1700859289979919, 0.1700859289979919, 0.1700859289979919, 0.14966476025823616, 0.14966476025823616, 0.14966476025823616, 0.3353929290925436, 0.3353929290925436, 0.3353929290925436, 0.3183330547963904, 0.3183330547963904, 0.3183330547963904, 0.39844986593988374, 0.39844986593988374, 0.39844986593988374, 0.17264269441154667, 0.17264269441154667, 0.17264269441154667, 0.24121874041684, 0.24121874041684, 0.24121874041684, 0.11482486493351407, 0.11482486493351407, 0.11482486493351407, 0.20148531950814963, 0.20148531950814963, 0.20148531950814963, 0.21381408454744788, 0.21381408454744788, 0.21381408454744788, 0.2133353228214887, 0.2133353228214887, 0.2133353228214887, 0.1661838921499299, 0.1661838921499299, 0.1661838921499299, 0.18103521242015663, 0.18103521242015663, 0.18103521242015663, 0.16968008604690454, 0.16968008604690454, 0.16968008604690454, 0.7392109410027312, 0.7392109410027312, 0.7392109410027312, 0.15952107399436977, 0.15952107399436977, 0.15952107399436977, 0.7213749726382364, 0.7213749726382364, 0.7213749726382364, 0.6605482523795295, 0.6605482523795295, 0.6605482523795295, 0.20689908243842314, 0.20689908243842314, 0.20689908243842314, 0.5743480096964131, 0.5743480096964131, 0.5743480096964131, 0.1727123003890545, 0.1727123003890545, 0.1727123003890545, 0.17582310925204714, 0.17582310925204714, 0.17582310925204714, 0.19410393862905817, 0.19410393862905817, 0.19410393862905817, 0.08966238783469793, 0.08966238783469793, 0.08966238783469793, 0.08583251425472538, 0.08583251425472538, 0.08583251425472538, 0.09148404455896886, 0.09148404455896886, 0.09148404455896886]}, "mutation_prompt": null}
{"id": "db12447c-2b6f-4048-813c-ff205134de06", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.9  # Adjusted initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.95  # New adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            # Update velocity and position\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                # Move particle\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                # Simulated annealing acceptance criterion\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            # Adaptive cooling schedule\n            temperature *= self.adaptive_factor\n\n            # Adaptive inertia weight\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "An enhanced PSO-SA optimizer with an improved balance between exploration and exploitation using adaptive inertia weight adjustment.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e0f6670c-264d-46ec-8861-a17782775bdf", "metadata": {"aucs": [0.6782647470792136, 0.6782647470792136, 0.6782647470792136, 0.6510620026916942, 0.6510620026916942, 0.6510620026916942, 0.6307662893010079, 0.6307662893010079, 0.6307662893010079, 0.05540475876260609, 0.05540475876260609, 0.05540475876260609, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01448574992938989, 0.01448574992938989, 0.01448574992938989, 0.09502846657201225, 0.09502846657201225, 0.09502846657201225, 0.0984190369503456, 0.0984190369503456, 0.0984190369503456, 0.13080427528685945, 0.13080427528685945, 0.13080427528685945, 0.073673847260183, 0.073673847260183, 0.073673847260183, 0.05739882526973683, 0.05739882526973683, 0.05739882526973683, 0.07794004265815979, 0.07794004265815979, 0.07794004265815979, 0.8525402858757739, 0.8525402858757739, 0.8525402858757739, 0.9114141382313873, 0.9114141382313873, 0.9114141382313873, 0.8850647317060869, 0.8850647317060869, 0.8850647317060869, 0.2171888195131806, 0.2171888195131806, 0.2171888195131806, 0.13116807101889227, 0.13116807101889227, 0.13116807101889227, 0.2072827847199925, 0.2072827847199925, 0.2072827847199925, 0.2139576603012453, 0.2139576603012453, 0.2139576603012453, 0.1571805014521238, 0.1571805014521238, 0.1571805014521238, 0.3048371907230467, 0.3048371907230467, 0.3048371907230467, 0.09213223331845144, 0.09213223331845144, 0.09213223331845144, 0.08981510009688898, 0.08981510009688898, 0.08981510009688898, 0.10607229217830427, 0.10607229217830427, 0.10607229217830427, 0.060920354018421885, 0.060920354018421885, 0.060920354018421885, 0.08479455500229305, 0.08479455500229305, 0.08479455500229305, 0.06180700910541692, 0.06180700910541692, 0.06180700910541692, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05761638572361749, 0.05761638572361749, 0.05761638572361749, 0.018114331716615584, 0.018114331716615584, 0.018114331716615584, 0.06399645503600315, 0.06399645503600315, 0.06399645503600315, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07319458700471948, 0.07319458700471948, 0.07319458700471948, 0.02800626687419594, 0.02800626687419594, 0.02800626687419594, 0.04304900736273831, 0.04304900736273831, 0.04304900736273831, 0.4645646844442144, 0.4645646844442144, 0.4645646844442144, 0.454150747587446, 0.454150747587446, 0.454150747587446, 0.4821512698573891, 0.4821512698573891, 0.4821512698573891, 0.07360090595713464, 0.07360090595713464, 0.07360090595713464, 0.08875960234614544, 0.08875960234614544, 0.08875960234614544, 0.15553736061881096, 0.15553736061881096, 0.15553736061881096, 0.19567324730641666, 0.19567324730641666, 0.19567324730641666, 0.1700859289979919, 0.1700859289979919, 0.1700859289979919, 0.14966476025823616, 0.14966476025823616, 0.14966476025823616, 0.3353929290925436, 0.3353929290925436, 0.3353929290925436, 0.3183330547963904, 0.3183330547963904, 0.3183330547963904, 0.39844986593988374, 0.39844986593988374, 0.39844986593988374, 0.17264269441154667, 0.17264269441154667, 0.17264269441154667, 0.24121874041684, 0.24121874041684, 0.24121874041684, 0.11482486493351407, 0.11482486493351407, 0.11482486493351407, 0.20148531950814963, 0.20148531950814963, 0.20148531950814963, 0.21381408454744788, 0.21381408454744788, 0.21381408454744788, 0.2133353228214887, 0.2133353228214887, 0.2133353228214887, 0.1661838921499299, 0.1661838921499299, 0.1661838921499299, 0.18103521242015663, 0.18103521242015663, 0.18103521242015663, 0.16968008604690454, 0.16968008604690454, 0.16968008604690454, 0.7392109410027312, 0.7392109410027312, 0.7392109410027312, 0.15952107399436977, 0.15952107399436977, 0.15952107399436977, 0.7213749726382364, 0.7213749726382364, 0.7213749726382364, 0.6605482523795295, 0.6605482523795295, 0.6605482523795295, 0.20689908243842314, 0.20689908243842314, 0.20689908243842314, 0.5743480096964131, 0.5743480096964131, 0.5743480096964131, 0.1727123003890545, 0.1727123003890545, 0.1727123003890545, 0.17582310925204714, 0.17582310925204714, 0.17582310925204714, 0.19410393862905817, 0.19410393862905817, 0.19410393862905817, 0.08966238783469793, 0.08966238783469793, 0.08966238783469793, 0.08583251425472538, 0.08583251425472538, 0.08583251425472538, 0.09148404455896886, 0.09148404455896886, 0.09148404455896886]}, "mutation_prompt": null}
{"id": "9a4081d3-0ddf-4f83-9c31-d052cd465be7", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.9  # Adjusted initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.95  # New adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            # Update velocity and position\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                # Move particle\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                # Simulated annealing acceptance criterion\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            # Adaptive cooling schedule\n            temperature *= self.adaptive_factor\n\n            # Adaptive inertia weight\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "An enhanced PSO-SA optimizer with an improved balance between exploration and exploitation using adaptive inertia weight adjustment.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e0f6670c-264d-46ec-8861-a17782775bdf", "metadata": {"aucs": [0.6782647470792136, 0.6782647470792136, 0.6782647470792136, 0.6510620026916942, 0.6510620026916942, 0.6510620026916942, 0.6307662893010079, 0.6307662893010079, 0.6307662893010079, 0.05540475876260609, 0.05540475876260609, 0.05540475876260609, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01448574992938989, 0.01448574992938989, 0.01448574992938989, 0.09502846657201225, 0.09502846657201225, 0.09502846657201225, 0.0984190369503456, 0.0984190369503456, 0.0984190369503456, 0.13080427528685945, 0.13080427528685945, 0.13080427528685945, 0.073673847260183, 0.073673847260183, 0.073673847260183, 0.05739882526973683, 0.05739882526973683, 0.05739882526973683, 0.07794004265815979, 0.07794004265815979, 0.07794004265815979, 0.8525402858757739, 0.8525402858757739, 0.8525402858757739, 0.9114141382313873, 0.9114141382313873, 0.9114141382313873, 0.8850647317060869, 0.8850647317060869, 0.8850647317060869, 0.2171888195131806, 0.2171888195131806, 0.2171888195131806, 0.13116807101889227, 0.13116807101889227, 0.13116807101889227, 0.2072827847199925, 0.2072827847199925, 0.2072827847199925, 0.2139576603012453, 0.2139576603012453, 0.2139576603012453, 0.1571805014521238, 0.1571805014521238, 0.1571805014521238, 0.3048371907230467, 0.3048371907230467, 0.3048371907230467, 0.09213223331845144, 0.09213223331845144, 0.09213223331845144, 0.08981510009688898, 0.08981510009688898, 0.08981510009688898, 0.10607229217830427, 0.10607229217830427, 0.10607229217830427, 0.060920354018421885, 0.060920354018421885, 0.060920354018421885, 0.08479455500229305, 0.08479455500229305, 0.08479455500229305, 0.06180700910541692, 0.06180700910541692, 0.06180700910541692, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05761638572361749, 0.05761638572361749, 0.05761638572361749, 0.018114331716615584, 0.018114331716615584, 0.018114331716615584, 0.06399645503600315, 0.06399645503600315, 0.06399645503600315, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07319458700471948, 0.07319458700471948, 0.07319458700471948, 0.02800626687419594, 0.02800626687419594, 0.02800626687419594, 0.04304900736273831, 0.04304900736273831, 0.04304900736273831, 0.4645646844442144, 0.4645646844442144, 0.4645646844442144, 0.454150747587446, 0.454150747587446, 0.454150747587446, 0.4821512698573891, 0.4821512698573891, 0.4821512698573891, 0.07360090595713464, 0.07360090595713464, 0.07360090595713464, 0.08875960234614544, 0.08875960234614544, 0.08875960234614544, 0.15553736061881096, 0.15553736061881096, 0.15553736061881096, 0.19567324730641666, 0.19567324730641666, 0.19567324730641666, 0.1700859289979919, 0.1700859289979919, 0.1700859289979919, 0.14966476025823616, 0.14966476025823616, 0.14966476025823616, 0.3353929290925436, 0.3353929290925436, 0.3353929290925436, 0.3183330547963904, 0.3183330547963904, 0.3183330547963904, 0.39844986593988374, 0.39844986593988374, 0.39844986593988374, 0.17264269441154667, 0.17264269441154667, 0.17264269441154667, 0.24121874041684, 0.24121874041684, 0.24121874041684, 0.11482486493351407, 0.11482486493351407, 0.11482486493351407, 0.20148531950814963, 0.20148531950814963, 0.20148531950814963, 0.21381408454744788, 0.21381408454744788, 0.21381408454744788, 0.2133353228214887, 0.2133353228214887, 0.2133353228214887, 0.1661838921499299, 0.1661838921499299, 0.1661838921499299, 0.18103521242015663, 0.18103521242015663, 0.18103521242015663, 0.16968008604690454, 0.16968008604690454, 0.16968008604690454, 0.7392109410027312, 0.7392109410027312, 0.7392109410027312, 0.15952107399436977, 0.15952107399436977, 0.15952107399436977, 0.7213749726382364, 0.7213749726382364, 0.7213749726382364, 0.6605482523795295, 0.6605482523795295, 0.6605482523795295, 0.20689908243842314, 0.20689908243842314, 0.20689908243842314, 0.5743480096964131, 0.5743480096964131, 0.5743480096964131, 0.1727123003890545, 0.1727123003890545, 0.1727123003890545, 0.17582310925204714, 0.17582310925204714, 0.17582310925204714, 0.19410393862905817, 0.19410393862905817, 0.19410393862905817, 0.08966238783469793, 0.08966238783469793, 0.08966238783469793, 0.08583251425472538, 0.08583251425472538, 0.08583251425472538, 0.09148404455896886, 0.09148404455896886, 0.09148404455896886]}, "mutation_prompt": null}
{"id": "f68d53a0-b193-472a-8d12-31b9aab5244f", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.9  # Adjusted initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.95  # New adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            # Update velocity and position\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                # Dynamic velocity bounds adjustment\n                max_velocity = (self.bounds[1] - self.bounds[0]) * 0.1\n                velocities[i] = np.clip(velocities[i], -max_velocity, max_velocity)\n\n                # Move particle\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                # Simulated annealing acceptance criterion\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            # Adaptive cooling schedule\n            temperature *= self.adaptive_factor\n\n            # Adaptive inertia weight\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "A refined PSO-SA optimizer with dynamic velocity bounds adjustment for improved convergence speed.", "configspace": "", "generation": 13, "fitness": 0.22300286117038115, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.23.", "error": "", "parent_id": "e0f6670c-264d-46ec-8861-a17782775bdf", "metadata": {"aucs": [0.6782647470792136, 0.6782647470792136, 0.6782647470792136, 0.6510620026916942, 0.6510620026916942, 0.6510620026916942, 0.6307662893010079, 0.6307662893010079, 0.6307662893010079, 0.05540475876260609, 0.05540475876260609, 0.05540475876260609, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01448574992938989, 0.01448574992938989, 0.01448574992938989, 0.09502846657201225, 0.09502846657201225, 0.09502846657201225, 0.0984190369503456, 0.0984190369503456, 0.0984190369503456, 0.13080427528685945, 0.13080427528685945, 0.13080427528685945, 0.073673847260183, 0.073673847260183, 0.073673847260183, 0.05739882526973683, 0.05739882526973683, 0.05739882526973683, 0.07794004265815979, 0.07794004265815979, 0.07794004265815979, 0.8525402858757739, 0.8525402858757739, 0.8525402858757739, 0.9114141382313873, 0.9114141382313873, 0.9114141382313873, 0.8850647317060869, 0.8850647317060869, 0.8850647317060869, 0.2171888195131806, 0.2171888195131806, 0.2171888195131806, 0.13116807101889227, 0.13116807101889227, 0.13116807101889227, 0.2072827847199925, 0.2072827847199925, 0.2072827847199925, 0.2139576603012453, 0.2139576603012453, 0.2139576603012453, 0.1571805014521238, 0.1571805014521238, 0.1571805014521238, 0.3048371907230467, 0.3048371907230467, 0.3048371907230467, 0.09213223331845144, 0.09213223331845144, 0.09213223331845144, 0.08981510009688898, 0.08981510009688898, 0.08981510009688898, 0.10607229217830427, 0.10607229217830427, 0.10607229217830427, 0.060920354018421885, 0.060920354018421885, 0.060920354018421885, 0.08479455500229305, 0.08479455500229305, 0.08479455500229305, 0.06180700910541692, 0.06180700910541692, 0.06180700910541692, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05761638572361749, 0.05761638572361749, 0.05761638572361749, 0.018114331716615584, 0.018114331716615584, 0.018114331716615584, 0.06399645503600315, 0.06399645503600315, 0.06399645503600315, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07319458700471948, 0.07319458700471948, 0.07319458700471948, 0.02800626687419594, 0.02800626687419594, 0.02800626687419594, 0.04304900736273831, 0.04304900736273831, 0.04304900736273831, 0.4645646844442144, 0.4645646844442144, 0.4645646844442144, 0.454150747587446, 0.454150747587446, 0.454150747587446, 0.4821512698573891, 0.4821512698573891, 0.4821512698573891, 0.07360090595713464, 0.07360090595713464, 0.07360090595713464, 0.08875960234614544, 0.08875960234614544, 0.08875960234614544, 0.15553736061881096, 0.15553736061881096, 0.15553736061881096, 0.19567324730641666, 0.19567324730641666, 0.19567324730641666, 0.1700859289979919, 0.1700859289979919, 0.1700859289979919, 0.14966476025823616, 0.14966476025823616, 0.14966476025823616, 0.3353929290925436, 0.3353929290925436, 0.3353929290925436, 0.3183330547963904, 0.3183330547963904, 0.3183330547963904, 0.39844986593988374, 0.39844986593988374, 0.39844986593988374, 0.17264269441154667, 0.17264269441154667, 0.17264269441154667, 0.24121874041684, 0.24121874041684, 0.24121874041684, 0.11482486493351407, 0.11482486493351407, 0.11482486493351407, 0.20148531950814963, 0.20148531950814963, 0.20148531950814963, 0.21381408454744788, 0.21381408454744788, 0.21381408454744788, 0.2133353228214887, 0.2133353228214887, 0.2133353228214887, 0.1661838921499299, 0.1661838921499299, 0.1661838921499299, 0.18103521242015663, 0.18103521242015663, 0.18103521242015663, 0.16968008604690454, 0.16968008604690454, 0.16968008604690454, 0.7392109410027312, 0.7392109410027312, 0.7392109410027312, 0.15952107399436977, 0.15952107399436977, 0.15952107399436977, 0.7213749726382364, 0.7213749726382364, 0.7213749726382364, 0.6605482523795295, 0.6605482523795295, 0.6605482523795295, 0.20689908243842314, 0.20689908243842314, 0.20689908243842314, 0.5743480096964131, 0.5743480096964131, 0.5743480096964131, 0.1727123003890545, 0.1727123003890545, 0.1727123003890545, 0.17582310925204714, 0.17582310925204714, 0.17582310925204714, 0.19410393862905817, 0.19410393862905817, 0.19410393862905817, 0.08966238783469793, 0.08966238783469793, 0.08966238783469793, 0.08583251425472538, 0.08583251425472538, 0.08583251425472538, 0.09148404455896886, 0.09148404455896886, 0.09148404455896886]}, "mutation_prompt": null}
{"id": "38654d7d-3eca-4dba-b271-fb2e9dfed35d", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.9  # Adjusted initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.95  # New adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            # Update velocity and position\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                # Move particle\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                # Simulated annealing acceptance criterion\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            # Adaptive cooling schedule\n            temperature *= self.adaptive_factor\n\n            # Adaptive inertia weight\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "An enhanced PSO-SA optimizer with an improved balance between exploration and exploitation using adaptive inertia weight adjustment.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e0f6670c-264d-46ec-8861-a17782775bdf", "metadata": {"aucs": [0.6782647470792136, 0.6782647470792136, 0.6782647470792136, 0.6510620026916942, 0.6510620026916942, 0.6510620026916942, 0.6307662893010079, 0.6307662893010079, 0.6307662893010079, 0.05540475876260609, 0.05540475876260609, 0.05540475876260609, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01448574992938989, 0.01448574992938989, 0.01448574992938989, 0.09502846657201225, 0.09502846657201225, 0.09502846657201225, 0.0984190369503456, 0.0984190369503456, 0.0984190369503456, 0.13080427528685945, 0.13080427528685945, 0.13080427528685945, 0.073673847260183, 0.073673847260183, 0.073673847260183, 0.05739882526973683, 0.05739882526973683, 0.05739882526973683, 0.07794004265815979, 0.07794004265815979, 0.07794004265815979, 0.8525402858757739, 0.8525402858757739, 0.8525402858757739, 0.9114141382313873, 0.9114141382313873, 0.9114141382313873, 0.8850647317060869, 0.8850647317060869, 0.8850647317060869, 0.2171888195131806, 0.2171888195131806, 0.2171888195131806, 0.13116807101889227, 0.13116807101889227, 0.13116807101889227, 0.2072827847199925, 0.2072827847199925, 0.2072827847199925, 0.2139576603012453, 0.2139576603012453, 0.2139576603012453, 0.1571805014521238, 0.1571805014521238, 0.1571805014521238, 0.3048371907230467, 0.3048371907230467, 0.3048371907230467, 0.09213223331845144, 0.09213223331845144, 0.09213223331845144, 0.08981510009688898, 0.08981510009688898, 0.08981510009688898, 0.10607229217830427, 0.10607229217830427, 0.10607229217830427, 0.060920354018421885, 0.060920354018421885, 0.060920354018421885, 0.08479455500229305, 0.08479455500229305, 0.08479455500229305, 0.06180700910541692, 0.06180700910541692, 0.06180700910541692, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05761638572361749, 0.05761638572361749, 0.05761638572361749, 0.018114331716615584, 0.018114331716615584, 0.018114331716615584, 0.06399645503600315, 0.06399645503600315, 0.06399645503600315, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07319458700471948, 0.07319458700471948, 0.07319458700471948, 0.02800626687419594, 0.02800626687419594, 0.02800626687419594, 0.04304900736273831, 0.04304900736273831, 0.04304900736273831, 0.4645646844442144, 0.4645646844442144, 0.4645646844442144, 0.454150747587446, 0.454150747587446, 0.454150747587446, 0.4821512698573891, 0.4821512698573891, 0.4821512698573891, 0.07360090595713464, 0.07360090595713464, 0.07360090595713464, 0.08875960234614544, 0.08875960234614544, 0.08875960234614544, 0.15553736061881096, 0.15553736061881096, 0.15553736061881096, 0.19567324730641666, 0.19567324730641666, 0.19567324730641666, 0.1700859289979919, 0.1700859289979919, 0.1700859289979919, 0.14966476025823616, 0.14966476025823616, 0.14966476025823616, 0.3353929290925436, 0.3353929290925436, 0.3353929290925436, 0.3183330547963904, 0.3183330547963904, 0.3183330547963904, 0.39844986593988374, 0.39844986593988374, 0.39844986593988374, 0.17264269441154667, 0.17264269441154667, 0.17264269441154667, 0.24121874041684, 0.24121874041684, 0.24121874041684, 0.11482486493351407, 0.11482486493351407, 0.11482486493351407, 0.20148531950814963, 0.20148531950814963, 0.20148531950814963, 0.21381408454744788, 0.21381408454744788, 0.21381408454744788, 0.2133353228214887, 0.2133353228214887, 0.2133353228214887, 0.1661838921499299, 0.1661838921499299, 0.1661838921499299, 0.18103521242015663, 0.18103521242015663, 0.18103521242015663, 0.16968008604690454, 0.16968008604690454, 0.16968008604690454, 0.7392109410027312, 0.7392109410027312, 0.7392109410027312, 0.15952107399436977, 0.15952107399436977, 0.15952107399436977, 0.7213749726382364, 0.7213749726382364, 0.7213749726382364, 0.6605482523795295, 0.6605482523795295, 0.6605482523795295, 0.20689908243842314, 0.20689908243842314, 0.20689908243842314, 0.5743480096964131, 0.5743480096964131, 0.5743480096964131, 0.1727123003890545, 0.1727123003890545, 0.1727123003890545, 0.17582310925204714, 0.17582310925204714, 0.17582310925204714, 0.19410393862905817, 0.19410393862905817, 0.19410393862905817, 0.08966238783469793, 0.08966238783469793, 0.08966238783469793, 0.08583251425472538, 0.08583251425472538, 0.08583251425472538, 0.09148404455896886, 0.09148404455896886, 0.09148404455896886]}, "mutation_prompt": null}
{"id": "9edda741-7e5a-4fc8-b698-bfd37995f5d9", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.9  # Adjusted initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.95  # New adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            # Update velocity and position\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                # Move particle\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                # Simulated annealing acceptance criterion\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            # Adaptive cooling schedule\n            temperature *= self.adaptive_factor\n\n            # Adaptive inertia weight\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "An enhanced PSO-SA optimizer with an improved balance between exploration and exploitation using adaptive inertia weight adjustment.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e0f6670c-264d-46ec-8861-a17782775bdf", "metadata": {"aucs": [0.6782647470792136, 0.6782647470792136, 0.6782647470792136, 0.6510620026916942, 0.6510620026916942, 0.6510620026916942, 0.6307662893010079, 0.6307662893010079, 0.6307662893010079, 0.05540475876260609, 0.05540475876260609, 0.05540475876260609, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01448574992938989, 0.01448574992938989, 0.01448574992938989, 0.09502846657201225, 0.09502846657201225, 0.09502846657201225, 0.0984190369503456, 0.0984190369503456, 0.0984190369503456, 0.13080427528685945, 0.13080427528685945, 0.13080427528685945, 0.073673847260183, 0.073673847260183, 0.073673847260183, 0.05739882526973683, 0.05739882526973683, 0.05739882526973683, 0.07794004265815979, 0.07794004265815979, 0.07794004265815979, 0.8525402858757739, 0.8525402858757739, 0.8525402858757739, 0.9114141382313873, 0.9114141382313873, 0.9114141382313873, 0.8850647317060869, 0.8850647317060869, 0.8850647317060869, 0.2171888195131806, 0.2171888195131806, 0.2171888195131806, 0.13116807101889227, 0.13116807101889227, 0.13116807101889227, 0.2072827847199925, 0.2072827847199925, 0.2072827847199925, 0.2139576603012453, 0.2139576603012453, 0.2139576603012453, 0.1571805014521238, 0.1571805014521238, 0.1571805014521238, 0.3048371907230467, 0.3048371907230467, 0.3048371907230467, 0.09213223331845144, 0.09213223331845144, 0.09213223331845144, 0.08981510009688898, 0.08981510009688898, 0.08981510009688898, 0.10607229217830427, 0.10607229217830427, 0.10607229217830427, 0.060920354018421885, 0.060920354018421885, 0.060920354018421885, 0.08479455500229305, 0.08479455500229305, 0.08479455500229305, 0.06180700910541692, 0.06180700910541692, 0.06180700910541692, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05761638572361749, 0.05761638572361749, 0.05761638572361749, 0.018114331716615584, 0.018114331716615584, 0.018114331716615584, 0.06399645503600315, 0.06399645503600315, 0.06399645503600315, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07319458700471948, 0.07319458700471948, 0.07319458700471948, 0.02800626687419594, 0.02800626687419594, 0.02800626687419594, 0.04304900736273831, 0.04304900736273831, 0.04304900736273831, 0.4645646844442144, 0.4645646844442144, 0.4645646844442144, 0.454150747587446, 0.454150747587446, 0.454150747587446, 0.4821512698573891, 0.4821512698573891, 0.4821512698573891, 0.07360090595713464, 0.07360090595713464, 0.07360090595713464, 0.08875960234614544, 0.08875960234614544, 0.08875960234614544, 0.15553736061881096, 0.15553736061881096, 0.15553736061881096, 0.19567324730641666, 0.19567324730641666, 0.19567324730641666, 0.1700859289979919, 0.1700859289979919, 0.1700859289979919, 0.14966476025823616, 0.14966476025823616, 0.14966476025823616, 0.3353929290925436, 0.3353929290925436, 0.3353929290925436, 0.3183330547963904, 0.3183330547963904, 0.3183330547963904, 0.39844986593988374, 0.39844986593988374, 0.39844986593988374, 0.17264269441154667, 0.17264269441154667, 0.17264269441154667, 0.24121874041684, 0.24121874041684, 0.24121874041684, 0.11482486493351407, 0.11482486493351407, 0.11482486493351407, 0.20148531950814963, 0.20148531950814963, 0.20148531950814963, 0.21381408454744788, 0.21381408454744788, 0.21381408454744788, 0.2133353228214887, 0.2133353228214887, 0.2133353228214887, 0.1661838921499299, 0.1661838921499299, 0.1661838921499299, 0.18103521242015663, 0.18103521242015663, 0.18103521242015663, 0.16968008604690454, 0.16968008604690454, 0.16968008604690454, 0.7392109410027312, 0.7392109410027312, 0.7392109410027312, 0.15952107399436977, 0.15952107399436977, 0.15952107399436977, 0.7213749726382364, 0.7213749726382364, 0.7213749726382364, 0.6605482523795295, 0.6605482523795295, 0.6605482523795295, 0.20689908243842314, 0.20689908243842314, 0.20689908243842314, 0.5743480096964131, 0.5743480096964131, 0.5743480096964131, 0.1727123003890545, 0.1727123003890545, 0.1727123003890545, 0.17582310925204714, 0.17582310925204714, 0.17582310925204714, 0.19410393862905817, 0.19410393862905817, 0.19410393862905817, 0.08966238783469793, 0.08966238783469793, 0.08966238783469793, 0.08583251425472538, 0.08583251425472538, 0.08583251425472538, 0.09148404455896886, 0.09148404455896886, 0.09148404455896886]}, "mutation_prompt": null}
{"id": "d4c2655c-aa48-4d6a-bb76-f3c5e8941444", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.9  # Adjusted initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.95  # New adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            # Update velocity and position\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                # Move particle\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                # Simulated annealing acceptance criterion\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            # Adaptive cooling schedule\n            temperature *= self.adaptive_factor\n\n            # Adaptive inertia weight\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "An enhanced PSO-SA optimizer with an improved balance between exploration and exploitation using adaptive inertia weight adjustment.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e0f6670c-264d-46ec-8861-a17782775bdf", "metadata": {"aucs": [0.6782647470792136, 0.6782647470792136, 0.6782647470792136, 0.6510620026916942, 0.6510620026916942, 0.6510620026916942, 0.6307662893010079, 0.6307662893010079, 0.6307662893010079, 0.05540475876260609, 0.05540475876260609, 0.05540475876260609, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01448574992938989, 0.01448574992938989, 0.01448574992938989, 0.09502846657201225, 0.09502846657201225, 0.09502846657201225, 0.0984190369503456, 0.0984190369503456, 0.0984190369503456, 0.13080427528685945, 0.13080427528685945, 0.13080427528685945, 0.073673847260183, 0.073673847260183, 0.073673847260183, 0.05739882526973683, 0.05739882526973683, 0.05739882526973683, 0.07794004265815979, 0.07794004265815979, 0.07794004265815979, 0.8525402858757739, 0.8525402858757739, 0.8525402858757739, 0.9114141382313873, 0.9114141382313873, 0.9114141382313873, 0.8850647317060869, 0.8850647317060869, 0.8850647317060869, 0.2171888195131806, 0.2171888195131806, 0.2171888195131806, 0.13116807101889227, 0.13116807101889227, 0.13116807101889227, 0.2072827847199925, 0.2072827847199925, 0.2072827847199925, 0.2139576603012453, 0.2139576603012453, 0.2139576603012453, 0.1571805014521238, 0.1571805014521238, 0.1571805014521238, 0.3048371907230467, 0.3048371907230467, 0.3048371907230467, 0.09213223331845144, 0.09213223331845144, 0.09213223331845144, 0.08981510009688898, 0.08981510009688898, 0.08981510009688898, 0.10607229217830427, 0.10607229217830427, 0.10607229217830427, 0.060920354018421885, 0.060920354018421885, 0.060920354018421885, 0.08479455500229305, 0.08479455500229305, 0.08479455500229305, 0.06180700910541692, 0.06180700910541692, 0.06180700910541692, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05761638572361749, 0.05761638572361749, 0.05761638572361749, 0.018114331716615584, 0.018114331716615584, 0.018114331716615584, 0.06399645503600315, 0.06399645503600315, 0.06399645503600315, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07319458700471948, 0.07319458700471948, 0.07319458700471948, 0.02800626687419594, 0.02800626687419594, 0.02800626687419594, 0.04304900736273831, 0.04304900736273831, 0.04304900736273831, 0.4645646844442144, 0.4645646844442144, 0.4645646844442144, 0.454150747587446, 0.454150747587446, 0.454150747587446, 0.4821512698573891, 0.4821512698573891, 0.4821512698573891, 0.07360090595713464, 0.07360090595713464, 0.07360090595713464, 0.08875960234614544, 0.08875960234614544, 0.08875960234614544, 0.15553736061881096, 0.15553736061881096, 0.15553736061881096, 0.19567324730641666, 0.19567324730641666, 0.19567324730641666, 0.1700859289979919, 0.1700859289979919, 0.1700859289979919, 0.14966476025823616, 0.14966476025823616, 0.14966476025823616, 0.3353929290925436, 0.3353929290925436, 0.3353929290925436, 0.3183330547963904, 0.3183330547963904, 0.3183330547963904, 0.39844986593988374, 0.39844986593988374, 0.39844986593988374, 0.17264269441154667, 0.17264269441154667, 0.17264269441154667, 0.24121874041684, 0.24121874041684, 0.24121874041684, 0.11482486493351407, 0.11482486493351407, 0.11482486493351407, 0.20148531950814963, 0.20148531950814963, 0.20148531950814963, 0.21381408454744788, 0.21381408454744788, 0.21381408454744788, 0.2133353228214887, 0.2133353228214887, 0.2133353228214887, 0.1661838921499299, 0.1661838921499299, 0.1661838921499299, 0.18103521242015663, 0.18103521242015663, 0.18103521242015663, 0.16968008604690454, 0.16968008604690454, 0.16968008604690454, 0.7392109410027312, 0.7392109410027312, 0.7392109410027312, 0.15952107399436977, 0.15952107399436977, 0.15952107399436977, 0.7213749726382364, 0.7213749726382364, 0.7213749726382364, 0.6605482523795295, 0.6605482523795295, 0.6605482523795295, 0.20689908243842314, 0.20689908243842314, 0.20689908243842314, 0.5743480096964131, 0.5743480096964131, 0.5743480096964131, 0.1727123003890545, 0.1727123003890545, 0.1727123003890545, 0.17582310925204714, 0.17582310925204714, 0.17582310925204714, 0.19410393862905817, 0.19410393862905817, 0.19410393862905817, 0.08966238783469793, 0.08966238783469793, 0.08966238783469793, 0.08583251425472538, 0.08583251425472538, 0.08583251425472538, 0.09148404455896886, 0.09148404455896886, 0.09148404455896886]}, "mutation_prompt": null}
{"id": "dde9bb89-b5c4-49ed-b403-65b9da2ab33d", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40  # Initial swarm size\n        self.w = 0.9  # Adjusted initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.95  # New adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            # Update velocity and position\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                # Move particle\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                # Simulated annealing acceptance criterion\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            # Adaptive cooling schedule\n            temperature *= self.adaptive_factor\n\n            # Adaptive inertia weight\n            self.w = max(self.w_min, self.w * 0.99)\n\n            # Dynamic swarm size adjustment\n            if evaluations < self.budget / 2:\n                self.swarm_size = min(self.swarm_size + 1, 60)  # Increase swarm size up to 60\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "An enhanced PSO-SA optimizer with an improved balance between exploration and exploitation using adaptive inertia weight adjustment and dynamic particle count.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 40 is out of bounds for axis 0 with size 40').", "error": "IndexError('index 40 is out of bounds for axis 0 with size 40')", "parent_id": "e0f6670c-264d-46ec-8861-a17782775bdf", "metadata": {}, "mutation_prompt": null}
{"id": "2fc3d659-6707-4340-8692-b83269c0f67c", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.9  # Adjusted initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.95  # New adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            # Update velocity and position\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                # Move particle\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                # Simulated annealing acceptance criterion\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            # Adaptive cooling schedule\n            temperature *= self.adaptive_factor\n\n            # Adaptive inertia weight\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "An enhanced PSO-SA optimizer with an improved balance between exploration and exploitation using adaptive inertia weight adjustment.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e0f6670c-264d-46ec-8861-a17782775bdf", "metadata": {"aucs": [0.6782647470792136, 0.6782647470792136, 0.6782647470792136, 0.6510620026916942, 0.6510620026916942, 0.6510620026916942, 0.6307662893010079, 0.6307662893010079, 0.6307662893010079, 0.05540475876260609, 0.05540475876260609, 0.05540475876260609, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01448574992938989, 0.01448574992938989, 0.01448574992938989, 0.09502846657201225, 0.09502846657201225, 0.09502846657201225, 0.0984190369503456, 0.0984190369503456, 0.0984190369503456, 0.13080427528685945, 0.13080427528685945, 0.13080427528685945, 0.073673847260183, 0.073673847260183, 0.073673847260183, 0.05739882526973683, 0.05739882526973683, 0.05739882526973683, 0.07794004265815979, 0.07794004265815979, 0.07794004265815979, 0.8525402858757739, 0.8525402858757739, 0.8525402858757739, 0.9114141382313873, 0.9114141382313873, 0.9114141382313873, 0.8850647317060869, 0.8850647317060869, 0.8850647317060869, 0.2171888195131806, 0.2171888195131806, 0.2171888195131806, 0.13116807101889227, 0.13116807101889227, 0.13116807101889227, 0.2072827847199925, 0.2072827847199925, 0.2072827847199925, 0.2139576603012453, 0.2139576603012453, 0.2139576603012453, 0.1571805014521238, 0.1571805014521238, 0.1571805014521238, 0.3048371907230467, 0.3048371907230467, 0.3048371907230467, 0.09213223331845144, 0.09213223331845144, 0.09213223331845144, 0.08981510009688898, 0.08981510009688898, 0.08981510009688898, 0.10607229217830427, 0.10607229217830427, 0.10607229217830427, 0.060920354018421885, 0.060920354018421885, 0.060920354018421885, 0.08479455500229305, 0.08479455500229305, 0.08479455500229305, 0.06180700910541692, 0.06180700910541692, 0.06180700910541692, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05761638572361749, 0.05761638572361749, 0.05761638572361749, 0.018114331716615584, 0.018114331716615584, 0.018114331716615584, 0.06399645503600315, 0.06399645503600315, 0.06399645503600315, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07319458700471948, 0.07319458700471948, 0.07319458700471948, 0.02800626687419594, 0.02800626687419594, 0.02800626687419594, 0.04304900736273831, 0.04304900736273831, 0.04304900736273831, 0.4645646844442144, 0.4645646844442144, 0.4645646844442144, 0.454150747587446, 0.454150747587446, 0.454150747587446, 0.4821512698573891, 0.4821512698573891, 0.4821512698573891, 0.07360090595713464, 0.07360090595713464, 0.07360090595713464, 0.08875960234614544, 0.08875960234614544, 0.08875960234614544, 0.15553736061881096, 0.15553736061881096, 0.15553736061881096, 0.19567324730641666, 0.19567324730641666, 0.19567324730641666, 0.1700859289979919, 0.1700859289979919, 0.1700859289979919, 0.14966476025823616, 0.14966476025823616, 0.14966476025823616, 0.3353929290925436, 0.3353929290925436, 0.3353929290925436, 0.3183330547963904, 0.3183330547963904, 0.3183330547963904, 0.39844986593988374, 0.39844986593988374, 0.39844986593988374, 0.17264269441154667, 0.17264269441154667, 0.17264269441154667, 0.24121874041684, 0.24121874041684, 0.24121874041684, 0.11482486493351407, 0.11482486493351407, 0.11482486493351407, 0.20148531950814963, 0.20148531950814963, 0.20148531950814963, 0.21381408454744788, 0.21381408454744788, 0.21381408454744788, 0.2133353228214887, 0.2133353228214887, 0.2133353228214887, 0.1661838921499299, 0.1661838921499299, 0.1661838921499299, 0.18103521242015663, 0.18103521242015663, 0.18103521242015663, 0.16968008604690454, 0.16968008604690454, 0.16968008604690454, 0.7392109410027312, 0.7392109410027312, 0.7392109410027312, 0.15952107399436977, 0.15952107399436977, 0.15952107399436977, 0.7213749726382364, 0.7213749726382364, 0.7213749726382364, 0.6605482523795295, 0.6605482523795295, 0.6605482523795295, 0.20689908243842314, 0.20689908243842314, 0.20689908243842314, 0.5743480096964131, 0.5743480096964131, 0.5743480096964131, 0.1727123003890545, 0.1727123003890545, 0.1727123003890545, 0.17582310925204714, 0.17582310925204714, 0.17582310925204714, 0.19410393862905817, 0.19410393862905817, 0.19410393862905817, 0.08966238783469793, 0.08966238783469793, 0.08966238783469793, 0.08583251425472538, 0.08583251425472538, 0.08583251425472538, 0.09148404455896886, 0.09148404455896886, 0.09148404455896886]}, "mutation_prompt": null}
{"id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with minor tuning in parameter values for improving convergence speed.", "configspace": "", "generation": 19, "fitness": 0.24028502205774427, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.24.", "error": "", "parent_id": "e0f6670c-264d-46ec-8861-a17782775bdf", "metadata": {"aucs": [0.6731653111579229, 0.6731653111579229, 0.6731653111579229, 0.711996635129519, 0.711996635129519, 0.711996635129519, 0.7078132901593165, 0.7078132901593165, 0.7078132901593165, 0.041381141768779384, 0.041381141768779384, 0.041381141768779384, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10950771709447105, 0.10950771709447105, 0.10950771709447105, 0.10521185649440323, 0.10521185649440323, 0.10521185649440323, 0.10507361746539623, 0.10507361746539623, 0.10507361746539623, 0.07764468958329585, 0.07764468958329585, 0.07764468958329585, 0.09106825770888427, 0.09106825770888427, 0.09106825770888427, 0.11676664795008551, 0.11676664795008551, 0.11676664795008551, 0.8873949697611814, 0.8873949697611814, 0.8873949697611814, 0.8899603182064498, 0.8899603182064498, 0.8899603182064498, 0.9242514104464227, 0.9242514104464227, 0.9242514104464227, 0.15529290578465005, 0.15529290578465005, 0.15529290578465005, 0.2190096480227307, 0.2190096480227307, 0.2190096480227307, 0.10602395596155945, 0.10602395596155945, 0.10602395596155945, 0.6785064774824554, 0.6785064774824554, 0.6785064774824554, 0.1588220386151905, 0.1588220386151905, 0.1588220386151905, 0.2013731947684061, 0.2013731947684061, 0.2013731947684061, 0.11757177930520302, 0.11757177930520302, 0.11757177930520302, 0.05893689880031361, 0.05893689880031361, 0.05893689880031361, 0.1347567060589916, 0.1347567060589916, 0.1347567060589916, 0.12717657197932586, 0.12717657197932586, 0.12717657197932586, 0.13013401995367202, 0.13013401995367202, 0.13013401995367202, 0.12393529212556109, 0.12393529212556109, 0.12393529212556109, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07406251021116783, 0.07406251021116783, 0.07406251021116783, 0.06698612153091676, 0.06698612153091676, 0.06698612153091676, 0.08330193363389515, 0.08330193363389515, 0.08330193363389515, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05394537933586785, 0.05394537933586785, 0.05394537933586785, 0.06280509881780472, 0.06280509881780472, 0.06280509881780472, 0.058389177628910716, 0.058389177628910716, 0.058389177628910716, 0.4471312292357341, 0.4471312292357341, 0.4471312292357341, 0.5243508001071969, 0.5243508001071969, 0.5243508001071969, 0.46983387154224854, 0.46983387154224854, 0.46983387154224854, 0.07663158410172577, 0.07663158410172577, 0.07663158410172577, 0.10886105391076506, 0.10886105391076506, 0.10886105391076506, 0.1298840489061095, 0.1298840489061095, 0.1298840489061095, 0.1594612677021673, 0.1594612677021673, 0.1594612677021673, 0.2988572920911492, 0.2988572920911492, 0.2988572920911492, 0.24455433586052078, 0.24455433586052078, 0.24455433586052078, 0.35593401052672236, 0.35593401052672236, 0.35593401052672236, 0.41401688285636506, 0.41401688285636506, 0.41401688285636506, 0.23348098648385784, 0.23348098648385784, 0.23348098648385784, 0.25155973801749965, 0.25155973801749965, 0.25155973801749965, 0.16473215297233235, 0.16473215297233235, 0.16473215297233235, 0.2618969115729881, 0.2618969115729881, 0.2618969115729881, 0.21816177922955693, 0.21816177922955693, 0.21816177922955693, 0.19590613448642658, 0.19590613448642658, 0.19590613448642658, 0.24283886563718105, 0.24283886563718105, 0.24283886563718105, 0.18712908296437525, 0.18712908296437525, 0.18712908296437525, 0.16823242717066367, 0.16823242717066367, 0.16823242717066367, 0.19714396552649538, 0.19714396552649538, 0.19714396552649538, 0.7424295255090958, 0.7424295255090958, 0.7424295255090958, 0.16360281335132354, 0.16360281335132354, 0.16360281335132354, 0.7787233078953587, 0.7787233078953587, 0.7787233078953587, 0.6864379667833054, 0.6864379667833054, 0.6864379667833054, 0.20954767599706114, 0.20954767599706114, 0.20954767599706114, 0.5250107589216552, 0.5250107589216552, 0.5250107589216552, 0.1978655172067132, 0.1978655172067132, 0.1978655172067132, 0.16373718664922376, 0.16373718664922376, 0.16373718664922376, 0.195695680947217, 0.195695680947217, 0.195695680947217, 0.07529581943051489, 0.07529581943051489, 0.07529581943051489, 0.0742746602426343, 0.0742746602426343, 0.0742746602426343, 0.08423668137865226, 0.08423668137865226, 0.08423668137865226]}, "mutation_prompt": null}
{"id": "239bdac6-6f34-4432-9589-8e41ddc56537", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2 = 1.3\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n        self.local_exploration_rate = 0.1  # Added local exploration rate\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            new_global_best_pos = self.global_best_pos + self.local_exploration_rate * np.random.uniform(-1, 1, self.dim)\n            new_global_best_pos = np.clip(new_global_best_pos, *self.bounds)\n            new_global_best_val = func(new_global_best_pos)\n            evaluations += 1\n            if new_global_best_val < self.global_best_val:\n                self.global_best_val = new_global_best_val\n                self.global_best_pos = new_global_best_pos\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Integrate a local exploration mechanism to enhance convergence speed by fine-tuning around the global best position.", "configspace": "", "generation": 20, "fitness": 0.22724517238543734, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.23.", "error": "", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6931378865465931, 0.6931378865465931, 0.6931378865465931, 0.6684018146474693, 0.6684018146474693, 0.6684018146474693, 0.6544096127782669, 0.6544096127782669, 0.6544096127782669, 0.03336737278554758, 0.03336737278554758, 0.03336737278554758, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11176022986206957, 0.11176022986206957, 0.11176022986206957, 0.08821967796600205, 0.08821967796600205, 0.08821967796600205, 0.10919341884374756, 0.10919341884374756, 0.10919341884374756, 0.08353727833210722, 0.08353727833210722, 0.08353727833210722, 0.06244228488213244, 0.06244228488213244, 0.06244228488213244, 0.10007972995109271, 0.10007972995109271, 0.10007972995109271, 0.8594922457220099, 0.8594922457220099, 0.8594922457220099, 0.8875233801200929, 0.8875233801200929, 0.8875233801200929, 0.8993215341517168, 0.8993215341517168, 0.8993215341517168, 0.2795073103520902, 0.2795073103520902, 0.2795073103520902, 0.19072856363645652, 0.19072856363645652, 0.19072856363645652, 0.14570569672352685, 0.14570569672352685, 0.14570569672352685, 0.21437254333290712, 0.21437254333290712, 0.21437254333290712, 0.25176575211805674, 0.25176575211805674, 0.25176575211805674, 0.15337071478462616, 0.15337071478462616, 0.15337071478462616, 0.14111217251632602, 0.14111217251632602, 0.14111217251632602, 0.11655826164876637, 0.11655826164876637, 0.11655826164876637, 0.10698864799777108, 0.10698864799777108, 0.10698864799777108, 0.13063924718081632, 0.13063924718081632, 0.13063924718081632, 0.12043831726953524, 0.12043831726953524, 0.12043831726953524, 0.09960004589492077, 0.09960004589492077, 0.09960004589492077, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08259931442703872, 0.08259931442703872, 0.08259931442703872, 0.01339764208726868, 0.01339764208726868, 0.01339764208726868, 0.10295012899032485, 0.10295012899032485, 0.10295012899032485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1695676549869337, 0.1695676549869337, 0.1695676549869337, 0.022421564961236484, 0.022421564961236484, 0.022421564961236484, 0.04318391584772219, 0.04318391584772219, 0.04318391584772219, 0.4542514315934367, 0.4542514315934367, 0.4542514315934367, 0.45566313577739426, 0.45566313577739426, 0.45566313577739426, 0.5011473512623119, 0.5011473512623119, 0.5011473512623119, 0.08530391042716079, 0.08530391042716079, 0.08530391042716079, 0.1004408941520647, 0.1004408941520647, 0.1004408941520647, 0.10515558431993577, 0.10515558431993577, 0.10515558431993577, 0.20066479131094617, 0.20066479131094617, 0.20066479131094617, 0.1897077964511108, 0.1897077964511108, 0.1897077964511108, 0.14941496658326736, 0.14941496658326736, 0.14941496658326736, 0.34134781150285753, 0.34134781150285753, 0.34134781150285753, 0.34864938995043426, 0.34864938995043426, 0.34864938995043426, 0.375214078150804, 0.375214078150804, 0.375214078150804, 0.2179370014396229, 0.2179370014396229, 0.2179370014396229, 0.15015262287631426, 0.15015262287631426, 0.15015262287631426, 0.26003827084149966, 0.26003827084149966, 0.26003827084149966, 0.208303889613895, 0.208303889613895, 0.208303889613895, 0.23331611185261003, 0.23331611185261003, 0.23331611185261003, 0.22822249550178353, 0.22822249550178353, 0.22822249550178353, 0.1798023899919532, 0.1798023899919532, 0.1798023899919532, 0.17102334318970136, 0.17102334318970136, 0.17102334318970136, 0.17825227069634564, 0.17825227069634564, 0.17825227069634564, 0.7566084739893064, 0.7566084739893064, 0.7566084739893064, 0.16222154908075792, 0.16222154908075792, 0.16222154908075792, 0.775371018295311, 0.775371018295311, 0.775371018295311, 0.6709982680750978, 0.6709982680750978, 0.6709982680750978, 0.20723902916174852, 0.20723902916174852, 0.20723902916174852, 0.15320035350109085, 0.15320035350109085, 0.15320035350109085, 0.20438832126892625, 0.20438832126892625, 0.20438832126892625, 0.1861732655386753, 0.1861732655386753, 0.1861732655386753, 0.19965593393440484, 0.19965593393440484, 0.19965593393440484, 0.10982990019673167, 0.10982990019673167, 0.10982990019673167, 0.08509457104649953, 0.08509457104649953, 0.08509457104649953, 0.08026822883231666, 0.08026822883231666, 0.08026822883231666]}, "mutation_prompt": null}
{"id": "f7b0a308-1146-4e3f-8da6-c165a651e13c", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n        self.c1_end = 1.4\n        self.c2_end = 1.6\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.c1 = self.c1_end + (self.c1 - self.c1_end) * (1 - progress)\n            self.c2 = self.c2_end + (self.c2 - self.c2_end) * (1 - progress)\n\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with dynamic adjustment of cognitive and social coefficients for improved exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": 0.2333301419469421, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.24.", "error": "", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6368713348574035, 0.6368713348574035, 0.6368713348574035, 0.6718337048183715, 0.6718337048183715, 0.6718337048183715, 0.6963884211842295, 0.6963884211842295, 0.6963884211842295, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01169893425095947, 0.01169893425095947, 0.01169893425095947, 0.10709620979161316, 0.10709620979161316, 0.10709620979161316, 0.10414170436156944, 0.10414170436156944, 0.10414170436156944, 0.10105181019219722, 0.10105181019219722, 0.10105181019219722, 0.0835149899234433, 0.0835149899234433, 0.0835149899234433, 0.08287862445689842, 0.08287862445689842, 0.08287862445689842, 0.05508834670190188, 0.05508834670190188, 0.05508834670190188, 0.8880313599478987, 0.8880313599478987, 0.8880313599478987, 0.8904770755727794, 0.8904770755727794, 0.8904770755727794, 0.92364799685417, 0.92364799685417, 0.92364799685417, 0.17572920760045418, 0.17572920760045418, 0.17572920760045418, 0.2203997851491224, 0.2203997851491224, 0.2203997851491224, 0.2481672369669884, 0.2481672369669884, 0.2481672369669884, 0.20976865726563187, 0.20976865726563187, 0.20976865726563187, 0.1564082192208771, 0.1564082192208771, 0.1564082192208771, 0.14033710886314543, 0.14033710886314543, 0.14033710886314543, 0.10142146105795513, 0.10142146105795513, 0.10142146105795513, 0.047222937615872485, 0.047222937615872485, 0.047222937615872485, 0.11396298337848787, 0.11396298337848787, 0.11396298337848787, 0.1250467099577134, 0.1250467099577134, 0.1250467099577134, 0.14315647230925355, 0.14315647230925355, 0.14315647230925355, 0.10433557096790114, 0.10433557096790114, 0.10433557096790114, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0176415766395287, 0.0176415766395287, 0.0176415766395287, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05712015223349176, 0.05712015223349176, 0.05712015223349176, 0.07224632385109853, 0.07224632385109853, 0.07224632385109853, 0.07820903318310468, 0.07820903318310468, 0.07820903318310468, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07081026316964578, 0.07081026316964578, 0.07081026316964578, 0.062399840469286705, 0.062399840469286705, 0.062399840469286705, 0.0893221750696428, 0.0893221750696428, 0.0893221750696428, 0.4542599110032651, 0.4542599110032651, 0.4542599110032651, 0.4742830164868147, 0.4742830164868147, 0.4742830164868147, 0.4885907559666137, 0.4885907559666137, 0.4885907559666137, 0.12367346388390366, 0.12367346388390366, 0.12367346388390366, 0.11165889121503025, 0.11165889121503025, 0.11165889121503025, 0.09244120870601114, 0.09244120870601114, 0.09244120870601114, 0.20752773684050874, 0.20752773684050874, 0.20752773684050874, 0.19729461016833016, 0.19729461016833016, 0.19729461016833016, 0.14040886352137438, 0.14040886352137438, 0.14040886352137438, 0.321569879107349, 0.321569879107349, 0.321569879107349, 0.3793562407017884, 0.3793562407017884, 0.3793562407017884, 0.3713868889489338, 0.3713868889489338, 0.3713868889489338, 0.24864305404099918, 0.24864305404099918, 0.24864305404099918, 0.21629155505468878, 0.21629155505468878, 0.21629155505468878, 0.16027906769968137, 0.16027906769968137, 0.16027906769968137, 0.20756002636363013, 0.20756002636363013, 0.20756002636363013, 0.22657498758373318, 0.22657498758373318, 0.22657498758373318, 0.2046074512371021, 0.2046074512371021, 0.2046074512371021, 0.19011975701395056, 0.19011975701395056, 0.19011975701395056, 0.21003431547882756, 0.21003431547882756, 0.21003431547882756, 0.19779998088236184, 0.19779998088236184, 0.19779998088236184, 0.7635302479552869, 0.7635302479552869, 0.7635302479552869, 0.16387320719163867, 0.16387320719163867, 0.16387320719163867, 0.764157623302467, 0.764157623302467, 0.764157623302467, 0.6711368238852842, 0.6711368238852842, 0.6711368238852842, 0.20865184658509905, 0.20865184658509905, 0.20865184658509905, 0.6811170536599361, 0.6811170536599361, 0.6811170536599361, 0.19634797882297084, 0.19634797882297084, 0.19634797882297084, 0.18609500480814745, 0.18609500480814745, 0.18609500480814745, 0.1892499636059891, 0.1892499636059891, 0.1892499636059891, 0.0849578458001281, 0.0849578458001281, 0.0849578458001281, 0.08422380766655058, 0.08422380766655058, 0.08422380766655058, 0.09494092710879865, 0.09494092710879865, 0.09494092710879865]}, "mutation_prompt": null}
{"id": "f10e7330-a59b-4a08-a646-1e3fbf29b318", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1_min, self.c1_max = 1.5, 2.0  # Variable cognitive coefficient\n        self.c2_min, self.c2_max = 1.0, 1.5  # Variable social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                c1_dynamic = self.c1_min + (self.c1_max - self.c1_min) * evaluations / self.budget\n                c2_dynamic = self.c2_min + (self.c2_max - self.c2_min) * (self.budget - evaluations) / self.budget\n                inertia = self.w * velocities[i]\n                cognitive = c1_dynamic * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = c2_dynamic * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Introducing variable cognitive and social coefficients for improved exploration and exploitation balance in PSO-SA.", "configspace": "", "generation": 22, "fitness": 0.22466809643605382, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.23.", "error": "", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.7047493381541952, 0.7047493381541952, 0.7047493381541952, 0.6623737256902922, 0.6623737256902922, 0.6623737256902922, 0.6872302205563253, 0.6872302205563253, 0.6872302205563253, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13862497670842677, 0.13862497670842677, 0.13862497670842677, 0.09747217494131455, 0.09747217494131455, 0.09747217494131455, 0.1051788489200961, 0.1051788489200961, 0.1051788489200961, 0.06844397699975069, 0.06844397699975069, 0.06844397699975069, 0.07647276759768207, 0.07647276759768207, 0.07647276759768207, 0.1232957751568785, 0.1232957751568785, 0.1232957751568785, 0.09661953940961954, 0.09661953940961954, 0.09661953940961954, 0.8958935696507142, 0.8958935696507142, 0.8958935696507142, 0.8927499073971723, 0.8927499073971723, 0.8927499073971723, 0.19518046542937906, 0.19518046542937906, 0.19518046542937906, 0.2077259755234181, 0.2077259755234181, 0.2077259755234181, 0.1399665579254008, 0.1399665579254008, 0.1399665579254008, 0.21224454187122999, 0.21224454187122999, 0.21224454187122999, 0.15724963165856132, 0.15724963165856132, 0.15724963165856132, 0.14041869234375004, 0.14041869234375004, 0.14041869234375004, 0.0920835382425077, 0.0920835382425077, 0.0920835382425077, 0.12353820290925255, 0.12353820290925255, 0.12353820290925255, 0.08589241432273154, 0.08589241432273154, 0.08589241432273154, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11106078375512496, 0.11106078375512496, 0.11106078375512496, 0.14439635236931359, 0.14439635236931359, 0.14439635236931359, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10238181360066223, 0.10238181360066223, 0.10238181360066223, 0.07173817586299724, 0.07173817586299724, 0.07173817586299724, 0.05138975978813176, 0.05138975978813176, 0.05138975978813176, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07814538408691063, 0.07814538408691063, 0.07814538408691063, 0.036961377876084445, 0.036961377876084445, 0.036961377876084445, 0.04731748885867815, 0.04731748885867815, 0.04731748885867815, 0.44161663882559343, 0.44161663882559343, 0.44161663882559343, 0.46080217960506353, 0.46080217960506353, 0.46080217960506353, 0.4607478661340574, 0.4607478661340574, 0.4607478661340574, 0.09615188391036367, 0.09615188391036367, 0.09615188391036367, 0.08044780393391993, 0.08044780393391993, 0.08044780393391993, 0.08208954789792056, 0.08208954789792056, 0.08208954789792056, 0.32725918009360044, 0.32725918009360044, 0.32725918009360044, 0.23468591883728063, 0.23468591883728063, 0.23468591883728063, 0.32280832474412025, 0.32280832474412025, 0.32280832474412025, 0.3332840245348019, 0.3332840245348019, 0.3332840245348019, 0.43213865882115654, 0.43213865882115654, 0.43213865882115654, 0.39113461103619696, 0.39113461103619696, 0.39113461103619696, 0.2791289207643284, 0.2791289207643284, 0.2791289207643284, 0.2898012520517639, 0.2898012520517639, 0.2898012520517639, 0.2085316465063204, 0.2085316465063204, 0.2085316465063204, 0.23845133914205252, 0.23845133914205252, 0.23845133914205252, 0.20794783730347932, 0.20794783730347932, 0.20794783730347932, 0.21757525721288473, 0.21757525721288473, 0.21757525721288473, 0.1692019699418208, 0.1692019699418208, 0.1692019699418208, 0.20545996577126446, 0.20545996577126446, 0.20545996577126446, 0.150701843206965, 0.150701843206965, 0.150701843206965, 0.7909008210096756, 0.7909008210096756, 0.7909008210096756, 0.16243390258611856, 0.16243390258611856, 0.16243390258611856, 0.7581148843259913, 0.7581148843259913, 0.7581148843259913, 0.6501789627858707, 0.6501789627858707, 0.6501789627858707, 0.2077013768372361, 0.2077013768372361, 0.2077013768372361, 0.5364413188582233, 0.5364413188582233, 0.5364413188582233, 0.23228439036488457, 0.23228439036488457, 0.23228439036488457, 0.21204400800592482, 0.21204400800592482, 0.21204400800592482, 0.18253513462519144, 0.18253513462519144, 0.18253513462519144, 0.10097846618498352, 0.10097846618498352, 0.10097846618498352, 0.09017108651904637, 0.09017108651904637, 0.09017108651904637, 0.07455594341117433, 0.07455594341117433, 0.07455594341117433]}, "mutation_prompt": null}
{"id": "6c01edd8-a85d-4004-a341-2f90f7d780ab", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with minor tuning in parameter values for improving convergence speed.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6731653111579229, 0.6731653111579229, 0.6731653111579229, 0.711996635129519, 0.711996635129519, 0.711996635129519, 0.7078132901593165, 0.7078132901593165, 0.7078132901593165, 0.041381141768779384, 0.041381141768779384, 0.041381141768779384, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10950771709447105, 0.10950771709447105, 0.10950771709447105, 0.10521185649440323, 0.10521185649440323, 0.10521185649440323, 0.10507361746539623, 0.10507361746539623, 0.10507361746539623, 0.07764468958329585, 0.07764468958329585, 0.07764468958329585, 0.09106825770888427, 0.09106825770888427, 0.09106825770888427, 0.11676664795008551, 0.11676664795008551, 0.11676664795008551, 0.8873949697611814, 0.8873949697611814, 0.8873949697611814, 0.8899603182064498, 0.8899603182064498, 0.8899603182064498, 0.9242514104464227, 0.9242514104464227, 0.9242514104464227, 0.15529290578465005, 0.15529290578465005, 0.15529290578465005, 0.2190096480227307, 0.2190096480227307, 0.2190096480227307, 0.10602395596155945, 0.10602395596155945, 0.10602395596155945, 0.6785064774824554, 0.6785064774824554, 0.6785064774824554, 0.1588220386151905, 0.1588220386151905, 0.1588220386151905, 0.2013731947684061, 0.2013731947684061, 0.2013731947684061, 0.11757177930520302, 0.11757177930520302, 0.11757177930520302, 0.05893689880031361, 0.05893689880031361, 0.05893689880031361, 0.1347567060589916, 0.1347567060589916, 0.1347567060589916, 0.12717657197932586, 0.12717657197932586, 0.12717657197932586, 0.13013401995367202, 0.13013401995367202, 0.13013401995367202, 0.12393529212556109, 0.12393529212556109, 0.12393529212556109, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07406251021116783, 0.07406251021116783, 0.07406251021116783, 0.06698612153091676, 0.06698612153091676, 0.06698612153091676, 0.08330193363389515, 0.08330193363389515, 0.08330193363389515, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05394537933586785, 0.05394537933586785, 0.05394537933586785, 0.06280509881780472, 0.06280509881780472, 0.06280509881780472, 0.058389177628910716, 0.058389177628910716, 0.058389177628910716, 0.4471312292357341, 0.4471312292357341, 0.4471312292357341, 0.5243508001071969, 0.5243508001071969, 0.5243508001071969, 0.46983387154224854, 0.46983387154224854, 0.46983387154224854, 0.07663158410172577, 0.07663158410172577, 0.07663158410172577, 0.10886105391076506, 0.10886105391076506, 0.10886105391076506, 0.1298840489061095, 0.1298840489061095, 0.1298840489061095, 0.1594612677021673, 0.1594612677021673, 0.1594612677021673, 0.2988572920911492, 0.2988572920911492, 0.2988572920911492, 0.24455433586052078, 0.24455433586052078, 0.24455433586052078, 0.35593401052672236, 0.35593401052672236, 0.35593401052672236, 0.41401688285636506, 0.41401688285636506, 0.41401688285636506, 0.23348098648385784, 0.23348098648385784, 0.23348098648385784, 0.25155973801749965, 0.25155973801749965, 0.25155973801749965, 0.16473215297233235, 0.16473215297233235, 0.16473215297233235, 0.2618969115729881, 0.2618969115729881, 0.2618969115729881, 0.21816177922955693, 0.21816177922955693, 0.21816177922955693, 0.19590613448642658, 0.19590613448642658, 0.19590613448642658, 0.24283886563718105, 0.24283886563718105, 0.24283886563718105, 0.18712908296437525, 0.18712908296437525, 0.18712908296437525, 0.16823242717066367, 0.16823242717066367, 0.16823242717066367, 0.19714396552649538, 0.19714396552649538, 0.19714396552649538, 0.7424295255090958, 0.7424295255090958, 0.7424295255090958, 0.16360281335132354, 0.16360281335132354, 0.16360281335132354, 0.7787233078953587, 0.7787233078953587, 0.7787233078953587, 0.6864379667833054, 0.6864379667833054, 0.6864379667833054, 0.20954767599706114, 0.20954767599706114, 0.20954767599706114, 0.5250107589216552, 0.5250107589216552, 0.5250107589216552, 0.1978655172067132, 0.1978655172067132, 0.1978655172067132, 0.16373718664922376, 0.16373718664922376, 0.16373718664922376, 0.195695680947217, 0.195695680947217, 0.195695680947217, 0.07529581943051489, 0.07529581943051489, 0.07529581943051489, 0.0742746602426343, 0.0742746602426343, 0.0742746602426343, 0.08423668137865226, 0.08423668137865226, 0.08423668137865226]}, "mutation_prompt": null}
{"id": "c184b6c7-8753-4b9e-a0d0-74775fd545a1", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85\n        self.w_min = 0.4\n        self.w_max = 0.9  # Added maximum inertia weight\n        self.c1 = 1.7\n        self.c2 = 1.3\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = np.random.uniform(self.w_min, self.w_max) * velocities[i]  # Stochastic inertia\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Introduced stochastic inertia weight adaptation for dynamic balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": 0.21758818234365407, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.23.", "error": "", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.615828965680359, 0.615828965680359, 0.615828965680359, 0.6362756139220003, 0.6362756139220003, 0.6362756139220003, 0.7175994462816052, 0.7175994462816052, 0.7175994462816052, 0.19666105539645473, 0.19666105539645473, 0.19666105539645473, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06417783273828648, 0.06417783273828648, 0.06417783273828648, 0.15130894556125463, 0.15130894556125463, 0.15130894556125463, 0.10111102460185706, 0.10111102460185706, 0.10111102460185706, 0.1328869531266148, 0.1328869531266148, 0.1328869531266148, 0.057720537638261016, 0.057720537638261016, 0.057720537638261016, 0.048174308342188166, 0.048174308342188166, 0.048174308342188166, 0.09604192822800539, 0.09604192822800539, 0.09604192822800539, 0.8523336097037995, 0.8523336097037995, 0.8523336097037995, 0.8889030047919461, 0.8889030047919461, 0.8889030047919461, 0.9241830358033654, 0.9241830358033654, 0.9241830358033654, 0.08703836603399628, 0.08703836603399628, 0.08703836603399628, 0.05292288947440704, 0.05292288947440704, 0.05292288947440704, 0.13822570904584686, 0.13822570904584686, 0.13822570904584686, 0.20729569790267255, 0.20729569790267255, 0.20729569790267255, 0.15938890711537423, 0.15938890711537423, 0.15938890711537423, 0.1617236803460379, 0.1617236803460379, 0.1617236803460379, 0.12449321955123738, 0.12449321955123738, 0.12449321955123738, 0.12733990742103174, 0.12733990742103174, 0.12733990742103174, 0.018758608343893313, 0.018758608343893313, 0.018758608343893313, 0.10971013344850655, 0.10971013344850655, 0.10971013344850655, 0.10551330941501513, 0.10551330941501513, 0.10551330941501513, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08105100373699825, 0.08105100373699825, 0.08105100373699825, 0.02429984659142337, 0.02429984659142337, 0.02429984659142337, 0.08416358071541874, 0.08416358071541874, 0.08416358071541874, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08206491862747511, 0.08206491862747511, 0.08206491862747511, 0.009276397948781101, 0.009276397948781101, 0.009276397948781101, 0.07158780333955983, 0.07158780333955983, 0.07158780333955983, 0.5003897852341187, 0.5003897852341187, 0.5003897852341187, 0.4442652618135744, 0.4442652618135744, 0.4442652618135744, 0.478693519640758, 0.478693519640758, 0.478693519640758, 0.08193191516555764, 0.08193191516555764, 0.08193191516555764, 0.11307489191299647, 0.11307489191299647, 0.11307489191299647, 0.09032619523435481, 0.09032619523435481, 0.09032619523435481, 0.2161918160880989, 0.2161918160880989, 0.2161918160880989, 0.1835705184342783, 0.1835705184342783, 0.1835705184342783, 0.2669296512057324, 0.2669296512057324, 0.2669296512057324, 0.34928698383043033, 0.34928698383043033, 0.34928698383043033, 0.2696422567846476, 0.2696422567846476, 0.2696422567846476, 0.2298166417209504, 0.2298166417209504, 0.2298166417209504, 0.17149188622770872, 0.17149188622770872, 0.17149188622770872, 0.3043786576503471, 0.3043786576503471, 0.3043786576503471, 0.2352851452919904, 0.2352851452919904, 0.2352851452919904, 0.1912539445124617, 0.1912539445124617, 0.1912539445124617, 0.23378049270017154, 0.23378049270017154, 0.23378049270017154, 0.21073629780869063, 0.21073629780869063, 0.21073629780869063, 0.18954649475613472, 0.18954649475613472, 0.18954649475613472, 0.16827770358686012, 0.16827770358686012, 0.16827770358686012, 0.1974520840392101, 0.1974520840392101, 0.1974520840392101, 0.8628512164404895, 0.8628512164404895, 0.8628512164404895, 0.11359032778439648, 0.11359032778439648, 0.11359032778439648, 0.767492329733493, 0.767492329733493, 0.767492329733493, 0.4672810053657571, 0.4672810053657571, 0.4672810053657571, 0.2092184639301563, 0.2092184639301563, 0.2092184639301563, 0.16291767060873863, 0.16291767060873863, 0.16291767060873863, 0.19498497826994676, 0.19498497826994676, 0.19498497826994676, 0.18716606213523734, 0.18716606213523734, 0.18716606213523734, 0.20065952026479283, 0.20065952026479283, 0.20065952026479283, 0.08267678505609255, 0.08267678505609255, 0.08267678505609255, 0.07765626690706762, 0.07765626690706762, 0.07765626690706762, 0.08467211773417893, 0.08467211773417893, 0.08467211773417893]}, "mutation_prompt": null}
{"id": "1873b601-3499-4fdd-8107-068d6b681c3a", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with minor tuning in parameter values for improving convergence speed.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6731653111579229, 0.6731653111579229, 0.6731653111579229, 0.711996635129519, 0.711996635129519, 0.711996635129519, 0.7078132901593165, 0.7078132901593165, 0.7078132901593165, 0.041381141768779384, 0.041381141768779384, 0.041381141768779384, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10950771709447105, 0.10950771709447105, 0.10950771709447105, 0.10521185649440323, 0.10521185649440323, 0.10521185649440323, 0.10507361746539623, 0.10507361746539623, 0.10507361746539623, 0.07764468958329585, 0.07764468958329585, 0.07764468958329585, 0.09106825770888427, 0.09106825770888427, 0.09106825770888427, 0.11676664795008551, 0.11676664795008551, 0.11676664795008551, 0.8873949697611814, 0.8873949697611814, 0.8873949697611814, 0.8899603182064498, 0.8899603182064498, 0.8899603182064498, 0.9242514104464227, 0.9242514104464227, 0.9242514104464227, 0.15529290578465005, 0.15529290578465005, 0.15529290578465005, 0.2190096480227307, 0.2190096480227307, 0.2190096480227307, 0.10602395596155945, 0.10602395596155945, 0.10602395596155945, 0.6785064774824554, 0.6785064774824554, 0.6785064774824554, 0.1588220386151905, 0.1588220386151905, 0.1588220386151905, 0.2013731947684061, 0.2013731947684061, 0.2013731947684061, 0.11757177930520302, 0.11757177930520302, 0.11757177930520302, 0.05893689880031361, 0.05893689880031361, 0.05893689880031361, 0.1347567060589916, 0.1347567060589916, 0.1347567060589916, 0.12717657197932586, 0.12717657197932586, 0.12717657197932586, 0.13013401995367202, 0.13013401995367202, 0.13013401995367202, 0.12393529212556109, 0.12393529212556109, 0.12393529212556109, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07406251021116783, 0.07406251021116783, 0.07406251021116783, 0.06698612153091676, 0.06698612153091676, 0.06698612153091676, 0.08330193363389515, 0.08330193363389515, 0.08330193363389515, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05394537933586785, 0.05394537933586785, 0.05394537933586785, 0.06280509881780472, 0.06280509881780472, 0.06280509881780472, 0.058389177628910716, 0.058389177628910716, 0.058389177628910716, 0.4471312292357341, 0.4471312292357341, 0.4471312292357341, 0.5243508001071969, 0.5243508001071969, 0.5243508001071969, 0.46983387154224854, 0.46983387154224854, 0.46983387154224854, 0.07663158410172577, 0.07663158410172577, 0.07663158410172577, 0.10886105391076506, 0.10886105391076506, 0.10886105391076506, 0.1298840489061095, 0.1298840489061095, 0.1298840489061095, 0.1594612677021673, 0.1594612677021673, 0.1594612677021673, 0.2988572920911492, 0.2988572920911492, 0.2988572920911492, 0.24455433586052078, 0.24455433586052078, 0.24455433586052078, 0.35593401052672236, 0.35593401052672236, 0.35593401052672236, 0.41401688285636506, 0.41401688285636506, 0.41401688285636506, 0.23348098648385784, 0.23348098648385784, 0.23348098648385784, 0.25155973801749965, 0.25155973801749965, 0.25155973801749965, 0.16473215297233235, 0.16473215297233235, 0.16473215297233235, 0.2618969115729881, 0.2618969115729881, 0.2618969115729881, 0.21816177922955693, 0.21816177922955693, 0.21816177922955693, 0.19590613448642658, 0.19590613448642658, 0.19590613448642658, 0.24283886563718105, 0.24283886563718105, 0.24283886563718105, 0.18712908296437525, 0.18712908296437525, 0.18712908296437525, 0.16823242717066367, 0.16823242717066367, 0.16823242717066367, 0.19714396552649538, 0.19714396552649538, 0.19714396552649538, 0.7424295255090958, 0.7424295255090958, 0.7424295255090958, 0.16360281335132354, 0.16360281335132354, 0.16360281335132354, 0.7787233078953587, 0.7787233078953587, 0.7787233078953587, 0.6864379667833054, 0.6864379667833054, 0.6864379667833054, 0.20954767599706114, 0.20954767599706114, 0.20954767599706114, 0.5250107589216552, 0.5250107589216552, 0.5250107589216552, 0.1978655172067132, 0.1978655172067132, 0.1978655172067132, 0.16373718664922376, 0.16373718664922376, 0.16373718664922376, 0.195695680947217, 0.195695680947217, 0.195695680947217, 0.07529581943051489, 0.07529581943051489, 0.07529581943051489, 0.0742746602426343, 0.0742746602426343, 0.0742746602426343, 0.08423668137865226, 0.08423668137865226, 0.08423668137865226]}, "mutation_prompt": null}
{"id": "a009cbd0-b3fe-4644-bdd6-4858ccf2b831", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2 = 1.3\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n            \n            # Dynamically adjust velocity bounds based on convergence\n            vel_range_adjustment = 1 - (temperature / self.temp_init)\n            self.vel_bounds = (-1.0 * vel_range_adjustment, 1.0 * vel_range_adjustment)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Hybrid PSO-SA optimizer with dynamically adjusted velocity bounds for improved exploration and exploitation balance.", "configspace": "", "generation": 26, "fitness": 0.20665151281991687, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.22.", "error": "", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.699582672361754, 0.699582672361754, 0.699582672361754, 0.6676254857410052, 0.6676254857410052, 0.6676254857410052, 0.6921983111797638, 0.6921983111797638, 0.6921983111797638, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11075457047825621, 0.11075457047825621, 0.11075457047825621, 0.08398529465536864, 0.08398529465536864, 0.08398529465536864, 0.07722115947239239, 0.07722115947239239, 0.07722115947239239, 0.05401872311360434, 0.05401872311360434, 0.05401872311360434, 0.045989097779539745, 0.045989097779539745, 0.045989097779539745, 0.040191334557073466, 0.040191334557073466, 0.040191334557073466, 0.7551338587200715, 0.7551338587200715, 0.7551338587200715, 0.7774440642005027, 0.7774440642005027, 0.7774440642005027, 0.7408324406134774, 0.7408324406134774, 0.7408324406134774, 0.08873425005151403, 0.08873425005151403, 0.08873425005151403, 0.15064984168109918, 0.15064984168109918, 0.15064984168109918, 0.18070533681027556, 0.18070533681027556, 0.18070533681027556, 0.12531471674696004, 0.12531471674696004, 0.12531471674696004, 0.1523276257926136, 0.1523276257926136, 0.1523276257926136, 0.10899861565964841, 0.10899861565964841, 0.10899861565964841, 0.12782198206018036, 0.12782198206018036, 0.12782198206018036, 0.04000590340661003, 0.04000590340661003, 0.04000590340661003, 0.1056205838452603, 0.1056205838452603, 0.1056205838452603, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10709014548539286, 0.10709014548539286, 0.10709014548539286, 0.1231455946190303, 0.1231455946190303, 0.1231455946190303, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05275387279418953, 0.05275387279418953, 0.05275387279418953, 0.052013943833185694, 0.052013943833185694, 0.052013943833185694, 0.04695885019956736, 0.04695885019956736, 0.04695885019956736, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0716673737482959, 0.0716673737482959, 0.0716673737482959, 0.028313314342092943, 0.028313314342092943, 0.028313314342092943, 0.0497737242230234, 0.0497737242230234, 0.0497737242230234, 0.4688914161807253, 0.4688914161807253, 0.4688914161807253, 0.4838411387381838, 0.4838411387381838, 0.4838411387381838, 0.4827172549443842, 0.4827172549443842, 0.4827172549443842, 0.09835667597017705, 0.09835667597017705, 0.09835667597017705, 0.0975810131187822, 0.0975810131187822, 0.0975810131187822, 0.05315670631225489, 0.05315670631225489, 0.05315670631225489, 0.17394232518018637, 0.17394232518018637, 0.17394232518018637, 0.11084777357644982, 0.11084777357644982, 0.11084777357644982, 0.18479233473646373, 0.18479233473646373, 0.18479233473646373, 0.3466589982203049, 0.3466589982203049, 0.3466589982203049, 0.35386578779131406, 0.35386578779131406, 0.35386578779131406, 0.36106228358114023, 0.36106228358114023, 0.36106228358114023, 0.23395482757963826, 0.23395482757963826, 0.23395482757963826, 0.17513003783477543, 0.17513003783477543, 0.17513003783477543, 0.1642493616366204, 0.1642493616366204, 0.1642493616366204, 0.20942755019471082, 0.20942755019471082, 0.20942755019471082, 0.19909704807592632, 0.19909704807592632, 0.19909704807592632, 0.20906136379053708, 0.20906136379053708, 0.20906136379053708, 0.17796097852981496, 0.17796097852981496, 0.17796097852981496, 0.1732947403435453, 0.1732947403435453, 0.1732947403435453, 0.1897122385173684, 0.1897122385173684, 0.1897122385173684, 0.7443764170962703, 0.7443764170962703, 0.7443764170962703, 0.157936279557373, 0.157936279557373, 0.157936279557373, 0.7019322778913251, 0.7019322778913251, 0.7019322778913251, 0.44570521807575614, 0.44570521807575614, 0.44570521807575614, 0.2052152985707275, 0.2052152985707275, 0.2052152985707275, 0.5101917852730035, 0.5101917852730035, 0.5101917852730035, 0.17036735532356584, 0.17036735532356584, 0.17036735532356584, 0.19977442518354727, 0.19977442518354727, 0.19977442518354727, 0.1720707594442421, 0.1720707594442421, 0.1720707594442421, 0.10315674045156742, 0.10315674045156742, 0.10315674045156742, 0.07651545762810308, 0.07651545762810308, 0.07651545762810308, 0.08619236551348242, 0.08619236551348242, 0.08619236551348242]}, "mutation_prompt": null}
{"id": "d1798397-5d7c-4b16-b817-7bc46bbc05ee", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer_V2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n        self.elite_solution = None\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            if self.elite_solution is None or self.global_best_val < func(self.elite_solution):\n                self.elite_solution = np.copy(self.global_best_pos)\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * (0.99 + 0.01 * np.random.rand()))  # Dynamic inertia adjustment\n\n        final_best_pos = min(self.global_best_pos, self.elite_solution, key=func)\n        return final_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer_V2", "description": "Integrate dynamic inertia weight adjustment and an elite solution retention strategy for improved convergence.", "configspace": "", "generation": 27, "fitness": 0.21814039311754174, "feedback": "The algorithm PSO_SA_Optimizer_V2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.22.", "error": "", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.5949896481834582, 0.5949896481834582, 0.5949896481834582, 0.5759037284666922, 0.5759037284666922, 0.5759037284666922, 0.5472752338233774, 0.5472752338233774, 0.5472752338233774, 0.012092161154180991, 0.012092161154180991, 0.012092161154180991, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.004376443208409353, 0.004376443208409353, 0.004376443208409353, 0.11309310625390989, 0.11309310625390989, 0.11309310625390989, 0.10875378152570281, 0.10875378152570281, 0.10875378152570281, 0.10992988826742256, 0.10992988826742256, 0.10992988826742256, 0.08408549032506163, 0.08408549032506163, 0.08408549032506163, 0.102590034198351, 0.102590034198351, 0.102590034198351, 0.07721199339326579, 0.07721199339326579, 0.07721199339326579, 0.8995720705063163, 0.8995720705063163, 0.8995720705063163, 0.8884220409412006, 0.8884220409412006, 0.8884220409412006, 0.8583278469235511, 0.8583278469235511, 0.8583278469235511, 0.18024125462316365, 0.18024125462316365, 0.18024125462316365, 0.23106144531466988, 0.23106144531466988, 0.23106144531466988, 0.14244120504815017, 0.14244120504815017, 0.14244120504815017, 0.19611774647696412, 0.19611774647696412, 0.19611774647696412, 0.2114305726803274, 0.2114305726803274, 0.2114305726803274, 0.3399878878134206, 0.3399878878134206, 0.3399878878134206, 0.12300230758254016, 0.12300230758254016, 0.12300230758254016, 0.10794973810034969, 0.10794973810034969, 0.10794973810034969, 0.15171247730319848, 0.15171247730319848, 0.15171247730319848, 0.07448622118287818, 0.07448622118287818, 0.07448622118287818, 0.13461560058344169, 0.13461560058344169, 0.13461560058344169, 0.12543197354032543, 0.12543197354032543, 0.12543197354032543, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05897649580396247, 0.05897649580396247, 0.05897649580396247, 0.026211174019383554, 0.026211174019383554, 0.026211174019383554, 0.09471398610298443, 0.09471398610298443, 0.09471398610298443, 0.0054255005558491165, 0.0054255005558491165, 0.0054255005558491165, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.042385086850392883, 0.042385086850392883, 0.042385086850392883, 0.009163266706509021, 0.009163266706509021, 0.009163266706509021, 0.03669429914923161, 0.03669429914923161, 0.03669429914923161, 0.4529657591005075, 0.4529657591005075, 0.4529657591005075, 0.4289625761377521, 0.4289625761377521, 0.4289625761377521, 0.440553334528232, 0.440553334528232, 0.440553334528232, 0.12073592193352656, 0.12073592193352656, 0.12073592193352656, 0.09095102731375704, 0.09095102731375704, 0.09095102731375704, 0.10526417604599925, 0.10526417604599925, 0.10526417604599925, 0.16621816328069106, 0.16621816328069106, 0.16621816328069106, 0.1891655565377579, 0.1891655565377579, 0.1891655565377579, 0.16243633119722622, 0.16243633119722622, 0.16243633119722622, 0.3202018635099384, 0.3202018635099384, 0.3202018635099384, 0.2447469341778321, 0.2447469341778321, 0.2447469341778321, 0.34579987904536913, 0.34579987904536913, 0.34579987904536913, 0.20214485265463122, 0.20214485265463122, 0.20214485265463122, 0.2625667306984171, 0.2625667306984171, 0.2625667306984171, 0.2058352503457037, 0.2058352503457037, 0.2058352503457037, 0.1975584520236644, 0.1975584520236644, 0.1975584520236644, 0.19893160205298277, 0.19893160205298277, 0.19893160205298277, 0.20358323140634138, 0.20358323140634138, 0.20358323140634138, 0.14656522325934251, 0.14656522325934251, 0.14656522325934251, 0.17684844697906232, 0.17684844697906232, 0.17684844697906232, 0.18143920308519235, 0.18143920308519235, 0.18143920308519235, 0.6719796322439935, 0.6719796322439935, 0.6719796322439935, 0.1633072707164005, 0.1633072707164005, 0.1633072707164005, 0.7364635002268337, 0.7364635002268337, 0.7364635002268337, 0.5715120316289992, 0.5715120316289992, 0.5715120316289992, 0.2068138102623921, 0.2068138102623921, 0.2068138102623921, 0.42537456054251976, 0.42537456054251976, 0.42537456054251976, 0.19150758368115417, 0.19150758368115417, 0.19150758368115417, 0.16888910382363265, 0.16888910382363265, 0.16888910382363265, 0.17893130337128582, 0.17893130337128582, 0.17893130337128582, 0.1009991708089456, 0.1009991708089456, 0.1009991708089456, 0.08721712805680804, 0.08721712805680804, 0.08721712805680804, 0.09036698717746838, 0.09036698717746838, 0.09036698717746838]}, "mutation_prompt": null}
{"id": "874cf449-2a8d-447e-a1b0-cbf5b27dfaf5", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with minor tuning in parameter values for improving convergence speed.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6731653111579229, 0.6731653111579229, 0.6731653111579229, 0.711996635129519, 0.711996635129519, 0.711996635129519, 0.7078132901593165, 0.7078132901593165, 0.7078132901593165, 0.041381141768779384, 0.041381141768779384, 0.041381141768779384, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10950771709447105, 0.10950771709447105, 0.10950771709447105, 0.10521185649440323, 0.10521185649440323, 0.10521185649440323, 0.10507361746539623, 0.10507361746539623, 0.10507361746539623, 0.07764468958329585, 0.07764468958329585, 0.07764468958329585, 0.09106825770888427, 0.09106825770888427, 0.09106825770888427, 0.11676664795008551, 0.11676664795008551, 0.11676664795008551, 0.8873949697611814, 0.8873949697611814, 0.8873949697611814, 0.8899603182064498, 0.8899603182064498, 0.8899603182064498, 0.9242514104464227, 0.9242514104464227, 0.9242514104464227, 0.15529290578465005, 0.15529290578465005, 0.15529290578465005, 0.2190096480227307, 0.2190096480227307, 0.2190096480227307, 0.10602395596155945, 0.10602395596155945, 0.10602395596155945, 0.6785064774824554, 0.6785064774824554, 0.6785064774824554, 0.1588220386151905, 0.1588220386151905, 0.1588220386151905, 0.2013731947684061, 0.2013731947684061, 0.2013731947684061, 0.11757177930520302, 0.11757177930520302, 0.11757177930520302, 0.05893689880031361, 0.05893689880031361, 0.05893689880031361, 0.1347567060589916, 0.1347567060589916, 0.1347567060589916, 0.12717657197932586, 0.12717657197932586, 0.12717657197932586, 0.13013401995367202, 0.13013401995367202, 0.13013401995367202, 0.12393529212556109, 0.12393529212556109, 0.12393529212556109, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07406251021116783, 0.07406251021116783, 0.07406251021116783, 0.06698612153091676, 0.06698612153091676, 0.06698612153091676, 0.08330193363389515, 0.08330193363389515, 0.08330193363389515, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05394537933586785, 0.05394537933586785, 0.05394537933586785, 0.06280509881780472, 0.06280509881780472, 0.06280509881780472, 0.058389177628910716, 0.058389177628910716, 0.058389177628910716, 0.4471312292357341, 0.4471312292357341, 0.4471312292357341, 0.5243508001071969, 0.5243508001071969, 0.5243508001071969, 0.46983387154224854, 0.46983387154224854, 0.46983387154224854, 0.07663158410172577, 0.07663158410172577, 0.07663158410172577, 0.10886105391076506, 0.10886105391076506, 0.10886105391076506, 0.1298840489061095, 0.1298840489061095, 0.1298840489061095, 0.1594612677021673, 0.1594612677021673, 0.1594612677021673, 0.2988572920911492, 0.2988572920911492, 0.2988572920911492, 0.24455433586052078, 0.24455433586052078, 0.24455433586052078, 0.35593401052672236, 0.35593401052672236, 0.35593401052672236, 0.41401688285636506, 0.41401688285636506, 0.41401688285636506, 0.23348098648385784, 0.23348098648385784, 0.23348098648385784, 0.25155973801749965, 0.25155973801749965, 0.25155973801749965, 0.16473215297233235, 0.16473215297233235, 0.16473215297233235, 0.2618969115729881, 0.2618969115729881, 0.2618969115729881, 0.21816177922955693, 0.21816177922955693, 0.21816177922955693, 0.19590613448642658, 0.19590613448642658, 0.19590613448642658, 0.24283886563718105, 0.24283886563718105, 0.24283886563718105, 0.18712908296437525, 0.18712908296437525, 0.18712908296437525, 0.16823242717066367, 0.16823242717066367, 0.16823242717066367, 0.19714396552649538, 0.19714396552649538, 0.19714396552649538, 0.7424295255090958, 0.7424295255090958, 0.7424295255090958, 0.16360281335132354, 0.16360281335132354, 0.16360281335132354, 0.7787233078953587, 0.7787233078953587, 0.7787233078953587, 0.6864379667833054, 0.6864379667833054, 0.6864379667833054, 0.20954767599706114, 0.20954767599706114, 0.20954767599706114, 0.5250107589216552, 0.5250107589216552, 0.5250107589216552, 0.1978655172067132, 0.1978655172067132, 0.1978655172067132, 0.16373718664922376, 0.16373718664922376, 0.16373718664922376, 0.195695680947217, 0.195695680947217, 0.195695680947217, 0.07529581943051489, 0.07529581943051489, 0.07529581943051489, 0.0742746602426343, 0.0742746602426343, 0.0742746602426343, 0.08423668137865226, 0.08423668137865226, 0.08423668137865226]}, "mutation_prompt": null}
{"id": "221e4cdf-347c-4f2d-bde4-f80d11b0a256", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with minor tuning in parameter values for improving convergence speed.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6731653111579229, 0.6731653111579229, 0.6731653111579229, 0.711996635129519, 0.711996635129519, 0.711996635129519, 0.7078132901593165, 0.7078132901593165, 0.7078132901593165, 0.041381141768779384, 0.041381141768779384, 0.041381141768779384, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10950771709447105, 0.10950771709447105, 0.10950771709447105, 0.10521185649440323, 0.10521185649440323, 0.10521185649440323, 0.10507361746539623, 0.10507361746539623, 0.10507361746539623, 0.07764468958329585, 0.07764468958329585, 0.07764468958329585, 0.09106825770888427, 0.09106825770888427, 0.09106825770888427, 0.11676664795008551, 0.11676664795008551, 0.11676664795008551, 0.8873949697611814, 0.8873949697611814, 0.8873949697611814, 0.8899603182064498, 0.8899603182064498, 0.8899603182064498, 0.9242514104464227, 0.9242514104464227, 0.9242514104464227, 0.15529290578465005, 0.15529290578465005, 0.15529290578465005, 0.2190096480227307, 0.2190096480227307, 0.2190096480227307, 0.10602395596155945, 0.10602395596155945, 0.10602395596155945, 0.6785064774824554, 0.6785064774824554, 0.6785064774824554, 0.1588220386151905, 0.1588220386151905, 0.1588220386151905, 0.2013731947684061, 0.2013731947684061, 0.2013731947684061, 0.11757177930520302, 0.11757177930520302, 0.11757177930520302, 0.05893689880031361, 0.05893689880031361, 0.05893689880031361, 0.1347567060589916, 0.1347567060589916, 0.1347567060589916, 0.12717657197932586, 0.12717657197932586, 0.12717657197932586, 0.13013401995367202, 0.13013401995367202, 0.13013401995367202, 0.12393529212556109, 0.12393529212556109, 0.12393529212556109, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07406251021116783, 0.07406251021116783, 0.07406251021116783, 0.06698612153091676, 0.06698612153091676, 0.06698612153091676, 0.08330193363389515, 0.08330193363389515, 0.08330193363389515, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05394537933586785, 0.05394537933586785, 0.05394537933586785, 0.06280509881780472, 0.06280509881780472, 0.06280509881780472, 0.058389177628910716, 0.058389177628910716, 0.058389177628910716, 0.4471312292357341, 0.4471312292357341, 0.4471312292357341, 0.5243508001071969, 0.5243508001071969, 0.5243508001071969, 0.46983387154224854, 0.46983387154224854, 0.46983387154224854, 0.07663158410172577, 0.07663158410172577, 0.07663158410172577, 0.10886105391076506, 0.10886105391076506, 0.10886105391076506, 0.1298840489061095, 0.1298840489061095, 0.1298840489061095, 0.1594612677021673, 0.1594612677021673, 0.1594612677021673, 0.2988572920911492, 0.2988572920911492, 0.2988572920911492, 0.24455433586052078, 0.24455433586052078, 0.24455433586052078, 0.35593401052672236, 0.35593401052672236, 0.35593401052672236, 0.41401688285636506, 0.41401688285636506, 0.41401688285636506, 0.23348098648385784, 0.23348098648385784, 0.23348098648385784, 0.25155973801749965, 0.25155973801749965, 0.25155973801749965, 0.16473215297233235, 0.16473215297233235, 0.16473215297233235, 0.2618969115729881, 0.2618969115729881, 0.2618969115729881, 0.21816177922955693, 0.21816177922955693, 0.21816177922955693, 0.19590613448642658, 0.19590613448642658, 0.19590613448642658, 0.24283886563718105, 0.24283886563718105, 0.24283886563718105, 0.18712908296437525, 0.18712908296437525, 0.18712908296437525, 0.16823242717066367, 0.16823242717066367, 0.16823242717066367, 0.19714396552649538, 0.19714396552649538, 0.19714396552649538, 0.7424295255090958, 0.7424295255090958, 0.7424295255090958, 0.16360281335132354, 0.16360281335132354, 0.16360281335132354, 0.7787233078953587, 0.7787233078953587, 0.7787233078953587, 0.6864379667833054, 0.6864379667833054, 0.6864379667833054, 0.20954767599706114, 0.20954767599706114, 0.20954767599706114, 0.5250107589216552, 0.5250107589216552, 0.5250107589216552, 0.1978655172067132, 0.1978655172067132, 0.1978655172067132, 0.16373718664922376, 0.16373718664922376, 0.16373718664922376, 0.195695680947217, 0.195695680947217, 0.195695680947217, 0.07529581943051489, 0.07529581943051489, 0.07529581943051489, 0.0742746602426343, 0.0742746602426343, 0.0742746602426343, 0.08423668137865226, 0.08423668137865226, 0.08423668137865226]}, "mutation_prompt": null}
{"id": "4f2de121-40a6-4803-96f6-3cb0db06090e", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with minor tuning in parameter values for improving convergence speed.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6731653111579229, 0.6731653111579229, 0.6731653111579229, 0.711996635129519, 0.711996635129519, 0.711996635129519, 0.7078132901593165, 0.7078132901593165, 0.7078132901593165, 0.041381141768779384, 0.041381141768779384, 0.041381141768779384, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10950771709447105, 0.10950771709447105, 0.10950771709447105, 0.10521185649440323, 0.10521185649440323, 0.10521185649440323, 0.10507361746539623, 0.10507361746539623, 0.10507361746539623, 0.07764468958329585, 0.07764468958329585, 0.07764468958329585, 0.09106825770888427, 0.09106825770888427, 0.09106825770888427, 0.11676664795008551, 0.11676664795008551, 0.11676664795008551, 0.8873949697611814, 0.8873949697611814, 0.8873949697611814, 0.8899603182064498, 0.8899603182064498, 0.8899603182064498, 0.9242514104464227, 0.9242514104464227, 0.9242514104464227, 0.15529290578465005, 0.15529290578465005, 0.15529290578465005, 0.2190096480227307, 0.2190096480227307, 0.2190096480227307, 0.10602395596155945, 0.10602395596155945, 0.10602395596155945, 0.6785064774824554, 0.6785064774824554, 0.6785064774824554, 0.1588220386151905, 0.1588220386151905, 0.1588220386151905, 0.2013731947684061, 0.2013731947684061, 0.2013731947684061, 0.11757177930520302, 0.11757177930520302, 0.11757177930520302, 0.05893689880031361, 0.05893689880031361, 0.05893689880031361, 0.1347567060589916, 0.1347567060589916, 0.1347567060589916, 0.12717657197932586, 0.12717657197932586, 0.12717657197932586, 0.13013401995367202, 0.13013401995367202, 0.13013401995367202, 0.12393529212556109, 0.12393529212556109, 0.12393529212556109, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07406251021116783, 0.07406251021116783, 0.07406251021116783, 0.06698612153091676, 0.06698612153091676, 0.06698612153091676, 0.08330193363389515, 0.08330193363389515, 0.08330193363389515, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05394537933586785, 0.05394537933586785, 0.05394537933586785, 0.06280509881780472, 0.06280509881780472, 0.06280509881780472, 0.058389177628910716, 0.058389177628910716, 0.058389177628910716, 0.4471312292357341, 0.4471312292357341, 0.4471312292357341, 0.5243508001071969, 0.5243508001071969, 0.5243508001071969, 0.46983387154224854, 0.46983387154224854, 0.46983387154224854, 0.07663158410172577, 0.07663158410172577, 0.07663158410172577, 0.10886105391076506, 0.10886105391076506, 0.10886105391076506, 0.1298840489061095, 0.1298840489061095, 0.1298840489061095, 0.1594612677021673, 0.1594612677021673, 0.1594612677021673, 0.2988572920911492, 0.2988572920911492, 0.2988572920911492, 0.24455433586052078, 0.24455433586052078, 0.24455433586052078, 0.35593401052672236, 0.35593401052672236, 0.35593401052672236, 0.41401688285636506, 0.41401688285636506, 0.41401688285636506, 0.23348098648385784, 0.23348098648385784, 0.23348098648385784, 0.25155973801749965, 0.25155973801749965, 0.25155973801749965, 0.16473215297233235, 0.16473215297233235, 0.16473215297233235, 0.2618969115729881, 0.2618969115729881, 0.2618969115729881, 0.21816177922955693, 0.21816177922955693, 0.21816177922955693, 0.19590613448642658, 0.19590613448642658, 0.19590613448642658, 0.24283886563718105, 0.24283886563718105, 0.24283886563718105, 0.18712908296437525, 0.18712908296437525, 0.18712908296437525, 0.16823242717066367, 0.16823242717066367, 0.16823242717066367, 0.19714396552649538, 0.19714396552649538, 0.19714396552649538, 0.7424295255090958, 0.7424295255090958, 0.7424295255090958, 0.16360281335132354, 0.16360281335132354, 0.16360281335132354, 0.7787233078953587, 0.7787233078953587, 0.7787233078953587, 0.6864379667833054, 0.6864379667833054, 0.6864379667833054, 0.20954767599706114, 0.20954767599706114, 0.20954767599706114, 0.5250107589216552, 0.5250107589216552, 0.5250107589216552, 0.1978655172067132, 0.1978655172067132, 0.1978655172067132, 0.16373718664922376, 0.16373718664922376, 0.16373718664922376, 0.195695680947217, 0.195695680947217, 0.195695680947217, 0.07529581943051489, 0.07529581943051489, 0.07529581943051489, 0.0742746602426343, 0.0742746602426343, 0.0742746602426343, 0.08423668137865226, 0.08423668137865226, 0.08423668137865226]}, "mutation_prompt": null}
{"id": "4e473c9c-afc6-49e4-bf31-cdaa77a5a75a", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n            # Dynamic velocity boundary adjustment\n            self.vel_bounds = (-abs(self.global_best_val)/100, abs(self.global_best_val)/100)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Introduced a dynamic velocity boundary adjustment and fine-tuned inertia weight decay for enhanced convergence.", "configspace": "", "generation": 31, "fitness": 0.20040352444389276, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.21.", "error": "", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6811986163053612, 0.6811986163053612, 0.6811986163053612, 0.6510269882814397, 0.6510269882814397, 0.6510269882814397, 0.6568035665696723, 0.6568035665696723, 0.6568035665696723, 0.0038638531978525403, 0.0038638531978525403, 0.0038638531978525403, 0.012181383439920701, 0.012181383439920701, 0.012181383439920701, 0.0007423767010410476, 0.0007423767010410476, 0.0007423767010410476, 0.08305372545403411, 0.08305372545403411, 0.08305372545403411, 0.11711276467376741, 0.11711276467376741, 0.11711276467376741, 0.09275782912060893, 0.09275782912060893, 0.09275782912060893, 0.05212239306055122, 0.05212239306055122, 0.05212239306055122, 0.08916120855753562, 0.08916120855753562, 0.08916120855753562, 0.11710181464819203, 0.11710181464819203, 0.11710181464819203, 0.07723818747449929, 0.07723818747449929, 0.07723818747449929, 0.9634046985210442, 0.9634046985210442, 0.9634046985210442, 0.9162463778946996, 0.9162463778946996, 0.9162463778946996, 0.12232918485122113, 0.12232918485122113, 0.12232918485122113, 0.21627782250298677, 0.21627782250298677, 0.21627782250298677, 0.16110025666626338, 0.16110025666626338, 0.16110025666626338, 0.21222339811203994, 0.21222339811203994, 0.21222339811203994, 0.20492582645817758, 0.20492582645817758, 0.20492582645817758, 0.11456217913422917, 0.11456217913422917, 0.11456217913422917, 0.10370743065735766, 0.10370743065735766, 0.10370743065735766, 0.1696295996278292, 0.1696295996278292, 0.1696295996278292, 0.11924526916765643, 0.11924526916765643, 0.11924526916765643, 0.14915723393473368, 0.14915723393473368, 0.14915723393473368, 0.11817229255226869, 0.11817229255226869, 0.11817229255226869, 0.17972868813024667, 0.17972868813024667, 0.17972868813024667, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05259118537494778, 0.05259118537494778, 0.05259118537494778, 0.01642134523735872, 0.01642134523735872, 0.01642134523735872, 0.07569082000033245, 0.07569082000033245, 0.07569082000033245, 0.03977783379346289, 0.03977783379346289, 0.03977783379346289, 0.0006117398686775743, 0.0006117398686775743, 0.0006117398686775743, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12910276479805893, 0.12910276479805893, 0.12910276479805893, 0.054178160522064034, 0.054178160522064034, 0.054178160522064034, 0.035530429406233965, 0.035530429406233965, 0.035530429406233965, 0.4665609088923892, 0.4665609088923892, 0.4665609088923892, 0.4522840928405377, 0.4522840928405377, 0.4522840928405377, 0.4740244417607453, 0.4740244417607453, 0.4740244417607453, 0.12948541044215234, 0.12948541044215234, 0.12948541044215234, 0.09151531718971673, 0.09151531718971673, 0.09151531718971673, 0.05364892518937381, 0.05364892518937381, 0.05364892518937381, 0.18164304837505862, 0.18164304837505862, 0.18164304837505862, 0.1731737896588691, 0.1731737896588691, 0.1731737896588691, 0.16183446456671502, 0.16183446456671502, 0.16183446456671502, 0.21666931133478073, 0.21666931133478073, 0.21666931133478073, 0.2933816008565735, 0.2933816008565735, 0.2933816008565735, 0.28387509135657096, 0.28387509135657096, 0.28387509135657096, 0.09011405860993493, 0.09011405860993493, 0.09011405860993493, 0.15401388090853219, 0.15401388090853219, 0.15401388090853219, 0.1339655781879232, 0.1339655781879232, 0.1339655781879232, 0.22624018195163598, 0.22624018195163598, 0.22624018195163598, 0.2806069372675831, 0.2806069372675831, 0.2806069372675831, 0.2072225671175797, 0.2072225671175797, 0.2072225671175797, 0.18103351622018593, 0.18103351622018593, 0.18103351622018593, 0.193216129819352, 0.193216129819352, 0.193216129819352, 0.22139609005066807, 0.22139609005066807, 0.22139609005066807, 0.8023348780879205, 0.8023348780879205, 0.8023348780879205, 0.13334234789673372, 0.13334234789673372, 0.13334234789673372, 0.7050182126326938, 0.7050182126326938, 0.7050182126326938, 0.14955703381359764, 0.14955703381359764, 0.14955703381359764, 0.2268456545745715, 0.2268456545745715, 0.2268456545745715, 0.15300860707269526, 0.15300860707269526, 0.15300860707269526, 0.17508308101321213, 0.17508308101321213, 0.17508308101321213, 0.19118317386777461, 0.19118317386777461, 0.19118317386777461, 0.16654630897187928, 0.16654630897187928, 0.16654630897187928, 0.0843249199715379, 0.0843249199715379, 0.0843249199715379, 0.09042811803414674, 0.09042811803414674, 0.09042811803414674, 0.09609683673027125, 0.09609683673027125, 0.09609683673027125]}, "mutation_prompt": null}
{"id": "25ef8e80-cce3-4f93-ba2e-a976bec3e883", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2 = 1.3\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                if np.any(proposed_position < self.bounds[0]) or np.any(proposed_position > self.bounds[1]):\n                    velocities[i] = -velocities[i]  # Mirror effect for boundary crossing\n\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with velocity mirror effect for boundary crossing to improve convergence.", "configspace": "", "generation": 32, "fitness": 0.2177984810590205, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.20.", "error": "", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6731653111579229, 0.6731653111579229, 0.6731653111579229, 0.6905851781687353, 0.6905851781687353, 0.6905851781687353, 0.6777392376457116, 0.6777392376457116, 0.6777392376457116, 0.13412068328985138, 0.13412068328985138, 0.13412068328985138, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00010135042069470135, 0.00010135042069470135, 0.00010135042069470135, 0.3387964941238415, 0.3387964941238415, 0.3387964941238415, 0.0873921965522575, 0.0873921965522575, 0.0873921965522575, 0.10507361746539623, 0.10507361746539623, 0.10507361746539623, 0.07764468958329585, 0.07764468958329585, 0.07764468958329585, 0.09106825770888427, 0.09106825770888427, 0.09106825770888427, 0.09542697015778412, 0.09542697015778412, 0.09542697015778412, 0.34777606329399513, 0.34777606329399513, 0.34777606329399513, 0.5667489588120649, 0.5667489588120649, 0.5667489588120649, 0.4163507896000237, 0.4163507896000237, 0.4163507896000237, 0.15529290578465005, 0.15529290578465005, 0.15529290578465005, 0.318182289304907, 0.318182289304907, 0.318182289304907, 0.1018763021549024, 0.1018763021549024, 0.1018763021549024, 0.21488832294417903, 0.21488832294417903, 0.21488832294417903, 0.201479971489413, 0.201479971489413, 0.201479971489413, 0.16814156631427435, 0.16814156631427435, 0.16814156631427435, 0.11757177930520302, 0.11757177930520302, 0.11757177930520302, 0.12433187449235195, 0.12433187449235195, 0.12433187449235195, 0.1347567060589916, 0.1347567060589916, 0.1347567060589916, 0.12717657197932586, 0.12717657197932586, 0.12717657197932586, 0.13013401995367202, 0.13013401995367202, 0.13013401995367202, 0.12393529212556109, 0.12393529212556109, 0.12393529212556109, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06395832717893923, 0.06395832717893923, 0.06395832717893923, 0.06698612153091676, 0.06698612153091676, 0.06698612153091676, 0.09307735549546303, 0.09307735549546303, 0.09307735549546303, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.038408337539002635, 0.038408337539002635, 0.038408337539002635, 0.0038661257779171176, 0.0038661257779171176, 0.0038661257779171176, 0.0639209729123944, 0.0639209729123944, 0.0639209729123944, 0.4471312292357341, 0.4471312292357341, 0.4471312292357341, 0.4503693097355478, 0.4503693097355478, 0.4503693097355478, 0.521946281743126, 0.521946281743126, 0.521946281743126, 0.10072299734943424, 0.10072299734943424, 0.10072299734943424, 0.10242580485076724, 0.10242580485076724, 0.10242580485076724, 0.1298840489061095, 0.1298840489061095, 0.1298840489061095, 0.20589731232610808, 0.20589731232610808, 0.20589731232610808, 0.2753619584131055, 0.2753619584131055, 0.2753619584131055, 0.21676449443352852, 0.21676449443352852, 0.21676449443352852, 0.3401795871392115, 0.3401795871392115, 0.3401795871392115, 0.3657610540794657, 0.3657610540794657, 0.3657610540794657, 0.4395825812550812, 0.4395825812550812, 0.4395825812550812, 0.29308353484063987, 0.29308353484063987, 0.29308353484063987, 0.19438874516947613, 0.19438874516947613, 0.19438874516947613, 0.23393960109818668, 0.23393960109818668, 0.23393960109818668, 0.21816177922955693, 0.21816177922955693, 0.21816177922955693, 0.1987923988073832, 0.1987923988073832, 0.1987923988073832, 0.24283886563718105, 0.24283886563718105, 0.24283886563718105, 0.18712908296437525, 0.18712908296437525, 0.18712908296437525, 0.16823242717066367, 0.16823242717066367, 0.16823242717066367, 0.19714396552649538, 0.19714396552649538, 0.19714396552649538, 0.7579999355408754, 0.7579999355408754, 0.7579999355408754, 0.16310712132966798, 0.16310712132966798, 0.16310712132966798, 0.7787233078953587, 0.7787233078953587, 0.7787233078953587, 0.7524158355408356, 0.7524158355408356, 0.7524158355408356, 0.20748921189260405, 0.20748921189260405, 0.20748921189260405, 0.16450411221929295, 0.16450411221929295, 0.16450411221929295, 0.1723192604672984, 0.1723192604672984, 0.1723192604672984, 0.16373718664922376, 0.16373718664922376, 0.16373718664922376, 0.1944888772434109, 0.1944888772434109, 0.1944888772434109, 0.07529581943051489, 0.07529581943051489, 0.07529581943051489, 0.08676158642804088, 0.08676158642804088, 0.08676158642804088, 0.08423668137865226, 0.08423668137865226, 0.08423668137865226]}, "mutation_prompt": null}
{"id": "69980dfd-ac92-4adf-b3e9-fb2f2ae16b64", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with minor tuning in parameter values for improving convergence speed.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6731653111579229, 0.6731653111579229, 0.6731653111579229, 0.711996635129519, 0.711996635129519, 0.711996635129519, 0.7078132901593165, 0.7078132901593165, 0.7078132901593165, 0.041381141768779384, 0.041381141768779384, 0.041381141768779384, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10950771709447105, 0.10950771709447105, 0.10950771709447105, 0.10521185649440323, 0.10521185649440323, 0.10521185649440323, 0.10507361746539623, 0.10507361746539623, 0.10507361746539623, 0.07764468958329585, 0.07764468958329585, 0.07764468958329585, 0.09106825770888427, 0.09106825770888427, 0.09106825770888427, 0.11676664795008551, 0.11676664795008551, 0.11676664795008551, 0.8873949697611814, 0.8873949697611814, 0.8873949697611814, 0.8899603182064498, 0.8899603182064498, 0.8899603182064498, 0.9242514104464227, 0.9242514104464227, 0.9242514104464227, 0.15529290578465005, 0.15529290578465005, 0.15529290578465005, 0.2190096480227307, 0.2190096480227307, 0.2190096480227307, 0.10602395596155945, 0.10602395596155945, 0.10602395596155945, 0.6785064774824554, 0.6785064774824554, 0.6785064774824554, 0.1588220386151905, 0.1588220386151905, 0.1588220386151905, 0.2013731947684061, 0.2013731947684061, 0.2013731947684061, 0.11757177930520302, 0.11757177930520302, 0.11757177930520302, 0.05893689880031361, 0.05893689880031361, 0.05893689880031361, 0.1347567060589916, 0.1347567060589916, 0.1347567060589916, 0.12717657197932586, 0.12717657197932586, 0.12717657197932586, 0.13013401995367202, 0.13013401995367202, 0.13013401995367202, 0.12393529212556109, 0.12393529212556109, 0.12393529212556109, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07406251021116783, 0.07406251021116783, 0.07406251021116783, 0.06698612153091676, 0.06698612153091676, 0.06698612153091676, 0.08330193363389515, 0.08330193363389515, 0.08330193363389515, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05394537933586785, 0.05394537933586785, 0.05394537933586785, 0.06280509881780472, 0.06280509881780472, 0.06280509881780472, 0.058389177628910716, 0.058389177628910716, 0.058389177628910716, 0.4471312292357341, 0.4471312292357341, 0.4471312292357341, 0.5243508001071969, 0.5243508001071969, 0.5243508001071969, 0.46983387154224854, 0.46983387154224854, 0.46983387154224854, 0.07663158410172577, 0.07663158410172577, 0.07663158410172577, 0.10886105391076506, 0.10886105391076506, 0.10886105391076506, 0.1298840489061095, 0.1298840489061095, 0.1298840489061095, 0.1594612677021673, 0.1594612677021673, 0.1594612677021673, 0.2988572920911492, 0.2988572920911492, 0.2988572920911492, 0.24455433586052078, 0.24455433586052078, 0.24455433586052078, 0.35593401052672236, 0.35593401052672236, 0.35593401052672236, 0.41401688285636506, 0.41401688285636506, 0.41401688285636506, 0.23348098648385784, 0.23348098648385784, 0.23348098648385784, 0.25155973801749965, 0.25155973801749965, 0.25155973801749965, 0.16473215297233235, 0.16473215297233235, 0.16473215297233235, 0.2618969115729881, 0.2618969115729881, 0.2618969115729881, 0.21816177922955693, 0.21816177922955693, 0.21816177922955693, 0.19590613448642658, 0.19590613448642658, 0.19590613448642658, 0.24283886563718105, 0.24283886563718105, 0.24283886563718105, 0.18712908296437525, 0.18712908296437525, 0.18712908296437525, 0.16823242717066367, 0.16823242717066367, 0.16823242717066367, 0.19714396552649538, 0.19714396552649538, 0.19714396552649538, 0.7424295255090958, 0.7424295255090958, 0.7424295255090958, 0.16360281335132354, 0.16360281335132354, 0.16360281335132354, 0.7787233078953587, 0.7787233078953587, 0.7787233078953587, 0.6864379667833054, 0.6864379667833054, 0.6864379667833054, 0.20954767599706114, 0.20954767599706114, 0.20954767599706114, 0.5250107589216552, 0.5250107589216552, 0.5250107589216552, 0.1978655172067132, 0.1978655172067132, 0.1978655172067132, 0.16373718664922376, 0.16373718664922376, 0.16373718664922376, 0.195695680947217, 0.195695680947217, 0.195695680947217, 0.07529581943051489, 0.07529581943051489, 0.07529581943051489, 0.0742746602426343, 0.0742746602426343, 0.0742746602426343, 0.08423668137865226, 0.08423668137865226, 0.08423668137865226]}, "mutation_prompt": null}
{"id": "1e74c0c7-b22a-466b-b916-5a3866365b22", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with minor tuning in parameter values for improving convergence speed.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6731653111579229, 0.6731653111579229, 0.6731653111579229, 0.711996635129519, 0.711996635129519, 0.711996635129519, 0.7078132901593165, 0.7078132901593165, 0.7078132901593165, 0.041381141768779384, 0.041381141768779384, 0.041381141768779384, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10950771709447105, 0.10950771709447105, 0.10950771709447105, 0.10521185649440323, 0.10521185649440323, 0.10521185649440323, 0.10507361746539623, 0.10507361746539623, 0.10507361746539623, 0.07764468958329585, 0.07764468958329585, 0.07764468958329585, 0.09106825770888427, 0.09106825770888427, 0.09106825770888427, 0.11676664795008551, 0.11676664795008551, 0.11676664795008551, 0.8873949697611814, 0.8873949697611814, 0.8873949697611814, 0.8899603182064498, 0.8899603182064498, 0.8899603182064498, 0.9242514104464227, 0.9242514104464227, 0.9242514104464227, 0.15529290578465005, 0.15529290578465005, 0.15529290578465005, 0.2190096480227307, 0.2190096480227307, 0.2190096480227307, 0.10602395596155945, 0.10602395596155945, 0.10602395596155945, 0.6785064774824554, 0.6785064774824554, 0.6785064774824554, 0.1588220386151905, 0.1588220386151905, 0.1588220386151905, 0.2013731947684061, 0.2013731947684061, 0.2013731947684061, 0.11757177930520302, 0.11757177930520302, 0.11757177930520302, 0.05893689880031361, 0.05893689880031361, 0.05893689880031361, 0.1347567060589916, 0.1347567060589916, 0.1347567060589916, 0.12717657197932586, 0.12717657197932586, 0.12717657197932586, 0.13013401995367202, 0.13013401995367202, 0.13013401995367202, 0.12393529212556109, 0.12393529212556109, 0.12393529212556109, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07406251021116783, 0.07406251021116783, 0.07406251021116783, 0.06698612153091676, 0.06698612153091676, 0.06698612153091676, 0.08330193363389515, 0.08330193363389515, 0.08330193363389515, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05394537933586785, 0.05394537933586785, 0.05394537933586785, 0.06280509881780472, 0.06280509881780472, 0.06280509881780472, 0.058389177628910716, 0.058389177628910716, 0.058389177628910716, 0.4471312292357341, 0.4471312292357341, 0.4471312292357341, 0.5243508001071969, 0.5243508001071969, 0.5243508001071969, 0.46983387154224854, 0.46983387154224854, 0.46983387154224854, 0.07663158410172577, 0.07663158410172577, 0.07663158410172577, 0.10886105391076506, 0.10886105391076506, 0.10886105391076506, 0.1298840489061095, 0.1298840489061095, 0.1298840489061095, 0.1594612677021673, 0.1594612677021673, 0.1594612677021673, 0.2988572920911492, 0.2988572920911492, 0.2988572920911492, 0.24455433586052078, 0.24455433586052078, 0.24455433586052078, 0.35593401052672236, 0.35593401052672236, 0.35593401052672236, 0.41401688285636506, 0.41401688285636506, 0.41401688285636506, 0.23348098648385784, 0.23348098648385784, 0.23348098648385784, 0.25155973801749965, 0.25155973801749965, 0.25155973801749965, 0.16473215297233235, 0.16473215297233235, 0.16473215297233235, 0.2618969115729881, 0.2618969115729881, 0.2618969115729881, 0.21816177922955693, 0.21816177922955693, 0.21816177922955693, 0.19590613448642658, 0.19590613448642658, 0.19590613448642658, 0.24283886563718105, 0.24283886563718105, 0.24283886563718105, 0.18712908296437525, 0.18712908296437525, 0.18712908296437525, 0.16823242717066367, 0.16823242717066367, 0.16823242717066367, 0.19714396552649538, 0.19714396552649538, 0.19714396552649538, 0.7424295255090958, 0.7424295255090958, 0.7424295255090958, 0.16360281335132354, 0.16360281335132354, 0.16360281335132354, 0.7787233078953587, 0.7787233078953587, 0.7787233078953587, 0.6864379667833054, 0.6864379667833054, 0.6864379667833054, 0.20954767599706114, 0.20954767599706114, 0.20954767599706114, 0.5250107589216552, 0.5250107589216552, 0.5250107589216552, 0.1978655172067132, 0.1978655172067132, 0.1978655172067132, 0.16373718664922376, 0.16373718664922376, 0.16373718664922376, 0.195695680947217, 0.195695680947217, 0.195695680947217, 0.07529581943051489, 0.07529581943051489, 0.07529581943051489, 0.0742746602426343, 0.0742746602426343, 0.0742746602426343, 0.08423668137865226, 0.08423668137865226, 0.08423668137865226]}, "mutation_prompt": null}
{"id": "5c618538-0480-4fe2-808c-6a108cafe4b6", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with minor tuning in parameter values for improving convergence speed.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6731653111579229, 0.6731653111579229, 0.6731653111579229, 0.711996635129519, 0.711996635129519, 0.711996635129519, 0.7078132901593165, 0.7078132901593165, 0.7078132901593165, 0.041381141768779384, 0.041381141768779384, 0.041381141768779384, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10950771709447105, 0.10950771709447105, 0.10950771709447105, 0.10521185649440323, 0.10521185649440323, 0.10521185649440323, 0.10507361746539623, 0.10507361746539623, 0.10507361746539623, 0.07764468958329585, 0.07764468958329585, 0.07764468958329585, 0.09106825770888427, 0.09106825770888427, 0.09106825770888427, 0.11676664795008551, 0.11676664795008551, 0.11676664795008551, 0.8873949697611814, 0.8873949697611814, 0.8873949697611814, 0.8899603182064498, 0.8899603182064498, 0.8899603182064498, 0.9242514104464227, 0.9242514104464227, 0.9242514104464227, 0.15529290578465005, 0.15529290578465005, 0.15529290578465005, 0.2190096480227307, 0.2190096480227307, 0.2190096480227307, 0.10602395596155945, 0.10602395596155945, 0.10602395596155945, 0.6785064774824554, 0.6785064774824554, 0.6785064774824554, 0.1588220386151905, 0.1588220386151905, 0.1588220386151905, 0.2013731947684061, 0.2013731947684061, 0.2013731947684061, 0.11757177930520302, 0.11757177930520302, 0.11757177930520302, 0.05893689880031361, 0.05893689880031361, 0.05893689880031361, 0.1347567060589916, 0.1347567060589916, 0.1347567060589916, 0.12717657197932586, 0.12717657197932586, 0.12717657197932586, 0.13013401995367202, 0.13013401995367202, 0.13013401995367202, 0.12393529212556109, 0.12393529212556109, 0.12393529212556109, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07406251021116783, 0.07406251021116783, 0.07406251021116783, 0.06698612153091676, 0.06698612153091676, 0.06698612153091676, 0.08330193363389515, 0.08330193363389515, 0.08330193363389515, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05394537933586785, 0.05394537933586785, 0.05394537933586785, 0.06280509881780472, 0.06280509881780472, 0.06280509881780472, 0.058389177628910716, 0.058389177628910716, 0.058389177628910716, 0.4471312292357341, 0.4471312292357341, 0.4471312292357341, 0.5243508001071969, 0.5243508001071969, 0.5243508001071969, 0.46983387154224854, 0.46983387154224854, 0.46983387154224854, 0.07663158410172577, 0.07663158410172577, 0.07663158410172577, 0.10886105391076506, 0.10886105391076506, 0.10886105391076506, 0.1298840489061095, 0.1298840489061095, 0.1298840489061095, 0.1594612677021673, 0.1594612677021673, 0.1594612677021673, 0.2988572920911492, 0.2988572920911492, 0.2988572920911492, 0.24455433586052078, 0.24455433586052078, 0.24455433586052078, 0.35593401052672236, 0.35593401052672236, 0.35593401052672236, 0.41401688285636506, 0.41401688285636506, 0.41401688285636506, 0.23348098648385784, 0.23348098648385784, 0.23348098648385784, 0.25155973801749965, 0.25155973801749965, 0.25155973801749965, 0.16473215297233235, 0.16473215297233235, 0.16473215297233235, 0.2618969115729881, 0.2618969115729881, 0.2618969115729881, 0.21816177922955693, 0.21816177922955693, 0.21816177922955693, 0.19590613448642658, 0.19590613448642658, 0.19590613448642658, 0.24283886563718105, 0.24283886563718105, 0.24283886563718105, 0.18712908296437525, 0.18712908296437525, 0.18712908296437525, 0.16823242717066367, 0.16823242717066367, 0.16823242717066367, 0.19714396552649538, 0.19714396552649538, 0.19714396552649538, 0.7424295255090958, 0.7424295255090958, 0.7424295255090958, 0.16360281335132354, 0.16360281335132354, 0.16360281335132354, 0.7787233078953587, 0.7787233078953587, 0.7787233078953587, 0.6864379667833054, 0.6864379667833054, 0.6864379667833054, 0.20954767599706114, 0.20954767599706114, 0.20954767599706114, 0.5250107589216552, 0.5250107589216552, 0.5250107589216552, 0.1978655172067132, 0.1978655172067132, 0.1978655172067132, 0.16373718664922376, 0.16373718664922376, 0.16373718664922376, 0.195695680947217, 0.195695680947217, 0.195695680947217, 0.07529581943051489, 0.07529581943051489, 0.07529581943051489, 0.0742746602426343, 0.0742746602426343, 0.0742746602426343, 0.08423668137865226, 0.08423668137865226, 0.08423668137865226]}, "mutation_prompt": null}
{"id": "418276d5-3c2a-4029-8c0a-4ceb73b4a30c", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with minor tuning in parameter values for improving convergence speed.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6731653111579229, 0.6731653111579229, 0.6731653111579229, 0.711996635129519, 0.711996635129519, 0.711996635129519, 0.7078132901593165, 0.7078132901593165, 0.7078132901593165, 0.041381141768779384, 0.041381141768779384, 0.041381141768779384, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10950771709447105, 0.10950771709447105, 0.10950771709447105, 0.10521185649440323, 0.10521185649440323, 0.10521185649440323, 0.10507361746539623, 0.10507361746539623, 0.10507361746539623, 0.07764468958329585, 0.07764468958329585, 0.07764468958329585, 0.09106825770888427, 0.09106825770888427, 0.09106825770888427, 0.11676664795008551, 0.11676664795008551, 0.11676664795008551, 0.8873949697611814, 0.8873949697611814, 0.8873949697611814, 0.8899603182064498, 0.8899603182064498, 0.8899603182064498, 0.9242514104464227, 0.9242514104464227, 0.9242514104464227, 0.15529290578465005, 0.15529290578465005, 0.15529290578465005, 0.2190096480227307, 0.2190096480227307, 0.2190096480227307, 0.10602395596155945, 0.10602395596155945, 0.10602395596155945, 0.6785064774824554, 0.6785064774824554, 0.6785064774824554, 0.1588220386151905, 0.1588220386151905, 0.1588220386151905, 0.2013731947684061, 0.2013731947684061, 0.2013731947684061, 0.11757177930520302, 0.11757177930520302, 0.11757177930520302, 0.05893689880031361, 0.05893689880031361, 0.05893689880031361, 0.1347567060589916, 0.1347567060589916, 0.1347567060589916, 0.12717657197932586, 0.12717657197932586, 0.12717657197932586, 0.13013401995367202, 0.13013401995367202, 0.13013401995367202, 0.12393529212556109, 0.12393529212556109, 0.12393529212556109, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07406251021116783, 0.07406251021116783, 0.07406251021116783, 0.06698612153091676, 0.06698612153091676, 0.06698612153091676, 0.08330193363389515, 0.08330193363389515, 0.08330193363389515, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05394537933586785, 0.05394537933586785, 0.05394537933586785, 0.06280509881780472, 0.06280509881780472, 0.06280509881780472, 0.058389177628910716, 0.058389177628910716, 0.058389177628910716, 0.4471312292357341, 0.4471312292357341, 0.4471312292357341, 0.5243508001071969, 0.5243508001071969, 0.5243508001071969, 0.46983387154224854, 0.46983387154224854, 0.46983387154224854, 0.07663158410172577, 0.07663158410172577, 0.07663158410172577, 0.10886105391076506, 0.10886105391076506, 0.10886105391076506, 0.1298840489061095, 0.1298840489061095, 0.1298840489061095, 0.1594612677021673, 0.1594612677021673, 0.1594612677021673, 0.2988572920911492, 0.2988572920911492, 0.2988572920911492, 0.24455433586052078, 0.24455433586052078, 0.24455433586052078, 0.35593401052672236, 0.35593401052672236, 0.35593401052672236, 0.41401688285636506, 0.41401688285636506, 0.41401688285636506, 0.23348098648385784, 0.23348098648385784, 0.23348098648385784, 0.25155973801749965, 0.25155973801749965, 0.25155973801749965, 0.16473215297233235, 0.16473215297233235, 0.16473215297233235, 0.2618969115729881, 0.2618969115729881, 0.2618969115729881, 0.21816177922955693, 0.21816177922955693, 0.21816177922955693, 0.19590613448642658, 0.19590613448642658, 0.19590613448642658, 0.24283886563718105, 0.24283886563718105, 0.24283886563718105, 0.18712908296437525, 0.18712908296437525, 0.18712908296437525, 0.16823242717066367, 0.16823242717066367, 0.16823242717066367, 0.19714396552649538, 0.19714396552649538, 0.19714396552649538, 0.7424295255090958, 0.7424295255090958, 0.7424295255090958, 0.16360281335132354, 0.16360281335132354, 0.16360281335132354, 0.7787233078953587, 0.7787233078953587, 0.7787233078953587, 0.6864379667833054, 0.6864379667833054, 0.6864379667833054, 0.20954767599706114, 0.20954767599706114, 0.20954767599706114, 0.5250107589216552, 0.5250107589216552, 0.5250107589216552, 0.1978655172067132, 0.1978655172067132, 0.1978655172067132, 0.16373718664922376, 0.16373718664922376, 0.16373718664922376, 0.195695680947217, 0.195695680947217, 0.195695680947217, 0.07529581943051489, 0.07529581943051489, 0.07529581943051489, 0.0742746602426343, 0.0742746602426343, 0.0742746602426343, 0.08423668137865226, 0.08423668137865226, 0.08423668137865226]}, "mutation_prompt": null}
{"id": "2283c4a2-c435-4996-aad4-ae526ae1fb42", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with minor tuning in parameter values for improving convergence speed.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6731653111579229, 0.6731653111579229, 0.6731653111579229, 0.711996635129519, 0.711996635129519, 0.711996635129519, 0.7078132901593165, 0.7078132901593165, 0.7078132901593165, 0.041381141768779384, 0.041381141768779384, 0.041381141768779384, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10950771709447105, 0.10950771709447105, 0.10950771709447105, 0.10521185649440323, 0.10521185649440323, 0.10521185649440323, 0.10507361746539623, 0.10507361746539623, 0.10507361746539623, 0.07764468958329585, 0.07764468958329585, 0.07764468958329585, 0.09106825770888427, 0.09106825770888427, 0.09106825770888427, 0.11676664795008551, 0.11676664795008551, 0.11676664795008551, 0.8873949697611814, 0.8873949697611814, 0.8873949697611814, 0.8899603182064498, 0.8899603182064498, 0.8899603182064498, 0.9242514104464227, 0.9242514104464227, 0.9242514104464227, 0.15529290578465005, 0.15529290578465005, 0.15529290578465005, 0.2190096480227307, 0.2190096480227307, 0.2190096480227307, 0.10602395596155945, 0.10602395596155945, 0.10602395596155945, 0.6785064774824554, 0.6785064774824554, 0.6785064774824554, 0.1588220386151905, 0.1588220386151905, 0.1588220386151905, 0.2013731947684061, 0.2013731947684061, 0.2013731947684061, 0.11757177930520302, 0.11757177930520302, 0.11757177930520302, 0.05893689880031361, 0.05893689880031361, 0.05893689880031361, 0.1347567060589916, 0.1347567060589916, 0.1347567060589916, 0.12717657197932586, 0.12717657197932586, 0.12717657197932586, 0.13013401995367202, 0.13013401995367202, 0.13013401995367202, 0.12393529212556109, 0.12393529212556109, 0.12393529212556109, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07406251021116783, 0.07406251021116783, 0.07406251021116783, 0.06698612153091676, 0.06698612153091676, 0.06698612153091676, 0.08330193363389515, 0.08330193363389515, 0.08330193363389515, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05394537933586785, 0.05394537933586785, 0.05394537933586785, 0.06280509881780472, 0.06280509881780472, 0.06280509881780472, 0.058389177628910716, 0.058389177628910716, 0.058389177628910716, 0.4471312292357341, 0.4471312292357341, 0.4471312292357341, 0.5243508001071969, 0.5243508001071969, 0.5243508001071969, 0.46983387154224854, 0.46983387154224854, 0.46983387154224854, 0.07663158410172577, 0.07663158410172577, 0.07663158410172577, 0.10886105391076506, 0.10886105391076506, 0.10886105391076506, 0.1298840489061095, 0.1298840489061095, 0.1298840489061095, 0.1594612677021673, 0.1594612677021673, 0.1594612677021673, 0.2988572920911492, 0.2988572920911492, 0.2988572920911492, 0.24455433586052078, 0.24455433586052078, 0.24455433586052078, 0.35593401052672236, 0.35593401052672236, 0.35593401052672236, 0.41401688285636506, 0.41401688285636506, 0.41401688285636506, 0.23348098648385784, 0.23348098648385784, 0.23348098648385784, 0.25155973801749965, 0.25155973801749965, 0.25155973801749965, 0.16473215297233235, 0.16473215297233235, 0.16473215297233235, 0.2618969115729881, 0.2618969115729881, 0.2618969115729881, 0.21816177922955693, 0.21816177922955693, 0.21816177922955693, 0.19590613448642658, 0.19590613448642658, 0.19590613448642658, 0.24283886563718105, 0.24283886563718105, 0.24283886563718105, 0.18712908296437525, 0.18712908296437525, 0.18712908296437525, 0.16823242717066367, 0.16823242717066367, 0.16823242717066367, 0.19714396552649538, 0.19714396552649538, 0.19714396552649538, 0.7424295255090958, 0.7424295255090958, 0.7424295255090958, 0.16360281335132354, 0.16360281335132354, 0.16360281335132354, 0.7787233078953587, 0.7787233078953587, 0.7787233078953587, 0.6864379667833054, 0.6864379667833054, 0.6864379667833054, 0.20954767599706114, 0.20954767599706114, 0.20954767599706114, 0.5250107589216552, 0.5250107589216552, 0.5250107589216552, 0.1978655172067132, 0.1978655172067132, 0.1978655172067132, 0.16373718664922376, 0.16373718664922376, 0.16373718664922376, 0.195695680947217, 0.195695680947217, 0.195695680947217, 0.07529581943051489, 0.07529581943051489, 0.07529581943051489, 0.0742746602426343, 0.0742746602426343, 0.0742746602426343, 0.08423668137865226, 0.08423668137865226, 0.08423668137865226]}, "mutation_prompt": null}
{"id": "5a89e741-2eef-4b2c-a259-c94a1492f51e", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with minor tuning in parameter values for improving convergence speed.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6731653111579229, 0.6731653111579229, 0.6731653111579229, 0.711996635129519, 0.711996635129519, 0.711996635129519, 0.7078132901593165, 0.7078132901593165, 0.7078132901593165, 0.041381141768779384, 0.041381141768779384, 0.041381141768779384, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10950771709447105, 0.10950771709447105, 0.10950771709447105, 0.10521185649440323, 0.10521185649440323, 0.10521185649440323, 0.10507361746539623, 0.10507361746539623, 0.10507361746539623, 0.07764468958329585, 0.07764468958329585, 0.07764468958329585, 0.09106825770888427, 0.09106825770888427, 0.09106825770888427, 0.11676664795008551, 0.11676664795008551, 0.11676664795008551, 0.8873949697611814, 0.8873949697611814, 0.8873949697611814, 0.8899603182064498, 0.8899603182064498, 0.8899603182064498, 0.9242514104464227, 0.9242514104464227, 0.9242514104464227, 0.15529290578465005, 0.15529290578465005, 0.15529290578465005, 0.2190096480227307, 0.2190096480227307, 0.2190096480227307, 0.10602395596155945, 0.10602395596155945, 0.10602395596155945, 0.6785064774824554, 0.6785064774824554, 0.6785064774824554, 0.1588220386151905, 0.1588220386151905, 0.1588220386151905, 0.2013731947684061, 0.2013731947684061, 0.2013731947684061, 0.11757177930520302, 0.11757177930520302, 0.11757177930520302, 0.05893689880031361, 0.05893689880031361, 0.05893689880031361, 0.1347567060589916, 0.1347567060589916, 0.1347567060589916, 0.12717657197932586, 0.12717657197932586, 0.12717657197932586, 0.13013401995367202, 0.13013401995367202, 0.13013401995367202, 0.12393529212556109, 0.12393529212556109, 0.12393529212556109, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07406251021116783, 0.07406251021116783, 0.07406251021116783, 0.06698612153091676, 0.06698612153091676, 0.06698612153091676, 0.08330193363389515, 0.08330193363389515, 0.08330193363389515, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05394537933586785, 0.05394537933586785, 0.05394537933586785, 0.06280509881780472, 0.06280509881780472, 0.06280509881780472, 0.058389177628910716, 0.058389177628910716, 0.058389177628910716, 0.4471312292357341, 0.4471312292357341, 0.4471312292357341, 0.5243508001071969, 0.5243508001071969, 0.5243508001071969, 0.46983387154224854, 0.46983387154224854, 0.46983387154224854, 0.07663158410172577, 0.07663158410172577, 0.07663158410172577, 0.10886105391076506, 0.10886105391076506, 0.10886105391076506, 0.1298840489061095, 0.1298840489061095, 0.1298840489061095, 0.1594612677021673, 0.1594612677021673, 0.1594612677021673, 0.2988572920911492, 0.2988572920911492, 0.2988572920911492, 0.24455433586052078, 0.24455433586052078, 0.24455433586052078, 0.35593401052672236, 0.35593401052672236, 0.35593401052672236, 0.41401688285636506, 0.41401688285636506, 0.41401688285636506, 0.23348098648385784, 0.23348098648385784, 0.23348098648385784, 0.25155973801749965, 0.25155973801749965, 0.25155973801749965, 0.16473215297233235, 0.16473215297233235, 0.16473215297233235, 0.2618969115729881, 0.2618969115729881, 0.2618969115729881, 0.21816177922955693, 0.21816177922955693, 0.21816177922955693, 0.19590613448642658, 0.19590613448642658, 0.19590613448642658, 0.24283886563718105, 0.24283886563718105, 0.24283886563718105, 0.18712908296437525, 0.18712908296437525, 0.18712908296437525, 0.16823242717066367, 0.16823242717066367, 0.16823242717066367, 0.19714396552649538, 0.19714396552649538, 0.19714396552649538, 0.7424295255090958, 0.7424295255090958, 0.7424295255090958, 0.16360281335132354, 0.16360281335132354, 0.16360281335132354, 0.7787233078953587, 0.7787233078953587, 0.7787233078953587, 0.6864379667833054, 0.6864379667833054, 0.6864379667833054, 0.20954767599706114, 0.20954767599706114, 0.20954767599706114, 0.5250107589216552, 0.5250107589216552, 0.5250107589216552, 0.1978655172067132, 0.1978655172067132, 0.1978655172067132, 0.16373718664922376, 0.16373718664922376, 0.16373718664922376, 0.195695680947217, 0.195695680947217, 0.195695680947217, 0.07529581943051489, 0.07529581943051489, 0.07529581943051489, 0.0742746602426343, 0.0742746602426343, 0.0742746602426343, 0.08423668137865226, 0.08423668137865226, 0.08423668137865226]}, "mutation_prompt": null}
{"id": "686e96a3-bc7d-4f74-b41e-7c333461200c", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with minor tuning in parameter values for improving convergence speed.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6731653111579229, 0.6731653111579229, 0.6731653111579229, 0.711996635129519, 0.711996635129519, 0.711996635129519, 0.7078132901593165, 0.7078132901593165, 0.7078132901593165, 0.041381141768779384, 0.041381141768779384, 0.041381141768779384, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10950771709447105, 0.10950771709447105, 0.10950771709447105, 0.10521185649440323, 0.10521185649440323, 0.10521185649440323, 0.10507361746539623, 0.10507361746539623, 0.10507361746539623, 0.07764468958329585, 0.07764468958329585, 0.07764468958329585, 0.09106825770888427, 0.09106825770888427, 0.09106825770888427, 0.11676664795008551, 0.11676664795008551, 0.11676664795008551, 0.8873949697611814, 0.8873949697611814, 0.8873949697611814, 0.8899603182064498, 0.8899603182064498, 0.8899603182064498, 0.9242514104464227, 0.9242514104464227, 0.9242514104464227, 0.15529290578465005, 0.15529290578465005, 0.15529290578465005, 0.2190096480227307, 0.2190096480227307, 0.2190096480227307, 0.10602395596155945, 0.10602395596155945, 0.10602395596155945, 0.6785064774824554, 0.6785064774824554, 0.6785064774824554, 0.1588220386151905, 0.1588220386151905, 0.1588220386151905, 0.2013731947684061, 0.2013731947684061, 0.2013731947684061, 0.11757177930520302, 0.11757177930520302, 0.11757177930520302, 0.05893689880031361, 0.05893689880031361, 0.05893689880031361, 0.1347567060589916, 0.1347567060589916, 0.1347567060589916, 0.12717657197932586, 0.12717657197932586, 0.12717657197932586, 0.13013401995367202, 0.13013401995367202, 0.13013401995367202, 0.12393529212556109, 0.12393529212556109, 0.12393529212556109, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07406251021116783, 0.07406251021116783, 0.07406251021116783, 0.06698612153091676, 0.06698612153091676, 0.06698612153091676, 0.08330193363389515, 0.08330193363389515, 0.08330193363389515, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05394537933586785, 0.05394537933586785, 0.05394537933586785, 0.06280509881780472, 0.06280509881780472, 0.06280509881780472, 0.058389177628910716, 0.058389177628910716, 0.058389177628910716, 0.4471312292357341, 0.4471312292357341, 0.4471312292357341, 0.5243508001071969, 0.5243508001071969, 0.5243508001071969, 0.46983387154224854, 0.46983387154224854, 0.46983387154224854, 0.07663158410172577, 0.07663158410172577, 0.07663158410172577, 0.10886105391076506, 0.10886105391076506, 0.10886105391076506, 0.1298840489061095, 0.1298840489061095, 0.1298840489061095, 0.1594612677021673, 0.1594612677021673, 0.1594612677021673, 0.2988572920911492, 0.2988572920911492, 0.2988572920911492, 0.24455433586052078, 0.24455433586052078, 0.24455433586052078, 0.35593401052672236, 0.35593401052672236, 0.35593401052672236, 0.41401688285636506, 0.41401688285636506, 0.41401688285636506, 0.23348098648385784, 0.23348098648385784, 0.23348098648385784, 0.25155973801749965, 0.25155973801749965, 0.25155973801749965, 0.16473215297233235, 0.16473215297233235, 0.16473215297233235, 0.2618969115729881, 0.2618969115729881, 0.2618969115729881, 0.21816177922955693, 0.21816177922955693, 0.21816177922955693, 0.19590613448642658, 0.19590613448642658, 0.19590613448642658, 0.24283886563718105, 0.24283886563718105, 0.24283886563718105, 0.18712908296437525, 0.18712908296437525, 0.18712908296437525, 0.16823242717066367, 0.16823242717066367, 0.16823242717066367, 0.19714396552649538, 0.19714396552649538, 0.19714396552649538, 0.7424295255090958, 0.7424295255090958, 0.7424295255090958, 0.16360281335132354, 0.16360281335132354, 0.16360281335132354, 0.7787233078953587, 0.7787233078953587, 0.7787233078953587, 0.6864379667833054, 0.6864379667833054, 0.6864379667833054, 0.20954767599706114, 0.20954767599706114, 0.20954767599706114, 0.5250107589216552, 0.5250107589216552, 0.5250107589216552, 0.1978655172067132, 0.1978655172067132, 0.1978655172067132, 0.16373718664922376, 0.16373718664922376, 0.16373718664922376, 0.195695680947217, 0.195695680947217, 0.195695680947217, 0.07529581943051489, 0.07529581943051489, 0.07529581943051489, 0.0742746602426343, 0.0742746602426343, 0.0742746602426343, 0.08423668137865226, 0.08423668137865226, 0.08423668137865226]}, "mutation_prompt": null}
{"id": "0594e7f9-af68-4d1a-9fc6-216ceea9a747", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with minor tuning in parameter values for improving convergence speed.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6731653111579229, 0.6731653111579229, 0.6731653111579229, 0.711996635129519, 0.711996635129519, 0.711996635129519, 0.7078132901593165, 0.7078132901593165, 0.7078132901593165, 0.041381141768779384, 0.041381141768779384, 0.041381141768779384, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10950771709447105, 0.10950771709447105, 0.10950771709447105, 0.10521185649440323, 0.10521185649440323, 0.10521185649440323, 0.10507361746539623, 0.10507361746539623, 0.10507361746539623, 0.07764468958329585, 0.07764468958329585, 0.07764468958329585, 0.09106825770888427, 0.09106825770888427, 0.09106825770888427, 0.11676664795008551, 0.11676664795008551, 0.11676664795008551, 0.8873949697611814, 0.8873949697611814, 0.8873949697611814, 0.8899603182064498, 0.8899603182064498, 0.8899603182064498, 0.9242514104464227, 0.9242514104464227, 0.9242514104464227, 0.15529290578465005, 0.15529290578465005, 0.15529290578465005, 0.2190096480227307, 0.2190096480227307, 0.2190096480227307, 0.10602395596155945, 0.10602395596155945, 0.10602395596155945, 0.6785064774824554, 0.6785064774824554, 0.6785064774824554, 0.1588220386151905, 0.1588220386151905, 0.1588220386151905, 0.2013731947684061, 0.2013731947684061, 0.2013731947684061, 0.11757177930520302, 0.11757177930520302, 0.11757177930520302, 0.05893689880031361, 0.05893689880031361, 0.05893689880031361, 0.1347567060589916, 0.1347567060589916, 0.1347567060589916, 0.12717657197932586, 0.12717657197932586, 0.12717657197932586, 0.13013401995367202, 0.13013401995367202, 0.13013401995367202, 0.12393529212556109, 0.12393529212556109, 0.12393529212556109, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07406251021116783, 0.07406251021116783, 0.07406251021116783, 0.06698612153091676, 0.06698612153091676, 0.06698612153091676, 0.08330193363389515, 0.08330193363389515, 0.08330193363389515, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05394537933586785, 0.05394537933586785, 0.05394537933586785, 0.06280509881780472, 0.06280509881780472, 0.06280509881780472, 0.058389177628910716, 0.058389177628910716, 0.058389177628910716, 0.4471312292357341, 0.4471312292357341, 0.4471312292357341, 0.5243508001071969, 0.5243508001071969, 0.5243508001071969, 0.46983387154224854, 0.46983387154224854, 0.46983387154224854, 0.07663158410172577, 0.07663158410172577, 0.07663158410172577, 0.10886105391076506, 0.10886105391076506, 0.10886105391076506, 0.1298840489061095, 0.1298840489061095, 0.1298840489061095, 0.1594612677021673, 0.1594612677021673, 0.1594612677021673, 0.2988572920911492, 0.2988572920911492, 0.2988572920911492, 0.24455433586052078, 0.24455433586052078, 0.24455433586052078, 0.35593401052672236, 0.35593401052672236, 0.35593401052672236, 0.41401688285636506, 0.41401688285636506, 0.41401688285636506, 0.23348098648385784, 0.23348098648385784, 0.23348098648385784, 0.25155973801749965, 0.25155973801749965, 0.25155973801749965, 0.16473215297233235, 0.16473215297233235, 0.16473215297233235, 0.2618969115729881, 0.2618969115729881, 0.2618969115729881, 0.21816177922955693, 0.21816177922955693, 0.21816177922955693, 0.19590613448642658, 0.19590613448642658, 0.19590613448642658, 0.24283886563718105, 0.24283886563718105, 0.24283886563718105, 0.18712908296437525, 0.18712908296437525, 0.18712908296437525, 0.16823242717066367, 0.16823242717066367, 0.16823242717066367, 0.19714396552649538, 0.19714396552649538, 0.19714396552649538, 0.7424295255090958, 0.7424295255090958, 0.7424295255090958, 0.16360281335132354, 0.16360281335132354, 0.16360281335132354, 0.7787233078953587, 0.7787233078953587, 0.7787233078953587, 0.6864379667833054, 0.6864379667833054, 0.6864379667833054, 0.20954767599706114, 0.20954767599706114, 0.20954767599706114, 0.5250107589216552, 0.5250107589216552, 0.5250107589216552, 0.1978655172067132, 0.1978655172067132, 0.1978655172067132, 0.16373718664922376, 0.16373718664922376, 0.16373718664922376, 0.195695680947217, 0.195695680947217, 0.195695680947217, 0.07529581943051489, 0.07529581943051489, 0.07529581943051489, 0.0742746602426343, 0.0742746602426343, 0.0742746602426343, 0.08423668137865226, 0.08423668137865226, 0.08423668137865226]}, "mutation_prompt": null}
{"id": "7d1548c9-08c9-48c4-b993-348004b5fec3", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.995)  # Slightly faster decay rate for inertia weight\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with dynamic adaptive mechanisms for improved exploration-exploitation balance and convergence speed.", "configspace": "", "generation": 41, "fitness": 0.21529156527343324, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.22.", "error": "", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.49267113341449964, 0.49267113341449964, 0.49267113341449964, 0.5225345774836219, 0.5225345774836219, 0.5225345774836219, 0.6067485503737708, 0.6067485503737708, 0.6067485503737708, 0.0023597593246930115, 0.0023597593246930115, 0.0023597593246930115, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10076965270147653, 0.10076965270147653, 0.10076965270147653, 0.10684768848693293, 0.10684768848693293, 0.10684768848693293, 0.07797252864077509, 0.07797252864077509, 0.07797252864077509, 0.06172184610553577, 0.06172184610553577, 0.06172184610553577, 0.08938898708610976, 0.08938898708610976, 0.08938898708610976, 0.07028383520459103, 0.07028383520459103, 0.07028383520459103, 0.8883190897893948, 0.8883190897893948, 0.8883190897893948, 0.8898229751018151, 0.8898229751018151, 0.8898229751018151, 0.9246085119599469, 0.9246085119599469, 0.9246085119599469, 0.1979071525812769, 0.1979071525812769, 0.1979071525812769, 0.1786755662102434, 0.1786755662102434, 0.1786755662102434, 0.1359129676710763, 0.1359129676710763, 0.1359129676710763, 0.20078515063910363, 0.20078515063910363, 0.20078515063910363, 0.18652792749206737, 0.18652792749206737, 0.18652792749206737, 0.17502228674995335, 0.17502228674995335, 0.17502228674995335, 0.1034222393929991, 0.1034222393929991, 0.1034222393929991, 0.10683129516205625, 0.10683129516205625, 0.10683129516205625, 0.11286169178774474, 0.11286169178774474, 0.11286169178774474, 0.05127829398359662, 0.05127829398359662, 0.05127829398359662, 0.12282756198404399, 0.12282756198404399, 0.12282756198404399, 0.10999517262157443, 0.10999517262157443, 0.10999517262157443, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0906323237396155, 0.0906323237396155, 0.0906323237396155, 0.08552857850891937, 0.08552857850891937, 0.08552857850891937, 0.07054174534236879, 0.07054174534236879, 0.07054174534236879, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04428332408871283, 0.04428332408871283, 0.04428332408871283, 0.04359336858630414, 0.04359336858630414, 0.04359336858630414, 0.10753274078048869, 0.10753274078048869, 0.10753274078048869, 0.4277708757936014, 0.4277708757936014, 0.4277708757936014, 0.41797809814036224, 0.41797809814036224, 0.41797809814036224, 0.39999041775005384, 0.39999041775005384, 0.39999041775005384, 0.08184265671082014, 0.08184265671082014, 0.08184265671082014, 0.09274992508314495, 0.09274992508314495, 0.09274992508314495, 0.1177776018908222, 0.1177776018908222, 0.1177776018908222, 0.19735665096089916, 0.19735665096089916, 0.19735665096089916, 0.26609732815607434, 0.26609732815607434, 0.26609732815607434, 0.15018553929666545, 0.15018553929666545, 0.15018553929666545, 0.33227792763577313, 0.33227792763577313, 0.33227792763577313, 0.2539740701557187, 0.2539740701557187, 0.2539740701557187, 0.32549737946196655, 0.32549737946196655, 0.32549737946196655, 0.24842656026154952, 0.24842656026154952, 0.24842656026154952, 0.16705984338359137, 0.16705984338359137, 0.16705984338359137, 0.2142395045671125, 0.2142395045671125, 0.2142395045671125, 0.22988187646545133, 0.22988187646545133, 0.22988187646545133, 0.21340416334991918, 0.21340416334991918, 0.21340416334991918, 0.18785693287822047, 0.18785693287822047, 0.18785693287822047, 0.1740901260209322, 0.1740901260209322, 0.1740901260209322, 0.20038733205829617, 0.20038733205829617, 0.20038733205829617, 0.21372722389467003, 0.21372722389467003, 0.21372722389467003, 0.7192971354641813, 0.7192971354641813, 0.7192971354641813, 0.162850510925316, 0.162850510925316, 0.162850510925316, 0.6835724398093688, 0.6835724398093688, 0.6835724398093688, 0.5869356987027918, 0.5869356987027918, 0.5869356987027918, 0.2071843350501522, 0.2071843350501522, 0.2071843350501522, 0.42721670611494644, 0.42721670611494644, 0.42721670611494644, 0.17861894825602664, 0.17861894825602664, 0.17861894825602664, 0.1859645888244582, 0.1859645888244582, 0.1859645888244582, 0.2147803538530746, 0.2147803538530746, 0.2147803538530746, 0.09195775949208784, 0.09195775949208784, 0.09195775949208784, 0.0808337286599834, 0.0808337286599834, 0.0808337286599834, 0.09019993762385381, 0.09019993762385381, 0.09019993762385381]}, "mutation_prompt": null}
{"id": "d4752eef-03c1-4b54-b0cb-fbc4dcff0ff1", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85\n        self.w_min = 0.4\n        self.w_max = 0.9  # New adaptive inertia weight maximum\n        self.c1 = 1.6  # Adjusted cognitive coefficient\n        self.c2 = 1.3\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                # Adaptive inertia strategy\n                dynamic_w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n                inertia = dynamic_w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Introduce an adaptive inertia strategy and slight adjustment to the cognitive coefficient to enhance convergence speed.", "configspace": "", "generation": 42, "fitness": 0.20907250155249976, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.21.", "error": "", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.5463871789219967, 0.5463871789219967, 0.5463871789219967, 0.5574039030495911, 0.5574039030495911, 0.5574039030495911, 0.5302201500429977, 0.5302201500429977, 0.5302201500429977, 0.0016230774505858747, 0.0016230774505858747, 0.0016230774505858747, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12666965292524268, 0.12666965292524268, 0.12666965292524268, 0.07926457474792803, 0.07926457474792803, 0.07926457474792803, 0.1079832477188315, 0.1079832477188315, 0.1079832477188315, 0.06557458537358218, 0.06557458537358218, 0.06557458537358218, 0.08688026029521412, 0.08688026029521412, 0.08688026029521412, 0.07289886565765358, 0.07289886565765358, 0.07289886565765358, 0.8808362313949285, 0.8808362313949285, 0.8808362313949285, 0.8963185496112387, 0.8963185496112387, 0.8963185496112387, 0.9249583007835586, 0.9249583007835586, 0.9249583007835586, 0.1772761777312346, 0.1772761777312346, 0.1772761777312346, 0.18800656552846418, 0.18800656552846418, 0.18800656552846418, 0.19251759323403872, 0.19251759323403872, 0.19251759323403872, 0.22333594421715364, 0.22333594421715364, 0.22333594421715364, 0.1905269977822147, 0.1905269977822147, 0.1905269977822147, 0.16701703942053714, 0.16701703942053714, 0.16701703942053714, 0.09370012187041099, 0.09370012187041099, 0.09370012187041099, 0.08465814993090859, 0.08465814993090859, 0.08465814993090859, 0.1091840510283757, 0.1091840510283757, 0.1091840510283757, 0.02033779689926596, 0.02033779689926596, 0.02033779689926596, 0.12111443912468733, 0.12111443912468733, 0.12111443912468733, 0.13636953626157955, 0.13636953626157955, 0.13636953626157955, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.053792187318800644, 0.053792187318800644, 0.053792187318800644, 0.027896755946381413, 0.027896755946381413, 0.027896755946381413, 0.037348619440451536, 0.037348619440451536, 0.037348619440451536, 0.005338776846555815, 0.005338776846555815, 0.005338776846555815, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062129396872454556, 0.062129396872454556, 0.062129396872454556, 0.02824439262386491, 0.02824439262386491, 0.02824439262386491, 0.04238767293505008, 0.04238767293505008, 0.04238767293505008, 0.446485871008956, 0.446485871008956, 0.446485871008956, 0.41318236160299604, 0.41318236160299604, 0.41318236160299604, 0.4228838324402563, 0.4228838324402563, 0.4228838324402563, 0.12164033217293069, 0.12164033217293069, 0.12164033217293069, 0.1036905959908756, 0.1036905959908756, 0.1036905959908756, 0.10869381489019159, 0.10869381489019159, 0.10869381489019159, 0.17172060342531226, 0.17172060342531226, 0.17172060342531226, 0.16480709120999748, 0.16480709120999748, 0.16480709120999748, 0.2770662222726281, 0.2770662222726281, 0.2770662222726281, 0.27984675337145914, 0.27984675337145914, 0.27984675337145914, 0.3078242880171218, 0.3078242880171218, 0.3078242880171218, 0.2929312015440618, 0.2929312015440618, 0.2929312015440618, 0.22453894892669946, 0.22453894892669946, 0.22453894892669946, 0.25360976521984, 0.25360976521984, 0.25360976521984, 0.20187332104410527, 0.20187332104410527, 0.20187332104410527, 0.2014450143529365, 0.2014450143529365, 0.2014450143529365, 0.22799439130207655, 0.22799439130207655, 0.22799439130207655, 0.2065480397522541, 0.2065480397522541, 0.2065480397522541, 0.2001962729660176, 0.2001962729660176, 0.2001962729660176, 0.16252502914321176, 0.16252502914321176, 0.16252502914321176, 0.17292044213714486, 0.17292044213714486, 0.17292044213714486, 0.6594295145555833, 0.6594295145555833, 0.6594295145555833, 0.16301918637116974, 0.16301918637116974, 0.16301918637116974, 0.6792201643345555, 0.6792201643345555, 0.6792201643345555, 0.4044186793984532, 0.4044186793984532, 0.4044186793984532, 0.20458127011147875, 0.20458127011147875, 0.20458127011147875, 0.32287553228511, 0.32287553228511, 0.32287553228511, 0.19554284411041267, 0.19554284411041267, 0.19554284411041267, 0.19635717982461287, 0.19635717982461287, 0.19635717982461287, 0.16959153482288836, 0.16959153482288836, 0.16959153482288836, 0.07227935074007397, 0.07227935074007397, 0.07227935074007397, 0.09472775041360038, 0.09472775041360038, 0.09472775041360038, 0.08985211903519208, 0.08985211903519208, 0.08985211903519208]}, "mutation_prompt": null}
{"id": "b50076a6-0ac4-4a57-9197-f0dbedc4db66", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2 = 1.3\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n            self.vel_bounds = (-1.0 * max(0.5, self.w), 1.0 * max(0.5, self.w))  # Adaptive velocity bounds\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Incorporate a dynamic inertia weight adjustment and adaptive velocity bounds to enhance convergence speed.", "configspace": "", "generation": 43, "fitness": 0.2231994331284047, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.23.", "error": "", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.7150158615381286, 0.7150158615381286, 0.7150158615381286, 0.7184841397347586, 0.7184841397347586, 0.7184841397347586, 0.6700595982966168, 0.6700595982966168, 0.6700595982966168, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11277506045564356, 0.11277506045564356, 0.11277506045564356, 0.10743667228884313, 0.10743667228884313, 0.10743667228884313, 0.16024919870629217, 0.16024919870629217, 0.16024919870629217, 0.07457728766996152, 0.07457728766996152, 0.07457728766996152, 0.051532254202849126, 0.051532254202849126, 0.051532254202849126, 0.11407506604167106, 0.11407506604167106, 0.11407506604167106, 0.846138395180408, 0.846138395180408, 0.846138395180408, 0.8449188056108243, 0.8449188056108243, 0.8449188056108243, 0.9029361839531557, 0.9029361839531557, 0.9029361839531557, 0.16667971996197029, 0.16667971996197029, 0.16667971996197029, 0.17932386009582735, 0.17932386009582735, 0.17932386009582735, 0.13487620755037244, 0.13487620755037244, 0.13487620755037244, 0.21154288768387786, 0.21154288768387786, 0.21154288768387786, 0.20034096490061992, 0.20034096490061992, 0.20034096490061992, 0.1735771117308026, 0.1735771117308026, 0.1735771117308026, 0.05874874519022921, 0.05874874519022921, 0.05874874519022921, 0.12646474941341634, 0.12646474941341634, 0.12646474941341634, 0.09848466454708027, 0.09848466454708027, 0.09848466454708027, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13906571734054374, 0.13906571734054374, 0.13906571734054374, 0.1765051691750701, 0.1765051691750701, 0.1765051691750701, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07211105212681035, 0.07211105212681035, 0.07211105212681035, 0.02488391770542253, 0.02488391770542253, 0.02488391770542253, 0.05681489795759387, 0.05681489795759387, 0.05681489795759387, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1312816569438533, 0.1312816569438533, 0.1312816569438533, 0.012589261631046456, 0.012589261631046456, 0.012589261631046456, 0.06211968998407558, 0.06211968998407558, 0.06211968998407558, 0.43190312078653204, 0.43190312078653204, 0.43190312078653204, 0.47146439523769657, 0.47146439523769657, 0.47146439523769657, 0.48935839721943697, 0.48935839721943697, 0.48935839721943697, 0.09094962505526905, 0.09094962505526905, 0.09094962505526905, 0.10235722729022034, 0.10235722729022034, 0.10235722729022034, 0.16169363920092927, 0.16169363920092927, 0.16169363920092927, 0.1636227706704627, 0.1636227706704627, 0.1636227706704627, 0.31619192495921344, 0.31619192495921344, 0.31619192495921344, 0.18399388068302858, 0.18399388068302858, 0.18399388068302858, 0.3921330348100459, 0.3921330348100459, 0.3921330348100459, 0.4214422482492707, 0.4214422482492707, 0.4214422482492707, 0.23768252394620049, 0.23768252394620049, 0.23768252394620049, 0.22372227959000401, 0.22372227959000401, 0.22372227959000401, 0.17833263977244862, 0.17833263977244862, 0.17833263977244862, 0.20142198706440362, 0.20142198706440362, 0.20142198706440362, 0.21249553711861568, 0.21249553711861568, 0.21249553711861568, 0.20795147450454787, 0.20795147450454787, 0.20795147450454787, 0.23213199202662382, 0.23213199202662382, 0.23213199202662382, 0.15670085358797858, 0.15670085358797858, 0.15670085358797858, 0.16654285875115182, 0.16654285875115182, 0.16654285875115182, 0.1826525219811137, 0.1826525219811137, 0.1826525219811137, 0.7853685180507387, 0.7853685180507387, 0.7853685180507387, 0.16341892600136976, 0.16341892600136976, 0.16341892600136976, 0.7547451075670819, 0.7547451075670819, 0.7547451075670819, 0.5750392335094594, 0.5750392335094594, 0.5750392335094594, 0.20943990439153004, 0.20943990439153004, 0.20943990439153004, 0.1654737270170179, 0.1654737270170179, 0.1654737270170179, 0.1870005614954573, 0.1870005614954573, 0.1870005614954573, 0.19320450970277192, 0.19320450970277192, 0.19320450970277192, 0.18137079580017612, 0.18137079580017612, 0.18137079580017612, 0.11187682580044134, 0.11187682580044134, 0.11187682580044134, 0.0858719927072914, 0.0858719927072914, 0.0858719927072914, 0.08819535307884385, 0.08819535307884385, 0.08819535307884385]}, "mutation_prompt": null}
{"id": "72991103-e3a9-46bc-be1a-138ca6f311de", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 40\n        self.w = 0.85\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2 = 1.3\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        swarm_size = self.initial_swarm_size\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.98)  # Slightly altered inertia weight decay\n            if evaluations > self.budget * 0.5 and swarm_size > 30:  # Dynamic swarm size reduction\n                swarm_size -= 1\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "A refined PSO-SA optimizer with improved inertia weight adjustment and dynamic swarm size reduction for enhanced convergence agility.", "configspace": "", "generation": 44, "fitness": 0.23582453272641082, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.25.", "error": "", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.7676071089050918, 0.7676071089050918, 0.7676071089050918, 0.7786793249164208, 0.7786793249164208, 0.7786793249164208, 0.7826277604499038, 0.7826277604499038, 0.7826277604499038, 0.0644418315090095, 0.0644418315090095, 0.0644418315090095, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.028129803479043924, 0.028129803479043924, 0.028129803479043924, 0.1489873123155223, 0.1489873123155223, 0.1489873123155223, 0.09980120301983297, 0.09980120301983297, 0.09980120301983297, 0.1279706631655143, 0.1279706631655143, 0.1279706631655143, 0.07446973061964146, 0.07446973061964146, 0.07446973061964146, 0.10486593350293494, 0.10486593350293494, 0.10486593350293494, 0.05265743625209651, 0.05265743625209651, 0.05265743625209651, 0.8496119464690546, 0.8496119464690546, 0.8496119464690546, 0.8900238563697216, 0.8900238563697216, 0.8900238563697216, 0.9221306999100594, 0.9221306999100594, 0.9221306999100594, 0.08579554036522219, 0.08579554036522219, 0.08579554036522219, 0.13835876170293537, 0.13835876170293537, 0.13835876170293537, 0.14359779198166778, 0.14359779198166778, 0.14359779198166778, 0.1359901718309151, 0.1359901718309151, 0.1359901718309151, 0.15554017504184903, 0.15554017504184903, 0.15554017504184903, 0.16103746451936551, 0.16103746451936551, 0.16103746451936551, 0.1283677936135862, 0.1283677936135862, 0.1283677936135862, 0.045056658578235154, 0.045056658578235154, 0.045056658578235154, 0.13315761858638142, 0.13315761858638142, 0.13315761858638142, 0.04078937655777404, 0.04078937655777404, 0.04078937655777404, 0.12225534865766963, 0.12225534865766963, 0.12225534865766963, 0.2209397500888769, 0.2209397500888769, 0.2209397500888769, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03327974136249645, 0.03327974136249645, 0.03327974136249645, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10132726172614626, 0.10132726172614626, 0.10132726172614626, 0.05916985202959657, 0.05916985202959657, 0.05916985202959657, 0.07271008584517569, 0.07271008584517569, 0.07271008584517569, 0.03722449090233804, 0.03722449090233804, 0.03722449090233804, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02831194749228305, 0.02831194749228305, 0.02831194749228305, 0.06863009594805314, 0.06863009594805314, 0.06863009594805314, 0.0856420942496583, 0.0856420942496583, 0.0856420942496583, 0.5022165920045674, 0.5022165920045674, 0.5022165920045674, 0.5009133990584613, 0.5009133990584613, 0.5009133990584613, 0.5134097507298414, 0.5134097507298414, 0.5134097507298414, 0.1201418816271893, 0.1201418816271893, 0.1201418816271893, 0.10671059825901807, 0.10671059825901807, 0.10671059825901807, 0.09762360443053009, 0.09762360443053009, 0.09762360443053009, 0.13974114747177502, 0.13974114747177502, 0.13974114747177502, 0.2196483412272282, 0.2196483412272282, 0.2196483412272282, 0.1788987523124701, 0.1788987523124701, 0.1788987523124701, 0.42239389704189934, 0.42239389704189934, 0.42239389704189934, 0.3548724729869358, 0.3548724729869358, 0.3548724729869358, 0.22263444021362466, 0.22263444021362466, 0.22263444021362466, 0.1938453956064713, 0.1938453956064713, 0.1938453956064713, 0.15653536461784556, 0.15653536461784556, 0.15653536461784556, 0.2736451225626414, 0.2736451225626414, 0.2736451225626414, 0.206927971239535, 0.206927971239535, 0.206927971239535, 0.25749852051491173, 0.25749852051491173, 0.25749852051491173, 0.25627244113583436, 0.25627244113583436, 0.25627244113583436, 0.18207930664024075, 0.18207930664024075, 0.18207930664024075, 0.18550566537267854, 0.18550566537267854, 0.18550566537267854, 0.17352220913577598, 0.17352220913577598, 0.17352220913577598, 0.8273436880906637, 0.8273436880906637, 0.8273436880906637, 0.1631524071137146, 0.1631524071137146, 0.1631524071137146, 0.7838661488770831, 0.7838661488770831, 0.7838661488770831, 0.7381252821286537, 0.7381252821286537, 0.7381252821286537, 0.2098841537656887, 0.2098841537656887, 0.2098841537656887, 0.46310174268509985, 0.46310174268509985, 0.46310174268509985, 0.1986364795507688, 0.1986364795507688, 0.1986364795507688, 0.17445590790301468, 0.17445590790301468, 0.17445590790301468, 0.18300410481872054, 0.18300410481872054, 0.18300410481872054, 0.09229081210414114, 0.09229081210414114, 0.09229081210414114, 0.08804585704563228, 0.08804585704563228, 0.08804585704563228, 0.10273626606484954, 0.10273626606484954, 0.10273626606484954]}, "mutation_prompt": null}
{"id": "1ad3380c-4596-4061-bc5e-4c7864f2d73c", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2 = 1.3\n        self.temp_init = 100.0\n        self.temp_end = 0.5  # Adjusted final temperature for enhanced cooling\n        self.adaptive_factor = 0.94  # Slightly modified adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n        self.momentum = 0.5  # Introduced momentum-like factor for velocity update\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social + self.momentum * velocities[i-1]  # Momentum factor added\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature = max(self.temp_end, temperature * self.adaptive_factor)  # Dynamic cooling\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with dynamic adaptive cooling and momentum-like velocity update for improved convergence.", "configspace": "", "generation": 45, "fitness": 0.14412775528825406, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.16.", "error": "", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.29950756815886703, 0.29950756815886703, 0.29950756815886703, 0.2971723812222494, 0.2971723812222494, 0.2971723812222494, 0.3164738085502802, 0.3164738085502802, 0.3164738085502802, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07576426796356939, 0.07576426796356939, 0.07576426796356939, 0.07602486840714318, 0.07602486840714318, 0.07602486840714318, 0.047073340093840454, 0.047073340093840454, 0.047073340093840454, 0.056360897632621754, 0.056360897632621754, 0.056360897632621754, 0.05449901407076774, 0.05449901407076774, 0.05449901407076774, 0.02254823370043646, 0.02254823370043646, 0.02254823370043646, 0.09714454536800055, 0.09714454536800055, 0.09714454536800055, 0.9390685604346146, 0.9390685604346146, 0.9390685604346146, 0.8872604584995968, 0.8872604584995968, 0.8872604584995968, 0.0760041504820792, 0.0760041504820792, 0.0760041504820792, 0.09973639512756705, 0.09973639512756705, 0.09973639512756705, 0.07637781133425847, 0.07637781133425847, 0.07637781133425847, 0.18349322807973878, 0.18349322807973878, 0.18349322807973878, 0.16928924615478957, 0.16928924615478957, 0.16928924615478957, 0.18695482411610975, 0.18695482411610975, 0.18695482411610975, 0.06357754084885092, 0.06357754084885092, 0.06357754084885092, 0.021222194857600907, 0.021222194857600907, 0.021222194857600907, 0.06472986963897343, 0.06472986963897343, 0.06472986963897343, 0.07355517089160857, 0.07355517089160857, 0.07355517089160857, 0.06332890775212219, 0.06332890775212219, 0.06332890775212219, 0.047952088033486495, 0.047952088033486495, 0.047952088033486495, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.060601668043338, 0.060601668043338, 0.060601668043338, 0.0034539645097082516, 0.0034539645097082516, 0.0034539645097082516, 0.026106846147464946, 0.026106846147464946, 0.026106846147464946, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013208855406378839, 0.013208855406378839, 0.013208855406378839, 0.28018489181647954, 0.28018489181647954, 0.28018489181647954, 0.2917297814938513, 0.2917297814938513, 0.2917297814938513, 0.31072854477182843, 0.31072854477182843, 0.31072854477182843, 0.054327026574402804, 0.054327026574402804, 0.054327026574402804, 0.09366843354076759, 0.09366843354076759, 0.09366843354076759, 0.1016246593150445, 0.1016246593150445, 0.1016246593150445, 0.14858430981093118, 0.14858430981093118, 0.14858430981093118, 0.1297175269356925, 0.1297175269356925, 0.1297175269356925, 0.16020175062253916, 0.16020175062253916, 0.16020175062253916, 0.22786604759026263, 0.22786604759026263, 0.22786604759026263, 0.22612365403068302, 0.22612365403068302, 0.22612365403068302, 0.22856914541703355, 0.22856914541703355, 0.22856914541703355, 0.1445288603574827, 0.1445288603574827, 0.1445288603574827, 0.1617702482113227, 0.1617702482113227, 0.1617702482113227, 0.184111085158011, 0.184111085158011, 0.184111085158011, 0.2235144755334325, 0.2235144755334325, 0.2235144755334325, 0.1999455056706576, 0.1999455056706576, 0.1999455056706576, 0.21053791635636554, 0.21053791635636554, 0.21053791635636554, 0.13895989466269787, 0.13895989466269787, 0.13895989466269787, 0.16289517135838993, 0.16289517135838993, 0.16289517135838993, 0.14995960033354772, 0.14995960033354772, 0.14995960033354772, 0.33991348404485444, 0.33991348404485444, 0.33991348404485444, 0.18675789606933035, 0.18675789606933035, 0.18675789606933035, 0.35580413209100903, 0.35580413209100903, 0.35580413209100903, 0.14594070713433593, 0.14594070713433593, 0.14594070713433593, 0.1894174995351644, 0.1894174995351644, 0.1894174995351644, 0.1579417449920909, 0.1579417449920909, 0.1579417449920909, 0.18033900667831726, 0.18033900667831726, 0.18033900667831726, 0.17162065264457793, 0.17162065264457793, 0.17162065264457793, 0.16726385918547326, 0.16726385918547326, 0.16726385918547326, 0.07794437138042665, 0.07794437138042665, 0.07794437138042665, 0.09262215581382605, 0.09262215581382605, 0.09262215581382605, 0.08249363609739901, 0.08249363609739901, 0.08249363609739901]}, "mutation_prompt": null}
{"id": "8c2e73d8-8918-44a1-a068-c7bc8db21541", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with minor tuning in parameter values for improving convergence speed.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6731653111579229, 0.6731653111579229, 0.6731653111579229, 0.711996635129519, 0.711996635129519, 0.711996635129519, 0.7078132901593165, 0.7078132901593165, 0.7078132901593165, 0.041381141768779384, 0.041381141768779384, 0.041381141768779384, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10950771709447105, 0.10950771709447105, 0.10950771709447105, 0.10521185649440323, 0.10521185649440323, 0.10521185649440323, 0.10507361746539623, 0.10507361746539623, 0.10507361746539623, 0.07764468958329585, 0.07764468958329585, 0.07764468958329585, 0.09106825770888427, 0.09106825770888427, 0.09106825770888427, 0.11676664795008551, 0.11676664795008551, 0.11676664795008551, 0.8873949697611814, 0.8873949697611814, 0.8873949697611814, 0.8899603182064498, 0.8899603182064498, 0.8899603182064498, 0.9242514104464227, 0.9242514104464227, 0.9242514104464227, 0.15529290578465005, 0.15529290578465005, 0.15529290578465005, 0.2190096480227307, 0.2190096480227307, 0.2190096480227307, 0.10602395596155945, 0.10602395596155945, 0.10602395596155945, 0.6785064774824554, 0.6785064774824554, 0.6785064774824554, 0.1588220386151905, 0.1588220386151905, 0.1588220386151905, 0.2013731947684061, 0.2013731947684061, 0.2013731947684061, 0.11757177930520302, 0.11757177930520302, 0.11757177930520302, 0.05893689880031361, 0.05893689880031361, 0.05893689880031361, 0.1347567060589916, 0.1347567060589916, 0.1347567060589916, 0.12717657197932586, 0.12717657197932586, 0.12717657197932586, 0.13013401995367202, 0.13013401995367202, 0.13013401995367202, 0.12393529212556109, 0.12393529212556109, 0.12393529212556109, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07406251021116783, 0.07406251021116783, 0.07406251021116783, 0.06698612153091676, 0.06698612153091676, 0.06698612153091676, 0.08330193363389515, 0.08330193363389515, 0.08330193363389515, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05394537933586785, 0.05394537933586785, 0.05394537933586785, 0.06280509881780472, 0.06280509881780472, 0.06280509881780472, 0.058389177628910716, 0.058389177628910716, 0.058389177628910716, 0.4471312292357341, 0.4471312292357341, 0.4471312292357341, 0.5243508001071969, 0.5243508001071969, 0.5243508001071969, 0.46983387154224854, 0.46983387154224854, 0.46983387154224854, 0.07663158410172577, 0.07663158410172577, 0.07663158410172577, 0.10886105391076506, 0.10886105391076506, 0.10886105391076506, 0.1298840489061095, 0.1298840489061095, 0.1298840489061095, 0.1594612677021673, 0.1594612677021673, 0.1594612677021673, 0.2988572920911492, 0.2988572920911492, 0.2988572920911492, 0.24455433586052078, 0.24455433586052078, 0.24455433586052078, 0.35593401052672236, 0.35593401052672236, 0.35593401052672236, 0.41401688285636506, 0.41401688285636506, 0.41401688285636506, 0.23348098648385784, 0.23348098648385784, 0.23348098648385784, 0.25155973801749965, 0.25155973801749965, 0.25155973801749965, 0.16473215297233235, 0.16473215297233235, 0.16473215297233235, 0.2618969115729881, 0.2618969115729881, 0.2618969115729881, 0.21816177922955693, 0.21816177922955693, 0.21816177922955693, 0.19590613448642658, 0.19590613448642658, 0.19590613448642658, 0.24283886563718105, 0.24283886563718105, 0.24283886563718105, 0.18712908296437525, 0.18712908296437525, 0.18712908296437525, 0.16823242717066367, 0.16823242717066367, 0.16823242717066367, 0.19714396552649538, 0.19714396552649538, 0.19714396552649538, 0.7424295255090958, 0.7424295255090958, 0.7424295255090958, 0.16360281335132354, 0.16360281335132354, 0.16360281335132354, 0.7787233078953587, 0.7787233078953587, 0.7787233078953587, 0.6864379667833054, 0.6864379667833054, 0.6864379667833054, 0.20954767599706114, 0.20954767599706114, 0.20954767599706114, 0.5250107589216552, 0.5250107589216552, 0.5250107589216552, 0.1978655172067132, 0.1978655172067132, 0.1978655172067132, 0.16373718664922376, 0.16373718664922376, 0.16373718664922376, 0.195695680947217, 0.195695680947217, 0.195695680947217, 0.07529581943051489, 0.07529581943051489, 0.07529581943051489, 0.0742746602426343, 0.0742746602426343, 0.0742746602426343, 0.08423668137865226, 0.08423668137865226, 0.08423668137865226]}, "mutation_prompt": null}
{"id": "5c43729a-7e8a-4253-be3c-d3fead02176b", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with minor tuning in parameter values for improving convergence speed.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6731653111579229, 0.6731653111579229, 0.6731653111579229, 0.711996635129519, 0.711996635129519, 0.711996635129519, 0.7078132901593165, 0.7078132901593165, 0.7078132901593165, 0.041381141768779384, 0.041381141768779384, 0.041381141768779384, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10950771709447105, 0.10950771709447105, 0.10950771709447105, 0.10521185649440323, 0.10521185649440323, 0.10521185649440323, 0.10507361746539623, 0.10507361746539623, 0.10507361746539623, 0.07764468958329585, 0.07764468958329585, 0.07764468958329585, 0.09106825770888427, 0.09106825770888427, 0.09106825770888427, 0.11676664795008551, 0.11676664795008551, 0.11676664795008551, 0.8873949697611814, 0.8873949697611814, 0.8873949697611814, 0.8899603182064498, 0.8899603182064498, 0.8899603182064498, 0.9242514104464227, 0.9242514104464227, 0.9242514104464227, 0.15529290578465005, 0.15529290578465005, 0.15529290578465005, 0.2190096480227307, 0.2190096480227307, 0.2190096480227307, 0.10602395596155945, 0.10602395596155945, 0.10602395596155945, 0.6785064774824554, 0.6785064774824554, 0.6785064774824554, 0.1588220386151905, 0.1588220386151905, 0.1588220386151905, 0.2013731947684061, 0.2013731947684061, 0.2013731947684061, 0.11757177930520302, 0.11757177930520302, 0.11757177930520302, 0.05893689880031361, 0.05893689880031361, 0.05893689880031361, 0.1347567060589916, 0.1347567060589916, 0.1347567060589916, 0.12717657197932586, 0.12717657197932586, 0.12717657197932586, 0.13013401995367202, 0.13013401995367202, 0.13013401995367202, 0.12393529212556109, 0.12393529212556109, 0.12393529212556109, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07406251021116783, 0.07406251021116783, 0.07406251021116783, 0.06698612153091676, 0.06698612153091676, 0.06698612153091676, 0.08330193363389515, 0.08330193363389515, 0.08330193363389515, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05394537933586785, 0.05394537933586785, 0.05394537933586785, 0.06280509881780472, 0.06280509881780472, 0.06280509881780472, 0.058389177628910716, 0.058389177628910716, 0.058389177628910716, 0.4471312292357341, 0.4471312292357341, 0.4471312292357341, 0.5243508001071969, 0.5243508001071969, 0.5243508001071969, 0.46983387154224854, 0.46983387154224854, 0.46983387154224854, 0.07663158410172577, 0.07663158410172577, 0.07663158410172577, 0.10886105391076506, 0.10886105391076506, 0.10886105391076506, 0.1298840489061095, 0.1298840489061095, 0.1298840489061095, 0.1594612677021673, 0.1594612677021673, 0.1594612677021673, 0.2988572920911492, 0.2988572920911492, 0.2988572920911492, 0.24455433586052078, 0.24455433586052078, 0.24455433586052078, 0.35593401052672236, 0.35593401052672236, 0.35593401052672236, 0.41401688285636506, 0.41401688285636506, 0.41401688285636506, 0.23348098648385784, 0.23348098648385784, 0.23348098648385784, 0.25155973801749965, 0.25155973801749965, 0.25155973801749965, 0.16473215297233235, 0.16473215297233235, 0.16473215297233235, 0.2618969115729881, 0.2618969115729881, 0.2618969115729881, 0.21816177922955693, 0.21816177922955693, 0.21816177922955693, 0.19590613448642658, 0.19590613448642658, 0.19590613448642658, 0.24283886563718105, 0.24283886563718105, 0.24283886563718105, 0.18712908296437525, 0.18712908296437525, 0.18712908296437525, 0.16823242717066367, 0.16823242717066367, 0.16823242717066367, 0.19714396552649538, 0.19714396552649538, 0.19714396552649538, 0.7424295255090958, 0.7424295255090958, 0.7424295255090958, 0.16360281335132354, 0.16360281335132354, 0.16360281335132354, 0.7787233078953587, 0.7787233078953587, 0.7787233078953587, 0.6864379667833054, 0.6864379667833054, 0.6864379667833054, 0.20954767599706114, 0.20954767599706114, 0.20954767599706114, 0.5250107589216552, 0.5250107589216552, 0.5250107589216552, 0.1978655172067132, 0.1978655172067132, 0.1978655172067132, 0.16373718664922376, 0.16373718664922376, 0.16373718664922376, 0.195695680947217, 0.195695680947217, 0.195695680947217, 0.07529581943051489, 0.07529581943051489, 0.07529581943051489, 0.0742746602426343, 0.0742746602426343, 0.0742746602426343, 0.08423668137865226, 0.08423668137865226, 0.08423668137865226]}, "mutation_prompt": null}
{"id": "4803c81d-8a30-4e96-afc3-dc89a3483047", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with minor tuning in parameter values for improving convergence speed.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6731653111579229, 0.6731653111579229, 0.6731653111579229, 0.711996635129519, 0.711996635129519, 0.711996635129519, 0.7078132901593165, 0.7078132901593165, 0.7078132901593165, 0.041381141768779384, 0.041381141768779384, 0.041381141768779384, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10950771709447105, 0.10950771709447105, 0.10950771709447105, 0.10521185649440323, 0.10521185649440323, 0.10521185649440323, 0.10507361746539623, 0.10507361746539623, 0.10507361746539623, 0.07764468958329585, 0.07764468958329585, 0.07764468958329585, 0.09106825770888427, 0.09106825770888427, 0.09106825770888427, 0.11676664795008551, 0.11676664795008551, 0.11676664795008551, 0.8873949697611814, 0.8873949697611814, 0.8873949697611814, 0.8899603182064498, 0.8899603182064498, 0.8899603182064498, 0.9242514104464227, 0.9242514104464227, 0.9242514104464227, 0.15529290578465005, 0.15529290578465005, 0.15529290578465005, 0.2190096480227307, 0.2190096480227307, 0.2190096480227307, 0.10602395596155945, 0.10602395596155945, 0.10602395596155945, 0.6785064774824554, 0.6785064774824554, 0.6785064774824554, 0.1588220386151905, 0.1588220386151905, 0.1588220386151905, 0.2013731947684061, 0.2013731947684061, 0.2013731947684061, 0.11757177930520302, 0.11757177930520302, 0.11757177930520302, 0.05893689880031361, 0.05893689880031361, 0.05893689880031361, 0.1347567060589916, 0.1347567060589916, 0.1347567060589916, 0.12717657197932586, 0.12717657197932586, 0.12717657197932586, 0.13013401995367202, 0.13013401995367202, 0.13013401995367202, 0.12393529212556109, 0.12393529212556109, 0.12393529212556109, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07406251021116783, 0.07406251021116783, 0.07406251021116783, 0.06698612153091676, 0.06698612153091676, 0.06698612153091676, 0.08330193363389515, 0.08330193363389515, 0.08330193363389515, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05394537933586785, 0.05394537933586785, 0.05394537933586785, 0.06280509881780472, 0.06280509881780472, 0.06280509881780472, 0.058389177628910716, 0.058389177628910716, 0.058389177628910716, 0.4471312292357341, 0.4471312292357341, 0.4471312292357341, 0.5243508001071969, 0.5243508001071969, 0.5243508001071969, 0.46983387154224854, 0.46983387154224854, 0.46983387154224854, 0.07663158410172577, 0.07663158410172577, 0.07663158410172577, 0.10886105391076506, 0.10886105391076506, 0.10886105391076506, 0.1298840489061095, 0.1298840489061095, 0.1298840489061095, 0.1594612677021673, 0.1594612677021673, 0.1594612677021673, 0.2988572920911492, 0.2988572920911492, 0.2988572920911492, 0.24455433586052078, 0.24455433586052078, 0.24455433586052078, 0.35593401052672236, 0.35593401052672236, 0.35593401052672236, 0.41401688285636506, 0.41401688285636506, 0.41401688285636506, 0.23348098648385784, 0.23348098648385784, 0.23348098648385784, 0.25155973801749965, 0.25155973801749965, 0.25155973801749965, 0.16473215297233235, 0.16473215297233235, 0.16473215297233235, 0.2618969115729881, 0.2618969115729881, 0.2618969115729881, 0.21816177922955693, 0.21816177922955693, 0.21816177922955693, 0.19590613448642658, 0.19590613448642658, 0.19590613448642658, 0.24283886563718105, 0.24283886563718105, 0.24283886563718105, 0.18712908296437525, 0.18712908296437525, 0.18712908296437525, 0.16823242717066367, 0.16823242717066367, 0.16823242717066367, 0.19714396552649538, 0.19714396552649538, 0.19714396552649538, 0.7424295255090958, 0.7424295255090958, 0.7424295255090958, 0.16360281335132354, 0.16360281335132354, 0.16360281335132354, 0.7787233078953587, 0.7787233078953587, 0.7787233078953587, 0.6864379667833054, 0.6864379667833054, 0.6864379667833054, 0.20954767599706114, 0.20954767599706114, 0.20954767599706114, 0.5250107589216552, 0.5250107589216552, 0.5250107589216552, 0.1978655172067132, 0.1978655172067132, 0.1978655172067132, 0.16373718664922376, 0.16373718664922376, 0.16373718664922376, 0.195695680947217, 0.195695680947217, 0.195695680947217, 0.07529581943051489, 0.07529581943051489, 0.07529581943051489, 0.0742746602426343, 0.0742746602426343, 0.0742746602426343, 0.08423668137865226, 0.08423668137865226, 0.08423668137865226]}, "mutation_prompt": null}
{"id": "a14a20e1-0c60-4176-a6d1-6a6ec3a002ea", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with minor tuning in parameter values for improving convergence speed.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6731653111579229, 0.6731653111579229, 0.6731653111579229, 0.711996635129519, 0.711996635129519, 0.711996635129519, 0.7078132901593165, 0.7078132901593165, 0.7078132901593165, 0.041381141768779384, 0.041381141768779384, 0.041381141768779384, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10950771709447105, 0.10950771709447105, 0.10950771709447105, 0.10521185649440323, 0.10521185649440323, 0.10521185649440323, 0.10507361746539623, 0.10507361746539623, 0.10507361746539623, 0.07764468958329585, 0.07764468958329585, 0.07764468958329585, 0.09106825770888427, 0.09106825770888427, 0.09106825770888427, 0.11676664795008551, 0.11676664795008551, 0.11676664795008551, 0.8873949697611814, 0.8873949697611814, 0.8873949697611814, 0.8899603182064498, 0.8899603182064498, 0.8899603182064498, 0.9242514104464227, 0.9242514104464227, 0.9242514104464227, 0.15529290578465005, 0.15529290578465005, 0.15529290578465005, 0.2190096480227307, 0.2190096480227307, 0.2190096480227307, 0.10602395596155945, 0.10602395596155945, 0.10602395596155945, 0.6785064774824554, 0.6785064774824554, 0.6785064774824554, 0.1588220386151905, 0.1588220386151905, 0.1588220386151905, 0.2013731947684061, 0.2013731947684061, 0.2013731947684061, 0.11757177930520302, 0.11757177930520302, 0.11757177930520302, 0.05893689880031361, 0.05893689880031361, 0.05893689880031361, 0.1347567060589916, 0.1347567060589916, 0.1347567060589916, 0.12717657197932586, 0.12717657197932586, 0.12717657197932586, 0.13013401995367202, 0.13013401995367202, 0.13013401995367202, 0.12393529212556109, 0.12393529212556109, 0.12393529212556109, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07406251021116783, 0.07406251021116783, 0.07406251021116783, 0.06698612153091676, 0.06698612153091676, 0.06698612153091676, 0.08330193363389515, 0.08330193363389515, 0.08330193363389515, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05394537933586785, 0.05394537933586785, 0.05394537933586785, 0.06280509881780472, 0.06280509881780472, 0.06280509881780472, 0.058389177628910716, 0.058389177628910716, 0.058389177628910716, 0.4471312292357341, 0.4471312292357341, 0.4471312292357341, 0.5243508001071969, 0.5243508001071969, 0.5243508001071969, 0.46983387154224854, 0.46983387154224854, 0.46983387154224854, 0.07663158410172577, 0.07663158410172577, 0.07663158410172577, 0.10886105391076506, 0.10886105391076506, 0.10886105391076506, 0.1298840489061095, 0.1298840489061095, 0.1298840489061095, 0.1594612677021673, 0.1594612677021673, 0.1594612677021673, 0.2988572920911492, 0.2988572920911492, 0.2988572920911492, 0.24455433586052078, 0.24455433586052078, 0.24455433586052078, 0.35593401052672236, 0.35593401052672236, 0.35593401052672236, 0.41401688285636506, 0.41401688285636506, 0.41401688285636506, 0.23348098648385784, 0.23348098648385784, 0.23348098648385784, 0.25155973801749965, 0.25155973801749965, 0.25155973801749965, 0.16473215297233235, 0.16473215297233235, 0.16473215297233235, 0.2618969115729881, 0.2618969115729881, 0.2618969115729881, 0.21816177922955693, 0.21816177922955693, 0.21816177922955693, 0.19590613448642658, 0.19590613448642658, 0.19590613448642658, 0.24283886563718105, 0.24283886563718105, 0.24283886563718105, 0.18712908296437525, 0.18712908296437525, 0.18712908296437525, 0.16823242717066367, 0.16823242717066367, 0.16823242717066367, 0.19714396552649538, 0.19714396552649538, 0.19714396552649538, 0.7424295255090958, 0.7424295255090958, 0.7424295255090958, 0.16360281335132354, 0.16360281335132354, 0.16360281335132354, 0.7787233078953587, 0.7787233078953587, 0.7787233078953587, 0.6864379667833054, 0.6864379667833054, 0.6864379667833054, 0.20954767599706114, 0.20954767599706114, 0.20954767599706114, 0.5250107589216552, 0.5250107589216552, 0.5250107589216552, 0.1978655172067132, 0.1978655172067132, 0.1978655172067132, 0.16373718664922376, 0.16373718664922376, 0.16373718664922376, 0.195695680947217, 0.195695680947217, 0.195695680947217, 0.07529581943051489, 0.07529581943051489, 0.07529581943051489, 0.0742746602426343, 0.0742746602426343, 0.0742746602426343, 0.08423668137865226, 0.08423668137865226, 0.08423668137865226]}, "mutation_prompt": null}
{"id": "bf000ea1-3b6d-41cb-a483-bf88a528af47", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.9  # Dynamic inertia weight initialization\n        self.w_min = 0.4\n        self.w_max = 0.9\n        self.c1 = 1.7\n        self.c2 = 1.3\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                # Update dynamic inertia weight\n                self.w = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                # Crossover operation\n                if np.random.rand() < 0.1:\n                    parent = particles[np.random.randint(self.swarm_size)]\n                    crossover_point = np.random.randint(1, self.dim)\n                    proposed_position[:crossover_point] = parent[:crossover_point]\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Integrating a dynamic inertia weight strategy and crossover operation to enhance exploration and exploitation balance.", "configspace": "", "generation": 50, "fitness": 0.20206987400573168, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.20.", "error": "", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.5144336710427275, 0.5144336710427275, 0.5144336710427275, 0.446401254143581, 0.446401254143581, 0.446401254143581, 0.4708762070213166, 0.4708762070213166, 0.4708762070213166, 0.0019410135358693958, 0.0019410135358693958, 0.0019410135358693958, 0.02485461046711812, 0.02485461046711812, 0.02485461046711812, 0.01587482579894861, 0.01587482579894861, 0.01587482579894861, 0.10457209600136153, 0.10457209600136153, 0.10457209600136153, 0.08557425993122869, 0.08557425993122869, 0.08557425993122869, 0.08841405422422721, 0.08841405422422721, 0.08841405422422721, 0.06417464680020801, 0.06417464680020801, 0.06417464680020801, 0.08115683972561805, 0.08115683972561805, 0.08115683972561805, 0.08667930974848059, 0.08667930974848059, 0.08667930974848059, 0.8811181463516814, 0.8811181463516814, 0.8811181463516814, 0.8823879238526171, 0.8823879238526171, 0.8823879238526171, 0.908159138501046, 0.908159138501046, 0.908159138501046, 0.22759753435418195, 0.22759753435418195, 0.22759753435418195, 0.19022454747326156, 0.19022454747326156, 0.19022454747326156, 0.1683123320687926, 0.1683123320687926, 0.1683123320687926, 0.1983922307831224, 0.1983922307831224, 0.1983922307831224, 0.200691757744329, 0.200691757744329, 0.200691757744329, 0.21567012969639077, 0.21567012969639077, 0.21567012969639077, 0.11142437432997343, 0.11142437432997343, 0.11142437432997343, 0.08356157556643973, 0.08356157556643973, 0.08356157556643973, 0.06975413134633712, 0.06975413134633712, 0.06975413134633712, 0.08036546777683073, 0.08036546777683073, 0.08036546777683073, 0.10349261189389403, 0.10349261189389403, 0.10349261189389403, 0.08316791312849459, 0.08316791312849459, 0.08316791312849459, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10250183539394564, 0.10250183539394564, 0.10250183539394564, 0.049436130047003424, 0.049436130047003424, 0.049436130047003424, 0.035853052266141994, 0.035853052266141994, 0.035853052266141994, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.030387889832200754, 0.030387889832200754, 0.030387889832200754, 0.010771760702712907, 0.010771760702712907, 0.010771760702712907, 0.042619611881001274, 0.042619611881001274, 0.042619611881001274, 0.392155150122234, 0.392155150122234, 0.392155150122234, 0.3702419791977408, 0.3702419791977408, 0.3702419791977408, 0.4035022279206024, 0.4035022279206024, 0.4035022279206024, 0.07509150849872148, 0.07509150849872148, 0.07509150849872148, 0.09844286090044585, 0.09844286090044585, 0.09844286090044585, 0.09574248163557275, 0.09574248163557275, 0.09574248163557275, 0.16553169155129566, 0.16553169155129566, 0.16553169155129566, 0.18999082698960879, 0.18999082698960879, 0.18999082698960879, 0.17692901883916945, 0.17692901883916945, 0.17692901883916945, 0.27454817599935644, 0.27454817599935644, 0.27454817599935644, 0.2961092059653281, 0.2961092059653281, 0.2961092059653281, 0.2836126914827469, 0.2836126914827469, 0.2836126914827469, 0.19354948934269767, 0.19354948934269767, 0.19354948934269767, 0.24043341351082004, 0.24043341351082004, 0.24043341351082004, 0.2005259401891215, 0.2005259401891215, 0.2005259401891215, 0.2227483168729385, 0.2227483168729385, 0.2227483168729385, 0.20057832086968397, 0.20057832086968397, 0.20057832086968397, 0.2236388488573665, 0.2236388488573665, 0.2236388488573665, 0.1787955953026118, 0.1787955953026118, 0.1787955953026118, 0.1800056304359432, 0.1800056304359432, 0.1800056304359432, 0.16085206495559667, 0.16085206495559667, 0.16085206495559667, 0.5911667005064005, 0.5911667005064005, 0.5911667005064005, 0.15515061162359156, 0.15515061162359156, 0.15515061162359156, 0.618690508141639, 0.618690508141639, 0.618690508141639, 0.533482637911237, 0.533482637911237, 0.533482637911237, 0.19974644596887192, 0.19974644596887192, 0.19974644596887192, 0.3777187700017218, 0.3777187700017218, 0.3777187700017218, 0.1628124462100743, 0.1628124462100743, 0.1628124462100743, 0.18197234634992154, 0.18197234634992154, 0.18197234634992154, 0.18282353793085127, 0.18282353793085127, 0.18282353793085127, 0.0893970042208646, 0.0893970042208646, 0.0893970042208646, 0.08552537452068787, 0.08552537452068787, 0.08552537452068787, 0.08607622215613264, 0.08607622215613264, 0.08607622215613264]}, "mutation_prompt": null}
{"id": "6382df85-7583-4061-ab12-bb116ea37e4d", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2 = 1.3\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = np.copy(particles[i])\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = np.copy(proposed_position)\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = np.copy(proposed_position)\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n            if evaluations % (self.budget // 10) == 0:  # Adaptive learning coefficients adjustment\n                self.c1 *= 0.95\n                self.c2 *= 1.05\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Hybrid PSO-SA optimizer with adaptive learning coefficients for improved exploration-exploitation balance.", "configspace": "", "generation": 51, "fitness": 0.22971652689868374, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.24.", "error": "", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.7745181258271263, 0.7745181258271263, 0.7745181258271263, 0.754218945081194, 0.754218945081194, 0.754218945081194, 0.7623889919019312, 0.7623889919019312, 0.7623889919019312, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0001839394486939927, 0.0001839394486939927, 0.0001839394486939927, 0.12230419164311657, 0.12230419164311657, 0.12230419164311657, 0.1099186142971037, 0.1099186142971037, 0.1099186142971037, 0.10791309507092939, 0.10791309507092939, 0.10791309507092939, 0.07027025686062949, 0.07027025686062949, 0.07027025686062949, 0.054993981420276894, 0.054993981420276894, 0.054993981420276894, 0.06997473140533295, 0.06997473140533295, 0.06997473140533295, 0.8532397888956942, 0.8532397888956942, 0.8532397888956942, 0.8826202847123042, 0.8826202847123042, 0.8826202847123042, 0.8803602422814292, 0.8803602422814292, 0.8803602422814292, 0.0546274781039372, 0.0546274781039372, 0.0546274781039372, 0.12744366559296827, 0.12744366559296827, 0.12744366559296827, 0.17495858878691128, 0.17495858878691128, 0.17495858878691128, 0.16518530923099606, 0.16518530923099606, 0.16518530923099606, 0.18366025337142722, 0.18366025337142722, 0.18366025337142722, 0.22375730508728364, 0.22375730508728364, 0.22375730508728364, 0.10638064053960083, 0.10638064053960083, 0.10638064053960083, 0.18413756062650677, 0.18413756062650677, 0.18413756062650677, 0.027136922715770395, 0.027136922715770395, 0.027136922715770395, 0.03259479122550546, 0.03259479122550546, 0.03259479122550546, 0.1314045193996426, 0.1314045193996426, 0.1314045193996426, 0.14064887028676787, 0.14064887028676787, 0.14064887028676787, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.004937811631280042, 0.004937811631280042, 0.004937811631280042, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0642638266742499, 0.0642638266742499, 0.0642638266742499, 0.05813349605321727, 0.05813349605321727, 0.05813349605321727, 0.057324613262080826, 0.057324613262080826, 0.057324613262080826, 0.06794915517095179, 0.06794915517095179, 0.06794915517095179, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09293725926202767, 0.09293725926202767, 0.09293725926202767, 0.048637650278308686, 0.048637650278308686, 0.048637650278308686, 0.0645863158772636, 0.0645863158772636, 0.0645863158772636, 0.507282901854393, 0.507282901854393, 0.507282901854393, 0.5337985801500273, 0.5337985801500273, 0.5337985801500273, 0.5601991156507744, 0.5601991156507744, 0.5601991156507744, 0.12015790423007033, 0.12015790423007033, 0.12015790423007033, 0.0987989225598016, 0.0987989225598016, 0.0987989225598016, 0.12846508884867014, 0.12846508884867014, 0.12846508884867014, 0.20177892585122037, 0.20177892585122037, 0.20177892585122037, 0.2154714031658851, 0.2154714031658851, 0.2154714031658851, 0.2367250991557872, 0.2367250991557872, 0.2367250991557872, 0.3171285676612513, 0.3171285676612513, 0.3171285676612513, 0.3598896512248241, 0.3598896512248241, 0.3598896512248241, 0.40979281446749705, 0.40979281446749705, 0.40979281446749705, 0.2921620243596388, 0.2921620243596388, 0.2921620243596388, 0.19277766198629376, 0.19277766198629376, 0.19277766198629376, 0.29722116193340475, 0.29722116193340475, 0.29722116193340475, 0.2112493927699165, 0.2112493927699165, 0.2112493927699165, 0.23452517767029124, 0.23452517767029124, 0.23452517767029124, 0.20854914173912065, 0.20854914173912065, 0.20854914173912065, 0.18217914862153717, 0.18217914862153717, 0.18217914862153717, 0.18616117626046635, 0.18616117626046635, 0.18616117626046635, 0.17658776902720386, 0.17658776902720386, 0.17658776902720386, 0.8111878223567316, 0.8111878223567316, 0.8111878223567316, 0.16388025540761209, 0.16388025540761209, 0.16388025540761209, 0.8037063641306291, 0.8037063641306291, 0.8037063641306291, 0.4449479217252611, 0.4449479217252611, 0.4449479217252611, 0.2076945930588242, 0.2076945930588242, 0.2076945930588242, 0.15452052064032518, 0.15452052064032518, 0.15452052064032518, 0.18451998198963315, 0.18451998198963315, 0.18451998198963315, 0.22217734188931804, 0.22217734188931804, 0.22217734188931804, 0.18027445012937116, 0.18027445012937116, 0.18027445012937116, 0.07729711070453937, 0.07729711070453937, 0.07729711070453937, 0.08512515142804822, 0.08512515142804822, 0.08512515142804822, 0.07914557203440165, 0.07914557203440165, 0.07914557203440165]}, "mutation_prompt": null}
{"id": "683a4ee1-674a-4060-afe7-efef83813e55", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with minor tuning in parameter values for improving convergence speed.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6731653111579229, 0.6731653111579229, 0.6731653111579229, 0.711996635129519, 0.711996635129519, 0.711996635129519, 0.7078132901593165, 0.7078132901593165, 0.7078132901593165, 0.041381141768779384, 0.041381141768779384, 0.041381141768779384, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10950771709447105, 0.10950771709447105, 0.10950771709447105, 0.10521185649440323, 0.10521185649440323, 0.10521185649440323, 0.10507361746539623, 0.10507361746539623, 0.10507361746539623, 0.07764468958329585, 0.07764468958329585, 0.07764468958329585, 0.09106825770888427, 0.09106825770888427, 0.09106825770888427, 0.11676664795008551, 0.11676664795008551, 0.11676664795008551, 0.8873949697611814, 0.8873949697611814, 0.8873949697611814, 0.8899603182064498, 0.8899603182064498, 0.8899603182064498, 0.9242514104464227, 0.9242514104464227, 0.9242514104464227, 0.15529290578465005, 0.15529290578465005, 0.15529290578465005, 0.2190096480227307, 0.2190096480227307, 0.2190096480227307, 0.10602395596155945, 0.10602395596155945, 0.10602395596155945, 0.6785064774824554, 0.6785064774824554, 0.6785064774824554, 0.1588220386151905, 0.1588220386151905, 0.1588220386151905, 0.2013731947684061, 0.2013731947684061, 0.2013731947684061, 0.11757177930520302, 0.11757177930520302, 0.11757177930520302, 0.05893689880031361, 0.05893689880031361, 0.05893689880031361, 0.1347567060589916, 0.1347567060589916, 0.1347567060589916, 0.12717657197932586, 0.12717657197932586, 0.12717657197932586, 0.13013401995367202, 0.13013401995367202, 0.13013401995367202, 0.12393529212556109, 0.12393529212556109, 0.12393529212556109, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07406251021116783, 0.07406251021116783, 0.07406251021116783, 0.06698612153091676, 0.06698612153091676, 0.06698612153091676, 0.08330193363389515, 0.08330193363389515, 0.08330193363389515, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05394537933586785, 0.05394537933586785, 0.05394537933586785, 0.06280509881780472, 0.06280509881780472, 0.06280509881780472, 0.058389177628910716, 0.058389177628910716, 0.058389177628910716, 0.4471312292357341, 0.4471312292357341, 0.4471312292357341, 0.5243508001071969, 0.5243508001071969, 0.5243508001071969, 0.46983387154224854, 0.46983387154224854, 0.46983387154224854, 0.07663158410172577, 0.07663158410172577, 0.07663158410172577, 0.10886105391076506, 0.10886105391076506, 0.10886105391076506, 0.1298840489061095, 0.1298840489061095, 0.1298840489061095, 0.1594612677021673, 0.1594612677021673, 0.1594612677021673, 0.2988572920911492, 0.2988572920911492, 0.2988572920911492, 0.24455433586052078, 0.24455433586052078, 0.24455433586052078, 0.35593401052672236, 0.35593401052672236, 0.35593401052672236, 0.41401688285636506, 0.41401688285636506, 0.41401688285636506, 0.23348098648385784, 0.23348098648385784, 0.23348098648385784, 0.25155973801749965, 0.25155973801749965, 0.25155973801749965, 0.16473215297233235, 0.16473215297233235, 0.16473215297233235, 0.2618969115729881, 0.2618969115729881, 0.2618969115729881, 0.21816177922955693, 0.21816177922955693, 0.21816177922955693, 0.19590613448642658, 0.19590613448642658, 0.19590613448642658, 0.24283886563718105, 0.24283886563718105, 0.24283886563718105, 0.18712908296437525, 0.18712908296437525, 0.18712908296437525, 0.16823242717066367, 0.16823242717066367, 0.16823242717066367, 0.19714396552649538, 0.19714396552649538, 0.19714396552649538, 0.7424295255090958, 0.7424295255090958, 0.7424295255090958, 0.16360281335132354, 0.16360281335132354, 0.16360281335132354, 0.7787233078953587, 0.7787233078953587, 0.7787233078953587, 0.6864379667833054, 0.6864379667833054, 0.6864379667833054, 0.20954767599706114, 0.20954767599706114, 0.20954767599706114, 0.5250107589216552, 0.5250107589216552, 0.5250107589216552, 0.1978655172067132, 0.1978655172067132, 0.1978655172067132, 0.16373718664922376, 0.16373718664922376, 0.16373718664922376, 0.195695680947217, 0.195695680947217, 0.195695680947217, 0.07529581943051489, 0.07529581943051489, 0.07529581943051489, 0.0742746602426343, 0.0742746602426343, 0.0742746602426343, 0.08423668137865226, 0.08423668137865226, 0.08423668137865226]}, "mutation_prompt": null}
{"id": "96364b75-546e-485e-9cd6-cacf256f6b88", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with minor tuning in parameter values for improving convergence speed.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6731653111579229, 0.6731653111579229, 0.6731653111579229, 0.711996635129519, 0.711996635129519, 0.711996635129519, 0.7078132901593165, 0.7078132901593165, 0.7078132901593165, 0.041381141768779384, 0.041381141768779384, 0.041381141768779384, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10950771709447105, 0.10950771709447105, 0.10950771709447105, 0.10521185649440323, 0.10521185649440323, 0.10521185649440323, 0.10507361746539623, 0.10507361746539623, 0.10507361746539623, 0.07764468958329585, 0.07764468958329585, 0.07764468958329585, 0.09106825770888427, 0.09106825770888427, 0.09106825770888427, 0.11676664795008551, 0.11676664795008551, 0.11676664795008551, 0.8873949697611814, 0.8873949697611814, 0.8873949697611814, 0.8899603182064498, 0.8899603182064498, 0.8899603182064498, 0.9242514104464227, 0.9242514104464227, 0.9242514104464227, 0.15529290578465005, 0.15529290578465005, 0.15529290578465005, 0.2190096480227307, 0.2190096480227307, 0.2190096480227307, 0.10602395596155945, 0.10602395596155945, 0.10602395596155945, 0.6785064774824554, 0.6785064774824554, 0.6785064774824554, 0.1588220386151905, 0.1588220386151905, 0.1588220386151905, 0.2013731947684061, 0.2013731947684061, 0.2013731947684061, 0.11757177930520302, 0.11757177930520302, 0.11757177930520302, 0.05893689880031361, 0.05893689880031361, 0.05893689880031361, 0.1347567060589916, 0.1347567060589916, 0.1347567060589916, 0.12717657197932586, 0.12717657197932586, 0.12717657197932586, 0.13013401995367202, 0.13013401995367202, 0.13013401995367202, 0.12393529212556109, 0.12393529212556109, 0.12393529212556109, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07406251021116783, 0.07406251021116783, 0.07406251021116783, 0.06698612153091676, 0.06698612153091676, 0.06698612153091676, 0.08330193363389515, 0.08330193363389515, 0.08330193363389515, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05394537933586785, 0.05394537933586785, 0.05394537933586785, 0.06280509881780472, 0.06280509881780472, 0.06280509881780472, 0.058389177628910716, 0.058389177628910716, 0.058389177628910716, 0.4471312292357341, 0.4471312292357341, 0.4471312292357341, 0.5243508001071969, 0.5243508001071969, 0.5243508001071969, 0.46983387154224854, 0.46983387154224854, 0.46983387154224854, 0.07663158410172577, 0.07663158410172577, 0.07663158410172577, 0.10886105391076506, 0.10886105391076506, 0.10886105391076506, 0.1298840489061095, 0.1298840489061095, 0.1298840489061095, 0.1594612677021673, 0.1594612677021673, 0.1594612677021673, 0.2988572920911492, 0.2988572920911492, 0.2988572920911492, 0.24455433586052078, 0.24455433586052078, 0.24455433586052078, 0.35593401052672236, 0.35593401052672236, 0.35593401052672236, 0.41401688285636506, 0.41401688285636506, 0.41401688285636506, 0.23348098648385784, 0.23348098648385784, 0.23348098648385784, 0.25155973801749965, 0.25155973801749965, 0.25155973801749965, 0.16473215297233235, 0.16473215297233235, 0.16473215297233235, 0.2618969115729881, 0.2618969115729881, 0.2618969115729881, 0.21816177922955693, 0.21816177922955693, 0.21816177922955693, 0.19590613448642658, 0.19590613448642658, 0.19590613448642658, 0.24283886563718105, 0.24283886563718105, 0.24283886563718105, 0.18712908296437525, 0.18712908296437525, 0.18712908296437525, 0.16823242717066367, 0.16823242717066367, 0.16823242717066367, 0.19714396552649538, 0.19714396552649538, 0.19714396552649538, 0.7424295255090958, 0.7424295255090958, 0.7424295255090958, 0.16360281335132354, 0.16360281335132354, 0.16360281335132354, 0.7787233078953587, 0.7787233078953587, 0.7787233078953587, 0.6864379667833054, 0.6864379667833054, 0.6864379667833054, 0.20954767599706114, 0.20954767599706114, 0.20954767599706114, 0.5250107589216552, 0.5250107589216552, 0.5250107589216552, 0.1978655172067132, 0.1978655172067132, 0.1978655172067132, 0.16373718664922376, 0.16373718664922376, 0.16373718664922376, 0.195695680947217, 0.195695680947217, 0.195695680947217, 0.07529581943051489, 0.07529581943051489, 0.07529581943051489, 0.0742746602426343, 0.0742746602426343, 0.0742746602426343, 0.08423668137865226, 0.08423668137865226, 0.08423668137865226]}, "mutation_prompt": null}
{"id": "825189c6-9f00-4687-be72-b92596f73d29", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with minor tuning in parameter values for improving convergence speed.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6731653111579229, 0.6731653111579229, 0.6731653111579229, 0.711996635129519, 0.711996635129519, 0.711996635129519, 0.7078132901593165, 0.7078132901593165, 0.7078132901593165, 0.041381141768779384, 0.041381141768779384, 0.041381141768779384, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10950771709447105, 0.10950771709447105, 0.10950771709447105, 0.10521185649440323, 0.10521185649440323, 0.10521185649440323, 0.10507361746539623, 0.10507361746539623, 0.10507361746539623, 0.07764468958329585, 0.07764468958329585, 0.07764468958329585, 0.09106825770888427, 0.09106825770888427, 0.09106825770888427, 0.11676664795008551, 0.11676664795008551, 0.11676664795008551, 0.8873949697611814, 0.8873949697611814, 0.8873949697611814, 0.8899603182064498, 0.8899603182064498, 0.8899603182064498, 0.9242514104464227, 0.9242514104464227, 0.9242514104464227, 0.15529290578465005, 0.15529290578465005, 0.15529290578465005, 0.2190096480227307, 0.2190096480227307, 0.2190096480227307, 0.10602395596155945, 0.10602395596155945, 0.10602395596155945, 0.6785064774824554, 0.6785064774824554, 0.6785064774824554, 0.1588220386151905, 0.1588220386151905, 0.1588220386151905, 0.2013731947684061, 0.2013731947684061, 0.2013731947684061, 0.11757177930520302, 0.11757177930520302, 0.11757177930520302, 0.05893689880031361, 0.05893689880031361, 0.05893689880031361, 0.1347567060589916, 0.1347567060589916, 0.1347567060589916, 0.12717657197932586, 0.12717657197932586, 0.12717657197932586, 0.13013401995367202, 0.13013401995367202, 0.13013401995367202, 0.12393529212556109, 0.12393529212556109, 0.12393529212556109, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07406251021116783, 0.07406251021116783, 0.07406251021116783, 0.06698612153091676, 0.06698612153091676, 0.06698612153091676, 0.08330193363389515, 0.08330193363389515, 0.08330193363389515, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05394537933586785, 0.05394537933586785, 0.05394537933586785, 0.06280509881780472, 0.06280509881780472, 0.06280509881780472, 0.058389177628910716, 0.058389177628910716, 0.058389177628910716, 0.4471312292357341, 0.4471312292357341, 0.4471312292357341, 0.5243508001071969, 0.5243508001071969, 0.5243508001071969, 0.46983387154224854, 0.46983387154224854, 0.46983387154224854, 0.07663158410172577, 0.07663158410172577, 0.07663158410172577, 0.10886105391076506, 0.10886105391076506, 0.10886105391076506, 0.1298840489061095, 0.1298840489061095, 0.1298840489061095, 0.1594612677021673, 0.1594612677021673, 0.1594612677021673, 0.2988572920911492, 0.2988572920911492, 0.2988572920911492, 0.24455433586052078, 0.24455433586052078, 0.24455433586052078, 0.35593401052672236, 0.35593401052672236, 0.35593401052672236, 0.41401688285636506, 0.41401688285636506, 0.41401688285636506, 0.23348098648385784, 0.23348098648385784, 0.23348098648385784, 0.25155973801749965, 0.25155973801749965, 0.25155973801749965, 0.16473215297233235, 0.16473215297233235, 0.16473215297233235, 0.2618969115729881, 0.2618969115729881, 0.2618969115729881, 0.21816177922955693, 0.21816177922955693, 0.21816177922955693, 0.19590613448642658, 0.19590613448642658, 0.19590613448642658, 0.24283886563718105, 0.24283886563718105, 0.24283886563718105, 0.18712908296437525, 0.18712908296437525, 0.18712908296437525, 0.16823242717066367, 0.16823242717066367, 0.16823242717066367, 0.19714396552649538, 0.19714396552649538, 0.19714396552649538, 0.7424295255090958, 0.7424295255090958, 0.7424295255090958, 0.16360281335132354, 0.16360281335132354, 0.16360281335132354, 0.7787233078953587, 0.7787233078953587, 0.7787233078953587, 0.6864379667833054, 0.6864379667833054, 0.6864379667833054, 0.20954767599706114, 0.20954767599706114, 0.20954767599706114, 0.5250107589216552, 0.5250107589216552, 0.5250107589216552, 0.1978655172067132, 0.1978655172067132, 0.1978655172067132, 0.16373718664922376, 0.16373718664922376, 0.16373718664922376, 0.195695680947217, 0.195695680947217, 0.195695680947217, 0.07529581943051489, 0.07529581943051489, 0.07529581943051489, 0.0742746602426343, 0.0742746602426343, 0.0742746602426343, 0.08423668137865226, 0.08423668137865226, 0.08423668137865226]}, "mutation_prompt": null}
{"id": "8e82e368-3a09-4cb1-99b9-4d24b6af89fe", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with minor tuning in parameter values for improving convergence speed.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6731653111579229, 0.6731653111579229, 0.6731653111579229, 0.711996635129519, 0.711996635129519, 0.711996635129519, 0.7078132901593165, 0.7078132901593165, 0.7078132901593165, 0.041381141768779384, 0.041381141768779384, 0.041381141768779384, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10950771709447105, 0.10950771709447105, 0.10950771709447105, 0.10521185649440323, 0.10521185649440323, 0.10521185649440323, 0.10507361746539623, 0.10507361746539623, 0.10507361746539623, 0.07764468958329585, 0.07764468958329585, 0.07764468958329585, 0.09106825770888427, 0.09106825770888427, 0.09106825770888427, 0.11676664795008551, 0.11676664795008551, 0.11676664795008551, 0.8873949697611814, 0.8873949697611814, 0.8873949697611814, 0.8899603182064498, 0.8899603182064498, 0.8899603182064498, 0.9242514104464227, 0.9242514104464227, 0.9242514104464227, 0.15529290578465005, 0.15529290578465005, 0.15529290578465005, 0.2190096480227307, 0.2190096480227307, 0.2190096480227307, 0.10602395596155945, 0.10602395596155945, 0.10602395596155945, 0.6785064774824554, 0.6785064774824554, 0.6785064774824554, 0.1588220386151905, 0.1588220386151905, 0.1588220386151905, 0.2013731947684061, 0.2013731947684061, 0.2013731947684061, 0.11757177930520302, 0.11757177930520302, 0.11757177930520302, 0.05893689880031361, 0.05893689880031361, 0.05893689880031361, 0.1347567060589916, 0.1347567060589916, 0.1347567060589916, 0.12717657197932586, 0.12717657197932586, 0.12717657197932586, 0.13013401995367202, 0.13013401995367202, 0.13013401995367202, 0.12393529212556109, 0.12393529212556109, 0.12393529212556109, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07406251021116783, 0.07406251021116783, 0.07406251021116783, 0.06698612153091676, 0.06698612153091676, 0.06698612153091676, 0.08330193363389515, 0.08330193363389515, 0.08330193363389515, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05394537933586785, 0.05394537933586785, 0.05394537933586785, 0.06280509881780472, 0.06280509881780472, 0.06280509881780472, 0.058389177628910716, 0.058389177628910716, 0.058389177628910716, 0.4471312292357341, 0.4471312292357341, 0.4471312292357341, 0.5243508001071969, 0.5243508001071969, 0.5243508001071969, 0.46983387154224854, 0.46983387154224854, 0.46983387154224854, 0.07663158410172577, 0.07663158410172577, 0.07663158410172577, 0.10886105391076506, 0.10886105391076506, 0.10886105391076506, 0.1298840489061095, 0.1298840489061095, 0.1298840489061095, 0.1594612677021673, 0.1594612677021673, 0.1594612677021673, 0.2988572920911492, 0.2988572920911492, 0.2988572920911492, 0.24455433586052078, 0.24455433586052078, 0.24455433586052078, 0.35593401052672236, 0.35593401052672236, 0.35593401052672236, 0.41401688285636506, 0.41401688285636506, 0.41401688285636506, 0.23348098648385784, 0.23348098648385784, 0.23348098648385784, 0.25155973801749965, 0.25155973801749965, 0.25155973801749965, 0.16473215297233235, 0.16473215297233235, 0.16473215297233235, 0.2618969115729881, 0.2618969115729881, 0.2618969115729881, 0.21816177922955693, 0.21816177922955693, 0.21816177922955693, 0.19590613448642658, 0.19590613448642658, 0.19590613448642658, 0.24283886563718105, 0.24283886563718105, 0.24283886563718105, 0.18712908296437525, 0.18712908296437525, 0.18712908296437525, 0.16823242717066367, 0.16823242717066367, 0.16823242717066367, 0.19714396552649538, 0.19714396552649538, 0.19714396552649538, 0.7424295255090958, 0.7424295255090958, 0.7424295255090958, 0.16360281335132354, 0.16360281335132354, 0.16360281335132354, 0.7787233078953587, 0.7787233078953587, 0.7787233078953587, 0.6864379667833054, 0.6864379667833054, 0.6864379667833054, 0.20954767599706114, 0.20954767599706114, 0.20954767599706114, 0.5250107589216552, 0.5250107589216552, 0.5250107589216552, 0.1978655172067132, 0.1978655172067132, 0.1978655172067132, 0.16373718664922376, 0.16373718664922376, 0.16373718664922376, 0.195695680947217, 0.195695680947217, 0.195695680947217, 0.07529581943051489, 0.07529581943051489, 0.07529581943051489, 0.0742746602426343, 0.0742746602426343, 0.0742746602426343, 0.08423668137865226, 0.08423668137865226, 0.08423668137865226]}, "mutation_prompt": null}
{"id": "0d997c54-95a2-428c-8891-c11181aa7d47", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2 = 1.3\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n        # Added learning rate factor for velocity adjustment\n        self.learning_rate = 0.05\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                # Modified velocity update with learning rate factor\n                velocities[i] = inertia + self.learning_rate * (cognitive + social)\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "PSO-SA optimizer with modified velocity update using dynamic adjustment for convergence and exploration balance.", "configspace": "", "generation": 56, "fitness": 0.09446708189231932, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.08.", "error": "", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.355288120089719, 0.355288120089719, 0.355288120089719, 0.18370596014698204, 0.18370596014698204, 0.18370596014698204, 0.18179557773252286, 0.18179557773252286, 0.18179557773252286, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.047787006637652674, 0.047787006637652674, 0.047787006637652674, 0.105714202808452, 0.105714202808452, 0.105714202808452, 0.05520570037694017, 0.05520570037694017, 0.05520570037694017, 0.04559991725726564, 0.04559991725726564, 0.04559991725726564, 0.025460752899198802, 0.025460752899198802, 0.025460752899198802, 0.047097204295244555, 0.047097204295244555, 0.047097204295244555, 0.06152370484037406, 0.06152370484037406, 0.06152370484037406, 0.09089675550319354, 0.09089675550319354, 0.09089675550319354, 0.09660761551987485, 0.09660761551987485, 0.09660761551987485, 0.03556746358498586, 0.03556746358498586, 0.03556746358498586, 0.06232556530389488, 0.06232556530389488, 0.06232556530389488, 0.05868251775702049, 0.05868251775702049, 0.05868251775702049, 0.09287327126675737, 0.09287327126675737, 0.09287327126675737, 0.12139851004925983, 0.12139851004925983, 0.12139851004925983, 0.14005335396732188, 0.14005335396732188, 0.14005335396732188, 0.0001918928245033813, 0.0001918928245033813, 0.0001918928245033813, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.040979627706106636, 0.040979627706106636, 0.040979627706106636, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06711551459323506, 0.06711551459323506, 0.06711551459323506, 0.027426163844283313, 0.027426163844283313, 0.027426163844283313, 0.0623712439069839, 0.0623712439069839, 0.0623712439069839, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.24548650471756295, 0.24548650471756295, 0.24548650471756295, 0.21424899269759157, 0.21424899269759157, 0.21424899269759157, 0.25343190126821113, 0.25343190126821113, 0.25343190126821113, 0.09346771410132493, 0.09346771410132493, 0.09346771410132493, 0.08439452812944237, 0.08439452812944237, 0.08439452812944237, 0.06164183839112758, 0.06164183839112758, 0.06164183839112758, 0.1145892567419613, 0.1145892567419613, 0.1145892567419613, 0.09580271302117327, 0.09580271302117327, 0.09580271302117327, 0.12725076100413857, 0.12725076100413857, 0.12725076100413857, 0.21765437833456414, 0.21765437833456414, 0.21765437833456414, 0.1978136151261427, 0.1978136151261427, 0.1978136151261427, 0.17866533541480534, 0.17866533541480534, 0.17866533541480534, 0.16090003844819967, 0.16090003844819967, 0.16090003844819967, 0.1440995176929638, 0.1440995176929638, 0.1440995176929638, 0.09817975770172416, 0.09817975770172416, 0.09817975770172416, 0.22774548784256987, 0.22774548784256987, 0.22774548784256987, 0.2001835848203627, 0.2001835848203627, 0.2001835848203627, 0.17904450777491443, 0.17904450777491443, 0.17904450777491443, 0.12926501696252946, 0.12926501696252946, 0.12926501696252946, 0.14955970184773726, 0.14955970184773726, 0.14955970184773726, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.16396855407660327, 0.16396855407660327, 0.16396855407660327, 0.09640604158836263, 0.09640604158836263, 0.09640604158836263, 0.14085464503373768, 0.14085464503373768, 0.14085464503373768, 0.19226092908154813, 0.19226092908154813, 0.19226092908154813, 0.1532276722132596, 0.1532276722132596, 0.1532276722132596, 0.12189482427463227, 0.12189482427463227, 0.12189482427463227, 0.1758451858384671, 0.1758451858384671, 0.1758451858384671, 0.1703562845197344, 0.1703562845197344, 0.1703562845197344, 0.1734236612437049, 0.1734236612437049, 0.1734236612437049, 0.0908123742424859, 0.0908123742424859, 0.0908123742424859, 0.07679783561248132, 0.07679783561248132, 0.07679783561248132, 0.0649890935711539, 0.0649890935711539, 0.0649890935711539]}, "mutation_prompt": null}
{"id": "8e1ac3ec-f81c-4f45-af1c-6d01f05aa11c", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n        self.vel_adapt_factor = 0.1  # Added velocity adaptation factor\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                # Dynamic velocity adaptation\n                velocities[i] += self.vel_adapt_factor * np.random.randn(self.dim)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "A slightly enhanced PSO-SA algorithm incorporating dynamic velocity adaptation for improved convergence.", "configspace": "", "generation": 57, "fitness": 0.19139318382735482, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.19.", "error": "", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.36234860205470776, 0.36234860205470776, 0.36234860205470776, 0.3706970754853731, 0.3706970754853731, 0.3706970754853731, 0.3812160300720968, 0.3812160300720968, 0.3812160300720968, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09614308491843471, 0.09614308491843471, 0.09614308491843471, 0.09058700767114258, 0.09058700767114258, 0.09058700767114258, 0.10099066179499061, 0.10099066179499061, 0.10099066179499061, 0.07426104452576221, 0.07426104452576221, 0.07426104452576221, 0.04881993036731491, 0.04881993036731491, 0.04881993036731491, 0.07277208312706229, 0.07277208312706229, 0.07277208312706229, 0.880556924219025, 0.880556924219025, 0.880556924219025, 0.9221769406015902, 0.9221769406015902, 0.9221769406015902, 0.9243662184583725, 0.9243662184583725, 0.9243662184583725, 0.14090295665337038, 0.14090295665337038, 0.14090295665337038, 0.21089292572389906, 0.21089292572389906, 0.21089292572389906, 0.20045071023603755, 0.20045071023603755, 0.20045071023603755, 0.1940620021042998, 0.1940620021042998, 0.1940620021042998, 0.28731596496286405, 0.28731596496286405, 0.28731596496286405, 0.21817270273211609, 0.21817270273211609, 0.21817270273211609, 0.12337645579686307, 0.12337645579686307, 0.12337645579686307, 0.08847160431239176, 0.08847160431239176, 0.08847160431239176, 0.1164302152218426, 0.1164302152218426, 0.1164302152218426, 0.08817324153496997, 0.08817324153496997, 0.08817324153496997, 0.1267192058301092, 0.1267192058301092, 0.1267192058301092, 0.11478849734319174, 0.11478849734319174, 0.11478849734319174, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0073268737465401745, 0.0073268737465401745, 0.0073268737465401745, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07530093775219338, 0.07530093775219338, 0.07530093775219338, 0.053526817868213006, 0.053526817868213006, 0.053526817868213006, 0.05695864839885145, 0.05695864839885145, 0.05695864839885145, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05569690450695708, 0.05569690450695708, 0.05569690450695708, 0.06379673209985015, 0.06379673209985015, 0.06379673209985015, 0.03495885952175304, 0.03495885952175304, 0.03495885952175304, 0.3714141291377011, 0.3714141291377011, 0.3714141291377011, 0.3563183297125717, 0.3563183297125717, 0.3563183297125717, 0.3680855071935636, 0.3680855071935636, 0.3680855071935636, 0.1058632918654836, 0.1058632918654836, 0.1058632918654836, 0.1087504036870609, 0.1087504036870609, 0.1087504036870609, 0.06845923788422148, 0.06845923788422148, 0.06845923788422148, 0.1751995222389774, 0.1751995222389774, 0.1751995222389774, 0.19443755815254782, 0.19443755815254782, 0.19443755815254782, 0.16109388710577166, 0.16109388710577166, 0.16109388710577166, 0.2461922689366033, 0.2461922689366033, 0.2461922689366033, 0.26352278915782124, 0.26352278915782124, 0.26352278915782124, 0.23575897433736015, 0.23575897433736015, 0.23575897433736015, 0.2104532004733729, 0.2104532004733729, 0.2104532004733729, 0.15166731948065226, 0.15166731948065226, 0.15166731948065226, 0.19504983524448316, 0.19504983524448316, 0.19504983524448316, 0.2086733152129796, 0.2086733152129796, 0.2086733152129796, 0.22056012886745258, 0.22056012886745258, 0.22056012886745258, 0.22648329198600725, 0.22648329198600725, 0.22648329198600725, 0.15002457536904434, 0.15002457536904434, 0.15002457536904434, 0.1849171572824474, 0.1849171572824474, 0.1849171572824474, 0.15037806978893098, 0.15037806978893098, 0.15037806978893098, 0.5249526771967057, 0.5249526771967057, 0.5249526771967057, 0.1617555902819513, 0.1617555902819513, 0.1617555902819513, 0.5424772074556796, 0.5424772074556796, 0.5424772074556796, 0.4867466415982712, 0.4867466415982712, 0.4867466415982712, 0.20260812039214948, 0.20260812039214948, 0.20260812039214948, 0.1528994055211873, 0.1528994055211873, 0.1528994055211873, 0.17049164500075709, 0.17049164500075709, 0.17049164500075709, 0.18783857343702604, 0.18783857343702604, 0.18783857343702604, 0.1819346645918123, 0.1819346645918123, 0.1819346645918123, 0.08586408113411692, 0.08586408113411692, 0.08586408113411692, 0.07546120970193837, 0.07546120970193837, 0.07546120970193837, 0.0709187665007126, 0.0709187665007126, 0.0709187665007126]}, "mutation_prompt": null}
{"id": "bbd89117-4c16-4603-8c80-84563ffe88ad", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with minor tuning in parameter values for improving convergence speed.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6731653111579229, 0.6731653111579229, 0.6731653111579229, 0.711996635129519, 0.711996635129519, 0.711996635129519, 0.7078132901593165, 0.7078132901593165, 0.7078132901593165, 0.041381141768779384, 0.041381141768779384, 0.041381141768779384, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10950771709447105, 0.10950771709447105, 0.10950771709447105, 0.10521185649440323, 0.10521185649440323, 0.10521185649440323, 0.10507361746539623, 0.10507361746539623, 0.10507361746539623, 0.07764468958329585, 0.07764468958329585, 0.07764468958329585, 0.09106825770888427, 0.09106825770888427, 0.09106825770888427, 0.11676664795008551, 0.11676664795008551, 0.11676664795008551, 0.8873949697611814, 0.8873949697611814, 0.8873949697611814, 0.8899603182064498, 0.8899603182064498, 0.8899603182064498, 0.9242514104464227, 0.9242514104464227, 0.9242514104464227, 0.15529290578465005, 0.15529290578465005, 0.15529290578465005, 0.2190096480227307, 0.2190096480227307, 0.2190096480227307, 0.10602395596155945, 0.10602395596155945, 0.10602395596155945, 0.6785064774824554, 0.6785064774824554, 0.6785064774824554, 0.1588220386151905, 0.1588220386151905, 0.1588220386151905, 0.2013731947684061, 0.2013731947684061, 0.2013731947684061, 0.11757177930520302, 0.11757177930520302, 0.11757177930520302, 0.05893689880031361, 0.05893689880031361, 0.05893689880031361, 0.1347567060589916, 0.1347567060589916, 0.1347567060589916, 0.12717657197932586, 0.12717657197932586, 0.12717657197932586, 0.13013401995367202, 0.13013401995367202, 0.13013401995367202, 0.12393529212556109, 0.12393529212556109, 0.12393529212556109, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07406251021116783, 0.07406251021116783, 0.07406251021116783, 0.06698612153091676, 0.06698612153091676, 0.06698612153091676, 0.08330193363389515, 0.08330193363389515, 0.08330193363389515, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05394537933586785, 0.05394537933586785, 0.05394537933586785, 0.06280509881780472, 0.06280509881780472, 0.06280509881780472, 0.058389177628910716, 0.058389177628910716, 0.058389177628910716, 0.4471312292357341, 0.4471312292357341, 0.4471312292357341, 0.5243508001071969, 0.5243508001071969, 0.5243508001071969, 0.46983387154224854, 0.46983387154224854, 0.46983387154224854, 0.07663158410172577, 0.07663158410172577, 0.07663158410172577, 0.10886105391076506, 0.10886105391076506, 0.10886105391076506, 0.1298840489061095, 0.1298840489061095, 0.1298840489061095, 0.1594612677021673, 0.1594612677021673, 0.1594612677021673, 0.2988572920911492, 0.2988572920911492, 0.2988572920911492, 0.24455433586052078, 0.24455433586052078, 0.24455433586052078, 0.35593401052672236, 0.35593401052672236, 0.35593401052672236, 0.41401688285636506, 0.41401688285636506, 0.41401688285636506, 0.23348098648385784, 0.23348098648385784, 0.23348098648385784, 0.25155973801749965, 0.25155973801749965, 0.25155973801749965, 0.16473215297233235, 0.16473215297233235, 0.16473215297233235, 0.2618969115729881, 0.2618969115729881, 0.2618969115729881, 0.21816177922955693, 0.21816177922955693, 0.21816177922955693, 0.19590613448642658, 0.19590613448642658, 0.19590613448642658, 0.24283886563718105, 0.24283886563718105, 0.24283886563718105, 0.18712908296437525, 0.18712908296437525, 0.18712908296437525, 0.16823242717066367, 0.16823242717066367, 0.16823242717066367, 0.19714396552649538, 0.19714396552649538, 0.19714396552649538, 0.7424295255090958, 0.7424295255090958, 0.7424295255090958, 0.16360281335132354, 0.16360281335132354, 0.16360281335132354, 0.7787233078953587, 0.7787233078953587, 0.7787233078953587, 0.6864379667833054, 0.6864379667833054, 0.6864379667833054, 0.20954767599706114, 0.20954767599706114, 0.20954767599706114, 0.5250107589216552, 0.5250107589216552, 0.5250107589216552, 0.1978655172067132, 0.1978655172067132, 0.1978655172067132, 0.16373718664922376, 0.16373718664922376, 0.16373718664922376, 0.195695680947217, 0.195695680947217, 0.195695680947217, 0.07529581943051489, 0.07529581943051489, 0.07529581943051489, 0.0742746602426343, 0.0742746602426343, 0.0742746602426343, 0.08423668137865226, 0.08423668137865226, 0.08423668137865226]}, "mutation_prompt": null}
{"id": "61681f4e-7023-47c2-a200-44e3adb0108b", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2 = 1.3\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                \n                # Modified velocity update for enhanced convergence\n                velocities[i] = inertia + cognitive + social + 0.1 * np.random.randn(self.dim) \n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Refined PSO-SA with tweaked velocity update rule for enhanced convergence speed.", "configspace": "", "generation": 59, "fitness": 0.18996135149253954, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.20.", "error": "", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.3722283387939751, 0.3722283387939751, 0.3722283387939751, 0.3606585559489751, 0.3606585559489751, 0.3606585559489751, 0.3566183152182041, 0.3566183152182041, 0.3566183152182041, 0.0024677763581799628, 0.0024677763581799628, 0.0024677763581799628, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10623003553989752, 0.10623003553989752, 0.10623003553989752, 0.09346842432864289, 0.09346842432864289, 0.09346842432864289, 0.06986294309774332, 0.06986294309774332, 0.06986294309774332, 0.07662340878426932, 0.07662340878426932, 0.07662340878426932, 0.057920709966013284, 0.057920709966013284, 0.057920709966013284, 0.07209040631553276, 0.07209040631553276, 0.07209040631553276, 0.8820743599683163, 0.8820743599683163, 0.8820743599683163, 0.9249162157286952, 0.9249162157286952, 0.9249162157286952, 0.9300047499886894, 0.9300047499886894, 0.9300047499886894, 0.14348817223860844, 0.14348817223860844, 0.14348817223860844, 0.11662250558940346, 0.11662250558940346, 0.11662250558940346, 0.17946742818277528, 0.17946742818277528, 0.17946742818277528, 0.2074171150236821, 0.2074171150236821, 0.2074171150236821, 0.2842542525891859, 0.2842542525891859, 0.2842542525891859, 0.25314256094187815, 0.25314256094187815, 0.25314256094187815, 0.11290487314382935, 0.11290487314382935, 0.11290487314382935, 0.07936118224774114, 0.07936118224774114, 0.07936118224774114, 0.08665594252578734, 0.08665594252578734, 0.08665594252578734, 0.08179355083235096, 0.08179355083235096, 0.08179355083235096, 0.11348291624345985, 0.11348291624345985, 0.11348291624345985, 0.10472054952899035, 0.10472054952899035, 0.10472054952899035, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.037146214888356344, 0.037146214888356344, 0.037146214888356344, 0.0392478304363274, 0.0392478304363274, 0.0392478304363274, 0.07487505971446584, 0.07487505971446584, 0.07487505971446584, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05036666544328783, 0.05036666544328783, 0.05036666544328783, 0.032069375086618, 0.032069375086618, 0.032069375086618, 0.03582537699413768, 0.03582537699413768, 0.03582537699413768, 0.35387579835193184, 0.35387579835193184, 0.35387579835193184, 0.35220338051381617, 0.35220338051381617, 0.35220338051381617, 0.3510539047080299, 0.3510539047080299, 0.3510539047080299, 0.08787694795571277, 0.08787694795571277, 0.08787694795571277, 0.08217996734167632, 0.08217996734167632, 0.08217996734167632, 0.09007114020052254, 0.09007114020052254, 0.09007114020052254, 0.15472536210764487, 0.15472536210764487, 0.15472536210764487, 0.19265994506779593, 0.19265994506779593, 0.19265994506779593, 0.18630025768520853, 0.18630025768520853, 0.18630025768520853, 0.20794545505574547, 0.20794545505574547, 0.20794545505574547, 0.266153602857486, 0.266153602857486, 0.266153602857486, 0.26033049988939494, 0.26033049988939494, 0.26033049988939494, 0.19198968475594036, 0.19198968475594036, 0.19198968475594036, 0.16264422308371418, 0.16264422308371418, 0.16264422308371418, 0.21396167670483968, 0.21396167670483968, 0.21396167670483968, 0.19699883932816398, 0.19699883932816398, 0.19699883932816398, 0.23463612488285812, 0.23463612488285812, 0.23463612488285812, 0.22243562091850722, 0.22243562091850722, 0.22243562091850722, 0.16518808577122635, 0.16518808577122635, 0.16518808577122635, 0.16980465450164062, 0.16980465450164062, 0.16980465450164062, 0.15481236162757928, 0.15481236162757928, 0.15481236162757928, 0.5173799159959975, 0.5173799159959975, 0.5173799159959975, 0.16283785016110464, 0.16283785016110464, 0.16283785016110464, 0.5056007546458956, 0.5056007546458956, 0.5056007546458956, 0.46520131738291604, 0.46520131738291604, 0.46520131738291604, 0.20491234697458272, 0.20491234697458272, 0.20491234697458272, 0.3953847514837783, 0.3953847514837783, 0.3953847514837783, 0.17648860209079975, 0.17648860209079975, 0.17648860209079975, 0.17064454518874284, 0.17064454518874284, 0.17064454518874284, 0.19250854356031033, 0.19250854356031033, 0.19250854356031033, 0.07701061360137718, 0.07701061360137718, 0.07701061360137718, 0.07808392151461396, 0.07808392151461396, 0.07808392151461396, 0.09451079986527455, 0.09451079986527455, 0.09451079986527455]}, "mutation_prompt": null}
{"id": "b344ba25-ac90-4be5-80bc-3aa2371ba683", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.5  # Cognitive coefficient tweaked for better balance\n        self.c2 = 1.5  # Social coefficient tweaked for better balance\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.95  # Enhanced cooling rate for dynamic cooling\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "PSO-SA with enhanced velocity update strategy and dynamic cooling to boost convergence speed.", "configspace": "", "generation": 60, "fitness": 0.21894538614168071, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.23.", "error": "", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.7105926118644232, 0.7105926118644232, 0.7105926118644232, 0.6235579186456737, 0.6235579186456737, 0.6235579186456737, 0.6643807187754402, 0.6643807187754402, 0.6643807187754402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07158463426090034, 0.07158463426090034, 0.07158463426090034, 0.023669091511426266, 0.023669091511426266, 0.023669091511426266, 0.12184623011073603, 0.12184623011073603, 0.12184623011073603, 0.09762572516664403, 0.09762572516664403, 0.09762572516664403, 0.09570711209731675, 0.09570711209731675, 0.09570711209731675, 0.044870666549395755, 0.044870666549395755, 0.044870666549395755, 0.07035911269603334, 0.07035911269603334, 0.07035911269603334, 0.09807702724514189, 0.09807702724514189, 0.09807702724514189, 0.09663431570115155, 0.09663431570115155, 0.09663431570115155, 0.910578471272182, 0.910578471272182, 0.910578471272182, 0.8705449753532698, 0.8705449753532698, 0.8705449753532698, 0.2009267995949473, 0.2009267995949473, 0.2009267995949473, 0.22898595112628994, 0.22898595112628994, 0.22898595112628994, 0.19332179881682432, 0.19332179881682432, 0.19332179881682432, 0.1385109267449911, 0.1385109267449911, 0.1385109267449911, 0.1572459535630536, 0.1572459535630536, 0.1572459535630536, 0.15383398179174068, 0.15383398179174068, 0.15383398179174068, 0.08778014819322977, 0.08778014819322977, 0.08778014819322977, 0.10314828668935938, 0.10314828668935938, 0.10314828668935938, 0.06050233053890297, 0.06050233053890297, 0.06050233053890297, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05216210879540395, 0.05216210879540395, 0.05216210879540395, 0.13504603948675886, 0.13504603948675886, 0.13504603948675886, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10383400924998054, 0.10383400924998054, 0.10383400924998054, 0.05069697332437828, 0.05069697332437828, 0.05069697332437828, 0.09475725310766248, 0.09475725310766248, 0.09475725310766248, 0.013991463163370965, 0.013991463163370965, 0.013991463163370965, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13279809809590282, 0.13279809809590282, 0.13279809809590282, 0.027751205239711085, 0.027751205239711085, 0.027751205239711085, 0.04382029009910582, 0.04382029009910582, 0.04382029009910582, 0.4873431799152885, 0.4873431799152885, 0.4873431799152885, 0.46376251307193883, 0.46376251307193883, 0.46376251307193883, 0.470013058961801, 0.470013058961801, 0.470013058961801, 0.09634178798646975, 0.09634178798646975, 0.09634178798646975, 0.10880321173426932, 0.10880321173426932, 0.10880321173426932, 0.10281639307740364, 0.10281639307740364, 0.10281639307740364, 0.22215490135266824, 0.22215490135266824, 0.22215490135266824, 0.17337045647668325, 0.17337045647668325, 0.17337045647668325, 0.1789608798969542, 0.1789608798969542, 0.1789608798969542, 0.29212382646127877, 0.29212382646127877, 0.29212382646127877, 0.41244491321874044, 0.41244491321874044, 0.41244491321874044, 0.41312558298549173, 0.41312558298549173, 0.41312558298549173, 0.22859261321457947, 0.22859261321457947, 0.22859261321457947, 0.25924751204344654, 0.25924751204344654, 0.25924751204344654, 0.19753412993831243, 0.19753412993831243, 0.19753412993831243, 0.1951775529317592, 0.1951775529317592, 0.1951775529317592, 0.19473033955145136, 0.19473033955145136, 0.19473033955145136, 0.2505582735281877, 0.2505582735281877, 0.2505582735281877, 0.16845066816327525, 0.16845066816327525, 0.16845066816327525, 0.17887796040747894, 0.17887796040747894, 0.17887796040747894, 0.14747140924803825, 0.14747140924803825, 0.14747140924803825, 0.7924667055809431, 0.7924667055809431, 0.7924667055809431, 0.16248832811827507, 0.16248832811827507, 0.16248832811827507, 0.8035059010875379, 0.8035059010875379, 0.8035059010875379, 0.7515225156902081, 0.7515225156902081, 0.7515225156902081, 0.20725578652517795, 0.20725578652517795, 0.20725578652517795, 0.5326206145864449, 0.5326206145864449, 0.5326206145864449, 0.17147848642842145, 0.17147848642842145, 0.17147848642842145, 0.1900263353582986, 0.1900263353582986, 0.1900263353582986, 0.18414315421796923, 0.18414315421796923, 0.18414315421796923, 0.08596887916129159, 0.08596887916129159, 0.08596887916129159, 0.07052376739328337, 0.07052376739328337, 0.07052376739328337, 0.09032393501629743, 0.09032393501629743, 0.09032393501629743]}, "mutation_prompt": null}
{"id": "7febac05-205f-470c-914d-aace3597796c", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Cognitive coefficient\n        self.c2 = 1.3  # Social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                perturbation = np.random.uniform(-0.01, 0.01, self.dim)  # Small random perturbation\n                proposed_position += perturbation\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Integrate a dynamic inertia weight adjustment and a stochastic perturbation to enhance exploration and convergence.", "configspace": "", "generation": 61, "fitness": 0.20054519665434062, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.20.", "error": "", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.5014483754231276, 0.5014483754231276, 0.5014483754231276, 0.5009740104782455, 0.5009740104782455, 0.5009740104782455, 0.5347880825081126, 0.5347880825081126, 0.5347880825081126, 0.0018042344216424588, 0.0018042344216424588, 0.0018042344216424588, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0623189628275832, 0.0623189628275832, 0.0623189628275832, 0.14083837208749794, 0.14083837208749794, 0.14083837208749794, 0.1524664872023188, 0.1524664872023188, 0.1524664872023188, 0.12380108015152946, 0.12380108015152946, 0.12380108015152946, 0.10687490248808007, 0.10687490248808007, 0.10687490248808007, 0.09818246809351117, 0.09818246809351117, 0.09818246809351117, 0.08808995862828484, 0.08808995862828484, 0.08808995862828484, 0.8730526978968703, 0.8730526978968703, 0.8730526978968703, 0.8949667132393444, 0.8949667132393444, 0.8949667132393444, 0.9096969254855923, 0.9096969254855923, 0.9096969254855923, 0.08389373146429313, 0.08389373146429313, 0.08389373146429313, 0.15014998458967765, 0.15014998458967765, 0.15014998458967765, 0.27156110653014476, 0.27156110653014476, 0.27156110653014476, 0.2875861935220524, 0.2875861935220524, 0.2875861935220524, 0.19332189200662497, 0.19332189200662497, 0.19332189200662497, 0.1074120046776127, 0.1074120046776127, 0.1074120046776127, 0.12101986471274229, 0.12101986471274229, 0.12101986471274229, 0.09129543798710382, 0.09129543798710382, 0.09129543798710382, 0.006576041010435851, 0.006576041010435851, 0.006576041010435851, 0.01174208525986653, 0.01174208525986653, 0.01174208525986653, 0.11537798051469239, 0.11537798051469239, 0.11537798051469239, 0.1277476676210454, 0.1277476676210454, 0.1277476676210454, 0.0076086232500686135, 0.0076086232500686135, 0.0076086232500686135, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14544710825635154, 0.14544710825635154, 0.14544710825635154, 0.0279358961934979, 0.0279358961934979, 0.0279358961934979, 0.05108179110379407, 0.05108179110379407, 0.05108179110379407, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02602830383627297, 0.02602830383627297, 0.02602830383627297, 0.12522681550234083, 0.12522681550234083, 0.12522681550234083, 0.025759395574037613, 0.025759395574037613, 0.025759395574037613, 0.025858241156015205, 0.025858241156015205, 0.025858241156015205, 0.4521974298770083, 0.4521974298770083, 0.4521974298770083, 0.4461014195813593, 0.4461014195813593, 0.4461014195813593, 0.45345952642931897, 0.45345952642931897, 0.45345952642931897, 0.08369567282253842, 0.08369567282253842, 0.08369567282253842, 0.14998166493257448, 0.14998166493257448, 0.14998166493257448, 0.12826166326329658, 0.12826166326329658, 0.12826166326329658, 0.24205435705242562, 0.24205435705242562, 0.24205435705242562, 0.22171576335578136, 0.22171576335578136, 0.22171576335578136, 0.28531926220888915, 0.28531926220888915, 0.28531926220888915, 0.2657230072194193, 0.2657230072194193, 0.2657230072194193, 0.2704978505781863, 0.2704978505781863, 0.2704978505781863, 0.2551063766695507, 0.2551063766695507, 0.2551063766695507, 0.23474102792214013, 0.23474102792214013, 0.23474102792214013, 0.1950398625914126, 0.1950398625914126, 0.1950398625914126, 0.201127509373348, 0.201127509373348, 0.201127509373348, 0.20291600138928612, 0.20291600138928612, 0.20291600138928612, 0.20934127661249102, 0.20934127661249102, 0.20934127661249102, 0.22950197928751048, 0.22950197928751048, 0.22950197928751048, 0.1993058887383753, 0.1993058887383753, 0.1993058887383753, 0.17252661249898482, 0.17252661249898482, 0.17252661249898482, 0.16766949487946714, 0.16766949487946714, 0.16766949487946714, 0.7342406432808306, 0.7342406432808306, 0.7342406432808306, 0.1564327372077643, 0.1564327372077643, 0.1564327372077643, 0.16976812806855046, 0.16976812806855046, 0.16976812806855046, 0.15142007241859645, 0.15142007241859645, 0.15142007241859645, 0.20807781770199008, 0.20807781770199008, 0.20807781770199008, 0.15311496229583987, 0.15311496229583987, 0.15311496229583987, 0.18089322216708215, 0.18089322216708215, 0.18089322216708215, 0.19023282969689792, 0.19023282969689792, 0.19023282969689792, 0.17594720672919195, 0.17594720672919195, 0.17594720672919195, 0.09453845187799048, 0.09453845187799048, 0.09453845187799048, 0.08325386517918465, 0.08325386517918465, 0.08325386517918465, 0.0826171395048304, 0.0826171395048304, 0.0826171395048304]}, "mutation_prompt": null}
{"id": "c998d6f9-3c12-4914-8fa2-407d281a974a", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.num_swarms = 2  # Introduce multiple swarms for diversity\n        self.w = 0.85\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2 = 1.3\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                if evaluations % 50 == 0:  # Periodic exploration\n                    exploration_vector = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    particles[i] = exploration_vector\n\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Multi-Swarm PSO with Reinforcement Learning-inspired Exploration for enhanced convergence.", "configspace": "", "generation": 62, "fitness": 0.22551764259777915, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.23.", "error": "", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6984363631076684, 0.6984363631076684, 0.6984363631076684, 0.6878650091480846, 0.6878650091480846, 0.6878650091480846, 0.6614795876576673, 0.6614795876576673, 0.6614795876576673, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09624218265524087, 0.09624218265524087, 0.09624218265524087, 0.08914664920449578, 0.08914664920449578, 0.08914664920449578, 0.09264015470531739, 0.09264015470531739, 0.09264015470531739, 0.09472420109355839, 0.09472420109355839, 0.09472420109355839, 0.10823891626194582, 0.10823891626194582, 0.10823891626194582, 0.09112870493732939, 0.09112870493732939, 0.09112870493732939, 0.8602198570226985, 0.8602198570226985, 0.8602198570226985, 0.882514323464039, 0.882514323464039, 0.882514323464039, 0.8723832635237976, 0.8723832635237976, 0.8723832635237976, 0.12745460773045303, 0.12745460773045303, 0.12745460773045303, 0.21967595220870406, 0.21967595220870406, 0.21967595220870406, 0.1486752468190794, 0.1486752468190794, 0.1486752468190794, 0.20555965561834766, 0.20555965561834766, 0.20555965561834766, 0.19799239961347193, 0.19799239961347193, 0.19799239961347193, 0.210295961565938, 0.210295961565938, 0.210295961565938, 0.1490332601879305, 0.1490332601879305, 0.1490332601879305, 0.10158072844703003, 0.10158072844703003, 0.10158072844703003, 0.11670809005243354, 0.11670809005243354, 0.11670809005243354, 0.1038131285249776, 0.1038131285249776, 0.1038131285249776, 0.11464935269111243, 0.11464935269111243, 0.11464935269111243, 0.12074774380061848, 0.12074774380061848, 0.12074774380061848, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0712605812118039, 0.0712605812118039, 0.0712605812118039, 0.050143481959746494, 0.050143481959746494, 0.050143481959746494, 0.048676020170733914, 0.048676020170733914, 0.048676020170733914, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03484479127653761, 0.03484479127653761, 0.03484479127653761, 0.027700136509641426, 0.027700136509641426, 0.027700136509641426, 0.035504554265764265, 0.035504554265764265, 0.035504554265764265, 0.4725316510869825, 0.4725316510869825, 0.4725316510869825, 0.45598986229612815, 0.45598986229612815, 0.45598986229612815, 0.45265877367933116, 0.45265877367933116, 0.45265877367933116, 0.07278439826699201, 0.07278439826699201, 0.07278439826699201, 0.0972552168866625, 0.0972552168866625, 0.0972552168866625, 0.11000229577822707, 0.11000229577822707, 0.11000229577822707, 0.23033919373339218, 0.23033919373339218, 0.23033919373339218, 0.32572431837985394, 0.32572431837985394, 0.32572431837985394, 0.28256908077741016, 0.28256908077741016, 0.28256908077741016, 0.1891793607605604, 0.1891793607605604, 0.1891793607605604, 0.3214413069461537, 0.3214413069461537, 0.3214413069461537, 0.24322553439886763, 0.24322553439886763, 0.24322553439886763, 0.25913489562041914, 0.25913489562041914, 0.25913489562041914, 0.2603858421786953, 0.2603858421786953, 0.2603858421786953, 0.1533970486251155, 0.1533970486251155, 0.1533970486251155, 0.22301779466180338, 0.22301779466180338, 0.22301779466180338, 0.2295624220415481, 0.2295624220415481, 0.2295624220415481, 0.22704009201151965, 0.22704009201151965, 0.22704009201151965, 0.17499514616420075, 0.17499514616420075, 0.17499514616420075, 0.1692692546298158, 0.1692692546298158, 0.1692692546298158, 0.20206520385532145, 0.20206520385532145, 0.20206520385532145, 0.7573415469908349, 0.7573415469908349, 0.7573415469908349, 0.11777786970186077, 0.11777786970186077, 0.11777786970186077, 0.7297398199293358, 0.7297398199293358, 0.7297398199293358, 0.5477224797220956, 0.5477224797220956, 0.5477224797220956, 0.20648231334522282, 0.20648231334522282, 0.20648231334522282, 0.588700391144938, 0.588700391144938, 0.588700391144938, 0.18065243790420193, 0.18065243790420193, 0.18065243790420193, 0.1938866816196353, 0.1938866816196353, 0.1938866816196353, 0.1770026665830181, 0.1770026665830181, 0.1770026665830181, 0.09618877346951327, 0.09618877346951327, 0.09618877346951327, 0.08539528675176866, 0.08539528675176866, 0.08539528675176866, 0.08357640166250635, 0.08357640166250635, 0.08357640166250635]}, "mutation_prompt": null}
{"id": "fdde37ce-1578-4f6b-bf08-3ce399ff6cc6", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n        initial_budget = self.budget\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n            # New feature: dynamic swarm size reduction\n            if evaluations > initial_budget * 0.5 and self.swarm_size > 20:\n                self.swarm_size -= 1\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Integrate a dynamic swarm size reduction strategy into the PSO-SA optimizer to enhance convergence speed.", "configspace": "", "generation": 63, "fitness": 0.23927776439768844, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.24.", "error": "", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6715955592595703, 0.6715955592595703, 0.6715955592595703, 0.7099679606936239, 0.7099679606936239, 0.7099679606936239, 0.7071381698608021, 0.7071381698608021, 0.7071381698608021, 0.04587494597731745, 0.04587494597731745, 0.04587494597731745, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10956341330211694, 0.10956341330211694, 0.10956341330211694, 0.08974295671937593, 0.08974295671937593, 0.08974295671937593, 0.10497422572983683, 0.10497422572983683, 0.10497422572983683, 0.07722022801939965, 0.07722022801939965, 0.07722022801939965, 0.09037337070554274, 0.09037337070554274, 0.09037337070554274, 0.1164446761878678, 0.1164446761878678, 0.1164446761878678, 0.8873949697611814, 0.8873949697611814, 0.8873949697611814, 0.8899603182064498, 0.8899603182064498, 0.8899603182064498, 0.9242514104464227, 0.9242514104464227, 0.9242514104464227, 0.1543361795004501, 0.1543361795004501, 0.1543361795004501, 0.2257504163575138, 0.2257504163575138, 0.2257504163575138, 0.1067055268249536, 0.1067055268249536, 0.1067055268249536, 0.6785064774824554, 0.6785064774824554, 0.6785064774824554, 0.1588220386151905, 0.1588220386151905, 0.1588220386151905, 0.2013731947684061, 0.2013731947684061, 0.2013731947684061, 0.11678876100364344, 0.11678876100364344, 0.11678876100364344, 0.05785894818236137, 0.05785894818236137, 0.05785894818236137, 0.13477418811156416, 0.13477418811156416, 0.13477418811156416, 0.1271400115580389, 0.1271400115580389, 0.1271400115580389, 0.1304031334523843, 0.1304031334523843, 0.1304031334523843, 0.12402794167986375, 0.12402794167986375, 0.12402794167986375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07409605647425144, 0.07409605647425144, 0.07409605647425144, 0.06731594698134269, 0.06731594698134269, 0.06731594698134269, 0.08330138917849073, 0.08330138917849073, 0.08330138917849073, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02570592961838425, 0.02570592961838425, 0.02570592961838425, 0.04891992557950675, 0.04891992557950675, 0.04891992557950675, 0.06428649189520508, 0.06428649189520508, 0.06428649189520508, 0.055352609810745856, 0.055352609810745856, 0.055352609810745856, 0.44823714740233755, 0.44823714740233755, 0.44823714740233755, 0.5417707863299945, 0.5417707863299945, 0.5417707863299945, 0.470272171052337, 0.470272171052337, 0.470272171052337, 0.07653980441187669, 0.07653980441187669, 0.07653980441187669, 0.10880326435451082, 0.10880326435451082, 0.10880326435451082, 0.12968346747833437, 0.12968346747833437, 0.12968346747833437, 0.1610968198665076, 0.1610968198665076, 0.1610968198665076, 0.26759300302690836, 0.26759300302690836, 0.26759300302690836, 0.24592957490034828, 0.24592957490034828, 0.24592957490034828, 0.3619522061767232, 0.3619522061767232, 0.3619522061767232, 0.3585007143983311, 0.3585007143983311, 0.3585007143983311, 0.23351681295014204, 0.23351681295014204, 0.23351681295014204, 0.2525071086630071, 0.2525071086630071, 0.2525071086630071, 0.16531290223379713, 0.16531290223379713, 0.16531290223379713, 0.2667977202566334, 0.2667977202566334, 0.2667977202566334, 0.21953708265639693, 0.21953708265639693, 0.21953708265639693, 0.19679608837551377, 0.19679608837551377, 0.19679608837551377, 0.23171240910088586, 0.23171240910088586, 0.23171240910088586, 0.18738335738779743, 0.18738335738779743, 0.18738335738779743, 0.168233296355906, 0.168233296355906, 0.168233296355906, 0.1994474508841627, 0.1994474508841627, 0.1994474508841627, 0.7424295255090958, 0.7424295255090958, 0.7424295255090958, 0.16357962178110685, 0.16357962178110685, 0.16357962178110685, 0.7787233078953587, 0.7787233078953587, 0.7787233078953587, 0.64273070428966, 0.64273070428966, 0.64273070428966, 0.20954773528906645, 0.20954773528906645, 0.20954773528906645, 0.5287260695436509, 0.5287260695436509, 0.5287260695436509, 0.20592538626401935, 0.20592538626401935, 0.20592538626401935, 0.1747486199424202, 0.1747486199424202, 0.1747486199424202, 0.19442631147702227, 0.19442631147702227, 0.19442631147702227, 0.07534817112222025, 0.07534817112222025, 0.07534817112222025, 0.07601940312445565, 0.07601940312445565, 0.07601940312445565, 0.08350362018877755, 0.08350362018877755, 0.08350362018877755]}, "mutation_prompt": null}
{"id": "961df851-ec85-45c3-965f-e6109a7f8289", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with minor tuning in parameter values for improving convergence speed.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6731653111579229, 0.6731653111579229, 0.6731653111579229, 0.711996635129519, 0.711996635129519, 0.711996635129519, 0.7078132901593165, 0.7078132901593165, 0.7078132901593165, 0.041381141768779384, 0.041381141768779384, 0.041381141768779384, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10950771709447105, 0.10950771709447105, 0.10950771709447105, 0.10521185649440323, 0.10521185649440323, 0.10521185649440323, 0.10507361746539623, 0.10507361746539623, 0.10507361746539623, 0.07764468958329585, 0.07764468958329585, 0.07764468958329585, 0.09106825770888427, 0.09106825770888427, 0.09106825770888427, 0.11676664795008551, 0.11676664795008551, 0.11676664795008551, 0.8873949697611814, 0.8873949697611814, 0.8873949697611814, 0.8899603182064498, 0.8899603182064498, 0.8899603182064498, 0.9242514104464227, 0.9242514104464227, 0.9242514104464227, 0.15529290578465005, 0.15529290578465005, 0.15529290578465005, 0.2190096480227307, 0.2190096480227307, 0.2190096480227307, 0.10602395596155945, 0.10602395596155945, 0.10602395596155945, 0.6785064774824554, 0.6785064774824554, 0.6785064774824554, 0.1588220386151905, 0.1588220386151905, 0.1588220386151905, 0.2013731947684061, 0.2013731947684061, 0.2013731947684061, 0.11757177930520302, 0.11757177930520302, 0.11757177930520302, 0.05893689880031361, 0.05893689880031361, 0.05893689880031361, 0.1347567060589916, 0.1347567060589916, 0.1347567060589916, 0.12717657197932586, 0.12717657197932586, 0.12717657197932586, 0.13013401995367202, 0.13013401995367202, 0.13013401995367202, 0.12393529212556109, 0.12393529212556109, 0.12393529212556109, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07406251021116783, 0.07406251021116783, 0.07406251021116783, 0.06698612153091676, 0.06698612153091676, 0.06698612153091676, 0.08330193363389515, 0.08330193363389515, 0.08330193363389515, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05394537933586785, 0.05394537933586785, 0.05394537933586785, 0.06280509881780472, 0.06280509881780472, 0.06280509881780472, 0.058389177628910716, 0.058389177628910716, 0.058389177628910716, 0.4471312292357341, 0.4471312292357341, 0.4471312292357341, 0.5243508001071969, 0.5243508001071969, 0.5243508001071969, 0.46983387154224854, 0.46983387154224854, 0.46983387154224854, 0.07663158410172577, 0.07663158410172577, 0.07663158410172577, 0.10886105391076506, 0.10886105391076506, 0.10886105391076506, 0.1298840489061095, 0.1298840489061095, 0.1298840489061095, 0.1594612677021673, 0.1594612677021673, 0.1594612677021673, 0.2988572920911492, 0.2988572920911492, 0.2988572920911492, 0.24455433586052078, 0.24455433586052078, 0.24455433586052078, 0.35593401052672236, 0.35593401052672236, 0.35593401052672236, 0.41401688285636506, 0.41401688285636506, 0.41401688285636506, 0.23348098648385784, 0.23348098648385784, 0.23348098648385784, 0.25155973801749965, 0.25155973801749965, 0.25155973801749965, 0.16473215297233235, 0.16473215297233235, 0.16473215297233235, 0.2618969115729881, 0.2618969115729881, 0.2618969115729881, 0.21816177922955693, 0.21816177922955693, 0.21816177922955693, 0.19590613448642658, 0.19590613448642658, 0.19590613448642658, 0.24283886563718105, 0.24283886563718105, 0.24283886563718105, 0.18712908296437525, 0.18712908296437525, 0.18712908296437525, 0.16823242717066367, 0.16823242717066367, 0.16823242717066367, 0.19714396552649538, 0.19714396552649538, 0.19714396552649538, 0.7424295255090958, 0.7424295255090958, 0.7424295255090958, 0.16360281335132354, 0.16360281335132354, 0.16360281335132354, 0.7787233078953587, 0.7787233078953587, 0.7787233078953587, 0.6864379667833054, 0.6864379667833054, 0.6864379667833054, 0.20954767599706114, 0.20954767599706114, 0.20954767599706114, 0.5250107589216552, 0.5250107589216552, 0.5250107589216552, 0.1978655172067132, 0.1978655172067132, 0.1978655172067132, 0.16373718664922376, 0.16373718664922376, 0.16373718664922376, 0.195695680947217, 0.195695680947217, 0.195695680947217, 0.07529581943051489, 0.07529581943051489, 0.07529581943051489, 0.0742746602426343, 0.0742746602426343, 0.0742746602426343, 0.08423668137865226, 0.08423668137865226, 0.08423668137865226]}, "mutation_prompt": null}
{"id": "1db41bc2-0d3e-428d-b08f-e8e835551999", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Cognitive coefficient\n        self.c2_initial = 1.3  # Initial social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            c2 = self.c2_initial * (self.global_best_val / (self.global_best_val + 1e-9))  # Adaptive social coefficient\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Improved PSO-SA optimizer with adaptive social coefficient and dynamic inertia weight adjustment for better convergence.", "configspace": "", "generation": 65, "fitness": 0.24028502069769214, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.24.", "error": "", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6731653107350154, 0.6731653107350154, 0.6731653107350154, 0.7119966350723584, 0.7119966350723584, 0.7119966350723584, 0.7078132901381823, 0.7078132901381823, 0.7078132901381823, 0.04138114176866725, 0.04138114176866725, 0.04138114176866725, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10950771709525475, 0.10950771709525475, 0.10950771709525475, 0.10521185650047737, 0.10521185650047737, 0.10521185650047737, 0.1050736174597594, 0.1050736174597594, 0.1050736174597594, 0.07764468958343496, 0.07764468958343496, 0.07764468958343496, 0.09106825770935689, 0.09106825770935689, 0.09106825770935689, 0.1167666479564039, 0.1167666479564039, 0.1167666479564039, 0.8873949697612201, 0.8873949697612201, 0.8873949697612201, 0.8899603182064454, 0.8899603182064454, 0.8899603182064454, 0.9242514104463769, 0.9242514104463769, 0.9242514104463769, 0.15529290577691612, 0.15529290577691612, 0.15529290577691612, 0.21900964782161003, 0.21900964782161003, 0.21900964782161003, 0.1060239559616164, 0.1060239559616164, 0.1060239559616164, 0.6785064774824554, 0.6785064774824554, 0.6785064774824554, 0.1588220386151905, 0.1588220386151905, 0.1588220386151905, 0.2013731947684061, 0.2013731947684061, 0.2013731947684061, 0.11757177930835294, 0.11757177930835294, 0.11757177930835294, 0.05893689879952668, 0.05893689879952668, 0.05893689879952668, 0.13475670605857704, 0.13475670605857704, 0.13475670605857704, 0.12717657197729748, 0.12717657197729748, 0.12717657197729748, 0.13013401995436547, 0.13013401995436547, 0.13013401995436547, 0.12393529212747167, 0.12393529212747167, 0.12393529212747167, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07406251020561572, 0.07406251020561572, 0.07406251020561572, 0.0669861207173974, 0.0669861207173974, 0.0669861207173974, 0.08330193364586358, 0.08330193364586358, 0.08330193364586358, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.053945379336235, 0.053945379336235, 0.053945379336235, 0.06280509882523966, 0.06280509882523966, 0.06280509882523966, 0.05838917762518725, 0.05838917762518725, 0.05838917762518725, 0.44713122918200887, 0.44713122918200887, 0.44713122918200887, 0.5243507972505201, 0.5243507972505201, 0.5243507972505201, 0.4698338715133964, 0.4698338715133964, 0.4698338715133964, 0.07663158410146265, 0.07663158410146265, 0.07663158410146265, 0.10886105391231193, 0.10886105391231193, 0.10886105391231193, 0.12988404889994376, 0.12988404889994376, 0.12988404889994376, 0.1594612677279631, 0.1594612677279631, 0.1594612677279631, 0.29885729231596747, 0.29885729231596747, 0.29885729231596747, 0.24455433582486918, 0.24455433582486918, 0.24455433582486918, 0.3559339806958999, 0.3559339806958999, 0.3559339806958999, 0.41401681034374993, 0.41401681034374993, 0.41401681034374993, 0.2334809865983396, 0.2334809865983396, 0.2334809865983396, 0.2515597472637924, 0.2515597472637924, 0.2515597472637924, 0.16473215294216703, 0.16473215294216703, 0.16473215294216703, 0.26189691291270445, 0.26189691291270445, 0.26189691291270445, 0.2181617791165582, 0.2181617791165582, 0.2181617791165582, 0.19590613451984207, 0.19590613451984207, 0.19590613451984207, 0.24283886569579582, 0.24283886569579582, 0.24283886569579582, 0.18712908296689224, 0.18712908296689224, 0.18712908296689224, 0.1682324271707577, 0.1682324271707577, 0.1682324271707577, 0.19714396552525681, 0.19714396552525681, 0.19714396552525681, 0.7424295256116438, 0.7424295256116438, 0.7424295256116438, 0.16360281335352556, 0.16360281335352556, 0.16360281335352556, 0.7787233079203727, 0.7787233079203727, 0.7787233079203727, 0.6864379667869173, 0.6864379667869173, 0.6864379667869173, 0.20954767599705715, 0.20954767599705715, 0.20954767599705715, 0.5250107588682016, 0.5250107588682016, 0.5250107588682016, 0.19786551826081356, 0.19786551826081356, 0.19786551826081356, 0.16373718307091112, 0.16373718307091112, 0.16373718307091112, 0.19569568155779427, 0.19569568155779427, 0.19569568155779427, 0.07529581926608098, 0.07529581926608098, 0.07529581926608098, 0.07427466025209761, 0.07427466025209761, 0.07427466025209761, 0.08423668136794349, 0.08423668136794349, 0.08423668136794349]}, "mutation_prompt": null}
{"id": "85913e88-a3a3-41fe-964e-1e4a914bf305", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with minor tuning in parameter values for improving convergence speed.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6731653111579229, 0.6731653111579229, 0.6731653111579229, 0.711996635129519, 0.711996635129519, 0.711996635129519, 0.7078132901593165, 0.7078132901593165, 0.7078132901593165, 0.041381141768779384, 0.041381141768779384, 0.041381141768779384, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10950771709447105, 0.10950771709447105, 0.10950771709447105, 0.10521185649440323, 0.10521185649440323, 0.10521185649440323, 0.10507361746539623, 0.10507361746539623, 0.10507361746539623, 0.07764468958329585, 0.07764468958329585, 0.07764468958329585, 0.09106825770888427, 0.09106825770888427, 0.09106825770888427, 0.11676664795008551, 0.11676664795008551, 0.11676664795008551, 0.8873949697611814, 0.8873949697611814, 0.8873949697611814, 0.8899603182064498, 0.8899603182064498, 0.8899603182064498, 0.9242514104464227, 0.9242514104464227, 0.9242514104464227, 0.15529290578465005, 0.15529290578465005, 0.15529290578465005, 0.2190096480227307, 0.2190096480227307, 0.2190096480227307, 0.10602395596155945, 0.10602395596155945, 0.10602395596155945, 0.6785064774824554, 0.6785064774824554, 0.6785064774824554, 0.1588220386151905, 0.1588220386151905, 0.1588220386151905, 0.2013731947684061, 0.2013731947684061, 0.2013731947684061, 0.11757177930520302, 0.11757177930520302, 0.11757177930520302, 0.05893689880031361, 0.05893689880031361, 0.05893689880031361, 0.1347567060589916, 0.1347567060589916, 0.1347567060589916, 0.12717657197932586, 0.12717657197932586, 0.12717657197932586, 0.13013401995367202, 0.13013401995367202, 0.13013401995367202, 0.12393529212556109, 0.12393529212556109, 0.12393529212556109, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07406251021116783, 0.07406251021116783, 0.07406251021116783, 0.06698612153091676, 0.06698612153091676, 0.06698612153091676, 0.08330193363389515, 0.08330193363389515, 0.08330193363389515, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05394537933586785, 0.05394537933586785, 0.05394537933586785, 0.06280509881780472, 0.06280509881780472, 0.06280509881780472, 0.058389177628910716, 0.058389177628910716, 0.058389177628910716, 0.4471312292357341, 0.4471312292357341, 0.4471312292357341, 0.5243508001071969, 0.5243508001071969, 0.5243508001071969, 0.46983387154224854, 0.46983387154224854, 0.46983387154224854, 0.07663158410172577, 0.07663158410172577, 0.07663158410172577, 0.10886105391076506, 0.10886105391076506, 0.10886105391076506, 0.1298840489061095, 0.1298840489061095, 0.1298840489061095, 0.1594612677021673, 0.1594612677021673, 0.1594612677021673, 0.2988572920911492, 0.2988572920911492, 0.2988572920911492, 0.24455433586052078, 0.24455433586052078, 0.24455433586052078, 0.35593401052672236, 0.35593401052672236, 0.35593401052672236, 0.41401688285636506, 0.41401688285636506, 0.41401688285636506, 0.23348098648385784, 0.23348098648385784, 0.23348098648385784, 0.25155973801749965, 0.25155973801749965, 0.25155973801749965, 0.16473215297233235, 0.16473215297233235, 0.16473215297233235, 0.2618969115729881, 0.2618969115729881, 0.2618969115729881, 0.21816177922955693, 0.21816177922955693, 0.21816177922955693, 0.19590613448642658, 0.19590613448642658, 0.19590613448642658, 0.24283886563718105, 0.24283886563718105, 0.24283886563718105, 0.18712908296437525, 0.18712908296437525, 0.18712908296437525, 0.16823242717066367, 0.16823242717066367, 0.16823242717066367, 0.19714396552649538, 0.19714396552649538, 0.19714396552649538, 0.7424295255090958, 0.7424295255090958, 0.7424295255090958, 0.16360281335132354, 0.16360281335132354, 0.16360281335132354, 0.7787233078953587, 0.7787233078953587, 0.7787233078953587, 0.6864379667833054, 0.6864379667833054, 0.6864379667833054, 0.20954767599706114, 0.20954767599706114, 0.20954767599706114, 0.5250107589216552, 0.5250107589216552, 0.5250107589216552, 0.1978655172067132, 0.1978655172067132, 0.1978655172067132, 0.16373718664922376, 0.16373718664922376, 0.16373718664922376, 0.195695680947217, 0.195695680947217, 0.195695680947217, 0.07529581943051489, 0.07529581943051489, 0.07529581943051489, 0.0742746602426343, 0.0742746602426343, 0.0742746602426343, 0.08423668137865226, 0.08423668137865226, 0.08423668137865226]}, "mutation_prompt": null}
{"id": "49c9eb11-269c-4291-9b9d-321f8c08e12f", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2 = 1.3\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        def swarm_diversity():\n            return np.mean(np.std(particles, axis=0))\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            diversity = swarm_diversity()\n            self.c1 = 1.5 + diversity\n            self.c2 = 1.5 - diversity\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with adaptive c1 and c2 based on swarm diversity for improved convergence.", "configspace": "", "generation": 67, "fitness": 0.07653982333449083, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.08.", "error": "", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.23959986583948667, 0.23959986583948667, 0.23959986583948667, 0.1520047011125134, 0.1520047011125134, 0.1520047011125134, 0.17721152423875575, 0.17721152423875575, 0.17721152423875575, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05117291660756196, 0.05117291660756196, 0.05117291660756196, 0.015275517656955895, 0.015275517656955895, 0.015275517656955895, 0.023925272539718212, 0.023925272539718212, 0.023925272539718212, 0.015872610662227116, 0.015872610662227116, 0.015872610662227116, 0.012510185152476483, 0.012510185152476483, 0.012510185152476483, 0.01617550300990045, 0.01617550300990045, 0.01617550300990045, 0.048459779536270564, 0.048459779536270564, 0.048459779536270564, 0.05458023816260016, 0.05458023816260016, 0.05458023816260016, 0.0835879685437918, 0.0835879685437918, 0.0835879685437918, 0.03998582589736033, 0.03998582589736033, 0.03998582589736033, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1137387796517021, 0.1137387796517021, 0.1137387796517021, 0.059953888953438006, 0.059953888953438006, 0.059953888953438006, 0.12140585094466627, 0.12140585094466627, 0.12140585094466627, 0.09502237463642882, 0.09502237463642882, 0.09502237463642882, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03853418545811016, 0.03853418545811016, 0.03853418545811016, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01611459162525586, 0.01611459162525586, 0.01611459162525586, 0.01506709822913177, 0.01506709822913177, 0.01506709822913177, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.26998335346821567, 0.26998335346821567, 0.26998335346821567, 0.10436961209827222, 0.10436961209827222, 0.10436961209827222, 0.24915317392450076, 0.24915317392450076, 0.24915317392450076, 0.04663435014811479, 0.04663435014811479, 0.04663435014811479, 0.034678737483242905, 0.034678737483242905, 0.034678737483242905, 0.017893481921896992, 0.017893481921896992, 0.017893481921896992, 0.1287707297517502, 0.1287707297517502, 0.1287707297517502, 0.10068977617927899, 0.10068977617927899, 0.10068977617927899, 0.11907754128784653, 0.11907754128784653, 0.11907754128784653, 0.13390304113504303, 0.13390304113504303, 0.13390304113504303, 0.14841158736372562, 0.14841158736372562, 0.14841158736372562, 0.14201478112147692, 0.14201478112147692, 0.14201478112147692, 0.10788831951020961, 0.10788831951020961, 0.10788831951020961, 0.10721552425050285, 0.10721552425050285, 0.10721552425050285, 0.10000028082327717, 0.10000028082327717, 0.10000028082327717, 0.1534830546429956, 0.1534830546429956, 0.1534830546429956, 0.12257570201196977, 0.12257570201196977, 0.12257570201196977, 0.12557435599106903, 0.12557435599106903, 0.12557435599106903, 0.14933290212922257, 0.14933290212922257, 0.14933290212922257, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1515429500682085, 0.1515429500682085, 0.1515429500682085, 0.32130339881477243, 0.32130339881477243, 0.32130339881477243, 0.1512801417452001, 0.1512801417452001, 0.1512801417452001, 0.09401572383385048, 0.09401572383385048, 0.09401572383385048, 0.10011334180695719, 0.10011334180695719, 0.10011334180695719, 0.17870417437937192, 0.17870417437937192, 0.17870417437937192, 0.11744743558003379, 0.11744743558003379, 0.11744743558003379, 0.18049927771767504, 0.18049927771767504, 0.18049927771767504, 0.1952510651425602, 0.1952510651425602, 0.1952510651425602, 0.16830578411253483, 0.16830578411253483, 0.16830578411253483, 0.027321535128584817, 0.027321535128584817, 0.027321535128584817, 0.04768493929460149, 0.04768493929460149, 0.04768493929460149, 0.023548528758025933, 0.023548528758025933, 0.023548528758025933]}, "mutation_prompt": null}
{"id": "3ccfa922-c05a-4fea-8cd8-f8773235ee35", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with minor tuning in parameter values for improving convergence speed.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6731653111579229, 0.6731653111579229, 0.6731653111579229, 0.711996635129519, 0.711996635129519, 0.711996635129519, 0.7078132901593165, 0.7078132901593165, 0.7078132901593165, 0.041381141768779384, 0.041381141768779384, 0.041381141768779384, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10950771709447105, 0.10950771709447105, 0.10950771709447105, 0.10521185649440323, 0.10521185649440323, 0.10521185649440323, 0.10507361746539623, 0.10507361746539623, 0.10507361746539623, 0.07764468958329585, 0.07764468958329585, 0.07764468958329585, 0.09106825770888427, 0.09106825770888427, 0.09106825770888427, 0.11676664795008551, 0.11676664795008551, 0.11676664795008551, 0.8873949697611814, 0.8873949697611814, 0.8873949697611814, 0.8899603182064498, 0.8899603182064498, 0.8899603182064498, 0.9242514104464227, 0.9242514104464227, 0.9242514104464227, 0.15529290578465005, 0.15529290578465005, 0.15529290578465005, 0.2190096480227307, 0.2190096480227307, 0.2190096480227307, 0.10602395596155945, 0.10602395596155945, 0.10602395596155945, 0.6785064774824554, 0.6785064774824554, 0.6785064774824554, 0.1588220386151905, 0.1588220386151905, 0.1588220386151905, 0.2013731947684061, 0.2013731947684061, 0.2013731947684061, 0.11757177930520302, 0.11757177930520302, 0.11757177930520302, 0.05893689880031361, 0.05893689880031361, 0.05893689880031361, 0.1347567060589916, 0.1347567060589916, 0.1347567060589916, 0.12717657197932586, 0.12717657197932586, 0.12717657197932586, 0.13013401995367202, 0.13013401995367202, 0.13013401995367202, 0.12393529212556109, 0.12393529212556109, 0.12393529212556109, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07406251021116783, 0.07406251021116783, 0.07406251021116783, 0.06698612153091676, 0.06698612153091676, 0.06698612153091676, 0.08330193363389515, 0.08330193363389515, 0.08330193363389515, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05394537933586785, 0.05394537933586785, 0.05394537933586785, 0.06280509881780472, 0.06280509881780472, 0.06280509881780472, 0.058389177628910716, 0.058389177628910716, 0.058389177628910716, 0.4471312292357341, 0.4471312292357341, 0.4471312292357341, 0.5243508001071969, 0.5243508001071969, 0.5243508001071969, 0.46983387154224854, 0.46983387154224854, 0.46983387154224854, 0.07663158410172577, 0.07663158410172577, 0.07663158410172577, 0.10886105391076506, 0.10886105391076506, 0.10886105391076506, 0.1298840489061095, 0.1298840489061095, 0.1298840489061095, 0.1594612677021673, 0.1594612677021673, 0.1594612677021673, 0.2988572920911492, 0.2988572920911492, 0.2988572920911492, 0.24455433586052078, 0.24455433586052078, 0.24455433586052078, 0.35593401052672236, 0.35593401052672236, 0.35593401052672236, 0.41401688285636506, 0.41401688285636506, 0.41401688285636506, 0.23348098648385784, 0.23348098648385784, 0.23348098648385784, 0.25155973801749965, 0.25155973801749965, 0.25155973801749965, 0.16473215297233235, 0.16473215297233235, 0.16473215297233235, 0.2618969115729881, 0.2618969115729881, 0.2618969115729881, 0.21816177922955693, 0.21816177922955693, 0.21816177922955693, 0.19590613448642658, 0.19590613448642658, 0.19590613448642658, 0.24283886563718105, 0.24283886563718105, 0.24283886563718105, 0.18712908296437525, 0.18712908296437525, 0.18712908296437525, 0.16823242717066367, 0.16823242717066367, 0.16823242717066367, 0.19714396552649538, 0.19714396552649538, 0.19714396552649538, 0.7424295255090958, 0.7424295255090958, 0.7424295255090958, 0.16360281335132354, 0.16360281335132354, 0.16360281335132354, 0.7787233078953587, 0.7787233078953587, 0.7787233078953587, 0.6864379667833054, 0.6864379667833054, 0.6864379667833054, 0.20954767599706114, 0.20954767599706114, 0.20954767599706114, 0.5250107589216552, 0.5250107589216552, 0.5250107589216552, 0.1978655172067132, 0.1978655172067132, 0.1978655172067132, 0.16373718664922376, 0.16373718664922376, 0.16373718664922376, 0.195695680947217, 0.195695680947217, 0.195695680947217, 0.07529581943051489, 0.07529581943051489, 0.07529581943051489, 0.0742746602426343, 0.0742746602426343, 0.0742746602426343, 0.08423668137865226, 0.08423668137865226, 0.08423668137865226]}, "mutation_prompt": null}
{"id": "fa97a2f4-93a4-407f-bf8c-1f9e45ef1f74", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with minor tuning in parameter values for improving convergence speed.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6731653111579229, 0.6731653111579229, 0.6731653111579229, 0.711996635129519, 0.711996635129519, 0.711996635129519, 0.7078132901593165, 0.7078132901593165, 0.7078132901593165, 0.041381141768779384, 0.041381141768779384, 0.041381141768779384, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10950771709447105, 0.10950771709447105, 0.10950771709447105, 0.10521185649440323, 0.10521185649440323, 0.10521185649440323, 0.10507361746539623, 0.10507361746539623, 0.10507361746539623, 0.07764468958329585, 0.07764468958329585, 0.07764468958329585, 0.09106825770888427, 0.09106825770888427, 0.09106825770888427, 0.11676664795008551, 0.11676664795008551, 0.11676664795008551, 0.8873949697611814, 0.8873949697611814, 0.8873949697611814, 0.8899603182064498, 0.8899603182064498, 0.8899603182064498, 0.9242514104464227, 0.9242514104464227, 0.9242514104464227, 0.15529290578465005, 0.15529290578465005, 0.15529290578465005, 0.2190096480227307, 0.2190096480227307, 0.2190096480227307, 0.10602395596155945, 0.10602395596155945, 0.10602395596155945, 0.6785064774824554, 0.6785064774824554, 0.6785064774824554, 0.1588220386151905, 0.1588220386151905, 0.1588220386151905, 0.2013731947684061, 0.2013731947684061, 0.2013731947684061, 0.11757177930520302, 0.11757177930520302, 0.11757177930520302, 0.05893689880031361, 0.05893689880031361, 0.05893689880031361, 0.1347567060589916, 0.1347567060589916, 0.1347567060589916, 0.12717657197932586, 0.12717657197932586, 0.12717657197932586, 0.13013401995367202, 0.13013401995367202, 0.13013401995367202, 0.12393529212556109, 0.12393529212556109, 0.12393529212556109, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07406251021116783, 0.07406251021116783, 0.07406251021116783, 0.06698612153091676, 0.06698612153091676, 0.06698612153091676, 0.08330193363389515, 0.08330193363389515, 0.08330193363389515, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05394537933586785, 0.05394537933586785, 0.05394537933586785, 0.06280509881780472, 0.06280509881780472, 0.06280509881780472, 0.058389177628910716, 0.058389177628910716, 0.058389177628910716, 0.4471312292357341, 0.4471312292357341, 0.4471312292357341, 0.5243508001071969, 0.5243508001071969, 0.5243508001071969, 0.46983387154224854, 0.46983387154224854, 0.46983387154224854, 0.07663158410172577, 0.07663158410172577, 0.07663158410172577, 0.10886105391076506, 0.10886105391076506, 0.10886105391076506, 0.1298840489061095, 0.1298840489061095, 0.1298840489061095, 0.1594612677021673, 0.1594612677021673, 0.1594612677021673, 0.2988572920911492, 0.2988572920911492, 0.2988572920911492, 0.24455433586052078, 0.24455433586052078, 0.24455433586052078, 0.35593401052672236, 0.35593401052672236, 0.35593401052672236, 0.41401688285636506, 0.41401688285636506, 0.41401688285636506, 0.23348098648385784, 0.23348098648385784, 0.23348098648385784, 0.25155973801749965, 0.25155973801749965, 0.25155973801749965, 0.16473215297233235, 0.16473215297233235, 0.16473215297233235, 0.2618969115729881, 0.2618969115729881, 0.2618969115729881, 0.21816177922955693, 0.21816177922955693, 0.21816177922955693, 0.19590613448642658, 0.19590613448642658, 0.19590613448642658, 0.24283886563718105, 0.24283886563718105, 0.24283886563718105, 0.18712908296437525, 0.18712908296437525, 0.18712908296437525, 0.16823242717066367, 0.16823242717066367, 0.16823242717066367, 0.19714396552649538, 0.19714396552649538, 0.19714396552649538, 0.7424295255090958, 0.7424295255090958, 0.7424295255090958, 0.16360281335132354, 0.16360281335132354, 0.16360281335132354, 0.7787233078953587, 0.7787233078953587, 0.7787233078953587, 0.6864379667833054, 0.6864379667833054, 0.6864379667833054, 0.20954767599706114, 0.20954767599706114, 0.20954767599706114, 0.5250107589216552, 0.5250107589216552, 0.5250107589216552, 0.1978655172067132, 0.1978655172067132, 0.1978655172067132, 0.16373718664922376, 0.16373718664922376, 0.16373718664922376, 0.195695680947217, 0.195695680947217, 0.195695680947217, 0.07529581943051489, 0.07529581943051489, 0.07529581943051489, 0.0742746602426343, 0.0742746602426343, 0.0742746602426343, 0.08423668137865226, 0.08423668137865226, 0.08423668137865226]}, "mutation_prompt": null}
{"id": "22488287-8528-448b-b4b1-bcd97a678478", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with minor tuning in parameter values for improving convergence speed.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6731653111579229, 0.6731653111579229, 0.6731653111579229, 0.711996635129519, 0.711996635129519, 0.711996635129519, 0.7078132901593165, 0.7078132901593165, 0.7078132901593165, 0.041381141768779384, 0.041381141768779384, 0.041381141768779384, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10950771709447105, 0.10950771709447105, 0.10950771709447105, 0.10521185649440323, 0.10521185649440323, 0.10521185649440323, 0.10507361746539623, 0.10507361746539623, 0.10507361746539623, 0.07764468958329585, 0.07764468958329585, 0.07764468958329585, 0.09106825770888427, 0.09106825770888427, 0.09106825770888427, 0.11676664795008551, 0.11676664795008551, 0.11676664795008551, 0.8873949697611814, 0.8873949697611814, 0.8873949697611814, 0.8899603182064498, 0.8899603182064498, 0.8899603182064498, 0.9242514104464227, 0.9242514104464227, 0.9242514104464227, 0.15529290578465005, 0.15529290578465005, 0.15529290578465005, 0.2190096480227307, 0.2190096480227307, 0.2190096480227307, 0.10602395596155945, 0.10602395596155945, 0.10602395596155945, 0.6785064774824554, 0.6785064774824554, 0.6785064774824554, 0.1588220386151905, 0.1588220386151905, 0.1588220386151905, 0.2013731947684061, 0.2013731947684061, 0.2013731947684061, 0.11757177930520302, 0.11757177930520302, 0.11757177930520302, 0.05893689880031361, 0.05893689880031361, 0.05893689880031361, 0.1347567060589916, 0.1347567060589916, 0.1347567060589916, 0.12717657197932586, 0.12717657197932586, 0.12717657197932586, 0.13013401995367202, 0.13013401995367202, 0.13013401995367202, 0.12393529212556109, 0.12393529212556109, 0.12393529212556109, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07406251021116783, 0.07406251021116783, 0.07406251021116783, 0.06698612153091676, 0.06698612153091676, 0.06698612153091676, 0.08330193363389515, 0.08330193363389515, 0.08330193363389515, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05394537933586785, 0.05394537933586785, 0.05394537933586785, 0.06280509881780472, 0.06280509881780472, 0.06280509881780472, 0.058389177628910716, 0.058389177628910716, 0.058389177628910716, 0.4471312292357341, 0.4471312292357341, 0.4471312292357341, 0.5243508001071969, 0.5243508001071969, 0.5243508001071969, 0.46983387154224854, 0.46983387154224854, 0.46983387154224854, 0.07663158410172577, 0.07663158410172577, 0.07663158410172577, 0.10886105391076506, 0.10886105391076506, 0.10886105391076506, 0.1298840489061095, 0.1298840489061095, 0.1298840489061095, 0.1594612677021673, 0.1594612677021673, 0.1594612677021673, 0.2988572920911492, 0.2988572920911492, 0.2988572920911492, 0.24455433586052078, 0.24455433586052078, 0.24455433586052078, 0.35593401052672236, 0.35593401052672236, 0.35593401052672236, 0.41401688285636506, 0.41401688285636506, 0.41401688285636506, 0.23348098648385784, 0.23348098648385784, 0.23348098648385784, 0.25155973801749965, 0.25155973801749965, 0.25155973801749965, 0.16473215297233235, 0.16473215297233235, 0.16473215297233235, 0.2618969115729881, 0.2618969115729881, 0.2618969115729881, 0.21816177922955693, 0.21816177922955693, 0.21816177922955693, 0.19590613448642658, 0.19590613448642658, 0.19590613448642658, 0.24283886563718105, 0.24283886563718105, 0.24283886563718105, 0.18712908296437525, 0.18712908296437525, 0.18712908296437525, 0.16823242717066367, 0.16823242717066367, 0.16823242717066367, 0.19714396552649538, 0.19714396552649538, 0.19714396552649538, 0.7424295255090958, 0.7424295255090958, 0.7424295255090958, 0.16360281335132354, 0.16360281335132354, 0.16360281335132354, 0.7787233078953587, 0.7787233078953587, 0.7787233078953587, 0.6864379667833054, 0.6864379667833054, 0.6864379667833054, 0.20954767599706114, 0.20954767599706114, 0.20954767599706114, 0.5250107589216552, 0.5250107589216552, 0.5250107589216552, 0.1978655172067132, 0.1978655172067132, 0.1978655172067132, 0.16373718664922376, 0.16373718664922376, 0.16373718664922376, 0.195695680947217, 0.195695680947217, 0.195695680947217, 0.07529581943051489, 0.07529581943051489, 0.07529581943051489, 0.0742746602426343, 0.0742746602426343, 0.0742746602426343, 0.08423668137865226, 0.08423668137865226, 0.08423668137865226]}, "mutation_prompt": null}
{"id": "e552846d-26b4-4d47-9f95-3eb16cebc216", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with minor tuning in parameter values for improving convergence speed.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6731653111579229, 0.6731653111579229, 0.6731653111579229, 0.711996635129519, 0.711996635129519, 0.711996635129519, 0.7078132901593165, 0.7078132901593165, 0.7078132901593165, 0.041381141768779384, 0.041381141768779384, 0.041381141768779384, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10950771709447105, 0.10950771709447105, 0.10950771709447105, 0.10521185649440323, 0.10521185649440323, 0.10521185649440323, 0.10507361746539623, 0.10507361746539623, 0.10507361746539623, 0.07764468958329585, 0.07764468958329585, 0.07764468958329585, 0.09106825770888427, 0.09106825770888427, 0.09106825770888427, 0.11676664795008551, 0.11676664795008551, 0.11676664795008551, 0.8873949697611814, 0.8873949697611814, 0.8873949697611814, 0.8899603182064498, 0.8899603182064498, 0.8899603182064498, 0.9242514104464227, 0.9242514104464227, 0.9242514104464227, 0.15529290578465005, 0.15529290578465005, 0.15529290578465005, 0.2190096480227307, 0.2190096480227307, 0.2190096480227307, 0.10602395596155945, 0.10602395596155945, 0.10602395596155945, 0.6785064774824554, 0.6785064774824554, 0.6785064774824554, 0.1588220386151905, 0.1588220386151905, 0.1588220386151905, 0.2013731947684061, 0.2013731947684061, 0.2013731947684061, 0.11757177930520302, 0.11757177930520302, 0.11757177930520302, 0.05893689880031361, 0.05893689880031361, 0.05893689880031361, 0.1347567060589916, 0.1347567060589916, 0.1347567060589916, 0.12717657197932586, 0.12717657197932586, 0.12717657197932586, 0.13013401995367202, 0.13013401995367202, 0.13013401995367202, 0.12393529212556109, 0.12393529212556109, 0.12393529212556109, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07406251021116783, 0.07406251021116783, 0.07406251021116783, 0.06698612153091676, 0.06698612153091676, 0.06698612153091676, 0.08330193363389515, 0.08330193363389515, 0.08330193363389515, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05394537933586785, 0.05394537933586785, 0.05394537933586785, 0.06280509881780472, 0.06280509881780472, 0.06280509881780472, 0.058389177628910716, 0.058389177628910716, 0.058389177628910716, 0.4471312292357341, 0.4471312292357341, 0.4471312292357341, 0.5243508001071969, 0.5243508001071969, 0.5243508001071969, 0.46983387154224854, 0.46983387154224854, 0.46983387154224854, 0.07663158410172577, 0.07663158410172577, 0.07663158410172577, 0.10886105391076506, 0.10886105391076506, 0.10886105391076506, 0.1298840489061095, 0.1298840489061095, 0.1298840489061095, 0.1594612677021673, 0.1594612677021673, 0.1594612677021673, 0.2988572920911492, 0.2988572920911492, 0.2988572920911492, 0.24455433586052078, 0.24455433586052078, 0.24455433586052078, 0.35593401052672236, 0.35593401052672236, 0.35593401052672236, 0.41401688285636506, 0.41401688285636506, 0.41401688285636506, 0.23348098648385784, 0.23348098648385784, 0.23348098648385784, 0.25155973801749965, 0.25155973801749965, 0.25155973801749965, 0.16473215297233235, 0.16473215297233235, 0.16473215297233235, 0.2618969115729881, 0.2618969115729881, 0.2618969115729881, 0.21816177922955693, 0.21816177922955693, 0.21816177922955693, 0.19590613448642658, 0.19590613448642658, 0.19590613448642658, 0.24283886563718105, 0.24283886563718105, 0.24283886563718105, 0.18712908296437525, 0.18712908296437525, 0.18712908296437525, 0.16823242717066367, 0.16823242717066367, 0.16823242717066367, 0.19714396552649538, 0.19714396552649538, 0.19714396552649538, 0.7424295255090958, 0.7424295255090958, 0.7424295255090958, 0.16360281335132354, 0.16360281335132354, 0.16360281335132354, 0.7787233078953587, 0.7787233078953587, 0.7787233078953587, 0.6864379667833054, 0.6864379667833054, 0.6864379667833054, 0.20954767599706114, 0.20954767599706114, 0.20954767599706114, 0.5250107589216552, 0.5250107589216552, 0.5250107589216552, 0.1978655172067132, 0.1978655172067132, 0.1978655172067132, 0.16373718664922376, 0.16373718664922376, 0.16373718664922376, 0.195695680947217, 0.195695680947217, 0.195695680947217, 0.07529581943051489, 0.07529581943051489, 0.07529581943051489, 0.0742746602426343, 0.0742746602426343, 0.0742746602426343, 0.08423668137865226, 0.08423668137865226, 0.08423668137865226]}, "mutation_prompt": null}
{"id": "6b9a0b2a-3234-457d-82c6-a30ff58ab66a", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with minor tuning in parameter values for improving convergence speed.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6731653111579229, 0.6731653111579229, 0.6731653111579229, 0.711996635129519, 0.711996635129519, 0.711996635129519, 0.7078132901593165, 0.7078132901593165, 0.7078132901593165, 0.041381141768779384, 0.041381141768779384, 0.041381141768779384, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10950771709447105, 0.10950771709447105, 0.10950771709447105, 0.10521185649440323, 0.10521185649440323, 0.10521185649440323, 0.10507361746539623, 0.10507361746539623, 0.10507361746539623, 0.07764468958329585, 0.07764468958329585, 0.07764468958329585, 0.09106825770888427, 0.09106825770888427, 0.09106825770888427, 0.11676664795008551, 0.11676664795008551, 0.11676664795008551, 0.8873949697611814, 0.8873949697611814, 0.8873949697611814, 0.8899603182064498, 0.8899603182064498, 0.8899603182064498, 0.9242514104464227, 0.9242514104464227, 0.9242514104464227, 0.15529290578465005, 0.15529290578465005, 0.15529290578465005, 0.2190096480227307, 0.2190096480227307, 0.2190096480227307, 0.10602395596155945, 0.10602395596155945, 0.10602395596155945, 0.6785064774824554, 0.6785064774824554, 0.6785064774824554, 0.1588220386151905, 0.1588220386151905, 0.1588220386151905, 0.2013731947684061, 0.2013731947684061, 0.2013731947684061, 0.11757177930520302, 0.11757177930520302, 0.11757177930520302, 0.05893689880031361, 0.05893689880031361, 0.05893689880031361, 0.1347567060589916, 0.1347567060589916, 0.1347567060589916, 0.12717657197932586, 0.12717657197932586, 0.12717657197932586, 0.13013401995367202, 0.13013401995367202, 0.13013401995367202, 0.12393529212556109, 0.12393529212556109, 0.12393529212556109, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07406251021116783, 0.07406251021116783, 0.07406251021116783, 0.06698612153091676, 0.06698612153091676, 0.06698612153091676, 0.08330193363389515, 0.08330193363389515, 0.08330193363389515, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05394537933586785, 0.05394537933586785, 0.05394537933586785, 0.06280509881780472, 0.06280509881780472, 0.06280509881780472, 0.058389177628910716, 0.058389177628910716, 0.058389177628910716, 0.4471312292357341, 0.4471312292357341, 0.4471312292357341, 0.5243508001071969, 0.5243508001071969, 0.5243508001071969, 0.46983387154224854, 0.46983387154224854, 0.46983387154224854, 0.07663158410172577, 0.07663158410172577, 0.07663158410172577, 0.10886105391076506, 0.10886105391076506, 0.10886105391076506, 0.1298840489061095, 0.1298840489061095, 0.1298840489061095, 0.1594612677021673, 0.1594612677021673, 0.1594612677021673, 0.2988572920911492, 0.2988572920911492, 0.2988572920911492, 0.24455433586052078, 0.24455433586052078, 0.24455433586052078, 0.35593401052672236, 0.35593401052672236, 0.35593401052672236, 0.41401688285636506, 0.41401688285636506, 0.41401688285636506, 0.23348098648385784, 0.23348098648385784, 0.23348098648385784, 0.25155973801749965, 0.25155973801749965, 0.25155973801749965, 0.16473215297233235, 0.16473215297233235, 0.16473215297233235, 0.2618969115729881, 0.2618969115729881, 0.2618969115729881, 0.21816177922955693, 0.21816177922955693, 0.21816177922955693, 0.19590613448642658, 0.19590613448642658, 0.19590613448642658, 0.24283886563718105, 0.24283886563718105, 0.24283886563718105, 0.18712908296437525, 0.18712908296437525, 0.18712908296437525, 0.16823242717066367, 0.16823242717066367, 0.16823242717066367, 0.19714396552649538, 0.19714396552649538, 0.19714396552649538, 0.7424295255090958, 0.7424295255090958, 0.7424295255090958, 0.16360281335132354, 0.16360281335132354, 0.16360281335132354, 0.7787233078953587, 0.7787233078953587, 0.7787233078953587, 0.6864379667833054, 0.6864379667833054, 0.6864379667833054, 0.20954767599706114, 0.20954767599706114, 0.20954767599706114, 0.5250107589216552, 0.5250107589216552, 0.5250107589216552, 0.1978655172067132, 0.1978655172067132, 0.1978655172067132, 0.16373718664922376, 0.16373718664922376, 0.16373718664922376, 0.195695680947217, 0.195695680947217, 0.195695680947217, 0.07529581943051489, 0.07529581943051489, 0.07529581943051489, 0.0742746602426343, 0.0742746602426343, 0.0742746602426343, 0.08423668137865226, 0.08423668137865226, 0.08423668137865226]}, "mutation_prompt": null}
{"id": "160dc12d-4a70-4b27-b284-43fd8b90c91d", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with minor tuning in parameter values for improving convergence speed.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6731653111579229, 0.6731653111579229, 0.6731653111579229, 0.711996635129519, 0.711996635129519, 0.711996635129519, 0.7078132901593165, 0.7078132901593165, 0.7078132901593165, 0.041381141768779384, 0.041381141768779384, 0.041381141768779384, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10950771709447105, 0.10950771709447105, 0.10950771709447105, 0.10521185649440323, 0.10521185649440323, 0.10521185649440323, 0.10507361746539623, 0.10507361746539623, 0.10507361746539623, 0.07764468958329585, 0.07764468958329585, 0.07764468958329585, 0.09106825770888427, 0.09106825770888427, 0.09106825770888427, 0.11676664795008551, 0.11676664795008551, 0.11676664795008551, 0.8873949697611814, 0.8873949697611814, 0.8873949697611814, 0.8899603182064498, 0.8899603182064498, 0.8899603182064498, 0.9242514104464227, 0.9242514104464227, 0.9242514104464227, 0.15529290578465005, 0.15529290578465005, 0.15529290578465005, 0.2190096480227307, 0.2190096480227307, 0.2190096480227307, 0.10602395596155945, 0.10602395596155945, 0.10602395596155945, 0.6785064774824554, 0.6785064774824554, 0.6785064774824554, 0.1588220386151905, 0.1588220386151905, 0.1588220386151905, 0.2013731947684061, 0.2013731947684061, 0.2013731947684061, 0.11757177930520302, 0.11757177930520302, 0.11757177930520302, 0.05893689880031361, 0.05893689880031361, 0.05893689880031361, 0.1347567060589916, 0.1347567060589916, 0.1347567060589916, 0.12717657197932586, 0.12717657197932586, 0.12717657197932586, 0.13013401995367202, 0.13013401995367202, 0.13013401995367202, 0.12393529212556109, 0.12393529212556109, 0.12393529212556109, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07406251021116783, 0.07406251021116783, 0.07406251021116783, 0.06698612153091676, 0.06698612153091676, 0.06698612153091676, 0.08330193363389515, 0.08330193363389515, 0.08330193363389515, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05394537933586785, 0.05394537933586785, 0.05394537933586785, 0.06280509881780472, 0.06280509881780472, 0.06280509881780472, 0.058389177628910716, 0.058389177628910716, 0.058389177628910716, 0.4471312292357341, 0.4471312292357341, 0.4471312292357341, 0.5243508001071969, 0.5243508001071969, 0.5243508001071969, 0.46983387154224854, 0.46983387154224854, 0.46983387154224854, 0.07663158410172577, 0.07663158410172577, 0.07663158410172577, 0.10886105391076506, 0.10886105391076506, 0.10886105391076506, 0.1298840489061095, 0.1298840489061095, 0.1298840489061095, 0.1594612677021673, 0.1594612677021673, 0.1594612677021673, 0.2988572920911492, 0.2988572920911492, 0.2988572920911492, 0.24455433586052078, 0.24455433586052078, 0.24455433586052078, 0.35593401052672236, 0.35593401052672236, 0.35593401052672236, 0.41401688285636506, 0.41401688285636506, 0.41401688285636506, 0.23348098648385784, 0.23348098648385784, 0.23348098648385784, 0.25155973801749965, 0.25155973801749965, 0.25155973801749965, 0.16473215297233235, 0.16473215297233235, 0.16473215297233235, 0.2618969115729881, 0.2618969115729881, 0.2618969115729881, 0.21816177922955693, 0.21816177922955693, 0.21816177922955693, 0.19590613448642658, 0.19590613448642658, 0.19590613448642658, 0.24283886563718105, 0.24283886563718105, 0.24283886563718105, 0.18712908296437525, 0.18712908296437525, 0.18712908296437525, 0.16823242717066367, 0.16823242717066367, 0.16823242717066367, 0.19714396552649538, 0.19714396552649538, 0.19714396552649538, 0.7424295255090958, 0.7424295255090958, 0.7424295255090958, 0.16360281335132354, 0.16360281335132354, 0.16360281335132354, 0.7787233078953587, 0.7787233078953587, 0.7787233078953587, 0.6864379667833054, 0.6864379667833054, 0.6864379667833054, 0.20954767599706114, 0.20954767599706114, 0.20954767599706114, 0.5250107589216552, 0.5250107589216552, 0.5250107589216552, 0.1978655172067132, 0.1978655172067132, 0.1978655172067132, 0.16373718664922376, 0.16373718664922376, 0.16373718664922376, 0.195695680947217, 0.195695680947217, 0.195695680947217, 0.07529581943051489, 0.07529581943051489, 0.07529581943051489, 0.0742746602426343, 0.0742746602426343, 0.0742746602426343, 0.08423668137865226, 0.08423668137865226, 0.08423668137865226]}, "mutation_prompt": null}
{"id": "35d5bb32-b9a7-45a2-b716-3d2b5af1fac4", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85 \n        self.w_min = 0.4\n        self.c1 = 1.7 \n        self.c2 = 1.3 \n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96 \n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n            # New adjustment: dynamically adjust swarm size and velocity bounds\n            if evaluations > 0.5 * self.budget:\n                self.swarm_size = int(self.swarm_size * 1.1)\n                particles = np.resize(particles, (self.swarm_size, self.dim))\n                velocities = np.resize(velocities, (self.swarm_size, self.dim))\n                self.vel_bounds = (-0.5, 0.5)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Improved PSO-SA with dynamic swarm size and adaptive velocity bounds for enhanced convergence.", "configspace": "", "generation": 74, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 40 is out of bounds for axis 0 with size 40').", "error": "IndexError('index 40 is out of bounds for axis 0 with size 40')", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {}, "mutation_prompt": null}
{"id": "6e72059d-d693-4ab0-bd7f-9e3d586c83cc", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2 = 1.3\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n        # New: Calculate swarm reduction factor\n        self.swarm_reduction = int(self.swarm_size / 10)\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n        swarm_size = self.swarm_size\n\n        while evaluations < self.budget:\n            for i in range(swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n            # New: Reduce swarm size as budget depletes\n            if evaluations > self.budget / 2 and swarm_size > self.swarm_reduction:\n                swarm_size -= self.swarm_reduction\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Introduced a dynamic swarm size reduction strategy to enhance convergence speed while adhering to a 2.0% code modification limit.", "configspace": "", "generation": 75, "fitness": 0.2346883442183945, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.24.", "error": "", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6588506153232523, 0.6588506153232523, 0.6588506153232523, 0.7086341174038882, 0.7086341174038882, 0.7086341174038882, 0.7103555584365822, 0.7103555584365822, 0.7103555584365822, 0.06365295990687958, 0.06365295990687958, 0.06365295990687958, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10845160275169563, 0.10845160275169563, 0.10845160275169563, 0.08967095354206445, 0.08967095354206445, 0.08967095354206445, 0.10436527698186215, 0.10436527698186215, 0.10436527698186215, 0.07793629057654361, 0.07793629057654361, 0.07793629057654361, 0.09017990790760455, 0.09017990790760455, 0.09017990790760455, 0.11599678193019203, 0.11599678193019203, 0.11599678193019203, 0.8873949697611814, 0.8873949697611814, 0.8873949697611814, 0.8899603182064498, 0.8899603182064498, 0.8899603182064498, 0.9242514104464227, 0.9242514104464227, 0.9242514104464227, 0.1543074577191561, 0.1543074577191561, 0.1543074577191561, 0.21892056451455122, 0.21892056451455122, 0.21892056451455122, 0.10929770793993232, 0.10929770793993232, 0.10929770793993232, 0.6785064774824554, 0.6785064774824554, 0.6785064774824554, 0.1588220386151905, 0.1588220386151905, 0.1588220386151905, 0.2013731947684061, 0.2013731947684061, 0.2013731947684061, 0.11749039286816698, 0.11749039286816698, 0.11749039286816698, 0.057157236488800445, 0.057157236488800445, 0.057157236488800445, 0.1376559767823724, 0.1376559767823724, 0.1376559767823724, 0.12686201207541659, 0.12686201207541659, 0.12686201207541659, 0.13023670696741008, 0.13023670696741008, 0.13023670696741008, 0.12255046677122916, 0.12255046677122916, 0.12255046677122916, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07408659373874049, 0.07408659373874049, 0.07408659373874049, 0.06689088930962339, 0.06689088930962339, 0.06689088930962339, 0.09132016914390229, 0.09132016914390229, 0.09132016914390229, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04897856528537636, 0.04897856528537636, 0.04897856528537636, 0.06279278350485407, 0.06279278350485407, 0.06279278350485407, 0.055352304017081355, 0.055352304017081355, 0.055352304017081355, 0.4231844483681213, 0.4231844483681213, 0.4231844483681213, 0.516421482502958, 0.516421482502958, 0.516421482502958, 0.449020085981087, 0.449020085981087, 0.449020085981087, 0.0765753573601029, 0.0765753573601029, 0.0765753573601029, 0.10593541353795555, 0.10593541353795555, 0.10593541353795555, 0.12942807195419714, 0.12942807195419714, 0.12942807195419714, 0.15958847663023734, 0.15958847663023734, 0.15958847663023734, 0.26406661323128366, 0.26406661323128366, 0.26406661323128366, 0.2333738121115826, 0.2333738121115826, 0.2333738121115826, 0.35133756876719513, 0.35133756876719513, 0.35133756876719513, 0.3533422583635364, 0.3533422583635364, 0.3533422583635364, 0.2318559911884871, 0.2318559911884871, 0.2318559911884871, 0.24940102649951412, 0.24940102649951412, 0.24940102649951412, 0.16508368155539777, 0.16508368155539777, 0.16508368155539777, 0.25278705463063056, 0.25278705463063056, 0.25278705463063056, 0.2168480617787002, 0.2168480617787002, 0.2168480617787002, 0.2002816322002282, 0.2002816322002282, 0.2002816322002282, 0.23274893758342785, 0.23274893758342785, 0.23274893758342785, 0.18772722921971874, 0.18772722921971874, 0.18772722921971874, 0.1682385410662619, 0.1682385410662619, 0.1682385410662619, 0.20007522884696083, 0.20007522884696083, 0.20007522884696083, 0.7424295255090958, 0.7424295255090958, 0.7424295255090958, 0.16357962209883403, 0.16357962209883403, 0.16357962209883403, 0.7787233078953587, 0.7787233078953587, 0.7787233078953587, 0.6271892873079246, 0.6271892873079246, 0.6271892873079246, 0.20954763001664967, 0.20954763001664967, 0.20954763001664967, 0.38752518254856083, 0.38752518254856083, 0.38752518254856083, 0.19877737539694162, 0.19877737539694162, 0.19877737539694162, 0.16723425834065242, 0.16723425834065242, 0.16723425834065242, 0.18339034928821862, 0.18339034928821862, 0.18339034928821862, 0.0755387645509552, 0.0755387645509552, 0.0755387645509552, 0.07097415127218099, 0.07097415127218099, 0.07097415127218099, 0.08222805495416252, 0.08222805495416252, 0.08222805495416252]}, "mutation_prompt": null}
{"id": "d2d216b8-868a-40f0-a9d8-0ebcfe7bde76", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with minor tuning in parameter values for improving convergence speed.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6731653111579229, 0.6731653111579229, 0.6731653111579229, 0.711996635129519, 0.711996635129519, 0.711996635129519, 0.7078132901593165, 0.7078132901593165, 0.7078132901593165, 0.041381141768779384, 0.041381141768779384, 0.041381141768779384, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10950771709447105, 0.10950771709447105, 0.10950771709447105, 0.10521185649440323, 0.10521185649440323, 0.10521185649440323, 0.10507361746539623, 0.10507361746539623, 0.10507361746539623, 0.07764468958329585, 0.07764468958329585, 0.07764468958329585, 0.09106825770888427, 0.09106825770888427, 0.09106825770888427, 0.11676664795008551, 0.11676664795008551, 0.11676664795008551, 0.8873949697611814, 0.8873949697611814, 0.8873949697611814, 0.8899603182064498, 0.8899603182064498, 0.8899603182064498, 0.9242514104464227, 0.9242514104464227, 0.9242514104464227, 0.15529290578465005, 0.15529290578465005, 0.15529290578465005, 0.2190096480227307, 0.2190096480227307, 0.2190096480227307, 0.10602395596155945, 0.10602395596155945, 0.10602395596155945, 0.6785064774824554, 0.6785064774824554, 0.6785064774824554, 0.1588220386151905, 0.1588220386151905, 0.1588220386151905, 0.2013731947684061, 0.2013731947684061, 0.2013731947684061, 0.11757177930520302, 0.11757177930520302, 0.11757177930520302, 0.05893689880031361, 0.05893689880031361, 0.05893689880031361, 0.1347567060589916, 0.1347567060589916, 0.1347567060589916, 0.12717657197932586, 0.12717657197932586, 0.12717657197932586, 0.13013401995367202, 0.13013401995367202, 0.13013401995367202, 0.12393529212556109, 0.12393529212556109, 0.12393529212556109, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07406251021116783, 0.07406251021116783, 0.07406251021116783, 0.06698612153091676, 0.06698612153091676, 0.06698612153091676, 0.08330193363389515, 0.08330193363389515, 0.08330193363389515, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05394537933586785, 0.05394537933586785, 0.05394537933586785, 0.06280509881780472, 0.06280509881780472, 0.06280509881780472, 0.058389177628910716, 0.058389177628910716, 0.058389177628910716, 0.4471312292357341, 0.4471312292357341, 0.4471312292357341, 0.5243508001071969, 0.5243508001071969, 0.5243508001071969, 0.46983387154224854, 0.46983387154224854, 0.46983387154224854, 0.07663158410172577, 0.07663158410172577, 0.07663158410172577, 0.10886105391076506, 0.10886105391076506, 0.10886105391076506, 0.1298840489061095, 0.1298840489061095, 0.1298840489061095, 0.1594612677021673, 0.1594612677021673, 0.1594612677021673, 0.2988572920911492, 0.2988572920911492, 0.2988572920911492, 0.24455433586052078, 0.24455433586052078, 0.24455433586052078, 0.35593401052672236, 0.35593401052672236, 0.35593401052672236, 0.41401688285636506, 0.41401688285636506, 0.41401688285636506, 0.23348098648385784, 0.23348098648385784, 0.23348098648385784, 0.25155973801749965, 0.25155973801749965, 0.25155973801749965, 0.16473215297233235, 0.16473215297233235, 0.16473215297233235, 0.2618969115729881, 0.2618969115729881, 0.2618969115729881, 0.21816177922955693, 0.21816177922955693, 0.21816177922955693, 0.19590613448642658, 0.19590613448642658, 0.19590613448642658, 0.24283886563718105, 0.24283886563718105, 0.24283886563718105, 0.18712908296437525, 0.18712908296437525, 0.18712908296437525, 0.16823242717066367, 0.16823242717066367, 0.16823242717066367, 0.19714396552649538, 0.19714396552649538, 0.19714396552649538, 0.7424295255090958, 0.7424295255090958, 0.7424295255090958, 0.16360281335132354, 0.16360281335132354, 0.16360281335132354, 0.7787233078953587, 0.7787233078953587, 0.7787233078953587, 0.6864379667833054, 0.6864379667833054, 0.6864379667833054, 0.20954767599706114, 0.20954767599706114, 0.20954767599706114, 0.5250107589216552, 0.5250107589216552, 0.5250107589216552, 0.1978655172067132, 0.1978655172067132, 0.1978655172067132, 0.16373718664922376, 0.16373718664922376, 0.16373718664922376, 0.195695680947217, 0.195695680947217, 0.195695680947217, 0.07529581943051489, 0.07529581943051489, 0.07529581943051489, 0.0742746602426343, 0.0742746602426343, 0.0742746602426343, 0.08423668137865226, 0.08423668137865226, 0.08423668137865226]}, "mutation_prompt": null}
{"id": "ed38aa36-0f31-4968-9ef4-bf5ff1fb2c40", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85  # Slightly adjusted initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.7  # Slightly increased cognitive coefficient\n        self.c2 = 1.3  # Slightly decreased social coefficient\n        self.temp_init = 100.0\n        self.temp_end = 1.0\n        self.adaptive_factor = 0.96  # Adjusted adaptive cooling rate\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.99)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with minor tuning in parameter values for improving convergence speed.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.6731653111579229, 0.6731653111579229, 0.6731653111579229, 0.711996635129519, 0.711996635129519, 0.711996635129519, 0.7078132901593165, 0.7078132901593165, 0.7078132901593165, 0.041381141768779384, 0.041381141768779384, 0.041381141768779384, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10950771709447105, 0.10950771709447105, 0.10950771709447105, 0.10521185649440323, 0.10521185649440323, 0.10521185649440323, 0.10507361746539623, 0.10507361746539623, 0.10507361746539623, 0.07764468958329585, 0.07764468958329585, 0.07764468958329585, 0.09106825770888427, 0.09106825770888427, 0.09106825770888427, 0.11676664795008551, 0.11676664795008551, 0.11676664795008551, 0.8873949697611814, 0.8873949697611814, 0.8873949697611814, 0.8899603182064498, 0.8899603182064498, 0.8899603182064498, 0.9242514104464227, 0.9242514104464227, 0.9242514104464227, 0.15529290578465005, 0.15529290578465005, 0.15529290578465005, 0.2190096480227307, 0.2190096480227307, 0.2190096480227307, 0.10602395596155945, 0.10602395596155945, 0.10602395596155945, 0.6785064774824554, 0.6785064774824554, 0.6785064774824554, 0.1588220386151905, 0.1588220386151905, 0.1588220386151905, 0.2013731947684061, 0.2013731947684061, 0.2013731947684061, 0.11757177930520302, 0.11757177930520302, 0.11757177930520302, 0.05893689880031361, 0.05893689880031361, 0.05893689880031361, 0.1347567060589916, 0.1347567060589916, 0.1347567060589916, 0.12717657197932586, 0.12717657197932586, 0.12717657197932586, 0.13013401995367202, 0.13013401995367202, 0.13013401995367202, 0.12393529212556109, 0.12393529212556109, 0.12393529212556109, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07406251021116783, 0.07406251021116783, 0.07406251021116783, 0.06698612153091676, 0.06698612153091676, 0.06698612153091676, 0.08330193363389515, 0.08330193363389515, 0.08330193363389515, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05394537933586785, 0.05394537933586785, 0.05394537933586785, 0.06280509881780472, 0.06280509881780472, 0.06280509881780472, 0.058389177628910716, 0.058389177628910716, 0.058389177628910716, 0.4471312292357341, 0.4471312292357341, 0.4471312292357341, 0.5243508001071969, 0.5243508001071969, 0.5243508001071969, 0.46983387154224854, 0.46983387154224854, 0.46983387154224854, 0.07663158410172577, 0.07663158410172577, 0.07663158410172577, 0.10886105391076506, 0.10886105391076506, 0.10886105391076506, 0.1298840489061095, 0.1298840489061095, 0.1298840489061095, 0.1594612677021673, 0.1594612677021673, 0.1594612677021673, 0.2988572920911492, 0.2988572920911492, 0.2988572920911492, 0.24455433586052078, 0.24455433586052078, 0.24455433586052078, 0.35593401052672236, 0.35593401052672236, 0.35593401052672236, 0.41401688285636506, 0.41401688285636506, 0.41401688285636506, 0.23348098648385784, 0.23348098648385784, 0.23348098648385784, 0.25155973801749965, 0.25155973801749965, 0.25155973801749965, 0.16473215297233235, 0.16473215297233235, 0.16473215297233235, 0.2618969115729881, 0.2618969115729881, 0.2618969115729881, 0.21816177922955693, 0.21816177922955693, 0.21816177922955693, 0.19590613448642658, 0.19590613448642658, 0.19590613448642658, 0.24283886563718105, 0.24283886563718105, 0.24283886563718105, 0.18712908296437525, 0.18712908296437525, 0.18712908296437525, 0.16823242717066367, 0.16823242717066367, 0.16823242717066367, 0.19714396552649538, 0.19714396552649538, 0.19714396552649538, 0.7424295255090958, 0.7424295255090958, 0.7424295255090958, 0.16360281335132354, 0.16360281335132354, 0.16360281335132354, 0.7787233078953587, 0.7787233078953587, 0.7787233078953587, 0.6864379667833054, 0.6864379667833054, 0.6864379667833054, 0.20954767599706114, 0.20954767599706114, 0.20954767599706114, 0.5250107589216552, 0.5250107589216552, 0.5250107589216552, 0.1978655172067132, 0.1978655172067132, 0.1978655172067132, 0.16373718664922376, 0.16373718664922376, 0.16373718664922376, 0.195695680947217, 0.195695680947217, 0.195695680947217, 0.07529581943051489, 0.07529581943051489, 0.07529581943051489, 0.0742746602426343, 0.0742746602426343, 0.0742746602426343, 0.08423668137865226, 0.08423668137865226, 0.08423668137865226]}, "mutation_prompt": null}
{"id": "72805d8f-0a9e-4ca0-8cb1-c94b20fd4300", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85\n        self.w_min = 0.3  # Adjusted for more flexibility in inertia weight decay\n        self.c1 = 1.5  # Reduced to favor exploration in early iterations\n        self.c2 = 1.5  # Balanced cognitive and social coefficients\n        self.temp_init = 100.0\n        self.temp_end = 0.5  # Reduced final temperature for finer convergence\n        self.adaptive_factor = 0.95  # Slightly adjusted for more cooling\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.98)  # Enhanced inertia weight decay\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Hybrid PSO-SA optimizer with dynamic parameter adjustment and inertia weight decay for enhanced convergence.", "configspace": "", "generation": 78, "fitness": 0.2403369958489995, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.25.", "error": "", "parent_id": "e3c3db27-afb9-4911-8ba9-da5512a25802", "metadata": {"aucs": [0.7684536810562734, 0.7684536810562734, 0.7684536810562734, 0.7783342393159393, 0.7783342393159393, 0.7783342393159393, 0.7907584893895563, 0.7907584893895563, 0.7907584893895563, 0.023716334680747186, 0.023716334680747186, 0.023716334680747186, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.123716556057062, 0.123716556057062, 0.123716556057062, 0.11855042009176142, 0.11855042009176142, 0.11855042009176142, 0.07427313242322942, 0.07427313242322942, 0.07427313242322942, 0.04605844760145483, 0.04605844760145483, 0.04605844760145483, 0.08415775905915812, 0.08415775905915812, 0.08415775905915812, 0.05928895423944924, 0.05928895423944924, 0.05928895423944924, 0.85244715737466, 0.85244715737466, 0.85244715737466, 0.9085126883996072, 0.9085126883996072, 0.9085126883996072, 0.8807036227727707, 0.8807036227727707, 0.8807036227727707, 0.2199032064971268, 0.2199032064971268, 0.2199032064971268, 0.05814089475241324, 0.05814089475241324, 0.05814089475241324, 0.14613295523046832, 0.14613295523046832, 0.14613295523046832, 0.2184892435990431, 0.2184892435990431, 0.2184892435990431, 0.15327171757954516, 0.15327171757954516, 0.15327171757954516, 0.1618971498227635, 0.1618971498227635, 0.1618971498227635, 0.11701286325669824, 0.11701286325669824, 0.11701286325669824, 0.1089067035922413, 0.1089067035922413, 0.1089067035922413, 0.09444856596399964, 0.09444856596399964, 0.09444856596399964, 0.01404200961434543, 0.01404200961434543, 0.01404200961434543, 0.11551173920855273, 0.11551173920855273, 0.11551173920855273, 0.08301142225415625, 0.08301142225415625, 0.08301142225415625, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09167204097074777, 0.09167204097074777, 0.09167204097074777, 0.040772380399989205, 0.040772380399989205, 0.040772380399989205, 0.06950788399023045, 0.06950788399023045, 0.06950788399023045, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07680505696159146, 0.07680505696159146, 0.07680505696159146, 0.020627761503948516, 0.020627761503948516, 0.020627761503948516, 0.03460291094987189, 0.03460291094987189, 0.03460291094987189, 0.48579061994835226, 0.48579061994835226, 0.48579061994835226, 0.4601227374767123, 0.4601227374767123, 0.4601227374767123, 0.5156256632889341, 0.5156256632889341, 0.5156256632889341, 0.14261714449025453, 0.14261714449025453, 0.14261714449025453, 0.09844129849765448, 0.09844129849765448, 0.09844129849765448, 0.1020611630124102, 0.1020611630124102, 0.1020611630124102, 0.23306840158410302, 0.23306840158410302, 0.23306840158410302, 0.23462141498388556, 0.23462141498388556, 0.23462141498388556, 0.18481170273401804, 0.18481170273401804, 0.18481170273401804, 0.37259804304105715, 0.37259804304105715, 0.37259804304105715, 0.41277297198057017, 0.41277297198057017, 0.41277297198057017, 0.3991190271349615, 0.3991190271349615, 0.3991190271349615, 0.26548449616260006, 0.26548449616260006, 0.26548449616260006, 0.22155779927948938, 0.22155779927948938, 0.22155779927948938, 0.2255518417257517, 0.2255518417257517, 0.2255518417257517, 0.23537641008072585, 0.23537641008072585, 0.23537641008072585, 0.2643951220238553, 0.2643951220238553, 0.2643951220238553, 0.21178721817694623, 0.21178721817694623, 0.21178721817694623, 0.1847713365996646, 0.1847713365996646, 0.1847713365996646, 0.21104286522385918, 0.21104286522385918, 0.21104286522385918, 0.17443955694830326, 0.17443955694830326, 0.17443955694830326, 0.8352410597901369, 0.8352410597901369, 0.8352410597901369, 0.16234534471649908, 0.16234534471649908, 0.16234534471649908, 0.8283792081345414, 0.8283792081345414, 0.8283792081345414, 0.7107431615350103, 0.7107431615350103, 0.7107431615350103, 0.2088474926654168, 0.2088474926654168, 0.2088474926654168, 0.6566124764768064, 0.6566124764768064, 0.6566124764768064, 0.19523907155833664, 0.19523907155833664, 0.19523907155833664, 0.1873681614006295, 0.1873681614006295, 0.1873681614006295, 0.22402390441506737, 0.22402390441506737, 0.22402390441506737, 0.1278754757649393, 0.1278754757649393, 0.1278754757649393, 0.08850554191970439, 0.08850554191970439, 0.08850554191970439, 0.10849797974736797, 0.10849797974736797, 0.10849797974736797]}, "mutation_prompt": null}
{"id": "6cebcb75-0bbe-4715-b244-ce20c83747c6", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85\n        self.w_min = 0.3  # Adjusted for more flexibility in inertia weight decay\n        self.c1 = 1.5  # Reduced to favor exploration in early iterations\n        self.c2 = 1.5  # Balanced cognitive and social coefficients\n        self.temp_init = 100.0\n        self.temp_end = 0.5  # Reduced final temperature for finer convergence\n        self.adaptive_factor = 0.95  # Slightly adjusted for more cooling\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.98)  # Enhanced inertia weight decay\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Hybrid PSO-SA optimizer with dynamic parameter adjustment and inertia weight decay for enhanced convergence.", "configspace": "", "generation": 79, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "72805d8f-0a9e-4ca0-8cb1-c94b20fd4300", "metadata": {"aucs": [0.7684536810562734, 0.7684536810562734, 0.7684536810562734, 0.7783342393159393, 0.7783342393159393, 0.7783342393159393, 0.7907584893895563, 0.7907584893895563, 0.7907584893895563, 0.023716334680747186, 0.023716334680747186, 0.023716334680747186, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.123716556057062, 0.123716556057062, 0.123716556057062, 0.11855042009176142, 0.11855042009176142, 0.11855042009176142, 0.07427313242322942, 0.07427313242322942, 0.07427313242322942, 0.04605844760145483, 0.04605844760145483, 0.04605844760145483, 0.08415775905915812, 0.08415775905915812, 0.08415775905915812, 0.05928895423944924, 0.05928895423944924, 0.05928895423944924, 0.85244715737466, 0.85244715737466, 0.85244715737466, 0.9085126883996072, 0.9085126883996072, 0.9085126883996072, 0.8807036227727707, 0.8807036227727707, 0.8807036227727707, 0.2199032064971268, 0.2199032064971268, 0.2199032064971268, 0.05814089475241324, 0.05814089475241324, 0.05814089475241324, 0.14613295523046832, 0.14613295523046832, 0.14613295523046832, 0.2184892435990431, 0.2184892435990431, 0.2184892435990431, 0.15327171757954516, 0.15327171757954516, 0.15327171757954516, 0.1618971498227635, 0.1618971498227635, 0.1618971498227635, 0.11701286325669824, 0.11701286325669824, 0.11701286325669824, 0.1089067035922413, 0.1089067035922413, 0.1089067035922413, 0.09444856596399964, 0.09444856596399964, 0.09444856596399964, 0.01404200961434543, 0.01404200961434543, 0.01404200961434543, 0.11551173920855273, 0.11551173920855273, 0.11551173920855273, 0.08301142225415625, 0.08301142225415625, 0.08301142225415625, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09167204097074777, 0.09167204097074777, 0.09167204097074777, 0.040772380399989205, 0.040772380399989205, 0.040772380399989205, 0.06950788399023045, 0.06950788399023045, 0.06950788399023045, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07680505696159146, 0.07680505696159146, 0.07680505696159146, 0.020627761503948516, 0.020627761503948516, 0.020627761503948516, 0.03460291094987189, 0.03460291094987189, 0.03460291094987189, 0.48579061994835226, 0.48579061994835226, 0.48579061994835226, 0.4601227374767123, 0.4601227374767123, 0.4601227374767123, 0.5156256632889341, 0.5156256632889341, 0.5156256632889341, 0.14261714449025453, 0.14261714449025453, 0.14261714449025453, 0.09844129849765448, 0.09844129849765448, 0.09844129849765448, 0.1020611630124102, 0.1020611630124102, 0.1020611630124102, 0.23306840158410302, 0.23306840158410302, 0.23306840158410302, 0.23462141498388556, 0.23462141498388556, 0.23462141498388556, 0.18481170273401804, 0.18481170273401804, 0.18481170273401804, 0.37259804304105715, 0.37259804304105715, 0.37259804304105715, 0.41277297198057017, 0.41277297198057017, 0.41277297198057017, 0.3991190271349615, 0.3991190271349615, 0.3991190271349615, 0.26548449616260006, 0.26548449616260006, 0.26548449616260006, 0.22155779927948938, 0.22155779927948938, 0.22155779927948938, 0.2255518417257517, 0.2255518417257517, 0.2255518417257517, 0.23537641008072585, 0.23537641008072585, 0.23537641008072585, 0.2643951220238553, 0.2643951220238553, 0.2643951220238553, 0.21178721817694623, 0.21178721817694623, 0.21178721817694623, 0.1847713365996646, 0.1847713365996646, 0.1847713365996646, 0.21104286522385918, 0.21104286522385918, 0.21104286522385918, 0.17443955694830326, 0.17443955694830326, 0.17443955694830326, 0.8352410597901369, 0.8352410597901369, 0.8352410597901369, 0.16234534471649908, 0.16234534471649908, 0.16234534471649908, 0.8283792081345414, 0.8283792081345414, 0.8283792081345414, 0.7107431615350103, 0.7107431615350103, 0.7107431615350103, 0.2088474926654168, 0.2088474926654168, 0.2088474926654168, 0.6566124764768064, 0.6566124764768064, 0.6566124764768064, 0.19523907155833664, 0.19523907155833664, 0.19523907155833664, 0.1873681614006295, 0.1873681614006295, 0.1873681614006295, 0.22402390441506737, 0.22402390441506737, 0.22402390441506737, 0.1278754757649393, 0.1278754757649393, 0.1278754757649393, 0.08850554191970439, 0.08850554191970439, 0.08850554191970439, 0.10849797974736797, 0.10849797974736797, 0.10849797974736797]}, "mutation_prompt": null}
{"id": "a5be029c-fb3b-405d-9cb3-28f0ced302cb", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85\n        self.w_min = 0.3  # Adjusted for more flexibility in inertia weight decay\n        self.c1 = 1.5  # Reduced to favor exploration in early iterations\n        self.c2 = 1.5  # Balanced cognitive and social coefficients\n        self.temp_init = 100.0\n        self.temp_end = 0.5  # Reduced final temperature for finer convergence\n        self.adaptive_factor = 0.95  # Slightly adjusted for more cooling\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.98)  # Enhanced inertia weight decay\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Hybrid PSO-SA optimizer with dynamic parameter adjustment and inertia weight decay for enhanced convergence.", "configspace": "", "generation": 79, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "72805d8f-0a9e-4ca0-8cb1-c94b20fd4300", "metadata": {"aucs": [0.7684536810562734, 0.7684536810562734, 0.7684536810562734, 0.7783342393159393, 0.7783342393159393, 0.7783342393159393, 0.7907584893895563, 0.7907584893895563, 0.7907584893895563, 0.023716334680747186, 0.023716334680747186, 0.023716334680747186, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.123716556057062, 0.123716556057062, 0.123716556057062, 0.11855042009176142, 0.11855042009176142, 0.11855042009176142, 0.07427313242322942, 0.07427313242322942, 0.07427313242322942, 0.04605844760145483, 0.04605844760145483, 0.04605844760145483, 0.08415775905915812, 0.08415775905915812, 0.08415775905915812, 0.05928895423944924, 0.05928895423944924, 0.05928895423944924, 0.85244715737466, 0.85244715737466, 0.85244715737466, 0.9085126883996072, 0.9085126883996072, 0.9085126883996072, 0.8807036227727707, 0.8807036227727707, 0.8807036227727707, 0.2199032064971268, 0.2199032064971268, 0.2199032064971268, 0.05814089475241324, 0.05814089475241324, 0.05814089475241324, 0.14613295523046832, 0.14613295523046832, 0.14613295523046832, 0.2184892435990431, 0.2184892435990431, 0.2184892435990431, 0.15327171757954516, 0.15327171757954516, 0.15327171757954516, 0.1618971498227635, 0.1618971498227635, 0.1618971498227635, 0.11701286325669824, 0.11701286325669824, 0.11701286325669824, 0.1089067035922413, 0.1089067035922413, 0.1089067035922413, 0.09444856596399964, 0.09444856596399964, 0.09444856596399964, 0.01404200961434543, 0.01404200961434543, 0.01404200961434543, 0.11551173920855273, 0.11551173920855273, 0.11551173920855273, 0.08301142225415625, 0.08301142225415625, 0.08301142225415625, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09167204097074777, 0.09167204097074777, 0.09167204097074777, 0.040772380399989205, 0.040772380399989205, 0.040772380399989205, 0.06950788399023045, 0.06950788399023045, 0.06950788399023045, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07680505696159146, 0.07680505696159146, 0.07680505696159146, 0.020627761503948516, 0.020627761503948516, 0.020627761503948516, 0.03460291094987189, 0.03460291094987189, 0.03460291094987189, 0.48579061994835226, 0.48579061994835226, 0.48579061994835226, 0.4601227374767123, 0.4601227374767123, 0.4601227374767123, 0.5156256632889341, 0.5156256632889341, 0.5156256632889341, 0.14261714449025453, 0.14261714449025453, 0.14261714449025453, 0.09844129849765448, 0.09844129849765448, 0.09844129849765448, 0.1020611630124102, 0.1020611630124102, 0.1020611630124102, 0.23306840158410302, 0.23306840158410302, 0.23306840158410302, 0.23462141498388556, 0.23462141498388556, 0.23462141498388556, 0.18481170273401804, 0.18481170273401804, 0.18481170273401804, 0.37259804304105715, 0.37259804304105715, 0.37259804304105715, 0.41277297198057017, 0.41277297198057017, 0.41277297198057017, 0.3991190271349615, 0.3991190271349615, 0.3991190271349615, 0.26548449616260006, 0.26548449616260006, 0.26548449616260006, 0.22155779927948938, 0.22155779927948938, 0.22155779927948938, 0.2255518417257517, 0.2255518417257517, 0.2255518417257517, 0.23537641008072585, 0.23537641008072585, 0.23537641008072585, 0.2643951220238553, 0.2643951220238553, 0.2643951220238553, 0.21178721817694623, 0.21178721817694623, 0.21178721817694623, 0.1847713365996646, 0.1847713365996646, 0.1847713365996646, 0.21104286522385918, 0.21104286522385918, 0.21104286522385918, 0.17443955694830326, 0.17443955694830326, 0.17443955694830326, 0.8352410597901369, 0.8352410597901369, 0.8352410597901369, 0.16234534471649908, 0.16234534471649908, 0.16234534471649908, 0.8283792081345414, 0.8283792081345414, 0.8283792081345414, 0.7107431615350103, 0.7107431615350103, 0.7107431615350103, 0.2088474926654168, 0.2088474926654168, 0.2088474926654168, 0.6566124764768064, 0.6566124764768064, 0.6566124764768064, 0.19523907155833664, 0.19523907155833664, 0.19523907155833664, 0.1873681614006295, 0.1873681614006295, 0.1873681614006295, 0.22402390441506737, 0.22402390441506737, 0.22402390441506737, 0.1278754757649393, 0.1278754757649393, 0.1278754757649393, 0.08850554191970439, 0.08850554191970439, 0.08850554191970439, 0.10849797974736797, 0.10849797974736797, 0.10849797974736797]}, "mutation_prompt": null}
{"id": "2bd2da2b-b56f-434f-9fbe-764eac45f58b", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85\n        self.w_min = 0.3  # Adjusted for more flexibility in inertia weight decay\n        self.c1 = 1.5  # Reduced to favor exploration in early iterations\n        self.c2 = 1.5  # Balanced cognitive and social coefficients\n        self.temp_init = 100.0\n        self.temp_end = 0.5  # Reduced final temperature for finer convergence\n        self.adaptive_factor = 0.95  # Slightly adjusted for more cooling\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.98)  # Enhanced inertia weight decay\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Hybrid PSO-SA optimizer with dynamic parameter adjustment and inertia weight decay for enhanced convergence.", "configspace": "", "generation": 79, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "72805d8f-0a9e-4ca0-8cb1-c94b20fd4300", "metadata": {"aucs": [0.7684536810562734, 0.7684536810562734, 0.7684536810562734, 0.7783342393159393, 0.7783342393159393, 0.7783342393159393, 0.7907584893895563, 0.7907584893895563, 0.7907584893895563, 0.023716334680747186, 0.023716334680747186, 0.023716334680747186, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.123716556057062, 0.123716556057062, 0.123716556057062, 0.11855042009176142, 0.11855042009176142, 0.11855042009176142, 0.07427313242322942, 0.07427313242322942, 0.07427313242322942, 0.04605844760145483, 0.04605844760145483, 0.04605844760145483, 0.08415775905915812, 0.08415775905915812, 0.08415775905915812, 0.05928895423944924, 0.05928895423944924, 0.05928895423944924, 0.85244715737466, 0.85244715737466, 0.85244715737466, 0.9085126883996072, 0.9085126883996072, 0.9085126883996072, 0.8807036227727707, 0.8807036227727707, 0.8807036227727707, 0.2199032064971268, 0.2199032064971268, 0.2199032064971268, 0.05814089475241324, 0.05814089475241324, 0.05814089475241324, 0.14613295523046832, 0.14613295523046832, 0.14613295523046832, 0.2184892435990431, 0.2184892435990431, 0.2184892435990431, 0.15327171757954516, 0.15327171757954516, 0.15327171757954516, 0.1618971498227635, 0.1618971498227635, 0.1618971498227635, 0.11701286325669824, 0.11701286325669824, 0.11701286325669824, 0.1089067035922413, 0.1089067035922413, 0.1089067035922413, 0.09444856596399964, 0.09444856596399964, 0.09444856596399964, 0.01404200961434543, 0.01404200961434543, 0.01404200961434543, 0.11551173920855273, 0.11551173920855273, 0.11551173920855273, 0.08301142225415625, 0.08301142225415625, 0.08301142225415625, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09167204097074777, 0.09167204097074777, 0.09167204097074777, 0.040772380399989205, 0.040772380399989205, 0.040772380399989205, 0.06950788399023045, 0.06950788399023045, 0.06950788399023045, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07680505696159146, 0.07680505696159146, 0.07680505696159146, 0.020627761503948516, 0.020627761503948516, 0.020627761503948516, 0.03460291094987189, 0.03460291094987189, 0.03460291094987189, 0.48579061994835226, 0.48579061994835226, 0.48579061994835226, 0.4601227374767123, 0.4601227374767123, 0.4601227374767123, 0.5156256632889341, 0.5156256632889341, 0.5156256632889341, 0.14261714449025453, 0.14261714449025453, 0.14261714449025453, 0.09844129849765448, 0.09844129849765448, 0.09844129849765448, 0.1020611630124102, 0.1020611630124102, 0.1020611630124102, 0.23306840158410302, 0.23306840158410302, 0.23306840158410302, 0.23462141498388556, 0.23462141498388556, 0.23462141498388556, 0.18481170273401804, 0.18481170273401804, 0.18481170273401804, 0.37259804304105715, 0.37259804304105715, 0.37259804304105715, 0.41277297198057017, 0.41277297198057017, 0.41277297198057017, 0.3991190271349615, 0.3991190271349615, 0.3991190271349615, 0.26548449616260006, 0.26548449616260006, 0.26548449616260006, 0.22155779927948938, 0.22155779927948938, 0.22155779927948938, 0.2255518417257517, 0.2255518417257517, 0.2255518417257517, 0.23537641008072585, 0.23537641008072585, 0.23537641008072585, 0.2643951220238553, 0.2643951220238553, 0.2643951220238553, 0.21178721817694623, 0.21178721817694623, 0.21178721817694623, 0.1847713365996646, 0.1847713365996646, 0.1847713365996646, 0.21104286522385918, 0.21104286522385918, 0.21104286522385918, 0.17443955694830326, 0.17443955694830326, 0.17443955694830326, 0.8352410597901369, 0.8352410597901369, 0.8352410597901369, 0.16234534471649908, 0.16234534471649908, 0.16234534471649908, 0.8283792081345414, 0.8283792081345414, 0.8283792081345414, 0.7107431615350103, 0.7107431615350103, 0.7107431615350103, 0.2088474926654168, 0.2088474926654168, 0.2088474926654168, 0.6566124764768064, 0.6566124764768064, 0.6566124764768064, 0.19523907155833664, 0.19523907155833664, 0.19523907155833664, 0.1873681614006295, 0.1873681614006295, 0.1873681614006295, 0.22402390441506737, 0.22402390441506737, 0.22402390441506737, 0.1278754757649393, 0.1278754757649393, 0.1278754757649393, 0.08850554191970439, 0.08850554191970439, 0.08850554191970439, 0.10849797974736797, 0.10849797974736797, 0.10849797974736797]}, "mutation_prompt": null}
{"id": "ad735235-10a8-49da-accb-a87b20607310", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85\n        self.w_min = 0.3  # Adjusted for more flexibility in inertia weight decay\n        self.c1 = 1.5  # Reduced to favor exploration in early iterations\n        self.c2 = 1.5  # Balanced cognitive and social coefficients\n        self.temp_init = 100.0\n        self.temp_end = 0.5  # Reduced final temperature for finer convergence\n        self.adaptive_factor = 0.95  # Slightly adjusted for more cooling\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.98)  # Enhanced inertia weight decay\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Hybrid PSO-SA optimizer with dynamic parameter adjustment and inertia weight decay for enhanced convergence.", "configspace": "", "generation": 79, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "72805d8f-0a9e-4ca0-8cb1-c94b20fd4300", "metadata": {"aucs": [0.7684536810562734, 0.7684536810562734, 0.7684536810562734, 0.7783342393159393, 0.7783342393159393, 0.7783342393159393, 0.7907584893895563, 0.7907584893895563, 0.7907584893895563, 0.023716334680747186, 0.023716334680747186, 0.023716334680747186, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.123716556057062, 0.123716556057062, 0.123716556057062, 0.11855042009176142, 0.11855042009176142, 0.11855042009176142, 0.07427313242322942, 0.07427313242322942, 0.07427313242322942, 0.04605844760145483, 0.04605844760145483, 0.04605844760145483, 0.08415775905915812, 0.08415775905915812, 0.08415775905915812, 0.05928895423944924, 0.05928895423944924, 0.05928895423944924, 0.85244715737466, 0.85244715737466, 0.85244715737466, 0.9085126883996072, 0.9085126883996072, 0.9085126883996072, 0.8807036227727707, 0.8807036227727707, 0.8807036227727707, 0.2199032064971268, 0.2199032064971268, 0.2199032064971268, 0.05814089475241324, 0.05814089475241324, 0.05814089475241324, 0.14613295523046832, 0.14613295523046832, 0.14613295523046832, 0.2184892435990431, 0.2184892435990431, 0.2184892435990431, 0.15327171757954516, 0.15327171757954516, 0.15327171757954516, 0.1618971498227635, 0.1618971498227635, 0.1618971498227635, 0.11701286325669824, 0.11701286325669824, 0.11701286325669824, 0.1089067035922413, 0.1089067035922413, 0.1089067035922413, 0.09444856596399964, 0.09444856596399964, 0.09444856596399964, 0.01404200961434543, 0.01404200961434543, 0.01404200961434543, 0.11551173920855273, 0.11551173920855273, 0.11551173920855273, 0.08301142225415625, 0.08301142225415625, 0.08301142225415625, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09167204097074777, 0.09167204097074777, 0.09167204097074777, 0.040772380399989205, 0.040772380399989205, 0.040772380399989205, 0.06950788399023045, 0.06950788399023045, 0.06950788399023045, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07680505696159146, 0.07680505696159146, 0.07680505696159146, 0.020627761503948516, 0.020627761503948516, 0.020627761503948516, 0.03460291094987189, 0.03460291094987189, 0.03460291094987189, 0.48579061994835226, 0.48579061994835226, 0.48579061994835226, 0.4601227374767123, 0.4601227374767123, 0.4601227374767123, 0.5156256632889341, 0.5156256632889341, 0.5156256632889341, 0.14261714449025453, 0.14261714449025453, 0.14261714449025453, 0.09844129849765448, 0.09844129849765448, 0.09844129849765448, 0.1020611630124102, 0.1020611630124102, 0.1020611630124102, 0.23306840158410302, 0.23306840158410302, 0.23306840158410302, 0.23462141498388556, 0.23462141498388556, 0.23462141498388556, 0.18481170273401804, 0.18481170273401804, 0.18481170273401804, 0.37259804304105715, 0.37259804304105715, 0.37259804304105715, 0.41277297198057017, 0.41277297198057017, 0.41277297198057017, 0.3991190271349615, 0.3991190271349615, 0.3991190271349615, 0.26548449616260006, 0.26548449616260006, 0.26548449616260006, 0.22155779927948938, 0.22155779927948938, 0.22155779927948938, 0.2255518417257517, 0.2255518417257517, 0.2255518417257517, 0.23537641008072585, 0.23537641008072585, 0.23537641008072585, 0.2643951220238553, 0.2643951220238553, 0.2643951220238553, 0.21178721817694623, 0.21178721817694623, 0.21178721817694623, 0.1847713365996646, 0.1847713365996646, 0.1847713365996646, 0.21104286522385918, 0.21104286522385918, 0.21104286522385918, 0.17443955694830326, 0.17443955694830326, 0.17443955694830326, 0.8352410597901369, 0.8352410597901369, 0.8352410597901369, 0.16234534471649908, 0.16234534471649908, 0.16234534471649908, 0.8283792081345414, 0.8283792081345414, 0.8283792081345414, 0.7107431615350103, 0.7107431615350103, 0.7107431615350103, 0.2088474926654168, 0.2088474926654168, 0.2088474926654168, 0.6566124764768064, 0.6566124764768064, 0.6566124764768064, 0.19523907155833664, 0.19523907155833664, 0.19523907155833664, 0.1873681614006295, 0.1873681614006295, 0.1873681614006295, 0.22402390441506737, 0.22402390441506737, 0.22402390441506737, 0.1278754757649393, 0.1278754757649393, 0.1278754757649393, 0.08850554191970439, 0.08850554191970439, 0.08850554191970439, 0.10849797974736797, 0.10849797974736797, 0.10849797974736797]}, "mutation_prompt": null}
{"id": "d70b50db-de60-4650-b8be-a567d7b74b32", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85\n        self.w_min = 0.3\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temp_init = 100.0\n        self.temp_end = 0.5\n        self.adaptive_factor = 0.95\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n        dynamic_swarm_size = self.swarm_size\n\n        while evaluations < self.budget:\n            for i in range(dynamic_swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(dynamic_swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                if evaluations % 50 == 0:  # Introduce velocity modification\n                    velocities[i] *= 0.9 \n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.98)\n\n            if evaluations % (self.budget // 10) == 0 and dynamic_swarm_size > 10:  # Adaptive swarm size\n                dynamic_swarm_size -= 1\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with adaptive swarm size and velocity modification for improved convergence.", "configspace": "", "generation": 83, "fitness": 0.23547017643199034, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.25.", "error": "", "parent_id": "72805d8f-0a9e-4ca0-8cb1-c94b20fd4300", "metadata": {"aucs": [0.7618483816438374, 0.7618483816438374, 0.7618483816438374, 0.7639542309720357, 0.7639542309720357, 0.7639542309720357, 0.750731342275285, 0.750731342275285, 0.750731342275285, 0.004924469369135265, 0.004924469369135265, 0.004924469369135265, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1299380754053564, 0.1299380754053564, 0.1299380754053564, 0.06870300176027555, 0.06870300176027555, 0.06870300176027555, 0.11137292857051617, 0.11137292857051617, 0.11137292857051617, 0.10881614123313521, 0.10881614123313521, 0.10881614123313521, 0.0641031619675767, 0.0641031619675767, 0.0641031619675767, 0.09785581605531735, 0.09785581605531735, 0.09785581605531735, 0.8601378542054556, 0.8601378542054556, 0.8601378542054556, 0.9078693245512326, 0.9078693245512326, 0.9078693245512326, 0.8801515938302504, 0.8801515938302504, 0.8801515938302504, 0.1705484602460865, 0.1705484602460865, 0.1705484602460865, 0.1036511919046812, 0.1036511919046812, 0.1036511919046812, 0.14643164120241292, 0.14643164120241292, 0.14643164120241292, 0.2145263345289351, 0.2145263345289351, 0.2145263345289351, 0.26268825008133645, 0.26268825008133645, 0.26268825008133645, 0.27380111051625877, 0.27380111051625877, 0.27380111051625877, 0.09165878721060328, 0.09165878721060328, 0.09165878721060328, 0.11165190499034539, 0.11165190499034539, 0.11165190499034539, 0.14067928392033413, 0.14067928392033413, 0.14067928392033413, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1175058980242698, 0.1175058980242698, 0.1175058980242698, 0.13731214478449105, 0.13731214478449105, 0.13731214478449105, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10187847664609362, 0.10187847664609362, 0.10187847664609362, 0.0329296068609245, 0.0329296068609245, 0.0329296068609245, 0.10111459042475812, 0.10111459042475812, 0.10111459042475812, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06855204828486927, 0.06855204828486927, 0.06855204828486927, 0.00307211612273417, 0.00307211612273417, 0.00307211612273417, 0.0474943403417305, 0.0474943403417305, 0.0474943403417305, 0.5407384534264916, 0.5407384534264916, 0.5407384534264916, 0.48060358980634665, 0.48060358980634665, 0.48060358980634665, 0.5051401590005719, 0.5051401590005719, 0.5051401590005719, 0.0779255307432124, 0.0779255307432124, 0.0779255307432124, 0.0653698163656723, 0.0653698163656723, 0.0653698163656723, 0.11097744519256192, 0.11097744519256192, 0.11097744519256192, 0.2102006571956313, 0.2102006571956313, 0.2102006571956313, 0.2144325011248921, 0.2144325011248921, 0.2144325011248921, 0.18899663907072373, 0.18899663907072373, 0.18899663907072373, 0.18104334225408458, 0.18104334225408458, 0.18104334225408458, 0.3666205253387952, 0.3666205253387952, 0.3666205253387952, 0.24813998252682967, 0.24813998252682967, 0.24813998252682967, 0.27761331446389936, 0.27761331446389936, 0.27761331446389936, 0.2043850234661193, 0.2043850234661193, 0.2043850234661193, 0.2541266228239428, 0.2541266228239428, 0.2541266228239428, 0.2021025239179669, 0.2021025239179669, 0.2021025239179669, 0.24074617766544992, 0.24074617766544992, 0.24074617766544992, 0.21637840818625131, 0.21637840818625131, 0.21637840818625131, 0.18527927629835972, 0.18527927629835972, 0.18527927629835972, 0.17946952302721308, 0.17946952302721308, 0.17946952302721308, 0.18841392952176206, 0.18841392952176206, 0.18841392952176206, 0.8411914526217725, 0.8411914526217725, 0.8411914526217725, 0.15701372508450162, 0.15701372508450162, 0.15701372508450162, 0.8350695394160783, 0.8350695394160783, 0.8350695394160783, 0.5973457787362482, 0.5973457787362482, 0.5973457787362482, 0.2090147314281855, 0.2090147314281855, 0.2090147314281855, 0.6511328051640891, 0.6511328051640891, 0.6511328051640891, 0.19986341863159296, 0.19986341863159296, 0.19986341863159296, 0.2313807253886765, 0.2313807253886765, 0.2313807253886765, 0.18101099713843305, 0.18101099713843305, 0.18101099713843305, 0.10583858676281832, 0.10583858676281832, 0.10583858676281832, 0.08921905517526851, 0.08921905517526851, 0.08921905517526851, 0.08026593820859029, 0.08026593820859029, 0.08026593820859029]}, "mutation_prompt": null}
{"id": "d79775d4-2752-4eb6-a84d-2fb5765042cc", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85\n        self.w_min = 0.3  # Adjusted for more flexibility in inertia weight decay\n        self.c1 = 1.5  # Reduced to favor exploration in early iterations\n        self.c2 = 1.5  # Balanced cognitive and social coefficients\n        self.temp_init = 100.0\n        self.temp_end = 0.5  # Reduced final temperature for finer convergence\n        self.adaptive_factor = 0.95  # Slightly adjusted for more cooling\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.98)  # Enhanced inertia weight decay\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Hybrid PSO-SA optimizer with dynamic parameter adjustment and inertia weight decay for enhanced convergence.", "configspace": "", "generation": 79, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "72805d8f-0a9e-4ca0-8cb1-c94b20fd4300", "metadata": {"aucs": [0.7684536810562734, 0.7684536810562734, 0.7684536810562734, 0.7783342393159393, 0.7783342393159393, 0.7783342393159393, 0.7907584893895563, 0.7907584893895563, 0.7907584893895563, 0.023716334680747186, 0.023716334680747186, 0.023716334680747186, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.123716556057062, 0.123716556057062, 0.123716556057062, 0.11855042009176142, 0.11855042009176142, 0.11855042009176142, 0.07427313242322942, 0.07427313242322942, 0.07427313242322942, 0.04605844760145483, 0.04605844760145483, 0.04605844760145483, 0.08415775905915812, 0.08415775905915812, 0.08415775905915812, 0.05928895423944924, 0.05928895423944924, 0.05928895423944924, 0.85244715737466, 0.85244715737466, 0.85244715737466, 0.9085126883996072, 0.9085126883996072, 0.9085126883996072, 0.8807036227727707, 0.8807036227727707, 0.8807036227727707, 0.2199032064971268, 0.2199032064971268, 0.2199032064971268, 0.05814089475241324, 0.05814089475241324, 0.05814089475241324, 0.14613295523046832, 0.14613295523046832, 0.14613295523046832, 0.2184892435990431, 0.2184892435990431, 0.2184892435990431, 0.15327171757954516, 0.15327171757954516, 0.15327171757954516, 0.1618971498227635, 0.1618971498227635, 0.1618971498227635, 0.11701286325669824, 0.11701286325669824, 0.11701286325669824, 0.1089067035922413, 0.1089067035922413, 0.1089067035922413, 0.09444856596399964, 0.09444856596399964, 0.09444856596399964, 0.01404200961434543, 0.01404200961434543, 0.01404200961434543, 0.11551173920855273, 0.11551173920855273, 0.11551173920855273, 0.08301142225415625, 0.08301142225415625, 0.08301142225415625, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09167204097074777, 0.09167204097074777, 0.09167204097074777, 0.040772380399989205, 0.040772380399989205, 0.040772380399989205, 0.06950788399023045, 0.06950788399023045, 0.06950788399023045, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07680505696159146, 0.07680505696159146, 0.07680505696159146, 0.020627761503948516, 0.020627761503948516, 0.020627761503948516, 0.03460291094987189, 0.03460291094987189, 0.03460291094987189, 0.48579061994835226, 0.48579061994835226, 0.48579061994835226, 0.4601227374767123, 0.4601227374767123, 0.4601227374767123, 0.5156256632889341, 0.5156256632889341, 0.5156256632889341, 0.14261714449025453, 0.14261714449025453, 0.14261714449025453, 0.09844129849765448, 0.09844129849765448, 0.09844129849765448, 0.1020611630124102, 0.1020611630124102, 0.1020611630124102, 0.23306840158410302, 0.23306840158410302, 0.23306840158410302, 0.23462141498388556, 0.23462141498388556, 0.23462141498388556, 0.18481170273401804, 0.18481170273401804, 0.18481170273401804, 0.37259804304105715, 0.37259804304105715, 0.37259804304105715, 0.41277297198057017, 0.41277297198057017, 0.41277297198057017, 0.3991190271349615, 0.3991190271349615, 0.3991190271349615, 0.26548449616260006, 0.26548449616260006, 0.26548449616260006, 0.22155779927948938, 0.22155779927948938, 0.22155779927948938, 0.2255518417257517, 0.2255518417257517, 0.2255518417257517, 0.23537641008072585, 0.23537641008072585, 0.23537641008072585, 0.2643951220238553, 0.2643951220238553, 0.2643951220238553, 0.21178721817694623, 0.21178721817694623, 0.21178721817694623, 0.1847713365996646, 0.1847713365996646, 0.1847713365996646, 0.21104286522385918, 0.21104286522385918, 0.21104286522385918, 0.17443955694830326, 0.17443955694830326, 0.17443955694830326, 0.8352410597901369, 0.8352410597901369, 0.8352410597901369, 0.16234534471649908, 0.16234534471649908, 0.16234534471649908, 0.8283792081345414, 0.8283792081345414, 0.8283792081345414, 0.7107431615350103, 0.7107431615350103, 0.7107431615350103, 0.2088474926654168, 0.2088474926654168, 0.2088474926654168, 0.6566124764768064, 0.6566124764768064, 0.6566124764768064, 0.19523907155833664, 0.19523907155833664, 0.19523907155833664, 0.1873681614006295, 0.1873681614006295, 0.1873681614006295, 0.22402390441506737, 0.22402390441506737, 0.22402390441506737, 0.1278754757649393, 0.1278754757649393, 0.1278754757649393, 0.08850554191970439, 0.08850554191970439, 0.08850554191970439, 0.10849797974736797, 0.10849797974736797, 0.10849797974736797]}, "mutation_prompt": null}
{"id": "db9899fa-da23-4a44-a256-11598f9703a3", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85\n        self.w_min = 0.3  # Adjusted for more flexibility in inertia weight decay\n        self.c1 = 1.5  # Reduced to favor exploration in early iterations\n        self.c2 = 1.5  # Balanced cognitive and social coefficients\n        self.temp_init = 100.0\n        self.temp_end = 0.5  # Reduced final temperature for finer convergence\n        self.adaptive_factor = 0.95  # Slightly adjusted for more cooling\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.98)  # Enhanced inertia weight decay\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Hybrid PSO-SA optimizer with dynamic parameter adjustment and inertia weight decay for enhanced convergence.", "configspace": "", "generation": 79, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "72805d8f-0a9e-4ca0-8cb1-c94b20fd4300", "metadata": {"aucs": [0.7684536810562734, 0.7684536810562734, 0.7684536810562734, 0.7783342393159393, 0.7783342393159393, 0.7783342393159393, 0.7907584893895563, 0.7907584893895563, 0.7907584893895563, 0.023716334680747186, 0.023716334680747186, 0.023716334680747186, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.123716556057062, 0.123716556057062, 0.123716556057062, 0.11855042009176142, 0.11855042009176142, 0.11855042009176142, 0.07427313242322942, 0.07427313242322942, 0.07427313242322942, 0.04605844760145483, 0.04605844760145483, 0.04605844760145483, 0.08415775905915812, 0.08415775905915812, 0.08415775905915812, 0.05928895423944924, 0.05928895423944924, 0.05928895423944924, 0.85244715737466, 0.85244715737466, 0.85244715737466, 0.9085126883996072, 0.9085126883996072, 0.9085126883996072, 0.8807036227727707, 0.8807036227727707, 0.8807036227727707, 0.2199032064971268, 0.2199032064971268, 0.2199032064971268, 0.05814089475241324, 0.05814089475241324, 0.05814089475241324, 0.14613295523046832, 0.14613295523046832, 0.14613295523046832, 0.2184892435990431, 0.2184892435990431, 0.2184892435990431, 0.15327171757954516, 0.15327171757954516, 0.15327171757954516, 0.1618971498227635, 0.1618971498227635, 0.1618971498227635, 0.11701286325669824, 0.11701286325669824, 0.11701286325669824, 0.1089067035922413, 0.1089067035922413, 0.1089067035922413, 0.09444856596399964, 0.09444856596399964, 0.09444856596399964, 0.01404200961434543, 0.01404200961434543, 0.01404200961434543, 0.11551173920855273, 0.11551173920855273, 0.11551173920855273, 0.08301142225415625, 0.08301142225415625, 0.08301142225415625, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09167204097074777, 0.09167204097074777, 0.09167204097074777, 0.040772380399989205, 0.040772380399989205, 0.040772380399989205, 0.06950788399023045, 0.06950788399023045, 0.06950788399023045, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07680505696159146, 0.07680505696159146, 0.07680505696159146, 0.020627761503948516, 0.020627761503948516, 0.020627761503948516, 0.03460291094987189, 0.03460291094987189, 0.03460291094987189, 0.48579061994835226, 0.48579061994835226, 0.48579061994835226, 0.4601227374767123, 0.4601227374767123, 0.4601227374767123, 0.5156256632889341, 0.5156256632889341, 0.5156256632889341, 0.14261714449025453, 0.14261714449025453, 0.14261714449025453, 0.09844129849765448, 0.09844129849765448, 0.09844129849765448, 0.1020611630124102, 0.1020611630124102, 0.1020611630124102, 0.23306840158410302, 0.23306840158410302, 0.23306840158410302, 0.23462141498388556, 0.23462141498388556, 0.23462141498388556, 0.18481170273401804, 0.18481170273401804, 0.18481170273401804, 0.37259804304105715, 0.37259804304105715, 0.37259804304105715, 0.41277297198057017, 0.41277297198057017, 0.41277297198057017, 0.3991190271349615, 0.3991190271349615, 0.3991190271349615, 0.26548449616260006, 0.26548449616260006, 0.26548449616260006, 0.22155779927948938, 0.22155779927948938, 0.22155779927948938, 0.2255518417257517, 0.2255518417257517, 0.2255518417257517, 0.23537641008072585, 0.23537641008072585, 0.23537641008072585, 0.2643951220238553, 0.2643951220238553, 0.2643951220238553, 0.21178721817694623, 0.21178721817694623, 0.21178721817694623, 0.1847713365996646, 0.1847713365996646, 0.1847713365996646, 0.21104286522385918, 0.21104286522385918, 0.21104286522385918, 0.17443955694830326, 0.17443955694830326, 0.17443955694830326, 0.8352410597901369, 0.8352410597901369, 0.8352410597901369, 0.16234534471649908, 0.16234534471649908, 0.16234534471649908, 0.8283792081345414, 0.8283792081345414, 0.8283792081345414, 0.7107431615350103, 0.7107431615350103, 0.7107431615350103, 0.2088474926654168, 0.2088474926654168, 0.2088474926654168, 0.6566124764768064, 0.6566124764768064, 0.6566124764768064, 0.19523907155833664, 0.19523907155833664, 0.19523907155833664, 0.1873681614006295, 0.1873681614006295, 0.1873681614006295, 0.22402390441506737, 0.22402390441506737, 0.22402390441506737, 0.1278754757649393, 0.1278754757649393, 0.1278754757649393, 0.08850554191970439, 0.08850554191970439, 0.08850554191970439, 0.10849797974736797, 0.10849797974736797, 0.10849797974736797]}, "mutation_prompt": null}
{"id": "802a85ca-53ba-432b-825a-f73dbf203b46", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85\n        self.w_min = 0.3  # Adjusted for more flexibility in inertia weight decay\n        self.c1 = 1.5  # Reduced to favor exploration in early iterations\n        self.c2 = 1.5  # Balanced cognitive and social coefficients\n        self.temp_init = 100.0\n        self.temp_end = 0.5  # Reduced final temperature for finer convergence\n        self.adaptive_factor = 0.95  # Slightly adjusted for more cooling\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.98)  # Enhanced inertia weight decay\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Hybrid PSO-SA optimizer with dynamic parameter adjustment and inertia weight decay for enhanced convergence.", "configspace": "", "generation": 79, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "72805d8f-0a9e-4ca0-8cb1-c94b20fd4300", "metadata": {"aucs": [0.7684536810562734, 0.7684536810562734, 0.7684536810562734, 0.7783342393159393, 0.7783342393159393, 0.7783342393159393, 0.7907584893895563, 0.7907584893895563, 0.7907584893895563, 0.023716334680747186, 0.023716334680747186, 0.023716334680747186, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.123716556057062, 0.123716556057062, 0.123716556057062, 0.11855042009176142, 0.11855042009176142, 0.11855042009176142, 0.07427313242322942, 0.07427313242322942, 0.07427313242322942, 0.04605844760145483, 0.04605844760145483, 0.04605844760145483, 0.08415775905915812, 0.08415775905915812, 0.08415775905915812, 0.05928895423944924, 0.05928895423944924, 0.05928895423944924, 0.85244715737466, 0.85244715737466, 0.85244715737466, 0.9085126883996072, 0.9085126883996072, 0.9085126883996072, 0.8807036227727707, 0.8807036227727707, 0.8807036227727707, 0.2199032064971268, 0.2199032064971268, 0.2199032064971268, 0.05814089475241324, 0.05814089475241324, 0.05814089475241324, 0.14613295523046832, 0.14613295523046832, 0.14613295523046832, 0.2184892435990431, 0.2184892435990431, 0.2184892435990431, 0.15327171757954516, 0.15327171757954516, 0.15327171757954516, 0.1618971498227635, 0.1618971498227635, 0.1618971498227635, 0.11701286325669824, 0.11701286325669824, 0.11701286325669824, 0.1089067035922413, 0.1089067035922413, 0.1089067035922413, 0.09444856596399964, 0.09444856596399964, 0.09444856596399964, 0.01404200961434543, 0.01404200961434543, 0.01404200961434543, 0.11551173920855273, 0.11551173920855273, 0.11551173920855273, 0.08301142225415625, 0.08301142225415625, 0.08301142225415625, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09167204097074777, 0.09167204097074777, 0.09167204097074777, 0.040772380399989205, 0.040772380399989205, 0.040772380399989205, 0.06950788399023045, 0.06950788399023045, 0.06950788399023045, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07680505696159146, 0.07680505696159146, 0.07680505696159146, 0.020627761503948516, 0.020627761503948516, 0.020627761503948516, 0.03460291094987189, 0.03460291094987189, 0.03460291094987189, 0.48579061994835226, 0.48579061994835226, 0.48579061994835226, 0.4601227374767123, 0.4601227374767123, 0.4601227374767123, 0.5156256632889341, 0.5156256632889341, 0.5156256632889341, 0.14261714449025453, 0.14261714449025453, 0.14261714449025453, 0.09844129849765448, 0.09844129849765448, 0.09844129849765448, 0.1020611630124102, 0.1020611630124102, 0.1020611630124102, 0.23306840158410302, 0.23306840158410302, 0.23306840158410302, 0.23462141498388556, 0.23462141498388556, 0.23462141498388556, 0.18481170273401804, 0.18481170273401804, 0.18481170273401804, 0.37259804304105715, 0.37259804304105715, 0.37259804304105715, 0.41277297198057017, 0.41277297198057017, 0.41277297198057017, 0.3991190271349615, 0.3991190271349615, 0.3991190271349615, 0.26548449616260006, 0.26548449616260006, 0.26548449616260006, 0.22155779927948938, 0.22155779927948938, 0.22155779927948938, 0.2255518417257517, 0.2255518417257517, 0.2255518417257517, 0.23537641008072585, 0.23537641008072585, 0.23537641008072585, 0.2643951220238553, 0.2643951220238553, 0.2643951220238553, 0.21178721817694623, 0.21178721817694623, 0.21178721817694623, 0.1847713365996646, 0.1847713365996646, 0.1847713365996646, 0.21104286522385918, 0.21104286522385918, 0.21104286522385918, 0.17443955694830326, 0.17443955694830326, 0.17443955694830326, 0.8352410597901369, 0.8352410597901369, 0.8352410597901369, 0.16234534471649908, 0.16234534471649908, 0.16234534471649908, 0.8283792081345414, 0.8283792081345414, 0.8283792081345414, 0.7107431615350103, 0.7107431615350103, 0.7107431615350103, 0.2088474926654168, 0.2088474926654168, 0.2088474926654168, 0.6566124764768064, 0.6566124764768064, 0.6566124764768064, 0.19523907155833664, 0.19523907155833664, 0.19523907155833664, 0.1873681614006295, 0.1873681614006295, 0.1873681614006295, 0.22402390441506737, 0.22402390441506737, 0.22402390441506737, 0.1278754757649393, 0.1278754757649393, 0.1278754757649393, 0.08850554191970439, 0.08850554191970439, 0.08850554191970439, 0.10849797974736797, 0.10849797974736797, 0.10849797974736797]}, "mutation_prompt": null}
{"id": "6c40ab67-b7c9-4552-bb6a-87b4a56c599f", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85\n        self.w_min = 0.3\n        self.c1 = 1.45  # Slightly reduced to encourage broader exploration\n        self.c2 = 1.55  # Slightly increased to enhance social influence\n        self.temp_init = 100.0\n        self.temp_end = 0.5\n        self.adaptive_factor = 0.95\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n        self.perturb_prob = 0.05  # Introduced small perturbation probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                if np.random.rand() < self.perturb_prob:  # Apply stochastic perturbation occasionally\n                    perturbation = np.random.uniform(-0.1, 0.1, self.dim)\n                    proposed_position += perturbation\n                    proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.98)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Improved hybrid PSO-SA optimizer with stochastic perturbation for enhanced exploration and convergence.", "configspace": "", "generation": 87, "fitness": 0.24905594575047765, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.25.", "error": "", "parent_id": "72805d8f-0a9e-4ca0-8cb1-c94b20fd4300", "metadata": {"aucs": [0.753092142234597, 0.753092142234597, 0.753092142234597, 0.7246196687684654, 0.7246196687684654, 0.7246196687684654, 0.6890043606486054, 0.6890043606486054, 0.6890043606486054, 0.05185899082743495, 0.05185899082743495, 0.05185899082743495, 0.0011543110382502553, 0.0011543110382502553, 0.0011543110382502553, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13385711763867325, 0.13385711763867325, 0.13385711763867325, 0.12821962340210846, 0.12821962340210846, 0.12821962340210846, 0.1124228221388952, 0.1124228221388952, 0.1124228221388952, 0.10656219445605986, 0.10656219445605986, 0.10656219445605986, 0.09934661859994953, 0.09934661859994953, 0.09934661859994953, 0.11913895817960563, 0.11913895817960563, 0.11913895817960563, 0.8604847325465861, 0.8604847325465861, 0.8604847325465861, 0.8883334804746417, 0.8883334804746417, 0.8883334804746417, 0.8953241333499276, 0.8953241333499276, 0.8953241333499276, 0.16965468283154206, 0.16965468283154206, 0.16965468283154206, 0.19753025689589354, 0.19753025689589354, 0.19753025689589354, 0.14332388332199675, 0.14332388332199675, 0.14332388332199675, 0.1678857222375273, 0.1678857222375273, 0.1678857222375273, 0.7022462144135599, 0.7022462144135599, 0.7022462144135599, 0.1284567888077418, 0.1284567888077418, 0.1284567888077418, 0.15208038682270342, 0.15208038682270342, 0.15208038682270342, 0.08055990451482176, 0.08055990451482176, 0.08055990451482176, 0.10351374750765463, 0.10351374750765463, 0.10351374750765463, 0.0540507801224861, 0.0540507801224861, 0.0540507801224861, 0.07239023071891226, 0.07239023071891226, 0.07239023071891226, 0.08870675443482867, 0.08870675443482867, 0.08870675443482867, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05954551789946727, 0.05954551789946727, 0.05954551789946727, 0.016845668227584598, 0.016845668227584598, 0.016845668227584598, 0.09713569279747558, 0.09713569279747558, 0.09713569279747558, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12066959240502928, 0.12066959240502928, 0.12066959240502928, 0.035746648230487565, 0.035746648230487565, 0.035746648230487565, 0.07139301481633775, 0.07139301481633775, 0.07139301481633775, 0.516874301153564, 0.516874301153564, 0.516874301153564, 0.47630223187349197, 0.47630223187349197, 0.47630223187349197, 0.5046483931367356, 0.5046483931367356, 0.5046483931367356, 0.10149975611764128, 0.10149975611764128, 0.10149975611764128, 0.14394013708221332, 0.14394013708221332, 0.14394013708221332, 0.08906072742595406, 0.08906072742595406, 0.08906072742595406, 0.4323697705853732, 0.4323697705853732, 0.4323697705853732, 0.2564918209635322, 0.2564918209635322, 0.2564918209635322, 0.29285859216365195, 0.29285859216365195, 0.29285859216365195, 0.3588556792904247, 0.3588556792904247, 0.3588556792904247, 0.3590311980583082, 0.3590311980583082, 0.3590311980583082, 0.3396563483078262, 0.3396563483078262, 0.3396563483078262, 0.2875594704789233, 0.2875594704789233, 0.2875594704789233, 0.19234496828321357, 0.19234496828321357, 0.19234496828321357, 0.2526599147478785, 0.2526599147478785, 0.2526599147478785, 0.2280750954270827, 0.2280750954270827, 0.2280750954270827, 0.22161289955923746, 0.22161289955923746, 0.22161289955923746, 0.20748813356705254, 0.20748813356705254, 0.20748813356705254, 0.1713878475142927, 0.1713878475142927, 0.1713878475142927, 0.1626120938914295, 0.1626120938914295, 0.1626120938914295, 0.1598829230984029, 0.1598829230984029, 0.1598829230984029, 0.8114357534335697, 0.8114357534335697, 0.8114357534335697, 0.16171724199671755, 0.16171724199671755, 0.16171724199671755, 0.7831256799009594, 0.7831256799009594, 0.7831256799009594, 0.808975283797377, 0.808975283797377, 0.808975283797377, 0.20834016469473393, 0.20834016469473393, 0.20834016469473393, 0.5719538144840941, 0.5719538144840941, 0.5719538144840941, 0.21366142706233227, 0.21366142706233227, 0.21366142706233227, 0.17753141240961634, 0.17753141240961634, 0.17753141240961634, 0.17022372847312295, 0.17022372847312295, 0.17022372847312295, 0.08461039908949919, 0.08461039908949919, 0.08461039908949919, 0.07845956885334493, 0.07845956885334493, 0.07845956885334493, 0.08092667580294455, 0.08092667580294455, 0.08092667580294455]}, "mutation_prompt": null}
{"id": "bbeb65c5-124d-4d03-8d81-a8039702abde", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85\n        self.w_min = 0.3\n        self.c1 = 1.45  # Slightly reduced to encourage broader exploration\n        self.c2 = 1.55  # Slightly increased to enhance social influence\n        self.temp_init = 100.0\n        self.temp_end = 0.5\n        self.adaptive_factor = 0.95\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n        self.perturb_prob = 0.05  # Introduced small perturbation probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                if np.random.rand() < self.perturb_prob:  # Apply stochastic perturbation occasionally\n                    perturbation = np.random.uniform(-0.1, 0.1, self.dim)\n                    proposed_position += perturbation\n                    proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.98)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Improved hybrid PSO-SA optimizer with stochastic perturbation for enhanced exploration and convergence.", "configspace": "", "generation": 88, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "6c40ab67-b7c9-4552-bb6a-87b4a56c599f", "metadata": {"aucs": [0.753092142234597, 0.753092142234597, 0.753092142234597, 0.7246196687684654, 0.7246196687684654, 0.7246196687684654, 0.6890043606486054, 0.6890043606486054, 0.6890043606486054, 0.05185899082743495, 0.05185899082743495, 0.05185899082743495, 0.0011543110382502553, 0.0011543110382502553, 0.0011543110382502553, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13385711763867325, 0.13385711763867325, 0.13385711763867325, 0.12821962340210846, 0.12821962340210846, 0.12821962340210846, 0.1124228221388952, 0.1124228221388952, 0.1124228221388952, 0.10656219445605986, 0.10656219445605986, 0.10656219445605986, 0.09934661859994953, 0.09934661859994953, 0.09934661859994953, 0.11913895817960563, 0.11913895817960563, 0.11913895817960563, 0.8604847325465861, 0.8604847325465861, 0.8604847325465861, 0.8883334804746417, 0.8883334804746417, 0.8883334804746417, 0.8953241333499276, 0.8953241333499276, 0.8953241333499276, 0.16965468283154206, 0.16965468283154206, 0.16965468283154206, 0.19753025689589354, 0.19753025689589354, 0.19753025689589354, 0.14332388332199675, 0.14332388332199675, 0.14332388332199675, 0.1678857222375273, 0.1678857222375273, 0.1678857222375273, 0.7022462144135599, 0.7022462144135599, 0.7022462144135599, 0.1284567888077418, 0.1284567888077418, 0.1284567888077418, 0.15208038682270342, 0.15208038682270342, 0.15208038682270342, 0.08055990451482176, 0.08055990451482176, 0.08055990451482176, 0.10351374750765463, 0.10351374750765463, 0.10351374750765463, 0.0540507801224861, 0.0540507801224861, 0.0540507801224861, 0.07239023071891226, 0.07239023071891226, 0.07239023071891226, 0.08870675443482867, 0.08870675443482867, 0.08870675443482867, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05954551789946727, 0.05954551789946727, 0.05954551789946727, 0.016845668227584598, 0.016845668227584598, 0.016845668227584598, 0.09713569279747558, 0.09713569279747558, 0.09713569279747558, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12066959240502928, 0.12066959240502928, 0.12066959240502928, 0.035746648230487565, 0.035746648230487565, 0.035746648230487565, 0.07139301481633775, 0.07139301481633775, 0.07139301481633775, 0.516874301153564, 0.516874301153564, 0.516874301153564, 0.47630223187349197, 0.47630223187349197, 0.47630223187349197, 0.5046483931367356, 0.5046483931367356, 0.5046483931367356, 0.10149975611764128, 0.10149975611764128, 0.10149975611764128, 0.14394013708221332, 0.14394013708221332, 0.14394013708221332, 0.08906072742595406, 0.08906072742595406, 0.08906072742595406, 0.4323697705853732, 0.4323697705853732, 0.4323697705853732, 0.2564918209635322, 0.2564918209635322, 0.2564918209635322, 0.29285859216365195, 0.29285859216365195, 0.29285859216365195, 0.3588556792904247, 0.3588556792904247, 0.3588556792904247, 0.3590311980583082, 0.3590311980583082, 0.3590311980583082, 0.3396563483078262, 0.3396563483078262, 0.3396563483078262, 0.2875594704789233, 0.2875594704789233, 0.2875594704789233, 0.19234496828321357, 0.19234496828321357, 0.19234496828321357, 0.2526599147478785, 0.2526599147478785, 0.2526599147478785, 0.2280750954270827, 0.2280750954270827, 0.2280750954270827, 0.22161289955923746, 0.22161289955923746, 0.22161289955923746, 0.20748813356705254, 0.20748813356705254, 0.20748813356705254, 0.1713878475142927, 0.1713878475142927, 0.1713878475142927, 0.1626120938914295, 0.1626120938914295, 0.1626120938914295, 0.1598829230984029, 0.1598829230984029, 0.1598829230984029, 0.8114357534335697, 0.8114357534335697, 0.8114357534335697, 0.16171724199671755, 0.16171724199671755, 0.16171724199671755, 0.7831256799009594, 0.7831256799009594, 0.7831256799009594, 0.808975283797377, 0.808975283797377, 0.808975283797377, 0.20834016469473393, 0.20834016469473393, 0.20834016469473393, 0.5719538144840941, 0.5719538144840941, 0.5719538144840941, 0.21366142706233227, 0.21366142706233227, 0.21366142706233227, 0.17753141240961634, 0.17753141240961634, 0.17753141240961634, 0.17022372847312295, 0.17022372847312295, 0.17022372847312295, 0.08461039908949919, 0.08461039908949919, 0.08461039908949919, 0.07845956885334493, 0.07845956885334493, 0.07845956885334493, 0.08092667580294455, 0.08092667580294455, 0.08092667580294455]}, "mutation_prompt": null}
{"id": "2a797fd3-45ed-4828-9621-cda2ed2a9ea8", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85\n        self.w_min = 0.3\n        self.c1 = 1.45\n        self.c2 = 1.55\n        self.temp_init = 100.0\n        self.temp_end = 0.5\n        self.adaptive_factor = 0.95\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n        self.perturb_prob = 0.05\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                if np.random.rand() < self.perturb_prob:  # Dynamic perturbation\n                    perturbation = np.random.uniform(-0.05, 0.05, self.dim)\n                    proposed_position += perturbation\n                    proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.98)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced hybrid PSO-SA optimizer with dynamic perturbation for improved convergence speed.", "configspace": "", "generation": 89, "fitness": 0.23542333252348124, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.25.", "error": "", "parent_id": "6c40ab67-b7c9-4552-bb6a-87b4a56c599f", "metadata": {"aucs": [0.762633003768609, 0.762633003768609, 0.762633003768609, 0.767097940253858, 0.767097940253858, 0.767097940253858, 0.7576161933887091, 0.7576161933887091, 0.7576161933887091, 0.07109274163940371, 0.07109274163940371, 0.07109274163940371, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1657704489557884, 0.1657704489557884, 0.1657704489557884, 0.09769375485958465, 0.09769375485958465, 0.09769375485958465, 0.10778259408327906, 0.10778259408327906, 0.10778259408327906, 0.0785666501520258, 0.0785666501520258, 0.0785666501520258, 0.08185805232417531, 0.08185805232417531, 0.08185805232417531, 0.0947256612033942, 0.0947256612033942, 0.0947256612033942, 0.876082183513988, 0.876082183513988, 0.876082183513988, 0.8959124413998871, 0.8959124413998871, 0.8959124413998871, 0.8988047704841581, 0.8988047704841581, 0.8988047704841581, 0.2064701493279556, 0.2064701493279556, 0.2064701493279556, 0.13394108280486894, 0.13394108280486894, 0.13394108280486894, 0.1295368596205133, 0.1295368596205133, 0.1295368596205133, 0.1684356940471594, 0.1684356940471594, 0.1684356940471594, 0.1662350924542263, 0.1662350924542263, 0.1662350924542263, 0.16002919853556685, 0.16002919853556685, 0.16002919853556685, 0.14276938273740958, 0.14276938273740958, 0.14276938273740958, 0.08890992369620943, 0.08890992369620943, 0.08890992369620943, 0.09048847744063515, 0.09048847744063515, 0.09048847744063515, 0.004840332792047541, 0.004840332792047541, 0.004840332792047541, 0.13458636508648192, 0.13458636508648192, 0.13458636508648192, 0.13105310754831112, 0.13105310754831112, 0.13105310754831112, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06055022120622455, 0.06055022120622455, 0.06055022120622455, 0.021268171165120253, 0.021268171165120253, 0.021268171165120253, 0.06464970433241723, 0.06464970433241723, 0.06464970433241723, 0.0049173212986967085, 0.0049173212986967085, 0.0049173212986967085, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10165927390920537, 0.10165927390920537, 0.10165927390920537, 0.03207872156101654, 0.03207872156101654, 0.03207872156101654, 0.07229604102396714, 0.07229604102396714, 0.07229604102396714, 0.48834252993949956, 0.48834252993949956, 0.48834252993949956, 0.537992557099505, 0.537992557099505, 0.537992557099505, 0.5190709201237922, 0.5190709201237922, 0.5190709201237922, 0.13704999912827132, 0.13704999912827132, 0.13704999912827132, 0.1496122837292514, 0.1496122837292514, 0.1496122837292514, 0.08953990292149139, 0.08953990292149139, 0.08953990292149139, 0.2664360828160717, 0.2664360828160717, 0.2664360828160717, 0.17861812734696336, 0.17861812734696336, 0.17861812734696336, 0.19830258254359145, 0.19830258254359145, 0.19830258254359145, 0.24231387871177656, 0.24231387871177656, 0.24231387871177656, 0.2663467208140653, 0.2663467208140653, 0.2663467208140653, 0.3292895848376859, 0.3292895848376859, 0.3292895848376859, 0.2158681763074456, 0.2158681763074456, 0.2158681763074456, 0.19989638271056476, 0.19989638271056476, 0.19989638271056476, 0.23104074315009548, 0.23104074315009548, 0.23104074315009548, 0.17163245841747699, 0.17163245841747699, 0.17163245841747699, 0.25873565417989, 0.25873565417989, 0.25873565417989, 0.22133221587425755, 0.22133221587425755, 0.22133221587425755, 0.1706189041647571, 0.1706189041647571, 0.1706189041647571, 0.1718317269656201, 0.1718317269656201, 0.1718317269656201, 0.17572593270518266, 0.17572593270518266, 0.17572593270518266, 0.8132918529133852, 0.8132918529133852, 0.8132918529133852, 0.161527516578727, 0.161527516578727, 0.161527516578727, 0.8007492003127649, 0.8007492003127649, 0.8007492003127649, 0.6864359735448844, 0.6864359735448844, 0.6864359735448844, 0.20861517274761332, 0.20861517274761332, 0.20861517274761332, 0.6496364775101247, 0.6496364775101247, 0.6496364775101247, 0.19636887543352, 0.19636887543352, 0.19636887543352, 0.18178905157523406, 0.18178905157523406, 0.18178905157523406, 0.212342662780016, 0.212342662780016, 0.212342662780016, 0.07730083667321452, 0.07730083667321452, 0.07730083667321452, 0.08692618423986731, 0.08692618423986731, 0.08692618423986731, 0.08484721627915148, 0.08484721627915148, 0.08484721627915148]}, "mutation_prompt": null}
{"id": "b75f715f-75af-4b74-92d1-fd1dc3e58525", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85\n        self.w_min = 0.3\n        self.c1 = 1.45\n        self.c2 = 1.55\n        self.temp_init = 100.0\n        self.temp_end = 0.5\n        self.adaptive_factor = 0.95\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n        self.perturb_prob = 0.05\n        self.perturb_scale = 0.1  # Introduce adaptive perturbation scale\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                if np.random.rand() < self.perturb_prob:\n                    perturbation = np.random.uniform(-self.perturb_scale, self.perturb_scale, self.dim)\n                    proposed_position += perturbation\n                    proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.98)\n            self.perturb_scale *= 0.99  # Gradually reduce perturbation scale\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with adaptive perturbation scaling for improved convergence.", "configspace": "", "generation": 90, "fitness": 0.2350700796409267, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.25.", "error": "", "parent_id": "6c40ab67-b7c9-4552-bb6a-87b4a56c599f", "metadata": {"aucs": [0.7553879585437342, 0.7553879585437342, 0.7553879585437342, 0.7422594369450344, 0.7422594369450344, 0.7422594369450344, 0.7545479213698963, 0.7545479213698963, 0.7545479213698963, 0.03895592416546423, 0.03895592416546423, 0.03895592416546423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13820513619389563, 0.13820513619389563, 0.13820513619389563, 0.14192683561500563, 0.14192683561500563, 0.14192683561500563, 0.09969326097558062, 0.09969326097558062, 0.09969326097558062, 0.08010834182132898, 0.08010834182132898, 0.08010834182132898, 0.08259557656728922, 0.08259557656728922, 0.08259557656728922, 0.1234480101691815, 0.1234480101691815, 0.1234480101691815, 0.859636507480798, 0.859636507480798, 0.859636507480798, 0.8889359332892347, 0.8889359332892347, 0.8889359332892347, 0.8954030051151227, 0.8954030051151227, 0.8954030051151227, 0.17282174826079588, 0.17282174826079588, 0.17282174826079588, 0.08832563343394195, 0.08832563343394195, 0.08832563343394195, 0.12080214065509931, 0.12080214065509931, 0.12080214065509931, 0.16795637190390733, 0.16795637190390733, 0.16795637190390733, 0.2006844344787604, 0.2006844344787604, 0.2006844344787604, 0.12618895625504334, 0.12618895625504334, 0.12618895625504334, 0.15626994027276597, 0.15626994027276597, 0.15626994027276597, 0.08399523334327363, 0.08399523334327363, 0.08399523334327363, 0.0854718751634942, 0.0854718751634942, 0.0854718751634942, 0.007017107955948787, 0.007017107955948787, 0.007017107955948787, 0.002631107246848896, 0.002631107246848896, 0.002631107246848896, 0.08642638950963233, 0.08642638950963233, 0.08642638950963233, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05681172395247791, 0.05681172395247791, 0.05681172395247791, 0.019131928570885748, 0.019131928570885748, 0.019131928570885748, 0.05733066564775313, 0.05733066564775313, 0.05733066564775313, 0.007734044225930714, 0.007734044225930714, 0.007734044225930714, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12045409105094418, 0.12045409105094418, 0.12045409105094418, 0.03357933482973097, 0.03357933482973097, 0.03357933482973097, 0.07266450950635173, 0.07266450950635173, 0.07266450950635173, 0.5122806084184955, 0.5122806084184955, 0.5122806084184955, 0.4684940650544174, 0.4684940650544174, 0.4684940650544174, 0.5263190704023161, 0.5263190704023161, 0.5263190704023161, 0.1279632380440895, 0.1279632380440895, 0.1279632380440895, 0.1161281638238495, 0.1161281638238495, 0.1161281638238495, 0.0771353951554582, 0.0771353951554582, 0.0771353951554582, 0.35185846326771775, 0.35185846326771775, 0.35185846326771775, 0.2721095718591241, 0.2721095718591241, 0.2721095718591241, 0.16444000779224388, 0.16444000779224388, 0.16444000779224388, 0.36587589398999043, 0.36587589398999043, 0.36587589398999043, 0.3491464965954434, 0.3491464965954434, 0.3491464965954434, 0.2621464330036736, 0.2621464330036736, 0.2621464330036736, 0.22289751386659706, 0.22289751386659706, 0.22289751386659706, 0.20378758445927336, 0.20378758445927336, 0.20378758445927336, 0.21007587235251035, 0.21007587235251035, 0.21007587235251035, 0.2165216627643256, 0.2165216627643256, 0.2165216627643256, 0.19838722283739507, 0.19838722283739507, 0.19838722283739507, 0.22719417684713183, 0.22719417684713183, 0.22719417684713183, 0.1709406231522822, 0.1709406231522822, 0.1709406231522822, 0.16132738445328743, 0.16132738445328743, 0.16132738445328743, 0.16567866325051583, 0.16567866325051583, 0.16567866325051583, 0.8237161060555335, 0.8237161060555335, 0.8237161060555335, 0.16295162830633092, 0.16295162830633092, 0.16295162830633092, 0.8017321127648492, 0.8017321127648492, 0.8017321127648492, 0.8295247309091875, 0.8295247309091875, 0.8295247309091875, 0.20889455821638292, 0.20889455821638292, 0.20889455821638292, 0.5988306205979635, 0.5988306205979635, 0.5988306205979635, 0.21591439805622425, 0.21591439805622425, 0.21591439805622425, 0.1882220494756276, 0.1882220494756276, 0.1882220494756276, 0.1850745015563574, 0.1850745015563574, 0.1850745015563574, 0.10027977421314516, 0.10027977421314516, 0.10027977421314516, 0.09157373731722074, 0.09157373731722074, 0.09157373731722074, 0.07952232077260868, 0.07952232077260868, 0.07952232077260868]}, "mutation_prompt": null}
{"id": "a7a6c6dc-9eed-4432-9666-93bea5b8e489", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85\n        self.w_min = 0.3\n        self.c1 = 1.45\n        self.c2 = 1.55\n        self.temp_init = 100.0\n        self.temp_end = 0.5\n        self.adaptive_factor = 0.95\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n        self.perturb_prob = 0.05\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                # Adaptive perturbation probability based on temperature\n                adaptive_perturb_prob = self.perturb_prob * (temperature / self.temp_init)\n                if np.random.rand() < adaptive_perturb_prob:\n                    perturbation = np.random.uniform(-0.1, 0.1, self.dim)\n                    proposed_position += perturbation\n                    proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.98)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA with adaptive perturbation probability for improved convergence.", "configspace": "", "generation": 91, "fitness": 0.2410496002060255, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.25.", "error": "", "parent_id": "6c40ab67-b7c9-4552-bb6a-87b4a56c599f", "metadata": {"aucs": [0.7366090184019256, 0.7366090184019256, 0.7366090184019256, 0.7547946446239157, 0.7547946446239157, 0.7547946446239157, 0.7515306226244792, 0.7515306226244792, 0.7515306226244792, 0.051143683214222246, 0.051143683214222246, 0.051143683214222246, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1502440464723639, 0.1502440464723639, 0.1502440464723639, 0.13117162951401296, 0.13117162951401296, 0.13117162951401296, 0.10265269522760423, 0.10265269522760423, 0.10265269522760423, 0.09492646340294864, 0.09492646340294864, 0.09492646340294864, 0.048790817245844664, 0.048790817245844664, 0.048790817245844664, 0.11898827666536449, 0.11898827666536449, 0.11898827666536449, 0.8681233664868078, 0.8681233664868078, 0.8681233664868078, 0.8891361245319155, 0.8891361245319155, 0.8891361245319155, 0.9003320475252893, 0.9003320475252893, 0.9003320475252893, 0.2258725674033396, 0.2258725674033396, 0.2258725674033396, 0.12357553331752502, 0.12357553331752502, 0.12357553331752502, 0.11784770933074418, 0.11784770933074418, 0.11784770933074418, 0.36408944936970555, 0.36408944936970555, 0.36408944936970555, 0.1592914083031015, 0.1592914083031015, 0.1592914083031015, 0.10746365067231967, 0.10746365067231967, 0.10746365067231967, 0.18588866656953706, 0.18588866656953706, 0.18588866656953706, 0.04563853219042868, 0.04563853219042868, 0.04563853219042868, 0.11987051590665321, 0.11987051590665321, 0.11987051590665321, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12752348624220355, 0.12752348624220355, 0.12752348624220355, 0.08433856023065256, 0.08433856023065256, 0.08433856023065256, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08273718531224827, 0.08273718531224827, 0.08273718531224827, 0.025457084954039977, 0.025457084954039977, 0.025457084954039977, 0.07058509025450566, 0.07058509025450566, 0.07058509025450566, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08656501258443972, 0.08656501258443972, 0.08656501258443972, 0.02746974200035912, 0.02746974200035912, 0.02746974200035912, 0.05136038343881588, 0.05136038343881588, 0.05136038343881588, 0.5189704912602504, 0.5189704912602504, 0.5189704912602504, 0.5632916387807863, 0.5632916387807863, 0.5632916387807863, 0.49554602826167615, 0.49554602826167615, 0.49554602826167615, 0.09762466108497048, 0.09762466108497048, 0.09762466108497048, 0.13069245943100882, 0.13069245943100882, 0.13069245943100882, 0.08920912787683666, 0.08920912787683666, 0.08920912787683666, 0.3059458665881448, 0.3059458665881448, 0.3059458665881448, 0.249402839097852, 0.249402839097852, 0.249402839097852, 0.18041106103264026, 0.18041106103264026, 0.18041106103264026, 0.3785502600592473, 0.3785502600592473, 0.3785502600592473, 0.38517378060968854, 0.38517378060968854, 0.38517378060968854, 0.30590504356806836, 0.30590504356806836, 0.30590504356806836, 0.32706206726587483, 0.32706206726587483, 0.32706206726587483, 0.2283551486963572, 0.2283551486963572, 0.2283551486963572, 0.2398400096109945, 0.2398400096109945, 0.2398400096109945, 0.25742880096439047, 0.25742880096439047, 0.25742880096439047, 0.24550275632227558, 0.24550275632227558, 0.24550275632227558, 0.24817634944505118, 0.24817634944505118, 0.24817634944505118, 0.2069415926209437, 0.2069415926209437, 0.2069415926209437, 0.18007308487928408, 0.18007308487928408, 0.18007308487928408, 0.17994400353400508, 0.17994400353400508, 0.17994400353400508, 0.8550420112625492, 0.8550420112625492, 0.8550420112625492, 0.16300164607311618, 0.16300164607311618, 0.16300164607311618, 0.823900663439064, 0.823900663439064, 0.823900663439064, 0.665053076486908, 0.665053076486908, 0.665053076486908, 0.20928586885402267, 0.20928586885402267, 0.20928586885402267, 0.41546227127101987, 0.41546227127101987, 0.41546227127101987, 0.17266471227166236, 0.17266471227166236, 0.17266471227166236, 0.19944535424548682, 0.19944535424548682, 0.19944535424548682, 0.18973325697611476, 0.18973325697611476, 0.18973325697611476, 0.09482410722930579, 0.09482410722930579, 0.09482410722930579, 0.08244808899943801, 0.08244808899943801, 0.08244808899943801, 0.06574507271748986, 0.06574507271748986, 0.06574507271748986]}, "mutation_prompt": null}
{"id": "9708903f-1463-41bd-bc19-8a4a2ede4b43", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85\n        self.w_min = 0.3\n        self.c1 = 1.45\n        self.c2 = 1.55\n        self.temp_init = 100.0\n        self.temp_end = 0.5\n        self.adaptive_factor = 0.95\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n        self.perturb_prob = 0.05\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        # Enhanced Initialization: Evaluate particles and adjust initial bests\n        for i in range(self.swarm_size):\n            current_value = func(particles[i])\n            evaluations += 1\n            personal_best_values[i] = current_value\n            personal_best_positions[i] = particles[i]\n            if current_value < self.global_best_val:\n                self.global_best_val = current_value\n                self.global_best_pos = particles[i]\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                if np.random.rand() < self.perturb_prob:\n                    perturbation = np.random.uniform(-0.1, 0.1, self.dim)\n                    proposed_position += perturbation\n                    proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.98)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Hybrid PSO-SA optimizer with enhanced jump-start initialization for faster convergence.", "configspace": "", "generation": 92, "fitness": 0.24797386546706104, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.25.", "error": "", "parent_id": "6c40ab67-b7c9-4552-bb6a-87b4a56c599f", "metadata": {"aucs": [0.7495923451529405, 0.7495923451529405, 0.7495923451529405, 0.7209031379452617, 0.7209031379452617, 0.7209031379452617, 0.6858498840199081, 0.6858498840199081, 0.6858498840199081, 0.051449614570322266, 0.051449614570322266, 0.051449614570322266, 0.0011371650493551266, 0.0011371650493551266, 0.0011371650493551266, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13333128627078916, 0.13333128627078916, 0.13333128627078916, 0.12761050210227498, 0.12761050210227498, 0.12761050210227498, 0.11194931682475895, 0.11194931682475895, 0.11194931682475895, 0.10607257732848951, 0.10607257732848951, 0.10607257732848951, 0.09885702640541127, 0.09885702640541127, 0.09885702640541127, 0.11857942196520144, 0.11857942196520144, 0.11857942196520144, 0.8566035691889716, 0.8566035691889716, 0.8566035691889716, 0.8844555479683929, 0.8844555479683929, 0.8844555479683929, 0.8914744586487275, 0.8914744586487275, 0.8914744586487275, 0.16878611778172004, 0.16878611778172004, 0.16878611778172004, 0.19639528505838033, 0.19639528505838033, 0.19639528505838033, 0.142766708751493, 0.142766708751493, 0.142766708751493, 0.1673144263998032, 0.1673144263998032, 0.1673144263998032, 0.6985497868704006, 0.6985497868704006, 0.6985497868704006, 0.12804085702173706, 0.12804085702173706, 0.12804085702173706, 0.15136079324731078, 0.15136079324731078, 0.15136079324731078, 0.08009461339422164, 0.08009461339422164, 0.08009461339422164, 0.10297102603276509, 0.10297102603276509, 0.10297102603276509, 0.053515150333109385, 0.053515150333109385, 0.053515150333109385, 0.0717512255247047, 0.0717512255247047, 0.0717512255247047, 0.08819090431678323, 0.08819090431678323, 0.08819090431678323, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05924824767644554, 0.05924824767644554, 0.05924824767644554, 0.01676081693146403, 0.01676081693146403, 0.01676081693146403, 0.09654432544373981, 0.09654432544373981, 0.09654432544373981, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11991428636605128, 0.11991428636605128, 0.11991428636605128, 0.035545106333249366, 0.035545106333249366, 0.035545106333249366, 0.07104353150905585, 0.07104353150905585, 0.07104353150905585, 0.5151634245189373, 0.5151634245189373, 0.5151634245189373, 0.47444885300625317, 0.47444885300625317, 0.47444885300625317, 0.5025156523094189, 0.5025156523094189, 0.5025156523094189, 0.1010997171609559, 0.1010997171609559, 0.1010997171609559, 0.1432598653968694, 0.1432598653968694, 0.1432598653968694, 0.08867845436861166, 0.08867845436861166, 0.08867845436861166, 0.43027865405710586, 0.43027865405710586, 0.43027865405710586, 0.255523801045065, 0.255523801045065, 0.255523801045065, 0.291623222837071, 0.291623222837071, 0.291623222837071, 0.3577105106659295, 0.3577105106659295, 0.3577105106659295, 0.3576767908690214, 0.3576767908690214, 0.3576767908690214, 0.3384986316464703, 0.3384986316464703, 0.3384986316464703, 0.2863516190662776, 0.2863516190662776, 0.2863516190662776, 0.19169472623251682, 0.19169472623251682, 0.19169472623251682, 0.2517716825923224, 0.2517716825923224, 0.2517716825923224, 0.22737010870553354, 0.22737010870553354, 0.22737010870553354, 0.22098776093155614, 0.22098776093155614, 0.22098776093155614, 0.20698028213238384, 0.20698028213238384, 0.20698028213238384, 0.17067153992666662, 0.17067153992666662, 0.17067153992666662, 0.16193715551451948, 0.16193715551451948, 0.16193715551451948, 0.1591006617009878, 0.1591006617009878, 0.1591006617009878, 0.8079572993143964, 0.8079572993143964, 0.8079572993143964, 0.1613571197539564, 0.1613571197539564, 0.1613571197539564, 0.7793960199149848, 0.7793960199149848, 0.7793960199149848, 0.8050813839595294, 0.8050813839595294, 0.8050813839595294, 0.20778207773592028, 0.20778207773592028, 0.20778207773592028, 0.5682082476024304, 0.5682082476024304, 0.5682082476024304, 0.21326906205219465, 0.21326906205219465, 0.21326906205219465, 0.17725843929701224, 0.17725843929701224, 0.17725843929701224, 0.1700197877241133, 0.1700197877241133, 0.1700197877241133, 0.08430314735857514, 0.08430314735857514, 0.08430314735857514, 0.07815584167046286, 0.07815584167046286, 0.07815584167046286, 0.08062771012710546, 0.08062771012710546, 0.08062771012710546]}, "mutation_prompt": null}
{"id": "7db12d7e-4116-4abf-95b0-5c7d054e2454", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85\n        self.w_min = 0.3\n        self.c1 = 1.45\n        self.c2 = 1.55\n        self.temp_init = 100.0\n        self.temp_end = 0.5\n        self.adaptive_factor = 0.95\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n        self.perturb_prob = 0.05\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                if np.random.rand() < self.perturb_prob:  \n                    perturbation_strength = (self.budget - evaluations) / self.budget\n                    perturbation = np.random.uniform(-0.1 * perturbation_strength, 0.1 * perturbation_strength, self.dim)\n                    proposed_position += perturbation\n                    proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.98)\n            # Adaptive velocity bounds based on remaining budget\n            self.vel_bounds = (-1.0 + 0.5 * (evaluations / self.budget), 1.0 - 0.5 * (evaluations / self.budget))\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with adaptive velocity bounds and improved perturbation mechanism for accelerated convergence.", "configspace": "", "generation": 93, "fitness": 0.24622578372253912, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.25.", "error": "", "parent_id": "6c40ab67-b7c9-4552-bb6a-87b4a56c599f", "metadata": {"aucs": [0.7483712717095894, 0.7483712717095894, 0.7483712717095894, 0.7427274569092218, 0.7427274569092218, 0.7427274569092218, 0.7408944906897327, 0.7408944906897327, 0.7408944906897327, 0.17506238007932806, 0.17506238007932806, 0.17506238007932806, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13895409911077805, 0.13895409911077805, 0.13895409911077805, 0.1279038081258046, 0.1279038081258046, 0.1279038081258046, 0.4308150177249336, 0.4308150177249336, 0.4308150177249336, 0.0772934398902293, 0.0772934398902293, 0.0772934398902293, 0.064010357162408, 0.064010357162408, 0.064010357162408, 0.13760232117581161, 0.13760232117581161, 0.13760232117581161, 0.8746543830792187, 0.8746543830792187, 0.8746543830792187, 0.8891091900748913, 0.8891091900748913, 0.8891091900748913, 0.8727860009787957, 0.8727860009787957, 0.8727860009787957, 0.105691951426507, 0.105691951426507, 0.105691951426507, 0.10389100490600178, 0.10389100490600178, 0.10389100490600178, 0.12408303322941505, 0.12408303322941505, 0.12408303322941505, 0.16690899652992097, 0.16690899652992097, 0.16690899652992097, 0.1586935762478715, 0.1586935762478715, 0.1586935762478715, 0.10485754384948964, 0.10485754384948964, 0.10485754384948964, 0.2800730451818757, 0.2800730451818757, 0.2800730451818757, 0.0836444496440516, 0.0836444496440516, 0.0836444496440516, 0.1135982159505291, 0.1135982159505291, 0.1135982159505291, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00010967600673883471, 0.00010967600673883471, 0.00010967600673883471, 0.11616974268197011, 0.11616974268197011, 0.11616974268197011, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09887264531403506, 0.09887264531403506, 0.09887264531403506, 0.014786390865915378, 0.014786390865915378, 0.014786390865915378, 0.046207416826618775, 0.046207416826618775, 0.046207416826618775, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.16176372299734743, 0.16176372299734743, 0.16176372299734743, 0.036592778766074696, 0.036592778766074696, 0.036592778766074696, 0.06825946288126727, 0.06825946288126727, 0.06825946288126727, 0.538354323542054, 0.538354323542054, 0.538354323542054, 0.47855868547701774, 0.47855868547701774, 0.47855868547701774, 0.5087659305692318, 0.5087659305692318, 0.5087659305692318, 0.12182156447441939, 0.12182156447441939, 0.12182156447441939, 0.10736136649411165, 0.10736136649411165, 0.10736136649411165, 0.10087750557292363, 0.10087750557292363, 0.10087750557292363, 0.23557167091379927, 0.23557167091379927, 0.23557167091379927, 0.3677872612374945, 0.3677872612374945, 0.3677872612374945, 0.2503447506914158, 0.2503447506914158, 0.2503447506914158, 0.36671091372333176, 0.36671091372333176, 0.36671091372333176, 0.3760506518347878, 0.3760506518347878, 0.3760506518347878, 0.4638159124919854, 0.4638159124919854, 0.4638159124919854, 0.2647129270560237, 0.2647129270560237, 0.2647129270560237, 0.2864045952326396, 0.2864045952326396, 0.2864045952326396, 0.24708743135529176, 0.24708743135529176, 0.24708743135529176, 0.2134283536572491, 0.2134283536572491, 0.2134283536572491, 0.18500380971775732, 0.18500380971775732, 0.18500380971775732, 0.23351197115320765, 0.23351197115320765, 0.23351197115320765, 0.18154425198567015, 0.18154425198567015, 0.18154425198567015, 0.18973362900476454, 0.18973362900476454, 0.18973362900476454, 0.1650340315638048, 0.1650340315638048, 0.1650340315638048, 0.8266837361258017, 0.8266837361258017, 0.8266837361258017, 0.1626591461600514, 0.1626591461600514, 0.1626591461600514, 0.8086599966698864, 0.8086599966698864, 0.8086599966698864, 0.6737482254253933, 0.6737482254253933, 0.6737482254253933, 0.20958152405295227, 0.20958152405295227, 0.20958152405295227, 0.532418139753418, 0.532418139753418, 0.532418139753418, 0.19875239353105156, 0.19875239353105156, 0.19875239353105156, 0.17092979117140494, 0.17092979117140494, 0.17092979117140494, 0.1792599488017198, 0.1792599488017198, 0.1792599488017198, 0.08211469290773543, 0.08211469290773543, 0.08211469290773543, 0.08856660565423768, 0.08856660565423768, 0.08856660565423768, 0.1071128200038125, 0.1071128200038125, 0.1071128200038125]}, "mutation_prompt": null}
{"id": "db83baa2-458b-4c50-884a-3cb19c9c56e6", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85\n        self.w_min = 0.3\n        self.c1 = 1.45\n        self.c2 = 1.55\n        self.temp_init = 100.0\n        self.temp_end = 0.5\n        self.adaptive_factor = 0.95\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n        self.perturb_prob = 0.05\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                if np.random.rand() < self.perturb_prob * (temperature / self.temp_init):  # Adaptive perturbation\n                    perturbation = np.random.uniform(-0.1, 0.1, self.dim)\n                    proposed_position += perturbation\n                    proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.98)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "An enhanced PSO-SA optimizer with adaptive perturbation and velocity scaling for improved exploration and convergence.", "configspace": "", "generation": 94, "fitness": 0.2410496002060255, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.25.", "error": "", "parent_id": "6c40ab67-b7c9-4552-bb6a-87b4a56c599f", "metadata": {"aucs": [0.7366090184019256, 0.7366090184019256, 0.7366090184019256, 0.7547946446239157, 0.7547946446239157, 0.7547946446239157, 0.7515306226244792, 0.7515306226244792, 0.7515306226244792, 0.051143683214222246, 0.051143683214222246, 0.051143683214222246, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1502440464723639, 0.1502440464723639, 0.1502440464723639, 0.13117162951401296, 0.13117162951401296, 0.13117162951401296, 0.10265269522760423, 0.10265269522760423, 0.10265269522760423, 0.09492646340294864, 0.09492646340294864, 0.09492646340294864, 0.048790817245844664, 0.048790817245844664, 0.048790817245844664, 0.11898827666536449, 0.11898827666536449, 0.11898827666536449, 0.8681233664868078, 0.8681233664868078, 0.8681233664868078, 0.8891361245319155, 0.8891361245319155, 0.8891361245319155, 0.9003320475252893, 0.9003320475252893, 0.9003320475252893, 0.2258725674033396, 0.2258725674033396, 0.2258725674033396, 0.12357553331752502, 0.12357553331752502, 0.12357553331752502, 0.11784770933074418, 0.11784770933074418, 0.11784770933074418, 0.36408944936970555, 0.36408944936970555, 0.36408944936970555, 0.1592914083031015, 0.1592914083031015, 0.1592914083031015, 0.10746365067231967, 0.10746365067231967, 0.10746365067231967, 0.18588866656953706, 0.18588866656953706, 0.18588866656953706, 0.04563853219042868, 0.04563853219042868, 0.04563853219042868, 0.11987051590665321, 0.11987051590665321, 0.11987051590665321, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12752348624220355, 0.12752348624220355, 0.12752348624220355, 0.08433856023065256, 0.08433856023065256, 0.08433856023065256, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08273718531224827, 0.08273718531224827, 0.08273718531224827, 0.025457084954039977, 0.025457084954039977, 0.025457084954039977, 0.07058509025450566, 0.07058509025450566, 0.07058509025450566, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08656501258443972, 0.08656501258443972, 0.08656501258443972, 0.02746974200035912, 0.02746974200035912, 0.02746974200035912, 0.05136038343881588, 0.05136038343881588, 0.05136038343881588, 0.5189704912602504, 0.5189704912602504, 0.5189704912602504, 0.5632916387807863, 0.5632916387807863, 0.5632916387807863, 0.49554602826167615, 0.49554602826167615, 0.49554602826167615, 0.09762466108497048, 0.09762466108497048, 0.09762466108497048, 0.13069245943100882, 0.13069245943100882, 0.13069245943100882, 0.08920912787683666, 0.08920912787683666, 0.08920912787683666, 0.3059458665881448, 0.3059458665881448, 0.3059458665881448, 0.249402839097852, 0.249402839097852, 0.249402839097852, 0.18041106103264026, 0.18041106103264026, 0.18041106103264026, 0.3785502600592473, 0.3785502600592473, 0.3785502600592473, 0.38517378060968854, 0.38517378060968854, 0.38517378060968854, 0.30590504356806836, 0.30590504356806836, 0.30590504356806836, 0.32706206726587483, 0.32706206726587483, 0.32706206726587483, 0.2283551486963572, 0.2283551486963572, 0.2283551486963572, 0.2398400096109945, 0.2398400096109945, 0.2398400096109945, 0.25742880096439047, 0.25742880096439047, 0.25742880096439047, 0.24550275632227558, 0.24550275632227558, 0.24550275632227558, 0.24817634944505118, 0.24817634944505118, 0.24817634944505118, 0.2069415926209437, 0.2069415926209437, 0.2069415926209437, 0.18007308487928408, 0.18007308487928408, 0.18007308487928408, 0.17994400353400508, 0.17994400353400508, 0.17994400353400508, 0.8550420112625492, 0.8550420112625492, 0.8550420112625492, 0.16300164607311618, 0.16300164607311618, 0.16300164607311618, 0.823900663439064, 0.823900663439064, 0.823900663439064, 0.665053076486908, 0.665053076486908, 0.665053076486908, 0.20928586885402267, 0.20928586885402267, 0.20928586885402267, 0.41546227127101987, 0.41546227127101987, 0.41546227127101987, 0.17266471227166236, 0.17266471227166236, 0.17266471227166236, 0.19944535424548682, 0.19944535424548682, 0.19944535424548682, 0.18973325697611476, 0.18973325697611476, 0.18973325697611476, 0.09482410722930579, 0.09482410722930579, 0.09482410722930579, 0.08244808899943801, 0.08244808899943801, 0.08244808899943801, 0.06574507271748986, 0.06574507271748986, 0.06574507271748986]}, "mutation_prompt": null}
{"id": "f4e34534-a4d8-49aa-a7ed-12c6ec2bdb1a", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85\n        self.w_min = 0.3\n        self.c1 = 1.45\n        self.c2 = 1.55\n        self.temp_init = 100.0\n        self.temp_end = 0.5\n        self.adaptive_factor = 0.95\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-0.9, 0.9)  # Adjusted velocity bounds\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n        self.perturb_prob = 0.07  # Increased perturbation probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                if np.random.rand() < self.perturb_prob:  # Apply stochastic perturbation occasionally\n                    perturbation = np.random.uniform(-0.1, 0.1, self.dim)\n                    proposed_position += perturbation\n                    proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.98)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Slightly adjusted velocity bounds and perturbation frequency to enhance convergence speed.", "configspace": "", "generation": 95, "fitness": 0.21421714798431923, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.23.", "error": "", "parent_id": "6c40ab67-b7c9-4552-bb6a-87b4a56c599f", "metadata": {"aucs": [0.7562964639765558, 0.7562964639765558, 0.7562964639765558, 0.7171234672770346, 0.7171234672770346, 0.7171234672770346, 0.7439652829491197, 0.7439652829491197, 0.7439652829491197, 0.04870707621834758, 0.04870707621834758, 0.04870707621834758, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11153880325016596, 0.11153880325016596, 0.11153880325016596, 0.07547352177373212, 0.07547352177373212, 0.07547352177373212, 0.09199092181865876, 0.09199092181865876, 0.09199092181865876, 0.07015509841037149, 0.07015509841037149, 0.07015509841037149, 0.050263259790557124, 0.050263259790557124, 0.050263259790557124, 0.07166924905571237, 0.07166924905571237, 0.07166924905571237, 0.8527533015913398, 0.8527533015913398, 0.8527533015913398, 0.8939799350438358, 0.8939799350438358, 0.8939799350438358, 0.9006361362927171, 0.9006361362927171, 0.9006361362927171, 0.10626976359032869, 0.10626976359032869, 0.10626976359032869, 0.2230607465672937, 0.2230607465672937, 0.2230607465672937, 0.12076121166622511, 0.12076121166622511, 0.12076121166622511, 0.16055111939714184, 0.16055111939714184, 0.16055111939714184, 0.20181340316959773, 0.20181340316959773, 0.20181340316959773, 0.16608705425253134, 0.16608705425253134, 0.16608705425253134, 0.13696364022699892, 0.13696364022699892, 0.13696364022699892, 0.11485394403679294, 0.11485394403679294, 0.11485394403679294, 0.09252358809650962, 0.09252358809650962, 0.09252358809650962, 0.13140741149333557, 0.13140741149333557, 0.13140741149333557, 0.1280181990714807, 0.1280181990714807, 0.1280181990714807, 0.13142219799943033, 0.13142219799943033, 0.13142219799943033, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04949614116537082, 0.04949614116537082, 0.04949614116537082, 0.04066925470558014, 0.04066925470558014, 0.04066925470558014, 0.09195923696017949, 0.09195923696017949, 0.09195923696017949, 0.03225074940912798, 0.03225074940912798, 0.03225074940912798, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08751508507703343, 0.08751508507703343, 0.08751508507703343, 0.028619319657518294, 0.028619319657518294, 0.028619319657518294, 0.0674572783236943, 0.0674572783236943, 0.0674572783236943, 0.49242107085464204, 0.49242107085464204, 0.49242107085464204, 0.4448334744031738, 0.4448334744031738, 0.4448334744031738, 0.5217142919221374, 0.5217142919221374, 0.5217142919221374, 0.07539229483252274, 0.07539229483252274, 0.07539229483252274, 0.14069463415464745, 0.14069463415464745, 0.14069463415464745, 0.07542501606352603, 0.07542501606352603, 0.07542501606352603, 0.1609383022974109, 0.1609383022974109, 0.1609383022974109, 0.1805696733951634, 0.1805696733951634, 0.1805696733951634, 0.2180748214399596, 0.2180748214399596, 0.2180748214399596, 0.32754596340318554, 0.32754596340318554, 0.32754596340318554, 0.33066862842311906, 0.33066862842311906, 0.33066862842311906, 0.38129375491883166, 0.38129375491883166, 0.38129375491883166, 0.2799830112881537, 0.2799830112881537, 0.2799830112881537, 0.20672034036957498, 0.20672034036957498, 0.20672034036957498, 0.18043148009012544, 0.18043148009012544, 0.18043148009012544, 0.22575968304016858, 0.22575968304016858, 0.22575968304016858, 0.2207396590977453, 0.2207396590977453, 0.2207396590977453, 0.23219561077030426, 0.23219561077030426, 0.23219561077030426, 0.16849174428457903, 0.16849174428457903, 0.16849174428457903, 0.15955722799516503, 0.15955722799516503, 0.15955722799516503, 0.38082605773280387, 0.38082605773280387, 0.38082605773280387, 0.8412239572490707, 0.8412239572490707, 0.8412239572490707, 0.16345847621777543, 0.16345847621777543, 0.16345847621777543, 0.1667583873639834, 0.1667583873639834, 0.1667583873639834, 0.15308540548474103, 0.15308540548474103, 0.15308540548474103, 0.2083686171850032, 0.2083686171850032, 0.2083686171850032, 0.15234316804263925, 0.15234316804263925, 0.15234316804263925, 0.18513511304691121, 0.18513511304691121, 0.18513511304691121, 0.19431548258633413, 0.19431548258633413, 0.19431548258633413, 0.18901449327917352, 0.18901449327917352, 0.18901449327917352, 0.09515102145157928, 0.09515102145157928, 0.09515102145157928, 0.08424696335172432, 0.08424696335172432, 0.08424696335172432, 0.08930496652079167, 0.08930496652079167, 0.08930496652079167]}, "mutation_prompt": null}
{"id": "4c282d6b-2ab4-44e7-95d1-ce2fb0343b06", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85\n        self.w_min = 0.3\n        self.c1 = 1.45\n        self.c2 = 1.60  # Minor increase for greater emphasis on social component\n        self.temp_init = 100.0\n        self.temp_end = 0.5\n        self.adaptive_factor = 0.95\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n        self.perturb_prob = 0.05\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social * (1 - self.w)  # Slightly alter velocity update\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                if np.random.rand() < self.perturb_prob:\n                    perturbation = np.random.uniform(-0.1, 0.1, self.dim)\n                    proposed_position += perturbation\n                    proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.98)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA algorithm with modified velocity update to improve convergence efficiency.", "configspace": "", "generation": 96, "fitness": 0.2241034730076107, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.25.", "error": "", "parent_id": "6c40ab67-b7c9-4552-bb6a-87b4a56c599f", "metadata": {"aucs": [0.7641976917572075, 0.7641976917572075, 0.7641976917572075, 0.7788004424112973, 0.7788004424112973, 0.7788004424112973, 0.8147363342522854, 0.8147363342522854, 0.8147363342522854, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12867434711784353, 0.12867434711784353, 0.12867434711784353, 0.1444130162271665, 0.1444130162271665, 0.1444130162271665, 0.1020779104386218, 0.1020779104386218, 0.1020779104386218, 0.056012212799322336, 0.056012212799322336, 0.056012212799322336, 0.06696637051208365, 0.06696637051208365, 0.06696637051208365, 0.06906950882649121, 0.06906950882649121, 0.06906950882649121, 0.7668803424026207, 0.7668803424026207, 0.7668803424026207, 0.8314903500546019, 0.8314903500546019, 0.8314903500546019, 0.8327491771891984, 0.8327491771891984, 0.8327491771891984, 0.06956251584091167, 0.06956251584091167, 0.06956251584091167, 0.1983681861901816, 0.1983681861901816, 0.1983681861901816, 0.12504825413397624, 0.12504825413397624, 0.12504825413397624, 0.17623612353611173, 0.17623612353611173, 0.17623612353611173, 0.20321214534911491, 0.20321214534911491, 0.20321214534911491, 0.12572296976015185, 0.12572296976015185, 0.12572296976015185, 0.019276965253419043, 0.019276965253419043, 0.019276965253419043, 0.09834039373605796, 0.09834039373605796, 0.09834039373605796, 0.10846342285480992, 0.10846342285480992, 0.10846342285480992, 0.11930127775533927, 0.11930127775533927, 0.11930127775533927, 0.12805332136689085, 0.12805332136689085, 0.12805332136689085, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06511142061668962, 0.06511142061668962, 0.06511142061668962, 0.04170710542829015, 0.04170710542829015, 0.04170710542829015, 0.04857339464813082, 0.04857339464813082, 0.04857339464813082, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0027680301333655732, 0.0027680301333655732, 0.0027680301333655732, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1391388617544872, 0.1391388617544872, 0.1391388617544872, 0.035345338947727734, 0.035345338947727734, 0.035345338947727734, 0.03208794103021462, 0.03208794103021462, 0.03208794103021462, 0.5355201422174605, 0.5355201422174605, 0.5355201422174605, 0.4861827814624792, 0.4861827814624792, 0.4861827814624792, 0.49230793737594714, 0.49230793737594714, 0.49230793737594714, 0.14888485124688555, 0.14888485124688555, 0.14888485124688555, 0.10599114502034157, 0.10599114502034157, 0.10599114502034157, 0.06641140891007491, 0.06641140891007491, 0.06641140891007491, 0.21136553013731685, 0.21136553013731685, 0.21136553013731685, 0.14831219087926384, 0.14831219087926384, 0.14831219087926384, 0.12587064500896628, 0.12587064500896628, 0.12587064500896628, 0.27761215295890074, 0.27761215295890074, 0.27761215295890074, 0.1832212770787941, 0.1832212770787941, 0.1832212770787941, 0.28713222540520067, 0.28713222540520067, 0.28713222540520067, 0.27286124183398897, 0.27286124183398897, 0.27286124183398897, 0.21514293899530057, 0.21514293899530057, 0.21514293899530057, 0.15235463093804424, 0.15235463093804424, 0.15235463093804424, 0.21524858044769446, 0.21524858044769446, 0.21524858044769446, 0.22591975430076394, 0.22591975430076394, 0.22591975430076394, 0.21227368976370276, 0.21227368976370276, 0.21227368976370276, 0.16620543557437117, 0.16620543557437117, 0.16620543557437117, 0.17332918876304448, 0.17332918876304448, 0.17332918876304448, 0.16722474033979684, 0.16722474033979684, 0.16722474033979684, 0.836237465932871, 0.836237465932871, 0.836237465932871, 0.1615591144149574, 0.1615591144149574, 0.1615591144149574, 0.8122131918791469, 0.8122131918791469, 0.8122131918791469, 0.7446623874655498, 0.7446623874655498, 0.7446623874655498, 0.20900299732049177, 0.20900299732049177, 0.20900299732049177, 0.5532564915980047, 0.5532564915980047, 0.5532564915980047, 0.20641541532272867, 0.20641541532272867, 0.20641541532272867, 0.18083210792551885, 0.18083210792551885, 0.18083210792551885, 0.2068408443741444, 0.2068408443741444, 0.2068408443741444, 0.09379577835710629, 0.09379577835710629, 0.09379577835710629, 0.085911237962365, 0.085911237962365, 0.085911237962365, 0.08206516301213529, 0.08206516301213529, 0.08206516301213529]}, "mutation_prompt": null}
{"id": "aa572c55-0523-4ccd-9b1e-16656ed8ae23", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85\n        self.w_min = 0.3\n        self.c1 = 1.75  # Increased cognitive coefficient to enhance self-exploration\n        self.c2 = 1.25  # Reduced social coefficient to balance exploration and exploitation\n        self.temp_init = 100.0\n        self.temp_end = 0.5\n        self.adaptive_factor = 0.95\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n        self.perturb_prob = 0.05\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                if np.random.rand() < self.perturb_prob:\n                    perturbation = np.random.uniform(-0.1, 0.1, self.dim)\n                    proposed_position += perturbation\n                    proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.98)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA optimizer with modified velocity update coefficients to improve convergence speed.", "configspace": "", "generation": 97, "fitness": 0.23137175139698624, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.24.", "error": "", "parent_id": "6c40ab67-b7c9-4552-bb6a-87b4a56c599f", "metadata": {"aucs": [0.7707576048477476, 0.7707576048477476, 0.7707576048477476, 0.73834177186895, 0.73834177186895, 0.73834177186895, 0.7478100023331664, 0.7478100023331664, 0.7478100023331664, 0.017289517447139913, 0.017289517447139913, 0.017289517447139913, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.004323399288424845, 0.004323399288424845, 0.004323399288424845, 0.16035114138502826, 0.16035114138502826, 0.16035114138502826, 0.10732464162382349, 0.10732464162382349, 0.10732464162382349, 0.11748797391279253, 0.11748797391279253, 0.11748797391279253, 0.07124015049001409, 0.07124015049001409, 0.07124015049001409, 0.1020505738058115, 0.1020505738058115, 0.1020505738058115, 0.09272949782178097, 0.09272949782178097, 0.09272949782178097, 0.8727448970404174, 0.8727448970404174, 0.8727448970404174, 0.8734214065964774, 0.8734214065964774, 0.8734214065964774, 0.8591904088664156, 0.8591904088664156, 0.8591904088664156, 0.20774278149536163, 0.20774278149536163, 0.20774278149536163, 0.19225150402988123, 0.19225150402988123, 0.19225150402988123, 0.13455039244816092, 0.13455039244816092, 0.13455039244816092, 0.15573152970994286, 0.15573152970994286, 0.15573152970994286, 0.181552063940567, 0.181552063940567, 0.181552063940567, 0.21865344437179568, 0.21865344437179568, 0.21865344437179568, 0.14828558532880975, 0.14828558532880975, 0.14828558532880975, 0.09969388455272021, 0.09969388455272021, 0.09969388455272021, 0.11709041552698596, 0.11709041552698596, 0.11709041552698596, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1351358116804946, 0.1351358116804946, 0.1351358116804946, 0.15156477364171983, 0.15156477364171983, 0.15156477364171983, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07726414427157557, 0.07726414427157557, 0.07726414427157557, 0.028097645588830322, 0.028097645588830322, 0.028097645588830322, 0.08549389071592994, 0.08549389071592994, 0.08549389071592994, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12347219989133396, 0.12347219989133396, 0.12347219989133396, 0.02780856589966718, 0.02780856589966718, 0.02780856589966718, 0.059160906126687896, 0.059160906126687896, 0.059160906126687896, 0.4932832612738567, 0.4932832612738567, 0.4932832612738567, 0.5258793043194631, 0.5258793043194631, 0.5258793043194631, 0.48878454815753747, 0.48878454815753747, 0.48878454815753747, 0.07695340322238042, 0.07695340322238042, 0.07695340322238042, 0.13620402100737705, 0.13620402100737705, 0.13620402100737705, 0.1029093108821324, 0.1029093108821324, 0.1029093108821324, 0.17981512411724, 0.17981512411724, 0.17981512411724, 0.24456348668832684, 0.24456348668832684, 0.24456348668832684, 0.33867320965221526, 0.33867320965221526, 0.33867320965221526, 0.27994503496829115, 0.27994503496829115, 0.27994503496829115, 0.4306843291712813, 0.4306843291712813, 0.4306843291712813, 0.25921631668559253, 0.25921631668559253, 0.25921631668559253, 0.22141904794145495, 0.22141904794145495, 0.22141904794145495, 0.1691833480844509, 0.1691833480844509, 0.1691833480844509, 0.21192391993161175, 0.21192391993161175, 0.21192391993161175, 0.1963103765697053, 0.1963103765697053, 0.1963103765697053, 0.244064215789621, 0.244064215789621, 0.244064215789621, 0.22356515079844674, 0.22356515079844674, 0.22356515079844674, 0.1876704583660831, 0.1876704583660831, 0.1876704583660831, 0.17627611320723957, 0.17627611320723957, 0.17627611320723957, 0.18809282390765825, 0.18809282390765825, 0.18809282390765825, 0.8271980772381791, 0.8271980772381791, 0.8271980772381791, 0.16307939341097955, 0.16307939341097955, 0.16307939341097955, 0.8181895590244245, 0.8181895590244245, 0.8181895590244245, 0.15136924371623495, 0.15136924371623495, 0.15136924371623495, 0.689179931160318, 0.689179931160318, 0.689179931160318, 0.16014624354286877, 0.16014624354286877, 0.16014624354286877, 0.1831193261335613, 0.1831193261335613, 0.1831193261335613, 0.17929529999322236, 0.17929529999322236, 0.17929529999322236, 0.19537989671580114, 0.19537989671580114, 0.19537989671580114, 0.09110745591443847, 0.09110745591443847, 0.09110745591443847, 0.06979339986398003, 0.06979339986398003, 0.06979339986398003, 0.07607894257858228, 0.07607894257858228, 0.07607894257858228]}, "mutation_prompt": null}
{"id": "536d6d78-a951-47c0-9505-f974da1ec2c7", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85\n        self.w_min = 0.3\n        self.c1 = 1.45  # Slightly reduced to encourage broader exploration\n        self.c2 = 1.55  # Slightly increased to enhance social influence\n        self.temp_init = 100.0\n        self.temp_end = 0.5\n        self.adaptive_factor = 0.95\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n        self.perturb_prob = 0.05  # Introduced small perturbation probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                if np.random.rand() < self.perturb_prob:  # Apply stochastic perturbation occasionally\n                    perturbation = np.random.uniform(-0.1, 0.1, self.dim)\n                    proposed_position += perturbation\n                    proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.98)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Improved hybrid PSO-SA optimizer with stochastic perturbation for enhanced exploration and convergence.", "configspace": "", "generation": 88, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "6c40ab67-b7c9-4552-bb6a-87b4a56c599f", "metadata": {"aucs": [0.753092142234597, 0.753092142234597, 0.753092142234597, 0.7246196687684654, 0.7246196687684654, 0.7246196687684654, 0.6890043606486054, 0.6890043606486054, 0.6890043606486054, 0.05185899082743495, 0.05185899082743495, 0.05185899082743495, 0.0011543110382502553, 0.0011543110382502553, 0.0011543110382502553, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13385711763867325, 0.13385711763867325, 0.13385711763867325, 0.12821962340210846, 0.12821962340210846, 0.12821962340210846, 0.1124228221388952, 0.1124228221388952, 0.1124228221388952, 0.10656219445605986, 0.10656219445605986, 0.10656219445605986, 0.09934661859994953, 0.09934661859994953, 0.09934661859994953, 0.11913895817960563, 0.11913895817960563, 0.11913895817960563, 0.8604847325465861, 0.8604847325465861, 0.8604847325465861, 0.8883334804746417, 0.8883334804746417, 0.8883334804746417, 0.8953241333499276, 0.8953241333499276, 0.8953241333499276, 0.16965468283154206, 0.16965468283154206, 0.16965468283154206, 0.19753025689589354, 0.19753025689589354, 0.19753025689589354, 0.14332388332199675, 0.14332388332199675, 0.14332388332199675, 0.1678857222375273, 0.1678857222375273, 0.1678857222375273, 0.7022462144135599, 0.7022462144135599, 0.7022462144135599, 0.1284567888077418, 0.1284567888077418, 0.1284567888077418, 0.15208038682270342, 0.15208038682270342, 0.15208038682270342, 0.08055990451482176, 0.08055990451482176, 0.08055990451482176, 0.10351374750765463, 0.10351374750765463, 0.10351374750765463, 0.0540507801224861, 0.0540507801224861, 0.0540507801224861, 0.07239023071891226, 0.07239023071891226, 0.07239023071891226, 0.08870675443482867, 0.08870675443482867, 0.08870675443482867, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05954551789946727, 0.05954551789946727, 0.05954551789946727, 0.016845668227584598, 0.016845668227584598, 0.016845668227584598, 0.09713569279747558, 0.09713569279747558, 0.09713569279747558, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12066959240502928, 0.12066959240502928, 0.12066959240502928, 0.035746648230487565, 0.035746648230487565, 0.035746648230487565, 0.07139301481633775, 0.07139301481633775, 0.07139301481633775, 0.516874301153564, 0.516874301153564, 0.516874301153564, 0.47630223187349197, 0.47630223187349197, 0.47630223187349197, 0.5046483931367356, 0.5046483931367356, 0.5046483931367356, 0.10149975611764128, 0.10149975611764128, 0.10149975611764128, 0.14394013708221332, 0.14394013708221332, 0.14394013708221332, 0.08906072742595406, 0.08906072742595406, 0.08906072742595406, 0.4323697705853732, 0.4323697705853732, 0.4323697705853732, 0.2564918209635322, 0.2564918209635322, 0.2564918209635322, 0.29285859216365195, 0.29285859216365195, 0.29285859216365195, 0.3588556792904247, 0.3588556792904247, 0.3588556792904247, 0.3590311980583082, 0.3590311980583082, 0.3590311980583082, 0.3396563483078262, 0.3396563483078262, 0.3396563483078262, 0.2875594704789233, 0.2875594704789233, 0.2875594704789233, 0.19234496828321357, 0.19234496828321357, 0.19234496828321357, 0.2526599147478785, 0.2526599147478785, 0.2526599147478785, 0.2280750954270827, 0.2280750954270827, 0.2280750954270827, 0.22161289955923746, 0.22161289955923746, 0.22161289955923746, 0.20748813356705254, 0.20748813356705254, 0.20748813356705254, 0.1713878475142927, 0.1713878475142927, 0.1713878475142927, 0.1626120938914295, 0.1626120938914295, 0.1626120938914295, 0.1598829230984029, 0.1598829230984029, 0.1598829230984029, 0.8114357534335697, 0.8114357534335697, 0.8114357534335697, 0.16171724199671755, 0.16171724199671755, 0.16171724199671755, 0.7831256799009594, 0.7831256799009594, 0.7831256799009594, 0.808975283797377, 0.808975283797377, 0.808975283797377, 0.20834016469473393, 0.20834016469473393, 0.20834016469473393, 0.5719538144840941, 0.5719538144840941, 0.5719538144840941, 0.21366142706233227, 0.21366142706233227, 0.21366142706233227, 0.17753141240961634, 0.17753141240961634, 0.17753141240961634, 0.17022372847312295, 0.17022372847312295, 0.17022372847312295, 0.08461039908949919, 0.08461039908949919, 0.08461039908949919, 0.07845956885334493, 0.07845956885334493, 0.07845956885334493, 0.08092667580294455, 0.08092667580294455, 0.08092667580294455]}, "mutation_prompt": null}
{"id": "b5b834db-279e-49ce-a6d6-f045e8936f1d", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.w = 0.85\n        self.w_min = 0.3\n        self.c1 = 1.45\n        self.c2 = 1.55\n        self.temp_init = 100.0\n        self.temp_end = 0.5\n        self.adaptive_factor = 0.95\n        self.bounds = (-5.0, 5.0)\n        self.vel_bounds = (-1.0, 1.0)\n        self.global_best_pos = np.random.uniform(*self.bounds, self.dim)\n        self.global_best_val = float('inf')\n        self.perturb_prob = 0.07  # Adjusted perturbation probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.random.uniform(self.vel_bounds[0], self.vel_bounds[1], (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, float('inf'))\n\n        evaluations = 0\n        temperature = self.temp_init\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_val:\n                    self.global_best_val = current_value\n                    self.global_best_pos = particles[i]\n\n            for i in range(self.swarm_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social = self.c2 * np.random.rand(self.dim) * (self.global_best_pos - particles[i])\n                velocities[i] = inertia + cognitive + social + np.random.normal(0, 0.01, self.dim)  # Added small Gaussian noise\n                velocities[i] = np.clip(velocities[i], *self.vel_bounds)\n\n                proposed_position = particles[i] + velocities[i]\n                proposed_position = np.clip(proposed_position, *self.bounds)\n\n                if np.random.rand() < self.perturb_prob:\n                    perturbation = np.random.uniform(-0.1, 0.1, self.dim)\n                    proposed_position += perturbation\n                    proposed_position = np.clip(proposed_position, *self.bounds)\n\n                proposed_value = func(proposed_position)\n                evaluations += 1\n\n                if proposed_value < current_value or np.random.rand() < np.exp((current_value - proposed_value) / temperature):\n                    particles[i] = proposed_position\n                    current_value = proposed_value\n                    if current_value < personal_best_values[i]:\n                        personal_best_values[i] = current_value\n                        personal_best_positions[i] = proposed_position\n\n            temperature *= self.adaptive_factor\n            self.w = max(self.w_min, self.w * 0.98)\n\n        return self.global_best_pos, self.global_best_val", "name": "PSO_SA_Optimizer", "description": "Slightly improved adaptive velocity adjustment and dynamic perturbation for faster convergence.", "configspace": "", "generation": 99, "fitness": 0.22799892977350014, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.23.", "error": "", "parent_id": "6c40ab67-b7c9-4552-bb6a-87b4a56c599f", "metadata": {"aucs": [0.5216923661546362, 0.5216923661546362, 0.5216923661546362, 0.526730266656932, 0.526730266656932, 0.526730266656932, 0.5260784572561107, 0.5260784572561107, 0.5260784572561107, 0.031033660325856194, 0.031033660325856194, 0.031033660325856194, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1077911988933723, 0.1077911988933723, 0.1077911988933723, 0.08577342228071849, 0.08577342228071849, 0.08577342228071849, 0.08068538293184824, 0.08068538293184824, 0.08068538293184824, 0.08987584665602211, 0.08987584665602211, 0.08987584665602211, 0.0757275895056646, 0.0757275895056646, 0.0757275895056646, 0.10021789631250044, 0.10021789631250044, 0.10021789631250044, 0.8981110076154448, 0.8981110076154448, 0.8981110076154448, 0.919327249713245, 0.919327249713245, 0.919327249713245, 0.9101301334109009, 0.9101301334109009, 0.9101301334109009, 0.22334045050051532, 0.22334045050051532, 0.22334045050051532, 0.28367902889255625, 0.28367902889255625, 0.28367902889255625, 0.16046725033426845, 0.16046725033426845, 0.16046725033426845, 0.1380516895987377, 0.1380516895987377, 0.1380516895987377, 0.1864009807868683, 0.1864009807868683, 0.1864009807868683, 0.21461104865393277, 0.21461104865393277, 0.21461104865393277, 0.12077259023243192, 0.12077259023243192, 0.12077259023243192, 0.09256018290519008, 0.09256018290519008, 0.09256018290519008, 0.11660783968564936, 0.11660783968564936, 0.11660783968564936, 0.12770575312400156, 0.12770575312400156, 0.12770575312400156, 0.11617363306952333, 0.11617363306952333, 0.11617363306952333, 0.059923259867152634, 0.059923259867152634, 0.059923259867152634, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09491462219274471, 0.09491462219274471, 0.09491462219274471, 0.025046603029738268, 0.025046603029738268, 0.025046603029738268, 0.06688083914280474, 0.06688083914280474, 0.06688083914280474, 0.008091686161417644, 0.008091686161417644, 0.008091686161417644, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11199788145081169, 0.11199788145081169, 0.11199788145081169, 0.033156543902426394, 0.033156543902426394, 0.033156543902426394, 0.0687708314664145, 0.0687708314664145, 0.0687708314664145, 0.4720999393317046, 0.4720999393317046, 0.4720999393317046, 0.45029523000915483, 0.45029523000915483, 0.45029523000915483, 0.4472868322862028, 0.4472868322862028, 0.4472868322862028, 0.14880299367405203, 0.14880299367405203, 0.14880299367405203, 0.11083560174273643, 0.11083560174273643, 0.11083560174273643, 0.09122242507686518, 0.09122242507686518, 0.09122242507686518, 0.3151923258851851, 0.3151923258851851, 0.3151923258851851, 0.34171930529261907, 0.34171930529261907, 0.34171930529261907, 0.34500194741919865, 0.34500194741919865, 0.34500194741919865, 0.32614486522048747, 0.32614486522048747, 0.32614486522048747, 0.33709890871762305, 0.33709890871762305, 0.33709890871762305, 0.3468812482506599, 0.3468812482506599, 0.3468812482506599, 0.20991098916778084, 0.20991098916778084, 0.20991098916778084, 0.20130774076041813, 0.20130774076041813, 0.20130774076041813, 0.22818267330952013, 0.22818267330952013, 0.22818267330952013, 0.2254470354488748, 0.2254470354488748, 0.2254470354488748, 0.21334916037366114, 0.21334916037366114, 0.21334916037366114, 0.2130255845931711, 0.2130255845931711, 0.2130255845931711, 0.16592755977051166, 0.16592755977051166, 0.16592755977051166, 0.19241324701757645, 0.19241324701757645, 0.19241324701757645, 0.1525696435200844, 0.1525696435200844, 0.1525696435200844, 0.8169153563300753, 0.8169153563300753, 0.8169153563300753, 0.15459271688633924, 0.15459271688633924, 0.15459271688633924, 0.8222039874293828, 0.8222039874293828, 0.8222039874293828, 0.7706975623691543, 0.7706975623691543, 0.7706975623691543, 0.20686447551831078, 0.20686447551831078, 0.20686447551831078, 0.1527073693874077, 0.1527073693874077, 0.1527073693874077, 0.1818321051225812, 0.1818321051225812, 0.1818321051225812, 0.1818548142352342, 0.1818548142352342, 0.1818548142352342, 0.2063926052551769, 0.2063926052551769, 0.2063926052551769, 0.0914770693975896, 0.0914770693975896, 0.0914770693975896, 0.06622166498838156, 0.06622166498838156, 0.06622166498838156, 0.10642076719385118, 0.10642076719385118, 0.10642076719385118]}, "mutation_prompt": null}

{"id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            # Bound positions\n            positions = np.clip(positions, self.lb, self.ub)\n\n            # Evaluate new positions\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            # Update personal bests\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Adaptive Differential Mutation\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.8 * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "HybridPSO", "description": "A hybrid particle swarm optimization with adaptive differential mutation balances exploration and exploitation efficiently.", "configspace": "", "generation": 0, "fitness": 0.2552196553551403, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.24.", "error": "", "parent_id": null, "metadata": {"aucs": [0.7192282850284312, 0.5168340857008723, 0.6846234116845872, 0.7473451340670973, 0.44590167675114, 0.7177523085068118, 0.751962615835188, 0.507453929730844, 0.6799256398352029, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19559599127823335, 0.02970441323486883, 0.11096595841071288, 0.14676657223313583, 0.10592460590777997, 0.04040868601545011, 0.06453080512785092, 0.08424129924959067, 0.14482960703394032, 0.12596087772304088, 0.10466414872067453, 0.09968093505935594, 0.09556840093578844, 0.1266707814832938, 0.15451638446824123, 0.08353935794307521, 0.09175091844091166, 0.11577306851162195, 0.0901782479222828, 0.08787258953535615, 0.0874204157768842, 0.07099005862787766, 0.0780027644954967, 0.1049044090573854, 0.986871927128186, 0.9888577568102923, 0.9841395406604165, 0.9587564242849532, 0.9749992231424514, 0.95341883713273, 0.9841826064614492, 0.9812872409200664, 0.9860836591966228, 0.5576772097784908, 0.2570625877476015, 0.05822140105781859, 0.1474555830900901, 0.1358965199793667, 0.23376341712849802, 0.1228635937753374, 0.2437899312263202, 0.39169357696551454, 0.16981736408600845, 0.5845308937910284, 0.22502806129098518, 0.6809418598131833, 0.17742377480503746, 0.20648207784302997, 0.12119005288043228, 0.5053751653460844, 0.7765840935138728, 0.3657576720147365, 0.125415344465879, 0.2121195213452689, 9.999999999998899e-05, 0.09346470551805053, 0.21811899436558302, 9.999999999998899e-05, 0.08964084229928937, 0.3020101709155415, 0.3443706013363482, 0.27705766684041633, 0.2170004528468722, 0.2954439973962145, 0.1586893109740437, 0.2356379836323167, 0.33045513386723446, 0.0868440127340595, 0.12912077732133076, 0.13901453956648457, 9.999999999998899e-05, 0.14004943949646165, 9.999999999998899e-05, 0.0738965864889678, 0.026175443700540924, 0.15205423909024285, 0.07018108820370894, 0.06632390909305708, 0.08495224488071218, 0.06449465292418499, 0.3075521568734839, 0.3063741155163029, 0.04689722871845625, 0.06663968569740863, 0.1809495787193004, 0.0907040919298262, 0.24311920344802007, 0.1823883188788431, 0.026758442389819947, 0.09893975037558755, 0.11005372597709706, 0.09534199086673856, 0.060521173796774796, 0.0703995294946762, 0.06168497185017063, 0.14539258170421376, 0.1802982434895819, 0.029699252956736255, 0.1698175212971209, 0.005830260095274542, 0.14745468698275288, 0.19746480836723157, 0.13446105354378246, 0.09967478792748241, 0.07833505816293529, 0.15269779794482363, 0.45268479444163545, 0.5319119345612638, 0.546626576734907, 0.44126875791280207, 0.5025545013298822, 0.5354592104587445, 0.4196551063736047, 0.5234676250391219, 0.12273692141825632, 0.07191974353402297, 0.09806815146701575, 0.09619567494706405, 0.08422198221706534, 0.12026437801395262, 0.13537823920063152, 0.09340609578952896, 0.09142444199167621, 0.2332702746507429, 0.27241995959464216, 0.1957548035840323, 0.2063349309423005, 0.27817845243066863, 0.21734473888159278, 0.25442152542739516, 0.16249108820503866, 0.22500289137696772, 0.3998986956725248, 0.30535352907680413, 0.3296205363350502, 0.20220610926671656, 0.2827284569439036, 0.25534122868473264, 0.2946655892546183, 0.2970055562039925, 0.3060993849392212, 0.32430560141483367, 0.20055268899183099, 0.2850729091832519, 0.21721890328931526, 0.17306799810176177, 0.2483118134212422, 0.25163493144047167, 0.2653303535771846, 0.2147623614153482, 0.23218211064824745, 0.15889439410157558, 0.23583622616058975, 0.19456643050425226, 0.16374003000060733, 0.21493953091769757, 0.22054221537976426, 0.21551086822309695, 0.2605374343106197, 0.20524551207598984, 0.20017766387611935, 0.1956276943474855, 0.20925170535343018, 0.20529381795845325, 0.18717220284413394, 0.18325239579642294, 0.18124447326753534, 0.19020501902925402, 0.8543511412457057, 0.16287565456475972, 0.15405114384215246, 0.8756578907995182, 0.19787582061465914, 0.20026239673368584, 0.14145544596878845, 0.1694883974512852, 0.8311271772006908, 0.8798375457660473, 0.2064413052170807, 0.15176246019230422, 0.20538455905359443, 0.566551491210618, 0.1550907979706735, 0.18481181998029672, 0.2089649029133862, 0.8021002040064757, 0.20259835816726113, 0.19294522648278056, 0.19996837239533938, 0.1998521869762372, 0.20039126424010079, 0.20393590761470382, 0.20086099584963946, 0.1904815661262652, 0.1857776711713358, 0.09433641993879316, 0.08015685705731035, 0.0939506345761596, 0.07902897205792137, 0.08872475901441956, 0.08341590190181958, 0.10648938366465865, 0.0730508682253449, 0.08920877147497341]}, "mutation_prompt": null}
{"id": "6e88348b-fc69-4e62-90d0-e44e6b79976c", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            # Bound positions\n            positions = np.clip(positions, self.lb, self.ub)\n\n            # Evaluate new positions\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            # Update personal bests\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Adaptive Differential Mutation\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.8 * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "HybridPSO", "description": "A hybrid particle swarm optimization with adaptive differential mutation balances exploration and exploitation efficiently.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.7192282850284312, 0.5168340857008723, 0.6846234116845872, 0.7473451340670973, 0.44590167675114, 0.7177523085068118, 0.751962615835188, 0.507453929730844, 0.6799256398352029, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19559599127823335, 0.02970441323486883, 0.11096595841071288, 0.14676657223313583, 0.10592460590777997, 0.04040868601545011, 0.06453080512785092, 0.08424129924959067, 0.14482960703394032, 0.12596087772304088, 0.10466414872067453, 0.09968093505935594, 0.09556840093578844, 0.1266707814832938, 0.15451638446824123, 0.08353935794307521, 0.09175091844091166, 0.11577306851162195, 0.0901782479222828, 0.08787258953535615, 0.0874204157768842, 0.07099005862787766, 0.0780027644954967, 0.1049044090573854, 0.986871927128186, 0.9888577568102923, 0.9841395406604165, 0.9587564242849532, 0.9749992231424514, 0.95341883713273, 0.9841826064614492, 0.9812872409200664, 0.9860836591966228, 0.5576772097784908, 0.2570625877476015, 0.05822140105781859, 0.1474555830900901, 0.1358965199793667, 0.23376341712849802, 0.1228635937753374, 0.2437899312263202, 0.39169357696551454, 0.16981736408600845, 0.5845308937910284, 0.22502806129098518, 0.6809418598131833, 0.17742377480503746, 0.20648207784302997, 0.12119005288043228, 0.5053751653460844, 0.7765840935138728, 0.3657576720147365, 0.125415344465879, 0.2121195213452689, 9.999999999998899e-05, 0.09346470551805053, 0.21811899436558302, 9.999999999998899e-05, 0.08964084229928937, 0.3020101709155415, 0.3443706013363482, 0.27705766684041633, 0.2170004528468722, 0.2954439973962145, 0.1586893109740437, 0.2356379836323167, 0.33045513386723446, 0.0868440127340595, 0.12912077732133076, 0.13901453956648457, 9.999999999998899e-05, 0.14004943949646165, 9.999999999998899e-05, 0.0738965864889678, 0.026175443700540924, 0.15205423909024285, 0.07018108820370894, 0.06632390909305708, 0.08495224488071218, 0.06449465292418499, 0.3075521568734839, 0.3063741155163029, 0.04689722871845625, 0.06663968569740863, 0.1809495787193004, 0.0907040919298262, 0.24311920344802007, 0.1823883188788431, 0.026758442389819947, 0.09893975037558755, 0.11005372597709706, 0.09534199086673856, 0.060521173796774796, 0.0703995294946762, 0.06168497185017063, 0.14539258170421376, 0.1802982434895819, 0.029699252956736255, 0.1698175212971209, 0.005830260095274542, 0.14745468698275288, 0.19746480836723157, 0.13446105354378246, 0.09967478792748241, 0.07833505816293529, 0.15269779794482363, 0.45268479444163545, 0.5319119345612638, 0.546626576734907, 0.44126875791280207, 0.5025545013298822, 0.5354592104587445, 0.4196551063736047, 0.5234676250391219, 0.12273692141825632, 0.07191974353402297, 0.09806815146701575, 0.09619567494706405, 0.08422198221706534, 0.12026437801395262, 0.13537823920063152, 0.09340609578952896, 0.09142444199167621, 0.2332702746507429, 0.27241995959464216, 0.1957548035840323, 0.2063349309423005, 0.27817845243066863, 0.21734473888159278, 0.25442152542739516, 0.16249108820503866, 0.22500289137696772, 0.3998986956725248, 0.30535352907680413, 0.3296205363350502, 0.20220610926671656, 0.2827284569439036, 0.25534122868473264, 0.2946655892546183, 0.2970055562039925, 0.3060993849392212, 0.32430560141483367, 0.20055268899183099, 0.2850729091832519, 0.21721890328931526, 0.17306799810176177, 0.2483118134212422, 0.25163493144047167, 0.2653303535771846, 0.2147623614153482, 0.23218211064824745, 0.15889439410157558, 0.23583622616058975, 0.19456643050425226, 0.16374003000060733, 0.21493953091769757, 0.22054221537976426, 0.21551086822309695, 0.2605374343106197, 0.20524551207598984, 0.20017766387611935, 0.1956276943474855, 0.20925170535343018, 0.20529381795845325, 0.18717220284413394, 0.18325239579642294, 0.18124447326753534, 0.19020501902925402, 0.8543511412457057, 0.16287565456475972, 0.15405114384215246, 0.8756578907995182, 0.19787582061465914, 0.20026239673368584, 0.14145544596878845, 0.1694883974512852, 0.8311271772006908, 0.8798375457660473, 0.2064413052170807, 0.15176246019230422, 0.20538455905359443, 0.566551491210618, 0.1550907979706735, 0.18481181998029672, 0.2089649029133862, 0.8021002040064757, 0.20259835816726113, 0.19294522648278056, 0.19996837239533938, 0.1998521869762372, 0.20039126424010079, 0.20393590761470382, 0.20086099584963946, 0.1904815661262652, 0.1857776711713358, 0.09433641993879316, 0.08015685705731035, 0.0939506345761596, 0.07902897205792137, 0.08872475901441956, 0.08341590190181958, 0.10648938366465865, 0.0730508682253449, 0.08920877147497341]}, "mutation_prompt": null}
{"id": "ad16c7da-fd25-4d08-9426-3a0b312d82ac", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            # Bound positions\n            positions = np.clip(positions, self.lb, self.ub)\n\n            # Evaluate new positions\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            # Update personal bests\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Adaptive Differential Mutation\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.8 * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "HybridPSO", "description": "A hybrid particle swarm optimization with adaptive differential mutation balances exploration and exploitation efficiently.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.7192282850284312, 0.5168340857008723, 0.6846234116845872, 0.7473451340670973, 0.44590167675114, 0.7177523085068118, 0.751962615835188, 0.507453929730844, 0.6799256398352029, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19559599127823335, 0.02970441323486883, 0.11096595841071288, 0.14676657223313583, 0.10592460590777997, 0.04040868601545011, 0.06453080512785092, 0.08424129924959067, 0.14482960703394032, 0.12596087772304088, 0.10466414872067453, 0.09968093505935594, 0.09556840093578844, 0.1266707814832938, 0.15451638446824123, 0.08353935794307521, 0.09175091844091166, 0.11577306851162195, 0.0901782479222828, 0.08787258953535615, 0.0874204157768842, 0.07099005862787766, 0.0780027644954967, 0.1049044090573854, 0.986871927128186, 0.9888577568102923, 0.9841395406604165, 0.9587564242849532, 0.9749992231424514, 0.95341883713273, 0.9841826064614492, 0.9812872409200664, 0.9860836591966228, 0.5576772097784908, 0.2570625877476015, 0.05822140105781859, 0.1474555830900901, 0.1358965199793667, 0.23376341712849802, 0.1228635937753374, 0.2437899312263202, 0.39169357696551454, 0.16981736408600845, 0.5845308937910284, 0.22502806129098518, 0.6809418598131833, 0.17742377480503746, 0.20648207784302997, 0.12119005288043228, 0.5053751653460844, 0.7765840935138728, 0.3657576720147365, 0.125415344465879, 0.2121195213452689, 9.999999999998899e-05, 0.09346470551805053, 0.21811899436558302, 9.999999999998899e-05, 0.08964084229928937, 0.3020101709155415, 0.3443706013363482, 0.27705766684041633, 0.2170004528468722, 0.2954439973962145, 0.1586893109740437, 0.2356379836323167, 0.33045513386723446, 0.0868440127340595, 0.12912077732133076, 0.13901453956648457, 9.999999999998899e-05, 0.14004943949646165, 9.999999999998899e-05, 0.0738965864889678, 0.026175443700540924, 0.15205423909024285, 0.07018108820370894, 0.06632390909305708, 0.08495224488071218, 0.06449465292418499, 0.3075521568734839, 0.3063741155163029, 0.04689722871845625, 0.06663968569740863, 0.1809495787193004, 0.0907040919298262, 0.24311920344802007, 0.1823883188788431, 0.026758442389819947, 0.09893975037558755, 0.11005372597709706, 0.09534199086673856, 0.060521173796774796, 0.0703995294946762, 0.06168497185017063, 0.14539258170421376, 0.1802982434895819, 0.029699252956736255, 0.1698175212971209, 0.005830260095274542, 0.14745468698275288, 0.19746480836723157, 0.13446105354378246, 0.09967478792748241, 0.07833505816293529, 0.15269779794482363, 0.45268479444163545, 0.5319119345612638, 0.546626576734907, 0.44126875791280207, 0.5025545013298822, 0.5354592104587445, 0.4196551063736047, 0.5234676250391219, 0.12273692141825632, 0.07191974353402297, 0.09806815146701575, 0.09619567494706405, 0.08422198221706534, 0.12026437801395262, 0.13537823920063152, 0.09340609578952896, 0.09142444199167621, 0.2332702746507429, 0.27241995959464216, 0.1957548035840323, 0.2063349309423005, 0.27817845243066863, 0.21734473888159278, 0.25442152542739516, 0.16249108820503866, 0.22500289137696772, 0.3998986956725248, 0.30535352907680413, 0.3296205363350502, 0.20220610926671656, 0.2827284569439036, 0.25534122868473264, 0.2946655892546183, 0.2970055562039925, 0.3060993849392212, 0.32430560141483367, 0.20055268899183099, 0.2850729091832519, 0.21721890328931526, 0.17306799810176177, 0.2483118134212422, 0.25163493144047167, 0.2653303535771846, 0.2147623614153482, 0.23218211064824745, 0.15889439410157558, 0.23583622616058975, 0.19456643050425226, 0.16374003000060733, 0.21493953091769757, 0.22054221537976426, 0.21551086822309695, 0.2605374343106197, 0.20524551207598984, 0.20017766387611935, 0.1956276943474855, 0.20925170535343018, 0.20529381795845325, 0.18717220284413394, 0.18325239579642294, 0.18124447326753534, 0.19020501902925402, 0.8543511412457057, 0.16287565456475972, 0.15405114384215246, 0.8756578907995182, 0.19787582061465914, 0.20026239673368584, 0.14145544596878845, 0.1694883974512852, 0.8311271772006908, 0.8798375457660473, 0.2064413052170807, 0.15176246019230422, 0.20538455905359443, 0.566551491210618, 0.1550907979706735, 0.18481181998029672, 0.2089649029133862, 0.8021002040064757, 0.20259835816726113, 0.19294522648278056, 0.19996837239533938, 0.1998521869762372, 0.20039126424010079, 0.20393590761470382, 0.20086099584963946, 0.1904815661262652, 0.1857776711713358, 0.09433641993879316, 0.08015685705731035, 0.0939506345761596, 0.07902897205792137, 0.08872475901441956, 0.08341590190181958, 0.10648938366465865, 0.0730508682253449, 0.08920877147497341]}, "mutation_prompt": null}
{"id": "88fe11bb-1eb6-4fa6-88bb-77f24bcd4fc1", "solution": "import numpy as np\n\nclass EnhancedPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.5  # Changed for chaotic dynamics\n        self.cognitive_weight = 1.8  # Increased cognitive influence\n        self.social_weight = 1.8  # Increased social influence\n        self.chaos_sequence = np.random.rand(self.budget)\n\n    def chaotic_inertia(self, step):\n        return 0.5 + 0.5 * np.sin(2.0 * np.pi * self.chaos_sequence[step % len(self.chaos_sequence)])\n\n    def opposition_based_learning(self, positions):\n        return self.lb + self.ub - positions\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            inertia_weight = self.chaotic_inertia(evaluations)\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            # Bound positions\n            positions = np.clip(positions, self.lb, self.ub)\n\n            # Evaluate new positions\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            # Update personal bests\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Apply opposition-based learning\n            opposition_positions = self.opposition_based_learning(positions)\n            opposition_scores = np.array([func(p) for p in opposition_positions])\n            evaluations += self.swarm_size\n\n            opposition_better_idxs = opposition_scores < personal_best_scores\n            personal_best_positions[opposition_better_idxs] = opposition_positions[opposition_better_idxs]\n            personal_best_scores[opposition_better_idxs] = opposition_scores[opposition_better_idxs]\n\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.8 * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "EnhancedPSO", "description": "An enhanced PSO with chaotic inertia and opposition-based learning for accelerated convergence.", "configspace": "", "generation": 3, "fitness": 0.23684859072051978, "feedback": "The algorithm EnhancedPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.22.", "error": "", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.7274326967418903, 0.6284399168640818, 0.6476532651402067, 0.188484267520172, 0.18634640369377253, 0.7053955867118125, 0.6697208215460944, 0.17412095369123293, 0.7236027265395525, 0.010035875944557793, 0.06866281683823128, 0.26066007277890557, 0.06775038261416377, 0.00016368179796844018, 0.24508676131120588, 0.10560481364920393, 0.011899484179762498, 0.02681034560769857, 0.0810159166494997, 0.10964232776510563, 0.05932568129561966, 0.10749185006473361, 0.10053718184318927, 0.17182255161323623, 0.09131978796257212, 0.08430067809003228, 0.11194224937775943, 0.11443226242636195, 0.09630930403757954, 0.06538276821510591, 0.021124194391652473, 0.09623761056349178, 0.10316010949836163, 0.10734320134430508, 0.09621439172457613, 0.07570682523313554, 0.9644630746697943, 0.9824608492371528, 0.9631522603479704, 0.970979096840404, 0.9850843969049777, 0.995384262349579, 0.9628386869003035, 0.9320428839824032, 0.9625662602265053, 0.4331946728989514, 0.2904508076546989, 0.05709503760122203, 0.14755922755252593, 0.2566522690733394, 0.37531235109862104, 0.05113568973624438, 0.07457637538229989, 0.26078227943312793, 0.23104660765251983, 0.6969823932868946, 0.6940979656395398, 0.21468225768907867, 0.2535725046337478, 0.20978991261065216, 0.141895552719146, 0.5888893564611413, 0.2259124882219794, 0.2029528826364616, 0.19541321102333564, 0.13619643881067345, 0.16640553243382894, 9.999999999998899e-05, 0.15679388922963589, 0.21876777668754654, 0.13071057676102626, 0.14968082633027968, 0.1391608672580107, 0.1651219000233486, 0.2763059211338692, 0.11705487454309316, 0.16879335488422198, 0.12295675745304124, 0.2962547789002392, 0.23792326174758616, 0.34471858018096546, 9.999999999998899e-05, 0.12330038805876864, 9.999999999998899e-05, 9.999999999998899e-05, 0.11712645254738596, 0.015804287868844358, 0.00586805275646507, 0.05879693017517873, 0.12939353571902068, 0.07783784538031957, 0.18713162632155889, 0.20918243758960642, 0.011789042211838519, 0.08145946420116912, 0.13560522368966665, 0.15468084726781928, 0.10392730686456164, 0.11375303044400842, 0.09549533826780521, 0.03414996283319727, 0.16309261840434597, 0.06671274679372985, 0.12767646083465445, 0.0731308242206351, 0.2722776218011468, 0.0714054550787736, 0.07994039713134882, 0.09067357942490639, 0.03595876819385757, 0.1372818220614197, 0.10165118494837533, 0.14794511771188223, 0.23954244572250782, 0.12030504403215181, 0.0693441163998687, 0.05130402287257785, 0.5323581291669427, 0.363029811215971, 0.5804141810745657, 0.18157482080365062, 0.42126784349687874, 0.5289834299794403, 0.6675650349227016, 0.4481704768135756, 0.46321695726313805, 0.12262819588587004, 0.1167154642955478, 0.09457981309300334, 0.09059764616250199, 0.11814366685103428, 0.07670787053053885, 0.03564990514206601, 0.09219386412523634, 0.14208102683921076, 0.15453178905217158, 0.16024128555975803, 0.16114114995631768, 0.290401322102938, 0.19610965335685515, 0.1335684170032404, 0.16554107079712443, 0.1506922897610119, 0.22621457586797156, 0.33989367671599, 0.3335107247091822, 0.2677566955048212, 0.2867979377451261, 0.2290700313922004, 0.3220119684751164, 0.1806498706394868, 0.2910666991983327, 0.31675493285058365, 0.2505383719757954, 0.2598744466956473, 0.24444564816470704, 0.19362953372513925, 0.2389327640407466, 0.2688428997143576, 0.2693152058293179, 0.20267446942904332, 0.21785157004179267, 0.24232073152923772, 0.20032911541305232, 0.256720644028273, 0.21187724832352395, 0.2194139074114443, 0.22058981791691978, 0.22763826428636147, 0.2108539514075699, 0.20595563990702226, 0.19141688662819956, 0.1708382175457902, 0.20132647859700525, 0.1831340307303393, 0.18080559604055502, 0.22364621756149783, 0.163718694461073, 0.17543295590859598, 0.19540462543714388, 0.16517050644173015, 0.16934286188601977, 0.15873175445408683, 0.17747173988932896, 0.7677919272797716, 0.7586883588775303, 0.6944162848028367, 0.1605974652954395, 0.1740163834995716, 0.5401087851667432, 0.16569539231058827, 0.16910522883957269, 0.10453370799606931, 0.3262161710771022, 0.20729518280904025, 0.16790395265776348, 0.15887443552274272, 0.6055998595078325, 0.1989300421203427, 0.19057380913981592, 0.19531177491906515, 0.20402863056742238, 0.17551343923503504, 0.20154766147600522, 0.20113617247261295, 0.19385607681176498, 0.18557535477315767, 0.08466628252134378, 0.0890801252096941, 0.08620990243181204, 0.07745979180405793, 0.112404153933503, 0.08672462847475904, 0.1367058654783706, 0.0767964046149553, 0.0889206062963136]}, "mutation_prompt": null}
{"id": "23e46aed-0220-4aee-a92c-c099acf8b212", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            # Bound positions\n            positions = np.clip(positions, self.lb, self.ub)\n\n            # Evaluate new positions\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            # Update personal bests\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Adaptive Differential Mutation\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.8 * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "HybridPSO", "description": "A hybrid particle swarm optimization with adaptive differential mutation balances exploration and exploitation efficiently.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.7192282850284312, 0.5168340857008723, 0.6846234116845872, 0.7473451340670973, 0.44590167675114, 0.7177523085068118, 0.751962615835188, 0.507453929730844, 0.6799256398352029, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19559599127823335, 0.02970441323486883, 0.11096595841071288, 0.14676657223313583, 0.10592460590777997, 0.04040868601545011, 0.06453080512785092, 0.08424129924959067, 0.14482960703394032, 0.12596087772304088, 0.10466414872067453, 0.09968093505935594, 0.09556840093578844, 0.1266707814832938, 0.15451638446824123, 0.08353935794307521, 0.09175091844091166, 0.11577306851162195, 0.0901782479222828, 0.08787258953535615, 0.0874204157768842, 0.07099005862787766, 0.0780027644954967, 0.1049044090573854, 0.986871927128186, 0.9888577568102923, 0.9841395406604165, 0.9587564242849532, 0.9749992231424514, 0.95341883713273, 0.9841826064614492, 0.9812872409200664, 0.9860836591966228, 0.5576772097784908, 0.2570625877476015, 0.05822140105781859, 0.1474555830900901, 0.1358965199793667, 0.23376341712849802, 0.1228635937753374, 0.2437899312263202, 0.39169357696551454, 0.16981736408600845, 0.5845308937910284, 0.22502806129098518, 0.6809418598131833, 0.17742377480503746, 0.20648207784302997, 0.12119005288043228, 0.5053751653460844, 0.7765840935138728, 0.3657576720147365, 0.125415344465879, 0.2121195213452689, 9.999999999998899e-05, 0.09346470551805053, 0.21811899436558302, 9.999999999998899e-05, 0.08964084229928937, 0.3020101709155415, 0.3443706013363482, 0.27705766684041633, 0.2170004528468722, 0.2954439973962145, 0.1586893109740437, 0.2356379836323167, 0.33045513386723446, 0.0868440127340595, 0.12912077732133076, 0.13901453956648457, 9.999999999998899e-05, 0.14004943949646165, 9.999999999998899e-05, 0.0738965864889678, 0.026175443700540924, 0.15205423909024285, 0.07018108820370894, 0.06632390909305708, 0.08495224488071218, 0.06449465292418499, 0.3075521568734839, 0.3063741155163029, 0.04689722871845625, 0.06663968569740863, 0.1809495787193004, 0.0907040919298262, 0.24311920344802007, 0.1823883188788431, 0.026758442389819947, 0.09893975037558755, 0.11005372597709706, 0.09534199086673856, 0.060521173796774796, 0.0703995294946762, 0.06168497185017063, 0.14539258170421376, 0.1802982434895819, 0.029699252956736255, 0.1698175212971209, 0.005830260095274542, 0.14745468698275288, 0.19746480836723157, 0.13446105354378246, 0.09967478792748241, 0.07833505816293529, 0.15269779794482363, 0.45268479444163545, 0.5319119345612638, 0.546626576734907, 0.44126875791280207, 0.5025545013298822, 0.5354592104587445, 0.4196551063736047, 0.5234676250391219, 0.12273692141825632, 0.07191974353402297, 0.09806815146701575, 0.09619567494706405, 0.08422198221706534, 0.12026437801395262, 0.13537823920063152, 0.09340609578952896, 0.09142444199167621, 0.2332702746507429, 0.27241995959464216, 0.1957548035840323, 0.2063349309423005, 0.27817845243066863, 0.21734473888159278, 0.25442152542739516, 0.16249108820503866, 0.22500289137696772, 0.3998986956725248, 0.30535352907680413, 0.3296205363350502, 0.20220610926671656, 0.2827284569439036, 0.25534122868473264, 0.2946655892546183, 0.2970055562039925, 0.3060993849392212, 0.32430560141483367, 0.20055268899183099, 0.2850729091832519, 0.21721890328931526, 0.17306799810176177, 0.2483118134212422, 0.25163493144047167, 0.2653303535771846, 0.2147623614153482, 0.23218211064824745, 0.15889439410157558, 0.23583622616058975, 0.19456643050425226, 0.16374003000060733, 0.21493953091769757, 0.22054221537976426, 0.21551086822309695, 0.2605374343106197, 0.20524551207598984, 0.20017766387611935, 0.1956276943474855, 0.20925170535343018, 0.20529381795845325, 0.18717220284413394, 0.18325239579642294, 0.18124447326753534, 0.19020501902925402, 0.8543511412457057, 0.16287565456475972, 0.15405114384215246, 0.8756578907995182, 0.19787582061465914, 0.20026239673368584, 0.14145544596878845, 0.1694883974512852, 0.8311271772006908, 0.8798375457660473, 0.2064413052170807, 0.15176246019230422, 0.20538455905359443, 0.566551491210618, 0.1550907979706735, 0.18481181998029672, 0.2089649029133862, 0.8021002040064757, 0.20259835816726113, 0.19294522648278056, 0.19996837239533938, 0.1998521869762372, 0.20039126424010079, 0.20393590761470382, 0.20086099584963946, 0.1904815661262652, 0.1857776711713358, 0.09433641993879316, 0.08015685705731035, 0.0939506345761596, 0.07902897205792137, 0.08872475901441956, 0.08341590190181958, 0.10648938366465865, 0.0730508682253449, 0.08920877147497341]}, "mutation_prompt": null}
{"id": "5337d6f9-12d9-46f7-b791-1d2a5dacdc65", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            # Bound positions\n            positions = np.clip(positions, self.lb, self.ub)\n\n            # Evaluate new positions\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            # Update personal bests\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Adaptive Differential Mutation\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.8 * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "HybridPSO", "description": "A hybrid particle swarm optimization with adaptive differential mutation balances exploration and exploitation efficiently.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.7192282850284312, 0.5168340857008723, 0.6846234116845872, 0.7473451340670973, 0.44590167675114, 0.7177523085068118, 0.751962615835188, 0.507453929730844, 0.6799256398352029, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19559599127823335, 0.02970441323486883, 0.11096595841071288, 0.14676657223313583, 0.10592460590777997, 0.04040868601545011, 0.06453080512785092, 0.08424129924959067, 0.14482960703394032, 0.12596087772304088, 0.10466414872067453, 0.09968093505935594, 0.09556840093578844, 0.1266707814832938, 0.15451638446824123, 0.08353935794307521, 0.09175091844091166, 0.11577306851162195, 0.0901782479222828, 0.08787258953535615, 0.0874204157768842, 0.07099005862787766, 0.0780027644954967, 0.1049044090573854, 0.986871927128186, 0.9888577568102923, 0.9841395406604165, 0.9587564242849532, 0.9749992231424514, 0.95341883713273, 0.9841826064614492, 0.9812872409200664, 0.9860836591966228, 0.5576772097784908, 0.2570625877476015, 0.05822140105781859, 0.1474555830900901, 0.1358965199793667, 0.23376341712849802, 0.1228635937753374, 0.2437899312263202, 0.39169357696551454, 0.16981736408600845, 0.5845308937910284, 0.22502806129098518, 0.6809418598131833, 0.17742377480503746, 0.20648207784302997, 0.12119005288043228, 0.5053751653460844, 0.7765840935138728, 0.3657576720147365, 0.125415344465879, 0.2121195213452689, 9.999999999998899e-05, 0.09346470551805053, 0.21811899436558302, 9.999999999998899e-05, 0.08964084229928937, 0.3020101709155415, 0.3443706013363482, 0.27705766684041633, 0.2170004528468722, 0.2954439973962145, 0.1586893109740437, 0.2356379836323167, 0.33045513386723446, 0.0868440127340595, 0.12912077732133076, 0.13901453956648457, 9.999999999998899e-05, 0.14004943949646165, 9.999999999998899e-05, 0.0738965864889678, 0.026175443700540924, 0.15205423909024285, 0.07018108820370894, 0.06632390909305708, 0.08495224488071218, 0.06449465292418499, 0.3075521568734839, 0.3063741155163029, 0.04689722871845625, 0.06663968569740863, 0.1809495787193004, 0.0907040919298262, 0.24311920344802007, 0.1823883188788431, 0.026758442389819947, 0.09893975037558755, 0.11005372597709706, 0.09534199086673856, 0.060521173796774796, 0.0703995294946762, 0.06168497185017063, 0.14539258170421376, 0.1802982434895819, 0.029699252956736255, 0.1698175212971209, 0.005830260095274542, 0.14745468698275288, 0.19746480836723157, 0.13446105354378246, 0.09967478792748241, 0.07833505816293529, 0.15269779794482363, 0.45268479444163545, 0.5319119345612638, 0.546626576734907, 0.44126875791280207, 0.5025545013298822, 0.5354592104587445, 0.4196551063736047, 0.5234676250391219, 0.12273692141825632, 0.07191974353402297, 0.09806815146701575, 0.09619567494706405, 0.08422198221706534, 0.12026437801395262, 0.13537823920063152, 0.09340609578952896, 0.09142444199167621, 0.2332702746507429, 0.27241995959464216, 0.1957548035840323, 0.2063349309423005, 0.27817845243066863, 0.21734473888159278, 0.25442152542739516, 0.16249108820503866, 0.22500289137696772, 0.3998986956725248, 0.30535352907680413, 0.3296205363350502, 0.20220610926671656, 0.2827284569439036, 0.25534122868473264, 0.2946655892546183, 0.2970055562039925, 0.3060993849392212, 0.32430560141483367, 0.20055268899183099, 0.2850729091832519, 0.21721890328931526, 0.17306799810176177, 0.2483118134212422, 0.25163493144047167, 0.2653303535771846, 0.2147623614153482, 0.23218211064824745, 0.15889439410157558, 0.23583622616058975, 0.19456643050425226, 0.16374003000060733, 0.21493953091769757, 0.22054221537976426, 0.21551086822309695, 0.2605374343106197, 0.20524551207598984, 0.20017766387611935, 0.1956276943474855, 0.20925170535343018, 0.20529381795845325, 0.18717220284413394, 0.18325239579642294, 0.18124447326753534, 0.19020501902925402, 0.8543511412457057, 0.16287565456475972, 0.15405114384215246, 0.8756578907995182, 0.19787582061465914, 0.20026239673368584, 0.14145544596878845, 0.1694883974512852, 0.8311271772006908, 0.8798375457660473, 0.2064413052170807, 0.15176246019230422, 0.20538455905359443, 0.566551491210618, 0.1550907979706735, 0.18481181998029672, 0.2089649029133862, 0.8021002040064757, 0.20259835816726113, 0.19294522648278056, 0.19996837239533938, 0.1998521869762372, 0.20039126424010079, 0.20393590761470382, 0.20086099584963946, 0.1904815661262652, 0.1857776711713358, 0.09433641993879316, 0.08015685705731035, 0.0939506345761596, 0.07902897205792137, 0.08872475901441956, 0.08341590190181958, 0.10648938366465865, 0.0730508682253449, 0.08920877147497341]}, "mutation_prompt": null}
{"id": "73858d1b-49bc-4fb1-bf35-d4728ecdf41d", "solution": "import numpy as np\n\nclass EnhancedHybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        stagnation_counter = 0\n        max_stagnation = 10\n\n        while evaluations < self.budget:\n            inertia_weight = self.inertia_weight_initial - (\n                (self.inertia_weight_initial - self.inertia_weight_final) * (evaluations / self.budget))\n\n            r1, r2 = np.random.rand(2)\n            velocities = (inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n            positions = np.clip(positions, self.lb, self.ub)\n\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n                stagnation_counter = 0\n            else:\n                stagnation_counter += 1\n\n            if stagnation_counter >= max_stagnation and evaluations + self.swarm_size * 2 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    if np.random.rand() < 0.5:\n                        mutant = x1 + 0.5 * (x2 - x3)\n                    else:\n                        neighbor_idxs = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                        n1, n2, n3 = positions[neighbor_idxs]\n                        mutant = n1 + 0.5 * (n2 - n3)\n                    \n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "EnhancedHybridPSO", "description": "Hybrid Particle Swarm Optimization with dynamic inertia and neighborhood-based mutation to enhance convergence speed.", "configspace": "", "generation": 6, "fitness": 0.21756394362157644, "feedback": "The algorithm EnhancedHybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.23.", "error": "", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.7512595717531052, 0.7148226677609166, 0.7701136383370597, 0.1893586727172747, 0.14096512229731084, 0.7706048550717884, 0.7200201856315829, 0.6985276393729684, 0.8014515006303724, 9.999999999998899e-05, 9.999999999998899e-05, 0.13889535995378777, 9.999999999998899e-05, 0.023595684281004115, 0.024305043706355556, 9.999999999998899e-05, 0.02992020804566986, 9.999999999998899e-05, 0.06565919266013753, 0.10840745756794568, 0.13374415574805754, 0.11538340979085515, 0.10648538384555362, 0.13689213073044526, 0.04513266359760715, 0.09504491798161652, 0.15107143430272862, 0.11399240548065681, 0.05138078729789708, 0.09942724495369004, 0.04394527364885348, 0.06553352009950997, 0.12559293644744773, 0.04709944429621826, 0.05889971374322145, 0.10525665556323716, 0.991669125509421, 0.9923943864778761, 0.9868036875338176, 0.9758525983715616, 0.9887387419505413, 0.9774935222705605, 0.9888423298272992, 0.9890427951000509, 0.9879284033619632, 0.3320360643658622, 0.11310816322517425, 0.5666999466446045, 0.14997604987451973, 0.14755101922724312, 0.17561841922481147, 0.08175420770355668, 0.056902846774870675, 0.20381211121635923, 0.17138167890758182, 0.33558298936516007, 0.2256064000943635, 0.35813865641466636, 0.1487095726710539, 0.19055721122482094, 0.10970451022885808, 0.12254719867547303, 0.8182589577008117, 0.2766095412482825, 0.10567448121329748, 0.12564692582930237, 9.999999999998899e-05, 0.1615744017555213, 0.12531311839341308, 9.999999999998899e-05, 0.12326974195729823, 0.1529338591746915, 0.17083405794776796, 0.16399239122287979, 0.12244118951126604, 0.1483545699630886, 0.13262622661313295, 0.25750687946606665, 0.18522942297041656, 9.999999999998899e-05, 0.1488219180817043, 9.999999999998899e-05, 0.03664423300086583, 0.10382355509811281, 9.999999999998899e-05, 0.0002710732426847162, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016425263383496036, 0.06959177194145671, 0.052036568148912, 0.08026610132965029, 0.11231870269305433, 9.999999999998899e-05, 0.007141287482166803, 0.05781868998651207, 0.05506260515492234, 0.0648960952382307, 9.999999999998899e-05, 0.024447008455335317, 0.12233571097030904, 0.10122267969630705, 0.10544740842148093, 0.060013518291011536, 0.0775302457147824, 0.17766405495328785, 0.29271548739660624, 0.24381760085733428, 9.999999999998899e-05, 0.10478369399179033, 0.006094904184555383, 0.03861115402686632, 0.14920942305713691, 9.999999999998899e-05, 9.999999999998899e-05, 0.08110767362805271, 0.152615167964138, 0.4665065984717286, 0.4965455197842932, 0.20844035056120536, 0.450313841294001, 0.20692543566172295, 0.4973343216551379, 0.13795052840576538, 0.5563176900269462, 0.09497887388139803, 0.11413328910517284, 0.07931152978919032, 0.08674990573598684, 0.08602842991051696, 0.15402210230364877, 0.12455865163032143, 0.08750487368395965, 0.11690627601526793, 0.26621447447859514, 0.15442294546354918, 0.1731503383226638, 0.2404629202634092, 0.33244603628621383, 0.27067536267717074, 0.2936530123893646, 0.2009742854223574, 0.33485307056357383, 0.22492403206017608, 0.16141062673836626, 0.3095576025352653, 0.23737794761466335, 0.2173264195194634, 0.2974748311645926, 0.1882651753490565, 0.24004055171982186, 0.3730669038238823, 0.21849517753281145, 0.08332910898711288, 0.24917279419664495, 0.21078625301041398, 0.20128987778823604, 0.29592771533015627, 0.15029733919652977, 0.302981187204569, 0.2169668350573951, 0.24937841126588045, 0.2217184499627104, 0.20036418740487383, 0.1975049676570736, 0.15565919830875463, 0.20763920937976732, 0.22820926487085913, 0.19925047086477876, 0.23024743819332982, 0.18336481369448043, 0.22637547791333634, 0.18296241675346547, 0.21501154990363813, 0.20805422256023098, 0.1887239022027719, 0.19979983723991734, 0.17419113767757244, 0.19826761430990092, 0.18074232471972596, 0.1262614754955399, 0.15454698520887378, 0.17666185745446106, 0.1975098705521261, 0.19856075601609224, 0.12326277123227591, 0.1705286741449249, 0.847771663863497, 0.7671207720344745, 0.1694054041779136, 0.14764388464697153, 0.10272185667865485, 0.22835108097013868, 0.1546180832726063, 0.1965958537966349, 0.19674564176225262, 0.7966902474055585, 0.17329264943892375, 0.2079411717931524, 0.1964427036947859, 0.19856391130157314, 0.18925613284610976, 0.19016789426168523, 0.20576385498638483, 0.21001605832264159, 0.19042983199386276, 0.08888199617645154, 0.09670660077219817, 0.08772054625180481, 0.09074339984254332, 0.08004309922409614, 0.08407697271586567, 0.10696541616811628, 0.06793080698283427, 0.09029508436415057]}, "mutation_prompt": null}
{"id": "64131ff6-a383-495e-9bfb-b710b61baf6f", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            # Bound positions\n            positions = np.clip(positions, self.lb, self.ub)\n\n            # Evaluate new positions\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            # Update personal bests\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Adaptive Differential Mutation\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.8 * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "HybridPSO", "description": "A hybrid particle swarm optimization with adaptive differential mutation balances exploration and exploitation efficiently.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.7192282850284312, 0.5168340857008723, 0.6846234116845872, 0.7473451340670973, 0.44590167675114, 0.7177523085068118, 0.751962615835188, 0.507453929730844, 0.6799256398352029, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19559599127823335, 0.02970441323486883, 0.11096595841071288, 0.14676657223313583, 0.10592460590777997, 0.04040868601545011, 0.06453080512785092, 0.08424129924959067, 0.14482960703394032, 0.12596087772304088, 0.10466414872067453, 0.09968093505935594, 0.09556840093578844, 0.1266707814832938, 0.15451638446824123, 0.08353935794307521, 0.09175091844091166, 0.11577306851162195, 0.0901782479222828, 0.08787258953535615, 0.0874204157768842, 0.07099005862787766, 0.0780027644954967, 0.1049044090573854, 0.986871927128186, 0.9888577568102923, 0.9841395406604165, 0.9587564242849532, 0.9749992231424514, 0.95341883713273, 0.9841826064614492, 0.9812872409200664, 0.9860836591966228, 0.5576772097784908, 0.2570625877476015, 0.05822140105781859, 0.1474555830900901, 0.1358965199793667, 0.23376341712849802, 0.1228635937753374, 0.2437899312263202, 0.39169357696551454, 0.16981736408600845, 0.5845308937910284, 0.22502806129098518, 0.6809418598131833, 0.17742377480503746, 0.20648207784302997, 0.12119005288043228, 0.5053751653460844, 0.7765840935138728, 0.3657576720147365, 0.125415344465879, 0.2121195213452689, 9.999999999998899e-05, 0.09346470551805053, 0.21811899436558302, 9.999999999998899e-05, 0.08964084229928937, 0.3020101709155415, 0.3443706013363482, 0.27705766684041633, 0.2170004528468722, 0.2954439973962145, 0.1586893109740437, 0.2356379836323167, 0.33045513386723446, 0.0868440127340595, 0.12912077732133076, 0.13901453956648457, 9.999999999998899e-05, 0.14004943949646165, 9.999999999998899e-05, 0.0738965864889678, 0.026175443700540924, 0.15205423909024285, 0.07018108820370894, 0.06632390909305708, 0.08495224488071218, 0.06449465292418499, 0.3075521568734839, 0.3063741155163029, 0.04689722871845625, 0.06663968569740863, 0.1809495787193004, 0.0907040919298262, 0.24311920344802007, 0.1823883188788431, 0.026758442389819947, 0.09893975037558755, 0.11005372597709706, 0.09534199086673856, 0.060521173796774796, 0.0703995294946762, 0.06168497185017063, 0.14539258170421376, 0.1802982434895819, 0.029699252956736255, 0.1698175212971209, 0.005830260095274542, 0.14745468698275288, 0.19746480836723157, 0.13446105354378246, 0.09967478792748241, 0.07833505816293529, 0.15269779794482363, 0.45268479444163545, 0.5319119345612638, 0.546626576734907, 0.44126875791280207, 0.5025545013298822, 0.5354592104587445, 0.4196551063736047, 0.5234676250391219, 0.12273692141825632, 0.07191974353402297, 0.09806815146701575, 0.09619567494706405, 0.08422198221706534, 0.12026437801395262, 0.13537823920063152, 0.09340609578952896, 0.09142444199167621, 0.2332702746507429, 0.27241995959464216, 0.1957548035840323, 0.2063349309423005, 0.27817845243066863, 0.21734473888159278, 0.25442152542739516, 0.16249108820503866, 0.22500289137696772, 0.3998986956725248, 0.30535352907680413, 0.3296205363350502, 0.20220610926671656, 0.2827284569439036, 0.25534122868473264, 0.2946655892546183, 0.2970055562039925, 0.3060993849392212, 0.32430560141483367, 0.20055268899183099, 0.2850729091832519, 0.21721890328931526, 0.17306799810176177, 0.2483118134212422, 0.25163493144047167, 0.2653303535771846, 0.2147623614153482, 0.23218211064824745, 0.15889439410157558, 0.23583622616058975, 0.19456643050425226, 0.16374003000060733, 0.21493953091769757, 0.22054221537976426, 0.21551086822309695, 0.2605374343106197, 0.20524551207598984, 0.20017766387611935, 0.1956276943474855, 0.20925170535343018, 0.20529381795845325, 0.18717220284413394, 0.18325239579642294, 0.18124447326753534, 0.19020501902925402, 0.8543511412457057, 0.16287565456475972, 0.15405114384215246, 0.8756578907995182, 0.19787582061465914, 0.20026239673368584, 0.14145544596878845, 0.1694883974512852, 0.8311271772006908, 0.8798375457660473, 0.2064413052170807, 0.15176246019230422, 0.20538455905359443, 0.566551491210618, 0.1550907979706735, 0.18481181998029672, 0.2089649029133862, 0.8021002040064757, 0.20259835816726113, 0.19294522648278056, 0.19996837239533938, 0.1998521869762372, 0.20039126424010079, 0.20393590761470382, 0.20086099584963946, 0.1904815661262652, 0.1857776711713358, 0.09433641993879316, 0.08015685705731035, 0.0939506345761596, 0.07902897205792137, 0.08872475901441956, 0.08341590190181958, 0.10648938366465865, 0.0730508682253449, 0.08920877147497341]}, "mutation_prompt": null}
{"id": "97635547-d7e3-4853-9b50-9e0f59b8cb6a", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            # Bound positions\n            positions = np.clip(positions, self.lb, self.ub)\n\n            # Evaluate new positions\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            # Update personal bests\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Adaptive Differential Mutation\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.8 * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "HybridPSO", "description": "A hybrid particle swarm optimization with adaptive differential mutation balances exploration and exploitation efficiently.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.7192282850284312, 0.5168340857008723, 0.6846234116845872, 0.7473451340670973, 0.44590167675114, 0.7177523085068118, 0.751962615835188, 0.507453929730844, 0.6799256398352029, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19559599127823335, 0.02970441323486883, 0.11096595841071288, 0.14676657223313583, 0.10592460590777997, 0.04040868601545011, 0.06453080512785092, 0.08424129924959067, 0.14482960703394032, 0.12596087772304088, 0.10466414872067453, 0.09968093505935594, 0.09556840093578844, 0.1266707814832938, 0.15451638446824123, 0.08353935794307521, 0.09175091844091166, 0.11577306851162195, 0.0901782479222828, 0.08787258953535615, 0.0874204157768842, 0.07099005862787766, 0.0780027644954967, 0.1049044090573854, 0.986871927128186, 0.9888577568102923, 0.9841395406604165, 0.9587564242849532, 0.9749992231424514, 0.95341883713273, 0.9841826064614492, 0.9812872409200664, 0.9860836591966228, 0.5576772097784908, 0.2570625877476015, 0.05822140105781859, 0.1474555830900901, 0.1358965199793667, 0.23376341712849802, 0.1228635937753374, 0.2437899312263202, 0.39169357696551454, 0.16981736408600845, 0.5845308937910284, 0.22502806129098518, 0.6809418598131833, 0.17742377480503746, 0.20648207784302997, 0.12119005288043228, 0.5053751653460844, 0.7765840935138728, 0.3657576720147365, 0.125415344465879, 0.2121195213452689, 9.999999999998899e-05, 0.09346470551805053, 0.21811899436558302, 9.999999999998899e-05, 0.08964084229928937, 0.3020101709155415, 0.3443706013363482, 0.27705766684041633, 0.2170004528468722, 0.2954439973962145, 0.1586893109740437, 0.2356379836323167, 0.33045513386723446, 0.0868440127340595, 0.12912077732133076, 0.13901453956648457, 9.999999999998899e-05, 0.14004943949646165, 9.999999999998899e-05, 0.0738965864889678, 0.026175443700540924, 0.15205423909024285, 0.07018108820370894, 0.06632390909305708, 0.08495224488071218, 0.06449465292418499, 0.3075521568734839, 0.3063741155163029, 0.04689722871845625, 0.06663968569740863, 0.1809495787193004, 0.0907040919298262, 0.24311920344802007, 0.1823883188788431, 0.026758442389819947, 0.09893975037558755, 0.11005372597709706, 0.09534199086673856, 0.060521173796774796, 0.0703995294946762, 0.06168497185017063, 0.14539258170421376, 0.1802982434895819, 0.029699252956736255, 0.1698175212971209, 0.005830260095274542, 0.14745468698275288, 0.19746480836723157, 0.13446105354378246, 0.09967478792748241, 0.07833505816293529, 0.15269779794482363, 0.45268479444163545, 0.5319119345612638, 0.546626576734907, 0.44126875791280207, 0.5025545013298822, 0.5354592104587445, 0.4196551063736047, 0.5234676250391219, 0.12273692141825632, 0.07191974353402297, 0.09806815146701575, 0.09619567494706405, 0.08422198221706534, 0.12026437801395262, 0.13537823920063152, 0.09340609578952896, 0.09142444199167621, 0.2332702746507429, 0.27241995959464216, 0.1957548035840323, 0.2063349309423005, 0.27817845243066863, 0.21734473888159278, 0.25442152542739516, 0.16249108820503866, 0.22500289137696772, 0.3998986956725248, 0.30535352907680413, 0.3296205363350502, 0.20220610926671656, 0.2827284569439036, 0.25534122868473264, 0.2946655892546183, 0.2970055562039925, 0.3060993849392212, 0.32430560141483367, 0.20055268899183099, 0.2850729091832519, 0.21721890328931526, 0.17306799810176177, 0.2483118134212422, 0.25163493144047167, 0.2653303535771846, 0.2147623614153482, 0.23218211064824745, 0.15889439410157558, 0.23583622616058975, 0.19456643050425226, 0.16374003000060733, 0.21493953091769757, 0.22054221537976426, 0.21551086822309695, 0.2605374343106197, 0.20524551207598984, 0.20017766387611935, 0.1956276943474855, 0.20925170535343018, 0.20529381795845325, 0.18717220284413394, 0.18325239579642294, 0.18124447326753534, 0.19020501902925402, 0.8543511412457057, 0.16287565456475972, 0.15405114384215246, 0.8756578907995182, 0.19787582061465914, 0.20026239673368584, 0.14145544596878845, 0.1694883974512852, 0.8311271772006908, 0.8798375457660473, 0.2064413052170807, 0.15176246019230422, 0.20538455905359443, 0.566551491210618, 0.1550907979706735, 0.18481181998029672, 0.2089649029133862, 0.8021002040064757, 0.20259835816726113, 0.19294522648278056, 0.19996837239533938, 0.1998521869762372, 0.20039126424010079, 0.20393590761470382, 0.20086099584963946, 0.1904815661262652, 0.1857776711713358, 0.09433641993879316, 0.08015685705731035, 0.0939506345761596, 0.07902897205792137, 0.08872475901441956, 0.08341590190181958, 0.10648938366465865, 0.0730508682253449, 0.08920877147497341]}, "mutation_prompt": null}
{"id": "306f4924-38bc-4255-942d-499a03cce56c", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            # Bound positions\n            positions = np.clip(positions, self.lb, self.ub)\n\n            # Evaluate new positions\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            # Update personal bests\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Adaptive Differential Mutation\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.8 * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "HybridPSO", "description": "A hybrid particle swarm optimization with adaptive differential mutation balances exploration and exploitation efficiently.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.7192282850284312, 0.5168340857008723, 0.6846234116845872, 0.7473451340670973, 0.44590167675114, 0.7177523085068118, 0.751962615835188, 0.507453929730844, 0.6799256398352029, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19559599127823335, 0.02970441323486883, 0.11096595841071288, 0.14676657223313583, 0.10592460590777997, 0.04040868601545011, 0.06453080512785092, 0.08424129924959067, 0.14482960703394032, 0.12596087772304088, 0.10466414872067453, 0.09968093505935594, 0.09556840093578844, 0.1266707814832938, 0.15451638446824123, 0.08353935794307521, 0.09175091844091166, 0.11577306851162195, 0.0901782479222828, 0.08787258953535615, 0.0874204157768842, 0.07099005862787766, 0.0780027644954967, 0.1049044090573854, 0.986871927128186, 0.9888577568102923, 0.9841395406604165, 0.9587564242849532, 0.9749992231424514, 0.95341883713273, 0.9841826064614492, 0.9812872409200664, 0.9860836591966228, 0.5576772097784908, 0.2570625877476015, 0.05822140105781859, 0.1474555830900901, 0.1358965199793667, 0.23376341712849802, 0.1228635937753374, 0.2437899312263202, 0.39169357696551454, 0.16981736408600845, 0.5845308937910284, 0.22502806129098518, 0.6809418598131833, 0.17742377480503746, 0.20648207784302997, 0.12119005288043228, 0.5053751653460844, 0.7765840935138728, 0.3657576720147365, 0.125415344465879, 0.2121195213452689, 9.999999999998899e-05, 0.09346470551805053, 0.21811899436558302, 9.999999999998899e-05, 0.08964084229928937, 0.3020101709155415, 0.3443706013363482, 0.27705766684041633, 0.2170004528468722, 0.2954439973962145, 0.1586893109740437, 0.2356379836323167, 0.33045513386723446, 0.0868440127340595, 0.12912077732133076, 0.13901453956648457, 9.999999999998899e-05, 0.14004943949646165, 9.999999999998899e-05, 0.0738965864889678, 0.026175443700540924, 0.15205423909024285, 0.07018108820370894, 0.06632390909305708, 0.08495224488071218, 0.06449465292418499, 0.3075521568734839, 0.3063741155163029, 0.04689722871845625, 0.06663968569740863, 0.1809495787193004, 0.0907040919298262, 0.24311920344802007, 0.1823883188788431, 0.026758442389819947, 0.09893975037558755, 0.11005372597709706, 0.09534199086673856, 0.060521173796774796, 0.0703995294946762, 0.06168497185017063, 0.14539258170421376, 0.1802982434895819, 0.029699252956736255, 0.1698175212971209, 0.005830260095274542, 0.14745468698275288, 0.19746480836723157, 0.13446105354378246, 0.09967478792748241, 0.07833505816293529, 0.15269779794482363, 0.45268479444163545, 0.5319119345612638, 0.546626576734907, 0.44126875791280207, 0.5025545013298822, 0.5354592104587445, 0.4196551063736047, 0.5234676250391219, 0.12273692141825632, 0.07191974353402297, 0.09806815146701575, 0.09619567494706405, 0.08422198221706534, 0.12026437801395262, 0.13537823920063152, 0.09340609578952896, 0.09142444199167621, 0.2332702746507429, 0.27241995959464216, 0.1957548035840323, 0.2063349309423005, 0.27817845243066863, 0.21734473888159278, 0.25442152542739516, 0.16249108820503866, 0.22500289137696772, 0.3998986956725248, 0.30535352907680413, 0.3296205363350502, 0.20220610926671656, 0.2827284569439036, 0.25534122868473264, 0.2946655892546183, 0.2970055562039925, 0.3060993849392212, 0.32430560141483367, 0.20055268899183099, 0.2850729091832519, 0.21721890328931526, 0.17306799810176177, 0.2483118134212422, 0.25163493144047167, 0.2653303535771846, 0.2147623614153482, 0.23218211064824745, 0.15889439410157558, 0.23583622616058975, 0.19456643050425226, 0.16374003000060733, 0.21493953091769757, 0.22054221537976426, 0.21551086822309695, 0.2605374343106197, 0.20524551207598984, 0.20017766387611935, 0.1956276943474855, 0.20925170535343018, 0.20529381795845325, 0.18717220284413394, 0.18325239579642294, 0.18124447326753534, 0.19020501902925402, 0.8543511412457057, 0.16287565456475972, 0.15405114384215246, 0.8756578907995182, 0.19787582061465914, 0.20026239673368584, 0.14145544596878845, 0.1694883974512852, 0.8311271772006908, 0.8798375457660473, 0.2064413052170807, 0.15176246019230422, 0.20538455905359443, 0.566551491210618, 0.1550907979706735, 0.18481181998029672, 0.2089649029133862, 0.8021002040064757, 0.20259835816726113, 0.19294522648278056, 0.19996837239533938, 0.1998521869762372, 0.20039126424010079, 0.20393590761470382, 0.20086099584963946, 0.1904815661262652, 0.1857776711713358, 0.09433641993879316, 0.08015685705731035, 0.0939506345761596, 0.07902897205792137, 0.08872475901441956, 0.08341590190181958, 0.10648938366465865, 0.0730508682253449, 0.08920877147497341]}, "mutation_prompt": null}
{"id": "cf0b8b56-5728-4b6c-af4e-7f3019581945", "solution": "import numpy as np\n\nclass DualStrategyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.9  # Increased inertia for exploration\n        self.cognitive_weight = 1.4\n        self.social_weight = 1.6\n        self.chaotic_factor = 0.5  # Chaotic factor for dynamic modification\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        chaotic_sequence = np.random.rand(self.swarm_size)\n\n        while evaluations < self.budget:\n            # Update velocities and positions with chaotic map\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions) +\n                          self.chaotic_factor * chaotic_sequence.reshape(-1, 1) * (np.random.rand(self.swarm_size, self.dim) - 0.5))\n            positions += velocities\n\n            # Bound positions\n            positions = np.clip(positions, self.lb, self.ub)\n\n            # Evaluate new positions\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            # Update personal bests\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Crowding mechanism for diversity\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.uniform(-0.1, 0.1, self.dim)\n                candidate = np.clip(candidate, self.lb, self.ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                    if candidate_score < global_best_score:\n                        global_best_position = candidate\n                        global_best_score = candidate_score\n\n        return global_best_position, global_best_score", "name": "DualStrategyPSO", "description": "A dual-strategy PSO combines fast convergence through chaotic maps and enhanced diversity with a crowding mechanism.", "configspace": "", "generation": 10, "fitness": 0.1851857285978882, "feedback": "The algorithm DualStrategyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.20.", "error": "", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.3980164648472736, 0.3750035088489181, 0.33874433419420324, 0.42961212291428397, 0.33515961002138506, 0.34362711851866523, 0.44088033880920463, 0.36116179923252845, 0.37247191093923704, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006725578328518722, 0.00827942540445914, 9.999999999998899e-05, 0.058159961867297216, 0.035931571962469544, 0.06116797993042, 0.09548123104868922, 0.10245427592927936, 0.09659179232217807, 0.06803683557209528, 0.0843517998804797, 0.05079035785580377, 0.09669661340264468, 0.04044973588901357, 0.06498564407758134, 0.08430548518096015, 0.07721325149777347, 0.041086843849982846, 0.05059450290462841, 0.048961069170729954, 0.07194979222251563, 0.9879658969418412, 0.9814763067103525, 0.9861908628424918, 0.960606698306107, 0.9733371984688448, 0.9610203060008308, 0.9821809856008566, 0.9740607677235348, 0.9810916843062755, 0.2634805185553366, 0.1811882166026728, 0.04273731378602419, 0.21393822625551107, 0.15925606720612595, 0.17966373830533033, 0.19922805498245166, 0.16625774828315187, 0.20296808283831247, 0.17153565920497715, 0.23193987004952665, 0.19948560920717184, 0.21273772587931117, 0.28601355697518627, 0.2654772106587666, 0.08803574292495797, 0.18062776126588365, 0.10811485516346042, 0.10777366819489964, 0.14495259918960857, 9.999999999998899e-05, 0.07752895163079632, 0.08223326762733452, 0.0959077174346632, 0.1252735153511998, 0.12819754893967306, 0.15426643115032856, 0.1290612311939412, 0.09858960570422337, 0.0808748530151413, 0.11088329139478814, 0.12444867444866814, 0.140140886541687, 0.14896387752866125, 0.1425272378583835, 0.07662937418816251, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.010750157318380804, 0.0017701758971383486, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.057680396740616424, 0.03439851603150512, 0.04665283911270213, 0.09578638315233767, 0.004085287635274271, 0.020055352338101518, 0.04980245321566468, 0.04794762655572049, 0.03827000345559339, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005944601892831081, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10709365005568106, 0.06119412167664395, 0.06950433564678749, 0.012222347446241844, 0.0322980607033142, 0.0874604589401804, 0.06645814226330948, 0.03343927733413543, 0.05321675700060646, 0.3409849620644465, 0.3367098534982951, 0.37515026821815156, 0.37366209400794304, 0.35668305818740687, 0.3574582477801139, 0.3634231334102913, 0.31803605973417914, 0.3566934937367856, 0.1263919006908516, 0.07980484089683249, 0.0661685136320368, 0.06808879825190362, 0.097515411334266, 0.09956377198783917, 0.07225502482053248, 0.05276780347688359, 0.08338070679371212, 0.15259403836573127, 0.15080585468907415, 0.1564159689945902, 0.22408041446340377, 0.23835733640485057, 0.1394439928418182, 0.16866648184398214, 0.1876722430560348, 0.1959740041962369, 0.24290366053504964, 0.23365929049742873, 0.2472569993711613, 0.2122266515973068, 0.24199007868599054, 0.24467454234209385, 0.1927449670266541, 0.22474957071650892, 0.23132166232593987, 0.17719515037390032, 0.17235717132238948, 0.20035311684630852, 0.18324475897930748, 0.13119155040175978, 0.13552096374629496, 0.17387971700310279, 0.19277216835231048, 0.19394439247983708, 0.20351727341448744, 0.1559902234579995, 0.19726793106686424, 0.19242316324530884, 0.14809792378913167, 0.19392967146572282, 0.20498259727962864, 0.17570444958764564, 0.21327306328095397, 0.17425113799439973, 0.18631451779425656, 0.17190358394804095, 0.18730857961632008, 0.19683846725009002, 0.17453761518812083, 0.2038926464253319, 0.16918061792984773, 0.18625740853069506, 0.5665910787400259, 0.18450057423736166, 0.14756705846802465, 0.5658934207637955, 0.1944588472916946, 0.19484627157047785, 0.14092407548564911, 0.16924268395051345, 0.5228227261457918, 0.5159216409627629, 0.3222192893149478, 0.36102716742939667, 0.49243821214176897, 0.2301244041927929, 0.13892627940783098, 0.2079661687787081, 0.1796623432987633, 0.36808447433525215, 0.1799047175959697, 0.17539491923479322, 0.18063644664711032, 0.20189278868616478, 0.19072842378271893, 0.1750419775080807, 0.19350998660735363, 0.19174106843838756, 0.1803151008940438, 0.07480971734558772, 0.06903142234941895, 0.08035035029619775, 0.05647326841691669, 0.06516493445524085, 0.07390561823903008, 0.06219369504572225, 0.07509641348734308, 0.07821295287839714]}, "mutation_prompt": null}
{"id": "1b64aacb-2d33-49b0-9c99-d854ab4a415a", "solution": "import numpy as np\n\nclass EnhancedHybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.inertia_min = 0.4\n        self.inertia_max = 0.9\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Dynamically adjust inertia weight\n            self.inertia_weight = self.inertia_max - ((self.inertia_max - self.inertia_min) * (evaluations / self.budget))\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            # Bound positions\n            positions = np.clip(positions, self.lb, self.ub)\n\n            # Evaluate new positions\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            # Update personal bests\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Quantum-inspired Mutation\n            if evaluations + self.swarm_size <= self.budget:\n                for i in range(self.swarm_size):\n                    quantum_step = np.random.uniform(self.lb, self.ub, self.dim)\n                    quantum_position = global_best_position + 0.5 * (quantum_step - positions[i])\n                    quantum_position = np.clip(quantum_position, self.lb, self.ub)\n\n                    quantum_score = func(quantum_position)\n                    evaluations += 1\n\n                    if quantum_score < personal_best_scores[i]:\n                        personal_best_positions[i] = quantum_position\n                        personal_best_scores[i] = quantum_score\n\n                        if quantum_score < global_best_score:\n                            global_best_position = quantum_position\n                            global_best_score = quantum_score\n\n        return global_best_position, global_best_score", "name": "EnhancedHybridPSO", "description": "Enhanced HybridPSO with adaptive inertia and quantum-inspired mutation for improved convergence speed.", "configspace": "", "generation": 11, "fitness": 0.22596175963860188, "feedback": "The algorithm EnhancedHybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.22.", "error": "", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.610230701959624, 0.3492088670094541, 0.5817918205992056, 0.6584043888115447, 0.39581566571598703, 0.550753050992186, 0.6237626094547852, 0.3570366971403941, 0.5762083334553261, 0.0373186334788248, 0.00035914163787820197, 0.024898443191007202, 0.0737378641759997, 0.007546774731470807, 0.023822982615056554, 0.03749622371965999, 0.005559453954707583, 0.06308772197134926, 0.10600504849073766, 0.06927874358828212, 0.08682646300605557, 0.12496430476302045, 0.11784664412242252, 0.08227810942316915, 0.13080432952039955, 0.07479587035612134, 0.08393618131731784, 0.06588979880704371, 0.07789639020366901, 0.08780933977974614, 0.08433826449957837, 0.09143929661054695, 0.10737368007429082, 0.11157775932093283, 0.08849031622719938, 0.06950059569706168, 0.9884088453476745, 0.9896007146466292, 0.9860286721911625, 0.9747651039329165, 0.9821645154409907, 0.9719431956033052, 0.987511357766799, 0.9828450336478309, 0.9808650138225489, 0.35500097892762006, 0.193156683353209, 0.21424806895063708, 0.2082333645118427, 0.1802694749659195, 0.2626629068350924, 0.2519042087077119, 0.19956272128603458, 0.2490640914212663, 0.3329824543095796, 0.24120867466853002, 0.2641701196694539, 0.18883635162822388, 0.2192934203410951, 0.3103438651091013, 0.6840027751817954, 0.2106997363041614, 0.21359085509536324, 0.29531681290697, 0.11039474619002942, 0.12834519147018164, 0.11681404938424189, 0.13657391814801445, 0.11892677995550005, 0.16923407427125914, 0.11430491180388491, 0.12188656576258305, 0.1510120662363843, 0.04175052716355532, 0.13669428083429214, 0.19072773522422382, 0.10612695906125413, 0.1550640227039639, 0.1705302529055378, 0.10778586499109455, 0.15293964893980228, 0.006262856806375061, 0.01957946106936903, 0.009136284461892852, 0.022696351812496518, 0.014255900231940566, 0.029394999667645583, 0.04333131624373132, 0.002602255838247247, 0.03782071852428015, 0.1412387661595318, 0.09485662139915108, 0.1666726089388596, 0.1726295619246746, 0.04051340752437138, 0.095765205136497, 0.19966196676755266, 0.10604427181035603, 0.13907130657352496, 0.03384632781276431, 0.00046542006441518957, 0.051351669401327515, 0.08219058219836095, 0.003390672878140877, 0.04083203814200076, 0.05867611659662486, 0.004843757801125892, 0.050280506763543786, 0.09062283846861141, 0.04257562994605868, 0.07499707015434687, 0.07712282291751416, 0.08447113102819825, 0.060151459404160224, 0.06832513560499176, 0.07382936598344714, 0.06967692287674576, 0.5114018278082204, 0.33888155191731695, 0.4076541694338447, 0.4271813094185003, 0.3815116455699663, 0.4229067832807234, 0.5388592475317148, 0.34149643935445206, 0.4089218194400064, 0.12677057667546632, 0.09989213380824657, 0.07812805705709502, 0.10983704329812449, 0.06688271497555598, 0.10749960140365078, 0.08150430503215944, 0.08163111672008594, 0.09006725936731397, 0.1851499455055372, 0.1796953510440613, 0.2365950372865413, 0.2427340946496086, 0.18260958867540733, 0.16976241931767144, 0.29929569196030403, 0.21423456972072552, 0.1947454412108205, 0.3277603286527022, 0.23376511154853608, 0.24881842776551288, 0.3101190641244732, 0.243079657127367, 0.2981851088234594, 0.35022023294301563, 0.22551921592660484, 0.25806467199687433, 0.23364083613888798, 0.18567327135921974, 0.2331315306884043, 0.2140229756797455, 0.18323361862145648, 0.24952754410330413, 0.18377745807635415, 0.1918144513982475, 0.2113074402140649, 0.20785340145453723, 0.19233359750201873, 0.18024146395801544, 0.20475270574228466, 0.16972410936385773, 0.17155656353966275, 0.22194944681559647, 0.16514884453212986, 0.20293817749225662, 0.1770037088033083, 0.17594852489964563, 0.19063174474822886, 0.22318775197620722, 0.1671669041362528, 0.1827916803140447, 0.20089070103147877, 0.16748093077554982, 0.1771282009796672, 0.743921259788926, 0.48506471851260835, 0.1531553704192734, 0.7796388169102377, 0.18594449337166652, 0.1973753731057989, 0.7503072899840522, 0.1682101231868499, 0.6148937186223642, 0.5707375312201843, 0.18917026305778029, 0.5669220963333361, 0.1469897466758332, 0.31451142832697565, 0.14876926763893772, 0.20449893064701152, 0.18312095762399927, 0.5171195382943106, 0.19187513546249058, 0.23234071289759883, 0.18754341996156565, 0.23910210131611398, 0.19361061075801467, 0.1996043303668663, 0.18968030346196585, 0.19809137863303927, 0.17767406000072405, 0.08192549425720352, 0.06922493988746192, 0.08317025884034901, 0.08443812289052599, 0.06846368730325447, 0.06891373444593629, 0.07797362131560093, 0.07246917264463704, 0.08998347808422513]}, "mutation_prompt": null}
{"id": "9cd57cf9-a52c-4e6c-aa52-6f211731e45c", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            # Bound positions\n            positions = np.clip(positions, self.lb, self.ub)\n\n            # Evaluate new positions\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            # Update personal bests\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Adaptive Differential Mutation\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.8 * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "HybridPSO", "description": "A hybrid particle swarm optimization with adaptive differential mutation balances exploration and exploitation efficiently.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.7192282850284312, 0.5168340857008723, 0.6846234116845872, 0.7473451340670973, 0.44590167675114, 0.7177523085068118, 0.751962615835188, 0.507453929730844, 0.6799256398352029, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19559599127823335, 0.02970441323486883, 0.11096595841071288, 0.14676657223313583, 0.10592460590777997, 0.04040868601545011, 0.06453080512785092, 0.08424129924959067, 0.14482960703394032, 0.12596087772304088, 0.10466414872067453, 0.09968093505935594, 0.09556840093578844, 0.1266707814832938, 0.15451638446824123, 0.08353935794307521, 0.09175091844091166, 0.11577306851162195, 0.0901782479222828, 0.08787258953535615, 0.0874204157768842, 0.07099005862787766, 0.0780027644954967, 0.1049044090573854, 0.986871927128186, 0.9888577568102923, 0.9841395406604165, 0.9587564242849532, 0.9749992231424514, 0.95341883713273, 0.9841826064614492, 0.9812872409200664, 0.9860836591966228, 0.5576772097784908, 0.2570625877476015, 0.05822140105781859, 0.1474555830900901, 0.1358965199793667, 0.23376341712849802, 0.1228635937753374, 0.2437899312263202, 0.39169357696551454, 0.16981736408600845, 0.5845308937910284, 0.22502806129098518, 0.6809418598131833, 0.17742377480503746, 0.20648207784302997, 0.12119005288043228, 0.5053751653460844, 0.7765840935138728, 0.3657576720147365, 0.125415344465879, 0.2121195213452689, 9.999999999998899e-05, 0.09346470551805053, 0.21811899436558302, 9.999999999998899e-05, 0.08964084229928937, 0.3020101709155415, 0.3443706013363482, 0.27705766684041633, 0.2170004528468722, 0.2954439973962145, 0.1586893109740437, 0.2356379836323167, 0.33045513386723446, 0.0868440127340595, 0.12912077732133076, 0.13901453956648457, 9.999999999998899e-05, 0.14004943949646165, 9.999999999998899e-05, 0.0738965864889678, 0.026175443700540924, 0.15205423909024285, 0.07018108820370894, 0.06632390909305708, 0.08495224488071218, 0.06449465292418499, 0.3075521568734839, 0.3063741155163029, 0.04689722871845625, 0.06663968569740863, 0.1809495787193004, 0.0907040919298262, 0.24311920344802007, 0.1823883188788431, 0.026758442389819947, 0.09893975037558755, 0.11005372597709706, 0.09534199086673856, 0.060521173796774796, 0.0703995294946762, 0.06168497185017063, 0.14539258170421376, 0.1802982434895819, 0.029699252956736255, 0.1698175212971209, 0.005830260095274542, 0.14745468698275288, 0.19746480836723157, 0.13446105354378246, 0.09967478792748241, 0.07833505816293529, 0.15269779794482363, 0.45268479444163545, 0.5319119345612638, 0.546626576734907, 0.44126875791280207, 0.5025545013298822, 0.5354592104587445, 0.4196551063736047, 0.5234676250391219, 0.12273692141825632, 0.07191974353402297, 0.09806815146701575, 0.09619567494706405, 0.08422198221706534, 0.12026437801395262, 0.13537823920063152, 0.09340609578952896, 0.09142444199167621, 0.2332702746507429, 0.27241995959464216, 0.1957548035840323, 0.2063349309423005, 0.27817845243066863, 0.21734473888159278, 0.25442152542739516, 0.16249108820503866, 0.22500289137696772, 0.3998986956725248, 0.30535352907680413, 0.3296205363350502, 0.20220610926671656, 0.2827284569439036, 0.25534122868473264, 0.2946655892546183, 0.2970055562039925, 0.3060993849392212, 0.32430560141483367, 0.20055268899183099, 0.2850729091832519, 0.21721890328931526, 0.17306799810176177, 0.2483118134212422, 0.25163493144047167, 0.2653303535771846, 0.2147623614153482, 0.23218211064824745, 0.15889439410157558, 0.23583622616058975, 0.19456643050425226, 0.16374003000060733, 0.21493953091769757, 0.22054221537976426, 0.21551086822309695, 0.2605374343106197, 0.20524551207598984, 0.20017766387611935, 0.1956276943474855, 0.20925170535343018, 0.20529381795845325, 0.18717220284413394, 0.18325239579642294, 0.18124447326753534, 0.19020501902925402, 0.8543511412457057, 0.16287565456475972, 0.15405114384215246, 0.8756578907995182, 0.19787582061465914, 0.20026239673368584, 0.14145544596878845, 0.1694883974512852, 0.8311271772006908, 0.8798375457660473, 0.2064413052170807, 0.15176246019230422, 0.20538455905359443, 0.566551491210618, 0.1550907979706735, 0.18481181998029672, 0.2089649029133862, 0.8021002040064757, 0.20259835816726113, 0.19294522648278056, 0.19996837239533938, 0.1998521869762372, 0.20039126424010079, 0.20393590761470382, 0.20086099584963946, 0.1904815661262652, 0.1857776711713358, 0.09433641993879316, 0.08015685705731035, 0.0939506345761596, 0.07902897205792137, 0.08872475901441956, 0.08341590190181958, 0.10648938366465865, 0.0730508682253449, 0.08920877147497341]}, "mutation_prompt": null}
{"id": "62383250-7c22-4b59-81d2-5070003c19c6", "solution": "import numpy as np\n\nclass EnhancedHybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n        self.inertia_damping = 0.99\n        self.chaotic_value = np.random.rand()\n\n    def chaotic_map(self):\n        # Using a simple logistic map for chaos\n        self.chaotic_value = 4 * self.chaotic_value * (1 - self.chaotic_value)\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.chaotic_map()\n            self.inertia_weight *= self.inertia_damping\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * self.chaotic_value * (global_best_position - positions))\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    F = 0.5 + 0.5 * self.chaotic_value\n                    mutant = x1 + F * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "EnhancedHybridPSO", "description": "Enhanced HybridPSO using chaotic maps for parameter adaptation to improve convergence speed.", "configspace": "", "generation": 13, "fitness": 0.2380653411809835, "feedback": "The algorithm EnhancedHybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.24.", "error": "", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.6477672108233398, 0.6447787559687359, 0.6754161569666559, 0.6794314062508453, 0.6380389972170206, 0.18778127031369118, 0.6789648047485921, 0.6679837505685244, 0.6907833433201889, 0.056229023361284325, 9.999999999998899e-05, 0.038185675678256814, 0.032070521872254676, 9.999999999998899e-05, 0.02501018698055779, 0.2199071047467802, 9.999999999998899e-05, 0.011520050376470858, 0.09779286133430998, 0.1336871305904559, 0.10934761137847926, 0.07047028274769895, 0.0865973944154883, 0.06564886870805409, 0.0499280165030801, 0.10668617206096354, 0.12359817124419603, 0.11349975851576488, 0.04303630618600418, 0.09287873686275472, 0.0772614765219698, 0.09613693632606246, 0.0976508966596562, 0.09824801859174481, 0.015052977012677493, 0.08211659203220456, 0.9644077004260141, 0.9460740040790596, 0.9886520676139655, 0.9606000231409924, 0.9682905551925565, 0.9894539253907717, 0.9935188010457442, 0.9960468144098057, 0.9726573801546102, 0.42283397771732845, 0.061214088859238514, 0.03463372612433502, 0.1383892486062085, 0.012401122787701002, 0.4143243529093553, 0.517226887430906, 0.08788165428970263, 0.08214213498961676, 0.6269473755344618, 0.7123754020629214, 0.22239336087741435, 0.6487628993425077, 0.16082017191177933, 0.11598474646326462, 0.6889478238240405, 0.12417414304899377, 0.13628515059296364, 0.08154526817970587, 0.20744928494755677, 0.4840627876364899, 0.1154589811950697, 0.11053876613924152, 0.09105965951029671, 0.11703861566363849, 0.10756155998320538, 0.14689279594323057, 0.05114796856528614, 0.14348443556547097, 0.38794665457864175, 0.12295206361837041, 0.3896589874428541, 0.13687752437037448, 0.2822948556666621, 0.12902008073512627, 0.1770659715893187, 9.999999999998899e-05, 9.999999999998899e-05, 0.20421725287961978, 9.999999999998899e-05, 9.999999999998899e-05, 0.0022296500981948686, 0.002659360488009188, 9.999999999998899e-05, 0.05161574468007679, 0.0794076551948607, 0.0784128098228073, 0.05163836166694491, 0.0750584306527664, 0.0794360374698676, 0.09784292018598661, 0.14890977736159006, 0.05726618597487654, 0.027758968786196436, 9.999999999998899e-05, 0.03578527849898405, 9.999999999998899e-05, 0.04733106870246828, 0.11729660730242719, 9.999999999998899e-05, 0.08843221814191893, 0.048526293554681965, 0.051921085989981464, 0.1433492028538409, 0.12107466687581558, 0.11784766565072224, 0.21079129886747516, 0.18287524551158618, 0.03614382131710059, 0.1093237738830416, 0.1622017091383725, 0.047656181357675687, 0.5628854496326965, 0.5466833866208813, 0.5225441454502723, 0.5830952400271527, 0.5793445536608322, 0.518991704354296, 0.5288591934968669, 0.5251558447251267, 0.5171600373073504, 0.14527546430468397, 0.0512119601914528, 0.07884626087343383, 0.11923560756518814, 0.084395065399815, 0.10828956922217081, 0.10599062170332363, 0.06652900001689199, 0.08085590327642678, 0.1999593875470428, 0.1878482016524058, 0.23532509476758345, 0.1881170060047932, 0.14273651119276642, 0.27253541112116286, 0.25571569676803163, 0.358360997241007, 0.19891154462242522, 0.27870552147629823, 0.22716338632800825, 0.16641679558029177, 0.30705070037306115, 0.21587926085590592, 0.2678691880035994, 0.2966566961627525, 0.2597858924538222, 0.35679181229497337, 0.1548061451277053, 0.221676380446446, 0.2201415935410963, 0.1795664604001992, 0.18562723898558509, 0.18134314432638954, 0.22778139038902, 0.2588129131077639, 0.24461306621610268, 0.2001065249024807, 0.2149423964388426, 0.18721935217590824, 0.2035482215056743, 0.20902885204611432, 0.18499077193157543, 0.19176231355789242, 0.1616358476946731, 0.22351374598961538, 0.19943229352842673, 0.2035449500804969, 0.5029075184538732, 0.18311733849878442, 0.19262107406156337, 0.22549036599385874, 0.17924447426109857, 0.18515268983744126, 0.20783423223759223, 0.08834732318730132, 0.26108508659870777, 0.16949828126123323, 0.1634400331281458, 0.7783667695027477, 0.13464431003141786, 0.15518577468235073, 0.1745724594907666, 0.1690547162278997, 0.6882415117731289, 0.1752346494167334, 0.20909698246137898, 0.7187398808781476, 0.16180136894867903, 0.6141961336267636, 0.19431229214446566, 0.6902049664888936, 0.18426412834585015, 0.18117809712952526, 0.20745018534771165, 0.18789567425006493, 0.17780775029650153, 0.20913036952078567, 0.19508148311517393, 0.21733317442335565, 0.19338600468624645, 0.20352512045355475, 0.0728883262641099, 0.08643094203507484, 0.08606819637379559, 0.1190656706056441, 0.11863330869062227, 0.07930759924606412, 0.11394167585618709, 0.0876008645686085, 0.08235163607432716]}, "mutation_prompt": null}
{"id": "56e42608-7b4d-44ce-ac22-e1ffba5c9e18", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            # Bound positions\n            positions = np.clip(positions, self.lb, self.ub)\n\n            # Evaluate new positions\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            # Update personal bests\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Adaptive Differential Mutation\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.8 * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "HybridPSO", "description": "A hybrid particle swarm optimization with adaptive differential mutation balances exploration and exploitation efficiently.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.7192282850284312, 0.5168340857008723, 0.6846234116845872, 0.7473451340670973, 0.44590167675114, 0.7177523085068118, 0.751962615835188, 0.507453929730844, 0.6799256398352029, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19559599127823335, 0.02970441323486883, 0.11096595841071288, 0.14676657223313583, 0.10592460590777997, 0.04040868601545011, 0.06453080512785092, 0.08424129924959067, 0.14482960703394032, 0.12596087772304088, 0.10466414872067453, 0.09968093505935594, 0.09556840093578844, 0.1266707814832938, 0.15451638446824123, 0.08353935794307521, 0.09175091844091166, 0.11577306851162195, 0.0901782479222828, 0.08787258953535615, 0.0874204157768842, 0.07099005862787766, 0.0780027644954967, 0.1049044090573854, 0.986871927128186, 0.9888577568102923, 0.9841395406604165, 0.9587564242849532, 0.9749992231424514, 0.95341883713273, 0.9841826064614492, 0.9812872409200664, 0.9860836591966228, 0.5576772097784908, 0.2570625877476015, 0.05822140105781859, 0.1474555830900901, 0.1358965199793667, 0.23376341712849802, 0.1228635937753374, 0.2437899312263202, 0.39169357696551454, 0.16981736408600845, 0.5845308937910284, 0.22502806129098518, 0.6809418598131833, 0.17742377480503746, 0.20648207784302997, 0.12119005288043228, 0.5053751653460844, 0.7765840935138728, 0.3657576720147365, 0.125415344465879, 0.2121195213452689, 9.999999999998899e-05, 0.09346470551805053, 0.21811899436558302, 9.999999999998899e-05, 0.08964084229928937, 0.3020101709155415, 0.3443706013363482, 0.27705766684041633, 0.2170004528468722, 0.2954439973962145, 0.1586893109740437, 0.2356379836323167, 0.33045513386723446, 0.0868440127340595, 0.12912077732133076, 0.13901453956648457, 9.999999999998899e-05, 0.14004943949646165, 9.999999999998899e-05, 0.0738965864889678, 0.026175443700540924, 0.15205423909024285, 0.07018108820370894, 0.06632390909305708, 0.08495224488071218, 0.06449465292418499, 0.3075521568734839, 0.3063741155163029, 0.04689722871845625, 0.06663968569740863, 0.1809495787193004, 0.0907040919298262, 0.24311920344802007, 0.1823883188788431, 0.026758442389819947, 0.09893975037558755, 0.11005372597709706, 0.09534199086673856, 0.060521173796774796, 0.0703995294946762, 0.06168497185017063, 0.14539258170421376, 0.1802982434895819, 0.029699252956736255, 0.1698175212971209, 0.005830260095274542, 0.14745468698275288, 0.19746480836723157, 0.13446105354378246, 0.09967478792748241, 0.07833505816293529, 0.15269779794482363, 0.45268479444163545, 0.5319119345612638, 0.546626576734907, 0.44126875791280207, 0.5025545013298822, 0.5354592104587445, 0.4196551063736047, 0.5234676250391219, 0.12273692141825632, 0.07191974353402297, 0.09806815146701575, 0.09619567494706405, 0.08422198221706534, 0.12026437801395262, 0.13537823920063152, 0.09340609578952896, 0.09142444199167621, 0.2332702746507429, 0.27241995959464216, 0.1957548035840323, 0.2063349309423005, 0.27817845243066863, 0.21734473888159278, 0.25442152542739516, 0.16249108820503866, 0.22500289137696772, 0.3998986956725248, 0.30535352907680413, 0.3296205363350502, 0.20220610926671656, 0.2827284569439036, 0.25534122868473264, 0.2946655892546183, 0.2970055562039925, 0.3060993849392212, 0.32430560141483367, 0.20055268899183099, 0.2850729091832519, 0.21721890328931526, 0.17306799810176177, 0.2483118134212422, 0.25163493144047167, 0.2653303535771846, 0.2147623614153482, 0.23218211064824745, 0.15889439410157558, 0.23583622616058975, 0.19456643050425226, 0.16374003000060733, 0.21493953091769757, 0.22054221537976426, 0.21551086822309695, 0.2605374343106197, 0.20524551207598984, 0.20017766387611935, 0.1956276943474855, 0.20925170535343018, 0.20529381795845325, 0.18717220284413394, 0.18325239579642294, 0.18124447326753534, 0.19020501902925402, 0.8543511412457057, 0.16287565456475972, 0.15405114384215246, 0.8756578907995182, 0.19787582061465914, 0.20026239673368584, 0.14145544596878845, 0.1694883974512852, 0.8311271772006908, 0.8798375457660473, 0.2064413052170807, 0.15176246019230422, 0.20538455905359443, 0.566551491210618, 0.1550907979706735, 0.18481181998029672, 0.2089649029133862, 0.8021002040064757, 0.20259835816726113, 0.19294522648278056, 0.19996837239533938, 0.1998521869762372, 0.20039126424010079, 0.20393590761470382, 0.20086099584963946, 0.1904815661262652, 0.1857776711713358, 0.09433641993879316, 0.08015685705731035, 0.0939506345761596, 0.07902897205792137, 0.08872475901441956, 0.08341590190181958, 0.10648938366465865, 0.0730508682253449, 0.08920877147497341]}, "mutation_prompt": null}
{"id": "10509165-3ffc-4732-9fa4-de2cd4343fa7", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            # Bound positions\n            positions = np.clip(positions, self.lb, self.ub)\n\n            # Evaluate new positions\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            # Update personal bests\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Adaptive Differential Mutation\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.8 * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "HybridPSO", "description": "A hybrid particle swarm optimization with adaptive differential mutation balances exploration and exploitation efficiently.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.7192282850284312, 0.5168340857008723, 0.6846234116845872, 0.7473451340670973, 0.44590167675114, 0.7177523085068118, 0.751962615835188, 0.507453929730844, 0.6799256398352029, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19559599127823335, 0.02970441323486883, 0.11096595841071288, 0.14676657223313583, 0.10592460590777997, 0.04040868601545011, 0.06453080512785092, 0.08424129924959067, 0.14482960703394032, 0.12596087772304088, 0.10466414872067453, 0.09968093505935594, 0.09556840093578844, 0.1266707814832938, 0.15451638446824123, 0.08353935794307521, 0.09175091844091166, 0.11577306851162195, 0.0901782479222828, 0.08787258953535615, 0.0874204157768842, 0.07099005862787766, 0.0780027644954967, 0.1049044090573854, 0.986871927128186, 0.9888577568102923, 0.9841395406604165, 0.9587564242849532, 0.9749992231424514, 0.95341883713273, 0.9841826064614492, 0.9812872409200664, 0.9860836591966228, 0.5576772097784908, 0.2570625877476015, 0.05822140105781859, 0.1474555830900901, 0.1358965199793667, 0.23376341712849802, 0.1228635937753374, 0.2437899312263202, 0.39169357696551454, 0.16981736408600845, 0.5845308937910284, 0.22502806129098518, 0.6809418598131833, 0.17742377480503746, 0.20648207784302997, 0.12119005288043228, 0.5053751653460844, 0.7765840935138728, 0.3657576720147365, 0.125415344465879, 0.2121195213452689, 9.999999999998899e-05, 0.09346470551805053, 0.21811899436558302, 9.999999999998899e-05, 0.08964084229928937, 0.3020101709155415, 0.3443706013363482, 0.27705766684041633, 0.2170004528468722, 0.2954439973962145, 0.1586893109740437, 0.2356379836323167, 0.33045513386723446, 0.0868440127340595, 0.12912077732133076, 0.13901453956648457, 9.999999999998899e-05, 0.14004943949646165, 9.999999999998899e-05, 0.0738965864889678, 0.026175443700540924, 0.15205423909024285, 0.07018108820370894, 0.06632390909305708, 0.08495224488071218, 0.06449465292418499, 0.3075521568734839, 0.3063741155163029, 0.04689722871845625, 0.06663968569740863, 0.1809495787193004, 0.0907040919298262, 0.24311920344802007, 0.1823883188788431, 0.026758442389819947, 0.09893975037558755, 0.11005372597709706, 0.09534199086673856, 0.060521173796774796, 0.0703995294946762, 0.06168497185017063, 0.14539258170421376, 0.1802982434895819, 0.029699252956736255, 0.1698175212971209, 0.005830260095274542, 0.14745468698275288, 0.19746480836723157, 0.13446105354378246, 0.09967478792748241, 0.07833505816293529, 0.15269779794482363, 0.45268479444163545, 0.5319119345612638, 0.546626576734907, 0.44126875791280207, 0.5025545013298822, 0.5354592104587445, 0.4196551063736047, 0.5234676250391219, 0.12273692141825632, 0.07191974353402297, 0.09806815146701575, 0.09619567494706405, 0.08422198221706534, 0.12026437801395262, 0.13537823920063152, 0.09340609578952896, 0.09142444199167621, 0.2332702746507429, 0.27241995959464216, 0.1957548035840323, 0.2063349309423005, 0.27817845243066863, 0.21734473888159278, 0.25442152542739516, 0.16249108820503866, 0.22500289137696772, 0.3998986956725248, 0.30535352907680413, 0.3296205363350502, 0.20220610926671656, 0.2827284569439036, 0.25534122868473264, 0.2946655892546183, 0.2970055562039925, 0.3060993849392212, 0.32430560141483367, 0.20055268899183099, 0.2850729091832519, 0.21721890328931526, 0.17306799810176177, 0.2483118134212422, 0.25163493144047167, 0.2653303535771846, 0.2147623614153482, 0.23218211064824745, 0.15889439410157558, 0.23583622616058975, 0.19456643050425226, 0.16374003000060733, 0.21493953091769757, 0.22054221537976426, 0.21551086822309695, 0.2605374343106197, 0.20524551207598984, 0.20017766387611935, 0.1956276943474855, 0.20925170535343018, 0.20529381795845325, 0.18717220284413394, 0.18325239579642294, 0.18124447326753534, 0.19020501902925402, 0.8543511412457057, 0.16287565456475972, 0.15405114384215246, 0.8756578907995182, 0.19787582061465914, 0.20026239673368584, 0.14145544596878845, 0.1694883974512852, 0.8311271772006908, 0.8798375457660473, 0.2064413052170807, 0.15176246019230422, 0.20538455905359443, 0.566551491210618, 0.1550907979706735, 0.18481181998029672, 0.2089649029133862, 0.8021002040064757, 0.20259835816726113, 0.19294522648278056, 0.19996837239533938, 0.1998521869762372, 0.20039126424010079, 0.20393590761470382, 0.20086099584963946, 0.1904815661262652, 0.1857776711713358, 0.09433641993879316, 0.08015685705731035, 0.0939506345761596, 0.07902897205792137, 0.08872475901441956, 0.08341590190181958, 0.10648938366465865, 0.0730508682253449, 0.08920877147497341]}, "mutation_prompt": null}
{"id": "9723076e-ac46-424d-b780-102834f6f9fa", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            # Bound positions\n            positions = np.clip(positions, self.lb, self.ub)\n\n            # Evaluate new positions\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            # Update personal bests\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Adaptive Differential Mutation\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.8 * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "HybridPSO", "description": "A hybrid particle swarm optimization with adaptive differential mutation balances exploration and exploitation efficiently.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.7192282850284312, 0.5168340857008723, 0.6846234116845872, 0.7473451340670973, 0.44590167675114, 0.7177523085068118, 0.751962615835188, 0.507453929730844, 0.6799256398352029, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19559599127823335, 0.02970441323486883, 0.11096595841071288, 0.14676657223313583, 0.10592460590777997, 0.04040868601545011, 0.06453080512785092, 0.08424129924959067, 0.14482960703394032, 0.12596087772304088, 0.10466414872067453, 0.09968093505935594, 0.09556840093578844, 0.1266707814832938, 0.15451638446824123, 0.08353935794307521, 0.09175091844091166, 0.11577306851162195, 0.0901782479222828, 0.08787258953535615, 0.0874204157768842, 0.07099005862787766, 0.0780027644954967, 0.1049044090573854, 0.986871927128186, 0.9888577568102923, 0.9841395406604165, 0.9587564242849532, 0.9749992231424514, 0.95341883713273, 0.9841826064614492, 0.9812872409200664, 0.9860836591966228, 0.5576772097784908, 0.2570625877476015, 0.05822140105781859, 0.1474555830900901, 0.1358965199793667, 0.23376341712849802, 0.1228635937753374, 0.2437899312263202, 0.39169357696551454, 0.16981736408600845, 0.5845308937910284, 0.22502806129098518, 0.6809418598131833, 0.17742377480503746, 0.20648207784302997, 0.12119005288043228, 0.5053751653460844, 0.7765840935138728, 0.3657576720147365, 0.125415344465879, 0.2121195213452689, 9.999999999998899e-05, 0.09346470551805053, 0.21811899436558302, 9.999999999998899e-05, 0.08964084229928937, 0.3020101709155415, 0.3443706013363482, 0.27705766684041633, 0.2170004528468722, 0.2954439973962145, 0.1586893109740437, 0.2356379836323167, 0.33045513386723446, 0.0868440127340595, 0.12912077732133076, 0.13901453956648457, 9.999999999998899e-05, 0.14004943949646165, 9.999999999998899e-05, 0.0738965864889678, 0.026175443700540924, 0.15205423909024285, 0.07018108820370894, 0.06632390909305708, 0.08495224488071218, 0.06449465292418499, 0.3075521568734839, 0.3063741155163029, 0.04689722871845625, 0.06663968569740863, 0.1809495787193004, 0.0907040919298262, 0.24311920344802007, 0.1823883188788431, 0.026758442389819947, 0.09893975037558755, 0.11005372597709706, 0.09534199086673856, 0.060521173796774796, 0.0703995294946762, 0.06168497185017063, 0.14539258170421376, 0.1802982434895819, 0.029699252956736255, 0.1698175212971209, 0.005830260095274542, 0.14745468698275288, 0.19746480836723157, 0.13446105354378246, 0.09967478792748241, 0.07833505816293529, 0.15269779794482363, 0.45268479444163545, 0.5319119345612638, 0.546626576734907, 0.44126875791280207, 0.5025545013298822, 0.5354592104587445, 0.4196551063736047, 0.5234676250391219, 0.12273692141825632, 0.07191974353402297, 0.09806815146701575, 0.09619567494706405, 0.08422198221706534, 0.12026437801395262, 0.13537823920063152, 0.09340609578952896, 0.09142444199167621, 0.2332702746507429, 0.27241995959464216, 0.1957548035840323, 0.2063349309423005, 0.27817845243066863, 0.21734473888159278, 0.25442152542739516, 0.16249108820503866, 0.22500289137696772, 0.3998986956725248, 0.30535352907680413, 0.3296205363350502, 0.20220610926671656, 0.2827284569439036, 0.25534122868473264, 0.2946655892546183, 0.2970055562039925, 0.3060993849392212, 0.32430560141483367, 0.20055268899183099, 0.2850729091832519, 0.21721890328931526, 0.17306799810176177, 0.2483118134212422, 0.25163493144047167, 0.2653303535771846, 0.2147623614153482, 0.23218211064824745, 0.15889439410157558, 0.23583622616058975, 0.19456643050425226, 0.16374003000060733, 0.21493953091769757, 0.22054221537976426, 0.21551086822309695, 0.2605374343106197, 0.20524551207598984, 0.20017766387611935, 0.1956276943474855, 0.20925170535343018, 0.20529381795845325, 0.18717220284413394, 0.18325239579642294, 0.18124447326753534, 0.19020501902925402, 0.8543511412457057, 0.16287565456475972, 0.15405114384215246, 0.8756578907995182, 0.19787582061465914, 0.20026239673368584, 0.14145544596878845, 0.1694883974512852, 0.8311271772006908, 0.8798375457660473, 0.2064413052170807, 0.15176246019230422, 0.20538455905359443, 0.566551491210618, 0.1550907979706735, 0.18481181998029672, 0.2089649029133862, 0.8021002040064757, 0.20259835816726113, 0.19294522648278056, 0.19996837239533938, 0.1998521869762372, 0.20039126424010079, 0.20393590761470382, 0.20086099584963946, 0.1904815661262652, 0.1857776711713358, 0.09433641993879316, 0.08015685705731035, 0.0939506345761596, 0.07902897205792137, 0.08872475901441956, 0.08341590190181958, 0.10648938366465865, 0.0730508682253449, 0.08920877147497341]}, "mutation_prompt": null}
{"id": "84a7c6e5-3fe3-4b11-af5c-7e04207a4c48", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            # Bound positions\n            positions = np.clip(positions, self.lb, self.ub)\n\n            # Evaluate new positions\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            # Update personal bests\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Adaptive Differential Mutation\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.8 * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "HybridPSO", "description": "A hybrid particle swarm optimization with adaptive differential mutation balances exploration and exploitation efficiently.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.7192282850284312, 0.5168340857008723, 0.6846234116845872, 0.7473451340670973, 0.44590167675114, 0.7177523085068118, 0.751962615835188, 0.507453929730844, 0.6799256398352029, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19559599127823335, 0.02970441323486883, 0.11096595841071288, 0.14676657223313583, 0.10592460590777997, 0.04040868601545011, 0.06453080512785092, 0.08424129924959067, 0.14482960703394032, 0.12596087772304088, 0.10466414872067453, 0.09968093505935594, 0.09556840093578844, 0.1266707814832938, 0.15451638446824123, 0.08353935794307521, 0.09175091844091166, 0.11577306851162195, 0.0901782479222828, 0.08787258953535615, 0.0874204157768842, 0.07099005862787766, 0.0780027644954967, 0.1049044090573854, 0.986871927128186, 0.9888577568102923, 0.9841395406604165, 0.9587564242849532, 0.9749992231424514, 0.95341883713273, 0.9841826064614492, 0.9812872409200664, 0.9860836591966228, 0.5576772097784908, 0.2570625877476015, 0.05822140105781859, 0.1474555830900901, 0.1358965199793667, 0.23376341712849802, 0.1228635937753374, 0.2437899312263202, 0.39169357696551454, 0.16981736408600845, 0.5845308937910284, 0.22502806129098518, 0.6809418598131833, 0.17742377480503746, 0.20648207784302997, 0.12119005288043228, 0.5053751653460844, 0.7765840935138728, 0.3657576720147365, 0.125415344465879, 0.2121195213452689, 9.999999999998899e-05, 0.09346470551805053, 0.21811899436558302, 9.999999999998899e-05, 0.08964084229928937, 0.3020101709155415, 0.3443706013363482, 0.27705766684041633, 0.2170004528468722, 0.2954439973962145, 0.1586893109740437, 0.2356379836323167, 0.33045513386723446, 0.0868440127340595, 0.12912077732133076, 0.13901453956648457, 9.999999999998899e-05, 0.14004943949646165, 9.999999999998899e-05, 0.0738965864889678, 0.026175443700540924, 0.15205423909024285, 0.07018108820370894, 0.06632390909305708, 0.08495224488071218, 0.06449465292418499, 0.3075521568734839, 0.3063741155163029, 0.04689722871845625, 0.06663968569740863, 0.1809495787193004, 0.0907040919298262, 0.24311920344802007, 0.1823883188788431, 0.026758442389819947, 0.09893975037558755, 0.11005372597709706, 0.09534199086673856, 0.060521173796774796, 0.0703995294946762, 0.06168497185017063, 0.14539258170421376, 0.1802982434895819, 0.029699252956736255, 0.1698175212971209, 0.005830260095274542, 0.14745468698275288, 0.19746480836723157, 0.13446105354378246, 0.09967478792748241, 0.07833505816293529, 0.15269779794482363, 0.45268479444163545, 0.5319119345612638, 0.546626576734907, 0.44126875791280207, 0.5025545013298822, 0.5354592104587445, 0.4196551063736047, 0.5234676250391219, 0.12273692141825632, 0.07191974353402297, 0.09806815146701575, 0.09619567494706405, 0.08422198221706534, 0.12026437801395262, 0.13537823920063152, 0.09340609578952896, 0.09142444199167621, 0.2332702746507429, 0.27241995959464216, 0.1957548035840323, 0.2063349309423005, 0.27817845243066863, 0.21734473888159278, 0.25442152542739516, 0.16249108820503866, 0.22500289137696772, 0.3998986956725248, 0.30535352907680413, 0.3296205363350502, 0.20220610926671656, 0.2827284569439036, 0.25534122868473264, 0.2946655892546183, 0.2970055562039925, 0.3060993849392212, 0.32430560141483367, 0.20055268899183099, 0.2850729091832519, 0.21721890328931526, 0.17306799810176177, 0.2483118134212422, 0.25163493144047167, 0.2653303535771846, 0.2147623614153482, 0.23218211064824745, 0.15889439410157558, 0.23583622616058975, 0.19456643050425226, 0.16374003000060733, 0.21493953091769757, 0.22054221537976426, 0.21551086822309695, 0.2605374343106197, 0.20524551207598984, 0.20017766387611935, 0.1956276943474855, 0.20925170535343018, 0.20529381795845325, 0.18717220284413394, 0.18325239579642294, 0.18124447326753534, 0.19020501902925402, 0.8543511412457057, 0.16287565456475972, 0.15405114384215246, 0.8756578907995182, 0.19787582061465914, 0.20026239673368584, 0.14145544596878845, 0.1694883974512852, 0.8311271772006908, 0.8798375457660473, 0.2064413052170807, 0.15176246019230422, 0.20538455905359443, 0.566551491210618, 0.1550907979706735, 0.18481181998029672, 0.2089649029133862, 0.8021002040064757, 0.20259835816726113, 0.19294522648278056, 0.19996837239533938, 0.1998521869762372, 0.20039126424010079, 0.20393590761470382, 0.20086099584963946, 0.1904815661262652, 0.1857776711713358, 0.09433641993879316, 0.08015685705731035, 0.0939506345761596, 0.07902897205792137, 0.08872475901441956, 0.08341590190181958, 0.10648938366465865, 0.0730508682253449, 0.08920877147497341]}, "mutation_prompt": null}
{"id": "73c9eaa6-fc6e-477b-847c-2d8a5c983797", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            # Bound positions\n            positions = np.clip(positions, self.lb, self.ub)\n\n            # Evaluate new positions\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            # Update personal bests\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Adaptive Differential Mutation\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.8 * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "HybridPSO", "description": "A hybrid particle swarm optimization with adaptive differential mutation balances exploration and exploitation efficiently.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.7192282850284312, 0.5168340857008723, 0.6846234116845872, 0.7473451340670973, 0.44590167675114, 0.7177523085068118, 0.751962615835188, 0.507453929730844, 0.6799256398352029, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19559599127823335, 0.02970441323486883, 0.11096595841071288, 0.14676657223313583, 0.10592460590777997, 0.04040868601545011, 0.06453080512785092, 0.08424129924959067, 0.14482960703394032, 0.12596087772304088, 0.10466414872067453, 0.09968093505935594, 0.09556840093578844, 0.1266707814832938, 0.15451638446824123, 0.08353935794307521, 0.09175091844091166, 0.11577306851162195, 0.0901782479222828, 0.08787258953535615, 0.0874204157768842, 0.07099005862787766, 0.0780027644954967, 0.1049044090573854, 0.986871927128186, 0.9888577568102923, 0.9841395406604165, 0.9587564242849532, 0.9749992231424514, 0.95341883713273, 0.9841826064614492, 0.9812872409200664, 0.9860836591966228, 0.5576772097784908, 0.2570625877476015, 0.05822140105781859, 0.1474555830900901, 0.1358965199793667, 0.23376341712849802, 0.1228635937753374, 0.2437899312263202, 0.39169357696551454, 0.16981736408600845, 0.5845308937910284, 0.22502806129098518, 0.6809418598131833, 0.17742377480503746, 0.20648207784302997, 0.12119005288043228, 0.5053751653460844, 0.7765840935138728, 0.3657576720147365, 0.125415344465879, 0.2121195213452689, 9.999999999998899e-05, 0.09346470551805053, 0.21811899436558302, 9.999999999998899e-05, 0.08964084229928937, 0.3020101709155415, 0.3443706013363482, 0.27705766684041633, 0.2170004528468722, 0.2954439973962145, 0.1586893109740437, 0.2356379836323167, 0.33045513386723446, 0.0868440127340595, 0.12912077732133076, 0.13901453956648457, 9.999999999998899e-05, 0.14004943949646165, 9.999999999998899e-05, 0.0738965864889678, 0.026175443700540924, 0.15205423909024285, 0.07018108820370894, 0.06632390909305708, 0.08495224488071218, 0.06449465292418499, 0.3075521568734839, 0.3063741155163029, 0.04689722871845625, 0.06663968569740863, 0.1809495787193004, 0.0907040919298262, 0.24311920344802007, 0.1823883188788431, 0.026758442389819947, 0.09893975037558755, 0.11005372597709706, 0.09534199086673856, 0.060521173796774796, 0.0703995294946762, 0.06168497185017063, 0.14539258170421376, 0.1802982434895819, 0.029699252956736255, 0.1698175212971209, 0.005830260095274542, 0.14745468698275288, 0.19746480836723157, 0.13446105354378246, 0.09967478792748241, 0.07833505816293529, 0.15269779794482363, 0.45268479444163545, 0.5319119345612638, 0.546626576734907, 0.44126875791280207, 0.5025545013298822, 0.5354592104587445, 0.4196551063736047, 0.5234676250391219, 0.12273692141825632, 0.07191974353402297, 0.09806815146701575, 0.09619567494706405, 0.08422198221706534, 0.12026437801395262, 0.13537823920063152, 0.09340609578952896, 0.09142444199167621, 0.2332702746507429, 0.27241995959464216, 0.1957548035840323, 0.2063349309423005, 0.27817845243066863, 0.21734473888159278, 0.25442152542739516, 0.16249108820503866, 0.22500289137696772, 0.3998986956725248, 0.30535352907680413, 0.3296205363350502, 0.20220610926671656, 0.2827284569439036, 0.25534122868473264, 0.2946655892546183, 0.2970055562039925, 0.3060993849392212, 0.32430560141483367, 0.20055268899183099, 0.2850729091832519, 0.21721890328931526, 0.17306799810176177, 0.2483118134212422, 0.25163493144047167, 0.2653303535771846, 0.2147623614153482, 0.23218211064824745, 0.15889439410157558, 0.23583622616058975, 0.19456643050425226, 0.16374003000060733, 0.21493953091769757, 0.22054221537976426, 0.21551086822309695, 0.2605374343106197, 0.20524551207598984, 0.20017766387611935, 0.1956276943474855, 0.20925170535343018, 0.20529381795845325, 0.18717220284413394, 0.18325239579642294, 0.18124447326753534, 0.19020501902925402, 0.8543511412457057, 0.16287565456475972, 0.15405114384215246, 0.8756578907995182, 0.19787582061465914, 0.20026239673368584, 0.14145544596878845, 0.1694883974512852, 0.8311271772006908, 0.8798375457660473, 0.2064413052170807, 0.15176246019230422, 0.20538455905359443, 0.566551491210618, 0.1550907979706735, 0.18481181998029672, 0.2089649029133862, 0.8021002040064757, 0.20259835816726113, 0.19294522648278056, 0.19996837239533938, 0.1998521869762372, 0.20039126424010079, 0.20393590761470382, 0.20086099584963946, 0.1904815661262652, 0.1857776711713358, 0.09433641993879316, 0.08015685705731035, 0.0939506345761596, 0.07902897205792137, 0.08872475901441956, 0.08341590190181958, 0.10648938366465865, 0.0730508682253449, 0.08920877147497341]}, "mutation_prompt": null}
{"id": "5d2e409a-987b-47d7-83ad-777bf9ce2b70", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            # Bound positions\n            positions = np.clip(positions, self.lb, self.ub)\n\n            # Evaluate new positions\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            # Update personal bests\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Adaptive Differential Mutation\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.8 * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "HybridPSO", "description": "A hybrid particle swarm optimization with adaptive differential mutation balances exploration and exploitation efficiently.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.7192282850284312, 0.5168340857008723, 0.6846234116845872, 0.7473451340670973, 0.44590167675114, 0.7177523085068118, 0.751962615835188, 0.507453929730844, 0.6799256398352029, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19559599127823335, 0.02970441323486883, 0.11096595841071288, 0.14676657223313583, 0.10592460590777997, 0.04040868601545011, 0.06453080512785092, 0.08424129924959067, 0.14482960703394032, 0.12596087772304088, 0.10466414872067453, 0.09968093505935594, 0.09556840093578844, 0.1266707814832938, 0.15451638446824123, 0.08353935794307521, 0.09175091844091166, 0.11577306851162195, 0.0901782479222828, 0.08787258953535615, 0.0874204157768842, 0.07099005862787766, 0.0780027644954967, 0.1049044090573854, 0.986871927128186, 0.9888577568102923, 0.9841395406604165, 0.9587564242849532, 0.9749992231424514, 0.95341883713273, 0.9841826064614492, 0.9812872409200664, 0.9860836591966228, 0.5576772097784908, 0.2570625877476015, 0.05822140105781859, 0.1474555830900901, 0.1358965199793667, 0.23376341712849802, 0.1228635937753374, 0.2437899312263202, 0.39169357696551454, 0.16981736408600845, 0.5845308937910284, 0.22502806129098518, 0.6809418598131833, 0.17742377480503746, 0.20648207784302997, 0.12119005288043228, 0.5053751653460844, 0.7765840935138728, 0.3657576720147365, 0.125415344465879, 0.2121195213452689, 9.999999999998899e-05, 0.09346470551805053, 0.21811899436558302, 9.999999999998899e-05, 0.08964084229928937, 0.3020101709155415, 0.3443706013363482, 0.27705766684041633, 0.2170004528468722, 0.2954439973962145, 0.1586893109740437, 0.2356379836323167, 0.33045513386723446, 0.0868440127340595, 0.12912077732133076, 0.13901453956648457, 9.999999999998899e-05, 0.14004943949646165, 9.999999999998899e-05, 0.0738965864889678, 0.026175443700540924, 0.15205423909024285, 0.07018108820370894, 0.06632390909305708, 0.08495224488071218, 0.06449465292418499, 0.3075521568734839, 0.3063741155163029, 0.04689722871845625, 0.06663968569740863, 0.1809495787193004, 0.0907040919298262, 0.24311920344802007, 0.1823883188788431, 0.026758442389819947, 0.09893975037558755, 0.11005372597709706, 0.09534199086673856, 0.060521173796774796, 0.0703995294946762, 0.06168497185017063, 0.14539258170421376, 0.1802982434895819, 0.029699252956736255, 0.1698175212971209, 0.005830260095274542, 0.14745468698275288, 0.19746480836723157, 0.13446105354378246, 0.09967478792748241, 0.07833505816293529, 0.15269779794482363, 0.45268479444163545, 0.5319119345612638, 0.546626576734907, 0.44126875791280207, 0.5025545013298822, 0.5354592104587445, 0.4196551063736047, 0.5234676250391219, 0.12273692141825632, 0.07191974353402297, 0.09806815146701575, 0.09619567494706405, 0.08422198221706534, 0.12026437801395262, 0.13537823920063152, 0.09340609578952896, 0.09142444199167621, 0.2332702746507429, 0.27241995959464216, 0.1957548035840323, 0.2063349309423005, 0.27817845243066863, 0.21734473888159278, 0.25442152542739516, 0.16249108820503866, 0.22500289137696772, 0.3998986956725248, 0.30535352907680413, 0.3296205363350502, 0.20220610926671656, 0.2827284569439036, 0.25534122868473264, 0.2946655892546183, 0.2970055562039925, 0.3060993849392212, 0.32430560141483367, 0.20055268899183099, 0.2850729091832519, 0.21721890328931526, 0.17306799810176177, 0.2483118134212422, 0.25163493144047167, 0.2653303535771846, 0.2147623614153482, 0.23218211064824745, 0.15889439410157558, 0.23583622616058975, 0.19456643050425226, 0.16374003000060733, 0.21493953091769757, 0.22054221537976426, 0.21551086822309695, 0.2605374343106197, 0.20524551207598984, 0.20017766387611935, 0.1956276943474855, 0.20925170535343018, 0.20529381795845325, 0.18717220284413394, 0.18325239579642294, 0.18124447326753534, 0.19020501902925402, 0.8543511412457057, 0.16287565456475972, 0.15405114384215246, 0.8756578907995182, 0.19787582061465914, 0.20026239673368584, 0.14145544596878845, 0.1694883974512852, 0.8311271772006908, 0.8798375457660473, 0.2064413052170807, 0.15176246019230422, 0.20538455905359443, 0.566551491210618, 0.1550907979706735, 0.18481181998029672, 0.2089649029133862, 0.8021002040064757, 0.20259835816726113, 0.19294522648278056, 0.19996837239533938, 0.1998521869762372, 0.20039126424010079, 0.20393590761470382, 0.20086099584963946, 0.1904815661262652, 0.1857776711713358, 0.09433641993879316, 0.08015685705731035, 0.0939506345761596, 0.07902897205792137, 0.08872475901441956, 0.08341590190181958, 0.10648938366465865, 0.0730508682253449, 0.08920877147497341]}, "mutation_prompt": null}
{"id": "58fc17e0-8ae0-43ce-871a-276a5c64bdd8", "solution": "import numpy as np\n\nclass AdaptiveGuidedPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = (0.9, 0.4)  # Adaptive inertia weight\n        self.cognitive_weight = 1.4\n        self.social_weight = 1.6\n        self.strategy_switch = 0.5  # Probability of using local search\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            w = self.inertia_weight[1] + (self.inertia_weight[0] - self.inertia_weight[1]) * ((self.budget - evaluations) / self.budget)\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n            positions = np.clip(positions, self.lb, self.ub)\n\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if np.random.rand() < self.strategy_switch:\n                for i in range(self.swarm_size):\n                    if evaluations + 1 > self.budget:\n                        break\n                    local_search = positions[i] + np.random.uniform(-0.1, 0.1, self.dim)\n                    local_search = np.clip(local_search, self.lb, self.ub)\n                    local_search_score = func(local_search)\n                    evaluations += 1\n\n                    if local_search_score < personal_best_scores[i]:\n                        personal_best_positions[i] = local_search\n                        personal_best_scores[i] = local_search_score\n                        if local_search_score < global_best_score:\n                            global_best_position = local_search\n                            global_best_score = local_search_score\n\n        return global_best_position, global_best_score", "name": "AdaptiveGuidedPSO", "description": "An adaptive guided particle swarm optimization with enhanced local search refines exploration and convergence.", "configspace": "", "generation": 20, "fitness": 0.23540051175884902, "feedback": "The algorithm AdaptiveGuidedPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.24.", "error": "", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.6535496205599854, 0.7108290137205306, 0.6327019689376179, 0.6658117973783989, 0.7056184793764813, 0.620396308251604, 0.6208100317319087, 0.7217615113273307, 0.6600560281477461, 9.999999999998899e-05, 0.03295394510894889, 0.03591314709441085, 0.016934372696600253, 0.03640960937126325, 0.03559728677497209, 0.028192009342455693, 0.041056659804510454, 0.023796101816757398, 0.07205117546691386, 0.08958837139828557, 0.10010177935458109, 0.08756189069485099, 0.059343394423065576, 0.0802348547334173, 0.12398719531517743, 0.13782973855451908, 0.11910126853800562, 0.08816847663871608, 0.07418683188851516, 0.0968680780343355, 0.08907867732223074, 0.09475224026051632, 0.05021559560884692, 0.05183700565796168, 0.08936594592529323, 0.11817244166060392, 0.9880554514654916, 0.9889734855526019, 0.9889225115100689, 0.9576031368698006, 0.9839515319682047, 0.971257915722912, 0.9871891616750211, 0.9850496442027808, 0.982757167609011, 0.38077150599162046, 0.4079394482051055, 0.2724515694303684, 0.29156333648796917, 0.35134570012329125, 0.3362831344058179, 0.2450717523693654, 0.33669290420037623, 0.2406998489605695, 0.2145602280011314, 0.7268175265270866, 0.20816302986990431, 0.25391804629738146, 0.18473575821379296, 0.21005642945705894, 0.07421376564681592, 0.16850674742957616, 0.13405602572811526, 0.242096971097304, 0.1228803066805092, 0.11532880731589235, 0.09062992779173129, 0.12272848792121638, 0.16273009196737964, 0.15239530063772921, 0.11958504361204736, 0.16155228823165513, 0.1131558129168041, 0.12474309713071197, 0.12121248206378532, 0.11931659121013438, 0.19169144118418746, 0.13042076834089944, 0.11694438306874422, 0.10579663998468547, 0.10563052458564903, 9.999999999998899e-05, 0.0014557293883527, 9.999999999998899e-05, 0.014811852794136549, 0.04155511811357315, 0.007686896570863966, 0.006912537692195464, 0.05865906244650143, 0.003839705615940714, 0.07541731025069753, 0.18196297530776373, 0.20254859239034195, 0.0915313706544133, 0.04938332900514175, 0.027111422798413498, 0.034703537028584974, 0.08278593325153483, 0.03667244492257815, 0.02675848678377768, 0.028399757566546224, 0.07464089674309016, 0.11464656058825295, 0.06320283175398456, 0.050781369577716395, 0.04829954114201296, 0.19506607271821763, 0.05759484298242701, 0.04814574451525222, 0.038088003294434736, 0.15472472037463814, 0.02104551826275569, 0.03681974284357381, 0.07644808344489451, 0.0445149642582785, 0.05001914457360668, 0.13071937726983562, 0.39038494270746715, 0.5269059755851079, 0.4546233391185259, 0.4557435896467126, 0.5102419476256299, 0.40850032937015146, 0.4875566424429859, 0.48788392486151566, 0.45535049446465126, 0.06353035293239118, 0.06814236016693975, 0.12157007849500712, 0.10230156791591782, 0.04463739396967181, 0.10378974662429996, 0.07059330898641913, 0.06439161612143385, 0.10898686510614242, 0.2397681843731242, 0.18089903367563331, 0.21309937097591558, 0.33879200448404967, 0.20134380448449907, 0.31981037063007856, 0.32476183452061136, 0.1374409690399251, 0.2499917477463781, 0.1671261636232816, 0.19232552852096174, 0.31941358583422763, 0.2243114695638806, 0.20615537202372203, 0.1507100245613976, 0.1982988891934384, 0.2787205703786846, 0.34057891844185584, 0.24689821071156792, 0.07207777518759018, 0.2132367092671027, 0.1419593151970756, 0.14069786566693088, 0.28731357786071043, 0.20365340730991321, 0.30022664596274906, 0.229902360899091, 0.21196251889702322, 0.15038034416172263, 0.1786230323680913, 0.18120136537655496, 0.15485845787005348, 0.20118583533708, 0.24705676908888718, 0.19383700063303655, 0.25071425566092, 0.18111662256571492, 0.17491258826568123, 0.16136411696249398, 0.19549276125774917, 0.18221446970304345, 0.19253751931152274, 0.17220319793291783, 0.19615674301448704, 0.20747722860571738, 0.710043498128785, 0.2048656720650841, 0.15073331005912183, 0.757682927738439, 0.198189965551259, 0.19812029619263472, 0.1384634999136728, 0.17003337152681397, 0.7807756479035011, 0.5732647883962689, 0.20611714048102647, 0.6647353256999222, 0.6652132066740482, 0.7730198803957489, 0.14933413769734616, 0.20816453679829305, 0.21059662226437503, 0.6530907457990218, 0.21316917132797797, 0.22375559952726742, 0.1836414093791664, 0.20015143688302373, 0.19126637996605766, 0.18846701055896053, 0.2180920891802378, 0.1967767973540021, 0.23727074388144942, 0.09402060162341064, 0.08197414982554196, 0.08768545933011807, 0.09185701679685754, 0.1068169089134664, 0.09293444020227415, 0.07952016439208909, 0.06629338062282442, 0.06989813406924072]}, "mutation_prompt": null}
{"id": "201378a1-de1f-4816-bb2d-a4f4a69b98df", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            # Bound positions\n            positions = np.clip(positions, self.lb, self.ub)\n\n            # Evaluate new positions\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            # Update personal bests\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Adaptive Differential Mutation\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.8 * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "HybridPSO", "description": "A hybrid particle swarm optimization with adaptive differential mutation balances exploration and exploitation efficiently.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.7192282850284312, 0.5168340857008723, 0.6846234116845872, 0.7473451340670973, 0.44590167675114, 0.7177523085068118, 0.751962615835188, 0.507453929730844, 0.6799256398352029, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19559599127823335, 0.02970441323486883, 0.11096595841071288, 0.14676657223313583, 0.10592460590777997, 0.04040868601545011, 0.06453080512785092, 0.08424129924959067, 0.14482960703394032, 0.12596087772304088, 0.10466414872067453, 0.09968093505935594, 0.09556840093578844, 0.1266707814832938, 0.15451638446824123, 0.08353935794307521, 0.09175091844091166, 0.11577306851162195, 0.0901782479222828, 0.08787258953535615, 0.0874204157768842, 0.07099005862787766, 0.0780027644954967, 0.1049044090573854, 0.986871927128186, 0.9888577568102923, 0.9841395406604165, 0.9587564242849532, 0.9749992231424514, 0.95341883713273, 0.9841826064614492, 0.9812872409200664, 0.9860836591966228, 0.5576772097784908, 0.2570625877476015, 0.05822140105781859, 0.1474555830900901, 0.1358965199793667, 0.23376341712849802, 0.1228635937753374, 0.2437899312263202, 0.39169357696551454, 0.16981736408600845, 0.5845308937910284, 0.22502806129098518, 0.6809418598131833, 0.17742377480503746, 0.20648207784302997, 0.12119005288043228, 0.5053751653460844, 0.7765840935138728, 0.3657576720147365, 0.125415344465879, 0.2121195213452689, 9.999999999998899e-05, 0.09346470551805053, 0.21811899436558302, 9.999999999998899e-05, 0.08964084229928937, 0.3020101709155415, 0.3443706013363482, 0.27705766684041633, 0.2170004528468722, 0.2954439973962145, 0.1586893109740437, 0.2356379836323167, 0.33045513386723446, 0.0868440127340595, 0.12912077732133076, 0.13901453956648457, 9.999999999998899e-05, 0.14004943949646165, 9.999999999998899e-05, 0.0738965864889678, 0.026175443700540924, 0.15205423909024285, 0.07018108820370894, 0.06632390909305708, 0.08495224488071218, 0.06449465292418499, 0.3075521568734839, 0.3063741155163029, 0.04689722871845625, 0.06663968569740863, 0.1809495787193004, 0.0907040919298262, 0.24311920344802007, 0.1823883188788431, 0.026758442389819947, 0.09893975037558755, 0.11005372597709706, 0.09534199086673856, 0.060521173796774796, 0.0703995294946762, 0.06168497185017063, 0.14539258170421376, 0.1802982434895819, 0.029699252956736255, 0.1698175212971209, 0.005830260095274542, 0.14745468698275288, 0.19746480836723157, 0.13446105354378246, 0.09967478792748241, 0.07833505816293529, 0.15269779794482363, 0.45268479444163545, 0.5319119345612638, 0.546626576734907, 0.44126875791280207, 0.5025545013298822, 0.5354592104587445, 0.4196551063736047, 0.5234676250391219, 0.12273692141825632, 0.07191974353402297, 0.09806815146701575, 0.09619567494706405, 0.08422198221706534, 0.12026437801395262, 0.13537823920063152, 0.09340609578952896, 0.09142444199167621, 0.2332702746507429, 0.27241995959464216, 0.1957548035840323, 0.2063349309423005, 0.27817845243066863, 0.21734473888159278, 0.25442152542739516, 0.16249108820503866, 0.22500289137696772, 0.3998986956725248, 0.30535352907680413, 0.3296205363350502, 0.20220610926671656, 0.2827284569439036, 0.25534122868473264, 0.2946655892546183, 0.2970055562039925, 0.3060993849392212, 0.32430560141483367, 0.20055268899183099, 0.2850729091832519, 0.21721890328931526, 0.17306799810176177, 0.2483118134212422, 0.25163493144047167, 0.2653303535771846, 0.2147623614153482, 0.23218211064824745, 0.15889439410157558, 0.23583622616058975, 0.19456643050425226, 0.16374003000060733, 0.21493953091769757, 0.22054221537976426, 0.21551086822309695, 0.2605374343106197, 0.20524551207598984, 0.20017766387611935, 0.1956276943474855, 0.20925170535343018, 0.20529381795845325, 0.18717220284413394, 0.18325239579642294, 0.18124447326753534, 0.19020501902925402, 0.8543511412457057, 0.16287565456475972, 0.15405114384215246, 0.8756578907995182, 0.19787582061465914, 0.20026239673368584, 0.14145544596878845, 0.1694883974512852, 0.8311271772006908, 0.8798375457660473, 0.2064413052170807, 0.15176246019230422, 0.20538455905359443, 0.566551491210618, 0.1550907979706735, 0.18481181998029672, 0.2089649029133862, 0.8021002040064757, 0.20259835816726113, 0.19294522648278056, 0.19996837239533938, 0.1998521869762372, 0.20039126424010079, 0.20393590761470382, 0.20086099584963946, 0.1904815661262652, 0.1857776711713358, 0.09433641993879316, 0.08015685705731035, 0.0939506345761596, 0.07902897205792137, 0.08872475901441956, 0.08341590190181958, 0.10648938366465865, 0.0730508682253449, 0.08920877147497341]}, "mutation_prompt": null}
{"id": "13627651-6b84-405f-a294-e5f539e31282", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            # Bound positions\n            positions = np.clip(positions, self.lb, self.ub)\n\n            # Evaluate new positions\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            # Update personal bests\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Adaptive Differential Mutation\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.8 * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "HybridPSO", "description": "A hybrid particle swarm optimization with adaptive differential mutation balances exploration and exploitation efficiently.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.7192282850284312, 0.5168340857008723, 0.6846234116845872, 0.7473451340670973, 0.44590167675114, 0.7177523085068118, 0.751962615835188, 0.507453929730844, 0.6799256398352029, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19559599127823335, 0.02970441323486883, 0.11096595841071288, 0.14676657223313583, 0.10592460590777997, 0.04040868601545011, 0.06453080512785092, 0.08424129924959067, 0.14482960703394032, 0.12596087772304088, 0.10466414872067453, 0.09968093505935594, 0.09556840093578844, 0.1266707814832938, 0.15451638446824123, 0.08353935794307521, 0.09175091844091166, 0.11577306851162195, 0.0901782479222828, 0.08787258953535615, 0.0874204157768842, 0.07099005862787766, 0.0780027644954967, 0.1049044090573854, 0.986871927128186, 0.9888577568102923, 0.9841395406604165, 0.9587564242849532, 0.9749992231424514, 0.95341883713273, 0.9841826064614492, 0.9812872409200664, 0.9860836591966228, 0.5576772097784908, 0.2570625877476015, 0.05822140105781859, 0.1474555830900901, 0.1358965199793667, 0.23376341712849802, 0.1228635937753374, 0.2437899312263202, 0.39169357696551454, 0.16981736408600845, 0.5845308937910284, 0.22502806129098518, 0.6809418598131833, 0.17742377480503746, 0.20648207784302997, 0.12119005288043228, 0.5053751653460844, 0.7765840935138728, 0.3657576720147365, 0.125415344465879, 0.2121195213452689, 9.999999999998899e-05, 0.09346470551805053, 0.21811899436558302, 9.999999999998899e-05, 0.08964084229928937, 0.3020101709155415, 0.3443706013363482, 0.27705766684041633, 0.2170004528468722, 0.2954439973962145, 0.1586893109740437, 0.2356379836323167, 0.33045513386723446, 0.0868440127340595, 0.12912077732133076, 0.13901453956648457, 9.999999999998899e-05, 0.14004943949646165, 9.999999999998899e-05, 0.0738965864889678, 0.026175443700540924, 0.15205423909024285, 0.07018108820370894, 0.06632390909305708, 0.08495224488071218, 0.06449465292418499, 0.3075521568734839, 0.3063741155163029, 0.04689722871845625, 0.06663968569740863, 0.1809495787193004, 0.0907040919298262, 0.24311920344802007, 0.1823883188788431, 0.026758442389819947, 0.09893975037558755, 0.11005372597709706, 0.09534199086673856, 0.060521173796774796, 0.0703995294946762, 0.06168497185017063, 0.14539258170421376, 0.1802982434895819, 0.029699252956736255, 0.1698175212971209, 0.005830260095274542, 0.14745468698275288, 0.19746480836723157, 0.13446105354378246, 0.09967478792748241, 0.07833505816293529, 0.15269779794482363, 0.45268479444163545, 0.5319119345612638, 0.546626576734907, 0.44126875791280207, 0.5025545013298822, 0.5354592104587445, 0.4196551063736047, 0.5234676250391219, 0.12273692141825632, 0.07191974353402297, 0.09806815146701575, 0.09619567494706405, 0.08422198221706534, 0.12026437801395262, 0.13537823920063152, 0.09340609578952896, 0.09142444199167621, 0.2332702746507429, 0.27241995959464216, 0.1957548035840323, 0.2063349309423005, 0.27817845243066863, 0.21734473888159278, 0.25442152542739516, 0.16249108820503866, 0.22500289137696772, 0.3998986956725248, 0.30535352907680413, 0.3296205363350502, 0.20220610926671656, 0.2827284569439036, 0.25534122868473264, 0.2946655892546183, 0.2970055562039925, 0.3060993849392212, 0.32430560141483367, 0.20055268899183099, 0.2850729091832519, 0.21721890328931526, 0.17306799810176177, 0.2483118134212422, 0.25163493144047167, 0.2653303535771846, 0.2147623614153482, 0.23218211064824745, 0.15889439410157558, 0.23583622616058975, 0.19456643050425226, 0.16374003000060733, 0.21493953091769757, 0.22054221537976426, 0.21551086822309695, 0.2605374343106197, 0.20524551207598984, 0.20017766387611935, 0.1956276943474855, 0.20925170535343018, 0.20529381795845325, 0.18717220284413394, 0.18325239579642294, 0.18124447326753534, 0.19020501902925402, 0.8543511412457057, 0.16287565456475972, 0.15405114384215246, 0.8756578907995182, 0.19787582061465914, 0.20026239673368584, 0.14145544596878845, 0.1694883974512852, 0.8311271772006908, 0.8798375457660473, 0.2064413052170807, 0.15176246019230422, 0.20538455905359443, 0.566551491210618, 0.1550907979706735, 0.18481181998029672, 0.2089649029133862, 0.8021002040064757, 0.20259835816726113, 0.19294522648278056, 0.19996837239533938, 0.1998521869762372, 0.20039126424010079, 0.20393590761470382, 0.20086099584963946, 0.1904815661262652, 0.1857776711713358, 0.09433641993879316, 0.08015685705731035, 0.0939506345761596, 0.07902897205792137, 0.08872475901441956, 0.08341590190181958, 0.10648938366465865, 0.0730508682253449, 0.08920877147497341]}, "mutation_prompt": null}
{"id": "cdf13143-0d73-4d38-82ff-ee2e59b7a955", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            # Bound positions\n            positions = np.clip(positions, self.lb, self.ub)\n\n            # Evaluate new positions\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            # Update personal bests\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Adaptive Differential Mutation\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.8 * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "HybridPSO", "description": "A hybrid particle swarm optimization with adaptive differential mutation balances exploration and exploitation efficiently.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.7192282850284312, 0.5168340857008723, 0.6846234116845872, 0.7473451340670973, 0.44590167675114, 0.7177523085068118, 0.751962615835188, 0.507453929730844, 0.6799256398352029, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19559599127823335, 0.02970441323486883, 0.11096595841071288, 0.14676657223313583, 0.10592460590777997, 0.04040868601545011, 0.06453080512785092, 0.08424129924959067, 0.14482960703394032, 0.12596087772304088, 0.10466414872067453, 0.09968093505935594, 0.09556840093578844, 0.1266707814832938, 0.15451638446824123, 0.08353935794307521, 0.09175091844091166, 0.11577306851162195, 0.0901782479222828, 0.08787258953535615, 0.0874204157768842, 0.07099005862787766, 0.0780027644954967, 0.1049044090573854, 0.986871927128186, 0.9888577568102923, 0.9841395406604165, 0.9587564242849532, 0.9749992231424514, 0.95341883713273, 0.9841826064614492, 0.9812872409200664, 0.9860836591966228, 0.5576772097784908, 0.2570625877476015, 0.05822140105781859, 0.1474555830900901, 0.1358965199793667, 0.23376341712849802, 0.1228635937753374, 0.2437899312263202, 0.39169357696551454, 0.16981736408600845, 0.5845308937910284, 0.22502806129098518, 0.6809418598131833, 0.17742377480503746, 0.20648207784302997, 0.12119005288043228, 0.5053751653460844, 0.7765840935138728, 0.3657576720147365, 0.125415344465879, 0.2121195213452689, 9.999999999998899e-05, 0.09346470551805053, 0.21811899436558302, 9.999999999998899e-05, 0.08964084229928937, 0.3020101709155415, 0.3443706013363482, 0.27705766684041633, 0.2170004528468722, 0.2954439973962145, 0.1586893109740437, 0.2356379836323167, 0.33045513386723446, 0.0868440127340595, 0.12912077732133076, 0.13901453956648457, 9.999999999998899e-05, 0.14004943949646165, 9.999999999998899e-05, 0.0738965864889678, 0.026175443700540924, 0.15205423909024285, 0.07018108820370894, 0.06632390909305708, 0.08495224488071218, 0.06449465292418499, 0.3075521568734839, 0.3063741155163029, 0.04689722871845625, 0.06663968569740863, 0.1809495787193004, 0.0907040919298262, 0.24311920344802007, 0.1823883188788431, 0.026758442389819947, 0.09893975037558755, 0.11005372597709706, 0.09534199086673856, 0.060521173796774796, 0.0703995294946762, 0.06168497185017063, 0.14539258170421376, 0.1802982434895819, 0.029699252956736255, 0.1698175212971209, 0.005830260095274542, 0.14745468698275288, 0.19746480836723157, 0.13446105354378246, 0.09967478792748241, 0.07833505816293529, 0.15269779794482363, 0.45268479444163545, 0.5319119345612638, 0.546626576734907, 0.44126875791280207, 0.5025545013298822, 0.5354592104587445, 0.4196551063736047, 0.5234676250391219, 0.12273692141825632, 0.07191974353402297, 0.09806815146701575, 0.09619567494706405, 0.08422198221706534, 0.12026437801395262, 0.13537823920063152, 0.09340609578952896, 0.09142444199167621, 0.2332702746507429, 0.27241995959464216, 0.1957548035840323, 0.2063349309423005, 0.27817845243066863, 0.21734473888159278, 0.25442152542739516, 0.16249108820503866, 0.22500289137696772, 0.3998986956725248, 0.30535352907680413, 0.3296205363350502, 0.20220610926671656, 0.2827284569439036, 0.25534122868473264, 0.2946655892546183, 0.2970055562039925, 0.3060993849392212, 0.32430560141483367, 0.20055268899183099, 0.2850729091832519, 0.21721890328931526, 0.17306799810176177, 0.2483118134212422, 0.25163493144047167, 0.2653303535771846, 0.2147623614153482, 0.23218211064824745, 0.15889439410157558, 0.23583622616058975, 0.19456643050425226, 0.16374003000060733, 0.21493953091769757, 0.22054221537976426, 0.21551086822309695, 0.2605374343106197, 0.20524551207598984, 0.20017766387611935, 0.1956276943474855, 0.20925170535343018, 0.20529381795845325, 0.18717220284413394, 0.18325239579642294, 0.18124447326753534, 0.19020501902925402, 0.8543511412457057, 0.16287565456475972, 0.15405114384215246, 0.8756578907995182, 0.19787582061465914, 0.20026239673368584, 0.14145544596878845, 0.1694883974512852, 0.8311271772006908, 0.8798375457660473, 0.2064413052170807, 0.15176246019230422, 0.20538455905359443, 0.566551491210618, 0.1550907979706735, 0.18481181998029672, 0.2089649029133862, 0.8021002040064757, 0.20259835816726113, 0.19294522648278056, 0.19996837239533938, 0.1998521869762372, 0.20039126424010079, 0.20393590761470382, 0.20086099584963946, 0.1904815661262652, 0.1857776711713358, 0.09433641993879316, 0.08015685705731035, 0.0939506345761596, 0.07902897205792137, 0.08872475901441956, 0.08341590190181958, 0.10648938366465865, 0.0730508682253449, 0.08920877147497341]}, "mutation_prompt": null}
{"id": "24787dfb-22ca-4960-bbd7-47ee7e7a1d47", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            # Bound positions\n            positions = np.clip(positions, self.lb, self.ub)\n\n            # Evaluate new positions\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            # Update personal bests\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Adaptive Differential Mutation\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.8 * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "HybridPSO", "description": "A hybrid particle swarm optimization with adaptive differential mutation balances exploration and exploitation efficiently.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.7192282850284312, 0.5168340857008723, 0.6846234116845872, 0.7473451340670973, 0.44590167675114, 0.7177523085068118, 0.751962615835188, 0.507453929730844, 0.6799256398352029, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19559599127823335, 0.02970441323486883, 0.11096595841071288, 0.14676657223313583, 0.10592460590777997, 0.04040868601545011, 0.06453080512785092, 0.08424129924959067, 0.14482960703394032, 0.12596087772304088, 0.10466414872067453, 0.09968093505935594, 0.09556840093578844, 0.1266707814832938, 0.15451638446824123, 0.08353935794307521, 0.09175091844091166, 0.11577306851162195, 0.0901782479222828, 0.08787258953535615, 0.0874204157768842, 0.07099005862787766, 0.0780027644954967, 0.1049044090573854, 0.986871927128186, 0.9888577568102923, 0.9841395406604165, 0.9587564242849532, 0.9749992231424514, 0.95341883713273, 0.9841826064614492, 0.9812872409200664, 0.9860836591966228, 0.5576772097784908, 0.2570625877476015, 0.05822140105781859, 0.1474555830900901, 0.1358965199793667, 0.23376341712849802, 0.1228635937753374, 0.2437899312263202, 0.39169357696551454, 0.16981736408600845, 0.5845308937910284, 0.22502806129098518, 0.6809418598131833, 0.17742377480503746, 0.20648207784302997, 0.12119005288043228, 0.5053751653460844, 0.7765840935138728, 0.3657576720147365, 0.125415344465879, 0.2121195213452689, 9.999999999998899e-05, 0.09346470551805053, 0.21811899436558302, 9.999999999998899e-05, 0.08964084229928937, 0.3020101709155415, 0.3443706013363482, 0.27705766684041633, 0.2170004528468722, 0.2954439973962145, 0.1586893109740437, 0.2356379836323167, 0.33045513386723446, 0.0868440127340595, 0.12912077732133076, 0.13901453956648457, 9.999999999998899e-05, 0.14004943949646165, 9.999999999998899e-05, 0.0738965864889678, 0.026175443700540924, 0.15205423909024285, 0.07018108820370894, 0.06632390909305708, 0.08495224488071218, 0.06449465292418499, 0.3075521568734839, 0.3063741155163029, 0.04689722871845625, 0.06663968569740863, 0.1809495787193004, 0.0907040919298262, 0.24311920344802007, 0.1823883188788431, 0.026758442389819947, 0.09893975037558755, 0.11005372597709706, 0.09534199086673856, 0.060521173796774796, 0.0703995294946762, 0.06168497185017063, 0.14539258170421376, 0.1802982434895819, 0.029699252956736255, 0.1698175212971209, 0.005830260095274542, 0.14745468698275288, 0.19746480836723157, 0.13446105354378246, 0.09967478792748241, 0.07833505816293529, 0.15269779794482363, 0.45268479444163545, 0.5319119345612638, 0.546626576734907, 0.44126875791280207, 0.5025545013298822, 0.5354592104587445, 0.4196551063736047, 0.5234676250391219, 0.12273692141825632, 0.07191974353402297, 0.09806815146701575, 0.09619567494706405, 0.08422198221706534, 0.12026437801395262, 0.13537823920063152, 0.09340609578952896, 0.09142444199167621, 0.2332702746507429, 0.27241995959464216, 0.1957548035840323, 0.2063349309423005, 0.27817845243066863, 0.21734473888159278, 0.25442152542739516, 0.16249108820503866, 0.22500289137696772, 0.3998986956725248, 0.30535352907680413, 0.3296205363350502, 0.20220610926671656, 0.2827284569439036, 0.25534122868473264, 0.2946655892546183, 0.2970055562039925, 0.3060993849392212, 0.32430560141483367, 0.20055268899183099, 0.2850729091832519, 0.21721890328931526, 0.17306799810176177, 0.2483118134212422, 0.25163493144047167, 0.2653303535771846, 0.2147623614153482, 0.23218211064824745, 0.15889439410157558, 0.23583622616058975, 0.19456643050425226, 0.16374003000060733, 0.21493953091769757, 0.22054221537976426, 0.21551086822309695, 0.2605374343106197, 0.20524551207598984, 0.20017766387611935, 0.1956276943474855, 0.20925170535343018, 0.20529381795845325, 0.18717220284413394, 0.18325239579642294, 0.18124447326753534, 0.19020501902925402, 0.8543511412457057, 0.16287565456475972, 0.15405114384215246, 0.8756578907995182, 0.19787582061465914, 0.20026239673368584, 0.14145544596878845, 0.1694883974512852, 0.8311271772006908, 0.8798375457660473, 0.2064413052170807, 0.15176246019230422, 0.20538455905359443, 0.566551491210618, 0.1550907979706735, 0.18481181998029672, 0.2089649029133862, 0.8021002040064757, 0.20259835816726113, 0.19294522648278056, 0.19996837239533938, 0.1998521869762372, 0.20039126424010079, 0.20393590761470382, 0.20086099584963946, 0.1904815661262652, 0.1857776711713358, 0.09433641993879316, 0.08015685705731035, 0.0939506345761596, 0.07902897205792137, 0.08872475901441956, 0.08341590190181958, 0.10648938366465865, 0.0730508682253449, 0.08920877147497341]}, "mutation_prompt": null}
{"id": "b8cc2c5b-0c1d-439d-8a85-19924fb13c5b", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            # Bound positions\n            positions = np.clip(positions, self.lb, self.ub)\n\n            # Evaluate new positions\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            # Update personal bests\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Adaptive Differential Mutation\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.8 * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "HybridPSO", "description": "A hybrid particle swarm optimization with adaptive differential mutation balances exploration and exploitation efficiently.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.7192282850284312, 0.5168340857008723, 0.6846234116845872, 0.7473451340670973, 0.44590167675114, 0.7177523085068118, 0.751962615835188, 0.507453929730844, 0.6799256398352029, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19559599127823335, 0.02970441323486883, 0.11096595841071288, 0.14676657223313583, 0.10592460590777997, 0.04040868601545011, 0.06453080512785092, 0.08424129924959067, 0.14482960703394032, 0.12596087772304088, 0.10466414872067453, 0.09968093505935594, 0.09556840093578844, 0.1266707814832938, 0.15451638446824123, 0.08353935794307521, 0.09175091844091166, 0.11577306851162195, 0.0901782479222828, 0.08787258953535615, 0.0874204157768842, 0.07099005862787766, 0.0780027644954967, 0.1049044090573854, 0.986871927128186, 0.9888577568102923, 0.9841395406604165, 0.9587564242849532, 0.9749992231424514, 0.95341883713273, 0.9841826064614492, 0.9812872409200664, 0.9860836591966228, 0.5576772097784908, 0.2570625877476015, 0.05822140105781859, 0.1474555830900901, 0.1358965199793667, 0.23376341712849802, 0.1228635937753374, 0.2437899312263202, 0.39169357696551454, 0.16981736408600845, 0.5845308937910284, 0.22502806129098518, 0.6809418598131833, 0.17742377480503746, 0.20648207784302997, 0.12119005288043228, 0.5053751653460844, 0.7765840935138728, 0.3657576720147365, 0.125415344465879, 0.2121195213452689, 9.999999999998899e-05, 0.09346470551805053, 0.21811899436558302, 9.999999999998899e-05, 0.08964084229928937, 0.3020101709155415, 0.3443706013363482, 0.27705766684041633, 0.2170004528468722, 0.2954439973962145, 0.1586893109740437, 0.2356379836323167, 0.33045513386723446, 0.0868440127340595, 0.12912077732133076, 0.13901453956648457, 9.999999999998899e-05, 0.14004943949646165, 9.999999999998899e-05, 0.0738965864889678, 0.026175443700540924, 0.15205423909024285, 0.07018108820370894, 0.06632390909305708, 0.08495224488071218, 0.06449465292418499, 0.3075521568734839, 0.3063741155163029, 0.04689722871845625, 0.06663968569740863, 0.1809495787193004, 0.0907040919298262, 0.24311920344802007, 0.1823883188788431, 0.026758442389819947, 0.09893975037558755, 0.11005372597709706, 0.09534199086673856, 0.060521173796774796, 0.0703995294946762, 0.06168497185017063, 0.14539258170421376, 0.1802982434895819, 0.029699252956736255, 0.1698175212971209, 0.005830260095274542, 0.14745468698275288, 0.19746480836723157, 0.13446105354378246, 0.09967478792748241, 0.07833505816293529, 0.15269779794482363, 0.45268479444163545, 0.5319119345612638, 0.546626576734907, 0.44126875791280207, 0.5025545013298822, 0.5354592104587445, 0.4196551063736047, 0.5234676250391219, 0.12273692141825632, 0.07191974353402297, 0.09806815146701575, 0.09619567494706405, 0.08422198221706534, 0.12026437801395262, 0.13537823920063152, 0.09340609578952896, 0.09142444199167621, 0.2332702746507429, 0.27241995959464216, 0.1957548035840323, 0.2063349309423005, 0.27817845243066863, 0.21734473888159278, 0.25442152542739516, 0.16249108820503866, 0.22500289137696772, 0.3998986956725248, 0.30535352907680413, 0.3296205363350502, 0.20220610926671656, 0.2827284569439036, 0.25534122868473264, 0.2946655892546183, 0.2970055562039925, 0.3060993849392212, 0.32430560141483367, 0.20055268899183099, 0.2850729091832519, 0.21721890328931526, 0.17306799810176177, 0.2483118134212422, 0.25163493144047167, 0.2653303535771846, 0.2147623614153482, 0.23218211064824745, 0.15889439410157558, 0.23583622616058975, 0.19456643050425226, 0.16374003000060733, 0.21493953091769757, 0.22054221537976426, 0.21551086822309695, 0.2605374343106197, 0.20524551207598984, 0.20017766387611935, 0.1956276943474855, 0.20925170535343018, 0.20529381795845325, 0.18717220284413394, 0.18325239579642294, 0.18124447326753534, 0.19020501902925402, 0.8543511412457057, 0.16287565456475972, 0.15405114384215246, 0.8756578907995182, 0.19787582061465914, 0.20026239673368584, 0.14145544596878845, 0.1694883974512852, 0.8311271772006908, 0.8798375457660473, 0.2064413052170807, 0.15176246019230422, 0.20538455905359443, 0.566551491210618, 0.1550907979706735, 0.18481181998029672, 0.2089649029133862, 0.8021002040064757, 0.20259835816726113, 0.19294522648278056, 0.19996837239533938, 0.1998521869762372, 0.20039126424010079, 0.20393590761470382, 0.20086099584963946, 0.1904815661262652, 0.1857776711713358, 0.09433641993879316, 0.08015685705731035, 0.0939506345761596, 0.07902897205792137, 0.08872475901441956, 0.08341590190181958, 0.10648938366465865, 0.0730508682253449, 0.08920877147497341]}, "mutation_prompt": null}
{"id": "4d487400-7b86-4de3-9ffa-1499a1b8f490", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            # Bound positions\n            positions = np.clip(positions, self.lb, self.ub)\n\n            # Evaluate new positions\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            # Update personal bests\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Adaptive Differential Mutation\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.8 * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "HybridPSO", "description": "A hybrid particle swarm optimization with adaptive differential mutation balances exploration and exploitation efficiently.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.7192282850284312, 0.5168340857008723, 0.6846234116845872, 0.7473451340670973, 0.44590167675114, 0.7177523085068118, 0.751962615835188, 0.507453929730844, 0.6799256398352029, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19559599127823335, 0.02970441323486883, 0.11096595841071288, 0.14676657223313583, 0.10592460590777997, 0.04040868601545011, 0.06453080512785092, 0.08424129924959067, 0.14482960703394032, 0.12596087772304088, 0.10466414872067453, 0.09968093505935594, 0.09556840093578844, 0.1266707814832938, 0.15451638446824123, 0.08353935794307521, 0.09175091844091166, 0.11577306851162195, 0.0901782479222828, 0.08787258953535615, 0.0874204157768842, 0.07099005862787766, 0.0780027644954967, 0.1049044090573854, 0.986871927128186, 0.9888577568102923, 0.9841395406604165, 0.9587564242849532, 0.9749992231424514, 0.95341883713273, 0.9841826064614492, 0.9812872409200664, 0.9860836591966228, 0.5576772097784908, 0.2570625877476015, 0.05822140105781859, 0.1474555830900901, 0.1358965199793667, 0.23376341712849802, 0.1228635937753374, 0.2437899312263202, 0.39169357696551454, 0.16981736408600845, 0.5845308937910284, 0.22502806129098518, 0.6809418598131833, 0.17742377480503746, 0.20648207784302997, 0.12119005288043228, 0.5053751653460844, 0.7765840935138728, 0.3657576720147365, 0.125415344465879, 0.2121195213452689, 9.999999999998899e-05, 0.09346470551805053, 0.21811899436558302, 9.999999999998899e-05, 0.08964084229928937, 0.3020101709155415, 0.3443706013363482, 0.27705766684041633, 0.2170004528468722, 0.2954439973962145, 0.1586893109740437, 0.2356379836323167, 0.33045513386723446, 0.0868440127340595, 0.12912077732133076, 0.13901453956648457, 9.999999999998899e-05, 0.14004943949646165, 9.999999999998899e-05, 0.0738965864889678, 0.026175443700540924, 0.15205423909024285, 0.07018108820370894, 0.06632390909305708, 0.08495224488071218, 0.06449465292418499, 0.3075521568734839, 0.3063741155163029, 0.04689722871845625, 0.06663968569740863, 0.1809495787193004, 0.0907040919298262, 0.24311920344802007, 0.1823883188788431, 0.026758442389819947, 0.09893975037558755, 0.11005372597709706, 0.09534199086673856, 0.060521173796774796, 0.0703995294946762, 0.06168497185017063, 0.14539258170421376, 0.1802982434895819, 0.029699252956736255, 0.1698175212971209, 0.005830260095274542, 0.14745468698275288, 0.19746480836723157, 0.13446105354378246, 0.09967478792748241, 0.07833505816293529, 0.15269779794482363, 0.45268479444163545, 0.5319119345612638, 0.546626576734907, 0.44126875791280207, 0.5025545013298822, 0.5354592104587445, 0.4196551063736047, 0.5234676250391219, 0.12273692141825632, 0.07191974353402297, 0.09806815146701575, 0.09619567494706405, 0.08422198221706534, 0.12026437801395262, 0.13537823920063152, 0.09340609578952896, 0.09142444199167621, 0.2332702746507429, 0.27241995959464216, 0.1957548035840323, 0.2063349309423005, 0.27817845243066863, 0.21734473888159278, 0.25442152542739516, 0.16249108820503866, 0.22500289137696772, 0.3998986956725248, 0.30535352907680413, 0.3296205363350502, 0.20220610926671656, 0.2827284569439036, 0.25534122868473264, 0.2946655892546183, 0.2970055562039925, 0.3060993849392212, 0.32430560141483367, 0.20055268899183099, 0.2850729091832519, 0.21721890328931526, 0.17306799810176177, 0.2483118134212422, 0.25163493144047167, 0.2653303535771846, 0.2147623614153482, 0.23218211064824745, 0.15889439410157558, 0.23583622616058975, 0.19456643050425226, 0.16374003000060733, 0.21493953091769757, 0.22054221537976426, 0.21551086822309695, 0.2605374343106197, 0.20524551207598984, 0.20017766387611935, 0.1956276943474855, 0.20925170535343018, 0.20529381795845325, 0.18717220284413394, 0.18325239579642294, 0.18124447326753534, 0.19020501902925402, 0.8543511412457057, 0.16287565456475972, 0.15405114384215246, 0.8756578907995182, 0.19787582061465914, 0.20026239673368584, 0.14145544596878845, 0.1694883974512852, 0.8311271772006908, 0.8798375457660473, 0.2064413052170807, 0.15176246019230422, 0.20538455905359443, 0.566551491210618, 0.1550907979706735, 0.18481181998029672, 0.2089649029133862, 0.8021002040064757, 0.20259835816726113, 0.19294522648278056, 0.19996837239533938, 0.1998521869762372, 0.20039126424010079, 0.20393590761470382, 0.20086099584963946, 0.1904815661262652, 0.1857776711713358, 0.09433641993879316, 0.08015685705731035, 0.0939506345761596, 0.07902897205792137, 0.08872475901441956, 0.08341590190181958, 0.10648938366465865, 0.0730508682253449, 0.08920877147497341]}, "mutation_prompt": null}
{"id": "8ee22fff-2bad-4d87-bc6a-a521bcdcf868", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            # Bound positions\n            positions = np.clip(positions, self.lb, self.ub)\n\n            # Evaluate new positions\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            # Update personal bests\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Adaptive Differential Mutation\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.8 * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "HybridPSO", "description": "A hybrid particle swarm optimization with adaptive differential mutation balances exploration and exploitation efficiently.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.7192282850284312, 0.5168340857008723, 0.6846234116845872, 0.7473451340670973, 0.44590167675114, 0.7177523085068118, 0.751962615835188, 0.507453929730844, 0.6799256398352029, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19559599127823335, 0.02970441323486883, 0.11096595841071288, 0.14676657223313583, 0.10592460590777997, 0.04040868601545011, 0.06453080512785092, 0.08424129924959067, 0.14482960703394032, 0.12596087772304088, 0.10466414872067453, 0.09968093505935594, 0.09556840093578844, 0.1266707814832938, 0.15451638446824123, 0.08353935794307521, 0.09175091844091166, 0.11577306851162195, 0.0901782479222828, 0.08787258953535615, 0.0874204157768842, 0.07099005862787766, 0.0780027644954967, 0.1049044090573854, 0.986871927128186, 0.9888577568102923, 0.9841395406604165, 0.9587564242849532, 0.9749992231424514, 0.95341883713273, 0.9841826064614492, 0.9812872409200664, 0.9860836591966228, 0.5576772097784908, 0.2570625877476015, 0.05822140105781859, 0.1474555830900901, 0.1358965199793667, 0.23376341712849802, 0.1228635937753374, 0.2437899312263202, 0.39169357696551454, 0.16981736408600845, 0.5845308937910284, 0.22502806129098518, 0.6809418598131833, 0.17742377480503746, 0.20648207784302997, 0.12119005288043228, 0.5053751653460844, 0.7765840935138728, 0.3657576720147365, 0.125415344465879, 0.2121195213452689, 9.999999999998899e-05, 0.09346470551805053, 0.21811899436558302, 9.999999999998899e-05, 0.08964084229928937, 0.3020101709155415, 0.3443706013363482, 0.27705766684041633, 0.2170004528468722, 0.2954439973962145, 0.1586893109740437, 0.2356379836323167, 0.33045513386723446, 0.0868440127340595, 0.12912077732133076, 0.13901453956648457, 9.999999999998899e-05, 0.14004943949646165, 9.999999999998899e-05, 0.0738965864889678, 0.026175443700540924, 0.15205423909024285, 0.07018108820370894, 0.06632390909305708, 0.08495224488071218, 0.06449465292418499, 0.3075521568734839, 0.3063741155163029, 0.04689722871845625, 0.06663968569740863, 0.1809495787193004, 0.0907040919298262, 0.24311920344802007, 0.1823883188788431, 0.026758442389819947, 0.09893975037558755, 0.11005372597709706, 0.09534199086673856, 0.060521173796774796, 0.0703995294946762, 0.06168497185017063, 0.14539258170421376, 0.1802982434895819, 0.029699252956736255, 0.1698175212971209, 0.005830260095274542, 0.14745468698275288, 0.19746480836723157, 0.13446105354378246, 0.09967478792748241, 0.07833505816293529, 0.15269779794482363, 0.45268479444163545, 0.5319119345612638, 0.546626576734907, 0.44126875791280207, 0.5025545013298822, 0.5354592104587445, 0.4196551063736047, 0.5234676250391219, 0.12273692141825632, 0.07191974353402297, 0.09806815146701575, 0.09619567494706405, 0.08422198221706534, 0.12026437801395262, 0.13537823920063152, 0.09340609578952896, 0.09142444199167621, 0.2332702746507429, 0.27241995959464216, 0.1957548035840323, 0.2063349309423005, 0.27817845243066863, 0.21734473888159278, 0.25442152542739516, 0.16249108820503866, 0.22500289137696772, 0.3998986956725248, 0.30535352907680413, 0.3296205363350502, 0.20220610926671656, 0.2827284569439036, 0.25534122868473264, 0.2946655892546183, 0.2970055562039925, 0.3060993849392212, 0.32430560141483367, 0.20055268899183099, 0.2850729091832519, 0.21721890328931526, 0.17306799810176177, 0.2483118134212422, 0.25163493144047167, 0.2653303535771846, 0.2147623614153482, 0.23218211064824745, 0.15889439410157558, 0.23583622616058975, 0.19456643050425226, 0.16374003000060733, 0.21493953091769757, 0.22054221537976426, 0.21551086822309695, 0.2605374343106197, 0.20524551207598984, 0.20017766387611935, 0.1956276943474855, 0.20925170535343018, 0.20529381795845325, 0.18717220284413394, 0.18325239579642294, 0.18124447326753534, 0.19020501902925402, 0.8543511412457057, 0.16287565456475972, 0.15405114384215246, 0.8756578907995182, 0.19787582061465914, 0.20026239673368584, 0.14145544596878845, 0.1694883974512852, 0.8311271772006908, 0.8798375457660473, 0.2064413052170807, 0.15176246019230422, 0.20538455905359443, 0.566551491210618, 0.1550907979706735, 0.18481181998029672, 0.2089649029133862, 0.8021002040064757, 0.20259835816726113, 0.19294522648278056, 0.19996837239533938, 0.1998521869762372, 0.20039126424010079, 0.20393590761470382, 0.20086099584963946, 0.1904815661262652, 0.1857776711713358, 0.09433641993879316, 0.08015685705731035, 0.0939506345761596, 0.07902897205792137, 0.08872475901441956, 0.08341590190181958, 0.10648938366465865, 0.0730508682253449, 0.08920877147497341]}, "mutation_prompt": null}
{"id": "69e7bf15-d556-4c4d-a5d9-16b11535a80c", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            # Bound positions\n            positions = np.clip(positions, self.lb, self.ub)\n\n            # Evaluate new positions\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            # Update personal bests\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Adaptive Differential Mutation\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.8 * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "HybridPSO", "description": "A hybrid particle swarm optimization with adaptive differential mutation balances exploration and exploitation efficiently.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.7192282850284312, 0.5168340857008723, 0.6846234116845872, 0.7473451340670973, 0.44590167675114, 0.7177523085068118, 0.751962615835188, 0.507453929730844, 0.6799256398352029, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19559599127823335, 0.02970441323486883, 0.11096595841071288, 0.14676657223313583, 0.10592460590777997, 0.04040868601545011, 0.06453080512785092, 0.08424129924959067, 0.14482960703394032, 0.12596087772304088, 0.10466414872067453, 0.09968093505935594, 0.09556840093578844, 0.1266707814832938, 0.15451638446824123, 0.08353935794307521, 0.09175091844091166, 0.11577306851162195, 0.0901782479222828, 0.08787258953535615, 0.0874204157768842, 0.07099005862787766, 0.0780027644954967, 0.1049044090573854, 0.986871927128186, 0.9888577568102923, 0.9841395406604165, 0.9587564242849532, 0.9749992231424514, 0.95341883713273, 0.9841826064614492, 0.9812872409200664, 0.9860836591966228, 0.5576772097784908, 0.2570625877476015, 0.05822140105781859, 0.1474555830900901, 0.1358965199793667, 0.23376341712849802, 0.1228635937753374, 0.2437899312263202, 0.39169357696551454, 0.16981736408600845, 0.5845308937910284, 0.22502806129098518, 0.6809418598131833, 0.17742377480503746, 0.20648207784302997, 0.12119005288043228, 0.5053751653460844, 0.7765840935138728, 0.3657576720147365, 0.125415344465879, 0.2121195213452689, 9.999999999998899e-05, 0.09346470551805053, 0.21811899436558302, 9.999999999998899e-05, 0.08964084229928937, 0.3020101709155415, 0.3443706013363482, 0.27705766684041633, 0.2170004528468722, 0.2954439973962145, 0.1586893109740437, 0.2356379836323167, 0.33045513386723446, 0.0868440127340595, 0.12912077732133076, 0.13901453956648457, 9.999999999998899e-05, 0.14004943949646165, 9.999999999998899e-05, 0.0738965864889678, 0.026175443700540924, 0.15205423909024285, 0.07018108820370894, 0.06632390909305708, 0.08495224488071218, 0.06449465292418499, 0.3075521568734839, 0.3063741155163029, 0.04689722871845625, 0.06663968569740863, 0.1809495787193004, 0.0907040919298262, 0.24311920344802007, 0.1823883188788431, 0.026758442389819947, 0.09893975037558755, 0.11005372597709706, 0.09534199086673856, 0.060521173796774796, 0.0703995294946762, 0.06168497185017063, 0.14539258170421376, 0.1802982434895819, 0.029699252956736255, 0.1698175212971209, 0.005830260095274542, 0.14745468698275288, 0.19746480836723157, 0.13446105354378246, 0.09967478792748241, 0.07833505816293529, 0.15269779794482363, 0.45268479444163545, 0.5319119345612638, 0.546626576734907, 0.44126875791280207, 0.5025545013298822, 0.5354592104587445, 0.4196551063736047, 0.5234676250391219, 0.12273692141825632, 0.07191974353402297, 0.09806815146701575, 0.09619567494706405, 0.08422198221706534, 0.12026437801395262, 0.13537823920063152, 0.09340609578952896, 0.09142444199167621, 0.2332702746507429, 0.27241995959464216, 0.1957548035840323, 0.2063349309423005, 0.27817845243066863, 0.21734473888159278, 0.25442152542739516, 0.16249108820503866, 0.22500289137696772, 0.3998986956725248, 0.30535352907680413, 0.3296205363350502, 0.20220610926671656, 0.2827284569439036, 0.25534122868473264, 0.2946655892546183, 0.2970055562039925, 0.3060993849392212, 0.32430560141483367, 0.20055268899183099, 0.2850729091832519, 0.21721890328931526, 0.17306799810176177, 0.2483118134212422, 0.25163493144047167, 0.2653303535771846, 0.2147623614153482, 0.23218211064824745, 0.15889439410157558, 0.23583622616058975, 0.19456643050425226, 0.16374003000060733, 0.21493953091769757, 0.22054221537976426, 0.21551086822309695, 0.2605374343106197, 0.20524551207598984, 0.20017766387611935, 0.1956276943474855, 0.20925170535343018, 0.20529381795845325, 0.18717220284413394, 0.18325239579642294, 0.18124447326753534, 0.19020501902925402, 0.8543511412457057, 0.16287565456475972, 0.15405114384215246, 0.8756578907995182, 0.19787582061465914, 0.20026239673368584, 0.14145544596878845, 0.1694883974512852, 0.8311271772006908, 0.8798375457660473, 0.2064413052170807, 0.15176246019230422, 0.20538455905359443, 0.566551491210618, 0.1550907979706735, 0.18481181998029672, 0.2089649029133862, 0.8021002040064757, 0.20259835816726113, 0.19294522648278056, 0.19996837239533938, 0.1998521869762372, 0.20039126424010079, 0.20393590761470382, 0.20086099584963946, 0.1904815661262652, 0.1857776711713358, 0.09433641993879316, 0.08015685705731035, 0.0939506345761596, 0.07902897205792137, 0.08872475901441956, 0.08341590190181958, 0.10648938366465865, 0.0730508682253449, 0.08920877147497341]}, "mutation_prompt": null}
{"id": "86c556f1-c531-4af5-bd7a-986217207bbe", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            # Bound positions\n            positions = np.clip(positions, self.lb, self.ub)\n\n            # Evaluate new positions\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            # Update personal bests\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Adaptive Differential Mutation\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.8 * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "HybridPSO", "description": "A hybrid particle swarm optimization with adaptive differential mutation balances exploration and exploitation efficiently.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.7192282850284312, 0.5168340857008723, 0.6846234116845872, 0.7473451340670973, 0.44590167675114, 0.7177523085068118, 0.751962615835188, 0.507453929730844, 0.6799256398352029, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19559599127823335, 0.02970441323486883, 0.11096595841071288, 0.14676657223313583, 0.10592460590777997, 0.04040868601545011, 0.06453080512785092, 0.08424129924959067, 0.14482960703394032, 0.12596087772304088, 0.10466414872067453, 0.09968093505935594, 0.09556840093578844, 0.1266707814832938, 0.15451638446824123, 0.08353935794307521, 0.09175091844091166, 0.11577306851162195, 0.0901782479222828, 0.08787258953535615, 0.0874204157768842, 0.07099005862787766, 0.0780027644954967, 0.1049044090573854, 0.986871927128186, 0.9888577568102923, 0.9841395406604165, 0.9587564242849532, 0.9749992231424514, 0.95341883713273, 0.9841826064614492, 0.9812872409200664, 0.9860836591966228, 0.5576772097784908, 0.2570625877476015, 0.05822140105781859, 0.1474555830900901, 0.1358965199793667, 0.23376341712849802, 0.1228635937753374, 0.2437899312263202, 0.39169357696551454, 0.16981736408600845, 0.5845308937910284, 0.22502806129098518, 0.6809418598131833, 0.17742377480503746, 0.20648207784302997, 0.12119005288043228, 0.5053751653460844, 0.7765840935138728, 0.3657576720147365, 0.125415344465879, 0.2121195213452689, 9.999999999998899e-05, 0.09346470551805053, 0.21811899436558302, 9.999999999998899e-05, 0.08964084229928937, 0.3020101709155415, 0.3443706013363482, 0.27705766684041633, 0.2170004528468722, 0.2954439973962145, 0.1586893109740437, 0.2356379836323167, 0.33045513386723446, 0.0868440127340595, 0.12912077732133076, 0.13901453956648457, 9.999999999998899e-05, 0.14004943949646165, 9.999999999998899e-05, 0.0738965864889678, 0.026175443700540924, 0.15205423909024285, 0.07018108820370894, 0.06632390909305708, 0.08495224488071218, 0.06449465292418499, 0.3075521568734839, 0.3063741155163029, 0.04689722871845625, 0.06663968569740863, 0.1809495787193004, 0.0907040919298262, 0.24311920344802007, 0.1823883188788431, 0.026758442389819947, 0.09893975037558755, 0.11005372597709706, 0.09534199086673856, 0.060521173796774796, 0.0703995294946762, 0.06168497185017063, 0.14539258170421376, 0.1802982434895819, 0.029699252956736255, 0.1698175212971209, 0.005830260095274542, 0.14745468698275288, 0.19746480836723157, 0.13446105354378246, 0.09967478792748241, 0.07833505816293529, 0.15269779794482363, 0.45268479444163545, 0.5319119345612638, 0.546626576734907, 0.44126875791280207, 0.5025545013298822, 0.5354592104587445, 0.4196551063736047, 0.5234676250391219, 0.12273692141825632, 0.07191974353402297, 0.09806815146701575, 0.09619567494706405, 0.08422198221706534, 0.12026437801395262, 0.13537823920063152, 0.09340609578952896, 0.09142444199167621, 0.2332702746507429, 0.27241995959464216, 0.1957548035840323, 0.2063349309423005, 0.27817845243066863, 0.21734473888159278, 0.25442152542739516, 0.16249108820503866, 0.22500289137696772, 0.3998986956725248, 0.30535352907680413, 0.3296205363350502, 0.20220610926671656, 0.2827284569439036, 0.25534122868473264, 0.2946655892546183, 0.2970055562039925, 0.3060993849392212, 0.32430560141483367, 0.20055268899183099, 0.2850729091832519, 0.21721890328931526, 0.17306799810176177, 0.2483118134212422, 0.25163493144047167, 0.2653303535771846, 0.2147623614153482, 0.23218211064824745, 0.15889439410157558, 0.23583622616058975, 0.19456643050425226, 0.16374003000060733, 0.21493953091769757, 0.22054221537976426, 0.21551086822309695, 0.2605374343106197, 0.20524551207598984, 0.20017766387611935, 0.1956276943474855, 0.20925170535343018, 0.20529381795845325, 0.18717220284413394, 0.18325239579642294, 0.18124447326753534, 0.19020501902925402, 0.8543511412457057, 0.16287565456475972, 0.15405114384215246, 0.8756578907995182, 0.19787582061465914, 0.20026239673368584, 0.14145544596878845, 0.1694883974512852, 0.8311271772006908, 0.8798375457660473, 0.2064413052170807, 0.15176246019230422, 0.20538455905359443, 0.566551491210618, 0.1550907979706735, 0.18481181998029672, 0.2089649029133862, 0.8021002040064757, 0.20259835816726113, 0.19294522648278056, 0.19996837239533938, 0.1998521869762372, 0.20039126424010079, 0.20393590761470382, 0.20086099584963946, 0.1904815661262652, 0.1857776711713358, 0.09433641993879316, 0.08015685705731035, 0.0939506345761596, 0.07902897205792137, 0.08872475901441956, 0.08341590190181958, 0.10648938366465865, 0.0730508682253449, 0.08920877147497341]}, "mutation_prompt": null}
{"id": "d17eb00a-9f21-4931-89cf-fdb73a4ad0eb", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            # Bound positions\n            positions = np.clip(positions, self.lb, self.ub)\n\n            # Evaluate new positions\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            # Update personal bests\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Adaptive Differential Mutation\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.8 * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "HybridPSO", "description": "A hybrid particle swarm optimization with adaptive differential mutation balances exploration and exploitation efficiently.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.7192282850284312, 0.5168340857008723, 0.6846234116845872, 0.7473451340670973, 0.44590167675114, 0.7177523085068118, 0.751962615835188, 0.507453929730844, 0.6799256398352029, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19559599127823335, 0.02970441323486883, 0.11096595841071288, 0.14676657223313583, 0.10592460590777997, 0.04040868601545011, 0.06453080512785092, 0.08424129924959067, 0.14482960703394032, 0.12596087772304088, 0.10466414872067453, 0.09968093505935594, 0.09556840093578844, 0.1266707814832938, 0.15451638446824123, 0.08353935794307521, 0.09175091844091166, 0.11577306851162195, 0.0901782479222828, 0.08787258953535615, 0.0874204157768842, 0.07099005862787766, 0.0780027644954967, 0.1049044090573854, 0.986871927128186, 0.9888577568102923, 0.9841395406604165, 0.9587564242849532, 0.9749992231424514, 0.95341883713273, 0.9841826064614492, 0.9812872409200664, 0.9860836591966228, 0.5576772097784908, 0.2570625877476015, 0.05822140105781859, 0.1474555830900901, 0.1358965199793667, 0.23376341712849802, 0.1228635937753374, 0.2437899312263202, 0.39169357696551454, 0.16981736408600845, 0.5845308937910284, 0.22502806129098518, 0.6809418598131833, 0.17742377480503746, 0.20648207784302997, 0.12119005288043228, 0.5053751653460844, 0.7765840935138728, 0.3657576720147365, 0.125415344465879, 0.2121195213452689, 9.999999999998899e-05, 0.09346470551805053, 0.21811899436558302, 9.999999999998899e-05, 0.08964084229928937, 0.3020101709155415, 0.3443706013363482, 0.27705766684041633, 0.2170004528468722, 0.2954439973962145, 0.1586893109740437, 0.2356379836323167, 0.33045513386723446, 0.0868440127340595, 0.12912077732133076, 0.13901453956648457, 9.999999999998899e-05, 0.14004943949646165, 9.999999999998899e-05, 0.0738965864889678, 0.026175443700540924, 0.15205423909024285, 0.07018108820370894, 0.06632390909305708, 0.08495224488071218, 0.06449465292418499, 0.3075521568734839, 0.3063741155163029, 0.04689722871845625, 0.06663968569740863, 0.1809495787193004, 0.0907040919298262, 0.24311920344802007, 0.1823883188788431, 0.026758442389819947, 0.09893975037558755, 0.11005372597709706, 0.09534199086673856, 0.060521173796774796, 0.0703995294946762, 0.06168497185017063, 0.14539258170421376, 0.1802982434895819, 0.029699252956736255, 0.1698175212971209, 0.005830260095274542, 0.14745468698275288, 0.19746480836723157, 0.13446105354378246, 0.09967478792748241, 0.07833505816293529, 0.15269779794482363, 0.45268479444163545, 0.5319119345612638, 0.546626576734907, 0.44126875791280207, 0.5025545013298822, 0.5354592104587445, 0.4196551063736047, 0.5234676250391219, 0.12273692141825632, 0.07191974353402297, 0.09806815146701575, 0.09619567494706405, 0.08422198221706534, 0.12026437801395262, 0.13537823920063152, 0.09340609578952896, 0.09142444199167621, 0.2332702746507429, 0.27241995959464216, 0.1957548035840323, 0.2063349309423005, 0.27817845243066863, 0.21734473888159278, 0.25442152542739516, 0.16249108820503866, 0.22500289137696772, 0.3998986956725248, 0.30535352907680413, 0.3296205363350502, 0.20220610926671656, 0.2827284569439036, 0.25534122868473264, 0.2946655892546183, 0.2970055562039925, 0.3060993849392212, 0.32430560141483367, 0.20055268899183099, 0.2850729091832519, 0.21721890328931526, 0.17306799810176177, 0.2483118134212422, 0.25163493144047167, 0.2653303535771846, 0.2147623614153482, 0.23218211064824745, 0.15889439410157558, 0.23583622616058975, 0.19456643050425226, 0.16374003000060733, 0.21493953091769757, 0.22054221537976426, 0.21551086822309695, 0.2605374343106197, 0.20524551207598984, 0.20017766387611935, 0.1956276943474855, 0.20925170535343018, 0.20529381795845325, 0.18717220284413394, 0.18325239579642294, 0.18124447326753534, 0.19020501902925402, 0.8543511412457057, 0.16287565456475972, 0.15405114384215246, 0.8756578907995182, 0.19787582061465914, 0.20026239673368584, 0.14145544596878845, 0.1694883974512852, 0.8311271772006908, 0.8798375457660473, 0.2064413052170807, 0.15176246019230422, 0.20538455905359443, 0.566551491210618, 0.1550907979706735, 0.18481181998029672, 0.2089649029133862, 0.8021002040064757, 0.20259835816726113, 0.19294522648278056, 0.19996837239533938, 0.1998521869762372, 0.20039126424010079, 0.20393590761470382, 0.20086099584963946, 0.1904815661262652, 0.1857776711713358, 0.09433641993879316, 0.08015685705731035, 0.0939506345761596, 0.07902897205792137, 0.08872475901441956, 0.08341590190181958, 0.10648938366465865, 0.0730508682253449, 0.08920877147497341]}, "mutation_prompt": null}
{"id": "9a3832db-ab18-4f5c-a7e9-935f5229d057", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            # Bound positions\n            positions = np.clip(positions, self.lb, self.ub)\n\n            # Evaluate new positions\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            # Update personal bests\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Adaptive Differential Mutation\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.8 * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "HybridPSO", "description": "A hybrid particle swarm optimization with adaptive differential mutation balances exploration and exploitation efficiently.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.7192282850284312, 0.5168340857008723, 0.6846234116845872, 0.7473451340670973, 0.44590167675114, 0.7177523085068118, 0.751962615835188, 0.507453929730844, 0.6799256398352029, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19559599127823335, 0.02970441323486883, 0.11096595841071288, 0.14676657223313583, 0.10592460590777997, 0.04040868601545011, 0.06453080512785092, 0.08424129924959067, 0.14482960703394032, 0.12596087772304088, 0.10466414872067453, 0.09968093505935594, 0.09556840093578844, 0.1266707814832938, 0.15451638446824123, 0.08353935794307521, 0.09175091844091166, 0.11577306851162195, 0.0901782479222828, 0.08787258953535615, 0.0874204157768842, 0.07099005862787766, 0.0780027644954967, 0.1049044090573854, 0.986871927128186, 0.9888577568102923, 0.9841395406604165, 0.9587564242849532, 0.9749992231424514, 0.95341883713273, 0.9841826064614492, 0.9812872409200664, 0.9860836591966228, 0.5576772097784908, 0.2570625877476015, 0.05822140105781859, 0.1474555830900901, 0.1358965199793667, 0.23376341712849802, 0.1228635937753374, 0.2437899312263202, 0.39169357696551454, 0.16981736408600845, 0.5845308937910284, 0.22502806129098518, 0.6809418598131833, 0.17742377480503746, 0.20648207784302997, 0.12119005288043228, 0.5053751653460844, 0.7765840935138728, 0.3657576720147365, 0.125415344465879, 0.2121195213452689, 9.999999999998899e-05, 0.09346470551805053, 0.21811899436558302, 9.999999999998899e-05, 0.08964084229928937, 0.3020101709155415, 0.3443706013363482, 0.27705766684041633, 0.2170004528468722, 0.2954439973962145, 0.1586893109740437, 0.2356379836323167, 0.33045513386723446, 0.0868440127340595, 0.12912077732133076, 0.13901453956648457, 9.999999999998899e-05, 0.14004943949646165, 9.999999999998899e-05, 0.0738965864889678, 0.026175443700540924, 0.15205423909024285, 0.07018108820370894, 0.06632390909305708, 0.08495224488071218, 0.06449465292418499, 0.3075521568734839, 0.3063741155163029, 0.04689722871845625, 0.06663968569740863, 0.1809495787193004, 0.0907040919298262, 0.24311920344802007, 0.1823883188788431, 0.026758442389819947, 0.09893975037558755, 0.11005372597709706, 0.09534199086673856, 0.060521173796774796, 0.0703995294946762, 0.06168497185017063, 0.14539258170421376, 0.1802982434895819, 0.029699252956736255, 0.1698175212971209, 0.005830260095274542, 0.14745468698275288, 0.19746480836723157, 0.13446105354378246, 0.09967478792748241, 0.07833505816293529, 0.15269779794482363, 0.45268479444163545, 0.5319119345612638, 0.546626576734907, 0.44126875791280207, 0.5025545013298822, 0.5354592104587445, 0.4196551063736047, 0.5234676250391219, 0.12273692141825632, 0.07191974353402297, 0.09806815146701575, 0.09619567494706405, 0.08422198221706534, 0.12026437801395262, 0.13537823920063152, 0.09340609578952896, 0.09142444199167621, 0.2332702746507429, 0.27241995959464216, 0.1957548035840323, 0.2063349309423005, 0.27817845243066863, 0.21734473888159278, 0.25442152542739516, 0.16249108820503866, 0.22500289137696772, 0.3998986956725248, 0.30535352907680413, 0.3296205363350502, 0.20220610926671656, 0.2827284569439036, 0.25534122868473264, 0.2946655892546183, 0.2970055562039925, 0.3060993849392212, 0.32430560141483367, 0.20055268899183099, 0.2850729091832519, 0.21721890328931526, 0.17306799810176177, 0.2483118134212422, 0.25163493144047167, 0.2653303535771846, 0.2147623614153482, 0.23218211064824745, 0.15889439410157558, 0.23583622616058975, 0.19456643050425226, 0.16374003000060733, 0.21493953091769757, 0.22054221537976426, 0.21551086822309695, 0.2605374343106197, 0.20524551207598984, 0.20017766387611935, 0.1956276943474855, 0.20925170535343018, 0.20529381795845325, 0.18717220284413394, 0.18325239579642294, 0.18124447326753534, 0.19020501902925402, 0.8543511412457057, 0.16287565456475972, 0.15405114384215246, 0.8756578907995182, 0.19787582061465914, 0.20026239673368584, 0.14145544596878845, 0.1694883974512852, 0.8311271772006908, 0.8798375457660473, 0.2064413052170807, 0.15176246019230422, 0.20538455905359443, 0.566551491210618, 0.1550907979706735, 0.18481181998029672, 0.2089649029133862, 0.8021002040064757, 0.20259835816726113, 0.19294522648278056, 0.19996837239533938, 0.1998521869762372, 0.20039126424010079, 0.20393590761470382, 0.20086099584963946, 0.1904815661262652, 0.1857776711713358, 0.09433641993879316, 0.08015685705731035, 0.0939506345761596, 0.07902897205792137, 0.08872475901441956, 0.08341590190181958, 0.10648938366465865, 0.0730508682253449, 0.08920877147497341]}, "mutation_prompt": null}
{"id": "e8f54d03-d166-44c0-85f1-99e8744486ba", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            # Bound positions\n            positions = np.clip(positions, self.lb, self.ub)\n\n            # Evaluate new positions\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            # Update personal bests\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Adaptive Differential Mutation\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.8 * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "HybridPSO", "description": "A hybrid particle swarm optimization with adaptive differential mutation balances exploration and exploitation efficiently.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.7192282850284312, 0.5168340857008723, 0.6846234116845872, 0.7473451340670973, 0.44590167675114, 0.7177523085068118, 0.751962615835188, 0.507453929730844, 0.6799256398352029, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19559599127823335, 0.02970441323486883, 0.11096595841071288, 0.14676657223313583, 0.10592460590777997, 0.04040868601545011, 0.06453080512785092, 0.08424129924959067, 0.14482960703394032, 0.12596087772304088, 0.10466414872067453, 0.09968093505935594, 0.09556840093578844, 0.1266707814832938, 0.15451638446824123, 0.08353935794307521, 0.09175091844091166, 0.11577306851162195, 0.0901782479222828, 0.08787258953535615, 0.0874204157768842, 0.07099005862787766, 0.0780027644954967, 0.1049044090573854, 0.986871927128186, 0.9888577568102923, 0.9841395406604165, 0.9587564242849532, 0.9749992231424514, 0.95341883713273, 0.9841826064614492, 0.9812872409200664, 0.9860836591966228, 0.5576772097784908, 0.2570625877476015, 0.05822140105781859, 0.1474555830900901, 0.1358965199793667, 0.23376341712849802, 0.1228635937753374, 0.2437899312263202, 0.39169357696551454, 0.16981736408600845, 0.5845308937910284, 0.22502806129098518, 0.6809418598131833, 0.17742377480503746, 0.20648207784302997, 0.12119005288043228, 0.5053751653460844, 0.7765840935138728, 0.3657576720147365, 0.125415344465879, 0.2121195213452689, 9.999999999998899e-05, 0.09346470551805053, 0.21811899436558302, 9.999999999998899e-05, 0.08964084229928937, 0.3020101709155415, 0.3443706013363482, 0.27705766684041633, 0.2170004528468722, 0.2954439973962145, 0.1586893109740437, 0.2356379836323167, 0.33045513386723446, 0.0868440127340595, 0.12912077732133076, 0.13901453956648457, 9.999999999998899e-05, 0.14004943949646165, 9.999999999998899e-05, 0.0738965864889678, 0.026175443700540924, 0.15205423909024285, 0.07018108820370894, 0.06632390909305708, 0.08495224488071218, 0.06449465292418499, 0.3075521568734839, 0.3063741155163029, 0.04689722871845625, 0.06663968569740863, 0.1809495787193004, 0.0907040919298262, 0.24311920344802007, 0.1823883188788431, 0.026758442389819947, 0.09893975037558755, 0.11005372597709706, 0.09534199086673856, 0.060521173796774796, 0.0703995294946762, 0.06168497185017063, 0.14539258170421376, 0.1802982434895819, 0.029699252956736255, 0.1698175212971209, 0.005830260095274542, 0.14745468698275288, 0.19746480836723157, 0.13446105354378246, 0.09967478792748241, 0.07833505816293529, 0.15269779794482363, 0.45268479444163545, 0.5319119345612638, 0.546626576734907, 0.44126875791280207, 0.5025545013298822, 0.5354592104587445, 0.4196551063736047, 0.5234676250391219, 0.12273692141825632, 0.07191974353402297, 0.09806815146701575, 0.09619567494706405, 0.08422198221706534, 0.12026437801395262, 0.13537823920063152, 0.09340609578952896, 0.09142444199167621, 0.2332702746507429, 0.27241995959464216, 0.1957548035840323, 0.2063349309423005, 0.27817845243066863, 0.21734473888159278, 0.25442152542739516, 0.16249108820503866, 0.22500289137696772, 0.3998986956725248, 0.30535352907680413, 0.3296205363350502, 0.20220610926671656, 0.2827284569439036, 0.25534122868473264, 0.2946655892546183, 0.2970055562039925, 0.3060993849392212, 0.32430560141483367, 0.20055268899183099, 0.2850729091832519, 0.21721890328931526, 0.17306799810176177, 0.2483118134212422, 0.25163493144047167, 0.2653303535771846, 0.2147623614153482, 0.23218211064824745, 0.15889439410157558, 0.23583622616058975, 0.19456643050425226, 0.16374003000060733, 0.21493953091769757, 0.22054221537976426, 0.21551086822309695, 0.2605374343106197, 0.20524551207598984, 0.20017766387611935, 0.1956276943474855, 0.20925170535343018, 0.20529381795845325, 0.18717220284413394, 0.18325239579642294, 0.18124447326753534, 0.19020501902925402, 0.8543511412457057, 0.16287565456475972, 0.15405114384215246, 0.8756578907995182, 0.19787582061465914, 0.20026239673368584, 0.14145544596878845, 0.1694883974512852, 0.8311271772006908, 0.8798375457660473, 0.2064413052170807, 0.15176246019230422, 0.20538455905359443, 0.566551491210618, 0.1550907979706735, 0.18481181998029672, 0.2089649029133862, 0.8021002040064757, 0.20259835816726113, 0.19294522648278056, 0.19996837239533938, 0.1998521869762372, 0.20039126424010079, 0.20393590761470382, 0.20086099584963946, 0.1904815661262652, 0.1857776711713358, 0.09433641993879316, 0.08015685705731035, 0.0939506345761596, 0.07902897205792137, 0.08872475901441956, 0.08341590190181958, 0.10648938366465865, 0.0730508682253449, 0.08920877147497341]}, "mutation_prompt": null}
{"id": "f63f1a3d-f147-4531-9320-6ee4e5c29bb9", "solution": "import numpy as np\n\nclass EnhancedHybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            inertia_decay = (self.max_inertia_weight - self.min_inertia_weight) * (1 - evaluations / self.budget)\n            self.inertia_weight = self.min_inertia_weight + inertia_decay\n\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n            positions = np.clip(positions, self.lb, self.ub)\n            \n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n            \n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.8 * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    chaotic_factor = np.random.uniform(0, 1)\n                    chaotic_mutant = mutant + chaotic_factor * (global_best_position - mutant)\n                    chaotic_mutant = np.clip(chaotic_mutant, self.lb, self.ub)\n\n                    mutant_score = func(mutant)\n                    chaotic_score = func(chaotic_mutant)\n                    evaluations += 2\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n                    if chaotic_score < personal_best_scores[i]:\n                        personal_best_positions[i] = chaotic_mutant\n                        personal_best_scores[i] = chaotic_score\n\n                        if chaotic_score < global_best_score:\n                            global_best_position = chaotic_mutant\n                            global_best_score = chaotic_score\n\n        return global_best_position, global_best_score", "name": "EnhancedHybridPSO", "description": "Enhanced Hybrid PSO with adaptive inertia weight and diversity injection via chaotic maps for faster convergence.", "configspace": "", "generation": 33, "fitness": 0.22299902806282773, "feedback": "The algorithm EnhancedHybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.23.", "error": "", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.6668214527797218, 0.5872406153840712, 0.6430671357541223, 0.6764658676105963, 0.19036996457353805, 0.6094943856809387, 0.6610545272796028, 0.1814476948842636, 0.6663409139552939, 9.999999999998899e-05, 9.999999999998899e-05, 0.12810328571921636, 0.02123106043122569, 0.0370073664393169, 0.0797382168532833, 0.0994396751121116, 0.01780220355385531, 0.01788052141177343, 0.09547017426555027, 0.039421052773608745, 0.08677603783308696, 0.10529591583794484, 0.06454813034335416, 0.08885871400985723, 0.07564011655845393, 0.1119766681267571, 0.13664493935965671, 0.13521158448811788, 0.03369539730668092, 0.11678463663873462, 0.06135670941139837, 0.08008779147113387, 0.09747940392059318, 0.0468483699886465, 0.07474845984555845, 0.0739382956797523, 0.9832849894722588, 0.9853869242733367, 0.9745849369455806, 0.950029710944443, 0.9684077600138051, 0.9535704714100044, 0.985187672498007, 0.9752510136875623, 0.9740701389412434, 0.45486744272763435, 0.05891249282514577, 0.39397267093495936, 0.14734189066501457, 0.14580847376868644, 0.14987536557192305, 0.08307958701752816, 0.08636493006301571, 0.42017238725141415, 0.170628464940781, 0.5666248871039536, 0.6387623499765271, 0.6769053701970918, 0.11677799125862587, 0.18962055159648228, 0.11159698636168491, 0.13609114340128836, 0.22745178116108045, 0.21657906016892525, 0.21141883558591035, 0.09012621876648241, 0.12422897517075393, 0.12236626291285158, 0.2396588823082908, 0.13647019619739043, 0.1535582925911424, 0.3200607254582355, 0.2990926638121565, 0.22217099912162608, 0.1126954551582432, 0.282856441024941, 0.13760613763570695, 0.3416229333280101, 0.06161545707342797, 0.11228693424923875, 0.11262980916639298, 9.999999999998899e-05, 9.999999999998899e-05, 0.03429653145784883, 9.999999999998899e-05, 0.00031411602967712504, 0.03374889193159014, 0.03967259225373221, 0.022703723094268158, 0.1211277960727859, 0.05504265247535545, 0.030087685003608367, 0.05058360306652521, 0.2346761128165451, 0.02625470231897631, 0.052158546342759515, 0.05149393794934476, 0.0446537479178889, 0.0769205845380806, 0.03213351001786868, 0.02793013594465099, 0.06037852482051642, 0.06825267575014038, 0.04392703581250479, 0.046861909224672704, 0.06544908934166338, 0.08026139755772199, 0.2142602296368259, 0.04527438040833154, 9.999999999998899e-05, 0.1251181016091938, 0.1215978218887096, 0.15473588026553475, 0.09569989151575065, 0.21906353642938214, 9.999999999998899e-05, 0.07927461981182693, 0.15252991610647426, 0.4449959474070906, 0.48521557938770643, 0.3781151920040554, 0.14036618293375613, 0.20550239830081451, 0.47174405565257405, 0.13446518027629284, 0.5120995831570857, 0.07998535444168553, 0.06859372276568776, 0.08721291846712087, 0.09902660370765648, 0.05319827255268028, 0.08187043557869178, 0.09305263977291711, 0.08437502925402673, 0.09541274862450788, 0.26448731925383795, 0.15276953233959234, 0.2427523172295578, 0.20042353175372252, 0.24829168906801535, 0.1738412485621451, 0.1924631413179272, 0.2479911234459119, 0.19270006954030383, 0.33715044583296616, 0.16798120251861637, 0.3636991609683634, 0.2742242439616158, 0.19662029461239128, 0.27361533869457955, 0.19826404099325645, 0.3280744036197166, 0.2263829911666484, 0.18990996197419463, 0.14881026309882694, 0.24207068841871038, 0.15734797045464455, 0.18382388033458552, 0.25091148352940174, 0.15622808997336268, 0.20484168712615114, 0.33806493815286276, 0.2109819099752307, 0.13884990648335738, 0.214342961658178, 0.18321735076856915, 0.15373588801352345, 0.20352778320407505, 0.21916386671951926, 0.16608119077995565, 0.21057594422357107, 0.1887662156044908, 0.2062354887806559, 0.18322732184236934, 0.19195809202734104, 0.18976368306247327, 0.18142539603539476, 0.17900061725448813, 0.18776494173745772, 0.3866846487174346, 0.8083693710931333, 0.16846427936305441, 0.15289087011543012, 0.8274625641337623, 0.19937701286058263, 0.2010201288664074, 0.1421322052344154, 0.17020496892601988, 0.8497447776395172, 0.8326050445855092, 0.1689921139396643, 0.1488616882872852, 0.20503152072975384, 0.22570384405818278, 0.14914276555100658, 0.19484937710154793, 0.20883608850965574, 0.6011038182725768, 0.1937205691930124, 0.194278257149612, 0.19959833130483762, 0.20669226096540982, 0.215603899262778, 0.2065606159530109, 0.19699290261888835, 0.17848960801415048, 0.20223938487811888, 0.08815451510566796, 0.08811800166573847, 0.08685662434699137, 0.0719978614864174, 0.06132470216766084, 0.08029644956962279, 0.0934587919818679, 0.06792114625842427, 0.07927376183535839]}, "mutation_prompt": null}
{"id": "ec7187d3-c654-4d1e-aa43-3998a4ed6ab3", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            # Bound positions\n            positions = np.clip(positions, self.lb, self.ub)\n\n            # Evaluate new positions\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            # Update personal bests\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Adaptive Differential Mutation\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.8 * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "HybridPSO", "description": "A hybrid particle swarm optimization with adaptive differential mutation balances exploration and exploitation efficiently.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.7192282850284312, 0.5168340857008723, 0.6846234116845872, 0.7473451340670973, 0.44590167675114, 0.7177523085068118, 0.751962615835188, 0.507453929730844, 0.6799256398352029, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19559599127823335, 0.02970441323486883, 0.11096595841071288, 0.14676657223313583, 0.10592460590777997, 0.04040868601545011, 0.06453080512785092, 0.08424129924959067, 0.14482960703394032, 0.12596087772304088, 0.10466414872067453, 0.09968093505935594, 0.09556840093578844, 0.1266707814832938, 0.15451638446824123, 0.08353935794307521, 0.09175091844091166, 0.11577306851162195, 0.0901782479222828, 0.08787258953535615, 0.0874204157768842, 0.07099005862787766, 0.0780027644954967, 0.1049044090573854, 0.986871927128186, 0.9888577568102923, 0.9841395406604165, 0.9587564242849532, 0.9749992231424514, 0.95341883713273, 0.9841826064614492, 0.9812872409200664, 0.9860836591966228, 0.5576772097784908, 0.2570625877476015, 0.05822140105781859, 0.1474555830900901, 0.1358965199793667, 0.23376341712849802, 0.1228635937753374, 0.2437899312263202, 0.39169357696551454, 0.16981736408600845, 0.5845308937910284, 0.22502806129098518, 0.6809418598131833, 0.17742377480503746, 0.20648207784302997, 0.12119005288043228, 0.5053751653460844, 0.7765840935138728, 0.3657576720147365, 0.125415344465879, 0.2121195213452689, 9.999999999998899e-05, 0.09346470551805053, 0.21811899436558302, 9.999999999998899e-05, 0.08964084229928937, 0.3020101709155415, 0.3443706013363482, 0.27705766684041633, 0.2170004528468722, 0.2954439973962145, 0.1586893109740437, 0.2356379836323167, 0.33045513386723446, 0.0868440127340595, 0.12912077732133076, 0.13901453956648457, 9.999999999998899e-05, 0.14004943949646165, 9.999999999998899e-05, 0.0738965864889678, 0.026175443700540924, 0.15205423909024285, 0.07018108820370894, 0.06632390909305708, 0.08495224488071218, 0.06449465292418499, 0.3075521568734839, 0.3063741155163029, 0.04689722871845625, 0.06663968569740863, 0.1809495787193004, 0.0907040919298262, 0.24311920344802007, 0.1823883188788431, 0.026758442389819947, 0.09893975037558755, 0.11005372597709706, 0.09534199086673856, 0.060521173796774796, 0.0703995294946762, 0.06168497185017063, 0.14539258170421376, 0.1802982434895819, 0.029699252956736255, 0.1698175212971209, 0.005830260095274542, 0.14745468698275288, 0.19746480836723157, 0.13446105354378246, 0.09967478792748241, 0.07833505816293529, 0.15269779794482363, 0.45268479444163545, 0.5319119345612638, 0.546626576734907, 0.44126875791280207, 0.5025545013298822, 0.5354592104587445, 0.4196551063736047, 0.5234676250391219, 0.12273692141825632, 0.07191974353402297, 0.09806815146701575, 0.09619567494706405, 0.08422198221706534, 0.12026437801395262, 0.13537823920063152, 0.09340609578952896, 0.09142444199167621, 0.2332702746507429, 0.27241995959464216, 0.1957548035840323, 0.2063349309423005, 0.27817845243066863, 0.21734473888159278, 0.25442152542739516, 0.16249108820503866, 0.22500289137696772, 0.3998986956725248, 0.30535352907680413, 0.3296205363350502, 0.20220610926671656, 0.2827284569439036, 0.25534122868473264, 0.2946655892546183, 0.2970055562039925, 0.3060993849392212, 0.32430560141483367, 0.20055268899183099, 0.2850729091832519, 0.21721890328931526, 0.17306799810176177, 0.2483118134212422, 0.25163493144047167, 0.2653303535771846, 0.2147623614153482, 0.23218211064824745, 0.15889439410157558, 0.23583622616058975, 0.19456643050425226, 0.16374003000060733, 0.21493953091769757, 0.22054221537976426, 0.21551086822309695, 0.2605374343106197, 0.20524551207598984, 0.20017766387611935, 0.1956276943474855, 0.20925170535343018, 0.20529381795845325, 0.18717220284413394, 0.18325239579642294, 0.18124447326753534, 0.19020501902925402, 0.8543511412457057, 0.16287565456475972, 0.15405114384215246, 0.8756578907995182, 0.19787582061465914, 0.20026239673368584, 0.14145544596878845, 0.1694883974512852, 0.8311271772006908, 0.8798375457660473, 0.2064413052170807, 0.15176246019230422, 0.20538455905359443, 0.566551491210618, 0.1550907979706735, 0.18481181998029672, 0.2089649029133862, 0.8021002040064757, 0.20259835816726113, 0.19294522648278056, 0.19996837239533938, 0.1998521869762372, 0.20039126424010079, 0.20393590761470382, 0.20086099584963946, 0.1904815661262652, 0.1857776711713358, 0.09433641993879316, 0.08015685705731035, 0.0939506345761596, 0.07902897205792137, 0.08872475901441956, 0.08341590190181958, 0.10648938366465865, 0.0730508682253449, 0.08920877147497341]}, "mutation_prompt": null}
{"id": "10e37d99-0646-46e0-8730-19203934877f", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            # Bound positions\n            positions = np.clip(positions, self.lb, self.ub)\n\n            # Evaluate new positions\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            # Update personal bests\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Adaptive Differential Mutation\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.8 * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "HybridPSO", "description": "A hybrid particle swarm optimization with adaptive differential mutation balances exploration and exploitation efficiently.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.7192282850284312, 0.5168340857008723, 0.6846234116845872, 0.7473451340670973, 0.44590167675114, 0.7177523085068118, 0.751962615835188, 0.507453929730844, 0.6799256398352029, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19559599127823335, 0.02970441323486883, 0.11096595841071288, 0.14676657223313583, 0.10592460590777997, 0.04040868601545011, 0.06453080512785092, 0.08424129924959067, 0.14482960703394032, 0.12596087772304088, 0.10466414872067453, 0.09968093505935594, 0.09556840093578844, 0.1266707814832938, 0.15451638446824123, 0.08353935794307521, 0.09175091844091166, 0.11577306851162195, 0.0901782479222828, 0.08787258953535615, 0.0874204157768842, 0.07099005862787766, 0.0780027644954967, 0.1049044090573854, 0.986871927128186, 0.9888577568102923, 0.9841395406604165, 0.9587564242849532, 0.9749992231424514, 0.95341883713273, 0.9841826064614492, 0.9812872409200664, 0.9860836591966228, 0.5576772097784908, 0.2570625877476015, 0.05822140105781859, 0.1474555830900901, 0.1358965199793667, 0.23376341712849802, 0.1228635937753374, 0.2437899312263202, 0.39169357696551454, 0.16981736408600845, 0.5845308937910284, 0.22502806129098518, 0.6809418598131833, 0.17742377480503746, 0.20648207784302997, 0.12119005288043228, 0.5053751653460844, 0.7765840935138728, 0.3657576720147365, 0.125415344465879, 0.2121195213452689, 9.999999999998899e-05, 0.09346470551805053, 0.21811899436558302, 9.999999999998899e-05, 0.08964084229928937, 0.3020101709155415, 0.3443706013363482, 0.27705766684041633, 0.2170004528468722, 0.2954439973962145, 0.1586893109740437, 0.2356379836323167, 0.33045513386723446, 0.0868440127340595, 0.12912077732133076, 0.13901453956648457, 9.999999999998899e-05, 0.14004943949646165, 9.999999999998899e-05, 0.0738965864889678, 0.026175443700540924, 0.15205423909024285, 0.07018108820370894, 0.06632390909305708, 0.08495224488071218, 0.06449465292418499, 0.3075521568734839, 0.3063741155163029, 0.04689722871845625, 0.06663968569740863, 0.1809495787193004, 0.0907040919298262, 0.24311920344802007, 0.1823883188788431, 0.026758442389819947, 0.09893975037558755, 0.11005372597709706, 0.09534199086673856, 0.060521173796774796, 0.0703995294946762, 0.06168497185017063, 0.14539258170421376, 0.1802982434895819, 0.029699252956736255, 0.1698175212971209, 0.005830260095274542, 0.14745468698275288, 0.19746480836723157, 0.13446105354378246, 0.09967478792748241, 0.07833505816293529, 0.15269779794482363, 0.45268479444163545, 0.5319119345612638, 0.546626576734907, 0.44126875791280207, 0.5025545013298822, 0.5354592104587445, 0.4196551063736047, 0.5234676250391219, 0.12273692141825632, 0.07191974353402297, 0.09806815146701575, 0.09619567494706405, 0.08422198221706534, 0.12026437801395262, 0.13537823920063152, 0.09340609578952896, 0.09142444199167621, 0.2332702746507429, 0.27241995959464216, 0.1957548035840323, 0.2063349309423005, 0.27817845243066863, 0.21734473888159278, 0.25442152542739516, 0.16249108820503866, 0.22500289137696772, 0.3998986956725248, 0.30535352907680413, 0.3296205363350502, 0.20220610926671656, 0.2827284569439036, 0.25534122868473264, 0.2946655892546183, 0.2970055562039925, 0.3060993849392212, 0.32430560141483367, 0.20055268899183099, 0.2850729091832519, 0.21721890328931526, 0.17306799810176177, 0.2483118134212422, 0.25163493144047167, 0.2653303535771846, 0.2147623614153482, 0.23218211064824745, 0.15889439410157558, 0.23583622616058975, 0.19456643050425226, 0.16374003000060733, 0.21493953091769757, 0.22054221537976426, 0.21551086822309695, 0.2605374343106197, 0.20524551207598984, 0.20017766387611935, 0.1956276943474855, 0.20925170535343018, 0.20529381795845325, 0.18717220284413394, 0.18325239579642294, 0.18124447326753534, 0.19020501902925402, 0.8543511412457057, 0.16287565456475972, 0.15405114384215246, 0.8756578907995182, 0.19787582061465914, 0.20026239673368584, 0.14145544596878845, 0.1694883974512852, 0.8311271772006908, 0.8798375457660473, 0.2064413052170807, 0.15176246019230422, 0.20538455905359443, 0.566551491210618, 0.1550907979706735, 0.18481181998029672, 0.2089649029133862, 0.8021002040064757, 0.20259835816726113, 0.19294522648278056, 0.19996837239533938, 0.1998521869762372, 0.20039126424010079, 0.20393590761470382, 0.20086099584963946, 0.1904815661262652, 0.1857776711713358, 0.09433641993879316, 0.08015685705731035, 0.0939506345761596, 0.07902897205792137, 0.08872475901441956, 0.08341590190181958, 0.10648938366465865, 0.0730508682253449, 0.08920877147497341]}, "mutation_prompt": null}
{"id": "d09e24e1-40d7-491a-b295-788509616f72", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            # Bound positions\n            positions = np.clip(positions, self.lb, self.ub)\n\n            # Evaluate new positions\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            # Update personal bests\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Adaptive Differential Mutation\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.8 * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "HybridPSO", "description": "A hybrid particle swarm optimization with adaptive differential mutation balances exploration and exploitation efficiently.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.7192282850284312, 0.5168340857008723, 0.6846234116845872, 0.7473451340670973, 0.44590167675114, 0.7177523085068118, 0.751962615835188, 0.507453929730844, 0.6799256398352029, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19559599127823335, 0.02970441323486883, 0.11096595841071288, 0.14676657223313583, 0.10592460590777997, 0.04040868601545011, 0.06453080512785092, 0.08424129924959067, 0.14482960703394032, 0.12596087772304088, 0.10466414872067453, 0.09968093505935594, 0.09556840093578844, 0.1266707814832938, 0.15451638446824123, 0.08353935794307521, 0.09175091844091166, 0.11577306851162195, 0.0901782479222828, 0.08787258953535615, 0.0874204157768842, 0.07099005862787766, 0.0780027644954967, 0.1049044090573854, 0.986871927128186, 0.9888577568102923, 0.9841395406604165, 0.9587564242849532, 0.9749992231424514, 0.95341883713273, 0.9841826064614492, 0.9812872409200664, 0.9860836591966228, 0.5576772097784908, 0.2570625877476015, 0.05822140105781859, 0.1474555830900901, 0.1358965199793667, 0.23376341712849802, 0.1228635937753374, 0.2437899312263202, 0.39169357696551454, 0.16981736408600845, 0.5845308937910284, 0.22502806129098518, 0.6809418598131833, 0.17742377480503746, 0.20648207784302997, 0.12119005288043228, 0.5053751653460844, 0.7765840935138728, 0.3657576720147365, 0.125415344465879, 0.2121195213452689, 9.999999999998899e-05, 0.09346470551805053, 0.21811899436558302, 9.999999999998899e-05, 0.08964084229928937, 0.3020101709155415, 0.3443706013363482, 0.27705766684041633, 0.2170004528468722, 0.2954439973962145, 0.1586893109740437, 0.2356379836323167, 0.33045513386723446, 0.0868440127340595, 0.12912077732133076, 0.13901453956648457, 9.999999999998899e-05, 0.14004943949646165, 9.999999999998899e-05, 0.0738965864889678, 0.026175443700540924, 0.15205423909024285, 0.07018108820370894, 0.06632390909305708, 0.08495224488071218, 0.06449465292418499, 0.3075521568734839, 0.3063741155163029, 0.04689722871845625, 0.06663968569740863, 0.1809495787193004, 0.0907040919298262, 0.24311920344802007, 0.1823883188788431, 0.026758442389819947, 0.09893975037558755, 0.11005372597709706, 0.09534199086673856, 0.060521173796774796, 0.0703995294946762, 0.06168497185017063, 0.14539258170421376, 0.1802982434895819, 0.029699252956736255, 0.1698175212971209, 0.005830260095274542, 0.14745468698275288, 0.19746480836723157, 0.13446105354378246, 0.09967478792748241, 0.07833505816293529, 0.15269779794482363, 0.45268479444163545, 0.5319119345612638, 0.546626576734907, 0.44126875791280207, 0.5025545013298822, 0.5354592104587445, 0.4196551063736047, 0.5234676250391219, 0.12273692141825632, 0.07191974353402297, 0.09806815146701575, 0.09619567494706405, 0.08422198221706534, 0.12026437801395262, 0.13537823920063152, 0.09340609578952896, 0.09142444199167621, 0.2332702746507429, 0.27241995959464216, 0.1957548035840323, 0.2063349309423005, 0.27817845243066863, 0.21734473888159278, 0.25442152542739516, 0.16249108820503866, 0.22500289137696772, 0.3998986956725248, 0.30535352907680413, 0.3296205363350502, 0.20220610926671656, 0.2827284569439036, 0.25534122868473264, 0.2946655892546183, 0.2970055562039925, 0.3060993849392212, 0.32430560141483367, 0.20055268899183099, 0.2850729091832519, 0.21721890328931526, 0.17306799810176177, 0.2483118134212422, 0.25163493144047167, 0.2653303535771846, 0.2147623614153482, 0.23218211064824745, 0.15889439410157558, 0.23583622616058975, 0.19456643050425226, 0.16374003000060733, 0.21493953091769757, 0.22054221537976426, 0.21551086822309695, 0.2605374343106197, 0.20524551207598984, 0.20017766387611935, 0.1956276943474855, 0.20925170535343018, 0.20529381795845325, 0.18717220284413394, 0.18325239579642294, 0.18124447326753534, 0.19020501902925402, 0.8543511412457057, 0.16287565456475972, 0.15405114384215246, 0.8756578907995182, 0.19787582061465914, 0.20026239673368584, 0.14145544596878845, 0.1694883974512852, 0.8311271772006908, 0.8798375457660473, 0.2064413052170807, 0.15176246019230422, 0.20538455905359443, 0.566551491210618, 0.1550907979706735, 0.18481181998029672, 0.2089649029133862, 0.8021002040064757, 0.20259835816726113, 0.19294522648278056, 0.19996837239533938, 0.1998521869762372, 0.20039126424010079, 0.20393590761470382, 0.20086099584963946, 0.1904815661262652, 0.1857776711713358, 0.09433641993879316, 0.08015685705731035, 0.0939506345761596, 0.07902897205792137, 0.08872475901441956, 0.08341590190181958, 0.10648938366465865, 0.0730508682253449, 0.08920877147497341]}, "mutation_prompt": null}
{"id": "2516280d-3b7e-4770-993e-aeb0e67056ea", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            # Bound positions\n            positions = np.clip(positions, self.lb, self.ub)\n\n            # Evaluate new positions\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            # Update personal bests\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Adaptive Differential Mutation\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.8 * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "HybridPSO", "description": "A hybrid particle swarm optimization with adaptive differential mutation balances exploration and exploitation efficiently.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.7192282850284312, 0.5168340857008723, 0.6846234116845872, 0.7473451340670973, 0.44590167675114, 0.7177523085068118, 0.751962615835188, 0.507453929730844, 0.6799256398352029, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19559599127823335, 0.02970441323486883, 0.11096595841071288, 0.14676657223313583, 0.10592460590777997, 0.04040868601545011, 0.06453080512785092, 0.08424129924959067, 0.14482960703394032, 0.12596087772304088, 0.10466414872067453, 0.09968093505935594, 0.09556840093578844, 0.1266707814832938, 0.15451638446824123, 0.08353935794307521, 0.09175091844091166, 0.11577306851162195, 0.0901782479222828, 0.08787258953535615, 0.0874204157768842, 0.07099005862787766, 0.0780027644954967, 0.1049044090573854, 0.986871927128186, 0.9888577568102923, 0.9841395406604165, 0.9587564242849532, 0.9749992231424514, 0.95341883713273, 0.9841826064614492, 0.9812872409200664, 0.9860836591966228, 0.5576772097784908, 0.2570625877476015, 0.05822140105781859, 0.1474555830900901, 0.1358965199793667, 0.23376341712849802, 0.1228635937753374, 0.2437899312263202, 0.39169357696551454, 0.16981736408600845, 0.5845308937910284, 0.22502806129098518, 0.6809418598131833, 0.17742377480503746, 0.20648207784302997, 0.12119005288043228, 0.5053751653460844, 0.7765840935138728, 0.3657576720147365, 0.125415344465879, 0.2121195213452689, 9.999999999998899e-05, 0.09346470551805053, 0.21811899436558302, 9.999999999998899e-05, 0.08964084229928937, 0.3020101709155415, 0.3443706013363482, 0.27705766684041633, 0.2170004528468722, 0.2954439973962145, 0.1586893109740437, 0.2356379836323167, 0.33045513386723446, 0.0868440127340595, 0.12912077732133076, 0.13901453956648457, 9.999999999998899e-05, 0.14004943949646165, 9.999999999998899e-05, 0.0738965864889678, 0.026175443700540924, 0.15205423909024285, 0.07018108820370894, 0.06632390909305708, 0.08495224488071218, 0.06449465292418499, 0.3075521568734839, 0.3063741155163029, 0.04689722871845625, 0.06663968569740863, 0.1809495787193004, 0.0907040919298262, 0.24311920344802007, 0.1823883188788431, 0.026758442389819947, 0.09893975037558755, 0.11005372597709706, 0.09534199086673856, 0.060521173796774796, 0.0703995294946762, 0.06168497185017063, 0.14539258170421376, 0.1802982434895819, 0.029699252956736255, 0.1698175212971209, 0.005830260095274542, 0.14745468698275288, 0.19746480836723157, 0.13446105354378246, 0.09967478792748241, 0.07833505816293529, 0.15269779794482363, 0.45268479444163545, 0.5319119345612638, 0.546626576734907, 0.44126875791280207, 0.5025545013298822, 0.5354592104587445, 0.4196551063736047, 0.5234676250391219, 0.12273692141825632, 0.07191974353402297, 0.09806815146701575, 0.09619567494706405, 0.08422198221706534, 0.12026437801395262, 0.13537823920063152, 0.09340609578952896, 0.09142444199167621, 0.2332702746507429, 0.27241995959464216, 0.1957548035840323, 0.2063349309423005, 0.27817845243066863, 0.21734473888159278, 0.25442152542739516, 0.16249108820503866, 0.22500289137696772, 0.3998986956725248, 0.30535352907680413, 0.3296205363350502, 0.20220610926671656, 0.2827284569439036, 0.25534122868473264, 0.2946655892546183, 0.2970055562039925, 0.3060993849392212, 0.32430560141483367, 0.20055268899183099, 0.2850729091832519, 0.21721890328931526, 0.17306799810176177, 0.2483118134212422, 0.25163493144047167, 0.2653303535771846, 0.2147623614153482, 0.23218211064824745, 0.15889439410157558, 0.23583622616058975, 0.19456643050425226, 0.16374003000060733, 0.21493953091769757, 0.22054221537976426, 0.21551086822309695, 0.2605374343106197, 0.20524551207598984, 0.20017766387611935, 0.1956276943474855, 0.20925170535343018, 0.20529381795845325, 0.18717220284413394, 0.18325239579642294, 0.18124447326753534, 0.19020501902925402, 0.8543511412457057, 0.16287565456475972, 0.15405114384215246, 0.8756578907995182, 0.19787582061465914, 0.20026239673368584, 0.14145544596878845, 0.1694883974512852, 0.8311271772006908, 0.8798375457660473, 0.2064413052170807, 0.15176246019230422, 0.20538455905359443, 0.566551491210618, 0.1550907979706735, 0.18481181998029672, 0.2089649029133862, 0.8021002040064757, 0.20259835816726113, 0.19294522648278056, 0.19996837239533938, 0.1998521869762372, 0.20039126424010079, 0.20393590761470382, 0.20086099584963946, 0.1904815661262652, 0.1857776711713358, 0.09433641993879316, 0.08015685705731035, 0.0939506345761596, 0.07902897205792137, 0.08872475901441956, 0.08341590190181958, 0.10648938366465865, 0.0730508682253449, 0.08920877147497341]}, "mutation_prompt": null}
{"id": "138641b8-3d35-4381-aed3-b15e32f438fe", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            # Bound positions\n            positions = np.clip(positions, self.lb, self.ub)\n\n            # Evaluate new positions\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            # Update personal bests\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Adaptive Differential Mutation\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.8 * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "HybridPSO", "description": "A hybrid particle swarm optimization with adaptive differential mutation balances exploration and exploitation efficiently.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.7192282850284312, 0.5168340857008723, 0.6846234116845872, 0.7473451340670973, 0.44590167675114, 0.7177523085068118, 0.751962615835188, 0.507453929730844, 0.6799256398352029, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19559599127823335, 0.02970441323486883, 0.11096595841071288, 0.14676657223313583, 0.10592460590777997, 0.04040868601545011, 0.06453080512785092, 0.08424129924959067, 0.14482960703394032, 0.12596087772304088, 0.10466414872067453, 0.09968093505935594, 0.09556840093578844, 0.1266707814832938, 0.15451638446824123, 0.08353935794307521, 0.09175091844091166, 0.11577306851162195, 0.0901782479222828, 0.08787258953535615, 0.0874204157768842, 0.07099005862787766, 0.0780027644954967, 0.1049044090573854, 0.986871927128186, 0.9888577568102923, 0.9841395406604165, 0.9587564242849532, 0.9749992231424514, 0.95341883713273, 0.9841826064614492, 0.9812872409200664, 0.9860836591966228, 0.5576772097784908, 0.2570625877476015, 0.05822140105781859, 0.1474555830900901, 0.1358965199793667, 0.23376341712849802, 0.1228635937753374, 0.2437899312263202, 0.39169357696551454, 0.16981736408600845, 0.5845308937910284, 0.22502806129098518, 0.6809418598131833, 0.17742377480503746, 0.20648207784302997, 0.12119005288043228, 0.5053751653460844, 0.7765840935138728, 0.3657576720147365, 0.125415344465879, 0.2121195213452689, 9.999999999998899e-05, 0.09346470551805053, 0.21811899436558302, 9.999999999998899e-05, 0.08964084229928937, 0.3020101709155415, 0.3443706013363482, 0.27705766684041633, 0.2170004528468722, 0.2954439973962145, 0.1586893109740437, 0.2356379836323167, 0.33045513386723446, 0.0868440127340595, 0.12912077732133076, 0.13901453956648457, 9.999999999998899e-05, 0.14004943949646165, 9.999999999998899e-05, 0.0738965864889678, 0.026175443700540924, 0.15205423909024285, 0.07018108820370894, 0.06632390909305708, 0.08495224488071218, 0.06449465292418499, 0.3075521568734839, 0.3063741155163029, 0.04689722871845625, 0.06663968569740863, 0.1809495787193004, 0.0907040919298262, 0.24311920344802007, 0.1823883188788431, 0.026758442389819947, 0.09893975037558755, 0.11005372597709706, 0.09534199086673856, 0.060521173796774796, 0.0703995294946762, 0.06168497185017063, 0.14539258170421376, 0.1802982434895819, 0.029699252956736255, 0.1698175212971209, 0.005830260095274542, 0.14745468698275288, 0.19746480836723157, 0.13446105354378246, 0.09967478792748241, 0.07833505816293529, 0.15269779794482363, 0.45268479444163545, 0.5319119345612638, 0.546626576734907, 0.44126875791280207, 0.5025545013298822, 0.5354592104587445, 0.4196551063736047, 0.5234676250391219, 0.12273692141825632, 0.07191974353402297, 0.09806815146701575, 0.09619567494706405, 0.08422198221706534, 0.12026437801395262, 0.13537823920063152, 0.09340609578952896, 0.09142444199167621, 0.2332702746507429, 0.27241995959464216, 0.1957548035840323, 0.2063349309423005, 0.27817845243066863, 0.21734473888159278, 0.25442152542739516, 0.16249108820503866, 0.22500289137696772, 0.3998986956725248, 0.30535352907680413, 0.3296205363350502, 0.20220610926671656, 0.2827284569439036, 0.25534122868473264, 0.2946655892546183, 0.2970055562039925, 0.3060993849392212, 0.32430560141483367, 0.20055268899183099, 0.2850729091832519, 0.21721890328931526, 0.17306799810176177, 0.2483118134212422, 0.25163493144047167, 0.2653303535771846, 0.2147623614153482, 0.23218211064824745, 0.15889439410157558, 0.23583622616058975, 0.19456643050425226, 0.16374003000060733, 0.21493953091769757, 0.22054221537976426, 0.21551086822309695, 0.2605374343106197, 0.20524551207598984, 0.20017766387611935, 0.1956276943474855, 0.20925170535343018, 0.20529381795845325, 0.18717220284413394, 0.18325239579642294, 0.18124447326753534, 0.19020501902925402, 0.8543511412457057, 0.16287565456475972, 0.15405114384215246, 0.8756578907995182, 0.19787582061465914, 0.20026239673368584, 0.14145544596878845, 0.1694883974512852, 0.8311271772006908, 0.8798375457660473, 0.2064413052170807, 0.15176246019230422, 0.20538455905359443, 0.566551491210618, 0.1550907979706735, 0.18481181998029672, 0.2089649029133862, 0.8021002040064757, 0.20259835816726113, 0.19294522648278056, 0.19996837239533938, 0.1998521869762372, 0.20039126424010079, 0.20393590761470382, 0.20086099584963946, 0.1904815661262652, 0.1857776711713358, 0.09433641993879316, 0.08015685705731035, 0.0939506345761596, 0.07902897205792137, 0.08872475901441956, 0.08341590190181958, 0.10648938366465865, 0.0730508682253449, 0.08920877147497341]}, "mutation_prompt": null}
{"id": "f6ccd04a-7cc1-45ae-b080-a116ed72e58f", "solution": "import numpy as np\n\nclass EnhancedHybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.5  # Decreased for faster convergence\n        self.cognitive_weight = 2.0  # Increased to emphasize personal experience\n        self.social_weight = 2.0  # Increased to enhance global cooperation\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        adaptive_lr = self.swarm_size  # Adaptive learning rate\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.9 * (x2 - x3)  # Increased factor for mutation\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    \n                    if np.random.rand() < 0.3:  # Local search with 30% probability\n                        local_search = mutant + np.random.normal(0, 0.1, self.dim)\n                        local_search = np.clip(local_search, self.lb, self.ub)\n                        mutant = local_search\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "EnhancedHybridPSO", "description": "Enhanced PSO with adaptive learning rates and local search to improve convergence speed.", "configspace": "", "generation": 39, "fitness": 0.27020419657112593, "feedback": "The algorithm EnhancedHybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.25.", "error": "", "parent_id": "02b8102b-9573-42d2-8ecc-cbcd0f73a93e", "metadata": {"aucs": [0.7171957053835964, 0.780137486347676, 0.6827151408603582, 0.6984922152642317, 0.7375113977089538, 0.766589172336417, 0.6931197341148846, 0.7738539845835767, 0.6620244474088419, 0.03257239363993303, 0.3417443079218486, 0.03633744007525308, 0.22615897477208968, 0.2993945097010785, 0.174169900923422, 0.1291479641445692, 0.20978274175446643, 0.034346437681954, 0.060882731728882034, 0.0995717315555259, 0.10204488502353093, 0.11138366837828417, 0.10541464751250551, 0.12180860209597488, 0.088358241994832, 0.10735596214791387, 0.06928203732424376, 0.09925037935589409, 0.04677656080572157, 0.08778513074062211, 0.09914953989939035, 0.08455399844447531, 0.11079923655501644, 0.10609433664542745, 0.05463417667899484, 0.09342165127832702, 0.989474310161318, 0.9895248236654537, 0.9829283463117212, 0.9825396314616374, 0.9818847345417261, 0.9669790489006388, 0.9894590329462951, 0.9878259088542194, 0.974382893305813, 0.4923486231827021, 0.37891171835291737, 0.4310409114979158, 0.3631119988941015, 0.4237010538714788, 0.3649962551267265, 0.439988536632679, 0.33207258210884516, 0.4240549089814948, 0.1720715629635925, 0.5511137154300236, 0.7632220055640622, 0.19401409638729783, 0.11647614996803202, 0.6191101725685184, 0.11565168402689219, 0.1472745000802077, 0.7382753601443569, 0.37811215689742406, 0.4101839123948977, 0.20377518297361785, 0.20819954455200307, 0.20177894228779136, 0.2592422735930029, 0.2923985608427342, 0.12074488299600128, 0.2225819645991748, 0.1355869523217238, 0.19983985327802156, 0.10742731802734051, 0.3004629885926129, 0.1255260582155161, 0.3117991802340837, 0.08370039405236462, 0.1513497984618014, 0.10819192282952028, 0.06234995318571401, 0.019066754000251818, 0.023632723852008763, 0.0005658451976636725, 0.032834875455656776, 0.08284419283150024, 0.23089127064630455, 0.006619566738323424, 0.12097614769757858, 0.1626031923319291, 0.06153321725245553, 0.18314135911563678, 0.23119285368730658, 0.008295037422650586, 0.04921324062047483, 0.11371949608153753, 0.07295530962541374, 0.11060295565606926, 0.03540267091134086, 0.039696935172835346, 0.0441281391529208, 0.1857279188197989, 0.0827403371036387, 0.06291431610762743, 0.07311190169265613, 0.09002275521396974, 0.07924700418505637, 0.05735368128555307, 0.05665705719494507, 0.24448427401834583, 0.22997797030237654, 0.23805335278113904, 0.2726629654485786, 0.05911457383305274, 0.13542072108794634, 0.07819503206598999, 0.6091542510560617, 0.6179659305122197, 0.5867874279577181, 0.6393757971903844, 0.4693118479981404, 0.5096041168517684, 0.6115279863530605, 0.6207021857061341, 0.5785845343262308, 0.05927275827856848, 0.07602933482521834, 0.08164278298810457, 0.0712868143569505, 0.08789339776338057, 0.16790667119578562, 0.07357860287302154, 0.08544322986685571, 0.12909243545054505, 0.252944871765195, 0.2070958768819685, 0.20745179213720766, 0.21159593717600045, 0.2576930231919571, 0.17223438724005724, 0.12965901138298364, 0.14712745136996896, 0.2107835870438718, 0.16976722260033872, 0.3364008527655141, 0.3909742676870488, 0.4132521890048866, 0.37408895914531026, 0.22352042658221594, 0.2047566825200171, 0.28163304128538424, 0.1938998904274536, 0.12197147167106581, 0.17435240104105, 0.25364409749048167, 0.27213329208829773, 0.19416030687939556, 0.2356430035430096, 0.2840059881450433, 0.28592694317017453, 0.291159946550418, 0.24286363079631412, 0.1368478022040326, 0.20423629734683924, 0.18697767459664882, 0.15478347530712722, 0.20113568547095373, 0.2039497103660124, 0.2220975707356071, 0.19689795386068543, 0.179657640170784, 0.19305290759791116, 0.19089329616914452, 0.19636708691118288, 0.21298661768998128, 0.19307283107254147, 0.20859625151888972, 0.1946566801667483, 0.18842495199187492, 0.8245709667566778, 0.1624860843876642, 0.15221100965343248, 0.8301456682659993, 0.18620171383534556, 0.1980846120401154, 0.14238183694580564, 0.1664848827188412, 0.2121238631228145, 0.8078478963481868, 0.20728343102491587, 0.7859679051714352, 0.20632771855555776, 0.667248979883264, 0.14471989761353377, 0.2080063564378758, 0.211196191207509, 0.716523800533237, 0.1938097579608279, 0.2114878352972962, 0.191720329451191, 0.19133405927113367, 0.19624784725392808, 0.1842017466785434, 0.19998052801159072, 0.19689251272469488, 0.179282088973875, 0.07730765922364158, 0.07835284906745688, 0.08225262965277447, 0.06486802326601415, 0.09141104167414704, 0.053629566615639335, 0.07259160383769991, 0.07574880066806922, 0.0974921512774739]}, "mutation_prompt": null}
{"id": "1d57dfe3-b148-4c67-bc97-906f5d4ceca2", "solution": "import numpy as np\n\nclass EnhancedHybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.5  # Decreased for faster convergence\n        self.cognitive_weight = 2.0  # Increased to emphasize personal experience\n        self.social_weight = 2.0  # Increased to enhance global cooperation\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        adaptive_lr = self.swarm_size  # Adaptive learning rate\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.9 * (x2 - x3)  # Increased factor for mutation\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    \n                    if np.random.rand() < 0.3:  # Local search with 30% probability\n                        local_search = mutant + np.random.normal(0, 0.1, self.dim)\n                        local_search = np.clip(local_search, self.lb, self.ub)\n                        mutant = local_search\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "EnhancedHybridPSO", "description": "Enhanced PSO with adaptive learning rates and local search to improve convergence speed.", "configspace": "", "generation": 40, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "f6ccd04a-7cc1-45ae-b080-a116ed72e58f", "metadata": {"aucs": [0.7171957053835964, 0.780137486347676, 0.6827151408603582, 0.6984922152642317, 0.7375113977089538, 0.766589172336417, 0.6931197341148846, 0.7738539845835767, 0.6620244474088419, 0.03257239363993303, 0.3417443079218486, 0.03633744007525308, 0.22615897477208968, 0.2993945097010785, 0.174169900923422, 0.1291479641445692, 0.20978274175446643, 0.034346437681954, 0.060882731728882034, 0.0995717315555259, 0.10204488502353093, 0.11138366837828417, 0.10541464751250551, 0.12180860209597488, 0.088358241994832, 0.10735596214791387, 0.06928203732424376, 0.09925037935589409, 0.04677656080572157, 0.08778513074062211, 0.09914953989939035, 0.08455399844447531, 0.11079923655501644, 0.10609433664542745, 0.05463417667899484, 0.09342165127832702, 0.989474310161318, 0.9895248236654537, 0.9829283463117212, 0.9825396314616374, 0.9818847345417261, 0.9669790489006388, 0.9894590329462951, 0.9878259088542194, 0.974382893305813, 0.4923486231827021, 0.37891171835291737, 0.4310409114979158, 0.3631119988941015, 0.4237010538714788, 0.3649962551267265, 0.439988536632679, 0.33207258210884516, 0.4240549089814948, 0.1720715629635925, 0.5511137154300236, 0.7632220055640622, 0.19401409638729783, 0.11647614996803202, 0.6191101725685184, 0.11565168402689219, 0.1472745000802077, 0.7382753601443569, 0.37811215689742406, 0.4101839123948977, 0.20377518297361785, 0.20819954455200307, 0.20177894228779136, 0.2592422735930029, 0.2923985608427342, 0.12074488299600128, 0.2225819645991748, 0.1355869523217238, 0.19983985327802156, 0.10742731802734051, 0.3004629885926129, 0.1255260582155161, 0.3117991802340837, 0.08370039405236462, 0.1513497984618014, 0.10819192282952028, 0.06234995318571401, 0.019066754000251818, 0.023632723852008763, 0.0005658451976636725, 0.032834875455656776, 0.08284419283150024, 0.23089127064630455, 0.006619566738323424, 0.12097614769757858, 0.1626031923319291, 0.06153321725245553, 0.18314135911563678, 0.23119285368730658, 0.008295037422650586, 0.04921324062047483, 0.11371949608153753, 0.07295530962541374, 0.11060295565606926, 0.03540267091134086, 0.039696935172835346, 0.0441281391529208, 0.1857279188197989, 0.0827403371036387, 0.06291431610762743, 0.07311190169265613, 0.09002275521396974, 0.07924700418505637, 0.05735368128555307, 0.05665705719494507, 0.24448427401834583, 0.22997797030237654, 0.23805335278113904, 0.2726629654485786, 0.05911457383305274, 0.13542072108794634, 0.07819503206598999, 0.6091542510560617, 0.6179659305122197, 0.5867874279577181, 0.6393757971903844, 0.4693118479981404, 0.5096041168517684, 0.6115279863530605, 0.6207021857061341, 0.5785845343262308, 0.05927275827856848, 0.07602933482521834, 0.08164278298810457, 0.0712868143569505, 0.08789339776338057, 0.16790667119578562, 0.07357860287302154, 0.08544322986685571, 0.12909243545054505, 0.252944871765195, 0.2070958768819685, 0.20745179213720766, 0.21159593717600045, 0.2576930231919571, 0.17223438724005724, 0.12965901138298364, 0.14712745136996896, 0.2107835870438718, 0.16976722260033872, 0.3364008527655141, 0.3909742676870488, 0.4132521890048866, 0.37408895914531026, 0.22352042658221594, 0.2047566825200171, 0.28163304128538424, 0.1938998904274536, 0.12197147167106581, 0.17435240104105, 0.25364409749048167, 0.27213329208829773, 0.19416030687939556, 0.2356430035430096, 0.2840059881450433, 0.28592694317017453, 0.291159946550418, 0.24286363079631412, 0.1368478022040326, 0.20423629734683924, 0.18697767459664882, 0.15478347530712722, 0.20113568547095373, 0.2039497103660124, 0.2220975707356071, 0.19689795386068543, 0.179657640170784, 0.19305290759791116, 0.19089329616914452, 0.19636708691118288, 0.21298661768998128, 0.19307283107254147, 0.20859625151888972, 0.1946566801667483, 0.18842495199187492, 0.8245709667566778, 0.1624860843876642, 0.15221100965343248, 0.8301456682659993, 0.18620171383534556, 0.1980846120401154, 0.14238183694580564, 0.1664848827188412, 0.2121238631228145, 0.8078478963481868, 0.20728343102491587, 0.7859679051714352, 0.20632771855555776, 0.667248979883264, 0.14471989761353377, 0.2080063564378758, 0.211196191207509, 0.716523800533237, 0.1938097579608279, 0.2114878352972962, 0.191720329451191, 0.19133405927113367, 0.19624784725392808, 0.1842017466785434, 0.19998052801159072, 0.19689251272469488, 0.179282088973875, 0.07730765922364158, 0.07835284906745688, 0.08225262965277447, 0.06486802326601415, 0.09141104167414704, 0.053629566615639335, 0.07259160383769991, 0.07574880066806922, 0.0974921512774739]}, "mutation_prompt": null}
{"id": "d8cd3f40-b626-4324-b0ad-a00dfef219f9", "solution": "import numpy as np\n\nclass EnhancedHybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.5  # Decreased for faster convergence\n        self.cognitive_weight = 2.0  # Increased to emphasize personal experience\n        self.social_weight = 2.0  # Increased to enhance global cooperation\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        adaptive_lr = self.swarm_size  # Adaptive learning rate\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.9 * (x2 - x3)  # Increased factor for mutation\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    \n                    if np.random.rand() < 0.3:  # Local search with 30% probability\n                        local_search = mutant + np.random.normal(0, 0.1, self.dim)\n                        local_search = np.clip(local_search, self.lb, self.ub)\n                        mutant = local_search\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "EnhancedHybridPSO", "description": "Enhanced PSO with adaptive learning rates and local search to improve convergence speed.", "configspace": "", "generation": 40, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "f6ccd04a-7cc1-45ae-b080-a116ed72e58f", "metadata": {"aucs": [0.7171957053835964, 0.780137486347676, 0.6827151408603582, 0.6984922152642317, 0.7375113977089538, 0.766589172336417, 0.6931197341148846, 0.7738539845835767, 0.6620244474088419, 0.03257239363993303, 0.3417443079218486, 0.03633744007525308, 0.22615897477208968, 0.2993945097010785, 0.174169900923422, 0.1291479641445692, 0.20978274175446643, 0.034346437681954, 0.060882731728882034, 0.0995717315555259, 0.10204488502353093, 0.11138366837828417, 0.10541464751250551, 0.12180860209597488, 0.088358241994832, 0.10735596214791387, 0.06928203732424376, 0.09925037935589409, 0.04677656080572157, 0.08778513074062211, 0.09914953989939035, 0.08455399844447531, 0.11079923655501644, 0.10609433664542745, 0.05463417667899484, 0.09342165127832702, 0.989474310161318, 0.9895248236654537, 0.9829283463117212, 0.9825396314616374, 0.9818847345417261, 0.9669790489006388, 0.9894590329462951, 0.9878259088542194, 0.974382893305813, 0.4923486231827021, 0.37891171835291737, 0.4310409114979158, 0.3631119988941015, 0.4237010538714788, 0.3649962551267265, 0.439988536632679, 0.33207258210884516, 0.4240549089814948, 0.1720715629635925, 0.5511137154300236, 0.7632220055640622, 0.19401409638729783, 0.11647614996803202, 0.6191101725685184, 0.11565168402689219, 0.1472745000802077, 0.7382753601443569, 0.37811215689742406, 0.4101839123948977, 0.20377518297361785, 0.20819954455200307, 0.20177894228779136, 0.2592422735930029, 0.2923985608427342, 0.12074488299600128, 0.2225819645991748, 0.1355869523217238, 0.19983985327802156, 0.10742731802734051, 0.3004629885926129, 0.1255260582155161, 0.3117991802340837, 0.08370039405236462, 0.1513497984618014, 0.10819192282952028, 0.06234995318571401, 0.019066754000251818, 0.023632723852008763, 0.0005658451976636725, 0.032834875455656776, 0.08284419283150024, 0.23089127064630455, 0.006619566738323424, 0.12097614769757858, 0.1626031923319291, 0.06153321725245553, 0.18314135911563678, 0.23119285368730658, 0.008295037422650586, 0.04921324062047483, 0.11371949608153753, 0.07295530962541374, 0.11060295565606926, 0.03540267091134086, 0.039696935172835346, 0.0441281391529208, 0.1857279188197989, 0.0827403371036387, 0.06291431610762743, 0.07311190169265613, 0.09002275521396974, 0.07924700418505637, 0.05735368128555307, 0.05665705719494507, 0.24448427401834583, 0.22997797030237654, 0.23805335278113904, 0.2726629654485786, 0.05911457383305274, 0.13542072108794634, 0.07819503206598999, 0.6091542510560617, 0.6179659305122197, 0.5867874279577181, 0.6393757971903844, 0.4693118479981404, 0.5096041168517684, 0.6115279863530605, 0.6207021857061341, 0.5785845343262308, 0.05927275827856848, 0.07602933482521834, 0.08164278298810457, 0.0712868143569505, 0.08789339776338057, 0.16790667119578562, 0.07357860287302154, 0.08544322986685571, 0.12909243545054505, 0.252944871765195, 0.2070958768819685, 0.20745179213720766, 0.21159593717600045, 0.2576930231919571, 0.17223438724005724, 0.12965901138298364, 0.14712745136996896, 0.2107835870438718, 0.16976722260033872, 0.3364008527655141, 0.3909742676870488, 0.4132521890048866, 0.37408895914531026, 0.22352042658221594, 0.2047566825200171, 0.28163304128538424, 0.1938998904274536, 0.12197147167106581, 0.17435240104105, 0.25364409749048167, 0.27213329208829773, 0.19416030687939556, 0.2356430035430096, 0.2840059881450433, 0.28592694317017453, 0.291159946550418, 0.24286363079631412, 0.1368478022040326, 0.20423629734683924, 0.18697767459664882, 0.15478347530712722, 0.20113568547095373, 0.2039497103660124, 0.2220975707356071, 0.19689795386068543, 0.179657640170784, 0.19305290759791116, 0.19089329616914452, 0.19636708691118288, 0.21298661768998128, 0.19307283107254147, 0.20859625151888972, 0.1946566801667483, 0.18842495199187492, 0.8245709667566778, 0.1624860843876642, 0.15221100965343248, 0.8301456682659993, 0.18620171383534556, 0.1980846120401154, 0.14238183694580564, 0.1664848827188412, 0.2121238631228145, 0.8078478963481868, 0.20728343102491587, 0.7859679051714352, 0.20632771855555776, 0.667248979883264, 0.14471989761353377, 0.2080063564378758, 0.211196191207509, 0.716523800533237, 0.1938097579608279, 0.2114878352972962, 0.191720329451191, 0.19133405927113367, 0.19624784725392808, 0.1842017466785434, 0.19998052801159072, 0.19689251272469488, 0.179282088973875, 0.07730765922364158, 0.07835284906745688, 0.08225262965277447, 0.06486802326601415, 0.09141104167414704, 0.053629566615639335, 0.07259160383769991, 0.07574880066806922, 0.0974921512774739]}, "mutation_prompt": null}
{"id": "c1afff8f-0b11-45ee-ae33-ad7a894b9c96", "solution": "import numpy as np\n\nclass EnhancedHybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.5  # Decreased for faster convergence\n        self.cognitive_weight = 2.0  # Increased to emphasize personal experience\n        self.social_weight = 2.0  # Increased to enhance global cooperation\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        adaptive_lr = self.swarm_size  # Adaptive learning rate\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.9 * (x2 - x3)  # Increased factor for mutation\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    \n                    if np.random.rand() < 0.3:  # Local search with 30% probability\n                        local_search = mutant + np.random.normal(0, 0.1, self.dim)\n                        local_search = np.clip(local_search, self.lb, self.ub)\n                        mutant = local_search\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "EnhancedHybridPSO", "description": "Enhanced PSO with adaptive learning rates and local search to improve convergence speed.", "configspace": "", "generation": 40, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "f6ccd04a-7cc1-45ae-b080-a116ed72e58f", "metadata": {"aucs": [0.7171957053835964, 0.780137486347676, 0.6827151408603582, 0.6984922152642317, 0.7375113977089538, 0.766589172336417, 0.6931197341148846, 0.7738539845835767, 0.6620244474088419, 0.03257239363993303, 0.3417443079218486, 0.03633744007525308, 0.22615897477208968, 0.2993945097010785, 0.174169900923422, 0.1291479641445692, 0.20978274175446643, 0.034346437681954, 0.060882731728882034, 0.0995717315555259, 0.10204488502353093, 0.11138366837828417, 0.10541464751250551, 0.12180860209597488, 0.088358241994832, 0.10735596214791387, 0.06928203732424376, 0.09925037935589409, 0.04677656080572157, 0.08778513074062211, 0.09914953989939035, 0.08455399844447531, 0.11079923655501644, 0.10609433664542745, 0.05463417667899484, 0.09342165127832702, 0.989474310161318, 0.9895248236654537, 0.9829283463117212, 0.9825396314616374, 0.9818847345417261, 0.9669790489006388, 0.9894590329462951, 0.9878259088542194, 0.974382893305813, 0.4923486231827021, 0.37891171835291737, 0.4310409114979158, 0.3631119988941015, 0.4237010538714788, 0.3649962551267265, 0.439988536632679, 0.33207258210884516, 0.4240549089814948, 0.1720715629635925, 0.5511137154300236, 0.7632220055640622, 0.19401409638729783, 0.11647614996803202, 0.6191101725685184, 0.11565168402689219, 0.1472745000802077, 0.7382753601443569, 0.37811215689742406, 0.4101839123948977, 0.20377518297361785, 0.20819954455200307, 0.20177894228779136, 0.2592422735930029, 0.2923985608427342, 0.12074488299600128, 0.2225819645991748, 0.1355869523217238, 0.19983985327802156, 0.10742731802734051, 0.3004629885926129, 0.1255260582155161, 0.3117991802340837, 0.08370039405236462, 0.1513497984618014, 0.10819192282952028, 0.06234995318571401, 0.019066754000251818, 0.023632723852008763, 0.0005658451976636725, 0.032834875455656776, 0.08284419283150024, 0.23089127064630455, 0.006619566738323424, 0.12097614769757858, 0.1626031923319291, 0.06153321725245553, 0.18314135911563678, 0.23119285368730658, 0.008295037422650586, 0.04921324062047483, 0.11371949608153753, 0.07295530962541374, 0.11060295565606926, 0.03540267091134086, 0.039696935172835346, 0.0441281391529208, 0.1857279188197989, 0.0827403371036387, 0.06291431610762743, 0.07311190169265613, 0.09002275521396974, 0.07924700418505637, 0.05735368128555307, 0.05665705719494507, 0.24448427401834583, 0.22997797030237654, 0.23805335278113904, 0.2726629654485786, 0.05911457383305274, 0.13542072108794634, 0.07819503206598999, 0.6091542510560617, 0.6179659305122197, 0.5867874279577181, 0.6393757971903844, 0.4693118479981404, 0.5096041168517684, 0.6115279863530605, 0.6207021857061341, 0.5785845343262308, 0.05927275827856848, 0.07602933482521834, 0.08164278298810457, 0.0712868143569505, 0.08789339776338057, 0.16790667119578562, 0.07357860287302154, 0.08544322986685571, 0.12909243545054505, 0.252944871765195, 0.2070958768819685, 0.20745179213720766, 0.21159593717600045, 0.2576930231919571, 0.17223438724005724, 0.12965901138298364, 0.14712745136996896, 0.2107835870438718, 0.16976722260033872, 0.3364008527655141, 0.3909742676870488, 0.4132521890048866, 0.37408895914531026, 0.22352042658221594, 0.2047566825200171, 0.28163304128538424, 0.1938998904274536, 0.12197147167106581, 0.17435240104105, 0.25364409749048167, 0.27213329208829773, 0.19416030687939556, 0.2356430035430096, 0.2840059881450433, 0.28592694317017453, 0.291159946550418, 0.24286363079631412, 0.1368478022040326, 0.20423629734683924, 0.18697767459664882, 0.15478347530712722, 0.20113568547095373, 0.2039497103660124, 0.2220975707356071, 0.19689795386068543, 0.179657640170784, 0.19305290759791116, 0.19089329616914452, 0.19636708691118288, 0.21298661768998128, 0.19307283107254147, 0.20859625151888972, 0.1946566801667483, 0.18842495199187492, 0.8245709667566778, 0.1624860843876642, 0.15221100965343248, 0.8301456682659993, 0.18620171383534556, 0.1980846120401154, 0.14238183694580564, 0.1664848827188412, 0.2121238631228145, 0.8078478963481868, 0.20728343102491587, 0.7859679051714352, 0.20632771855555776, 0.667248979883264, 0.14471989761353377, 0.2080063564378758, 0.211196191207509, 0.716523800533237, 0.1938097579608279, 0.2114878352972962, 0.191720329451191, 0.19133405927113367, 0.19624784725392808, 0.1842017466785434, 0.19998052801159072, 0.19689251272469488, 0.179282088973875, 0.07730765922364158, 0.07835284906745688, 0.08225262965277447, 0.06486802326601415, 0.09141104167414704, 0.053629566615639335, 0.07259160383769991, 0.07574880066806922, 0.0974921512774739]}, "mutation_prompt": null}
{"id": "8a28e93d-98cc-4103-85a0-b9eba2c26e9c", "solution": "import numpy as np\n\nclass AdaptiveHybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_inertia_weight = 0.9  # Dynamic inertia to act on exploration\n        self.min_inertia_weight = 0.4  # Dynamic inertia to act on exploitation\n        self.cognitive_weight = 1.5  # Balanced between personal and global\n        self.social_weight = 2.5  # Enhanced social influence\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (\n                (self.max_inertia_weight - self.min_inertia_weight) * evaluations / self.budget\n            )\n            r1, r2 = np.random.rand(2)\n            velocities = (inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    F = np.random.uniform(0.5, 1.0)  # Self-adaptive differential weight\n                    mutant = x1 + F * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    if np.random.rand() < 0.4:  # Increased probability for local search\n                        local_search = mutant + np.random.normal(0, 0.05, self.dim)\n                        local_search = np.clip(local_search, self.lb, self.ub)\n                        mutant = local_search\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "AdaptiveHybridPSO", "description": "Hybrid PSO with adaptive dynamic inertia and self-adaptive differential evolution for enhanced exploration and exploitation balance.", "configspace": "", "generation": 43, "fitness": 0.18959696139192667, "feedback": "The algorithm AdaptiveHybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.21.", "error": "", "parent_id": "f6ccd04a-7cc1-45ae-b080-a116ed72e58f", "metadata": {"aucs": [0.483762668454906, 0.3738597893274611, 0.47503137059655953, 0.45047869874644453, 0.3748169646969336, 0.3725616451652135, 0.37946459398208965, 0.4166002067704079, 0.42877283333059535, 0.09091693248421251, 0.010937429744244609, 0.01061128585593818, 0.0005459081647671837, 0.012237592358368743, 0.01624280045295634, 0.008266380745106883, 0.02015872335276292, 0.13225805001004354, 0.08220304975132642, 0.08564386198086271, 0.07651657952787305, 0.09604773499376773, 0.06334348873896145, 0.08881660008882586, 0.08870661928751067, 0.08563332656863953, 0.050975257601319934, 0.1055410518775165, 0.048214628947714444, 0.03548816115077458, 0.06718375711148239, 0.08412787595627647, 0.0780511316077882, 0.03703677817985862, 0.08173434972338878, 0.0721641605434945, 0.9932941465812017, 0.9960513676931961, 0.9891920032860921, 0.9747377870355807, 0.9890858513685397, 0.981647728958958, 0.9923701666767663, 0.9890141774336418, 0.9880044522621344, 0.2518704238325863, 0.11976981279139232, 0.12316258940051705, 0.17995207915904177, 0.14690967495507323, 0.1921365847523171, 0.16197981279324503, 0.13976765100410993, 0.18078989255207545, 0.20186544313260246, 0.3719382485240297, 0.5365727996659122, 0.6095753364441336, 0.11045243729506127, 0.1888407410544688, 0.08565041317675881, 0.3792733646338683, 0.42645204427523065, 0.17278572462626762, 0.15041400447470954, 0.026066939351669816, 0.07704848389803542, 0.11740928335749012, 0.08731809440380278, 0.08425206457088807, 0.06572437797889419, 0.13860383702079726, 0.08703160800487864, 0.07763098508601796, 0.07395969079753373, 0.19382977242788413, 0.03970216870869192, 0.12426552452219986, 0.06630017523544374, 0.05600300486830512, 0.09357502611983104, 0.053348951180679394, 9.999999999998899e-05, 9.999999999998899e-05, 0.007737211460160709, 0.009736547052137445, 0.009784406211345464, 0.04196439951983899, 0.0020991492668650524, 0.031753039094174706, 0.06635423689986986, 0.017829844405930495, 0.0769175981996797, 0.10373591863174514, 0.008123402417170134, 0.016736025941139432, 0.10762852028890668, 0.03359500319986186, 0.034425636745123334, 0.020559079129281455, 0.007638504372931343, 0.02423137402991271, 0.021536226838081873, 0.04194901929609207, 0.03597315165530124, 0.03472415594357248, 0.014189518122809552, 0.05446704962535587, 0.0295527239999005, 0.018425130431186543, 0.015983014016512476, 0.07569077863420481, 0.037977896731064, 0.12336679294403452, 0.03263527930796262, 0.027772285361126192, 0.07117303002445041, 0.26625914117612215, 0.36924706756687664, 0.4196545370984013, 0.32984467523730676, 0.342287290411445, 0.42341902402661213, 0.397258483399633, 0.2505702278545128, 0.40013927489720047, 0.08824351320734802, 0.046903627908506995, 0.07789860304869256, 0.11895015880526805, 0.07713471335191768, 0.08909596875380288, 0.09125650940589147, 0.07217161934545435, 0.09777953653844795, 0.16736832983135608, 0.17390308369177743, 0.1836582078392872, 0.17788089458489031, 0.1738870189866939, 0.302741694565158, 0.16367502518777477, 0.12117104745582108, 0.2335092287494147, 0.18293517361902145, 0.19700851595505509, 0.22361360177070377, 0.19514904441910463, 0.26047703154023205, 0.197831286322251, 0.30193744117224697, 0.24266300591692092, 0.24591689403140837, 0.16189037099356396, 0.06529117753061242, 0.22442615661054477, 0.1982444900588285, 0.13296165902855828, 0.2626828117576301, 0.2222048349342094, 0.18684297726805932, 0.1403303616447169, 0.2000164403813124, 0.16260764381852566, 0.2033671584762684, 0.16752021198736733, 0.15049786645077567, 0.19054523047188487, 0.1777986316281729, 0.16054515265163594, 0.2002206718549432, 0.2931723795205895, 0.16501469143277192, 0.1705288663883342, 0.17949139051142737, 0.17130531529112492, 0.17968571824445967, 0.17365035841066978, 0.16874720473102278, 0.17251597597285073, 0.5219119540269754, 0.16134244340766835, 0.14551693422703083, 0.17097034972388592, 0.17600950330002507, 0.13030187422073158, 0.13581383621095178, 0.1644756875339275, 0.20113660735883343, 0.5216814333546957, 0.19407692564426327, 0.43242263288825755, 0.2217781090517753, 0.3731839928472712, 0.13529971970286403, 0.20444308403748646, 0.20417880413590084, 0.2032619766745395, 0.19597089657355427, 0.1792140632520297, 0.21994990321774188, 0.19948912909035066, 0.20128632371807986, 0.18166949545198963, 0.18764038471099354, 0.1768968104124451, 0.1942571667849854, 0.08433494969055977, 0.06260262421341811, 0.07274724798992083, 0.06767588986224204, 0.07632602417176293, 0.04736783058243599, 0.05571933588088174, 0.068613883204247, 0.07078460273134146]}, "mutation_prompt": null}
{"id": "47780e7a-1864-4399-9fb4-10a301492c83", "solution": "import numpy as np\n\nclass EnhancedHybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.5  # Decreased for faster convergence\n        self.cognitive_weight = 2.0  # Increased to emphasize personal experience\n        self.social_weight = 2.0  # Increased to enhance global cooperation\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        adaptive_lr = self.swarm_size  # Adaptive learning rate\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.9 * (x2 - x3)  # Increased factor for mutation\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    \n                    if np.random.rand() < 0.3:  # Local search with 30% probability\n                        local_search = mutant + np.random.normal(0, 0.1, self.dim)\n                        local_search = np.clip(local_search, self.lb, self.ub)\n                        mutant = local_search\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "EnhancedHybridPSO", "description": "Enhanced PSO with adaptive learning rates and local search to improve convergence speed.", "configspace": "", "generation": 40, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "f6ccd04a-7cc1-45ae-b080-a116ed72e58f", "metadata": {"aucs": [0.7171957053835964, 0.780137486347676, 0.6827151408603582, 0.6984922152642317, 0.7375113977089538, 0.766589172336417, 0.6931197341148846, 0.7738539845835767, 0.6620244474088419, 0.03257239363993303, 0.3417443079218486, 0.03633744007525308, 0.22615897477208968, 0.2993945097010785, 0.174169900923422, 0.1291479641445692, 0.20978274175446643, 0.034346437681954, 0.060882731728882034, 0.0995717315555259, 0.10204488502353093, 0.11138366837828417, 0.10541464751250551, 0.12180860209597488, 0.088358241994832, 0.10735596214791387, 0.06928203732424376, 0.09925037935589409, 0.04677656080572157, 0.08778513074062211, 0.09914953989939035, 0.08455399844447531, 0.11079923655501644, 0.10609433664542745, 0.05463417667899484, 0.09342165127832702, 0.989474310161318, 0.9895248236654537, 0.9829283463117212, 0.9825396314616374, 0.9818847345417261, 0.9669790489006388, 0.9894590329462951, 0.9878259088542194, 0.974382893305813, 0.4923486231827021, 0.37891171835291737, 0.4310409114979158, 0.3631119988941015, 0.4237010538714788, 0.3649962551267265, 0.439988536632679, 0.33207258210884516, 0.4240549089814948, 0.1720715629635925, 0.5511137154300236, 0.7632220055640622, 0.19401409638729783, 0.11647614996803202, 0.6191101725685184, 0.11565168402689219, 0.1472745000802077, 0.7382753601443569, 0.37811215689742406, 0.4101839123948977, 0.20377518297361785, 0.20819954455200307, 0.20177894228779136, 0.2592422735930029, 0.2923985608427342, 0.12074488299600128, 0.2225819645991748, 0.1355869523217238, 0.19983985327802156, 0.10742731802734051, 0.3004629885926129, 0.1255260582155161, 0.3117991802340837, 0.08370039405236462, 0.1513497984618014, 0.10819192282952028, 0.06234995318571401, 0.019066754000251818, 0.023632723852008763, 0.0005658451976636725, 0.032834875455656776, 0.08284419283150024, 0.23089127064630455, 0.006619566738323424, 0.12097614769757858, 0.1626031923319291, 0.06153321725245553, 0.18314135911563678, 0.23119285368730658, 0.008295037422650586, 0.04921324062047483, 0.11371949608153753, 0.07295530962541374, 0.11060295565606926, 0.03540267091134086, 0.039696935172835346, 0.0441281391529208, 0.1857279188197989, 0.0827403371036387, 0.06291431610762743, 0.07311190169265613, 0.09002275521396974, 0.07924700418505637, 0.05735368128555307, 0.05665705719494507, 0.24448427401834583, 0.22997797030237654, 0.23805335278113904, 0.2726629654485786, 0.05911457383305274, 0.13542072108794634, 0.07819503206598999, 0.6091542510560617, 0.6179659305122197, 0.5867874279577181, 0.6393757971903844, 0.4693118479981404, 0.5096041168517684, 0.6115279863530605, 0.6207021857061341, 0.5785845343262308, 0.05927275827856848, 0.07602933482521834, 0.08164278298810457, 0.0712868143569505, 0.08789339776338057, 0.16790667119578562, 0.07357860287302154, 0.08544322986685571, 0.12909243545054505, 0.252944871765195, 0.2070958768819685, 0.20745179213720766, 0.21159593717600045, 0.2576930231919571, 0.17223438724005724, 0.12965901138298364, 0.14712745136996896, 0.2107835870438718, 0.16976722260033872, 0.3364008527655141, 0.3909742676870488, 0.4132521890048866, 0.37408895914531026, 0.22352042658221594, 0.2047566825200171, 0.28163304128538424, 0.1938998904274536, 0.12197147167106581, 0.17435240104105, 0.25364409749048167, 0.27213329208829773, 0.19416030687939556, 0.2356430035430096, 0.2840059881450433, 0.28592694317017453, 0.291159946550418, 0.24286363079631412, 0.1368478022040326, 0.20423629734683924, 0.18697767459664882, 0.15478347530712722, 0.20113568547095373, 0.2039497103660124, 0.2220975707356071, 0.19689795386068543, 0.179657640170784, 0.19305290759791116, 0.19089329616914452, 0.19636708691118288, 0.21298661768998128, 0.19307283107254147, 0.20859625151888972, 0.1946566801667483, 0.18842495199187492, 0.8245709667566778, 0.1624860843876642, 0.15221100965343248, 0.8301456682659993, 0.18620171383534556, 0.1980846120401154, 0.14238183694580564, 0.1664848827188412, 0.2121238631228145, 0.8078478963481868, 0.20728343102491587, 0.7859679051714352, 0.20632771855555776, 0.667248979883264, 0.14471989761353377, 0.2080063564378758, 0.211196191207509, 0.716523800533237, 0.1938097579608279, 0.2114878352972962, 0.191720329451191, 0.19133405927113367, 0.19624784725392808, 0.1842017466785434, 0.19998052801159072, 0.19689251272469488, 0.179282088973875, 0.07730765922364158, 0.07835284906745688, 0.08225262965277447, 0.06486802326601415, 0.09141104167414704, 0.053629566615639335, 0.07259160383769991, 0.07574880066806922, 0.0974921512774739]}, "mutation_prompt": null}
{"id": "bb11ce4c-11d1-48ae-969f-0b340d3d5a93", "solution": "import numpy as np\n\nclass EnhancedHybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.5  # Decreased for faster convergence\n        self.cognitive_weight = 2.0  # Increased to emphasize personal experience\n        self.social_weight = 2.0  # Increased to enhance global cooperation\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        adaptive_lr = self.swarm_size  # Adaptive learning rate\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.9 * (x2 - x3)  # Increased factor for mutation\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    \n                    if np.random.rand() < 0.3:  # Local search with 30% probability\n                        local_search = mutant + np.random.normal(0, 0.1, self.dim)\n                        local_search = np.clip(local_search, self.lb, self.ub)\n                        mutant = local_search\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "EnhancedHybridPSO", "description": "Enhanced PSO with adaptive learning rates and local search to improve convergence speed.", "configspace": "", "generation": 40, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "f6ccd04a-7cc1-45ae-b080-a116ed72e58f", "metadata": {"aucs": [0.7171957053835964, 0.780137486347676, 0.6827151408603582, 0.6984922152642317, 0.7375113977089538, 0.766589172336417, 0.6931197341148846, 0.7738539845835767, 0.6620244474088419, 0.03257239363993303, 0.3417443079218486, 0.03633744007525308, 0.22615897477208968, 0.2993945097010785, 0.174169900923422, 0.1291479641445692, 0.20978274175446643, 0.034346437681954, 0.060882731728882034, 0.0995717315555259, 0.10204488502353093, 0.11138366837828417, 0.10541464751250551, 0.12180860209597488, 0.088358241994832, 0.10735596214791387, 0.06928203732424376, 0.09925037935589409, 0.04677656080572157, 0.08778513074062211, 0.09914953989939035, 0.08455399844447531, 0.11079923655501644, 0.10609433664542745, 0.05463417667899484, 0.09342165127832702, 0.989474310161318, 0.9895248236654537, 0.9829283463117212, 0.9825396314616374, 0.9818847345417261, 0.9669790489006388, 0.9894590329462951, 0.9878259088542194, 0.974382893305813, 0.4923486231827021, 0.37891171835291737, 0.4310409114979158, 0.3631119988941015, 0.4237010538714788, 0.3649962551267265, 0.439988536632679, 0.33207258210884516, 0.4240549089814948, 0.1720715629635925, 0.5511137154300236, 0.7632220055640622, 0.19401409638729783, 0.11647614996803202, 0.6191101725685184, 0.11565168402689219, 0.1472745000802077, 0.7382753601443569, 0.37811215689742406, 0.4101839123948977, 0.20377518297361785, 0.20819954455200307, 0.20177894228779136, 0.2592422735930029, 0.2923985608427342, 0.12074488299600128, 0.2225819645991748, 0.1355869523217238, 0.19983985327802156, 0.10742731802734051, 0.3004629885926129, 0.1255260582155161, 0.3117991802340837, 0.08370039405236462, 0.1513497984618014, 0.10819192282952028, 0.06234995318571401, 0.019066754000251818, 0.023632723852008763, 0.0005658451976636725, 0.032834875455656776, 0.08284419283150024, 0.23089127064630455, 0.006619566738323424, 0.12097614769757858, 0.1626031923319291, 0.06153321725245553, 0.18314135911563678, 0.23119285368730658, 0.008295037422650586, 0.04921324062047483, 0.11371949608153753, 0.07295530962541374, 0.11060295565606926, 0.03540267091134086, 0.039696935172835346, 0.0441281391529208, 0.1857279188197989, 0.0827403371036387, 0.06291431610762743, 0.07311190169265613, 0.09002275521396974, 0.07924700418505637, 0.05735368128555307, 0.05665705719494507, 0.24448427401834583, 0.22997797030237654, 0.23805335278113904, 0.2726629654485786, 0.05911457383305274, 0.13542072108794634, 0.07819503206598999, 0.6091542510560617, 0.6179659305122197, 0.5867874279577181, 0.6393757971903844, 0.4693118479981404, 0.5096041168517684, 0.6115279863530605, 0.6207021857061341, 0.5785845343262308, 0.05927275827856848, 0.07602933482521834, 0.08164278298810457, 0.0712868143569505, 0.08789339776338057, 0.16790667119578562, 0.07357860287302154, 0.08544322986685571, 0.12909243545054505, 0.252944871765195, 0.2070958768819685, 0.20745179213720766, 0.21159593717600045, 0.2576930231919571, 0.17223438724005724, 0.12965901138298364, 0.14712745136996896, 0.2107835870438718, 0.16976722260033872, 0.3364008527655141, 0.3909742676870488, 0.4132521890048866, 0.37408895914531026, 0.22352042658221594, 0.2047566825200171, 0.28163304128538424, 0.1938998904274536, 0.12197147167106581, 0.17435240104105, 0.25364409749048167, 0.27213329208829773, 0.19416030687939556, 0.2356430035430096, 0.2840059881450433, 0.28592694317017453, 0.291159946550418, 0.24286363079631412, 0.1368478022040326, 0.20423629734683924, 0.18697767459664882, 0.15478347530712722, 0.20113568547095373, 0.2039497103660124, 0.2220975707356071, 0.19689795386068543, 0.179657640170784, 0.19305290759791116, 0.19089329616914452, 0.19636708691118288, 0.21298661768998128, 0.19307283107254147, 0.20859625151888972, 0.1946566801667483, 0.18842495199187492, 0.8245709667566778, 0.1624860843876642, 0.15221100965343248, 0.8301456682659993, 0.18620171383534556, 0.1980846120401154, 0.14238183694580564, 0.1664848827188412, 0.2121238631228145, 0.8078478963481868, 0.20728343102491587, 0.7859679051714352, 0.20632771855555776, 0.667248979883264, 0.14471989761353377, 0.2080063564378758, 0.211196191207509, 0.716523800533237, 0.1938097579608279, 0.2114878352972962, 0.191720329451191, 0.19133405927113367, 0.19624784725392808, 0.1842017466785434, 0.19998052801159072, 0.19689251272469488, 0.179282088973875, 0.07730765922364158, 0.07835284906745688, 0.08225262965277447, 0.06486802326601415, 0.09141104167414704, 0.053629566615639335, 0.07259160383769991, 0.07574880066806922, 0.0974921512774739]}, "mutation_prompt": null}
{"id": "76784198-e708-4fdd-a5ee-b2f6f33a43f5", "solution": "import numpy as np\n\nclass AdaptiveInertiaHybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.initial_inertia_weight = 0.9  # Adaptive inertia weight\n        self.final_inertia_weight = 0.4\n        self.cognitive_weight = 1.5  # Balanced emphasis on personal experience\n        self.social_weight = 1.5  # Balanced global cooperation\n    \n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - evaluations / self.budget) + self.final_inertia_weight\n\n            r1, r2 = np.random.rand(2)\n            velocities = (inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 2 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.8 * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    \n                    if np.random.rand() < 0.4:\n                        local_search = mutant + np.random.normal(0, 0.1, self.dim)\n                        local_search = np.clip(local_search, self.lb, self.ub)\n                        mutant = local_search\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "AdaptiveInertiaHybridPSO", "description": "Hybrid Particle Swarm Optimization with adaptive inertia and differential mutation to enhance convergence speed.", "configspace": "", "generation": 46, "fitness": 0.25191257679855594, "feedback": "The algorithm AdaptiveInertiaHybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.24.", "error": "", "parent_id": "f6ccd04a-7cc1-45ae-b080-a116ed72e58f", "metadata": {"aucs": [0.7117710501018453, 0.6400810845352736, 0.6061696813738952, 0.6694596887003099, 0.5797481196967565, 0.629106836312567, 0.7096624839702708, 0.6587714759442203, 0.5767631250667654, 0.03779952628941685, 0.024424544545583515, 0.07192862137231237, 0.0393335004059423, 0.04096067533057135, 0.02214838989771084, 0.019798342010204806, 0.22236859305733025, 0.035007696052288706, 0.06694917133641753, 0.09938280232711261, 0.06597254142738807, 0.12869547349585087, 0.0781179077550529, 0.12288797735996737, 0.06872450609877612, 0.15783434180723688, 0.1045585184686395, 0.07681441318185245, 0.045414339449665886, 0.07913237205412282, 0.04518476533237248, 0.14280355086509966, 0.09815549735453732, 0.08327996767447077, 0.10608973016181988, 0.09040994637927546, 0.98805882807291, 0.9888262385988489, 0.9804328915472538, 0.9618774828007418, 0.9770665311750392, 0.9668173925467803, 0.9872125381425555, 0.9817636023070716, 0.9806234587048553, 0.5212770862292615, 0.35292163007795463, 0.299601194765307, 0.4660632474412094, 0.35324282420926434, 0.34799503201384696, 0.38284270028232137, 0.32159668765053706, 0.35106317063756365, 0.17028319528599845, 0.6897174177700719, 0.6112891672454581, 0.7370757776549548, 0.12577773148123483, 0.19814852139910843, 0.10308393102257818, 0.13100129256406368, 0.544107897273612, 0.12044942009834525, 0.2898535842163332, 0.1420387512666481, 0.10583094241944913, 0.1159553328783599, 0.10352312716665568, 0.160514111121703, 0.09573435652378448, 0.20890994414169162, 0.3849970393959503, 0.14117003009411422, 0.10729521006548459, 0.29665030717404817, 0.20721398222307685, 0.197373914581075, 0.08761885658025781, 0.04041559027319164, 0.09658930693479362, 0.03531809296750543, 0.018141705506585448, 0.051120821112447645, 0.033388252324810686, 0.095110884386858, 9.999999999998899e-05, 0.08337251723948069, 0.005440511122562608, 0.04516902791087285, 0.10141758529524236, 0.05212571964662116, 0.15932686120923334, 0.1534308718292139, 0.028796087640884593, 0.05417780901084335, 0.101699890941358, 0.11738318033073336, 0.07762326609859649, 0.03370904063533575, 0.028952472092544812, 0.08963620530923178, 0.06156274325319522, 0.07887921911026385, 0.04343283821041499, 0.10179201139327776, 0.06118035310921255, 0.03889268695382564, 0.108707990751015, 0.03778629648487053, 0.11996610509124295, 0.15180787495363057, 0.18570598031934005, 0.1434264687076442, 0.04813054265875216, 0.04251720730152719, 0.06632162990593093, 0.4772315493120257, 0.4891747187557157, 0.44973818410718636, 0.5571902467946819, 0.4808706515964335, 0.44990016108556385, 0.535591078284759, 0.43451280977132933, 0.4797097029982872, 0.1023905759888879, 0.05089520819957505, 0.10958128864276784, 0.08607835169772804, 0.04407880664082586, 0.11738008431471991, 0.059298944943811716, 0.06236448609306067, 0.08847134078940722, 0.2628049232122526, 0.1948027920239338, 0.17490924765587257, 0.3732403051956773, 0.3078369834274358, 0.1960821367768878, 0.3565101796832878, 0.2436297786811742, 0.19304522976884642, 0.23150153912816152, 0.1917347487221518, 0.33111847265122873, 0.21622061492482458, 0.20492448356982895, 0.31074687241528676, 0.3749172217834492, 0.36303340473220025, 0.29559536994182256, 0.25806435069145406, 0.1602809258944743, 0.23088623997846736, 0.148174680374072, 0.1835433389539025, 0.2571579350980264, 0.32711070123415753, 0.2805908450273241, 0.218453954735219, 0.2040648732345517, 0.13890353707278136, 0.19512935695529743, 0.1853541659435879, 0.2165866362535428, 0.17934209143466273, 0.27873794008001174, 0.2120647229988324, 0.18797999818717737, 0.17543464834161837, 0.18686290545856887, 0.17679065765981028, 0.23475343097669876, 0.16437319273913475, 0.18075291532227877, 0.17330171570656183, 0.1794608182384776, 0.22490613717240282, 0.8165582148131643, 0.16512238025848236, 0.15384247408740392, 0.8184239646970924, 0.19710915298662235, 0.1930247101587329, 0.1397554662960765, 0.16937328323315937, 0.733954764802802, 0.78026047978463, 0.1981105397700359, 0.6094126365982073, 0.7622762442512026, 0.5533229544757368, 0.47904612518051104, 0.20837151769744366, 0.20496251169453883, 0.1978689124777505, 0.2023370606743865, 0.2046496200944271, 0.21084346635229345, 0.21904455024132718, 0.20128121914520503, 0.18232636382578526, 0.2242955138158813, 0.18880026705284458, 0.18219118005783608, 0.08789303806644255, 0.08175894040419518, 0.06674410670577069, 0.0829855857952696, 0.09985282594479594, 0.07460933383195201, 0.08442045476584681, 0.0609897549714542, 0.08795847934120271]}, "mutation_prompt": null}
{"id": "68b82061-a3ac-4780-acd4-a4299cbbd987", "solution": "import numpy as np\n\nclass EnhancedHybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.5  # Decreased for faster convergence\n        self.cognitive_weight = 2.0  # Increased to emphasize personal experience\n        self.social_weight = 2.0  # Increased to enhance global cooperation\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        adaptive_lr = self.swarm_size  # Adaptive learning rate\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.9 * (x2 - x3)  # Increased factor for mutation\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    \n                    if np.random.rand() < 0.3:  # Local search with 30% probability\n                        local_search = mutant + np.random.normal(0, 0.1, self.dim)\n                        local_search = np.clip(local_search, self.lb, self.ub)\n                        mutant = local_search\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "EnhancedHybridPSO", "description": "Enhanced PSO with adaptive learning rates and local search to improve convergence speed.", "configspace": "", "generation": 40, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "f6ccd04a-7cc1-45ae-b080-a116ed72e58f", "metadata": {"aucs": [0.7171957053835964, 0.780137486347676, 0.6827151408603582, 0.6984922152642317, 0.7375113977089538, 0.766589172336417, 0.6931197341148846, 0.7738539845835767, 0.6620244474088419, 0.03257239363993303, 0.3417443079218486, 0.03633744007525308, 0.22615897477208968, 0.2993945097010785, 0.174169900923422, 0.1291479641445692, 0.20978274175446643, 0.034346437681954, 0.060882731728882034, 0.0995717315555259, 0.10204488502353093, 0.11138366837828417, 0.10541464751250551, 0.12180860209597488, 0.088358241994832, 0.10735596214791387, 0.06928203732424376, 0.09925037935589409, 0.04677656080572157, 0.08778513074062211, 0.09914953989939035, 0.08455399844447531, 0.11079923655501644, 0.10609433664542745, 0.05463417667899484, 0.09342165127832702, 0.989474310161318, 0.9895248236654537, 0.9829283463117212, 0.9825396314616374, 0.9818847345417261, 0.9669790489006388, 0.9894590329462951, 0.9878259088542194, 0.974382893305813, 0.4923486231827021, 0.37891171835291737, 0.4310409114979158, 0.3631119988941015, 0.4237010538714788, 0.3649962551267265, 0.439988536632679, 0.33207258210884516, 0.4240549089814948, 0.1720715629635925, 0.5511137154300236, 0.7632220055640622, 0.19401409638729783, 0.11647614996803202, 0.6191101725685184, 0.11565168402689219, 0.1472745000802077, 0.7382753601443569, 0.37811215689742406, 0.4101839123948977, 0.20377518297361785, 0.20819954455200307, 0.20177894228779136, 0.2592422735930029, 0.2923985608427342, 0.12074488299600128, 0.2225819645991748, 0.1355869523217238, 0.19983985327802156, 0.10742731802734051, 0.3004629885926129, 0.1255260582155161, 0.3117991802340837, 0.08370039405236462, 0.1513497984618014, 0.10819192282952028, 0.06234995318571401, 0.019066754000251818, 0.023632723852008763, 0.0005658451976636725, 0.032834875455656776, 0.08284419283150024, 0.23089127064630455, 0.006619566738323424, 0.12097614769757858, 0.1626031923319291, 0.06153321725245553, 0.18314135911563678, 0.23119285368730658, 0.008295037422650586, 0.04921324062047483, 0.11371949608153753, 0.07295530962541374, 0.11060295565606926, 0.03540267091134086, 0.039696935172835346, 0.0441281391529208, 0.1857279188197989, 0.0827403371036387, 0.06291431610762743, 0.07311190169265613, 0.09002275521396974, 0.07924700418505637, 0.05735368128555307, 0.05665705719494507, 0.24448427401834583, 0.22997797030237654, 0.23805335278113904, 0.2726629654485786, 0.05911457383305274, 0.13542072108794634, 0.07819503206598999, 0.6091542510560617, 0.6179659305122197, 0.5867874279577181, 0.6393757971903844, 0.4693118479981404, 0.5096041168517684, 0.6115279863530605, 0.6207021857061341, 0.5785845343262308, 0.05927275827856848, 0.07602933482521834, 0.08164278298810457, 0.0712868143569505, 0.08789339776338057, 0.16790667119578562, 0.07357860287302154, 0.08544322986685571, 0.12909243545054505, 0.252944871765195, 0.2070958768819685, 0.20745179213720766, 0.21159593717600045, 0.2576930231919571, 0.17223438724005724, 0.12965901138298364, 0.14712745136996896, 0.2107835870438718, 0.16976722260033872, 0.3364008527655141, 0.3909742676870488, 0.4132521890048866, 0.37408895914531026, 0.22352042658221594, 0.2047566825200171, 0.28163304128538424, 0.1938998904274536, 0.12197147167106581, 0.17435240104105, 0.25364409749048167, 0.27213329208829773, 0.19416030687939556, 0.2356430035430096, 0.2840059881450433, 0.28592694317017453, 0.291159946550418, 0.24286363079631412, 0.1368478022040326, 0.20423629734683924, 0.18697767459664882, 0.15478347530712722, 0.20113568547095373, 0.2039497103660124, 0.2220975707356071, 0.19689795386068543, 0.179657640170784, 0.19305290759791116, 0.19089329616914452, 0.19636708691118288, 0.21298661768998128, 0.19307283107254147, 0.20859625151888972, 0.1946566801667483, 0.18842495199187492, 0.8245709667566778, 0.1624860843876642, 0.15221100965343248, 0.8301456682659993, 0.18620171383534556, 0.1980846120401154, 0.14238183694580564, 0.1664848827188412, 0.2121238631228145, 0.8078478963481868, 0.20728343102491587, 0.7859679051714352, 0.20632771855555776, 0.667248979883264, 0.14471989761353377, 0.2080063564378758, 0.211196191207509, 0.716523800533237, 0.1938097579608279, 0.2114878352972962, 0.191720329451191, 0.19133405927113367, 0.19624784725392808, 0.1842017466785434, 0.19998052801159072, 0.19689251272469488, 0.179282088973875, 0.07730765922364158, 0.07835284906745688, 0.08225262965277447, 0.06486802326601415, 0.09141104167414704, 0.053629566615639335, 0.07259160383769991, 0.07574880066806922, 0.0974921512774739]}, "mutation_prompt": null}
{"id": "83fcba96-bea4-431f-a748-824e3466b02a", "solution": "import numpy as np\n\nclass EnhancedHybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.5  # Decreased for faster convergence\n        self.cognitive_weight = 2.0  # Increased to emphasize personal experience\n        self.social_weight = 2.0  # Increased to enhance global cooperation\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        adaptive_lr = self.swarm_size  # Adaptive learning rate\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.9 * (x2 - x3)  # Increased factor for mutation\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    \n                    if np.random.rand() < 0.3:  # Local search with 30% probability\n                        local_search = mutant + np.random.normal(0, 0.1, self.dim)\n                        local_search = np.clip(local_search, self.lb, self.ub)\n                        mutant = local_search\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "EnhancedHybridPSO", "description": "Enhanced PSO with adaptive learning rates and local search to improve convergence speed.", "configspace": "", "generation": 40, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "f6ccd04a-7cc1-45ae-b080-a116ed72e58f", "metadata": {"aucs": [0.7171957053835964, 0.780137486347676, 0.6827151408603582, 0.6984922152642317, 0.7375113977089538, 0.766589172336417, 0.6931197341148846, 0.7738539845835767, 0.6620244474088419, 0.03257239363993303, 0.3417443079218486, 0.03633744007525308, 0.22615897477208968, 0.2993945097010785, 0.174169900923422, 0.1291479641445692, 0.20978274175446643, 0.034346437681954, 0.060882731728882034, 0.0995717315555259, 0.10204488502353093, 0.11138366837828417, 0.10541464751250551, 0.12180860209597488, 0.088358241994832, 0.10735596214791387, 0.06928203732424376, 0.09925037935589409, 0.04677656080572157, 0.08778513074062211, 0.09914953989939035, 0.08455399844447531, 0.11079923655501644, 0.10609433664542745, 0.05463417667899484, 0.09342165127832702, 0.989474310161318, 0.9895248236654537, 0.9829283463117212, 0.9825396314616374, 0.9818847345417261, 0.9669790489006388, 0.9894590329462951, 0.9878259088542194, 0.974382893305813, 0.4923486231827021, 0.37891171835291737, 0.4310409114979158, 0.3631119988941015, 0.4237010538714788, 0.3649962551267265, 0.439988536632679, 0.33207258210884516, 0.4240549089814948, 0.1720715629635925, 0.5511137154300236, 0.7632220055640622, 0.19401409638729783, 0.11647614996803202, 0.6191101725685184, 0.11565168402689219, 0.1472745000802077, 0.7382753601443569, 0.37811215689742406, 0.4101839123948977, 0.20377518297361785, 0.20819954455200307, 0.20177894228779136, 0.2592422735930029, 0.2923985608427342, 0.12074488299600128, 0.2225819645991748, 0.1355869523217238, 0.19983985327802156, 0.10742731802734051, 0.3004629885926129, 0.1255260582155161, 0.3117991802340837, 0.08370039405236462, 0.1513497984618014, 0.10819192282952028, 0.06234995318571401, 0.019066754000251818, 0.023632723852008763, 0.0005658451976636725, 0.032834875455656776, 0.08284419283150024, 0.23089127064630455, 0.006619566738323424, 0.12097614769757858, 0.1626031923319291, 0.06153321725245553, 0.18314135911563678, 0.23119285368730658, 0.008295037422650586, 0.04921324062047483, 0.11371949608153753, 0.07295530962541374, 0.11060295565606926, 0.03540267091134086, 0.039696935172835346, 0.0441281391529208, 0.1857279188197989, 0.0827403371036387, 0.06291431610762743, 0.07311190169265613, 0.09002275521396974, 0.07924700418505637, 0.05735368128555307, 0.05665705719494507, 0.24448427401834583, 0.22997797030237654, 0.23805335278113904, 0.2726629654485786, 0.05911457383305274, 0.13542072108794634, 0.07819503206598999, 0.6091542510560617, 0.6179659305122197, 0.5867874279577181, 0.6393757971903844, 0.4693118479981404, 0.5096041168517684, 0.6115279863530605, 0.6207021857061341, 0.5785845343262308, 0.05927275827856848, 0.07602933482521834, 0.08164278298810457, 0.0712868143569505, 0.08789339776338057, 0.16790667119578562, 0.07357860287302154, 0.08544322986685571, 0.12909243545054505, 0.252944871765195, 0.2070958768819685, 0.20745179213720766, 0.21159593717600045, 0.2576930231919571, 0.17223438724005724, 0.12965901138298364, 0.14712745136996896, 0.2107835870438718, 0.16976722260033872, 0.3364008527655141, 0.3909742676870488, 0.4132521890048866, 0.37408895914531026, 0.22352042658221594, 0.2047566825200171, 0.28163304128538424, 0.1938998904274536, 0.12197147167106581, 0.17435240104105, 0.25364409749048167, 0.27213329208829773, 0.19416030687939556, 0.2356430035430096, 0.2840059881450433, 0.28592694317017453, 0.291159946550418, 0.24286363079631412, 0.1368478022040326, 0.20423629734683924, 0.18697767459664882, 0.15478347530712722, 0.20113568547095373, 0.2039497103660124, 0.2220975707356071, 0.19689795386068543, 0.179657640170784, 0.19305290759791116, 0.19089329616914452, 0.19636708691118288, 0.21298661768998128, 0.19307283107254147, 0.20859625151888972, 0.1946566801667483, 0.18842495199187492, 0.8245709667566778, 0.1624860843876642, 0.15221100965343248, 0.8301456682659993, 0.18620171383534556, 0.1980846120401154, 0.14238183694580564, 0.1664848827188412, 0.2121238631228145, 0.8078478963481868, 0.20728343102491587, 0.7859679051714352, 0.20632771855555776, 0.667248979883264, 0.14471989761353377, 0.2080063564378758, 0.211196191207509, 0.716523800533237, 0.1938097579608279, 0.2114878352972962, 0.191720329451191, 0.19133405927113367, 0.19624784725392808, 0.1842017466785434, 0.19998052801159072, 0.19689251272469488, 0.179282088973875, 0.07730765922364158, 0.07835284906745688, 0.08225262965277447, 0.06486802326601415, 0.09141104167414704, 0.053629566615639335, 0.07259160383769991, 0.07574880066806922, 0.0974921512774739]}, "mutation_prompt": null}
{"id": "2bc1102f-a26f-4829-b7ff-948f39fc1ecb", "solution": "import numpy as np\n\nclass EnhancedHybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.5  # Decreased for faster convergence\n        self.cognitive_weight = 2.0  # Increased to emphasize personal experience\n        self.social_weight = 2.0  # Increased to enhance global cooperation\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        adaptive_lr = self.swarm_size  # Adaptive learning rate\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.9 * (x2 - x3)  # Increased factor for mutation\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    \n                    if np.random.rand() < 0.3:  # Local search with 30% probability\n                        local_search = mutant + np.random.normal(0, 0.1, self.dim)\n                        local_search = np.clip(local_search, self.lb, self.ub)\n                        mutant = local_search\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "EnhancedHybridPSO", "description": "Enhanced PSO with adaptive learning rates and local search to improve convergence speed.", "configspace": "", "generation": 40, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "f6ccd04a-7cc1-45ae-b080-a116ed72e58f", "metadata": {"aucs": [0.7171957053835964, 0.780137486347676, 0.6827151408603582, 0.6984922152642317, 0.7375113977089538, 0.766589172336417, 0.6931197341148846, 0.7738539845835767, 0.6620244474088419, 0.03257239363993303, 0.3417443079218486, 0.03633744007525308, 0.22615897477208968, 0.2993945097010785, 0.174169900923422, 0.1291479641445692, 0.20978274175446643, 0.034346437681954, 0.060882731728882034, 0.0995717315555259, 0.10204488502353093, 0.11138366837828417, 0.10541464751250551, 0.12180860209597488, 0.088358241994832, 0.10735596214791387, 0.06928203732424376, 0.09925037935589409, 0.04677656080572157, 0.08778513074062211, 0.09914953989939035, 0.08455399844447531, 0.11079923655501644, 0.10609433664542745, 0.05463417667899484, 0.09342165127832702, 0.989474310161318, 0.9895248236654537, 0.9829283463117212, 0.9825396314616374, 0.9818847345417261, 0.9669790489006388, 0.9894590329462951, 0.9878259088542194, 0.974382893305813, 0.4923486231827021, 0.37891171835291737, 0.4310409114979158, 0.3631119988941015, 0.4237010538714788, 0.3649962551267265, 0.439988536632679, 0.33207258210884516, 0.4240549089814948, 0.1720715629635925, 0.5511137154300236, 0.7632220055640622, 0.19401409638729783, 0.11647614996803202, 0.6191101725685184, 0.11565168402689219, 0.1472745000802077, 0.7382753601443569, 0.37811215689742406, 0.4101839123948977, 0.20377518297361785, 0.20819954455200307, 0.20177894228779136, 0.2592422735930029, 0.2923985608427342, 0.12074488299600128, 0.2225819645991748, 0.1355869523217238, 0.19983985327802156, 0.10742731802734051, 0.3004629885926129, 0.1255260582155161, 0.3117991802340837, 0.08370039405236462, 0.1513497984618014, 0.10819192282952028, 0.06234995318571401, 0.019066754000251818, 0.023632723852008763, 0.0005658451976636725, 0.032834875455656776, 0.08284419283150024, 0.23089127064630455, 0.006619566738323424, 0.12097614769757858, 0.1626031923319291, 0.06153321725245553, 0.18314135911563678, 0.23119285368730658, 0.008295037422650586, 0.04921324062047483, 0.11371949608153753, 0.07295530962541374, 0.11060295565606926, 0.03540267091134086, 0.039696935172835346, 0.0441281391529208, 0.1857279188197989, 0.0827403371036387, 0.06291431610762743, 0.07311190169265613, 0.09002275521396974, 0.07924700418505637, 0.05735368128555307, 0.05665705719494507, 0.24448427401834583, 0.22997797030237654, 0.23805335278113904, 0.2726629654485786, 0.05911457383305274, 0.13542072108794634, 0.07819503206598999, 0.6091542510560617, 0.6179659305122197, 0.5867874279577181, 0.6393757971903844, 0.4693118479981404, 0.5096041168517684, 0.6115279863530605, 0.6207021857061341, 0.5785845343262308, 0.05927275827856848, 0.07602933482521834, 0.08164278298810457, 0.0712868143569505, 0.08789339776338057, 0.16790667119578562, 0.07357860287302154, 0.08544322986685571, 0.12909243545054505, 0.252944871765195, 0.2070958768819685, 0.20745179213720766, 0.21159593717600045, 0.2576930231919571, 0.17223438724005724, 0.12965901138298364, 0.14712745136996896, 0.2107835870438718, 0.16976722260033872, 0.3364008527655141, 0.3909742676870488, 0.4132521890048866, 0.37408895914531026, 0.22352042658221594, 0.2047566825200171, 0.28163304128538424, 0.1938998904274536, 0.12197147167106581, 0.17435240104105, 0.25364409749048167, 0.27213329208829773, 0.19416030687939556, 0.2356430035430096, 0.2840059881450433, 0.28592694317017453, 0.291159946550418, 0.24286363079631412, 0.1368478022040326, 0.20423629734683924, 0.18697767459664882, 0.15478347530712722, 0.20113568547095373, 0.2039497103660124, 0.2220975707356071, 0.19689795386068543, 0.179657640170784, 0.19305290759791116, 0.19089329616914452, 0.19636708691118288, 0.21298661768998128, 0.19307283107254147, 0.20859625151888972, 0.1946566801667483, 0.18842495199187492, 0.8245709667566778, 0.1624860843876642, 0.15221100965343248, 0.8301456682659993, 0.18620171383534556, 0.1980846120401154, 0.14238183694580564, 0.1664848827188412, 0.2121238631228145, 0.8078478963481868, 0.20728343102491587, 0.7859679051714352, 0.20632771855555776, 0.667248979883264, 0.14471989761353377, 0.2080063564378758, 0.211196191207509, 0.716523800533237, 0.1938097579608279, 0.2114878352972962, 0.191720329451191, 0.19133405927113367, 0.19624784725392808, 0.1842017466785434, 0.19998052801159072, 0.19689251272469488, 0.179282088973875, 0.07730765922364158, 0.07835284906745688, 0.08225262965277447, 0.06486802326601415, 0.09141104167414704, 0.053629566615639335, 0.07259160383769991, 0.07574880066806922, 0.0974921512774739]}, "mutation_prompt": null}
{"id": "ea7cfc52-388f-4b7c-b748-e6fe357b5961", "solution": "import numpy as np\n\nclass EnhancedHybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.5  # Decreased for faster convergence\n        self.cognitive_weight = 2.0  # Increased to emphasize personal experience\n        self.social_weight = 2.0  # Increased to enhance global cooperation\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        adaptive_lr = self.swarm_size  # Adaptive learning rate\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.9 * (x2 - x3)  # Increased factor for mutation\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    \n                    if np.random.rand() < 0.3:  # Local search with 30% probability\n                        local_search = mutant + np.random.normal(0, 0.1, self.dim)\n                        local_search = np.clip(local_search, self.lb, self.ub)\n                        mutant = local_search\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "EnhancedHybridPSO", "description": "Enhanced PSO with adaptive learning rates and local search to improve convergence speed.", "configspace": "", "generation": 40, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "f6ccd04a-7cc1-45ae-b080-a116ed72e58f", "metadata": {"aucs": [0.7171957053835964, 0.780137486347676, 0.6827151408603582, 0.6984922152642317, 0.7375113977089538, 0.766589172336417, 0.6931197341148846, 0.7738539845835767, 0.6620244474088419, 0.03257239363993303, 0.3417443079218486, 0.03633744007525308, 0.22615897477208968, 0.2993945097010785, 0.174169900923422, 0.1291479641445692, 0.20978274175446643, 0.034346437681954, 0.060882731728882034, 0.0995717315555259, 0.10204488502353093, 0.11138366837828417, 0.10541464751250551, 0.12180860209597488, 0.088358241994832, 0.10735596214791387, 0.06928203732424376, 0.09925037935589409, 0.04677656080572157, 0.08778513074062211, 0.09914953989939035, 0.08455399844447531, 0.11079923655501644, 0.10609433664542745, 0.05463417667899484, 0.09342165127832702, 0.989474310161318, 0.9895248236654537, 0.9829283463117212, 0.9825396314616374, 0.9818847345417261, 0.9669790489006388, 0.9894590329462951, 0.9878259088542194, 0.974382893305813, 0.4923486231827021, 0.37891171835291737, 0.4310409114979158, 0.3631119988941015, 0.4237010538714788, 0.3649962551267265, 0.439988536632679, 0.33207258210884516, 0.4240549089814948, 0.1720715629635925, 0.5511137154300236, 0.7632220055640622, 0.19401409638729783, 0.11647614996803202, 0.6191101725685184, 0.11565168402689219, 0.1472745000802077, 0.7382753601443569, 0.37811215689742406, 0.4101839123948977, 0.20377518297361785, 0.20819954455200307, 0.20177894228779136, 0.2592422735930029, 0.2923985608427342, 0.12074488299600128, 0.2225819645991748, 0.1355869523217238, 0.19983985327802156, 0.10742731802734051, 0.3004629885926129, 0.1255260582155161, 0.3117991802340837, 0.08370039405236462, 0.1513497984618014, 0.10819192282952028, 0.06234995318571401, 0.019066754000251818, 0.023632723852008763, 0.0005658451976636725, 0.032834875455656776, 0.08284419283150024, 0.23089127064630455, 0.006619566738323424, 0.12097614769757858, 0.1626031923319291, 0.06153321725245553, 0.18314135911563678, 0.23119285368730658, 0.008295037422650586, 0.04921324062047483, 0.11371949608153753, 0.07295530962541374, 0.11060295565606926, 0.03540267091134086, 0.039696935172835346, 0.0441281391529208, 0.1857279188197989, 0.0827403371036387, 0.06291431610762743, 0.07311190169265613, 0.09002275521396974, 0.07924700418505637, 0.05735368128555307, 0.05665705719494507, 0.24448427401834583, 0.22997797030237654, 0.23805335278113904, 0.2726629654485786, 0.05911457383305274, 0.13542072108794634, 0.07819503206598999, 0.6091542510560617, 0.6179659305122197, 0.5867874279577181, 0.6393757971903844, 0.4693118479981404, 0.5096041168517684, 0.6115279863530605, 0.6207021857061341, 0.5785845343262308, 0.05927275827856848, 0.07602933482521834, 0.08164278298810457, 0.0712868143569505, 0.08789339776338057, 0.16790667119578562, 0.07357860287302154, 0.08544322986685571, 0.12909243545054505, 0.252944871765195, 0.2070958768819685, 0.20745179213720766, 0.21159593717600045, 0.2576930231919571, 0.17223438724005724, 0.12965901138298364, 0.14712745136996896, 0.2107835870438718, 0.16976722260033872, 0.3364008527655141, 0.3909742676870488, 0.4132521890048866, 0.37408895914531026, 0.22352042658221594, 0.2047566825200171, 0.28163304128538424, 0.1938998904274536, 0.12197147167106581, 0.17435240104105, 0.25364409749048167, 0.27213329208829773, 0.19416030687939556, 0.2356430035430096, 0.2840059881450433, 0.28592694317017453, 0.291159946550418, 0.24286363079631412, 0.1368478022040326, 0.20423629734683924, 0.18697767459664882, 0.15478347530712722, 0.20113568547095373, 0.2039497103660124, 0.2220975707356071, 0.19689795386068543, 0.179657640170784, 0.19305290759791116, 0.19089329616914452, 0.19636708691118288, 0.21298661768998128, 0.19307283107254147, 0.20859625151888972, 0.1946566801667483, 0.18842495199187492, 0.8245709667566778, 0.1624860843876642, 0.15221100965343248, 0.8301456682659993, 0.18620171383534556, 0.1980846120401154, 0.14238183694580564, 0.1664848827188412, 0.2121238631228145, 0.8078478963481868, 0.20728343102491587, 0.7859679051714352, 0.20632771855555776, 0.667248979883264, 0.14471989761353377, 0.2080063564378758, 0.211196191207509, 0.716523800533237, 0.1938097579608279, 0.2114878352972962, 0.191720329451191, 0.19133405927113367, 0.19624784725392808, 0.1842017466785434, 0.19998052801159072, 0.19689251272469488, 0.179282088973875, 0.07730765922364158, 0.07835284906745688, 0.08225262965277447, 0.06486802326601415, 0.09141104167414704, 0.053629566615639335, 0.07259160383769991, 0.07574880066806922, 0.0974921512774739]}, "mutation_prompt": null}
{"id": "9c384889-b989-4b6c-bb7f-6bcfaf281e8d", "solution": "import numpy as np\n\nclass EnhancedHybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7  # Slightly increased for better exploration\n        self.cognitive_weight = 1.5  # Adjusted for balanced search\n        self.social_weight = 2.5  # Increased for stronger global influence\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.swarm_size, self.dim))  # Narrowed velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 2 <= self.budget:  # Increased iteration cap\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.8 * (x2 - x3)  # Slightly reduced mutation factor\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    \n                    if np.random.rand() < 0.35:  # Slightly increased local search probability\n                        local_search = mutant + np.random.normal(0, 0.15, self.dim)  # Adjusted local search perturbation\n                        local_search = np.clip(local_search, self.lb, self.ub)\n                        mutant = local_search\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "EnhancedHybridPSO", "description": "Hybrid PSO with enhanced local search and adaptive mutation strategies to improve convergence.", "configspace": "", "generation": 51, "fitness": 0.19364585360358302, "feedback": "The algorithm EnhancedHybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.20.", "error": "", "parent_id": "f6ccd04a-7cc1-45ae-b080-a116ed72e58f", "metadata": {"aucs": [0.4225820078838052, 0.4146500020696846, 0.46553511974060435, 0.4295088483826274, 0.39226543793230495, 0.4785367236639486, 0.4939782880345587, 0.2902405305749495, 0.44340951778822335, 0.037818702262801374, 0.016295270108514837, 0.003419045231106921, 0.0029302088981892904, 0.006750171702977648, 0.054157816375246526, 0.017719789615997406, 0.008406103255371056, 0.028335867721155594, 0.06589025538404347, 0.0744809644028972, 0.06025975263529182, 0.09635203143687099, 0.10382356441664908, 0.0890152741237551, 0.1116098348713771, 0.09726941633400732, 0.06797659011368373, 0.07272459845091472, 0.044189404902176155, 0.06978683267454222, 0.08413373545737468, 0.09452181356259204, 0.0938066761480073, 0.07711808525495922, 0.055452929574395404, 0.07468425373498899, 0.9932938639363438, 0.9960511779651787, 0.9890931299021547, 0.9818367228002486, 0.9888189810376208, 0.9747149101794027, 0.9896405144179378, 0.9887011023674421, 0.9867107876771283, 0.2023039816460348, 0.16037177930780966, 0.1663077230181701, 0.15482329606417589, 0.1818408056139761, 0.22703050661402113, 0.20857330552940445, 0.13629280740411231, 0.27594045263367695, 0.20495906460952806, 0.13038937883872337, 0.1957044943000894, 0.24433758344473544, 0.16279139692330358, 0.2059685337559114, 0.12611989236771592, 0.39222534929312836, 0.20480216363845516, 0.16047513805517177, 0.1440148626532346, 0.1028190857797392, 0.0803457630499157, 0.14229461662297072, 0.10922179097491658, 0.13091544477249284, 0.09697193873032539, 0.21889409932835402, 0.1391013451831643, 0.1049590253372904, 0.11053866248043664, 0.11956651315944888, 0.10849334624470153, 0.156119955489193, 0.0799849444798656, 0.02224975740766677, 0.08420271574120142, 0.025872597869265546, 0.0013693772650638092, 9.999999999998899e-05, 0.00042962562147019767, 9.999999999998899e-05, 9.999999999998899e-05, 0.00043390350437844116, 9.999999999998899e-05, 0.067452160008735, 0.028734121837251214, 0.041256879869242535, 0.07166076516963549, 0.09338088512038722, 0.014951216962228342, 0.050571434260672454, 0.06506582030106733, 0.04059587506206985, 0.05434208533585749, 0.009384580210650917, 9.999999999998899e-05, 0.019116508919704733, 0.034195923698544406, 0.005670187212819422, 0.042389356671638234, 0.04063707855804155, 0.0016528324502400604, 0.07049491543608144, 0.0809074571185181, 0.02311992533196916, 0.13015781527762593, 0.08404073576315274, 0.05941815648821225, 0.17451854298224134, 0.04582153446876236, 0.044672395660254716, 0.07000576163254968, 0.35306247624586573, 0.3474573449544751, 0.47778620370907987, 0.3370742782450027, 0.2997733367625298, 0.4589969304116257, 0.36663980267561824, 0.33520743381099927, 0.41566567793321674, 0.051784521808856177, 0.05959420492308509, 0.08655934405708976, 0.079934296045711, 0.08353846507150864, 0.11549010621804823, 0.055818795161628576, 0.10157188724780064, 0.07307753222722335, 0.21147722785875966, 0.16053187706840433, 0.19017616288370298, 0.22898514369102396, 0.19910344845725136, 0.15099258767271517, 0.17719797925897074, 0.17899134968829056, 0.21802335298390885, 0.17659521680117285, 0.2201339338457704, 0.2651104483241148, 0.2231201153483181, 0.1844855983011049, 0.23991634127961248, 0.19252173746217482, 0.2729685291897628, 0.21510245769191438, 0.1632728819519318, 0.07423493421706806, 0.20028308664443273, 0.2246618768634383, 0.16799972775921412, 0.1737848195801729, 0.2115480509184815, 0.18138057735790947, 0.2566912277636896, 0.20461633924769107, 0.1427816029637492, 0.20345966041849162, 0.1994430771670026, 0.15962800663095245, 0.19516841149421416, 0.20765333375405537, 0.19157660112865882, 0.1872065765770209, 0.16220441177964295, 0.20197073981032732, 0.16617420055686982, 0.2114056175000666, 0.19922397197551944, 0.20348923979950595, 0.18815911142476094, 0.19930697259047825, 0.17204041169290685, 0.6135131967131471, 0.1665996851201157, 0.15113032536239301, 0.18284852050495914, 0.191513296317959, 0.19638824662721033, 0.14058167335414595, 0.18596754571280072, 0.6711974258197668, 0.4301010198247597, 0.1969867299755207, 0.4302219194903163, 0.29003042080776276, 0.43828669879695237, 0.14332550899275498, 0.20849336568414645, 0.20912648139679813, 0.20326657826483674, 0.1829900769465258, 0.18104980238346702, 0.17627155988443033, 0.2002646527366866, 0.19697000888686522, 0.18229320354367362, 0.1842594831534795, 0.2435570841363961, 0.18216120916522682, 0.08093248631515448, 0.0706473996600202, 0.08001214878971352, 0.07096421951301513, 0.07528205045107805, 0.08239811274079567, 0.06647464533854686, 0.0720926676143494, 0.08220468189812202]}, "mutation_prompt": null}
{"id": "3ed18923-d579-4034-9dfa-ad734bc06a5c", "solution": "import numpy as np\n\nclass EnhancedHybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.5  # Decreased for faster convergence\n        self.cognitive_weight = 2.0  # Increased to emphasize personal experience\n        self.social_weight = 2.0  # Increased to enhance global cooperation\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        adaptive_lr = self.swarm_size  # Adaptive learning rate\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.9 * (x2 - x3)  # Increased factor for mutation\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    \n                    if np.random.rand() < 0.3:  # Local search with 30% probability\n                        local_search = mutant + np.random.normal(0, 0.1, self.dim)\n                        local_search = np.clip(local_search, self.lb, self.ub)\n                        mutant = local_search\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "EnhancedHybridPSO", "description": "Enhanced PSO with adaptive learning rates and local search to improve convergence speed.", "configspace": "", "generation": 40, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "f6ccd04a-7cc1-45ae-b080-a116ed72e58f", "metadata": {"aucs": [0.7171957053835964, 0.780137486347676, 0.6827151408603582, 0.6984922152642317, 0.7375113977089538, 0.766589172336417, 0.6931197341148846, 0.7738539845835767, 0.6620244474088419, 0.03257239363993303, 0.3417443079218486, 0.03633744007525308, 0.22615897477208968, 0.2993945097010785, 0.174169900923422, 0.1291479641445692, 0.20978274175446643, 0.034346437681954, 0.060882731728882034, 0.0995717315555259, 0.10204488502353093, 0.11138366837828417, 0.10541464751250551, 0.12180860209597488, 0.088358241994832, 0.10735596214791387, 0.06928203732424376, 0.09925037935589409, 0.04677656080572157, 0.08778513074062211, 0.09914953989939035, 0.08455399844447531, 0.11079923655501644, 0.10609433664542745, 0.05463417667899484, 0.09342165127832702, 0.989474310161318, 0.9895248236654537, 0.9829283463117212, 0.9825396314616374, 0.9818847345417261, 0.9669790489006388, 0.9894590329462951, 0.9878259088542194, 0.974382893305813, 0.4923486231827021, 0.37891171835291737, 0.4310409114979158, 0.3631119988941015, 0.4237010538714788, 0.3649962551267265, 0.439988536632679, 0.33207258210884516, 0.4240549089814948, 0.1720715629635925, 0.5511137154300236, 0.7632220055640622, 0.19401409638729783, 0.11647614996803202, 0.6191101725685184, 0.11565168402689219, 0.1472745000802077, 0.7382753601443569, 0.37811215689742406, 0.4101839123948977, 0.20377518297361785, 0.20819954455200307, 0.20177894228779136, 0.2592422735930029, 0.2923985608427342, 0.12074488299600128, 0.2225819645991748, 0.1355869523217238, 0.19983985327802156, 0.10742731802734051, 0.3004629885926129, 0.1255260582155161, 0.3117991802340837, 0.08370039405236462, 0.1513497984618014, 0.10819192282952028, 0.06234995318571401, 0.019066754000251818, 0.023632723852008763, 0.0005658451976636725, 0.032834875455656776, 0.08284419283150024, 0.23089127064630455, 0.006619566738323424, 0.12097614769757858, 0.1626031923319291, 0.06153321725245553, 0.18314135911563678, 0.23119285368730658, 0.008295037422650586, 0.04921324062047483, 0.11371949608153753, 0.07295530962541374, 0.11060295565606926, 0.03540267091134086, 0.039696935172835346, 0.0441281391529208, 0.1857279188197989, 0.0827403371036387, 0.06291431610762743, 0.07311190169265613, 0.09002275521396974, 0.07924700418505637, 0.05735368128555307, 0.05665705719494507, 0.24448427401834583, 0.22997797030237654, 0.23805335278113904, 0.2726629654485786, 0.05911457383305274, 0.13542072108794634, 0.07819503206598999, 0.6091542510560617, 0.6179659305122197, 0.5867874279577181, 0.6393757971903844, 0.4693118479981404, 0.5096041168517684, 0.6115279863530605, 0.6207021857061341, 0.5785845343262308, 0.05927275827856848, 0.07602933482521834, 0.08164278298810457, 0.0712868143569505, 0.08789339776338057, 0.16790667119578562, 0.07357860287302154, 0.08544322986685571, 0.12909243545054505, 0.252944871765195, 0.2070958768819685, 0.20745179213720766, 0.21159593717600045, 0.2576930231919571, 0.17223438724005724, 0.12965901138298364, 0.14712745136996896, 0.2107835870438718, 0.16976722260033872, 0.3364008527655141, 0.3909742676870488, 0.4132521890048866, 0.37408895914531026, 0.22352042658221594, 0.2047566825200171, 0.28163304128538424, 0.1938998904274536, 0.12197147167106581, 0.17435240104105, 0.25364409749048167, 0.27213329208829773, 0.19416030687939556, 0.2356430035430096, 0.2840059881450433, 0.28592694317017453, 0.291159946550418, 0.24286363079631412, 0.1368478022040326, 0.20423629734683924, 0.18697767459664882, 0.15478347530712722, 0.20113568547095373, 0.2039497103660124, 0.2220975707356071, 0.19689795386068543, 0.179657640170784, 0.19305290759791116, 0.19089329616914452, 0.19636708691118288, 0.21298661768998128, 0.19307283107254147, 0.20859625151888972, 0.1946566801667483, 0.18842495199187492, 0.8245709667566778, 0.1624860843876642, 0.15221100965343248, 0.8301456682659993, 0.18620171383534556, 0.1980846120401154, 0.14238183694580564, 0.1664848827188412, 0.2121238631228145, 0.8078478963481868, 0.20728343102491587, 0.7859679051714352, 0.20632771855555776, 0.667248979883264, 0.14471989761353377, 0.2080063564378758, 0.211196191207509, 0.716523800533237, 0.1938097579608279, 0.2114878352972962, 0.191720329451191, 0.19133405927113367, 0.19624784725392808, 0.1842017466785434, 0.19998052801159072, 0.19689251272469488, 0.179282088973875, 0.07730765922364158, 0.07835284906745688, 0.08225262965277447, 0.06486802326601415, 0.09141104167414704, 0.053629566615639335, 0.07259160383769991, 0.07574880066806922, 0.0974921512774739]}, "mutation_prompt": null}
{"id": "f54a0d0d-153f-45fe-91c3-981ed8564dab", "solution": "import numpy as np\n\nclass EnhancedHybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.5  # Decreased for faster convergence\n        self.cognitive_weight = 2.0  # Increased to emphasize personal experience\n        self.social_weight = 2.0  # Increased to enhance global cooperation\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        adaptive_lr = self.swarm_size  # Adaptive learning rate\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.9 * (x2 - x3)  # Increased factor for mutation\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    \n                    if np.random.rand() < 0.3:  # Local search with 30% probability\n                        local_search = mutant + np.random.normal(0, 0.1, self.dim)\n                        local_search = np.clip(local_search, self.lb, self.ub)\n                        mutant = local_search\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "EnhancedHybridPSO", "description": "Enhanced PSO with adaptive learning rates and local search to improve convergence speed.", "configspace": "", "generation": 40, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "f6ccd04a-7cc1-45ae-b080-a116ed72e58f", "metadata": {"aucs": [0.7171957053835964, 0.780137486347676, 0.6827151408603582, 0.6984922152642317, 0.7375113977089538, 0.766589172336417, 0.6931197341148846, 0.7738539845835767, 0.6620244474088419, 0.03257239363993303, 0.3417443079218486, 0.03633744007525308, 0.22615897477208968, 0.2993945097010785, 0.174169900923422, 0.1291479641445692, 0.20978274175446643, 0.034346437681954, 0.060882731728882034, 0.0995717315555259, 0.10204488502353093, 0.11138366837828417, 0.10541464751250551, 0.12180860209597488, 0.088358241994832, 0.10735596214791387, 0.06928203732424376, 0.09925037935589409, 0.04677656080572157, 0.08778513074062211, 0.09914953989939035, 0.08455399844447531, 0.11079923655501644, 0.10609433664542745, 0.05463417667899484, 0.09342165127832702, 0.989474310161318, 0.9895248236654537, 0.9829283463117212, 0.9825396314616374, 0.9818847345417261, 0.9669790489006388, 0.9894590329462951, 0.9878259088542194, 0.974382893305813, 0.4923486231827021, 0.37891171835291737, 0.4310409114979158, 0.3631119988941015, 0.4237010538714788, 0.3649962551267265, 0.439988536632679, 0.33207258210884516, 0.4240549089814948, 0.1720715629635925, 0.5511137154300236, 0.7632220055640622, 0.19401409638729783, 0.11647614996803202, 0.6191101725685184, 0.11565168402689219, 0.1472745000802077, 0.7382753601443569, 0.37811215689742406, 0.4101839123948977, 0.20377518297361785, 0.20819954455200307, 0.20177894228779136, 0.2592422735930029, 0.2923985608427342, 0.12074488299600128, 0.2225819645991748, 0.1355869523217238, 0.19983985327802156, 0.10742731802734051, 0.3004629885926129, 0.1255260582155161, 0.3117991802340837, 0.08370039405236462, 0.1513497984618014, 0.10819192282952028, 0.06234995318571401, 0.019066754000251818, 0.023632723852008763, 0.0005658451976636725, 0.032834875455656776, 0.08284419283150024, 0.23089127064630455, 0.006619566738323424, 0.12097614769757858, 0.1626031923319291, 0.06153321725245553, 0.18314135911563678, 0.23119285368730658, 0.008295037422650586, 0.04921324062047483, 0.11371949608153753, 0.07295530962541374, 0.11060295565606926, 0.03540267091134086, 0.039696935172835346, 0.0441281391529208, 0.1857279188197989, 0.0827403371036387, 0.06291431610762743, 0.07311190169265613, 0.09002275521396974, 0.07924700418505637, 0.05735368128555307, 0.05665705719494507, 0.24448427401834583, 0.22997797030237654, 0.23805335278113904, 0.2726629654485786, 0.05911457383305274, 0.13542072108794634, 0.07819503206598999, 0.6091542510560617, 0.6179659305122197, 0.5867874279577181, 0.6393757971903844, 0.4693118479981404, 0.5096041168517684, 0.6115279863530605, 0.6207021857061341, 0.5785845343262308, 0.05927275827856848, 0.07602933482521834, 0.08164278298810457, 0.0712868143569505, 0.08789339776338057, 0.16790667119578562, 0.07357860287302154, 0.08544322986685571, 0.12909243545054505, 0.252944871765195, 0.2070958768819685, 0.20745179213720766, 0.21159593717600045, 0.2576930231919571, 0.17223438724005724, 0.12965901138298364, 0.14712745136996896, 0.2107835870438718, 0.16976722260033872, 0.3364008527655141, 0.3909742676870488, 0.4132521890048866, 0.37408895914531026, 0.22352042658221594, 0.2047566825200171, 0.28163304128538424, 0.1938998904274536, 0.12197147167106581, 0.17435240104105, 0.25364409749048167, 0.27213329208829773, 0.19416030687939556, 0.2356430035430096, 0.2840059881450433, 0.28592694317017453, 0.291159946550418, 0.24286363079631412, 0.1368478022040326, 0.20423629734683924, 0.18697767459664882, 0.15478347530712722, 0.20113568547095373, 0.2039497103660124, 0.2220975707356071, 0.19689795386068543, 0.179657640170784, 0.19305290759791116, 0.19089329616914452, 0.19636708691118288, 0.21298661768998128, 0.19307283107254147, 0.20859625151888972, 0.1946566801667483, 0.18842495199187492, 0.8245709667566778, 0.1624860843876642, 0.15221100965343248, 0.8301456682659993, 0.18620171383534556, 0.1980846120401154, 0.14238183694580564, 0.1664848827188412, 0.2121238631228145, 0.8078478963481868, 0.20728343102491587, 0.7859679051714352, 0.20632771855555776, 0.667248979883264, 0.14471989761353377, 0.2080063564378758, 0.211196191207509, 0.716523800533237, 0.1938097579608279, 0.2114878352972962, 0.191720329451191, 0.19133405927113367, 0.19624784725392808, 0.1842017466785434, 0.19998052801159072, 0.19689251272469488, 0.179282088973875, 0.07730765922364158, 0.07835284906745688, 0.08225262965277447, 0.06486802326601415, 0.09141104167414704, 0.053629566615639335, 0.07259160383769991, 0.07574880066806922, 0.0974921512774739]}, "mutation_prompt": null}
{"id": "a483bbdf-3c20-4dff-9e81-846e18707470", "solution": "import numpy as np\n\nclass EnhancedHybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.5  # Decreased for faster convergence\n        self.cognitive_weight = 2.0  # Increased to emphasize personal experience\n        self.social_weight = 2.0  # Increased to enhance global cooperation\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        adaptive_lr = self.swarm_size  # Adaptive learning rate\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.9 * (x2 - x3)  # Increased factor for mutation\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    \n                    if np.random.rand() < 0.3:  # Local search with 30% probability\n                        local_search = mutant + np.random.normal(0, 0.1, self.dim)\n                        local_search = np.clip(local_search, self.lb, self.ub)\n                        mutant = local_search\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "EnhancedHybridPSO", "description": "Enhanced PSO with adaptive learning rates and local search to improve convergence speed.", "configspace": "", "generation": 40, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "f6ccd04a-7cc1-45ae-b080-a116ed72e58f", "metadata": {"aucs": [0.7171957053835964, 0.780137486347676, 0.6827151408603582, 0.6984922152642317, 0.7375113977089538, 0.766589172336417, 0.6931197341148846, 0.7738539845835767, 0.6620244474088419, 0.03257239363993303, 0.3417443079218486, 0.03633744007525308, 0.22615897477208968, 0.2993945097010785, 0.174169900923422, 0.1291479641445692, 0.20978274175446643, 0.034346437681954, 0.060882731728882034, 0.0995717315555259, 0.10204488502353093, 0.11138366837828417, 0.10541464751250551, 0.12180860209597488, 0.088358241994832, 0.10735596214791387, 0.06928203732424376, 0.09925037935589409, 0.04677656080572157, 0.08778513074062211, 0.09914953989939035, 0.08455399844447531, 0.11079923655501644, 0.10609433664542745, 0.05463417667899484, 0.09342165127832702, 0.989474310161318, 0.9895248236654537, 0.9829283463117212, 0.9825396314616374, 0.9818847345417261, 0.9669790489006388, 0.9894590329462951, 0.9878259088542194, 0.974382893305813, 0.4923486231827021, 0.37891171835291737, 0.4310409114979158, 0.3631119988941015, 0.4237010538714788, 0.3649962551267265, 0.439988536632679, 0.33207258210884516, 0.4240549089814948, 0.1720715629635925, 0.5511137154300236, 0.7632220055640622, 0.19401409638729783, 0.11647614996803202, 0.6191101725685184, 0.11565168402689219, 0.1472745000802077, 0.7382753601443569, 0.37811215689742406, 0.4101839123948977, 0.20377518297361785, 0.20819954455200307, 0.20177894228779136, 0.2592422735930029, 0.2923985608427342, 0.12074488299600128, 0.2225819645991748, 0.1355869523217238, 0.19983985327802156, 0.10742731802734051, 0.3004629885926129, 0.1255260582155161, 0.3117991802340837, 0.08370039405236462, 0.1513497984618014, 0.10819192282952028, 0.06234995318571401, 0.019066754000251818, 0.023632723852008763, 0.0005658451976636725, 0.032834875455656776, 0.08284419283150024, 0.23089127064630455, 0.006619566738323424, 0.12097614769757858, 0.1626031923319291, 0.06153321725245553, 0.18314135911563678, 0.23119285368730658, 0.008295037422650586, 0.04921324062047483, 0.11371949608153753, 0.07295530962541374, 0.11060295565606926, 0.03540267091134086, 0.039696935172835346, 0.0441281391529208, 0.1857279188197989, 0.0827403371036387, 0.06291431610762743, 0.07311190169265613, 0.09002275521396974, 0.07924700418505637, 0.05735368128555307, 0.05665705719494507, 0.24448427401834583, 0.22997797030237654, 0.23805335278113904, 0.2726629654485786, 0.05911457383305274, 0.13542072108794634, 0.07819503206598999, 0.6091542510560617, 0.6179659305122197, 0.5867874279577181, 0.6393757971903844, 0.4693118479981404, 0.5096041168517684, 0.6115279863530605, 0.6207021857061341, 0.5785845343262308, 0.05927275827856848, 0.07602933482521834, 0.08164278298810457, 0.0712868143569505, 0.08789339776338057, 0.16790667119578562, 0.07357860287302154, 0.08544322986685571, 0.12909243545054505, 0.252944871765195, 0.2070958768819685, 0.20745179213720766, 0.21159593717600045, 0.2576930231919571, 0.17223438724005724, 0.12965901138298364, 0.14712745136996896, 0.2107835870438718, 0.16976722260033872, 0.3364008527655141, 0.3909742676870488, 0.4132521890048866, 0.37408895914531026, 0.22352042658221594, 0.2047566825200171, 0.28163304128538424, 0.1938998904274536, 0.12197147167106581, 0.17435240104105, 0.25364409749048167, 0.27213329208829773, 0.19416030687939556, 0.2356430035430096, 0.2840059881450433, 0.28592694317017453, 0.291159946550418, 0.24286363079631412, 0.1368478022040326, 0.20423629734683924, 0.18697767459664882, 0.15478347530712722, 0.20113568547095373, 0.2039497103660124, 0.2220975707356071, 0.19689795386068543, 0.179657640170784, 0.19305290759791116, 0.19089329616914452, 0.19636708691118288, 0.21298661768998128, 0.19307283107254147, 0.20859625151888972, 0.1946566801667483, 0.18842495199187492, 0.8245709667566778, 0.1624860843876642, 0.15221100965343248, 0.8301456682659993, 0.18620171383534556, 0.1980846120401154, 0.14238183694580564, 0.1664848827188412, 0.2121238631228145, 0.8078478963481868, 0.20728343102491587, 0.7859679051714352, 0.20632771855555776, 0.667248979883264, 0.14471989761353377, 0.2080063564378758, 0.211196191207509, 0.716523800533237, 0.1938097579608279, 0.2114878352972962, 0.191720329451191, 0.19133405927113367, 0.19624784725392808, 0.1842017466785434, 0.19998052801159072, 0.19689251272469488, 0.179282088973875, 0.07730765922364158, 0.07835284906745688, 0.08225262965277447, 0.06486802326601415, 0.09141104167414704, 0.053629566615639335, 0.07259160383769991, 0.07574880066806922, 0.0974921512774739]}, "mutation_prompt": null}
{"id": "257ad545-d7bc-43f6-b750-53ebcf880b29", "solution": "import numpy as np\n\nclass EnhancedHybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.5  # Decreased for faster convergence\n        self.cognitive_weight = 2.0  # Increased to emphasize personal experience\n        self.social_weight = 2.0  # Increased to enhance global cooperation\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        adaptive_lr = self.swarm_size  # Adaptive learning rate\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.9 * (x2 - x3)  # Increased factor for mutation\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    \n                    if np.random.rand() < 0.3:  # Local search with 30% probability\n                        local_search = mutant + np.random.normal(0, 0.1, self.dim)\n                        local_search = np.clip(local_search, self.lb, self.ub)\n                        mutant = local_search\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "EnhancedHybridPSO", "description": "Enhanced PSO with adaptive learning rates and local search to improve convergence speed.", "configspace": "", "generation": 40, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "f6ccd04a-7cc1-45ae-b080-a116ed72e58f", "metadata": {"aucs": [0.7171957053835964, 0.780137486347676, 0.6827151408603582, 0.6984922152642317, 0.7375113977089538, 0.766589172336417, 0.6931197341148846, 0.7738539845835767, 0.6620244474088419, 0.03257239363993303, 0.3417443079218486, 0.03633744007525308, 0.22615897477208968, 0.2993945097010785, 0.174169900923422, 0.1291479641445692, 0.20978274175446643, 0.034346437681954, 0.060882731728882034, 0.0995717315555259, 0.10204488502353093, 0.11138366837828417, 0.10541464751250551, 0.12180860209597488, 0.088358241994832, 0.10735596214791387, 0.06928203732424376, 0.09925037935589409, 0.04677656080572157, 0.08778513074062211, 0.09914953989939035, 0.08455399844447531, 0.11079923655501644, 0.10609433664542745, 0.05463417667899484, 0.09342165127832702, 0.989474310161318, 0.9895248236654537, 0.9829283463117212, 0.9825396314616374, 0.9818847345417261, 0.9669790489006388, 0.9894590329462951, 0.9878259088542194, 0.974382893305813, 0.4923486231827021, 0.37891171835291737, 0.4310409114979158, 0.3631119988941015, 0.4237010538714788, 0.3649962551267265, 0.439988536632679, 0.33207258210884516, 0.4240549089814948, 0.1720715629635925, 0.5511137154300236, 0.7632220055640622, 0.19401409638729783, 0.11647614996803202, 0.6191101725685184, 0.11565168402689219, 0.1472745000802077, 0.7382753601443569, 0.37811215689742406, 0.4101839123948977, 0.20377518297361785, 0.20819954455200307, 0.20177894228779136, 0.2592422735930029, 0.2923985608427342, 0.12074488299600128, 0.2225819645991748, 0.1355869523217238, 0.19983985327802156, 0.10742731802734051, 0.3004629885926129, 0.1255260582155161, 0.3117991802340837, 0.08370039405236462, 0.1513497984618014, 0.10819192282952028, 0.06234995318571401, 0.019066754000251818, 0.023632723852008763, 0.0005658451976636725, 0.032834875455656776, 0.08284419283150024, 0.23089127064630455, 0.006619566738323424, 0.12097614769757858, 0.1626031923319291, 0.06153321725245553, 0.18314135911563678, 0.23119285368730658, 0.008295037422650586, 0.04921324062047483, 0.11371949608153753, 0.07295530962541374, 0.11060295565606926, 0.03540267091134086, 0.039696935172835346, 0.0441281391529208, 0.1857279188197989, 0.0827403371036387, 0.06291431610762743, 0.07311190169265613, 0.09002275521396974, 0.07924700418505637, 0.05735368128555307, 0.05665705719494507, 0.24448427401834583, 0.22997797030237654, 0.23805335278113904, 0.2726629654485786, 0.05911457383305274, 0.13542072108794634, 0.07819503206598999, 0.6091542510560617, 0.6179659305122197, 0.5867874279577181, 0.6393757971903844, 0.4693118479981404, 0.5096041168517684, 0.6115279863530605, 0.6207021857061341, 0.5785845343262308, 0.05927275827856848, 0.07602933482521834, 0.08164278298810457, 0.0712868143569505, 0.08789339776338057, 0.16790667119578562, 0.07357860287302154, 0.08544322986685571, 0.12909243545054505, 0.252944871765195, 0.2070958768819685, 0.20745179213720766, 0.21159593717600045, 0.2576930231919571, 0.17223438724005724, 0.12965901138298364, 0.14712745136996896, 0.2107835870438718, 0.16976722260033872, 0.3364008527655141, 0.3909742676870488, 0.4132521890048866, 0.37408895914531026, 0.22352042658221594, 0.2047566825200171, 0.28163304128538424, 0.1938998904274536, 0.12197147167106581, 0.17435240104105, 0.25364409749048167, 0.27213329208829773, 0.19416030687939556, 0.2356430035430096, 0.2840059881450433, 0.28592694317017453, 0.291159946550418, 0.24286363079631412, 0.1368478022040326, 0.20423629734683924, 0.18697767459664882, 0.15478347530712722, 0.20113568547095373, 0.2039497103660124, 0.2220975707356071, 0.19689795386068543, 0.179657640170784, 0.19305290759791116, 0.19089329616914452, 0.19636708691118288, 0.21298661768998128, 0.19307283107254147, 0.20859625151888972, 0.1946566801667483, 0.18842495199187492, 0.8245709667566778, 0.1624860843876642, 0.15221100965343248, 0.8301456682659993, 0.18620171383534556, 0.1980846120401154, 0.14238183694580564, 0.1664848827188412, 0.2121238631228145, 0.8078478963481868, 0.20728343102491587, 0.7859679051714352, 0.20632771855555776, 0.667248979883264, 0.14471989761353377, 0.2080063564378758, 0.211196191207509, 0.716523800533237, 0.1938097579608279, 0.2114878352972962, 0.191720329451191, 0.19133405927113367, 0.19624784725392808, 0.1842017466785434, 0.19998052801159072, 0.19689251272469488, 0.179282088973875, 0.07730765922364158, 0.07835284906745688, 0.08225262965277447, 0.06486802326601415, 0.09141104167414704, 0.053629566615639335, 0.07259160383769991, 0.07574880066806922, 0.0974921512774739]}, "mutation_prompt": null}
{"id": "5d2564d2-a0db-453b-9062-2bda23c8cc06", "solution": "import numpy as np\n\nclass EnhancedHybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.5  # Decreased for faster convergence\n        self.cognitive_weight = 2.0  # Increased to emphasize personal experience\n        self.social_weight = 2.0  # Increased to enhance global cooperation\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        adaptive_lr = self.swarm_size  # Adaptive learning rate\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.9 * (x2 - x3)  # Increased factor for mutation\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    \n                    if np.random.rand() < 0.3:  # Local search with 30% probability\n                        local_search = mutant + np.random.normal(0, 0.1, self.dim)\n                        local_search = np.clip(local_search, self.lb, self.ub)\n                        mutant = local_search\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "EnhancedHybridPSO", "description": "Enhanced PSO with adaptive learning rates and local search to improve convergence speed.", "configspace": "", "generation": 40, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "f6ccd04a-7cc1-45ae-b080-a116ed72e58f", "metadata": {"aucs": [0.7171957053835964, 0.780137486347676, 0.6827151408603582, 0.6984922152642317, 0.7375113977089538, 0.766589172336417, 0.6931197341148846, 0.7738539845835767, 0.6620244474088419, 0.03257239363993303, 0.3417443079218486, 0.03633744007525308, 0.22615897477208968, 0.2993945097010785, 0.174169900923422, 0.1291479641445692, 0.20978274175446643, 0.034346437681954, 0.060882731728882034, 0.0995717315555259, 0.10204488502353093, 0.11138366837828417, 0.10541464751250551, 0.12180860209597488, 0.088358241994832, 0.10735596214791387, 0.06928203732424376, 0.09925037935589409, 0.04677656080572157, 0.08778513074062211, 0.09914953989939035, 0.08455399844447531, 0.11079923655501644, 0.10609433664542745, 0.05463417667899484, 0.09342165127832702, 0.989474310161318, 0.9895248236654537, 0.9829283463117212, 0.9825396314616374, 0.9818847345417261, 0.9669790489006388, 0.9894590329462951, 0.9878259088542194, 0.974382893305813, 0.4923486231827021, 0.37891171835291737, 0.4310409114979158, 0.3631119988941015, 0.4237010538714788, 0.3649962551267265, 0.439988536632679, 0.33207258210884516, 0.4240549089814948, 0.1720715629635925, 0.5511137154300236, 0.7632220055640622, 0.19401409638729783, 0.11647614996803202, 0.6191101725685184, 0.11565168402689219, 0.1472745000802077, 0.7382753601443569, 0.37811215689742406, 0.4101839123948977, 0.20377518297361785, 0.20819954455200307, 0.20177894228779136, 0.2592422735930029, 0.2923985608427342, 0.12074488299600128, 0.2225819645991748, 0.1355869523217238, 0.19983985327802156, 0.10742731802734051, 0.3004629885926129, 0.1255260582155161, 0.3117991802340837, 0.08370039405236462, 0.1513497984618014, 0.10819192282952028, 0.06234995318571401, 0.019066754000251818, 0.023632723852008763, 0.0005658451976636725, 0.032834875455656776, 0.08284419283150024, 0.23089127064630455, 0.006619566738323424, 0.12097614769757858, 0.1626031923319291, 0.06153321725245553, 0.18314135911563678, 0.23119285368730658, 0.008295037422650586, 0.04921324062047483, 0.11371949608153753, 0.07295530962541374, 0.11060295565606926, 0.03540267091134086, 0.039696935172835346, 0.0441281391529208, 0.1857279188197989, 0.0827403371036387, 0.06291431610762743, 0.07311190169265613, 0.09002275521396974, 0.07924700418505637, 0.05735368128555307, 0.05665705719494507, 0.24448427401834583, 0.22997797030237654, 0.23805335278113904, 0.2726629654485786, 0.05911457383305274, 0.13542072108794634, 0.07819503206598999, 0.6091542510560617, 0.6179659305122197, 0.5867874279577181, 0.6393757971903844, 0.4693118479981404, 0.5096041168517684, 0.6115279863530605, 0.6207021857061341, 0.5785845343262308, 0.05927275827856848, 0.07602933482521834, 0.08164278298810457, 0.0712868143569505, 0.08789339776338057, 0.16790667119578562, 0.07357860287302154, 0.08544322986685571, 0.12909243545054505, 0.252944871765195, 0.2070958768819685, 0.20745179213720766, 0.21159593717600045, 0.2576930231919571, 0.17223438724005724, 0.12965901138298364, 0.14712745136996896, 0.2107835870438718, 0.16976722260033872, 0.3364008527655141, 0.3909742676870488, 0.4132521890048866, 0.37408895914531026, 0.22352042658221594, 0.2047566825200171, 0.28163304128538424, 0.1938998904274536, 0.12197147167106581, 0.17435240104105, 0.25364409749048167, 0.27213329208829773, 0.19416030687939556, 0.2356430035430096, 0.2840059881450433, 0.28592694317017453, 0.291159946550418, 0.24286363079631412, 0.1368478022040326, 0.20423629734683924, 0.18697767459664882, 0.15478347530712722, 0.20113568547095373, 0.2039497103660124, 0.2220975707356071, 0.19689795386068543, 0.179657640170784, 0.19305290759791116, 0.19089329616914452, 0.19636708691118288, 0.21298661768998128, 0.19307283107254147, 0.20859625151888972, 0.1946566801667483, 0.18842495199187492, 0.8245709667566778, 0.1624860843876642, 0.15221100965343248, 0.8301456682659993, 0.18620171383534556, 0.1980846120401154, 0.14238183694580564, 0.1664848827188412, 0.2121238631228145, 0.8078478963481868, 0.20728343102491587, 0.7859679051714352, 0.20632771855555776, 0.667248979883264, 0.14471989761353377, 0.2080063564378758, 0.211196191207509, 0.716523800533237, 0.1938097579608279, 0.2114878352972962, 0.191720329451191, 0.19133405927113367, 0.19624784725392808, 0.1842017466785434, 0.19998052801159072, 0.19689251272469488, 0.179282088973875, 0.07730765922364158, 0.07835284906745688, 0.08225262965277447, 0.06486802326601415, 0.09141104167414704, 0.053629566615639335, 0.07259160383769991, 0.07574880066806922, 0.0974921512774739]}, "mutation_prompt": null}
{"id": "2a7284c0-b6fa-44d3-af6d-d4634415ac81", "solution": "import numpy as np\n\nclass EnhancedHybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.5  # Decreased for faster convergence\n        self.cognitive_weight = 2.0  # Increased to emphasize personal experience\n        self.social_weight = 2.0  # Increased to enhance global cooperation\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        adaptive_lr = self.swarm_size  # Adaptive learning rate\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.9 * (x2 - x3)  # Increased factor for mutation\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    \n                    if np.random.rand() < 0.3:  # Local search with 30% probability\n                        local_search = mutant + np.random.normal(0, 0.1, self.dim)\n                        local_search = np.clip(local_search, self.lb, self.ub)\n                        mutant = local_search\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "EnhancedHybridPSO", "description": "Enhanced PSO with adaptive learning rates and local search to improve convergence speed.", "configspace": "", "generation": 40, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "f6ccd04a-7cc1-45ae-b080-a116ed72e58f", "metadata": {"aucs": [0.7171957053835964, 0.780137486347676, 0.6827151408603582, 0.6984922152642317, 0.7375113977089538, 0.766589172336417, 0.6931197341148846, 0.7738539845835767, 0.6620244474088419, 0.03257239363993303, 0.3417443079218486, 0.03633744007525308, 0.22615897477208968, 0.2993945097010785, 0.174169900923422, 0.1291479641445692, 0.20978274175446643, 0.034346437681954, 0.060882731728882034, 0.0995717315555259, 0.10204488502353093, 0.11138366837828417, 0.10541464751250551, 0.12180860209597488, 0.088358241994832, 0.10735596214791387, 0.06928203732424376, 0.09925037935589409, 0.04677656080572157, 0.08778513074062211, 0.09914953989939035, 0.08455399844447531, 0.11079923655501644, 0.10609433664542745, 0.05463417667899484, 0.09342165127832702, 0.989474310161318, 0.9895248236654537, 0.9829283463117212, 0.9825396314616374, 0.9818847345417261, 0.9669790489006388, 0.9894590329462951, 0.9878259088542194, 0.974382893305813, 0.4923486231827021, 0.37891171835291737, 0.4310409114979158, 0.3631119988941015, 0.4237010538714788, 0.3649962551267265, 0.439988536632679, 0.33207258210884516, 0.4240549089814948, 0.1720715629635925, 0.5511137154300236, 0.7632220055640622, 0.19401409638729783, 0.11647614996803202, 0.6191101725685184, 0.11565168402689219, 0.1472745000802077, 0.7382753601443569, 0.37811215689742406, 0.4101839123948977, 0.20377518297361785, 0.20819954455200307, 0.20177894228779136, 0.2592422735930029, 0.2923985608427342, 0.12074488299600128, 0.2225819645991748, 0.1355869523217238, 0.19983985327802156, 0.10742731802734051, 0.3004629885926129, 0.1255260582155161, 0.3117991802340837, 0.08370039405236462, 0.1513497984618014, 0.10819192282952028, 0.06234995318571401, 0.019066754000251818, 0.023632723852008763, 0.0005658451976636725, 0.032834875455656776, 0.08284419283150024, 0.23089127064630455, 0.006619566738323424, 0.12097614769757858, 0.1626031923319291, 0.06153321725245553, 0.18314135911563678, 0.23119285368730658, 0.008295037422650586, 0.04921324062047483, 0.11371949608153753, 0.07295530962541374, 0.11060295565606926, 0.03540267091134086, 0.039696935172835346, 0.0441281391529208, 0.1857279188197989, 0.0827403371036387, 0.06291431610762743, 0.07311190169265613, 0.09002275521396974, 0.07924700418505637, 0.05735368128555307, 0.05665705719494507, 0.24448427401834583, 0.22997797030237654, 0.23805335278113904, 0.2726629654485786, 0.05911457383305274, 0.13542072108794634, 0.07819503206598999, 0.6091542510560617, 0.6179659305122197, 0.5867874279577181, 0.6393757971903844, 0.4693118479981404, 0.5096041168517684, 0.6115279863530605, 0.6207021857061341, 0.5785845343262308, 0.05927275827856848, 0.07602933482521834, 0.08164278298810457, 0.0712868143569505, 0.08789339776338057, 0.16790667119578562, 0.07357860287302154, 0.08544322986685571, 0.12909243545054505, 0.252944871765195, 0.2070958768819685, 0.20745179213720766, 0.21159593717600045, 0.2576930231919571, 0.17223438724005724, 0.12965901138298364, 0.14712745136996896, 0.2107835870438718, 0.16976722260033872, 0.3364008527655141, 0.3909742676870488, 0.4132521890048866, 0.37408895914531026, 0.22352042658221594, 0.2047566825200171, 0.28163304128538424, 0.1938998904274536, 0.12197147167106581, 0.17435240104105, 0.25364409749048167, 0.27213329208829773, 0.19416030687939556, 0.2356430035430096, 0.2840059881450433, 0.28592694317017453, 0.291159946550418, 0.24286363079631412, 0.1368478022040326, 0.20423629734683924, 0.18697767459664882, 0.15478347530712722, 0.20113568547095373, 0.2039497103660124, 0.2220975707356071, 0.19689795386068543, 0.179657640170784, 0.19305290759791116, 0.19089329616914452, 0.19636708691118288, 0.21298661768998128, 0.19307283107254147, 0.20859625151888972, 0.1946566801667483, 0.18842495199187492, 0.8245709667566778, 0.1624860843876642, 0.15221100965343248, 0.8301456682659993, 0.18620171383534556, 0.1980846120401154, 0.14238183694580564, 0.1664848827188412, 0.2121238631228145, 0.8078478963481868, 0.20728343102491587, 0.7859679051714352, 0.20632771855555776, 0.667248979883264, 0.14471989761353377, 0.2080063564378758, 0.211196191207509, 0.716523800533237, 0.1938097579608279, 0.2114878352972962, 0.191720329451191, 0.19133405927113367, 0.19624784725392808, 0.1842017466785434, 0.19998052801159072, 0.19689251272469488, 0.179282088973875, 0.07730765922364158, 0.07835284906745688, 0.08225262965277447, 0.06486802326601415, 0.09141104167414704, 0.053629566615639335, 0.07259160383769991, 0.07574880066806922, 0.0974921512774739]}, "mutation_prompt": null}
{"id": "bd85c7aa-cd40-4b0f-8f52-db7abe99cf7e", "solution": "import numpy as np\n\nclass AdaptiveNonlinearPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50  # Increased swarm size for better exploration\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.9  # Start with high inertia for exploration\n        self.inertia_damping = 0.99  # Nonlinear inertia reduction\n        self.cognitive_weight = 1.5  # Adjusted cognition and social weights\n        self.social_weight = 1.5\n        self.local_search_prob = 0.4  # Increased probability for local search\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.85 * (x2 - x3)  # Adjusted mutation factor\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    \n                    if np.random.rand() < self.local_search_prob:  # Enhanced local search\n                        local_search = mutant + np.random.normal(0, 0.2, self.dim)  # Increased search radius\n                        local_search = np.clip(local_search, self.lb, self.ub)\n                        mutant = local_search\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n            # Nonlinear inertia reduction\n            self.inertia_weight *= self.inertia_damping\n\n        return global_best_position, global_best_score", "name": "AdaptiveNonlinearPSO", "description": "Adaptive PSO with nonlinear inertia and enhanced local mutation for improved convergence speed.", "configspace": "", "generation": 58, "fitness": 0.2549392550462223, "feedback": "The algorithm AdaptiveNonlinearPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.23.", "error": "", "parent_id": "f6ccd04a-7cc1-45ae-b080-a116ed72e58f", "metadata": {"aucs": [0.5879737546398046, 0.6518050176879586, 0.48059065893090325, 0.6017833555253144, 0.6502988167224986, 0.49549996399813356, 0.6184715000464873, 0.6523860154584428, 0.5020503954057471, 0.03796390664824323, 0.023534867635788714, 0.011138582960567911, 0.0643994579894901, 0.021086525347798868, 0.04932330451046474, 0.028965129662799183, 0.18809738264412412, 0.0187621682758341, 0.08017378648159534, 0.1129223230266716, 0.10966766136772077, 0.11019942565307772, 0.09941023990848985, 0.09292839452060653, 0.10446109574539553, 0.11929571765105917, 0.07873527259199342, 0.0693740967752936, 0.08625315743821371, 0.08395351600010037, 0.07734892342354505, 0.04165021653943057, 0.02820796847647067, 0.08611561227473308, 0.12044713239462668, 0.09717120921831524, 0.9676190982249329, 0.9781153195726774, 0.9765909252751392, 0.9642073497404854, 0.9732691552486262, 0.968133839171489, 0.9734162994513458, 0.9775639418456531, 0.975860294335061, 0.3651896600626513, 0.450620854549704, 0.30148294630913774, 0.3759425591840686, 0.46063983004663556, 0.2551397840558979, 0.3299952292136421, 0.3698704852791139, 0.275599841147263, 0.5924292926546487, 0.655640470898172, 0.2033611079697515, 0.19764090862418926, 0.24277894609923045, 0.19832310651298035, 0.5919105518344155, 0.22529853343493023, 0.46779824326253483, 0.12519772200852441, 0.08877050170798484, 0.10259624041811699, 0.08265560795945714, 0.11531976516558029, 0.08411190693184889, 0.14314154569793025, 0.193183874539825, 0.17670727823377108, 0.1698157653455744, 0.19664836999407354, 0.1812595448625166, 0.15285000933845072, 0.16418662852591714, 0.11718140019668555, 0.20884547470196035, 0.11136468108134101, 0.2453784307336372, 0.03662627796800444, 0.16669029767356336, 9.999999999998899e-05, 0.00043527079745142583, 0.04167300200521751, 9.999999999998899e-05, 0.07093574861242924, 0.12038437451148598, 0.027236134310795412, 0.14365105120460742, 0.08616871917855351, 0.10477704559495482, 0.10062068183539208, 0.028078483302943602, 0.11870116017586385, 0.3253148928413331, 0.36408689360651847, 0.11085835963142143, 0.018540026836056267, 0.13214698709474537, 0.017030678653936815, 0.04372839235893311, 0.05009233778328359, 0.03234453868509557, 0.08855299708568787, 0.09943198753770977, 0.03709687204977741, 0.03363783876093185, 0.16062046568517652, 0.09888364486203305, 0.12974925437532747, 0.18714979577827484, 0.049696198245259615, 0.047061356279749056, 0.06016605486173432, 0.06491562457010691, 0.49858909649449523, 0.5564004250240571, 0.45449667209365086, 0.48352390565484527, 0.528539346708679, 0.3845381577235275, 0.44961378885321646, 0.4908021518829193, 0.40319700533540104, 0.07857341369727344, 0.07010661868437851, 0.07532588832130227, 0.11826697047331969, 0.10682451334205745, 0.09487377208392922, 0.12076109453321549, 0.08830679952723985, 0.07172134948617237, 0.33330439137896606, 0.18823059259887986, 0.16995797027209758, 0.21027865063969553, 0.36812535369751453, 0.198618761669749, 0.23020763388727628, 0.23306952345731724, 0.2144968462745349, 0.3191861960351532, 0.27133606648539477, 0.28869266350018974, 0.35231464258031586, 0.30869586277538597, 0.31197780945006715, 0.28643113322500635, 0.27053092231181697, 0.28482548836213706, 0.2089855933387248, 0.2621767100257566, 0.2041490682099356, 0.3039856888770256, 0.18209091134004995, 0.23665061028868994, 0.207921003140757, 0.35428569916078423, 0.1982510465586853, 0.1999897670502896, 0.23918930708185304, 0.18527630020468955, 0.2286127329859683, 0.23910994366844363, 0.20313314626691104, 0.2933125238930776, 0.21258410376209136, 0.2169682349357035, 0.1874000029058932, 0.22186300220307276, 0.1905418375644936, 0.1846665465424392, 0.17943643807430565, 0.21796207640211418, 0.17134496074491612, 0.5143974847259503, 0.20469109105006067, 0.7297716013767761, 0.19914896750072153, 0.569537079402151, 0.6615938053058186, 0.19852145167189694, 0.14245882578399283, 0.620920899389191, 0.7500440415147751, 0.16805805481964942, 0.6657148347362931, 0.2041651047837233, 0.5433371299361289, 0.5044353584893206, 0.7179414210244119, 0.13785011883428966, 0.2049855244293024, 0.7100327660287085, 0.2029449990205976, 0.1943033898758576, 0.21109653155598795, 0.19259880075181712, 0.21554590694876874, 0.18506958595655665, 0.1922419792756076, 0.20410977344778036, 0.18214986068878092, 0.21323900049382205, 0.08051366515842351, 0.08293615179350422, 0.06901982238071958, 0.07173804413287566, 0.09021033160249714, 0.07319305391231024, 0.09232288294545721, 0.0826681566683175, 0.0853595390436589]}, "mutation_prompt": null}
{"id": "c405c7ea-fdd0-403a-a75a-7fd398c5a9c5", "solution": "import numpy as np\n\nclass AdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.lb = -5.0\n        self.ub = 5.0\n        self.F = 0.8  # Scaling factor for mutation\n        self.CR = 0.7  # Crossover probability\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n        best_score = scores[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                idxs = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = population[idxs]\n                mutant = np.clip(x1 + self.F * (x2 - x3), self.lb, self.ub)\n\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial\n                    scores[i] = trial_score\n\n                    if trial_score < best_score:\n                        best_solution = trial\n                        best_score = trial_score\n\n            if evaluations + self.population_size <= self.budget:\n                for i in range(self.population_size):\n                    local_search = best_solution + np.random.normal(0, 0.05, self.dim)\n                    local_search = np.clip(local_search, self.lb, self.ub)\n                    local_score = func(local_search)\n                    evaluations += 1\n\n                    if local_score < scores[i]:\n                        population[i] = local_search\n                        scores[i] = local_score\n\n                        if local_score < best_score:\n                            best_solution = local_search\n                            best_score = local_score\n\n        return best_solution, best_score", "name": "AdaptiveDELS", "description": "Adaptive Differential Evolution integrated with enhanced local search for improved convergence speed.", "configspace": "", "generation": 59, "fitness": 0.23616628117957486, "feedback": "The algorithm AdaptiveDELS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.22.", "error": "", "parent_id": "f6ccd04a-7cc1-45ae-b080-a116ed72e58f", "metadata": {"aucs": [0.752004171353402, 0.7546704042254008, 0.7600641944793611, 0.7405468969172824, 0.7598223392789931, 0.7297853814496139, 0.73191738929878, 0.7595499779911423, 0.7548686774268447, 0.26036571425565114, 0.27503291226921756, 0.2980318165856449, 0.3088192836788256, 0.30116305981738534, 0.28066826772915343, 0.30392337664249425, 0.3319116303393279, 0.29422093527552506, 0.025154714070155904, 0.032752517826587835, 0.046176553432416, 0.023720038629995166, 0.022263413685735034, 0.03456788569880387, 0.04178649200854834, 0.11399724318765914, 0.07122058839751244, 0.014349895728483664, 0.03011758922795782, 0.014864449856435202, 0.07365370756787382, 0.013736078486123682, 0.006208735841491175, 0.043666840591261136, 0.012019816585086107, 9.999999999998899e-05, 0.8723083475428357, 0.746543215613378, 0.8589450143259529, 0.8442105121225382, 0.9057207871365125, 0.819948328481539, 0.9226652202226908, 0.8190121151875003, 0.9037766646169325, 0.47527134459302145, 0.43637338508082935, 0.3863197991956614, 0.43440381382075777, 0.43278111824107923, 0.4420668201722543, 0.4366645612194492, 0.44697798354318086, 0.41211387063044935, 0.130035762013067, 0.18342962863158807, 0.0792520369388856, 0.2828072168163207, 0.13533019227928633, 0.010755008433955715, 0.03993187058150893, 0.12746571485637015, 0.05371850624534669, 0.3646939129901653, 0.2120158598406917, 0.2863863546493486, 0.21309747496623288, 0.24420471406389832, 0.1988551840893158, 0.25875715670477617, 0.33548386024338184, 0.28629184107856176, 0.24999238940150703, 0.2475318579495145, 0.2623366018213017, 0.25085458716425924, 0.23606038836209142, 0.19597114870726562, 0.27574120216056086, 0.2792720657104417, 0.26273216673068045, 0.02909448203534848, 0.15179327930083364, 0.1029118707002834, 0.048207943658032715, 0.10540277883198412, 0.054075993551742085, 0.03957307470988469, 0.09703797913578782, 0.07389412410596119, 0.10407774852922991, 0.09075898844342412, 0.16221324057622954, 0.15656175066621814, 0.1328725667929117, 0.12406293024943915, 0.20661982145524005, 0.1799717606063439, 0.2375780384726952, 0.08439977870290294, 0.05801024675574573, 0.067018141510784, 0.06640895840940086, 0.06771490428032634, 0.0771512570582168, 0.0876681604019528, 0.08686382602878329, 0.11067392532463005, 0.19055944765631705, 0.11699106394039915, 0.19636622788842195, 0.16075201836889685, 0.20018189177625245, 0.16282239445170654, 0.20147504672951622, 0.18351330155888823, 0.1456087403865517, 0.5405977209756798, 0.5464643937516405, 0.5352928363230346, 0.5352396907083778, 0.5073366992720613, 0.5259783172271262, 0.534950617808523, 0.5389923618690395, 0.5627472258836816, 0.015457076657483748, 0.07379489997394917, 0.05343863243315505, 0.05209175329220184, 0.02668721069032509, 0.05981715788447839, 0.050532996863511426, 0.026729310206884627, 0.08438391661670397, 0.20239407221706374, 0.1676499246812997, 0.22222260261882576, 0.16492410925315693, 0.20027300054294805, 0.16892687162313136, 0.2351044897996858, 0.1659216721240826, 0.2194778468450007, 0.1444856737572613, 0.12780416248850435, 0.166990404591152, 0.18639403234284757, 0.1788661761075786, 0.16164989652612438, 0.16053487170637348, 0.23486959875409852, 0.14973027652278526, 0.12974546725257785, 0.041082171127556855, 0.11180915859838803, 0.24035745763533534, 0.07788073629539227, 0.10786663405718011, 0.21991112655965628, 0.20551038128687238, 0.08660044874876605, 0.2060465573988568, 0.21042650953298203, 0.17286721210811318, 0.23701262119185262, 0.17002328360080576, 0.15044218676721777, 0.1970623355794976, 0.1560369777434435, 0.22114144188762408, 0.16631708506402954, 0.166010413164296, 0.16815533762246737, 0.21346360200231884, 0.19842673533212762, 0.1941631731269845, 0.174129454906072, 0.1998177201366168, 0.2092201923207635, 0.1129311490542857, 0.21375430090330338, 0.15439578798744902, 0.11980788407394416, 0.20186510894435883, 0.11299014176157729, 0.1322428969424947, 0.16409193899009533, 0.15943779175248707, 0.8268643034597176, 0.21406396812737227, 0.07362546512846435, 0.10470842505373856, 0.11313750278093526, 0.08326318515901243, 0.1048489913548234, 0.15704524924464947, 0.7499893629190266, 0.18810520580034185, 0.19147302003309163, 0.17713561341805684, 0.22890596898705795, 0.19851900980585868, 0.17677265711038703, 0.2185371289889222, 0.1983035672984842, 0.18758186043828629, 0.07780278495694093, 0.04865821549929572, 0.06663126410140319, 0.05819954607486033, 0.0752063013480192, 0.0526480070160984, 0.08882634445386917, 0.08730890502595645, 0.05424066074159695]}, "mutation_prompt": null}
{"id": "4bd952dc-d546-44c8-abea-5a04aba682e2", "solution": "import numpy as np\n\nclass EnhancedHybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.5  # Decreased for faster convergence\n        self.cognitive_weight = 2.0  # Increased to emphasize personal experience\n        self.social_weight = 2.0  # Increased to enhance global cooperation\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        adaptive_lr = self.swarm_size  # Adaptive learning rate\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                for i in range(self.swarm_size):\n                    idxs = np.random.choice(np.arange(self.swarm_size), 3, replace=False)\n                    x1, x2, x3 = positions[idxs]\n                    mutant = x1 + 0.9 * (x2 - x3)  # Increased factor for mutation\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    \n                    if np.random.rand() < 0.3:  # Local search with 30% probability\n                        local_search = mutant + np.random.normal(0, 0.1, self.dim)\n                        local_search = np.clip(local_search, self.lb, self.ub)\n                        mutant = local_search\n\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n        return global_best_position, global_best_score", "name": "EnhancedHybridPSO", "description": "Enhanced PSO with adaptive learning rates and local search to improve convergence speed.", "configspace": "", "generation": 40, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "f6ccd04a-7cc1-45ae-b080-a116ed72e58f", "metadata": {"aucs": [0.7171957053835964, 0.780137486347676, 0.6827151408603582, 0.6984922152642317, 0.7375113977089538, 0.766589172336417, 0.6931197341148846, 0.7738539845835767, 0.6620244474088419, 0.03257239363993303, 0.3417443079218486, 0.03633744007525308, 0.22615897477208968, 0.2993945097010785, 0.174169900923422, 0.1291479641445692, 0.20978274175446643, 0.034346437681954, 0.060882731728882034, 0.0995717315555259, 0.10204488502353093, 0.11138366837828417, 0.10541464751250551, 0.12180860209597488, 0.088358241994832, 0.10735596214791387, 0.06928203732424376, 0.09925037935589409, 0.04677656080572157, 0.08778513074062211, 0.09914953989939035, 0.08455399844447531, 0.11079923655501644, 0.10609433664542745, 0.05463417667899484, 0.09342165127832702, 0.989474310161318, 0.9895248236654537, 0.9829283463117212, 0.9825396314616374, 0.9818847345417261, 0.9669790489006388, 0.9894590329462951, 0.9878259088542194, 0.974382893305813, 0.4923486231827021, 0.37891171835291737, 0.4310409114979158, 0.3631119988941015, 0.4237010538714788, 0.3649962551267265, 0.439988536632679, 0.33207258210884516, 0.4240549089814948, 0.1720715629635925, 0.5511137154300236, 0.7632220055640622, 0.19401409638729783, 0.11647614996803202, 0.6191101725685184, 0.11565168402689219, 0.1472745000802077, 0.7382753601443569, 0.37811215689742406, 0.4101839123948977, 0.20377518297361785, 0.20819954455200307, 0.20177894228779136, 0.2592422735930029, 0.2923985608427342, 0.12074488299600128, 0.2225819645991748, 0.1355869523217238, 0.19983985327802156, 0.10742731802734051, 0.3004629885926129, 0.1255260582155161, 0.3117991802340837, 0.08370039405236462, 0.1513497984618014, 0.10819192282952028, 0.06234995318571401, 0.019066754000251818, 0.023632723852008763, 0.0005658451976636725, 0.032834875455656776, 0.08284419283150024, 0.23089127064630455, 0.006619566738323424, 0.12097614769757858, 0.1626031923319291, 0.06153321725245553, 0.18314135911563678, 0.23119285368730658, 0.008295037422650586, 0.04921324062047483, 0.11371949608153753, 0.07295530962541374, 0.11060295565606926, 0.03540267091134086, 0.039696935172835346, 0.0441281391529208, 0.1857279188197989, 0.0827403371036387, 0.06291431610762743, 0.07311190169265613, 0.09002275521396974, 0.07924700418505637, 0.05735368128555307, 0.05665705719494507, 0.24448427401834583, 0.22997797030237654, 0.23805335278113904, 0.2726629654485786, 0.05911457383305274, 0.13542072108794634, 0.07819503206598999, 0.6091542510560617, 0.6179659305122197, 0.5867874279577181, 0.6393757971903844, 0.4693118479981404, 0.5096041168517684, 0.6115279863530605, 0.6207021857061341, 0.5785845343262308, 0.05927275827856848, 0.07602933482521834, 0.08164278298810457, 0.0712868143569505, 0.08789339776338057, 0.16790667119578562, 0.07357860287302154, 0.08544322986685571, 0.12909243545054505, 0.252944871765195, 0.2070958768819685, 0.20745179213720766, 0.21159593717600045, 0.2576930231919571, 0.17223438724005724, 0.12965901138298364, 0.14712745136996896, 0.2107835870438718, 0.16976722260033872, 0.3364008527655141, 0.3909742676870488, 0.4132521890048866, 0.37408895914531026, 0.22352042658221594, 0.2047566825200171, 0.28163304128538424, 0.1938998904274536, 0.12197147167106581, 0.17435240104105, 0.25364409749048167, 0.27213329208829773, 0.19416030687939556, 0.2356430035430096, 0.2840059881450433, 0.28592694317017453, 0.291159946550418, 0.24286363079631412, 0.1368478022040326, 0.20423629734683924, 0.18697767459664882, 0.15478347530712722, 0.20113568547095373, 0.2039497103660124, 0.2220975707356071, 0.19689795386068543, 0.179657640170784, 0.19305290759791116, 0.19089329616914452, 0.19636708691118288, 0.21298661768998128, 0.19307283107254147, 0.20859625151888972, 0.1946566801667483, 0.18842495199187492, 0.8245709667566778, 0.1624860843876642, 0.15221100965343248, 0.8301456682659993, 0.18620171383534556, 0.1980846120401154, 0.14238183694580564, 0.1664848827188412, 0.2121238631228145, 0.8078478963481868, 0.20728343102491587, 0.7859679051714352, 0.20632771855555776, 0.667248979883264, 0.14471989761353377, 0.2080063564378758, 0.211196191207509, 0.716523800533237, 0.1938097579608279, 0.2114878352972962, 0.191720329451191, 0.19133405927113367, 0.19624784725392808, 0.1842017466785434, 0.19998052801159072, 0.19689251272469488, 0.179282088973875, 0.07730765922364158, 0.07835284906745688, 0.08225262965277447, 0.06486802326601415, 0.09141104167414704, 0.053629566615639335, 0.07259160383769991, 0.07574880066806922, 0.0974921512774739]}, "mutation_prompt": null}
{"id": "a5d7036d-9a2d-4b13-9fbb-00412e65f461", "solution": "import numpy as np\n\nclass DynamicAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7  # Increased for exploration\n        self.cognitive_weight = 1.5  # Adjusted for balanced learning\n        self.social_weight = 1.5  # Adjusted for balanced cooperation\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: 0.9 - iter * 0.5 / (self.budget/self.swarm_size)\n\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            velocities = np.clip(velocities, -1, 1)  # Control velocity\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 2 <= self.budget:\n                elite_idxs = np.argsort(personal_best_scores)[:3]\n                for i in elite_idxs:\n                    mutant = 0.5 * (positions[i] + global_best_position)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "DynamicAdaptivePSO", "description": "Dynamic Adaptive PSO with velocity control and elitist learning for enhanced convergence.", "configspace": "", "generation": 61, "fitness": 0.28095010709088053, "feedback": "The algorithm DynamicAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.25.", "error": "", "parent_id": "f6ccd04a-7cc1-45ae-b080-a116ed72e58f", "metadata": {"aucs": [0.8032135972550823, 0.7949118659281794, 0.8482728446676409, 0.7993670345346594, 0.7737528802393012, 0.8464902526554178, 0.8046519253932358, 0.805590481213056, 0.8461412014093087, 0.005783314147535412, 0.08588937958091614, 0.07784687388371492, 0.016921844029064936, 0.0421895187336917, 0.15930331104042017, 0.04351665314983588, 9.999999999998899e-05, 0.09932457982432175, 0.10887936612205595, 0.14106487423359249, 0.10120120324682214, 0.13712488658640198, 0.1131927136557066, 0.11801005973914358, 0.06999116975530628, 0.08998994870091392, 0.153945641686013, 0.08902008972685305, 0.08609414085503653, 0.07747571058178349, 0.0991600265351037, 0.09621864220040444, 0.08885327355791683, 0.08154460108384465, 0.1206487651268191, 0.12317125854406696, 0.9500949981300757, 0.9610162495112076, 0.9608173185629282, 0.9569062299208816, 0.9579478633221649, 0.9533167253824387, 0.9589146234755783, 0.9456046762511077, 0.9615824603584858, 0.4997793869222614, 0.4305469045242265, 0.058042371818485705, 0.46568283067902316, 0.5187228327236573, 0.6723002426355029, 0.4294246886935441, 0.5551157071569044, 0.641129866546762, 0.2292504105416071, 0.2218058456312637, 0.22230656550713235, 0.33686295881202966, 0.27848606767370654, 0.21454053637429038, 0.20372963880149297, 0.15128821080273958, 0.39794626784261933, 0.22356068920084582, 0.14967899882762736, 0.3460745606001445, 0.13462870221790602, 0.13066161760638317, 0.1324333383194748, 0.26398070659869854, 0.5457827007374707, 0.6120169801637243, 0.13625233789797386, 0.24549133917399624, 0.13080430473110705, 0.13304666547801958, 0.13049659211334108, 0.13322173749730915, 0.21974090720652262, 0.1329639560906808, 0.1496385188927687, 0.004779048812517228, 0.17108797815354215, 0.25301519995891086, 0.05261252643587688, 0.12892384650099942, 0.0551684261914539, 0.006967628751370136, 0.11560747877196131, 0.12697739756745263, 0.15582431031483435, 0.09271555454571134, 0.15588800980252215, 0.10144902398426314, 0.06251420999704094, 0.07262084805527613, 0.08868747636358199, 0.11478102569127746, 0.09063059883759139, 0.12629005560510398, 0.09117513492272067, 0.17992686308692896, 0.10157509588947888, 0.11298179534745356, 0.15921708450034489, 0.08881133929437979, 0.13247967106154301, 0.20445416066555633, 0.1399055081927416, 0.10754854008343029, 0.26729325538556115, 0.0596286347337982, 0.2448441980950371, 0.07214332914793808, 0.22059840068686798, 0.07908865836731516, 0.09107640683861773, 0.5499288843441377, 0.6016802621354878, 0.5231668860289979, 0.5644406241666733, 0.5566533566676373, 0.5288568064385815, 0.5475886810377337, 0.5761841935507019, 0.6504214794789962, 0.08579403613110825, 0.09511929359087767, 0.14358011889337485, 0.09139821050759911, 0.11572463611429029, 0.10133279161032172, 0.11044625751079806, 0.10866352333885332, 0.11943270448993082, 0.2573311502062082, 0.22937414607557227, 0.19562154618877514, 0.3202692776393762, 0.20794559527720802, 0.20597359180019348, 0.26406130645571035, 0.2074774402405345, 0.40768283736460964, 0.18968002504602866, 0.32157365857738074, 0.3186151167879774, 0.33270363046002127, 0.2627444216739391, 0.2956015666241564, 0.21223646936301965, 0.3446130627616192, 0.22516985515672672, 0.22839949534625337, 0.25188988208791263, 0.25708494613176014, 0.29383914690161095, 0.17597975328975912, 0.25694322558054883, 0.18494244727765208, 0.2339092527794896, 0.22570769178373118, 0.23044350852583495, 0.2027194210053198, 0.211207360384028, 0.2385316905634688, 0.22879519414509175, 0.2526855623887996, 0.2889346062899941, 0.2307853887943655, 0.24870378186150188, 0.18483349298354435, 0.17058772111900034, 0.17391439201665038, 0.2270224744771232, 0.19906074777213134, 0.2014155098146012, 0.18572017396038665, 0.1875717454911342, 0.1765831943232613, 0.12658049617049671, 0.18757007971982376, 0.18694638686780962, 0.8592490352296711, 0.20049573519452968, 0.905463766379589, 0.14279112348068845, 0.8799172487320415, 0.9193381292571849, 0.8451848882252659, 0.2127446801105125, 0.862780704699071, 0.20899976331010583, 0.16866968390842374, 0.15521966944610244, 0.1050603046932228, 0.16750994235662564, 0.8301194917821172, 0.19359790302667412, 0.20541408507986803, 0.1828618480262616, 0.2147502480355553, 0.22612882847610083, 0.21115730752580986, 0.19981973822326748, 0.2168632705337129, 0.21118635083666837, 0.11197120297328023, 0.10713089067001458, 0.09632377131591785, 0.09663159245068198, 0.0932014556206584, 0.09202853398997957, 0.07720826498898636, 0.0996155979047102, 0.10561207933836725]}, "mutation_prompt": null}
{"id": "104f4feb-cced-4b1a-872c-8f75a4227b78", "solution": "import numpy as np\n\nclass DynamicAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7  # Increased for exploration\n        self.cognitive_weight = 1.5  # Adjusted for balanced learning\n        self.social_weight = 1.5  # Adjusted for balanced cooperation\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: 0.9 - iter * 0.5 / (self.budget/self.swarm_size)\n\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            velocities = np.clip(velocities, -1, 1)  # Control velocity\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 2 <= self.budget:\n                elite_idxs = np.argsort(personal_best_scores)[:3]\n                for i in elite_idxs:\n                    mutant = 0.5 * (positions[i] + global_best_position)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "DynamicAdaptivePSO", "description": "Dynamic Adaptive PSO with velocity control and elitist learning for enhanced convergence.", "configspace": "", "generation": 62, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a5d7036d-9a2d-4b13-9fbb-00412e65f461", "metadata": {"aucs": [0.8032135972550823, 0.7949118659281794, 0.8482728446676409, 0.7993670345346594, 0.7737528802393012, 0.8464902526554178, 0.8046519253932358, 0.805590481213056, 0.8461412014093087, 0.005783314147535412, 0.08588937958091614, 0.07784687388371492, 0.016921844029064936, 0.0421895187336917, 0.15930331104042017, 0.04351665314983588, 9.999999999998899e-05, 0.09932457982432175, 0.10887936612205595, 0.14106487423359249, 0.10120120324682214, 0.13712488658640198, 0.1131927136557066, 0.11801005973914358, 0.06999116975530628, 0.08998994870091392, 0.153945641686013, 0.08902008972685305, 0.08609414085503653, 0.07747571058178349, 0.0991600265351037, 0.09621864220040444, 0.08885327355791683, 0.08154460108384465, 0.1206487651268191, 0.12317125854406696, 0.9500949981300757, 0.9610162495112076, 0.9608173185629282, 0.9569062299208816, 0.9579478633221649, 0.9533167253824387, 0.9589146234755783, 0.9456046762511077, 0.9615824603584858, 0.4997793869222614, 0.4305469045242265, 0.058042371818485705, 0.46568283067902316, 0.5187228327236573, 0.6723002426355029, 0.4294246886935441, 0.5551157071569044, 0.641129866546762, 0.2292504105416071, 0.2218058456312637, 0.22230656550713235, 0.33686295881202966, 0.27848606767370654, 0.21454053637429038, 0.20372963880149297, 0.15128821080273958, 0.39794626784261933, 0.22356068920084582, 0.14967899882762736, 0.3460745606001445, 0.13462870221790602, 0.13066161760638317, 0.1324333383194748, 0.26398070659869854, 0.5457827007374707, 0.6120169801637243, 0.13625233789797386, 0.24549133917399624, 0.13080430473110705, 0.13304666547801958, 0.13049659211334108, 0.13322173749730915, 0.21974090720652262, 0.1329639560906808, 0.1496385188927687, 0.004779048812517228, 0.17108797815354215, 0.25301519995891086, 0.05261252643587688, 0.12892384650099942, 0.0551684261914539, 0.006967628751370136, 0.11560747877196131, 0.12697739756745263, 0.15582431031483435, 0.09271555454571134, 0.15588800980252215, 0.10144902398426314, 0.06251420999704094, 0.07262084805527613, 0.08868747636358199, 0.11478102569127746, 0.09063059883759139, 0.12629005560510398, 0.09117513492272067, 0.17992686308692896, 0.10157509588947888, 0.11298179534745356, 0.15921708450034489, 0.08881133929437979, 0.13247967106154301, 0.20445416066555633, 0.1399055081927416, 0.10754854008343029, 0.26729325538556115, 0.0596286347337982, 0.2448441980950371, 0.07214332914793808, 0.22059840068686798, 0.07908865836731516, 0.09107640683861773, 0.5499288843441377, 0.6016802621354878, 0.5231668860289979, 0.5644406241666733, 0.5566533566676373, 0.5288568064385815, 0.5475886810377337, 0.5761841935507019, 0.6504214794789962, 0.08579403613110825, 0.09511929359087767, 0.14358011889337485, 0.09139821050759911, 0.11572463611429029, 0.10133279161032172, 0.11044625751079806, 0.10866352333885332, 0.11943270448993082, 0.2573311502062082, 0.22937414607557227, 0.19562154618877514, 0.3202692776393762, 0.20794559527720802, 0.20597359180019348, 0.26406130645571035, 0.2074774402405345, 0.40768283736460964, 0.18968002504602866, 0.32157365857738074, 0.3186151167879774, 0.33270363046002127, 0.2627444216739391, 0.2956015666241564, 0.21223646936301965, 0.3446130627616192, 0.22516985515672672, 0.22839949534625337, 0.25188988208791263, 0.25708494613176014, 0.29383914690161095, 0.17597975328975912, 0.25694322558054883, 0.18494244727765208, 0.2339092527794896, 0.22570769178373118, 0.23044350852583495, 0.2027194210053198, 0.211207360384028, 0.2385316905634688, 0.22879519414509175, 0.2526855623887996, 0.2889346062899941, 0.2307853887943655, 0.24870378186150188, 0.18483349298354435, 0.17058772111900034, 0.17391439201665038, 0.2270224744771232, 0.19906074777213134, 0.2014155098146012, 0.18572017396038665, 0.1875717454911342, 0.1765831943232613, 0.12658049617049671, 0.18757007971982376, 0.18694638686780962, 0.8592490352296711, 0.20049573519452968, 0.905463766379589, 0.14279112348068845, 0.8799172487320415, 0.9193381292571849, 0.8451848882252659, 0.2127446801105125, 0.862780704699071, 0.20899976331010583, 0.16866968390842374, 0.15521966944610244, 0.1050603046932228, 0.16750994235662564, 0.8301194917821172, 0.19359790302667412, 0.20541408507986803, 0.1828618480262616, 0.2147502480355553, 0.22612882847610083, 0.21115730752580986, 0.19981973822326748, 0.2168632705337129, 0.21118635083666837, 0.11197120297328023, 0.10713089067001458, 0.09632377131591785, 0.09663159245068198, 0.0932014556206584, 0.09202853398997957, 0.07720826498898636, 0.0996155979047102, 0.10561207933836725]}, "mutation_prompt": null}
{"id": "e9279f41-f146-4af4-8565-4e24117f4dd2", "solution": "import numpy as np\n\nclass DynamicAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7  # Increased for exploration\n        self.cognitive_weight = 1.5  # Adjusted for balanced learning\n        self.social_weight = 1.5  # Adjusted for balanced cooperation\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: 0.9 - iter * 0.5 / (self.budget/self.swarm_size)\n\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            velocities = np.clip(velocities, -1, 1)  # Control velocity\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 2 <= self.budget:\n                elite_idxs = np.argsort(personal_best_scores)[:3]\n                for i in elite_idxs:\n                    mutant = 0.5 * (positions[i] + global_best_position)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "DynamicAdaptivePSO", "description": "Dynamic Adaptive PSO with velocity control and elitist learning for enhanced convergence.", "configspace": "", "generation": 62, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a5d7036d-9a2d-4b13-9fbb-00412e65f461", "metadata": {"aucs": [0.8032135972550823, 0.7949118659281794, 0.8482728446676409, 0.7993670345346594, 0.7737528802393012, 0.8464902526554178, 0.8046519253932358, 0.805590481213056, 0.8461412014093087, 0.005783314147535412, 0.08588937958091614, 0.07784687388371492, 0.016921844029064936, 0.0421895187336917, 0.15930331104042017, 0.04351665314983588, 9.999999999998899e-05, 0.09932457982432175, 0.10887936612205595, 0.14106487423359249, 0.10120120324682214, 0.13712488658640198, 0.1131927136557066, 0.11801005973914358, 0.06999116975530628, 0.08998994870091392, 0.153945641686013, 0.08902008972685305, 0.08609414085503653, 0.07747571058178349, 0.0991600265351037, 0.09621864220040444, 0.08885327355791683, 0.08154460108384465, 0.1206487651268191, 0.12317125854406696, 0.9500949981300757, 0.9610162495112076, 0.9608173185629282, 0.9569062299208816, 0.9579478633221649, 0.9533167253824387, 0.9589146234755783, 0.9456046762511077, 0.9615824603584858, 0.4997793869222614, 0.4305469045242265, 0.058042371818485705, 0.46568283067902316, 0.5187228327236573, 0.6723002426355029, 0.4294246886935441, 0.5551157071569044, 0.641129866546762, 0.2292504105416071, 0.2218058456312637, 0.22230656550713235, 0.33686295881202966, 0.27848606767370654, 0.21454053637429038, 0.20372963880149297, 0.15128821080273958, 0.39794626784261933, 0.22356068920084582, 0.14967899882762736, 0.3460745606001445, 0.13462870221790602, 0.13066161760638317, 0.1324333383194748, 0.26398070659869854, 0.5457827007374707, 0.6120169801637243, 0.13625233789797386, 0.24549133917399624, 0.13080430473110705, 0.13304666547801958, 0.13049659211334108, 0.13322173749730915, 0.21974090720652262, 0.1329639560906808, 0.1496385188927687, 0.004779048812517228, 0.17108797815354215, 0.25301519995891086, 0.05261252643587688, 0.12892384650099942, 0.0551684261914539, 0.006967628751370136, 0.11560747877196131, 0.12697739756745263, 0.15582431031483435, 0.09271555454571134, 0.15588800980252215, 0.10144902398426314, 0.06251420999704094, 0.07262084805527613, 0.08868747636358199, 0.11478102569127746, 0.09063059883759139, 0.12629005560510398, 0.09117513492272067, 0.17992686308692896, 0.10157509588947888, 0.11298179534745356, 0.15921708450034489, 0.08881133929437979, 0.13247967106154301, 0.20445416066555633, 0.1399055081927416, 0.10754854008343029, 0.26729325538556115, 0.0596286347337982, 0.2448441980950371, 0.07214332914793808, 0.22059840068686798, 0.07908865836731516, 0.09107640683861773, 0.5499288843441377, 0.6016802621354878, 0.5231668860289979, 0.5644406241666733, 0.5566533566676373, 0.5288568064385815, 0.5475886810377337, 0.5761841935507019, 0.6504214794789962, 0.08579403613110825, 0.09511929359087767, 0.14358011889337485, 0.09139821050759911, 0.11572463611429029, 0.10133279161032172, 0.11044625751079806, 0.10866352333885332, 0.11943270448993082, 0.2573311502062082, 0.22937414607557227, 0.19562154618877514, 0.3202692776393762, 0.20794559527720802, 0.20597359180019348, 0.26406130645571035, 0.2074774402405345, 0.40768283736460964, 0.18968002504602866, 0.32157365857738074, 0.3186151167879774, 0.33270363046002127, 0.2627444216739391, 0.2956015666241564, 0.21223646936301965, 0.3446130627616192, 0.22516985515672672, 0.22839949534625337, 0.25188988208791263, 0.25708494613176014, 0.29383914690161095, 0.17597975328975912, 0.25694322558054883, 0.18494244727765208, 0.2339092527794896, 0.22570769178373118, 0.23044350852583495, 0.2027194210053198, 0.211207360384028, 0.2385316905634688, 0.22879519414509175, 0.2526855623887996, 0.2889346062899941, 0.2307853887943655, 0.24870378186150188, 0.18483349298354435, 0.17058772111900034, 0.17391439201665038, 0.2270224744771232, 0.19906074777213134, 0.2014155098146012, 0.18572017396038665, 0.1875717454911342, 0.1765831943232613, 0.12658049617049671, 0.18757007971982376, 0.18694638686780962, 0.8592490352296711, 0.20049573519452968, 0.905463766379589, 0.14279112348068845, 0.8799172487320415, 0.9193381292571849, 0.8451848882252659, 0.2127446801105125, 0.862780704699071, 0.20899976331010583, 0.16866968390842374, 0.15521966944610244, 0.1050603046932228, 0.16750994235662564, 0.8301194917821172, 0.19359790302667412, 0.20541408507986803, 0.1828618480262616, 0.2147502480355553, 0.22612882847610083, 0.21115730752580986, 0.19981973822326748, 0.2168632705337129, 0.21118635083666837, 0.11197120297328023, 0.10713089067001458, 0.09632377131591785, 0.09663159245068198, 0.0932014556206584, 0.09202853398997957, 0.07720826498898636, 0.0996155979047102, 0.10561207933836725]}, "mutation_prompt": null}
{"id": "bf7bc2d7-41d6-4efb-89f1-08a9502a25a7", "solution": "import numpy as np\n\nclass DynamicAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7  # Increased for exploration\n        self.cognitive_weight = 1.5  # Adjusted for balanced learning\n        self.social_weight = 1.5  # Adjusted for balanced cooperation\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: 0.9 - iter * 0.5 / (self.budget/self.swarm_size)\n\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            velocities = np.clip(velocities, -1, 1)  # Control velocity\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 2 <= self.budget:\n                elite_idxs = np.argsort(personal_best_scores)[:3]\n                for i in elite_idxs:\n                    mutant = 0.5 * (positions[i] + global_best_position)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "DynamicAdaptivePSO", "description": "Dynamic Adaptive PSO with velocity control and elitist learning for enhanced convergence.", "configspace": "", "generation": 62, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a5d7036d-9a2d-4b13-9fbb-00412e65f461", "metadata": {"aucs": [0.8032135972550823, 0.7949118659281794, 0.8482728446676409, 0.7993670345346594, 0.7737528802393012, 0.8464902526554178, 0.8046519253932358, 0.805590481213056, 0.8461412014093087, 0.005783314147535412, 0.08588937958091614, 0.07784687388371492, 0.016921844029064936, 0.0421895187336917, 0.15930331104042017, 0.04351665314983588, 9.999999999998899e-05, 0.09932457982432175, 0.10887936612205595, 0.14106487423359249, 0.10120120324682214, 0.13712488658640198, 0.1131927136557066, 0.11801005973914358, 0.06999116975530628, 0.08998994870091392, 0.153945641686013, 0.08902008972685305, 0.08609414085503653, 0.07747571058178349, 0.0991600265351037, 0.09621864220040444, 0.08885327355791683, 0.08154460108384465, 0.1206487651268191, 0.12317125854406696, 0.9500949981300757, 0.9610162495112076, 0.9608173185629282, 0.9569062299208816, 0.9579478633221649, 0.9533167253824387, 0.9589146234755783, 0.9456046762511077, 0.9615824603584858, 0.4997793869222614, 0.4305469045242265, 0.058042371818485705, 0.46568283067902316, 0.5187228327236573, 0.6723002426355029, 0.4294246886935441, 0.5551157071569044, 0.641129866546762, 0.2292504105416071, 0.2218058456312637, 0.22230656550713235, 0.33686295881202966, 0.27848606767370654, 0.21454053637429038, 0.20372963880149297, 0.15128821080273958, 0.39794626784261933, 0.22356068920084582, 0.14967899882762736, 0.3460745606001445, 0.13462870221790602, 0.13066161760638317, 0.1324333383194748, 0.26398070659869854, 0.5457827007374707, 0.6120169801637243, 0.13625233789797386, 0.24549133917399624, 0.13080430473110705, 0.13304666547801958, 0.13049659211334108, 0.13322173749730915, 0.21974090720652262, 0.1329639560906808, 0.1496385188927687, 0.004779048812517228, 0.17108797815354215, 0.25301519995891086, 0.05261252643587688, 0.12892384650099942, 0.0551684261914539, 0.006967628751370136, 0.11560747877196131, 0.12697739756745263, 0.15582431031483435, 0.09271555454571134, 0.15588800980252215, 0.10144902398426314, 0.06251420999704094, 0.07262084805527613, 0.08868747636358199, 0.11478102569127746, 0.09063059883759139, 0.12629005560510398, 0.09117513492272067, 0.17992686308692896, 0.10157509588947888, 0.11298179534745356, 0.15921708450034489, 0.08881133929437979, 0.13247967106154301, 0.20445416066555633, 0.1399055081927416, 0.10754854008343029, 0.26729325538556115, 0.0596286347337982, 0.2448441980950371, 0.07214332914793808, 0.22059840068686798, 0.07908865836731516, 0.09107640683861773, 0.5499288843441377, 0.6016802621354878, 0.5231668860289979, 0.5644406241666733, 0.5566533566676373, 0.5288568064385815, 0.5475886810377337, 0.5761841935507019, 0.6504214794789962, 0.08579403613110825, 0.09511929359087767, 0.14358011889337485, 0.09139821050759911, 0.11572463611429029, 0.10133279161032172, 0.11044625751079806, 0.10866352333885332, 0.11943270448993082, 0.2573311502062082, 0.22937414607557227, 0.19562154618877514, 0.3202692776393762, 0.20794559527720802, 0.20597359180019348, 0.26406130645571035, 0.2074774402405345, 0.40768283736460964, 0.18968002504602866, 0.32157365857738074, 0.3186151167879774, 0.33270363046002127, 0.2627444216739391, 0.2956015666241564, 0.21223646936301965, 0.3446130627616192, 0.22516985515672672, 0.22839949534625337, 0.25188988208791263, 0.25708494613176014, 0.29383914690161095, 0.17597975328975912, 0.25694322558054883, 0.18494244727765208, 0.2339092527794896, 0.22570769178373118, 0.23044350852583495, 0.2027194210053198, 0.211207360384028, 0.2385316905634688, 0.22879519414509175, 0.2526855623887996, 0.2889346062899941, 0.2307853887943655, 0.24870378186150188, 0.18483349298354435, 0.17058772111900034, 0.17391439201665038, 0.2270224744771232, 0.19906074777213134, 0.2014155098146012, 0.18572017396038665, 0.1875717454911342, 0.1765831943232613, 0.12658049617049671, 0.18757007971982376, 0.18694638686780962, 0.8592490352296711, 0.20049573519452968, 0.905463766379589, 0.14279112348068845, 0.8799172487320415, 0.9193381292571849, 0.8451848882252659, 0.2127446801105125, 0.862780704699071, 0.20899976331010583, 0.16866968390842374, 0.15521966944610244, 0.1050603046932228, 0.16750994235662564, 0.8301194917821172, 0.19359790302667412, 0.20541408507986803, 0.1828618480262616, 0.2147502480355553, 0.22612882847610083, 0.21115730752580986, 0.19981973822326748, 0.2168632705337129, 0.21118635083666837, 0.11197120297328023, 0.10713089067001458, 0.09632377131591785, 0.09663159245068198, 0.0932014556206584, 0.09202853398997957, 0.07720826498898636, 0.0996155979047102, 0.10561207933836725]}, "mutation_prompt": null}
{"id": "293f1c0f-29d8-4d5c-9b2a-e758d3cb22b7", "solution": "import numpy as np\n\nclass DynamicAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7  # Increased for exploration\n        self.cognitive_weight = 1.5  # Adjusted for balanced learning\n        self.social_weight = 1.5  # Adjusted for balanced cooperation\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: 0.9 - iter * 0.5 / (self.budget/self.swarm_size)\n\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            velocities = np.clip(velocities, -1, 1)  # Control velocity\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 2 <= self.budget:\n                elite_idxs = np.argsort(personal_best_scores)[:3]\n                for i in elite_idxs:\n                    mutant = 0.5 * (positions[i] + global_best_position)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "DynamicAdaptivePSO", "description": "Dynamic Adaptive PSO with velocity control and elitist learning for enhanced convergence.", "configspace": "", "generation": 62, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a5d7036d-9a2d-4b13-9fbb-00412e65f461", "metadata": {"aucs": [0.8032135972550823, 0.7949118659281794, 0.8482728446676409, 0.7993670345346594, 0.7737528802393012, 0.8464902526554178, 0.8046519253932358, 0.805590481213056, 0.8461412014093087, 0.005783314147535412, 0.08588937958091614, 0.07784687388371492, 0.016921844029064936, 0.0421895187336917, 0.15930331104042017, 0.04351665314983588, 9.999999999998899e-05, 0.09932457982432175, 0.10887936612205595, 0.14106487423359249, 0.10120120324682214, 0.13712488658640198, 0.1131927136557066, 0.11801005973914358, 0.06999116975530628, 0.08998994870091392, 0.153945641686013, 0.08902008972685305, 0.08609414085503653, 0.07747571058178349, 0.0991600265351037, 0.09621864220040444, 0.08885327355791683, 0.08154460108384465, 0.1206487651268191, 0.12317125854406696, 0.9500949981300757, 0.9610162495112076, 0.9608173185629282, 0.9569062299208816, 0.9579478633221649, 0.9533167253824387, 0.9589146234755783, 0.9456046762511077, 0.9615824603584858, 0.4997793869222614, 0.4305469045242265, 0.058042371818485705, 0.46568283067902316, 0.5187228327236573, 0.6723002426355029, 0.4294246886935441, 0.5551157071569044, 0.641129866546762, 0.2292504105416071, 0.2218058456312637, 0.22230656550713235, 0.33686295881202966, 0.27848606767370654, 0.21454053637429038, 0.20372963880149297, 0.15128821080273958, 0.39794626784261933, 0.22356068920084582, 0.14967899882762736, 0.3460745606001445, 0.13462870221790602, 0.13066161760638317, 0.1324333383194748, 0.26398070659869854, 0.5457827007374707, 0.6120169801637243, 0.13625233789797386, 0.24549133917399624, 0.13080430473110705, 0.13304666547801958, 0.13049659211334108, 0.13322173749730915, 0.21974090720652262, 0.1329639560906808, 0.1496385188927687, 0.004779048812517228, 0.17108797815354215, 0.25301519995891086, 0.05261252643587688, 0.12892384650099942, 0.0551684261914539, 0.006967628751370136, 0.11560747877196131, 0.12697739756745263, 0.15582431031483435, 0.09271555454571134, 0.15588800980252215, 0.10144902398426314, 0.06251420999704094, 0.07262084805527613, 0.08868747636358199, 0.11478102569127746, 0.09063059883759139, 0.12629005560510398, 0.09117513492272067, 0.17992686308692896, 0.10157509588947888, 0.11298179534745356, 0.15921708450034489, 0.08881133929437979, 0.13247967106154301, 0.20445416066555633, 0.1399055081927416, 0.10754854008343029, 0.26729325538556115, 0.0596286347337982, 0.2448441980950371, 0.07214332914793808, 0.22059840068686798, 0.07908865836731516, 0.09107640683861773, 0.5499288843441377, 0.6016802621354878, 0.5231668860289979, 0.5644406241666733, 0.5566533566676373, 0.5288568064385815, 0.5475886810377337, 0.5761841935507019, 0.6504214794789962, 0.08579403613110825, 0.09511929359087767, 0.14358011889337485, 0.09139821050759911, 0.11572463611429029, 0.10133279161032172, 0.11044625751079806, 0.10866352333885332, 0.11943270448993082, 0.2573311502062082, 0.22937414607557227, 0.19562154618877514, 0.3202692776393762, 0.20794559527720802, 0.20597359180019348, 0.26406130645571035, 0.2074774402405345, 0.40768283736460964, 0.18968002504602866, 0.32157365857738074, 0.3186151167879774, 0.33270363046002127, 0.2627444216739391, 0.2956015666241564, 0.21223646936301965, 0.3446130627616192, 0.22516985515672672, 0.22839949534625337, 0.25188988208791263, 0.25708494613176014, 0.29383914690161095, 0.17597975328975912, 0.25694322558054883, 0.18494244727765208, 0.2339092527794896, 0.22570769178373118, 0.23044350852583495, 0.2027194210053198, 0.211207360384028, 0.2385316905634688, 0.22879519414509175, 0.2526855623887996, 0.2889346062899941, 0.2307853887943655, 0.24870378186150188, 0.18483349298354435, 0.17058772111900034, 0.17391439201665038, 0.2270224744771232, 0.19906074777213134, 0.2014155098146012, 0.18572017396038665, 0.1875717454911342, 0.1765831943232613, 0.12658049617049671, 0.18757007971982376, 0.18694638686780962, 0.8592490352296711, 0.20049573519452968, 0.905463766379589, 0.14279112348068845, 0.8799172487320415, 0.9193381292571849, 0.8451848882252659, 0.2127446801105125, 0.862780704699071, 0.20899976331010583, 0.16866968390842374, 0.15521966944610244, 0.1050603046932228, 0.16750994235662564, 0.8301194917821172, 0.19359790302667412, 0.20541408507986803, 0.1828618480262616, 0.2147502480355553, 0.22612882847610083, 0.21115730752580986, 0.19981973822326748, 0.2168632705337129, 0.21118635083666837, 0.11197120297328023, 0.10713089067001458, 0.09632377131591785, 0.09663159245068198, 0.0932014556206584, 0.09202853398997957, 0.07720826498898636, 0.0996155979047102, 0.10561207933836725]}, "mutation_prompt": null}
{"id": "a0fcb38e-d6c9-47a9-b896-765ce8f38ca2", "solution": "import numpy as np\n\nclass DynamicAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7  # Increased for exploration\n        self.cognitive_weight = 1.5  # Adjusted for balanced learning\n        self.social_weight = 1.5  # Adjusted for balanced cooperation\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: 0.9 - iter * 0.5 / (self.budget/self.swarm_size)\n\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            velocities = np.clip(velocities, -1, 1)  # Control velocity\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 2 <= self.budget:\n                elite_idxs = np.argsort(personal_best_scores)[:3]\n                for i in elite_idxs:\n                    mutant = 0.5 * (positions[i] + global_best_position)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "DynamicAdaptivePSO", "description": "Dynamic Adaptive PSO with velocity control and elitist learning for enhanced convergence.", "configspace": "", "generation": 62, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a5d7036d-9a2d-4b13-9fbb-00412e65f461", "metadata": {"aucs": [0.8032135972550823, 0.7949118659281794, 0.8482728446676409, 0.7993670345346594, 0.7737528802393012, 0.8464902526554178, 0.8046519253932358, 0.805590481213056, 0.8461412014093087, 0.005783314147535412, 0.08588937958091614, 0.07784687388371492, 0.016921844029064936, 0.0421895187336917, 0.15930331104042017, 0.04351665314983588, 9.999999999998899e-05, 0.09932457982432175, 0.10887936612205595, 0.14106487423359249, 0.10120120324682214, 0.13712488658640198, 0.1131927136557066, 0.11801005973914358, 0.06999116975530628, 0.08998994870091392, 0.153945641686013, 0.08902008972685305, 0.08609414085503653, 0.07747571058178349, 0.0991600265351037, 0.09621864220040444, 0.08885327355791683, 0.08154460108384465, 0.1206487651268191, 0.12317125854406696, 0.9500949981300757, 0.9610162495112076, 0.9608173185629282, 0.9569062299208816, 0.9579478633221649, 0.9533167253824387, 0.9589146234755783, 0.9456046762511077, 0.9615824603584858, 0.4997793869222614, 0.4305469045242265, 0.058042371818485705, 0.46568283067902316, 0.5187228327236573, 0.6723002426355029, 0.4294246886935441, 0.5551157071569044, 0.641129866546762, 0.2292504105416071, 0.2218058456312637, 0.22230656550713235, 0.33686295881202966, 0.27848606767370654, 0.21454053637429038, 0.20372963880149297, 0.15128821080273958, 0.39794626784261933, 0.22356068920084582, 0.14967899882762736, 0.3460745606001445, 0.13462870221790602, 0.13066161760638317, 0.1324333383194748, 0.26398070659869854, 0.5457827007374707, 0.6120169801637243, 0.13625233789797386, 0.24549133917399624, 0.13080430473110705, 0.13304666547801958, 0.13049659211334108, 0.13322173749730915, 0.21974090720652262, 0.1329639560906808, 0.1496385188927687, 0.004779048812517228, 0.17108797815354215, 0.25301519995891086, 0.05261252643587688, 0.12892384650099942, 0.0551684261914539, 0.006967628751370136, 0.11560747877196131, 0.12697739756745263, 0.15582431031483435, 0.09271555454571134, 0.15588800980252215, 0.10144902398426314, 0.06251420999704094, 0.07262084805527613, 0.08868747636358199, 0.11478102569127746, 0.09063059883759139, 0.12629005560510398, 0.09117513492272067, 0.17992686308692896, 0.10157509588947888, 0.11298179534745356, 0.15921708450034489, 0.08881133929437979, 0.13247967106154301, 0.20445416066555633, 0.1399055081927416, 0.10754854008343029, 0.26729325538556115, 0.0596286347337982, 0.2448441980950371, 0.07214332914793808, 0.22059840068686798, 0.07908865836731516, 0.09107640683861773, 0.5499288843441377, 0.6016802621354878, 0.5231668860289979, 0.5644406241666733, 0.5566533566676373, 0.5288568064385815, 0.5475886810377337, 0.5761841935507019, 0.6504214794789962, 0.08579403613110825, 0.09511929359087767, 0.14358011889337485, 0.09139821050759911, 0.11572463611429029, 0.10133279161032172, 0.11044625751079806, 0.10866352333885332, 0.11943270448993082, 0.2573311502062082, 0.22937414607557227, 0.19562154618877514, 0.3202692776393762, 0.20794559527720802, 0.20597359180019348, 0.26406130645571035, 0.2074774402405345, 0.40768283736460964, 0.18968002504602866, 0.32157365857738074, 0.3186151167879774, 0.33270363046002127, 0.2627444216739391, 0.2956015666241564, 0.21223646936301965, 0.3446130627616192, 0.22516985515672672, 0.22839949534625337, 0.25188988208791263, 0.25708494613176014, 0.29383914690161095, 0.17597975328975912, 0.25694322558054883, 0.18494244727765208, 0.2339092527794896, 0.22570769178373118, 0.23044350852583495, 0.2027194210053198, 0.211207360384028, 0.2385316905634688, 0.22879519414509175, 0.2526855623887996, 0.2889346062899941, 0.2307853887943655, 0.24870378186150188, 0.18483349298354435, 0.17058772111900034, 0.17391439201665038, 0.2270224744771232, 0.19906074777213134, 0.2014155098146012, 0.18572017396038665, 0.1875717454911342, 0.1765831943232613, 0.12658049617049671, 0.18757007971982376, 0.18694638686780962, 0.8592490352296711, 0.20049573519452968, 0.905463766379589, 0.14279112348068845, 0.8799172487320415, 0.9193381292571849, 0.8451848882252659, 0.2127446801105125, 0.862780704699071, 0.20899976331010583, 0.16866968390842374, 0.15521966944610244, 0.1050603046932228, 0.16750994235662564, 0.8301194917821172, 0.19359790302667412, 0.20541408507986803, 0.1828618480262616, 0.2147502480355553, 0.22612882847610083, 0.21115730752580986, 0.19981973822326748, 0.2168632705337129, 0.21118635083666837, 0.11197120297328023, 0.10713089067001458, 0.09632377131591785, 0.09663159245068198, 0.0932014556206584, 0.09202853398997957, 0.07720826498898636, 0.0996155979047102, 0.10561207933836725]}, "mutation_prompt": null}
{"id": "8e125215-9eb1-496f-b352-0ef24163da38", "solution": "import numpy as np\n\nclass DynamicAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7  # Increased for exploration\n        self.cognitive_weight = 1.5  # Adjusted for balanced learning\n        self.social_weight = 1.5  # Adjusted for balanced cooperation\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: 0.9 - iter * 0.5 / (self.budget/self.swarm_size)\n\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            velocities = np.clip(velocities, -1, 1)  # Control velocity\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 2 <= self.budget:\n                elite_idxs = np.argsort(personal_best_scores)[:3]\n                for i in elite_idxs:\n                    mutant = 0.5 * (positions[i] + global_best_position)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "DynamicAdaptivePSO", "description": "Dynamic Adaptive PSO with velocity control and elitist learning for enhanced convergence.", "configspace": "", "generation": 62, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a5d7036d-9a2d-4b13-9fbb-00412e65f461", "metadata": {"aucs": [0.8032135972550823, 0.7949118659281794, 0.8482728446676409, 0.7993670345346594, 0.7737528802393012, 0.8464902526554178, 0.8046519253932358, 0.805590481213056, 0.8461412014093087, 0.005783314147535412, 0.08588937958091614, 0.07784687388371492, 0.016921844029064936, 0.0421895187336917, 0.15930331104042017, 0.04351665314983588, 9.999999999998899e-05, 0.09932457982432175, 0.10887936612205595, 0.14106487423359249, 0.10120120324682214, 0.13712488658640198, 0.1131927136557066, 0.11801005973914358, 0.06999116975530628, 0.08998994870091392, 0.153945641686013, 0.08902008972685305, 0.08609414085503653, 0.07747571058178349, 0.0991600265351037, 0.09621864220040444, 0.08885327355791683, 0.08154460108384465, 0.1206487651268191, 0.12317125854406696, 0.9500949981300757, 0.9610162495112076, 0.9608173185629282, 0.9569062299208816, 0.9579478633221649, 0.9533167253824387, 0.9589146234755783, 0.9456046762511077, 0.9615824603584858, 0.4997793869222614, 0.4305469045242265, 0.058042371818485705, 0.46568283067902316, 0.5187228327236573, 0.6723002426355029, 0.4294246886935441, 0.5551157071569044, 0.641129866546762, 0.2292504105416071, 0.2218058456312637, 0.22230656550713235, 0.33686295881202966, 0.27848606767370654, 0.21454053637429038, 0.20372963880149297, 0.15128821080273958, 0.39794626784261933, 0.22356068920084582, 0.14967899882762736, 0.3460745606001445, 0.13462870221790602, 0.13066161760638317, 0.1324333383194748, 0.26398070659869854, 0.5457827007374707, 0.6120169801637243, 0.13625233789797386, 0.24549133917399624, 0.13080430473110705, 0.13304666547801958, 0.13049659211334108, 0.13322173749730915, 0.21974090720652262, 0.1329639560906808, 0.1496385188927687, 0.004779048812517228, 0.17108797815354215, 0.25301519995891086, 0.05261252643587688, 0.12892384650099942, 0.0551684261914539, 0.006967628751370136, 0.11560747877196131, 0.12697739756745263, 0.15582431031483435, 0.09271555454571134, 0.15588800980252215, 0.10144902398426314, 0.06251420999704094, 0.07262084805527613, 0.08868747636358199, 0.11478102569127746, 0.09063059883759139, 0.12629005560510398, 0.09117513492272067, 0.17992686308692896, 0.10157509588947888, 0.11298179534745356, 0.15921708450034489, 0.08881133929437979, 0.13247967106154301, 0.20445416066555633, 0.1399055081927416, 0.10754854008343029, 0.26729325538556115, 0.0596286347337982, 0.2448441980950371, 0.07214332914793808, 0.22059840068686798, 0.07908865836731516, 0.09107640683861773, 0.5499288843441377, 0.6016802621354878, 0.5231668860289979, 0.5644406241666733, 0.5566533566676373, 0.5288568064385815, 0.5475886810377337, 0.5761841935507019, 0.6504214794789962, 0.08579403613110825, 0.09511929359087767, 0.14358011889337485, 0.09139821050759911, 0.11572463611429029, 0.10133279161032172, 0.11044625751079806, 0.10866352333885332, 0.11943270448993082, 0.2573311502062082, 0.22937414607557227, 0.19562154618877514, 0.3202692776393762, 0.20794559527720802, 0.20597359180019348, 0.26406130645571035, 0.2074774402405345, 0.40768283736460964, 0.18968002504602866, 0.32157365857738074, 0.3186151167879774, 0.33270363046002127, 0.2627444216739391, 0.2956015666241564, 0.21223646936301965, 0.3446130627616192, 0.22516985515672672, 0.22839949534625337, 0.25188988208791263, 0.25708494613176014, 0.29383914690161095, 0.17597975328975912, 0.25694322558054883, 0.18494244727765208, 0.2339092527794896, 0.22570769178373118, 0.23044350852583495, 0.2027194210053198, 0.211207360384028, 0.2385316905634688, 0.22879519414509175, 0.2526855623887996, 0.2889346062899941, 0.2307853887943655, 0.24870378186150188, 0.18483349298354435, 0.17058772111900034, 0.17391439201665038, 0.2270224744771232, 0.19906074777213134, 0.2014155098146012, 0.18572017396038665, 0.1875717454911342, 0.1765831943232613, 0.12658049617049671, 0.18757007971982376, 0.18694638686780962, 0.8592490352296711, 0.20049573519452968, 0.905463766379589, 0.14279112348068845, 0.8799172487320415, 0.9193381292571849, 0.8451848882252659, 0.2127446801105125, 0.862780704699071, 0.20899976331010583, 0.16866968390842374, 0.15521966944610244, 0.1050603046932228, 0.16750994235662564, 0.8301194917821172, 0.19359790302667412, 0.20541408507986803, 0.1828618480262616, 0.2147502480355553, 0.22612882847610083, 0.21115730752580986, 0.19981973822326748, 0.2168632705337129, 0.21118635083666837, 0.11197120297328023, 0.10713089067001458, 0.09632377131591785, 0.09663159245068198, 0.0932014556206584, 0.09202853398997957, 0.07720826498898636, 0.0996155979047102, 0.10561207933836725]}, "mutation_prompt": null}
{"id": "bc7eeb9b-2573-43e2-aaa8-6e8ca8cdaa12", "solution": "import numpy as np\n\nclass DynamicAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7  # Increased for exploration\n        self.cognitive_weight = 1.5  # Adjusted for balanced learning\n        self.social_weight = 1.5  # Adjusted for balanced cooperation\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: 0.9 - iter * 0.5 / (self.budget/self.swarm_size)\n\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            velocities = np.clip(velocities, -1, 1)  # Control velocity\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 2 <= self.budget:\n                elite_idxs = np.argsort(personal_best_scores)[:3]\n                for i in elite_idxs:\n                    mutant = 0.5 * (positions[i] + global_best_position)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "DynamicAdaptivePSO", "description": "Dynamic Adaptive PSO with velocity control and elitist learning for enhanced convergence.", "configspace": "", "generation": 62, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a5d7036d-9a2d-4b13-9fbb-00412e65f461", "metadata": {"aucs": [0.8032135972550823, 0.7949118659281794, 0.8482728446676409, 0.7993670345346594, 0.7737528802393012, 0.8464902526554178, 0.8046519253932358, 0.805590481213056, 0.8461412014093087, 0.005783314147535412, 0.08588937958091614, 0.07784687388371492, 0.016921844029064936, 0.0421895187336917, 0.15930331104042017, 0.04351665314983588, 9.999999999998899e-05, 0.09932457982432175, 0.10887936612205595, 0.14106487423359249, 0.10120120324682214, 0.13712488658640198, 0.1131927136557066, 0.11801005973914358, 0.06999116975530628, 0.08998994870091392, 0.153945641686013, 0.08902008972685305, 0.08609414085503653, 0.07747571058178349, 0.0991600265351037, 0.09621864220040444, 0.08885327355791683, 0.08154460108384465, 0.1206487651268191, 0.12317125854406696, 0.9500949981300757, 0.9610162495112076, 0.9608173185629282, 0.9569062299208816, 0.9579478633221649, 0.9533167253824387, 0.9589146234755783, 0.9456046762511077, 0.9615824603584858, 0.4997793869222614, 0.4305469045242265, 0.058042371818485705, 0.46568283067902316, 0.5187228327236573, 0.6723002426355029, 0.4294246886935441, 0.5551157071569044, 0.641129866546762, 0.2292504105416071, 0.2218058456312637, 0.22230656550713235, 0.33686295881202966, 0.27848606767370654, 0.21454053637429038, 0.20372963880149297, 0.15128821080273958, 0.39794626784261933, 0.22356068920084582, 0.14967899882762736, 0.3460745606001445, 0.13462870221790602, 0.13066161760638317, 0.1324333383194748, 0.26398070659869854, 0.5457827007374707, 0.6120169801637243, 0.13625233789797386, 0.24549133917399624, 0.13080430473110705, 0.13304666547801958, 0.13049659211334108, 0.13322173749730915, 0.21974090720652262, 0.1329639560906808, 0.1496385188927687, 0.004779048812517228, 0.17108797815354215, 0.25301519995891086, 0.05261252643587688, 0.12892384650099942, 0.0551684261914539, 0.006967628751370136, 0.11560747877196131, 0.12697739756745263, 0.15582431031483435, 0.09271555454571134, 0.15588800980252215, 0.10144902398426314, 0.06251420999704094, 0.07262084805527613, 0.08868747636358199, 0.11478102569127746, 0.09063059883759139, 0.12629005560510398, 0.09117513492272067, 0.17992686308692896, 0.10157509588947888, 0.11298179534745356, 0.15921708450034489, 0.08881133929437979, 0.13247967106154301, 0.20445416066555633, 0.1399055081927416, 0.10754854008343029, 0.26729325538556115, 0.0596286347337982, 0.2448441980950371, 0.07214332914793808, 0.22059840068686798, 0.07908865836731516, 0.09107640683861773, 0.5499288843441377, 0.6016802621354878, 0.5231668860289979, 0.5644406241666733, 0.5566533566676373, 0.5288568064385815, 0.5475886810377337, 0.5761841935507019, 0.6504214794789962, 0.08579403613110825, 0.09511929359087767, 0.14358011889337485, 0.09139821050759911, 0.11572463611429029, 0.10133279161032172, 0.11044625751079806, 0.10866352333885332, 0.11943270448993082, 0.2573311502062082, 0.22937414607557227, 0.19562154618877514, 0.3202692776393762, 0.20794559527720802, 0.20597359180019348, 0.26406130645571035, 0.2074774402405345, 0.40768283736460964, 0.18968002504602866, 0.32157365857738074, 0.3186151167879774, 0.33270363046002127, 0.2627444216739391, 0.2956015666241564, 0.21223646936301965, 0.3446130627616192, 0.22516985515672672, 0.22839949534625337, 0.25188988208791263, 0.25708494613176014, 0.29383914690161095, 0.17597975328975912, 0.25694322558054883, 0.18494244727765208, 0.2339092527794896, 0.22570769178373118, 0.23044350852583495, 0.2027194210053198, 0.211207360384028, 0.2385316905634688, 0.22879519414509175, 0.2526855623887996, 0.2889346062899941, 0.2307853887943655, 0.24870378186150188, 0.18483349298354435, 0.17058772111900034, 0.17391439201665038, 0.2270224744771232, 0.19906074777213134, 0.2014155098146012, 0.18572017396038665, 0.1875717454911342, 0.1765831943232613, 0.12658049617049671, 0.18757007971982376, 0.18694638686780962, 0.8592490352296711, 0.20049573519452968, 0.905463766379589, 0.14279112348068845, 0.8799172487320415, 0.9193381292571849, 0.8451848882252659, 0.2127446801105125, 0.862780704699071, 0.20899976331010583, 0.16866968390842374, 0.15521966944610244, 0.1050603046932228, 0.16750994235662564, 0.8301194917821172, 0.19359790302667412, 0.20541408507986803, 0.1828618480262616, 0.2147502480355553, 0.22612882847610083, 0.21115730752580986, 0.19981973822326748, 0.2168632705337129, 0.21118635083666837, 0.11197120297328023, 0.10713089067001458, 0.09632377131591785, 0.09663159245068198, 0.0932014556206584, 0.09202853398997957, 0.07720826498898636, 0.0996155979047102, 0.10561207933836725]}, "mutation_prompt": null}
{"id": "1856956b-50a0-4164-b6ca-70f516487c12", "solution": "import numpy as np\n\nclass DynamicAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7  # Increased for exploration\n        self.cognitive_weight = 1.5  # Adjusted for balanced learning\n        self.social_weight = 1.5  # Adjusted for balanced cooperation\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: 0.9 - iter * 0.5 / (self.budget/self.swarm_size)\n\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            velocities = np.clip(velocities, -1, 1)  # Control velocity\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 2 <= self.budget:\n                elite_idxs = np.argsort(personal_best_scores)[:3]\n                for i in elite_idxs:\n                    mutant = 0.5 * (positions[i] + global_best_position)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "DynamicAdaptivePSO", "description": "Dynamic Adaptive PSO with velocity control and elitist learning for enhanced convergence.", "configspace": "", "generation": 62, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a5d7036d-9a2d-4b13-9fbb-00412e65f461", "metadata": {"aucs": [0.8032135972550823, 0.7949118659281794, 0.8482728446676409, 0.7993670345346594, 0.7737528802393012, 0.8464902526554178, 0.8046519253932358, 0.805590481213056, 0.8461412014093087, 0.005783314147535412, 0.08588937958091614, 0.07784687388371492, 0.016921844029064936, 0.0421895187336917, 0.15930331104042017, 0.04351665314983588, 9.999999999998899e-05, 0.09932457982432175, 0.10887936612205595, 0.14106487423359249, 0.10120120324682214, 0.13712488658640198, 0.1131927136557066, 0.11801005973914358, 0.06999116975530628, 0.08998994870091392, 0.153945641686013, 0.08902008972685305, 0.08609414085503653, 0.07747571058178349, 0.0991600265351037, 0.09621864220040444, 0.08885327355791683, 0.08154460108384465, 0.1206487651268191, 0.12317125854406696, 0.9500949981300757, 0.9610162495112076, 0.9608173185629282, 0.9569062299208816, 0.9579478633221649, 0.9533167253824387, 0.9589146234755783, 0.9456046762511077, 0.9615824603584858, 0.4997793869222614, 0.4305469045242265, 0.058042371818485705, 0.46568283067902316, 0.5187228327236573, 0.6723002426355029, 0.4294246886935441, 0.5551157071569044, 0.641129866546762, 0.2292504105416071, 0.2218058456312637, 0.22230656550713235, 0.33686295881202966, 0.27848606767370654, 0.21454053637429038, 0.20372963880149297, 0.15128821080273958, 0.39794626784261933, 0.22356068920084582, 0.14967899882762736, 0.3460745606001445, 0.13462870221790602, 0.13066161760638317, 0.1324333383194748, 0.26398070659869854, 0.5457827007374707, 0.6120169801637243, 0.13625233789797386, 0.24549133917399624, 0.13080430473110705, 0.13304666547801958, 0.13049659211334108, 0.13322173749730915, 0.21974090720652262, 0.1329639560906808, 0.1496385188927687, 0.004779048812517228, 0.17108797815354215, 0.25301519995891086, 0.05261252643587688, 0.12892384650099942, 0.0551684261914539, 0.006967628751370136, 0.11560747877196131, 0.12697739756745263, 0.15582431031483435, 0.09271555454571134, 0.15588800980252215, 0.10144902398426314, 0.06251420999704094, 0.07262084805527613, 0.08868747636358199, 0.11478102569127746, 0.09063059883759139, 0.12629005560510398, 0.09117513492272067, 0.17992686308692896, 0.10157509588947888, 0.11298179534745356, 0.15921708450034489, 0.08881133929437979, 0.13247967106154301, 0.20445416066555633, 0.1399055081927416, 0.10754854008343029, 0.26729325538556115, 0.0596286347337982, 0.2448441980950371, 0.07214332914793808, 0.22059840068686798, 0.07908865836731516, 0.09107640683861773, 0.5499288843441377, 0.6016802621354878, 0.5231668860289979, 0.5644406241666733, 0.5566533566676373, 0.5288568064385815, 0.5475886810377337, 0.5761841935507019, 0.6504214794789962, 0.08579403613110825, 0.09511929359087767, 0.14358011889337485, 0.09139821050759911, 0.11572463611429029, 0.10133279161032172, 0.11044625751079806, 0.10866352333885332, 0.11943270448993082, 0.2573311502062082, 0.22937414607557227, 0.19562154618877514, 0.3202692776393762, 0.20794559527720802, 0.20597359180019348, 0.26406130645571035, 0.2074774402405345, 0.40768283736460964, 0.18968002504602866, 0.32157365857738074, 0.3186151167879774, 0.33270363046002127, 0.2627444216739391, 0.2956015666241564, 0.21223646936301965, 0.3446130627616192, 0.22516985515672672, 0.22839949534625337, 0.25188988208791263, 0.25708494613176014, 0.29383914690161095, 0.17597975328975912, 0.25694322558054883, 0.18494244727765208, 0.2339092527794896, 0.22570769178373118, 0.23044350852583495, 0.2027194210053198, 0.211207360384028, 0.2385316905634688, 0.22879519414509175, 0.2526855623887996, 0.2889346062899941, 0.2307853887943655, 0.24870378186150188, 0.18483349298354435, 0.17058772111900034, 0.17391439201665038, 0.2270224744771232, 0.19906074777213134, 0.2014155098146012, 0.18572017396038665, 0.1875717454911342, 0.1765831943232613, 0.12658049617049671, 0.18757007971982376, 0.18694638686780962, 0.8592490352296711, 0.20049573519452968, 0.905463766379589, 0.14279112348068845, 0.8799172487320415, 0.9193381292571849, 0.8451848882252659, 0.2127446801105125, 0.862780704699071, 0.20899976331010583, 0.16866968390842374, 0.15521966944610244, 0.1050603046932228, 0.16750994235662564, 0.8301194917821172, 0.19359790302667412, 0.20541408507986803, 0.1828618480262616, 0.2147502480355553, 0.22612882847610083, 0.21115730752580986, 0.19981973822326748, 0.2168632705337129, 0.21118635083666837, 0.11197120297328023, 0.10713089067001458, 0.09632377131591785, 0.09663159245068198, 0.0932014556206584, 0.09202853398997957, 0.07720826498898636, 0.0996155979047102, 0.10561207933836725]}, "mutation_prompt": null}
{"id": "e1f25e58-d330-4ac4-a00d-9b4662618d0e", "solution": "import numpy as np\n\nclass DynamicAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7  # Increased for exploration\n        self.cognitive_weight = 1.5  # Adjusted for balanced learning\n        self.social_weight = 1.5  # Adjusted for balanced cooperation\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: 0.9 - iter * 0.5 / (self.budget/self.swarm_size)\n\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            velocities = np.clip(velocities, -1, 1)  # Control velocity\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 2 <= self.budget:\n                elite_idxs = np.argsort(personal_best_scores)[:3]\n                for i in elite_idxs:\n                    mutant = 0.5 * (positions[i] + global_best_position)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "DynamicAdaptivePSO", "description": "Dynamic Adaptive PSO with velocity control and elitist learning for enhanced convergence.", "configspace": "", "generation": 62, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a5d7036d-9a2d-4b13-9fbb-00412e65f461", "metadata": {"aucs": [0.8032135972550823, 0.7949118659281794, 0.8482728446676409, 0.7993670345346594, 0.7737528802393012, 0.8464902526554178, 0.8046519253932358, 0.805590481213056, 0.8461412014093087, 0.005783314147535412, 0.08588937958091614, 0.07784687388371492, 0.016921844029064936, 0.0421895187336917, 0.15930331104042017, 0.04351665314983588, 9.999999999998899e-05, 0.09932457982432175, 0.10887936612205595, 0.14106487423359249, 0.10120120324682214, 0.13712488658640198, 0.1131927136557066, 0.11801005973914358, 0.06999116975530628, 0.08998994870091392, 0.153945641686013, 0.08902008972685305, 0.08609414085503653, 0.07747571058178349, 0.0991600265351037, 0.09621864220040444, 0.08885327355791683, 0.08154460108384465, 0.1206487651268191, 0.12317125854406696, 0.9500949981300757, 0.9610162495112076, 0.9608173185629282, 0.9569062299208816, 0.9579478633221649, 0.9533167253824387, 0.9589146234755783, 0.9456046762511077, 0.9615824603584858, 0.4997793869222614, 0.4305469045242265, 0.058042371818485705, 0.46568283067902316, 0.5187228327236573, 0.6723002426355029, 0.4294246886935441, 0.5551157071569044, 0.641129866546762, 0.2292504105416071, 0.2218058456312637, 0.22230656550713235, 0.33686295881202966, 0.27848606767370654, 0.21454053637429038, 0.20372963880149297, 0.15128821080273958, 0.39794626784261933, 0.22356068920084582, 0.14967899882762736, 0.3460745606001445, 0.13462870221790602, 0.13066161760638317, 0.1324333383194748, 0.26398070659869854, 0.5457827007374707, 0.6120169801637243, 0.13625233789797386, 0.24549133917399624, 0.13080430473110705, 0.13304666547801958, 0.13049659211334108, 0.13322173749730915, 0.21974090720652262, 0.1329639560906808, 0.1496385188927687, 0.004779048812517228, 0.17108797815354215, 0.25301519995891086, 0.05261252643587688, 0.12892384650099942, 0.0551684261914539, 0.006967628751370136, 0.11560747877196131, 0.12697739756745263, 0.15582431031483435, 0.09271555454571134, 0.15588800980252215, 0.10144902398426314, 0.06251420999704094, 0.07262084805527613, 0.08868747636358199, 0.11478102569127746, 0.09063059883759139, 0.12629005560510398, 0.09117513492272067, 0.17992686308692896, 0.10157509588947888, 0.11298179534745356, 0.15921708450034489, 0.08881133929437979, 0.13247967106154301, 0.20445416066555633, 0.1399055081927416, 0.10754854008343029, 0.26729325538556115, 0.0596286347337982, 0.2448441980950371, 0.07214332914793808, 0.22059840068686798, 0.07908865836731516, 0.09107640683861773, 0.5499288843441377, 0.6016802621354878, 0.5231668860289979, 0.5644406241666733, 0.5566533566676373, 0.5288568064385815, 0.5475886810377337, 0.5761841935507019, 0.6504214794789962, 0.08579403613110825, 0.09511929359087767, 0.14358011889337485, 0.09139821050759911, 0.11572463611429029, 0.10133279161032172, 0.11044625751079806, 0.10866352333885332, 0.11943270448993082, 0.2573311502062082, 0.22937414607557227, 0.19562154618877514, 0.3202692776393762, 0.20794559527720802, 0.20597359180019348, 0.26406130645571035, 0.2074774402405345, 0.40768283736460964, 0.18968002504602866, 0.32157365857738074, 0.3186151167879774, 0.33270363046002127, 0.2627444216739391, 0.2956015666241564, 0.21223646936301965, 0.3446130627616192, 0.22516985515672672, 0.22839949534625337, 0.25188988208791263, 0.25708494613176014, 0.29383914690161095, 0.17597975328975912, 0.25694322558054883, 0.18494244727765208, 0.2339092527794896, 0.22570769178373118, 0.23044350852583495, 0.2027194210053198, 0.211207360384028, 0.2385316905634688, 0.22879519414509175, 0.2526855623887996, 0.2889346062899941, 0.2307853887943655, 0.24870378186150188, 0.18483349298354435, 0.17058772111900034, 0.17391439201665038, 0.2270224744771232, 0.19906074777213134, 0.2014155098146012, 0.18572017396038665, 0.1875717454911342, 0.1765831943232613, 0.12658049617049671, 0.18757007971982376, 0.18694638686780962, 0.8592490352296711, 0.20049573519452968, 0.905463766379589, 0.14279112348068845, 0.8799172487320415, 0.9193381292571849, 0.8451848882252659, 0.2127446801105125, 0.862780704699071, 0.20899976331010583, 0.16866968390842374, 0.15521966944610244, 0.1050603046932228, 0.16750994235662564, 0.8301194917821172, 0.19359790302667412, 0.20541408507986803, 0.1828618480262616, 0.2147502480355553, 0.22612882847610083, 0.21115730752580986, 0.19981973822326748, 0.2168632705337129, 0.21118635083666837, 0.11197120297328023, 0.10713089067001458, 0.09632377131591785, 0.09663159245068198, 0.0932014556206584, 0.09202853398997957, 0.07720826498898636, 0.0996155979047102, 0.10561207933836725]}, "mutation_prompt": null}
{"id": "c61f54ae-0053-4fc1-8393-060845eecdc2", "solution": "import numpy as np\n\nclass DynamicAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7  # Increased for exploration\n        self.cognitive_weight = 1.5  # Adjusted for balanced learning\n        self.social_weight = 1.5  # Adjusted for balanced cooperation\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: 0.9 - iter * 0.5 / (self.budget/self.swarm_size)\n\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            velocities = np.clip(velocities, -1, 1)  # Control velocity\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 2 <= self.budget:\n                elite_idxs = np.argsort(personal_best_scores)[:3]\n                for i in elite_idxs:\n                    mutant = 0.5 * (positions[i] + global_best_position)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "DynamicAdaptivePSO", "description": "Dynamic Adaptive PSO with velocity control and elitist learning for enhanced convergence.", "configspace": "", "generation": 62, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a5d7036d-9a2d-4b13-9fbb-00412e65f461", "metadata": {"aucs": [0.8032135972550823, 0.7949118659281794, 0.8482728446676409, 0.7993670345346594, 0.7737528802393012, 0.8464902526554178, 0.8046519253932358, 0.805590481213056, 0.8461412014093087, 0.005783314147535412, 0.08588937958091614, 0.07784687388371492, 0.016921844029064936, 0.0421895187336917, 0.15930331104042017, 0.04351665314983588, 9.999999999998899e-05, 0.09932457982432175, 0.10887936612205595, 0.14106487423359249, 0.10120120324682214, 0.13712488658640198, 0.1131927136557066, 0.11801005973914358, 0.06999116975530628, 0.08998994870091392, 0.153945641686013, 0.08902008972685305, 0.08609414085503653, 0.07747571058178349, 0.0991600265351037, 0.09621864220040444, 0.08885327355791683, 0.08154460108384465, 0.1206487651268191, 0.12317125854406696, 0.9500949981300757, 0.9610162495112076, 0.9608173185629282, 0.9569062299208816, 0.9579478633221649, 0.9533167253824387, 0.9589146234755783, 0.9456046762511077, 0.9615824603584858, 0.4997793869222614, 0.4305469045242265, 0.058042371818485705, 0.46568283067902316, 0.5187228327236573, 0.6723002426355029, 0.4294246886935441, 0.5551157071569044, 0.641129866546762, 0.2292504105416071, 0.2218058456312637, 0.22230656550713235, 0.33686295881202966, 0.27848606767370654, 0.21454053637429038, 0.20372963880149297, 0.15128821080273958, 0.39794626784261933, 0.22356068920084582, 0.14967899882762736, 0.3460745606001445, 0.13462870221790602, 0.13066161760638317, 0.1324333383194748, 0.26398070659869854, 0.5457827007374707, 0.6120169801637243, 0.13625233789797386, 0.24549133917399624, 0.13080430473110705, 0.13304666547801958, 0.13049659211334108, 0.13322173749730915, 0.21974090720652262, 0.1329639560906808, 0.1496385188927687, 0.004779048812517228, 0.17108797815354215, 0.25301519995891086, 0.05261252643587688, 0.12892384650099942, 0.0551684261914539, 0.006967628751370136, 0.11560747877196131, 0.12697739756745263, 0.15582431031483435, 0.09271555454571134, 0.15588800980252215, 0.10144902398426314, 0.06251420999704094, 0.07262084805527613, 0.08868747636358199, 0.11478102569127746, 0.09063059883759139, 0.12629005560510398, 0.09117513492272067, 0.17992686308692896, 0.10157509588947888, 0.11298179534745356, 0.15921708450034489, 0.08881133929437979, 0.13247967106154301, 0.20445416066555633, 0.1399055081927416, 0.10754854008343029, 0.26729325538556115, 0.0596286347337982, 0.2448441980950371, 0.07214332914793808, 0.22059840068686798, 0.07908865836731516, 0.09107640683861773, 0.5499288843441377, 0.6016802621354878, 0.5231668860289979, 0.5644406241666733, 0.5566533566676373, 0.5288568064385815, 0.5475886810377337, 0.5761841935507019, 0.6504214794789962, 0.08579403613110825, 0.09511929359087767, 0.14358011889337485, 0.09139821050759911, 0.11572463611429029, 0.10133279161032172, 0.11044625751079806, 0.10866352333885332, 0.11943270448993082, 0.2573311502062082, 0.22937414607557227, 0.19562154618877514, 0.3202692776393762, 0.20794559527720802, 0.20597359180019348, 0.26406130645571035, 0.2074774402405345, 0.40768283736460964, 0.18968002504602866, 0.32157365857738074, 0.3186151167879774, 0.33270363046002127, 0.2627444216739391, 0.2956015666241564, 0.21223646936301965, 0.3446130627616192, 0.22516985515672672, 0.22839949534625337, 0.25188988208791263, 0.25708494613176014, 0.29383914690161095, 0.17597975328975912, 0.25694322558054883, 0.18494244727765208, 0.2339092527794896, 0.22570769178373118, 0.23044350852583495, 0.2027194210053198, 0.211207360384028, 0.2385316905634688, 0.22879519414509175, 0.2526855623887996, 0.2889346062899941, 0.2307853887943655, 0.24870378186150188, 0.18483349298354435, 0.17058772111900034, 0.17391439201665038, 0.2270224744771232, 0.19906074777213134, 0.2014155098146012, 0.18572017396038665, 0.1875717454911342, 0.1765831943232613, 0.12658049617049671, 0.18757007971982376, 0.18694638686780962, 0.8592490352296711, 0.20049573519452968, 0.905463766379589, 0.14279112348068845, 0.8799172487320415, 0.9193381292571849, 0.8451848882252659, 0.2127446801105125, 0.862780704699071, 0.20899976331010583, 0.16866968390842374, 0.15521966944610244, 0.1050603046932228, 0.16750994235662564, 0.8301194917821172, 0.19359790302667412, 0.20541408507986803, 0.1828618480262616, 0.2147502480355553, 0.22612882847610083, 0.21115730752580986, 0.19981973822326748, 0.2168632705337129, 0.21118635083666837, 0.11197120297328023, 0.10713089067001458, 0.09632377131591785, 0.09663159245068198, 0.0932014556206584, 0.09202853398997957, 0.07720826498898636, 0.0996155979047102, 0.10561207933836725]}, "mutation_prompt": null}
{"id": "4e484a03-4ac7-4236-94dc-150720d01306", "solution": "import numpy as np\n\nclass DynamicAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7  # Increased for exploration\n        self.cognitive_weight = 1.5  # Adjusted for balanced learning\n        self.social_weight = 1.5  # Adjusted for balanced cooperation\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: 0.9 - iter * 0.5 / (self.budget/self.swarm_size)\n\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            velocities = np.clip(velocities, -1, 1)  # Control velocity\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 2 <= self.budget:\n                elite_idxs = np.argsort(personal_best_scores)[:3]\n                for i in elite_idxs:\n                    mutant = 0.5 * (positions[i] + global_best_position)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "DynamicAdaptivePSO", "description": "Dynamic Adaptive PSO with velocity control and elitist learning for enhanced convergence.", "configspace": "", "generation": 62, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a5d7036d-9a2d-4b13-9fbb-00412e65f461", "metadata": {"aucs": [0.8032135972550823, 0.7949118659281794, 0.8482728446676409, 0.7993670345346594, 0.7737528802393012, 0.8464902526554178, 0.8046519253932358, 0.805590481213056, 0.8461412014093087, 0.005783314147535412, 0.08588937958091614, 0.07784687388371492, 0.016921844029064936, 0.0421895187336917, 0.15930331104042017, 0.04351665314983588, 9.999999999998899e-05, 0.09932457982432175, 0.10887936612205595, 0.14106487423359249, 0.10120120324682214, 0.13712488658640198, 0.1131927136557066, 0.11801005973914358, 0.06999116975530628, 0.08998994870091392, 0.153945641686013, 0.08902008972685305, 0.08609414085503653, 0.07747571058178349, 0.0991600265351037, 0.09621864220040444, 0.08885327355791683, 0.08154460108384465, 0.1206487651268191, 0.12317125854406696, 0.9500949981300757, 0.9610162495112076, 0.9608173185629282, 0.9569062299208816, 0.9579478633221649, 0.9533167253824387, 0.9589146234755783, 0.9456046762511077, 0.9615824603584858, 0.4997793869222614, 0.4305469045242265, 0.058042371818485705, 0.46568283067902316, 0.5187228327236573, 0.6723002426355029, 0.4294246886935441, 0.5551157071569044, 0.641129866546762, 0.2292504105416071, 0.2218058456312637, 0.22230656550713235, 0.33686295881202966, 0.27848606767370654, 0.21454053637429038, 0.20372963880149297, 0.15128821080273958, 0.39794626784261933, 0.22356068920084582, 0.14967899882762736, 0.3460745606001445, 0.13462870221790602, 0.13066161760638317, 0.1324333383194748, 0.26398070659869854, 0.5457827007374707, 0.6120169801637243, 0.13625233789797386, 0.24549133917399624, 0.13080430473110705, 0.13304666547801958, 0.13049659211334108, 0.13322173749730915, 0.21974090720652262, 0.1329639560906808, 0.1496385188927687, 0.004779048812517228, 0.17108797815354215, 0.25301519995891086, 0.05261252643587688, 0.12892384650099942, 0.0551684261914539, 0.006967628751370136, 0.11560747877196131, 0.12697739756745263, 0.15582431031483435, 0.09271555454571134, 0.15588800980252215, 0.10144902398426314, 0.06251420999704094, 0.07262084805527613, 0.08868747636358199, 0.11478102569127746, 0.09063059883759139, 0.12629005560510398, 0.09117513492272067, 0.17992686308692896, 0.10157509588947888, 0.11298179534745356, 0.15921708450034489, 0.08881133929437979, 0.13247967106154301, 0.20445416066555633, 0.1399055081927416, 0.10754854008343029, 0.26729325538556115, 0.0596286347337982, 0.2448441980950371, 0.07214332914793808, 0.22059840068686798, 0.07908865836731516, 0.09107640683861773, 0.5499288843441377, 0.6016802621354878, 0.5231668860289979, 0.5644406241666733, 0.5566533566676373, 0.5288568064385815, 0.5475886810377337, 0.5761841935507019, 0.6504214794789962, 0.08579403613110825, 0.09511929359087767, 0.14358011889337485, 0.09139821050759911, 0.11572463611429029, 0.10133279161032172, 0.11044625751079806, 0.10866352333885332, 0.11943270448993082, 0.2573311502062082, 0.22937414607557227, 0.19562154618877514, 0.3202692776393762, 0.20794559527720802, 0.20597359180019348, 0.26406130645571035, 0.2074774402405345, 0.40768283736460964, 0.18968002504602866, 0.32157365857738074, 0.3186151167879774, 0.33270363046002127, 0.2627444216739391, 0.2956015666241564, 0.21223646936301965, 0.3446130627616192, 0.22516985515672672, 0.22839949534625337, 0.25188988208791263, 0.25708494613176014, 0.29383914690161095, 0.17597975328975912, 0.25694322558054883, 0.18494244727765208, 0.2339092527794896, 0.22570769178373118, 0.23044350852583495, 0.2027194210053198, 0.211207360384028, 0.2385316905634688, 0.22879519414509175, 0.2526855623887996, 0.2889346062899941, 0.2307853887943655, 0.24870378186150188, 0.18483349298354435, 0.17058772111900034, 0.17391439201665038, 0.2270224744771232, 0.19906074777213134, 0.2014155098146012, 0.18572017396038665, 0.1875717454911342, 0.1765831943232613, 0.12658049617049671, 0.18757007971982376, 0.18694638686780962, 0.8592490352296711, 0.20049573519452968, 0.905463766379589, 0.14279112348068845, 0.8799172487320415, 0.9193381292571849, 0.8451848882252659, 0.2127446801105125, 0.862780704699071, 0.20899976331010583, 0.16866968390842374, 0.15521966944610244, 0.1050603046932228, 0.16750994235662564, 0.8301194917821172, 0.19359790302667412, 0.20541408507986803, 0.1828618480262616, 0.2147502480355553, 0.22612882847610083, 0.21115730752580986, 0.19981973822326748, 0.2168632705337129, 0.21118635083666837, 0.11197120297328023, 0.10713089067001458, 0.09632377131591785, 0.09663159245068198, 0.0932014556206584, 0.09202853398997957, 0.07720826498898636, 0.0996155979047102, 0.10561207933836725]}, "mutation_prompt": null}
{"id": "f7e144c4-c781-4f97-962b-c7e5fe6a057c", "solution": "import numpy as np\n\nclass DynamicAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7  # Increased for exploration\n        self.cognitive_weight = 1.5  # Adjusted for balanced learning\n        self.social_weight = 1.5  # Adjusted for balanced cooperation\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: 0.9 - iter * 0.5 / (self.budget/self.swarm_size)\n\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            velocities = np.clip(velocities, -1, 1)  # Control velocity\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 2 <= self.budget:\n                elite_idxs = np.argsort(personal_best_scores)[:3]\n                for i in elite_idxs:\n                    mutant = 0.5 * (positions[i] + global_best_position)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "DynamicAdaptivePSO", "description": "Dynamic Adaptive PSO with velocity control and elitist learning for enhanced convergence.", "configspace": "", "generation": 62, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a5d7036d-9a2d-4b13-9fbb-00412e65f461", "metadata": {"aucs": [0.8032135972550823, 0.7949118659281794, 0.8482728446676409, 0.7993670345346594, 0.7737528802393012, 0.8464902526554178, 0.8046519253932358, 0.805590481213056, 0.8461412014093087, 0.005783314147535412, 0.08588937958091614, 0.07784687388371492, 0.016921844029064936, 0.0421895187336917, 0.15930331104042017, 0.04351665314983588, 9.999999999998899e-05, 0.09932457982432175, 0.10887936612205595, 0.14106487423359249, 0.10120120324682214, 0.13712488658640198, 0.1131927136557066, 0.11801005973914358, 0.06999116975530628, 0.08998994870091392, 0.153945641686013, 0.08902008972685305, 0.08609414085503653, 0.07747571058178349, 0.0991600265351037, 0.09621864220040444, 0.08885327355791683, 0.08154460108384465, 0.1206487651268191, 0.12317125854406696, 0.9500949981300757, 0.9610162495112076, 0.9608173185629282, 0.9569062299208816, 0.9579478633221649, 0.9533167253824387, 0.9589146234755783, 0.9456046762511077, 0.9615824603584858, 0.4997793869222614, 0.4305469045242265, 0.058042371818485705, 0.46568283067902316, 0.5187228327236573, 0.6723002426355029, 0.4294246886935441, 0.5551157071569044, 0.641129866546762, 0.2292504105416071, 0.2218058456312637, 0.22230656550713235, 0.33686295881202966, 0.27848606767370654, 0.21454053637429038, 0.20372963880149297, 0.15128821080273958, 0.39794626784261933, 0.22356068920084582, 0.14967899882762736, 0.3460745606001445, 0.13462870221790602, 0.13066161760638317, 0.1324333383194748, 0.26398070659869854, 0.5457827007374707, 0.6120169801637243, 0.13625233789797386, 0.24549133917399624, 0.13080430473110705, 0.13304666547801958, 0.13049659211334108, 0.13322173749730915, 0.21974090720652262, 0.1329639560906808, 0.1496385188927687, 0.004779048812517228, 0.17108797815354215, 0.25301519995891086, 0.05261252643587688, 0.12892384650099942, 0.0551684261914539, 0.006967628751370136, 0.11560747877196131, 0.12697739756745263, 0.15582431031483435, 0.09271555454571134, 0.15588800980252215, 0.10144902398426314, 0.06251420999704094, 0.07262084805527613, 0.08868747636358199, 0.11478102569127746, 0.09063059883759139, 0.12629005560510398, 0.09117513492272067, 0.17992686308692896, 0.10157509588947888, 0.11298179534745356, 0.15921708450034489, 0.08881133929437979, 0.13247967106154301, 0.20445416066555633, 0.1399055081927416, 0.10754854008343029, 0.26729325538556115, 0.0596286347337982, 0.2448441980950371, 0.07214332914793808, 0.22059840068686798, 0.07908865836731516, 0.09107640683861773, 0.5499288843441377, 0.6016802621354878, 0.5231668860289979, 0.5644406241666733, 0.5566533566676373, 0.5288568064385815, 0.5475886810377337, 0.5761841935507019, 0.6504214794789962, 0.08579403613110825, 0.09511929359087767, 0.14358011889337485, 0.09139821050759911, 0.11572463611429029, 0.10133279161032172, 0.11044625751079806, 0.10866352333885332, 0.11943270448993082, 0.2573311502062082, 0.22937414607557227, 0.19562154618877514, 0.3202692776393762, 0.20794559527720802, 0.20597359180019348, 0.26406130645571035, 0.2074774402405345, 0.40768283736460964, 0.18968002504602866, 0.32157365857738074, 0.3186151167879774, 0.33270363046002127, 0.2627444216739391, 0.2956015666241564, 0.21223646936301965, 0.3446130627616192, 0.22516985515672672, 0.22839949534625337, 0.25188988208791263, 0.25708494613176014, 0.29383914690161095, 0.17597975328975912, 0.25694322558054883, 0.18494244727765208, 0.2339092527794896, 0.22570769178373118, 0.23044350852583495, 0.2027194210053198, 0.211207360384028, 0.2385316905634688, 0.22879519414509175, 0.2526855623887996, 0.2889346062899941, 0.2307853887943655, 0.24870378186150188, 0.18483349298354435, 0.17058772111900034, 0.17391439201665038, 0.2270224744771232, 0.19906074777213134, 0.2014155098146012, 0.18572017396038665, 0.1875717454911342, 0.1765831943232613, 0.12658049617049671, 0.18757007971982376, 0.18694638686780962, 0.8592490352296711, 0.20049573519452968, 0.905463766379589, 0.14279112348068845, 0.8799172487320415, 0.9193381292571849, 0.8451848882252659, 0.2127446801105125, 0.862780704699071, 0.20899976331010583, 0.16866968390842374, 0.15521966944610244, 0.1050603046932228, 0.16750994235662564, 0.8301194917821172, 0.19359790302667412, 0.20541408507986803, 0.1828618480262616, 0.2147502480355553, 0.22612882847610083, 0.21115730752580986, 0.19981973822326748, 0.2168632705337129, 0.21118635083666837, 0.11197120297328023, 0.10713089067001458, 0.09632377131591785, 0.09663159245068198, 0.0932014556206584, 0.09202853398997957, 0.07720826498898636, 0.0996155979047102, 0.10561207933836725]}, "mutation_prompt": null}
{"id": "70fa5a69-174b-49ba-adcd-934e771fb85d", "solution": "import numpy as np\n\nclass DynamicAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7  # Increased for exploration\n        self.cognitive_weight = 1.5  # Adjusted for balanced learning\n        self.social_weight = 1.5  # Adjusted for balanced cooperation\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: 0.9 - iter * 0.5 / (self.budget/self.swarm_size)\n\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            velocities = np.clip(velocities, -1, 1)  # Control velocity\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 2 <= self.budget:\n                elite_idxs = np.argsort(personal_best_scores)[:3]\n                for i in elite_idxs:\n                    mutant = 0.5 * (positions[i] + global_best_position)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "DynamicAdaptivePSO", "description": "Dynamic Adaptive PSO with velocity control and elitist learning for enhanced convergence.", "configspace": "", "generation": 62, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a5d7036d-9a2d-4b13-9fbb-00412e65f461", "metadata": {"aucs": [0.8032135972550823, 0.7949118659281794, 0.8482728446676409, 0.7993670345346594, 0.7737528802393012, 0.8464902526554178, 0.8046519253932358, 0.805590481213056, 0.8461412014093087, 0.005783314147535412, 0.08588937958091614, 0.07784687388371492, 0.016921844029064936, 0.0421895187336917, 0.15930331104042017, 0.04351665314983588, 9.999999999998899e-05, 0.09932457982432175, 0.10887936612205595, 0.14106487423359249, 0.10120120324682214, 0.13712488658640198, 0.1131927136557066, 0.11801005973914358, 0.06999116975530628, 0.08998994870091392, 0.153945641686013, 0.08902008972685305, 0.08609414085503653, 0.07747571058178349, 0.0991600265351037, 0.09621864220040444, 0.08885327355791683, 0.08154460108384465, 0.1206487651268191, 0.12317125854406696, 0.9500949981300757, 0.9610162495112076, 0.9608173185629282, 0.9569062299208816, 0.9579478633221649, 0.9533167253824387, 0.9589146234755783, 0.9456046762511077, 0.9615824603584858, 0.4997793869222614, 0.4305469045242265, 0.058042371818485705, 0.46568283067902316, 0.5187228327236573, 0.6723002426355029, 0.4294246886935441, 0.5551157071569044, 0.641129866546762, 0.2292504105416071, 0.2218058456312637, 0.22230656550713235, 0.33686295881202966, 0.27848606767370654, 0.21454053637429038, 0.20372963880149297, 0.15128821080273958, 0.39794626784261933, 0.22356068920084582, 0.14967899882762736, 0.3460745606001445, 0.13462870221790602, 0.13066161760638317, 0.1324333383194748, 0.26398070659869854, 0.5457827007374707, 0.6120169801637243, 0.13625233789797386, 0.24549133917399624, 0.13080430473110705, 0.13304666547801958, 0.13049659211334108, 0.13322173749730915, 0.21974090720652262, 0.1329639560906808, 0.1496385188927687, 0.004779048812517228, 0.17108797815354215, 0.25301519995891086, 0.05261252643587688, 0.12892384650099942, 0.0551684261914539, 0.006967628751370136, 0.11560747877196131, 0.12697739756745263, 0.15582431031483435, 0.09271555454571134, 0.15588800980252215, 0.10144902398426314, 0.06251420999704094, 0.07262084805527613, 0.08868747636358199, 0.11478102569127746, 0.09063059883759139, 0.12629005560510398, 0.09117513492272067, 0.17992686308692896, 0.10157509588947888, 0.11298179534745356, 0.15921708450034489, 0.08881133929437979, 0.13247967106154301, 0.20445416066555633, 0.1399055081927416, 0.10754854008343029, 0.26729325538556115, 0.0596286347337982, 0.2448441980950371, 0.07214332914793808, 0.22059840068686798, 0.07908865836731516, 0.09107640683861773, 0.5499288843441377, 0.6016802621354878, 0.5231668860289979, 0.5644406241666733, 0.5566533566676373, 0.5288568064385815, 0.5475886810377337, 0.5761841935507019, 0.6504214794789962, 0.08579403613110825, 0.09511929359087767, 0.14358011889337485, 0.09139821050759911, 0.11572463611429029, 0.10133279161032172, 0.11044625751079806, 0.10866352333885332, 0.11943270448993082, 0.2573311502062082, 0.22937414607557227, 0.19562154618877514, 0.3202692776393762, 0.20794559527720802, 0.20597359180019348, 0.26406130645571035, 0.2074774402405345, 0.40768283736460964, 0.18968002504602866, 0.32157365857738074, 0.3186151167879774, 0.33270363046002127, 0.2627444216739391, 0.2956015666241564, 0.21223646936301965, 0.3446130627616192, 0.22516985515672672, 0.22839949534625337, 0.25188988208791263, 0.25708494613176014, 0.29383914690161095, 0.17597975328975912, 0.25694322558054883, 0.18494244727765208, 0.2339092527794896, 0.22570769178373118, 0.23044350852583495, 0.2027194210053198, 0.211207360384028, 0.2385316905634688, 0.22879519414509175, 0.2526855623887996, 0.2889346062899941, 0.2307853887943655, 0.24870378186150188, 0.18483349298354435, 0.17058772111900034, 0.17391439201665038, 0.2270224744771232, 0.19906074777213134, 0.2014155098146012, 0.18572017396038665, 0.1875717454911342, 0.1765831943232613, 0.12658049617049671, 0.18757007971982376, 0.18694638686780962, 0.8592490352296711, 0.20049573519452968, 0.905463766379589, 0.14279112348068845, 0.8799172487320415, 0.9193381292571849, 0.8451848882252659, 0.2127446801105125, 0.862780704699071, 0.20899976331010583, 0.16866968390842374, 0.15521966944610244, 0.1050603046932228, 0.16750994235662564, 0.8301194917821172, 0.19359790302667412, 0.20541408507986803, 0.1828618480262616, 0.2147502480355553, 0.22612882847610083, 0.21115730752580986, 0.19981973822326748, 0.2168632705337129, 0.21118635083666837, 0.11197120297328023, 0.10713089067001458, 0.09632377131591785, 0.09663159245068198, 0.0932014556206584, 0.09202853398997957, 0.07720826498898636, 0.0996155979047102, 0.10561207933836725]}, "mutation_prompt": null}
{"id": "60594534-e3fe-4da2-bb21-c7e6b718b32d", "solution": "import numpy as np\n\nclass DynamicAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7  # Increased for exploration\n        self.cognitive_weight = 1.5  # Adjusted for balanced learning\n        self.social_weight = 1.5  # Adjusted for balanced cooperation\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: 0.9 - iter * 0.5 / (self.budget/self.swarm_size)\n\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            velocities = np.clip(velocities, -1, 1)  # Control velocity\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 2 <= self.budget:\n                elite_idxs = np.argsort(personal_best_scores)[:3]\n                for i in elite_idxs:\n                    mutant = 0.5 * (positions[i] + global_best_position)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "DynamicAdaptivePSO", "description": "Dynamic Adaptive PSO with velocity control and elitist learning for enhanced convergence.", "configspace": "", "generation": 62, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a5d7036d-9a2d-4b13-9fbb-00412e65f461", "metadata": {"aucs": [0.8032135972550823, 0.7949118659281794, 0.8482728446676409, 0.7993670345346594, 0.7737528802393012, 0.8464902526554178, 0.8046519253932358, 0.805590481213056, 0.8461412014093087, 0.005783314147535412, 0.08588937958091614, 0.07784687388371492, 0.016921844029064936, 0.0421895187336917, 0.15930331104042017, 0.04351665314983588, 9.999999999998899e-05, 0.09932457982432175, 0.10887936612205595, 0.14106487423359249, 0.10120120324682214, 0.13712488658640198, 0.1131927136557066, 0.11801005973914358, 0.06999116975530628, 0.08998994870091392, 0.153945641686013, 0.08902008972685305, 0.08609414085503653, 0.07747571058178349, 0.0991600265351037, 0.09621864220040444, 0.08885327355791683, 0.08154460108384465, 0.1206487651268191, 0.12317125854406696, 0.9500949981300757, 0.9610162495112076, 0.9608173185629282, 0.9569062299208816, 0.9579478633221649, 0.9533167253824387, 0.9589146234755783, 0.9456046762511077, 0.9615824603584858, 0.4997793869222614, 0.4305469045242265, 0.058042371818485705, 0.46568283067902316, 0.5187228327236573, 0.6723002426355029, 0.4294246886935441, 0.5551157071569044, 0.641129866546762, 0.2292504105416071, 0.2218058456312637, 0.22230656550713235, 0.33686295881202966, 0.27848606767370654, 0.21454053637429038, 0.20372963880149297, 0.15128821080273958, 0.39794626784261933, 0.22356068920084582, 0.14967899882762736, 0.3460745606001445, 0.13462870221790602, 0.13066161760638317, 0.1324333383194748, 0.26398070659869854, 0.5457827007374707, 0.6120169801637243, 0.13625233789797386, 0.24549133917399624, 0.13080430473110705, 0.13304666547801958, 0.13049659211334108, 0.13322173749730915, 0.21974090720652262, 0.1329639560906808, 0.1496385188927687, 0.004779048812517228, 0.17108797815354215, 0.25301519995891086, 0.05261252643587688, 0.12892384650099942, 0.0551684261914539, 0.006967628751370136, 0.11560747877196131, 0.12697739756745263, 0.15582431031483435, 0.09271555454571134, 0.15588800980252215, 0.10144902398426314, 0.06251420999704094, 0.07262084805527613, 0.08868747636358199, 0.11478102569127746, 0.09063059883759139, 0.12629005560510398, 0.09117513492272067, 0.17992686308692896, 0.10157509588947888, 0.11298179534745356, 0.15921708450034489, 0.08881133929437979, 0.13247967106154301, 0.20445416066555633, 0.1399055081927416, 0.10754854008343029, 0.26729325538556115, 0.0596286347337982, 0.2448441980950371, 0.07214332914793808, 0.22059840068686798, 0.07908865836731516, 0.09107640683861773, 0.5499288843441377, 0.6016802621354878, 0.5231668860289979, 0.5644406241666733, 0.5566533566676373, 0.5288568064385815, 0.5475886810377337, 0.5761841935507019, 0.6504214794789962, 0.08579403613110825, 0.09511929359087767, 0.14358011889337485, 0.09139821050759911, 0.11572463611429029, 0.10133279161032172, 0.11044625751079806, 0.10866352333885332, 0.11943270448993082, 0.2573311502062082, 0.22937414607557227, 0.19562154618877514, 0.3202692776393762, 0.20794559527720802, 0.20597359180019348, 0.26406130645571035, 0.2074774402405345, 0.40768283736460964, 0.18968002504602866, 0.32157365857738074, 0.3186151167879774, 0.33270363046002127, 0.2627444216739391, 0.2956015666241564, 0.21223646936301965, 0.3446130627616192, 0.22516985515672672, 0.22839949534625337, 0.25188988208791263, 0.25708494613176014, 0.29383914690161095, 0.17597975328975912, 0.25694322558054883, 0.18494244727765208, 0.2339092527794896, 0.22570769178373118, 0.23044350852583495, 0.2027194210053198, 0.211207360384028, 0.2385316905634688, 0.22879519414509175, 0.2526855623887996, 0.2889346062899941, 0.2307853887943655, 0.24870378186150188, 0.18483349298354435, 0.17058772111900034, 0.17391439201665038, 0.2270224744771232, 0.19906074777213134, 0.2014155098146012, 0.18572017396038665, 0.1875717454911342, 0.1765831943232613, 0.12658049617049671, 0.18757007971982376, 0.18694638686780962, 0.8592490352296711, 0.20049573519452968, 0.905463766379589, 0.14279112348068845, 0.8799172487320415, 0.9193381292571849, 0.8451848882252659, 0.2127446801105125, 0.862780704699071, 0.20899976331010583, 0.16866968390842374, 0.15521966944610244, 0.1050603046932228, 0.16750994235662564, 0.8301194917821172, 0.19359790302667412, 0.20541408507986803, 0.1828618480262616, 0.2147502480355553, 0.22612882847610083, 0.21115730752580986, 0.19981973822326748, 0.2168632705337129, 0.21118635083666837, 0.11197120297328023, 0.10713089067001458, 0.09632377131591785, 0.09663159245068198, 0.0932014556206584, 0.09202853398997957, 0.07720826498898636, 0.0996155979047102, 0.10561207933836725]}, "mutation_prompt": null}
{"id": "03272152-2edc-491e-be03-206057de165a", "solution": "import numpy as np\n\nclass DynamicAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7  # Increased for exploration\n        self.cognitive_weight = 1.5  # Adjusted for balanced learning\n        self.social_weight = 1.5  # Adjusted for balanced cooperation\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: 0.9 - iter * 0.5 / (self.budget/self.swarm_size)\n\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            velocities = np.clip(velocities, -1, 1)  # Control velocity\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 2 <= self.budget:\n                elite_idxs = np.argsort(personal_best_scores)[:3]\n                for i in elite_idxs:\n                    mutant = 0.5 * (positions[i] + global_best_position)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "DynamicAdaptivePSO", "description": "Dynamic Adaptive PSO with velocity control and elitist learning for enhanced convergence.", "configspace": "", "generation": 62, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a5d7036d-9a2d-4b13-9fbb-00412e65f461", "metadata": {"aucs": [0.8032135972550823, 0.7949118659281794, 0.8482728446676409, 0.7993670345346594, 0.7737528802393012, 0.8464902526554178, 0.8046519253932358, 0.805590481213056, 0.8461412014093087, 0.005783314147535412, 0.08588937958091614, 0.07784687388371492, 0.016921844029064936, 0.0421895187336917, 0.15930331104042017, 0.04351665314983588, 9.999999999998899e-05, 0.09932457982432175, 0.10887936612205595, 0.14106487423359249, 0.10120120324682214, 0.13712488658640198, 0.1131927136557066, 0.11801005973914358, 0.06999116975530628, 0.08998994870091392, 0.153945641686013, 0.08902008972685305, 0.08609414085503653, 0.07747571058178349, 0.0991600265351037, 0.09621864220040444, 0.08885327355791683, 0.08154460108384465, 0.1206487651268191, 0.12317125854406696, 0.9500949981300757, 0.9610162495112076, 0.9608173185629282, 0.9569062299208816, 0.9579478633221649, 0.9533167253824387, 0.9589146234755783, 0.9456046762511077, 0.9615824603584858, 0.4997793869222614, 0.4305469045242265, 0.058042371818485705, 0.46568283067902316, 0.5187228327236573, 0.6723002426355029, 0.4294246886935441, 0.5551157071569044, 0.641129866546762, 0.2292504105416071, 0.2218058456312637, 0.22230656550713235, 0.33686295881202966, 0.27848606767370654, 0.21454053637429038, 0.20372963880149297, 0.15128821080273958, 0.39794626784261933, 0.22356068920084582, 0.14967899882762736, 0.3460745606001445, 0.13462870221790602, 0.13066161760638317, 0.1324333383194748, 0.26398070659869854, 0.5457827007374707, 0.6120169801637243, 0.13625233789797386, 0.24549133917399624, 0.13080430473110705, 0.13304666547801958, 0.13049659211334108, 0.13322173749730915, 0.21974090720652262, 0.1329639560906808, 0.1496385188927687, 0.004779048812517228, 0.17108797815354215, 0.25301519995891086, 0.05261252643587688, 0.12892384650099942, 0.0551684261914539, 0.006967628751370136, 0.11560747877196131, 0.12697739756745263, 0.15582431031483435, 0.09271555454571134, 0.15588800980252215, 0.10144902398426314, 0.06251420999704094, 0.07262084805527613, 0.08868747636358199, 0.11478102569127746, 0.09063059883759139, 0.12629005560510398, 0.09117513492272067, 0.17992686308692896, 0.10157509588947888, 0.11298179534745356, 0.15921708450034489, 0.08881133929437979, 0.13247967106154301, 0.20445416066555633, 0.1399055081927416, 0.10754854008343029, 0.26729325538556115, 0.0596286347337982, 0.2448441980950371, 0.07214332914793808, 0.22059840068686798, 0.07908865836731516, 0.09107640683861773, 0.5499288843441377, 0.6016802621354878, 0.5231668860289979, 0.5644406241666733, 0.5566533566676373, 0.5288568064385815, 0.5475886810377337, 0.5761841935507019, 0.6504214794789962, 0.08579403613110825, 0.09511929359087767, 0.14358011889337485, 0.09139821050759911, 0.11572463611429029, 0.10133279161032172, 0.11044625751079806, 0.10866352333885332, 0.11943270448993082, 0.2573311502062082, 0.22937414607557227, 0.19562154618877514, 0.3202692776393762, 0.20794559527720802, 0.20597359180019348, 0.26406130645571035, 0.2074774402405345, 0.40768283736460964, 0.18968002504602866, 0.32157365857738074, 0.3186151167879774, 0.33270363046002127, 0.2627444216739391, 0.2956015666241564, 0.21223646936301965, 0.3446130627616192, 0.22516985515672672, 0.22839949534625337, 0.25188988208791263, 0.25708494613176014, 0.29383914690161095, 0.17597975328975912, 0.25694322558054883, 0.18494244727765208, 0.2339092527794896, 0.22570769178373118, 0.23044350852583495, 0.2027194210053198, 0.211207360384028, 0.2385316905634688, 0.22879519414509175, 0.2526855623887996, 0.2889346062899941, 0.2307853887943655, 0.24870378186150188, 0.18483349298354435, 0.17058772111900034, 0.17391439201665038, 0.2270224744771232, 0.19906074777213134, 0.2014155098146012, 0.18572017396038665, 0.1875717454911342, 0.1765831943232613, 0.12658049617049671, 0.18757007971982376, 0.18694638686780962, 0.8592490352296711, 0.20049573519452968, 0.905463766379589, 0.14279112348068845, 0.8799172487320415, 0.9193381292571849, 0.8451848882252659, 0.2127446801105125, 0.862780704699071, 0.20899976331010583, 0.16866968390842374, 0.15521966944610244, 0.1050603046932228, 0.16750994235662564, 0.8301194917821172, 0.19359790302667412, 0.20541408507986803, 0.1828618480262616, 0.2147502480355553, 0.22612882847610083, 0.21115730752580986, 0.19981973822326748, 0.2168632705337129, 0.21118635083666837, 0.11197120297328023, 0.10713089067001458, 0.09632377131591785, 0.09663159245068198, 0.0932014556206584, 0.09202853398997957, 0.07720826498898636, 0.0996155979047102, 0.10561207933836725]}, "mutation_prompt": null}
{"id": "639e9f06-d61f-4969-8a55-c0c3d0361833", "solution": "import numpy as np\n\nclass EnhancedDynamicAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50  # Increased swarm size for better exploration\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.6  # Adjusted for dynamic balance\n        self.cognitive_weight = 1.4  # Lowered to diversify individual learning\n        self.social_weight = 1.6  # Increased to enhance cooperation\n    \n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: 0.9 - iter * 0.4 / (self.budget/self.swarm_size)\n\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            velocities = np.clip(velocities, -0.8, 0.8)  # Broadened velocity control\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 2 <= self.budget:\n                elite_idxs = np.argsort(personal_best_scores)[:5]  # Expanded elite selection\n                for i in elite_idxs:\n                    mutant = np.mean([positions[i], global_best_position], axis=0)  # Different mutation strategy\n                    mutant += np.random.uniform(-0.1, 0.1, self.dim)  # Added randomness\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "EnhancedDynamicAdaptivePSO", "description": "Enhanced DynamicAdaptivePSO using adaptive learning rates and diversified mutation strategies for improved convergence.", "configspace": "", "generation": 77, "fitness": 0.29009806849161696, "feedback": "The algorithm EnhancedDynamicAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.25.", "error": "", "parent_id": "a5d7036d-9a2d-4b13-9fbb-00412e65f461", "metadata": {"aucs": [0.7764172761482304, 0.7791925772543138, 0.8088414785173241, 0.7736817395608215, 0.7335170716919777, 0.8233280632664114, 0.7644540863459688, 0.7503726147687699, 0.808885038241872, 0.10145433440754803, 0.08886492868101392, 0.10779988380833405, 0.012489698104030666, 0.10374344978688754, 0.09472143133958011, 0.03770454147075342, 0.07923929648403538, 0.09743893955390026, 0.0937693616971208, 0.15756190703038775, 0.08512178709331453, 0.10019881650732188, 0.1182852242649155, 0.14143324414187353, 0.0916655867239844, 0.13045925253729507, 0.08479471180540565, 0.0708637449105951, 0.11381742983374565, 0.07942762112021451, 0.10496472241728894, 0.06243939416296762, 0.14350939546816666, 0.11115278672449658, 0.08429688325756357, 0.053452648295375216, 0.940716539968656, 0.9301424862212919, 0.9447263039166043, 0.9279154024101078, 0.931741478936038, 0.9311645176189779, 0.9370566535541718, 0.916613353438103, 0.935952862764997, 0.5498361651436212, 0.5893710474437985, 0.4753730307706171, 0.39256756418766203, 0.5583338388223831, 0.5527707087792406, 0.6093353095758114, 0.3830193674795944, 0.4890357930519651, 0.22775153998171394, 0.23064893712311196, 0.2265946400504405, 0.2151385531686042, 0.392859353076362, 0.2799715252646944, 0.17769498048709342, 0.17319091652713559, 0.3370714248990936, 0.24426855596387764, 0.11277726034119973, 0.1476964760241668, 0.2113218420042493, 0.1320497193495337, 0.10827644598439778, 0.22275553862796216, 0.4070052642978689, 0.21095840903968754, 0.4130694146277546, 0.2072513932505825, 0.21598895225429982, 0.24926099617045883, 0.16334296535944903, 0.13861598300393307, 0.25475989483215267, 0.252042180934684, 0.13419465571159905, 0.048576754668604005, 0.06408249246393538, 0.17949728027191647, 0.056755124068638585, 0.09571434361130982, 0.040162324108560465, 0.003466879770134601, 0.05896738219090725, 0.15973196407318158, 0.2787596717549302, 0.12479577343238868, 0.1851563143013244, 0.1398077359755966, 0.12049704882731127, 0.07426307375222718, 0.10696834036091063, 0.23689042232604784, 0.10280559026869851, 0.15644371283923064, 0.12770771422075977, 0.20112622708829564, 0.10262247621634757, 0.08531241446381477, 0.10364155494520677, 0.1088837048023713, 0.2026714035021886, 0.07402708524750035, 0.1200614439767903, 0.08228256542690282, 0.09916543140583312, 0.09752339355879103, 0.26728285832650844, 0.18587408452010434, 0.12429369121497291, 0.21481195008839216, 0.08613435415652371, 0.5431778514999291, 0.5530873069440211, 0.6150239392448322, 0.5289453178573889, 0.5247566852085477, 0.5839669919733769, 0.5285908996198474, 0.6472113896083879, 0.6223664175871519, 0.07769869015555508, 0.11275622116458384, 0.0733487195743513, 0.11159702017130535, 0.07844043909786846, 0.0969815970941954, 0.10744955439045156, 0.11410703319367732, 0.05463306959087311, 0.17010463970632117, 0.373483847348935, 0.1788229282745598, 0.15094402043160593, 0.2833654393758277, 0.2832058623051086, 0.4071281726841057, 0.17058491309247126, 0.2576200204194934, 0.29615671074820615, 0.3007755380632863, 0.42894898655448455, 0.37546071958019034, 0.2124669004399874, 0.4393102826460452, 0.4245389739547337, 0.33094716374690814, 0.21714392684277617, 0.2035701696149439, 0.32472492058916824, 0.3092937359767537, 0.24735898495040654, 0.2011132532434966, 0.27912712612050083, 0.20045852826308364, 0.24775335497630446, 0.2638727694403509, 0.2325864475947519, 0.25516062474123835, 0.33159852860652683, 0.2535725632367337, 0.2455606784137262, 0.21383427193588822, 0.286648671065718, 0.21679759697041034, 0.23865236590285444, 0.20276627835993266, 0.19713902290755358, 0.16352938768816117, 0.1821433309985141, 0.22322248205657935, 0.1886465638129604, 0.2531130332962719, 0.1844615862185217, 0.19148023723466767, 0.8449966508117753, 0.17649176090782515, 0.18712783910321096, 0.8913008314607084, 0.20092107438539453, 0.8844491266774176, 0.1429540651278809, 0.16248688303411019, 0.8963906833618371, 0.7497490014056183, 0.2140081109477019, 0.07355561670582578, 0.8003438736891941, 0.20958833096535057, 0.1536351008690775, 0.7838724760686904, 0.7767816695930769, 0.7886190180713445, 0.21428290760997137, 0.19830155206983602, 0.21519856561889006, 0.201020102509465, 0.22373837274427122, 0.19968077353946379, 0.21823718232895206, 0.3011306039197078, 0.2052143748016373, 0.12536324019064649, 0.1246747842825976, 0.08399849127312586, 0.09174620889419516, 0.08395837012742158, 0.10144180620851495, 0.14141362560373694, 0.10976017175242869, 0.10305905103024338]}, "mutation_prompt": null}
{"id": "d2015455-eda1-4461-a9a7-8fad2687b63f", "solution": "import numpy as np\n\nclass EnhancedDynamicAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50  # Increased swarm size for better exploration\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.6  # Adjusted for dynamic balance\n        self.cognitive_weight = 1.4  # Lowered to diversify individual learning\n        self.social_weight = 1.6  # Increased to enhance cooperation\n    \n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: 0.9 - iter * 0.4 / (self.budget/self.swarm_size)\n\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            velocities = np.clip(velocities, -0.8, 0.8)  # Broadened velocity control\n            positions += velocities\n\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 2 <= self.budget:\n                elite_idxs = np.argsort(personal_best_scores)[:5]  # Expanded elite selection\n                for i in elite_idxs:\n                    mutant = np.mean([positions[i], global_best_position], axis=0)  # Different mutation strategy\n                    mutant += np.random.uniform(-0.1, 0.1, self.dim)  # Added randomness\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "EnhancedDynamicAdaptivePSO", "description": "Enhanced DynamicAdaptivePSO using adaptive learning rates and diversified mutation strategies for improved convergence.", "configspace": "", "generation": 78, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "639e9f06-d61f-4969-8a55-c0c3d0361833", "metadata": {"aucs": [0.7764172761482304, 0.7791925772543138, 0.8088414785173241, 0.7736817395608215, 0.7335170716919777, 0.8233280632664114, 0.7644540863459688, 0.7503726147687699, 0.808885038241872, 0.10145433440754803, 0.08886492868101392, 0.10779988380833405, 0.012489698104030666, 0.10374344978688754, 0.09472143133958011, 0.03770454147075342, 0.07923929648403538, 0.09743893955390026, 0.0937693616971208, 0.15756190703038775, 0.08512178709331453, 0.10019881650732188, 0.1182852242649155, 0.14143324414187353, 0.0916655867239844, 0.13045925253729507, 0.08479471180540565, 0.0708637449105951, 0.11381742983374565, 0.07942762112021451, 0.10496472241728894, 0.06243939416296762, 0.14350939546816666, 0.11115278672449658, 0.08429688325756357, 0.053452648295375216, 0.940716539968656, 0.9301424862212919, 0.9447263039166043, 0.9279154024101078, 0.931741478936038, 0.9311645176189779, 0.9370566535541718, 0.916613353438103, 0.935952862764997, 0.5498361651436212, 0.5893710474437985, 0.4753730307706171, 0.39256756418766203, 0.5583338388223831, 0.5527707087792406, 0.6093353095758114, 0.3830193674795944, 0.4890357930519651, 0.22775153998171394, 0.23064893712311196, 0.2265946400504405, 0.2151385531686042, 0.392859353076362, 0.2799715252646944, 0.17769498048709342, 0.17319091652713559, 0.3370714248990936, 0.24426855596387764, 0.11277726034119973, 0.1476964760241668, 0.2113218420042493, 0.1320497193495337, 0.10827644598439778, 0.22275553862796216, 0.4070052642978689, 0.21095840903968754, 0.4130694146277546, 0.2072513932505825, 0.21598895225429982, 0.24926099617045883, 0.16334296535944903, 0.13861598300393307, 0.25475989483215267, 0.252042180934684, 0.13419465571159905, 0.048576754668604005, 0.06408249246393538, 0.17949728027191647, 0.056755124068638585, 0.09571434361130982, 0.040162324108560465, 0.003466879770134601, 0.05896738219090725, 0.15973196407318158, 0.2787596717549302, 0.12479577343238868, 0.1851563143013244, 0.1398077359755966, 0.12049704882731127, 0.07426307375222718, 0.10696834036091063, 0.23689042232604784, 0.10280559026869851, 0.15644371283923064, 0.12770771422075977, 0.20112622708829564, 0.10262247621634757, 0.08531241446381477, 0.10364155494520677, 0.1088837048023713, 0.2026714035021886, 0.07402708524750035, 0.1200614439767903, 0.08228256542690282, 0.09916543140583312, 0.09752339355879103, 0.26728285832650844, 0.18587408452010434, 0.12429369121497291, 0.21481195008839216, 0.08613435415652371, 0.5431778514999291, 0.5530873069440211, 0.6150239392448322, 0.5289453178573889, 0.5247566852085477, 0.5839669919733769, 0.5285908996198474, 0.6472113896083879, 0.6223664175871519, 0.07769869015555508, 0.11275622116458384, 0.0733487195743513, 0.11159702017130535, 0.07844043909786846, 0.0969815970941954, 0.10744955439045156, 0.11410703319367732, 0.05463306959087311, 0.17010463970632117, 0.373483847348935, 0.1788229282745598, 0.15094402043160593, 0.2833654393758277, 0.2832058623051086, 0.4071281726841057, 0.17058491309247126, 0.2576200204194934, 0.29615671074820615, 0.3007755380632863, 0.42894898655448455, 0.37546071958019034, 0.2124669004399874, 0.4393102826460452, 0.4245389739547337, 0.33094716374690814, 0.21714392684277617, 0.2035701696149439, 0.32472492058916824, 0.3092937359767537, 0.24735898495040654, 0.2011132532434966, 0.27912712612050083, 0.20045852826308364, 0.24775335497630446, 0.2638727694403509, 0.2325864475947519, 0.25516062474123835, 0.33159852860652683, 0.2535725632367337, 0.2455606784137262, 0.21383427193588822, 0.286648671065718, 0.21679759697041034, 0.23865236590285444, 0.20276627835993266, 0.19713902290755358, 0.16352938768816117, 0.1821433309985141, 0.22322248205657935, 0.1886465638129604, 0.2531130332962719, 0.1844615862185217, 0.19148023723466767, 0.8449966508117753, 0.17649176090782515, 0.18712783910321096, 0.8913008314607084, 0.20092107438539453, 0.8844491266774176, 0.1429540651278809, 0.16248688303411019, 0.8963906833618371, 0.7497490014056183, 0.2140081109477019, 0.07355561670582578, 0.8003438736891941, 0.20958833096535057, 0.1536351008690775, 0.7838724760686904, 0.7767816695930769, 0.7886190180713445, 0.21428290760997137, 0.19830155206983602, 0.21519856561889006, 0.201020102509465, 0.22373837274427122, 0.19968077353946379, 0.21823718232895206, 0.3011306039197078, 0.2052143748016373, 0.12536324019064649, 0.1246747842825976, 0.08399849127312586, 0.09174620889419516, 0.08395837012742158, 0.10144180620851495, 0.14141362560373694, 0.10976017175242869, 0.10305905103024338]}, "mutation_prompt": null}
{"id": "f504b4eb-377b-4913-ab27-016266811fcc", "solution": "import numpy as np\n\nclass EnhancedDynamicAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50  # Retained for suitable exploration balance\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight_initial = 0.9  # Initial inertia weight\n        self.inertia_weight_final = 0.4  # Final inertia weight\n        self.cognitive_weight = 1.5  # Adjusted for progressive balance\n        self.social_weight = 1.8  # Tweaked to enhance social influence\n        self.mutation_scale = 0.2  # Introduced for dynamic mutation scaling\n    \n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: self.inertia_weight_initial - iter * (self.inertia_weight_initial - self.inertia_weight_final) / (self.budget/self.swarm_size)\n        phase_threshold = self.budget // 3\n\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            \n            if evaluations < phase_threshold:\n                velocities *= 0.9  # Early phase: Reduced velocity for exploration\n            elif evaluations >= 2 * phase_threshold:\n                velocities *= 1.1  # Final phase: Increased velocity for hard convergence\n            \n            velocities = np.clip(velocities, -0.7, 0.7)  # Narrowed velocity limits\n            positions += velocities\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 2 <= self.budget:\n                elite_idxs = np.argsort(personal_best_scores)[:5]\n                for i in elite_idxs:\n                    mutant = personal_best_positions[i] + self.mutation_scale * np.random.randn(self.dim)  # Localized mutation\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "EnhancedDynamicAdaptivePSO", "description": "Enhanced DynamicAdaptivePSO with localized adaptive mutation and improved convergence through multi-phase velocity adjustment.", "configspace": "", "generation": 79, "fitness": 0.29103635491967494, "feedback": "The algorithm EnhancedDynamicAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.25.", "error": "", "parent_id": "639e9f06-d61f-4969-8a55-c0c3d0361833", "metadata": {"aucs": [0.8255365451014325, 0.8393661689493802, 0.7962718787353378, 0.8029255908750941, 0.816893411354797, 0.8144307721734786, 0.8296129288313758, 0.8106696976084877, 0.779679945524369, 0.1321514895696535, 0.07421570947954592, 0.11106805012522014, 0.19577484124117084, 0.024773225385118502, 0.182446867259899, 0.012087657631880577, 0.1661403597108858, 0.053175713815289405, 0.08464904296472109, 0.12979187219674437, 0.10418379631855545, 0.12159432132193504, 0.14134421277726217, 0.07857451668656379, 0.09212246705847615, 0.18391496114302974, 0.10081323313719226, 0.09406884628712564, 0.10933946176965414, 0.08660640232040218, 0.10865033723761641, 0.08539961726959178, 0.07682567258410722, 0.1174645174805179, 0.11436507789082662, 0.10867581176051555, 0.9169389471426204, 0.92541549248428, 0.9256760034541365, 0.9313689868478806, 0.9261554383767587, 0.9409024892989085, 0.9184372773463394, 0.9123746832811891, 0.8977073763827935, 0.5897041414669146, 0.6909461092735627, 0.4812261536000709, 0.5353690596808591, 0.45373214082698576, 0.5596826050887089, 0.5766951461590897, 0.4867530655100404, 0.6509131749379833, 0.22905708583453466, 0.22876155118432262, 0.22811875419273797, 0.2799237158029244, 0.28059197425659155, 0.21190388028208906, 0.177317388490707, 0.13046195069227307, 0.1953006648335014, 0.272755212152869, 0.127889286546352, 0.1411585675337852, 0.15965784627946344, 0.15806170174745715, 0.12938698207280286, 0.23666437224263903, 0.20323765586135034, 0.15607834254587272, 0.17843911098084864, 0.17175956558458105, 0.13344382579398384, 0.2676813509541345, 0.2662643733873792, 0.13195810944233455, 0.13424989576953228, 0.19876788449363825, 0.21757784363579702, 0.06361887748951012, 0.2546096157208021, 0.12155690724757373, 0.05481104611042886, 0.122191518569992, 0.12462485356399522, 0.04047463149229824, 0.10033907819231935, 0.10713957474779601, 0.20969602639972795, 0.08879826769830523, 0.1107450636866748, 0.12235176551554561, 0.08194887477072277, 0.11045240399205691, 0.17496972272324018, 0.14619652270185524, 0.10915821320380659, 0.18848323805786515, 0.09667942755032777, 0.13127445765357082, 0.21173038484297046, 0.19469477667023816, 0.12363022278070546, 0.14111047938251353, 0.18962087869874278, 0.14055247151595962, 0.18330807987956432, 0.09047236212299103, 0.10735960530921107, 0.08159921382969004, 0.1669971475816977, 0.0397080912408142, 0.28806680489283865, 0.15686695582190024, 0.08698337295155512, 0.6365924600850138, 0.5385868720655855, 0.4905671563346792, 0.6080485079156319, 0.5374608261167791, 0.5868338749440684, 0.5848415855381106, 0.5746259929539631, 0.5044329684366783, 0.11235444808642692, 0.1505628199799265, 0.07159056037863498, 0.11842895688892441, 0.10922438825914815, 0.10751048387492645, 0.08306836985328969, 0.08841861945144525, 0.08651211490884092, 0.3548959213095524, 0.1827570046153697, 0.3210299406192061, 0.188775661151232, 0.5374617633834693, 0.331949870198483, 0.2563058478385092, 0.36199759751933347, 0.16550885741861954, 0.2059399508453159, 0.21782721116704562, 0.3826037044976788, 0.388688896704951, 0.2750297754076444, 0.34693117279427743, 0.30580935286996813, 0.3892147468875068, 0.22657762432392492, 0.20322362731150567, 0.33442659819853393, 0.20851357609847476, 0.28233728231721866, 0.20217653123708312, 0.29707155682085706, 0.20842991906289543, 0.2781580678904324, 0.275339470485384, 0.2603502344230595, 0.20497086220490568, 0.23978890663200814, 0.2449215222412794, 0.28283559576477135, 0.2386359313645643, 0.2389785138111994, 0.2045569108931391, 0.26502739966193134, 0.16261387151467965, 0.19042605501142618, 0.17606495156591917, 0.23003511637190155, 0.20262440031577578, 0.17766542320128464, 0.19059473756713652, 0.2200096666334056, 0.185654231592693, 0.8891002115415316, 0.17753368057052288, 0.15296836068898334, 0.9113512697508489, 0.20129408993508024, 0.933375717676, 0.14247068227390736, 0.1751399736434902, 0.886893400924852, 0.8376306861025531, 0.15703041419271868, 0.07355442485594488, 0.8464543981409132, 0.1536380091225088, 0.16360671968452045, 0.739668163325643, 0.816205474258347, 0.6855367231612559, 0.23034272298127512, 0.2038972728884897, 0.19234141776525293, 0.20982100317205243, 0.21445828418519275, 0.22098798478027581, 0.24028709160391604, 0.2090807332152942, 0.2346236053848253, 0.06637376160989261, 0.1077940561710824, 0.10766548978729751, 0.0829907767951632, 0.0937643035576855, 0.09758488163759671, 0.0928795926659608, 0.077105310842001, 0.06911196799859576]}, "mutation_prompt": null}
{"id": "27aadf85-368c-4b68-89ce-8a689fee7172", "solution": "import numpy as np\n\nclass EnhancedDynamicAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50  # Retained for suitable exploration balance\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight_initial = 0.9  # Initial inertia weight\n        self.inertia_weight_final = 0.4  # Final inertia weight\n        self.cognitive_weight = 1.5  # Adjusted for progressive balance\n        self.social_weight = 1.8  # Tweaked to enhance social influence\n        self.mutation_scale = 0.2  # Introduced for dynamic mutation scaling\n    \n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: self.inertia_weight_initial - iter * (self.inertia_weight_initial - self.inertia_weight_final) / (self.budget/self.swarm_size)\n        phase_threshold = self.budget // 3\n\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            \n            if evaluations < phase_threshold:\n                velocities *= 0.9  # Early phase: Reduced velocity for exploration\n            elif evaluations >= 2 * phase_threshold:\n                velocities *= 1.1  # Final phase: Increased velocity for hard convergence\n            \n            velocities = np.clip(velocities, -0.7, 0.7)  # Narrowed velocity limits\n            positions += velocities\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 2 <= self.budget:\n                elite_idxs = np.argsort(personal_best_scores)[:5]\n                for i in elite_idxs:\n                    mutant = personal_best_positions[i] + self.mutation_scale * np.random.randn(self.dim)  # Localized mutation\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "EnhancedDynamicAdaptivePSO", "description": "Enhanced DynamicAdaptivePSO with localized adaptive mutation and improved convergence through multi-phase velocity adjustment.", "configspace": "", "generation": 80, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "f504b4eb-377b-4913-ab27-016266811fcc", "metadata": {"aucs": [0.8255365451014325, 0.8393661689493802, 0.7962718787353378, 0.8029255908750941, 0.816893411354797, 0.8144307721734786, 0.8296129288313758, 0.8106696976084877, 0.779679945524369, 0.1321514895696535, 0.07421570947954592, 0.11106805012522014, 0.19577484124117084, 0.024773225385118502, 0.182446867259899, 0.012087657631880577, 0.1661403597108858, 0.053175713815289405, 0.08464904296472109, 0.12979187219674437, 0.10418379631855545, 0.12159432132193504, 0.14134421277726217, 0.07857451668656379, 0.09212246705847615, 0.18391496114302974, 0.10081323313719226, 0.09406884628712564, 0.10933946176965414, 0.08660640232040218, 0.10865033723761641, 0.08539961726959178, 0.07682567258410722, 0.1174645174805179, 0.11436507789082662, 0.10867581176051555, 0.9169389471426204, 0.92541549248428, 0.9256760034541365, 0.9313689868478806, 0.9261554383767587, 0.9409024892989085, 0.9184372773463394, 0.9123746832811891, 0.8977073763827935, 0.5897041414669146, 0.6909461092735627, 0.4812261536000709, 0.5353690596808591, 0.45373214082698576, 0.5596826050887089, 0.5766951461590897, 0.4867530655100404, 0.6509131749379833, 0.22905708583453466, 0.22876155118432262, 0.22811875419273797, 0.2799237158029244, 0.28059197425659155, 0.21190388028208906, 0.177317388490707, 0.13046195069227307, 0.1953006648335014, 0.272755212152869, 0.127889286546352, 0.1411585675337852, 0.15965784627946344, 0.15806170174745715, 0.12938698207280286, 0.23666437224263903, 0.20323765586135034, 0.15607834254587272, 0.17843911098084864, 0.17175956558458105, 0.13344382579398384, 0.2676813509541345, 0.2662643733873792, 0.13195810944233455, 0.13424989576953228, 0.19876788449363825, 0.21757784363579702, 0.06361887748951012, 0.2546096157208021, 0.12155690724757373, 0.05481104611042886, 0.122191518569992, 0.12462485356399522, 0.04047463149229824, 0.10033907819231935, 0.10713957474779601, 0.20969602639972795, 0.08879826769830523, 0.1107450636866748, 0.12235176551554561, 0.08194887477072277, 0.11045240399205691, 0.17496972272324018, 0.14619652270185524, 0.10915821320380659, 0.18848323805786515, 0.09667942755032777, 0.13127445765357082, 0.21173038484297046, 0.19469477667023816, 0.12363022278070546, 0.14111047938251353, 0.18962087869874278, 0.14055247151595962, 0.18330807987956432, 0.09047236212299103, 0.10735960530921107, 0.08159921382969004, 0.1669971475816977, 0.0397080912408142, 0.28806680489283865, 0.15686695582190024, 0.08698337295155512, 0.6365924600850138, 0.5385868720655855, 0.4905671563346792, 0.6080485079156319, 0.5374608261167791, 0.5868338749440684, 0.5848415855381106, 0.5746259929539631, 0.5044329684366783, 0.11235444808642692, 0.1505628199799265, 0.07159056037863498, 0.11842895688892441, 0.10922438825914815, 0.10751048387492645, 0.08306836985328969, 0.08841861945144525, 0.08651211490884092, 0.3548959213095524, 0.1827570046153697, 0.3210299406192061, 0.188775661151232, 0.5374617633834693, 0.331949870198483, 0.2563058478385092, 0.36199759751933347, 0.16550885741861954, 0.2059399508453159, 0.21782721116704562, 0.3826037044976788, 0.388688896704951, 0.2750297754076444, 0.34693117279427743, 0.30580935286996813, 0.3892147468875068, 0.22657762432392492, 0.20322362731150567, 0.33442659819853393, 0.20851357609847476, 0.28233728231721866, 0.20217653123708312, 0.29707155682085706, 0.20842991906289543, 0.2781580678904324, 0.275339470485384, 0.2603502344230595, 0.20497086220490568, 0.23978890663200814, 0.2449215222412794, 0.28283559576477135, 0.2386359313645643, 0.2389785138111994, 0.2045569108931391, 0.26502739966193134, 0.16261387151467965, 0.19042605501142618, 0.17606495156591917, 0.23003511637190155, 0.20262440031577578, 0.17766542320128464, 0.19059473756713652, 0.2200096666334056, 0.185654231592693, 0.8891002115415316, 0.17753368057052288, 0.15296836068898334, 0.9113512697508489, 0.20129408993508024, 0.933375717676, 0.14247068227390736, 0.1751399736434902, 0.886893400924852, 0.8376306861025531, 0.15703041419271868, 0.07355442485594488, 0.8464543981409132, 0.1536380091225088, 0.16360671968452045, 0.739668163325643, 0.816205474258347, 0.6855367231612559, 0.23034272298127512, 0.2038972728884897, 0.19234141776525293, 0.20982100317205243, 0.21445828418519275, 0.22098798478027581, 0.24028709160391604, 0.2090807332152942, 0.2346236053848253, 0.06637376160989261, 0.1077940561710824, 0.10766548978729751, 0.0829907767951632, 0.0937643035576855, 0.09758488163759671, 0.0928795926659608, 0.077105310842001, 0.06911196799859576]}, "mutation_prompt": null}
{"id": "d402523d-a902-4374-9617-6a8797e6d3da", "solution": "import numpy as np\n\nclass EnhancedNeighborhoodAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_weight_initial = 1.5\n        self.social_weight_initial = 1.8\n        self.mutation_scale = 0.2\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: self.inertia_weight_initial - iter * (self.inertia_weight_initial - self.inertia_weight_final) / (self.budget/self.swarm_size)\n        dynamic_cognitive = lambda iter: self.cognitive_weight_initial + iter * (2.0 - self.cognitive_weight_initial) / (self.budget/self.swarm_size)\n        dynamic_social = lambda iter: self.social_weight_initial + iter * (2.5 - self.social_weight_initial) / (self.budget/self.swarm_size)\n        \n        iter_count = 0\n\n        neighbors = lambda idx: np.random.choice(np.delete(np.arange(self.swarm_size), idx), self.neighborhood_size, replace=False)\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            for i in range(self.swarm_size):\n                neighborhood_best = min(neighbors(i), key=lambda n: personal_best_scores[n])\n                neighborhood_best_pos = personal_best_positions[neighborhood_best]\n\n                velocities[i] = (dynamic_inertia(iter_count) * velocities[i] +\n                                 dynamic_cognitive(iter_count) * r1 * (personal_best_positions[i] - positions[i]) +\n                                 dynamic_social(iter_count) * r2 * (neighborhood_best_pos - positions[i]))\n                \n                velocities[i] = np.clip(velocities[i], -0.7, 0.7)\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], self.lb, self.ub)\n            \n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "EnhancedNeighborhoodAdaptivePSO", "description": "Enhanced PSO with dynamic neighborhood topology and adaptive learning rates for improved convergence.", "configspace": "", "generation": 81, "fitness": 0.28440768467179567, "feedback": "The algorithm EnhancedNeighborhoodAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.22.", "error": "", "parent_id": "f504b4eb-377b-4913-ab27-016266811fcc", "metadata": {"aucs": [0.6335138458032554, 0.6238494288855541, 0.5621217870993882, 0.6268525829108917, 0.6001283039223917, 0.5727435588139596, 0.6473730061149761, 0.6268361325544352, 0.5490310864906743, 0.154444495071838, 0.2428042171777297, 0.18532634728396613, 0.19128053161211045, 0.1935711776339719, 0.14586847091888122, 0.14456216084060558, 0.19824961628889415, 0.10393173247038012, 0.08698725267356056, 0.10063856187350684, 0.09166542053254412, 0.09739440119619558, 0.09651237560881132, 0.10719714195007657, 0.0993332270673396, 0.13435074781336476, 0.10053491037652562, 0.10012792626587774, 0.08510272375965922, 0.0968830323076445, 0.09481749447498677, 0.09659599230148774, 0.12458107306124888, 0.10889675057755122, 0.09838438813698502, 0.09645699065774938, 0.8866861422581771, 0.8780097702800134, 0.8767882606043125, 0.895824558494559, 0.8553568646894626, 0.8876210078054181, 0.8828529566901765, 0.8729643544019506, 0.8956024177118597, 0.3587644824610243, 0.35164473764120996, 0.32622539165926356, 0.33608171828802247, 0.3416812181565587, 0.34170185213971715, 0.3317000550148307, 0.3706943002964379, 0.3163845825897845, 0.5961024524238857, 0.6547667412171506, 0.5944428262342343, 0.6034363100846635, 0.6207801586945756, 0.5832701902103621, 0.5695751446826309, 0.6734371047773408, 0.6283787732766991, 0.23221646548768982, 0.12387494477923533, 0.197251100573841, 0.2604979655391839, 0.2559157610273225, 0.19356906125844875, 0.25775450578951276, 0.3265456836165017, 0.24388014013110648, 0.23914819425724698, 0.23202001144263273, 0.23951947796381778, 0.2140486981041566, 0.22588923071621614, 0.20010581962291518, 0.2893809840496059, 0.25578139206602846, 0.22078850565173247, 0.012025650424233203, 0.05430391405763435, 0.011216895825350348, 0.08733017882148653, 0.10246402471095462, 0.054747564807534066, 0.041775090646027135, 0.07473065807094659, 0.10566248730581496, 0.15447541560593725, 0.11113523873815134, 0.18388993069326376, 0.05475366153782868, 0.07699584479867716, 0.04766565145783874, 0.10592373664539667, 0.10872824029484363, 0.09964046170742236, 0.03688130811732049, 0.06267088418483124, 0.022812687646027174, 0.03254619588368346, 0.040590522039000265, 0.031831097691696786, 0.05147168521799228, 0.06458492001005911, 0.04015310675172856, 0.139075154110871, 0.16119251538855806, 0.15121942962650647, 0.1666690985587409, 0.18527097533827885, 0.16357304302521147, 0.19606600504435923, 0.1359557092569912, 0.10743633533405883, 0.5475005657077805, 0.5514798241472241, 0.49949998278703034, 0.526821042204215, 0.5496666034340543, 0.4891969523974382, 0.5396587503946226, 0.5408100633857339, 0.5162698040181285, 0.10262471579812371, 0.09590740144954002, 0.10147917730356404, 0.11716064135485016, 0.09771468746767498, 0.09303483704770676, 0.10646202427593798, 0.11763263152363601, 0.11312708913657621, 0.2596549205992491, 0.3420844567167345, 0.27960474775640076, 0.30586923020804546, 0.2132538740825496, 0.277636614773339, 0.2730651916951139, 0.24254220015838956, 0.28310462776026024, 0.32529211910236777, 0.32756647762487434, 0.33695671091218315, 0.3395856031799773, 0.34229476300690853, 0.33039830588901975, 0.2770445304898377, 0.3413345979356259, 0.26735495958864985, 0.24418080732643765, 0.28542336703987237, 0.26643122511512474, 0.2568325444112963, 0.2756161387470367, 0.27329454298710487, 0.19797471386309484, 0.21948975052226538, 0.19211045066837684, 0.25612713051089375, 0.23694299338496794, 0.2770506898460995, 0.2576820755943966, 0.22632042640368188, 0.23744509155654048, 0.23694542326827084, 0.25313172655782445, 0.2533093121085995, 0.17448513729782422, 0.1804818978063948, 0.17827202539641784, 0.1922799863119552, 0.2918283694098661, 0.1811283745099891, 0.17211872256900773, 0.2022715682707963, 0.1908427542054768, 0.18573128435905473, 0.18652540080507674, 0.1861050684560389, 0.846957598874946, 0.19801480684645345, 0.7608943767308077, 0.494477595221707, 0.15979524995784522, 0.7297040997095032, 0.7853036138237915, 0.7155609967266179, 0.7559572503728098, 0.7775594838618654, 0.2055821128641271, 0.15159494019553843, 0.6416836402745076, 0.4510591230107822, 0.5571263537097026, 0.18183643888416867, 0.1853135235077833, 0.20558825110597734, 0.1936650271278606, 0.18573851339078062, 0.1912157665460359, 0.19187690470543617, 0.1859153176221826, 0.18217963030794837, 0.08966069721704062, 0.08496465188791391, 0.10269143671992131, 0.09336200333301037, 0.08500453465560731, 0.09904838439102337, 0.08307609940992189, 0.094048488271124, 0.09115672645418893]}, "mutation_prompt": null}
{"id": "bfd8f75b-f353-4265-89d2-ee3552e90bab", "solution": "import numpy as np\n\nclass EnhancedDynamicAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50  # Retained for suitable exploration balance\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight_initial = 0.9  # Initial inertia weight\n        self.inertia_weight_final = 0.4  # Final inertia weight\n        self.cognitive_weight = 1.5  # Adjusted for progressive balance\n        self.social_weight = 1.8  # Tweaked to enhance social influence\n        self.mutation_scale = 0.2  # Introduced for dynamic mutation scaling\n    \n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: self.inertia_weight_initial - iter * (self.inertia_weight_initial - self.inertia_weight_final) / (self.budget/self.swarm_size)\n        phase_threshold = self.budget // 3\n\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            \n            if evaluations < phase_threshold:\n                velocities *= 0.9  # Early phase: Reduced velocity for exploration\n            elif evaluations >= 2 * phase_threshold:\n                velocities *= 1.1  # Final phase: Increased velocity for hard convergence\n            \n            velocities = np.clip(velocities, -0.7, 0.7)  # Narrowed velocity limits\n            positions += velocities\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 2 <= self.budget:\n                elite_idxs = np.argsort(personal_best_scores)[:5]\n                for i in elite_idxs:\n                    mutant = personal_best_positions[i] + self.mutation_scale * np.random.randn(self.dim)  # Localized mutation\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "EnhancedDynamicAdaptivePSO", "description": "Enhanced DynamicAdaptivePSO with localized adaptive mutation and improved convergence through multi-phase velocity adjustment.", "configspace": "", "generation": 80, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "f504b4eb-377b-4913-ab27-016266811fcc", "metadata": {"aucs": [0.8255365451014325, 0.8393661689493802, 0.7962718787353378, 0.8029255908750941, 0.816893411354797, 0.8144307721734786, 0.8296129288313758, 0.8106696976084877, 0.779679945524369, 0.1321514895696535, 0.07421570947954592, 0.11106805012522014, 0.19577484124117084, 0.024773225385118502, 0.182446867259899, 0.012087657631880577, 0.1661403597108858, 0.053175713815289405, 0.08464904296472109, 0.12979187219674437, 0.10418379631855545, 0.12159432132193504, 0.14134421277726217, 0.07857451668656379, 0.09212246705847615, 0.18391496114302974, 0.10081323313719226, 0.09406884628712564, 0.10933946176965414, 0.08660640232040218, 0.10865033723761641, 0.08539961726959178, 0.07682567258410722, 0.1174645174805179, 0.11436507789082662, 0.10867581176051555, 0.9169389471426204, 0.92541549248428, 0.9256760034541365, 0.9313689868478806, 0.9261554383767587, 0.9409024892989085, 0.9184372773463394, 0.9123746832811891, 0.8977073763827935, 0.5897041414669146, 0.6909461092735627, 0.4812261536000709, 0.5353690596808591, 0.45373214082698576, 0.5596826050887089, 0.5766951461590897, 0.4867530655100404, 0.6509131749379833, 0.22905708583453466, 0.22876155118432262, 0.22811875419273797, 0.2799237158029244, 0.28059197425659155, 0.21190388028208906, 0.177317388490707, 0.13046195069227307, 0.1953006648335014, 0.272755212152869, 0.127889286546352, 0.1411585675337852, 0.15965784627946344, 0.15806170174745715, 0.12938698207280286, 0.23666437224263903, 0.20323765586135034, 0.15607834254587272, 0.17843911098084864, 0.17175956558458105, 0.13344382579398384, 0.2676813509541345, 0.2662643733873792, 0.13195810944233455, 0.13424989576953228, 0.19876788449363825, 0.21757784363579702, 0.06361887748951012, 0.2546096157208021, 0.12155690724757373, 0.05481104611042886, 0.122191518569992, 0.12462485356399522, 0.04047463149229824, 0.10033907819231935, 0.10713957474779601, 0.20969602639972795, 0.08879826769830523, 0.1107450636866748, 0.12235176551554561, 0.08194887477072277, 0.11045240399205691, 0.17496972272324018, 0.14619652270185524, 0.10915821320380659, 0.18848323805786515, 0.09667942755032777, 0.13127445765357082, 0.21173038484297046, 0.19469477667023816, 0.12363022278070546, 0.14111047938251353, 0.18962087869874278, 0.14055247151595962, 0.18330807987956432, 0.09047236212299103, 0.10735960530921107, 0.08159921382969004, 0.1669971475816977, 0.0397080912408142, 0.28806680489283865, 0.15686695582190024, 0.08698337295155512, 0.6365924600850138, 0.5385868720655855, 0.4905671563346792, 0.6080485079156319, 0.5374608261167791, 0.5868338749440684, 0.5848415855381106, 0.5746259929539631, 0.5044329684366783, 0.11235444808642692, 0.1505628199799265, 0.07159056037863498, 0.11842895688892441, 0.10922438825914815, 0.10751048387492645, 0.08306836985328969, 0.08841861945144525, 0.08651211490884092, 0.3548959213095524, 0.1827570046153697, 0.3210299406192061, 0.188775661151232, 0.5374617633834693, 0.331949870198483, 0.2563058478385092, 0.36199759751933347, 0.16550885741861954, 0.2059399508453159, 0.21782721116704562, 0.3826037044976788, 0.388688896704951, 0.2750297754076444, 0.34693117279427743, 0.30580935286996813, 0.3892147468875068, 0.22657762432392492, 0.20322362731150567, 0.33442659819853393, 0.20851357609847476, 0.28233728231721866, 0.20217653123708312, 0.29707155682085706, 0.20842991906289543, 0.2781580678904324, 0.275339470485384, 0.2603502344230595, 0.20497086220490568, 0.23978890663200814, 0.2449215222412794, 0.28283559576477135, 0.2386359313645643, 0.2389785138111994, 0.2045569108931391, 0.26502739966193134, 0.16261387151467965, 0.19042605501142618, 0.17606495156591917, 0.23003511637190155, 0.20262440031577578, 0.17766542320128464, 0.19059473756713652, 0.2200096666334056, 0.185654231592693, 0.8891002115415316, 0.17753368057052288, 0.15296836068898334, 0.9113512697508489, 0.20129408993508024, 0.933375717676, 0.14247068227390736, 0.1751399736434902, 0.886893400924852, 0.8376306861025531, 0.15703041419271868, 0.07355442485594488, 0.8464543981409132, 0.1536380091225088, 0.16360671968452045, 0.739668163325643, 0.816205474258347, 0.6855367231612559, 0.23034272298127512, 0.2038972728884897, 0.19234141776525293, 0.20982100317205243, 0.21445828418519275, 0.22098798478027581, 0.24028709160391604, 0.2090807332152942, 0.2346236053848253, 0.06637376160989261, 0.1077940561710824, 0.10766548978729751, 0.0829907767951632, 0.0937643035576855, 0.09758488163759671, 0.0928795926659608, 0.077105310842001, 0.06911196799859576]}, "mutation_prompt": null}
{"id": "1e0003a4-b492-434c-ad58-c4165388f26d", "solution": "import numpy as np\n\nclass EnhancedDynamicAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50  # Retained for suitable exploration balance\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight_initial = 0.9  # Initial inertia weight\n        self.inertia_weight_final = 0.4  # Final inertia weight\n        self.cognitive_weight = 1.5  # Adjusted for progressive balance\n        self.social_weight = 1.8  # Tweaked to enhance social influence\n        self.mutation_scale = 0.2  # Introduced for dynamic mutation scaling\n    \n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: self.inertia_weight_initial - iter * (self.inertia_weight_initial - self.inertia_weight_final) / (self.budget/self.swarm_size)\n        phase_threshold = self.budget // 3\n\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            \n            if evaluations < phase_threshold:\n                velocities *= 0.9  # Early phase: Reduced velocity for exploration\n            elif evaluations >= 2 * phase_threshold:\n                velocities *= 1.1  # Final phase: Increased velocity for hard convergence\n            \n            velocities = np.clip(velocities, -0.7, 0.7)  # Narrowed velocity limits\n            positions += velocities\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 2 <= self.budget:\n                elite_idxs = np.argsort(personal_best_scores)[:5]\n                for i in elite_idxs:\n                    mutant = personal_best_positions[i] + self.mutation_scale * np.random.randn(self.dim)  # Localized mutation\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "EnhancedDynamicAdaptivePSO", "description": "Enhanced DynamicAdaptivePSO with localized adaptive mutation and improved convergence through multi-phase velocity adjustment.", "configspace": "", "generation": 80, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "f504b4eb-377b-4913-ab27-016266811fcc", "metadata": {"aucs": [0.8255365451014325, 0.8393661689493802, 0.7962718787353378, 0.8029255908750941, 0.816893411354797, 0.8144307721734786, 0.8296129288313758, 0.8106696976084877, 0.779679945524369, 0.1321514895696535, 0.07421570947954592, 0.11106805012522014, 0.19577484124117084, 0.024773225385118502, 0.182446867259899, 0.012087657631880577, 0.1661403597108858, 0.053175713815289405, 0.08464904296472109, 0.12979187219674437, 0.10418379631855545, 0.12159432132193504, 0.14134421277726217, 0.07857451668656379, 0.09212246705847615, 0.18391496114302974, 0.10081323313719226, 0.09406884628712564, 0.10933946176965414, 0.08660640232040218, 0.10865033723761641, 0.08539961726959178, 0.07682567258410722, 0.1174645174805179, 0.11436507789082662, 0.10867581176051555, 0.9169389471426204, 0.92541549248428, 0.9256760034541365, 0.9313689868478806, 0.9261554383767587, 0.9409024892989085, 0.9184372773463394, 0.9123746832811891, 0.8977073763827935, 0.5897041414669146, 0.6909461092735627, 0.4812261536000709, 0.5353690596808591, 0.45373214082698576, 0.5596826050887089, 0.5766951461590897, 0.4867530655100404, 0.6509131749379833, 0.22905708583453466, 0.22876155118432262, 0.22811875419273797, 0.2799237158029244, 0.28059197425659155, 0.21190388028208906, 0.177317388490707, 0.13046195069227307, 0.1953006648335014, 0.272755212152869, 0.127889286546352, 0.1411585675337852, 0.15965784627946344, 0.15806170174745715, 0.12938698207280286, 0.23666437224263903, 0.20323765586135034, 0.15607834254587272, 0.17843911098084864, 0.17175956558458105, 0.13344382579398384, 0.2676813509541345, 0.2662643733873792, 0.13195810944233455, 0.13424989576953228, 0.19876788449363825, 0.21757784363579702, 0.06361887748951012, 0.2546096157208021, 0.12155690724757373, 0.05481104611042886, 0.122191518569992, 0.12462485356399522, 0.04047463149229824, 0.10033907819231935, 0.10713957474779601, 0.20969602639972795, 0.08879826769830523, 0.1107450636866748, 0.12235176551554561, 0.08194887477072277, 0.11045240399205691, 0.17496972272324018, 0.14619652270185524, 0.10915821320380659, 0.18848323805786515, 0.09667942755032777, 0.13127445765357082, 0.21173038484297046, 0.19469477667023816, 0.12363022278070546, 0.14111047938251353, 0.18962087869874278, 0.14055247151595962, 0.18330807987956432, 0.09047236212299103, 0.10735960530921107, 0.08159921382969004, 0.1669971475816977, 0.0397080912408142, 0.28806680489283865, 0.15686695582190024, 0.08698337295155512, 0.6365924600850138, 0.5385868720655855, 0.4905671563346792, 0.6080485079156319, 0.5374608261167791, 0.5868338749440684, 0.5848415855381106, 0.5746259929539631, 0.5044329684366783, 0.11235444808642692, 0.1505628199799265, 0.07159056037863498, 0.11842895688892441, 0.10922438825914815, 0.10751048387492645, 0.08306836985328969, 0.08841861945144525, 0.08651211490884092, 0.3548959213095524, 0.1827570046153697, 0.3210299406192061, 0.188775661151232, 0.5374617633834693, 0.331949870198483, 0.2563058478385092, 0.36199759751933347, 0.16550885741861954, 0.2059399508453159, 0.21782721116704562, 0.3826037044976788, 0.388688896704951, 0.2750297754076444, 0.34693117279427743, 0.30580935286996813, 0.3892147468875068, 0.22657762432392492, 0.20322362731150567, 0.33442659819853393, 0.20851357609847476, 0.28233728231721866, 0.20217653123708312, 0.29707155682085706, 0.20842991906289543, 0.2781580678904324, 0.275339470485384, 0.2603502344230595, 0.20497086220490568, 0.23978890663200814, 0.2449215222412794, 0.28283559576477135, 0.2386359313645643, 0.2389785138111994, 0.2045569108931391, 0.26502739966193134, 0.16261387151467965, 0.19042605501142618, 0.17606495156591917, 0.23003511637190155, 0.20262440031577578, 0.17766542320128464, 0.19059473756713652, 0.2200096666334056, 0.185654231592693, 0.8891002115415316, 0.17753368057052288, 0.15296836068898334, 0.9113512697508489, 0.20129408993508024, 0.933375717676, 0.14247068227390736, 0.1751399736434902, 0.886893400924852, 0.8376306861025531, 0.15703041419271868, 0.07355442485594488, 0.8464543981409132, 0.1536380091225088, 0.16360671968452045, 0.739668163325643, 0.816205474258347, 0.6855367231612559, 0.23034272298127512, 0.2038972728884897, 0.19234141776525293, 0.20982100317205243, 0.21445828418519275, 0.22098798478027581, 0.24028709160391604, 0.2090807332152942, 0.2346236053848253, 0.06637376160989261, 0.1077940561710824, 0.10766548978729751, 0.0829907767951632, 0.0937643035576855, 0.09758488163759671, 0.0928795926659608, 0.077105310842001, 0.06911196799859576]}, "mutation_prompt": null}
{"id": "094fabb3-bc23-47d3-90e0-fa6be6e73185", "solution": "import numpy as np\n\nclass EnhancedDynamicAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50  # Retained for suitable exploration balance\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight_initial = 0.9  # Initial inertia weight\n        self.inertia_weight_final = 0.4  # Final inertia weight\n        self.cognitive_weight = 1.5  # Adjusted for progressive balance\n        self.social_weight = 1.8  # Tweaked to enhance social influence\n        self.mutation_scale = 0.2  # Introduced for dynamic mutation scaling\n    \n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: self.inertia_weight_initial - iter * (self.inertia_weight_initial - self.inertia_weight_final) / (self.budget/self.swarm_size)\n        phase_threshold = self.budget // 3\n\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            \n            if evaluations < phase_threshold:\n                velocities *= 0.9  # Early phase: Reduced velocity for exploration\n            elif evaluations >= 2 * phase_threshold:\n                velocities *= 1.1  # Final phase: Increased velocity for hard convergence\n            \n            velocities = np.clip(velocities, -0.7, 0.7)  # Narrowed velocity limits\n            positions += velocities\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 2 <= self.budget:\n                elite_idxs = np.argsort(personal_best_scores)[:5]\n                for i in elite_idxs:\n                    mutant = personal_best_positions[i] + self.mutation_scale * np.random.randn(self.dim)  # Localized mutation\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "EnhancedDynamicAdaptivePSO", "description": "Enhanced DynamicAdaptivePSO with localized adaptive mutation and improved convergence through multi-phase velocity adjustment.", "configspace": "", "generation": 80, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "f504b4eb-377b-4913-ab27-016266811fcc", "metadata": {"aucs": [0.8255365451014325, 0.8393661689493802, 0.7962718787353378, 0.8029255908750941, 0.816893411354797, 0.8144307721734786, 0.8296129288313758, 0.8106696976084877, 0.779679945524369, 0.1321514895696535, 0.07421570947954592, 0.11106805012522014, 0.19577484124117084, 0.024773225385118502, 0.182446867259899, 0.012087657631880577, 0.1661403597108858, 0.053175713815289405, 0.08464904296472109, 0.12979187219674437, 0.10418379631855545, 0.12159432132193504, 0.14134421277726217, 0.07857451668656379, 0.09212246705847615, 0.18391496114302974, 0.10081323313719226, 0.09406884628712564, 0.10933946176965414, 0.08660640232040218, 0.10865033723761641, 0.08539961726959178, 0.07682567258410722, 0.1174645174805179, 0.11436507789082662, 0.10867581176051555, 0.9169389471426204, 0.92541549248428, 0.9256760034541365, 0.9313689868478806, 0.9261554383767587, 0.9409024892989085, 0.9184372773463394, 0.9123746832811891, 0.8977073763827935, 0.5897041414669146, 0.6909461092735627, 0.4812261536000709, 0.5353690596808591, 0.45373214082698576, 0.5596826050887089, 0.5766951461590897, 0.4867530655100404, 0.6509131749379833, 0.22905708583453466, 0.22876155118432262, 0.22811875419273797, 0.2799237158029244, 0.28059197425659155, 0.21190388028208906, 0.177317388490707, 0.13046195069227307, 0.1953006648335014, 0.272755212152869, 0.127889286546352, 0.1411585675337852, 0.15965784627946344, 0.15806170174745715, 0.12938698207280286, 0.23666437224263903, 0.20323765586135034, 0.15607834254587272, 0.17843911098084864, 0.17175956558458105, 0.13344382579398384, 0.2676813509541345, 0.2662643733873792, 0.13195810944233455, 0.13424989576953228, 0.19876788449363825, 0.21757784363579702, 0.06361887748951012, 0.2546096157208021, 0.12155690724757373, 0.05481104611042886, 0.122191518569992, 0.12462485356399522, 0.04047463149229824, 0.10033907819231935, 0.10713957474779601, 0.20969602639972795, 0.08879826769830523, 0.1107450636866748, 0.12235176551554561, 0.08194887477072277, 0.11045240399205691, 0.17496972272324018, 0.14619652270185524, 0.10915821320380659, 0.18848323805786515, 0.09667942755032777, 0.13127445765357082, 0.21173038484297046, 0.19469477667023816, 0.12363022278070546, 0.14111047938251353, 0.18962087869874278, 0.14055247151595962, 0.18330807987956432, 0.09047236212299103, 0.10735960530921107, 0.08159921382969004, 0.1669971475816977, 0.0397080912408142, 0.28806680489283865, 0.15686695582190024, 0.08698337295155512, 0.6365924600850138, 0.5385868720655855, 0.4905671563346792, 0.6080485079156319, 0.5374608261167791, 0.5868338749440684, 0.5848415855381106, 0.5746259929539631, 0.5044329684366783, 0.11235444808642692, 0.1505628199799265, 0.07159056037863498, 0.11842895688892441, 0.10922438825914815, 0.10751048387492645, 0.08306836985328969, 0.08841861945144525, 0.08651211490884092, 0.3548959213095524, 0.1827570046153697, 0.3210299406192061, 0.188775661151232, 0.5374617633834693, 0.331949870198483, 0.2563058478385092, 0.36199759751933347, 0.16550885741861954, 0.2059399508453159, 0.21782721116704562, 0.3826037044976788, 0.388688896704951, 0.2750297754076444, 0.34693117279427743, 0.30580935286996813, 0.3892147468875068, 0.22657762432392492, 0.20322362731150567, 0.33442659819853393, 0.20851357609847476, 0.28233728231721866, 0.20217653123708312, 0.29707155682085706, 0.20842991906289543, 0.2781580678904324, 0.275339470485384, 0.2603502344230595, 0.20497086220490568, 0.23978890663200814, 0.2449215222412794, 0.28283559576477135, 0.2386359313645643, 0.2389785138111994, 0.2045569108931391, 0.26502739966193134, 0.16261387151467965, 0.19042605501142618, 0.17606495156591917, 0.23003511637190155, 0.20262440031577578, 0.17766542320128464, 0.19059473756713652, 0.2200096666334056, 0.185654231592693, 0.8891002115415316, 0.17753368057052288, 0.15296836068898334, 0.9113512697508489, 0.20129408993508024, 0.933375717676, 0.14247068227390736, 0.1751399736434902, 0.886893400924852, 0.8376306861025531, 0.15703041419271868, 0.07355442485594488, 0.8464543981409132, 0.1536380091225088, 0.16360671968452045, 0.739668163325643, 0.816205474258347, 0.6855367231612559, 0.23034272298127512, 0.2038972728884897, 0.19234141776525293, 0.20982100317205243, 0.21445828418519275, 0.22098798478027581, 0.24028709160391604, 0.2090807332152942, 0.2346236053848253, 0.06637376160989261, 0.1077940561710824, 0.10766548978729751, 0.0829907767951632, 0.0937643035576855, 0.09758488163759671, 0.0928795926659608, 0.077105310842001, 0.06911196799859576]}, "mutation_prompt": null}
{"id": "db009225-2510-4358-a323-553c7d744a38", "solution": "import numpy as np\n\nclass EnhancedDynamicAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 60  # Increased for enhanced exploration\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight_initial = 0.85  # Slightly adjusted inertia weight\n        self.inertia_weight_final = 0.3  # Reduced final inertia weight for convergence\n        self.cognitive_weight = 2.0  # Increased to enhance personal best influence\n        self.social_weight = 2.5  # Amplified to boost collective convergence\n        self.mutation_scale = 0.3  # Increased for more significant mutation impact\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: self.inertia_weight_initial - iter * (self.inertia_weight_initial - self.inertia_weight_final) / (self.budget/self.swarm_size)\n        phase_threshold = self.budget // 2\n\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions))\n            \n            if evaluations < phase_threshold:\n                velocities *= 0.8  # Early phase: More conservative speed\n            elif evaluations >= 3 * phase_threshold // 2:\n                velocities *= 1.2  # Final phase: Aggressive convergence strategy\n\n            velocities = np.clip(velocities, -1.0, 1.0)  # Broadened velocity limits\n            positions += velocities\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 3 <= self.budget:\n                elite_idxs = np.argsort(personal_best_scores)[:10]\n                for i in elite_idxs:\n                    mutant = personal_best_positions[i] + self.mutation_scale * np.random.randn(self.dim)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "EnhancedDynamicAdaptivePSO", "description": "Enhanced Particle Swarm Optimization with adaptive inertia, elite-driven mutation, and dynamic exploration-convergence balance.", "configspace": "", "generation": 85, "fitness": 0.28947965754540494, "feedback": "The algorithm EnhancedDynamicAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.25.", "error": "", "parent_id": "f504b4eb-377b-4913-ab27-016266811fcc", "metadata": {"aucs": [0.8165326431267635, 0.8046731435261416, 0.8116990709494474, 0.8284700334466335, 0.7886913717180457, 0.8303491851676087, 0.8113598417083759, 0.8083942799053985, 0.8313146524627932, 0.2884611625289364, 0.05212127394426769, 0.2091276932742524, 0.11060067023267062, 0.005245396214849318, 0.08903353372669676, 0.06643852070541212, 9.999999999998899e-05, 0.07595345713906121, 0.14005203812452693, 0.1131119113861303, 0.12824550116977917, 0.11003662529892622, 0.11421244022299237, 0.10384188948623685, 0.1579502766664842, 0.1094153757775519, 0.0942155107270608, 0.09419850420996423, 0.15624517604550925, 0.09889236043132932, 0.1373318832808189, 0.10403737765583643, 0.12124790234427851, 0.10784117879386335, 0.10608089490618045, 0.0877851068919634, 0.9317516637050097, 0.9263928323107741, 0.9193654838357501, 0.9383137930920946, 0.9272982106463906, 0.9065024766085383, 0.9324783106628108, 0.9377546621417988, 0.9230617490595097, 0.387531771047948, 0.3366231193332021, 0.31853087509714684, 0.4555357741641777, 0.41520283157859517, 0.3813437674070743, 0.4832246897923975, 0.46873495182989044, 0.4193229039011439, 0.2313284061646398, 0.32673276425345343, 0.22808132666575576, 0.2777887789121859, 0.8788280913293365, 0.8141672357568008, 0.23242205294875284, 0.17771310960074316, 0.8147025970729076, 0.12104364027856696, 0.02135968968381896, 0.14410912997853942, 0.17500448080496311, 0.1485580485533663, 0.2389192660321896, 0.20525133017615904, 0.12068084634631782, 0.15380873194063083, 0.2478835621137534, 0.12098820600567506, 0.12826287159680738, 0.26333411403644713, 0.13013501231225766, 0.22904581290819093, 0.17711395464940016, 0.16422765735748468, 0.22716636461540418, 0.11573683377968169, 0.036860690585707956, 0.08528230116875513, 0.1165962143515259, 0.02183053733784146, 0.02548504037787791, 0.13247970310821533, 0.029032337286941545, 0.0425148511015524, 0.3033371115733894, 0.12530913194264215, 0.1120636280494629, 0.1330352052767414, 0.091716792990441, 0.11986437381136783, 0.11445522115893492, 0.3256808333255973, 0.13484994207348755, 0.16479429154174763, 0.11974379753240683, 0.14577876854100413, 0.07313658110271004, 0.15921150567188835, 0.19908385897530612, 0.08629170527788377, 0.17012587898905107, 0.22684330369447459, 0.12010216260278306, 0.1505170539981907, 0.23474312496847538, 0.12218746475772169, 0.20416182462629517, 0.061335975344577465, 0.10106905990082105, 0.15754175463842024, 0.08112796720644144, 0.5956991833789738, 0.5116970183905266, 0.5789805119528968, 0.5930959424215503, 0.5560887603126722, 0.49276992400293107, 0.6237660581863064, 0.5363438593077531, 0.5893034624290725, 0.0972148787777658, 0.08754572608681288, 0.11272362566374616, 0.12769255741627716, 0.103660012580577, 0.09562055386385093, 0.0962579218676266, 0.13380876518506635, 0.15413235433033712, 0.2761250918581606, 0.24164761914862176, 0.18652877386894617, 0.337046598037019, 0.33750833684668113, 0.2637403647447535, 0.27459652463318784, 0.20257445001990504, 0.19412165908107115, 0.4550188129057797, 0.29288207151762946, 0.3224715949239835, 0.3079081965294558, 0.41723433288137435, 0.4097521126095621, 0.2680901711974799, 0.3349547781069261, 0.42517318712739005, 0.3236471047373277, 0.30930172732937367, 0.3019607940786615, 0.315609700198889, 0.21305728159884652, 0.37140510512397473, 0.2661864585594693, 0.25536058516667204, 0.2282921486141668, 0.2554172519496971, 0.20298310341935777, 0.20103245085752286, 0.29660838686966395, 0.21177631753912818, 0.21539060087449657, 0.23373127165125607, 0.23189663215848466, 0.28085126667061655, 0.180497664850504, 0.17872370969101248, 0.18797753467628986, 0.2011070636267558, 0.1945290651071715, 0.22538561872130858, 0.18760428874850532, 0.22005416102221875, 0.1812063741501968, 0.18581869814036933, 0.18693551908630002, 0.18644176317317662, 0.8996013435133406, 0.20085640589180997, 0.9061176165197123, 0.14230814122064062, 0.16198144050763763, 0.8984489892217723, 0.8756252515236356, 0.212451857964992, 0.8097766740004645, 0.21077759974344545, 0.1685499199531867, 0.15309551324717685, 0.10465568662063673, 0.5567271473940669, 0.8253645950421756, 0.19365434597299258, 0.20120215822313103, 0.19594649971817224, 0.23175033546782264, 0.1856855357056294, 0.21876986842021628, 0.21623865576120294, 0.23548241447118623, 0.23611458476192415, 0.09451873330780314, 0.08144277115046095, 0.10508261280891806, 0.11430153166608414, 0.08880223505361051, 0.09576853911311922, 0.06969039905927699, 0.10319479209656934, 0.10419473392462608]}, "mutation_prompt": null}
{"id": "14c3a7f5-dfdf-4817-8de3-c73adf8fb7db", "solution": "import numpy as np\n\nclass EnhancedDynamicAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 60  # Increased for diversified exploration\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_weight_initial = 2.0  # Adaptive cognitive component\n        self.cognitive_weight_final = 1.5\n        self.social_weight_initial = 1.5  # Adaptive social component\n        self.social_weight_final = 2.0\n        self.mutation_scale = 0.15  # Adjusted mutation scale for finer search\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: self.inertia_weight_initial - iter * (self.inertia_weight_initial - self.inertia_weight_final) / (self.budget/self.swarm_size)\n        cognitive_weight = lambda iter: self.cognitive_weight_initial - iter * (self.cognitive_weight_initial - self.cognitive_weight_final) / (self.budget/self.swarm_size)\n        social_weight = lambda iter: self.social_weight_initial + iter * (self.social_weight_final - self.social_weight_initial) / (self.budget/self.swarm_size)\n        phase_threshold = self.budget // 4  # Modified phase threshold\n\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          cognitive_weight(iter_count) * r1 * (personal_best_positions - positions) +\n                          social_weight(iter_count) * r2 * (global_best_position - positions))\n            \n            if evaluations < phase_threshold:\n                velocities *= 0.85  # Slightly more exploration initially\n            elif evaluations >= 3 * phase_threshold:\n                velocities *= 1.15  # Aggressive convergence in the final phase\n            \n            velocities = np.clip(velocities, -0.6, 0.6)  # Adjusted velocity limits for stability\n            positions += velocities\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 2 <= self.budget:\n                elite_idxs = np.argsort(personal_best_scores)[:10]  # Increased elite count for broader local search\n                for i in elite_idxs:\n                    mutant = personal_best_positions[i] + self.mutation_scale * np.random.randn(self.dim)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "EnhancedDynamicAdaptivePSO", "description": "Enhanced Dynamic Adaptive PSO with time-varying acceleration coefficients and adaptive learning for improved convergence.", "configspace": "", "generation": 86, "fitness": 0.3001522116556713, "feedback": "The algorithm EnhancedDynamicAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.24.", "error": "", "parent_id": "f504b4eb-377b-4913-ab27-016266811fcc", "metadata": {"aucs": [0.8020471570533934, 0.7949564961683525, 0.8146466866646247, 0.7763275357220406, 0.7929768865490827, 0.7973994338636003, 0.7726775457645403, 0.7540054986511723, 0.8041348587417557, 0.3445172498429281, 0.06048155229427188, 0.20910159701101427, 0.24374567219474685, 0.12421859296891036, 0.1110837885742878, 0.36294992419298244, 0.13911009755718695, 0.16442021067757473, 0.12632852943123474, 0.15424397989275163, 0.1805319027586405, 0.09230166422416874, 0.1136289166400013, 0.09878731116026851, 0.08226435205968319, 0.15566516760771099, 0.10025168141414997, 0.09966408829208995, 0.14529204580707722, 0.14152085477286724, 0.09421641899694655, 0.1093773664466331, 0.09007001082944932, 0.1472665923630051, 0.10375248537575477, 0.07274016431434649, 0.8779702365706996, 0.8763191434603799, 0.8796689986741434, 0.879792894992393, 0.8465373796291675, 0.8751058160304845, 0.8954279560713013, 0.9016455854496092, 0.8690453690929729, 0.4947920315531925, 0.6045024597363504, 0.4113053023020109, 0.49411152989383855, 0.40408666470607235, 0.43301997308136875, 0.3595194095291908, 0.5049667923884684, 0.5528950800296266, 0.3606662711275823, 0.374656276700839, 0.2090250046158123, 0.2788555281937315, 0.21098449712565892, 0.36404785502710435, 0.17783894458075644, 0.17667541476765947, 0.7543341160853944, 0.28932723446341146, 0.18569224421860164, 0.1220994350287794, 0.17486220276212627, 0.643047643176514, 0.08946417801303397, 0.3965780420645303, 0.27758261619314517, 0.165833387648755, 0.38794320367259727, 0.21549769536649865, 0.4961795663689399, 0.3321372963397564, 0.31751808410321647, 0.1305584716025574, 0.2721988587050763, 0.2318788238462084, 0.13193061311316956, 0.1181415627680733, 0.06559516984645763, 0.22266308469453566, 0.10188176476195154, 0.03968225182824203, 0.06734801158862025, 0.11236947167295275, 0.07430734326591137, 0.18048861351943812, 0.2910297724519548, 0.08541484040365344, 0.14025177832401547, 0.07581705274876516, 0.07933436595954935, 0.08704391449047666, 0.14681261032506066, 0.2970205468247684, 0.19673616817888262, 0.2614918118250036, 0.06488537286518259, 0.15396003919859214, 0.1112906295975854, 0.1865542952416429, 0.12423976287443805, 0.15340959417299893, 0.1994673222674792, 0.13506248528781595, 0.14259191587717412, 0.15071660542570475, 0.12556687306745884, 0.11294731777626799, 0.3545400780970409, 0.2190147765629774, 0.11480453237881116, 0.1811276337598705, 0.2526340633288432, 0.6382832406331043, 0.5667499411130505, 0.5177968145835997, 0.5329761003756135, 0.5130421980729689, 0.5519663539411426, 0.6398155335575333, 0.5162154690276677, 0.556113352796578, 0.07106990986097428, 0.06498579025776985, 0.06261951024181711, 0.07753758413743672, 0.09616870713380488, 0.1557862906289731, 0.1526564236496779, 0.18347212901169974, 0.0912977523015468, 0.18156040975409582, 0.26923541695523767, 0.29081157613475417, 0.24466264625788825, 0.32072857481225714, 0.2765570654311569, 0.22424103466653766, 0.2856009012056998, 0.1929644562621431, 0.26867366225620093, 0.35327661995215154, 0.4022244003293255, 0.38132735745847346, 0.31932908190605835, 0.25958829228923774, 0.25886651714228714, 0.27751131739911095, 0.37315919137053166, 0.20687012069575672, 0.30297879850476706, 0.36624056639666225, 0.24957694818580956, 0.1935558522470251, 0.2656512209846481, 0.247846138707014, 0.22686880577624913, 0.21530097024307537, 0.20044053105676063, 0.2469921060449748, 0.22666064078866388, 0.23959170298485477, 0.27774082574743075, 0.22653584493072976, 0.25556101510815254, 0.22778254980723145, 0.225337753317696, 0.19747644154903843, 0.19105332412720655, 0.17820314374832247, 0.19857241010407956, 0.19316329921755293, 0.2081242220418269, 0.1755695653653505, 0.2101501060558678, 0.18756445524364806, 0.1531176301431213, 0.18735540384373994, 0.8845885609053665, 0.9034673804325656, 0.1992286589749903, 0.8894563963379676, 0.1422578927914545, 0.17652389091147447, 0.8907308753120227, 0.8526118157946586, 0.21237014242829122, 0.20601914482520434, 0.20934138928023305, 0.1541354941251447, 0.1504822396921789, 0.6743309804043753, 0.7684828745784709, 0.7998158024278585, 0.18777256654272056, 0.21207759711737084, 0.18526920125729762, 0.20680865359573408, 0.20375546704823955, 0.2242542215195673, 0.19441199545284538, 0.2341985875403444, 0.2348795480789937, 0.08629837720187139, 0.13335657336468443, 0.08491841129995059, 0.10222727818450672, 0.08582213452517551, 0.09932768410690462, 0.08499479359999218, 0.09510916795473934, 0.08172402589627614]}, "mutation_prompt": null}
{"id": "84db7f8b-bd8b-4188-bba6-00a29fde8f5f", "solution": "import numpy as np\n\nclass EnhancedDynamicAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 60  # Increased for diversified exploration\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_weight_initial = 2.0  # Adaptive cognitive component\n        self.cognitive_weight_final = 1.5\n        self.social_weight_initial = 1.5  # Adaptive social component\n        self.social_weight_final = 2.0\n        self.mutation_scale = 0.15  # Adjusted mutation scale for finer search\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: self.inertia_weight_initial - iter * (self.inertia_weight_initial - self.inertia_weight_final) / (self.budget/self.swarm_size)\n        cognitive_weight = lambda iter: self.cognitive_weight_initial - iter * (self.cognitive_weight_initial - self.cognitive_weight_final) / (self.budget/self.swarm_size)\n        social_weight = lambda iter: self.social_weight_initial + iter * (self.social_weight_final - self.social_weight_initial) / (self.budget/self.swarm_size)\n        phase_threshold = self.budget // 4  # Modified phase threshold\n\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          cognitive_weight(iter_count) * r1 * (personal_best_positions - positions) +\n                          social_weight(iter_count) * r2 * (global_best_position - positions))\n            \n            if evaluations < phase_threshold:\n                velocities *= 0.85  # Slightly more exploration initially\n            elif evaluations >= 3 * phase_threshold:\n                velocities *= 1.15  # Aggressive convergence in the final phase\n            \n            velocities = np.clip(velocities, -0.6, 0.6)  # Adjusted velocity limits for stability\n            positions += velocities\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 2 <= self.budget:\n                elite_idxs = np.argsort(personal_best_scores)[:10]  # Increased elite count for broader local search\n                for i in elite_idxs:\n                    mutant = personal_best_positions[i] + self.mutation_scale * np.random.randn(self.dim)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "EnhancedDynamicAdaptivePSO", "description": "Enhanced Dynamic Adaptive PSO with time-varying acceleration coefficients and adaptive learning for improved convergence.", "configspace": "", "generation": 87, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "14c3a7f5-dfdf-4817-8de3-c73adf8fb7db", "metadata": {"aucs": [0.8020471570533934, 0.7949564961683525, 0.8146466866646247, 0.7763275357220406, 0.7929768865490827, 0.7973994338636003, 0.7726775457645403, 0.7540054986511723, 0.8041348587417557, 0.3445172498429281, 0.06048155229427188, 0.20910159701101427, 0.24374567219474685, 0.12421859296891036, 0.1110837885742878, 0.36294992419298244, 0.13911009755718695, 0.16442021067757473, 0.12632852943123474, 0.15424397989275163, 0.1805319027586405, 0.09230166422416874, 0.1136289166400013, 0.09878731116026851, 0.08226435205968319, 0.15566516760771099, 0.10025168141414997, 0.09966408829208995, 0.14529204580707722, 0.14152085477286724, 0.09421641899694655, 0.1093773664466331, 0.09007001082944932, 0.1472665923630051, 0.10375248537575477, 0.07274016431434649, 0.8779702365706996, 0.8763191434603799, 0.8796689986741434, 0.879792894992393, 0.8465373796291675, 0.8751058160304845, 0.8954279560713013, 0.9016455854496092, 0.8690453690929729, 0.4947920315531925, 0.6045024597363504, 0.4113053023020109, 0.49411152989383855, 0.40408666470607235, 0.43301997308136875, 0.3595194095291908, 0.5049667923884684, 0.5528950800296266, 0.3606662711275823, 0.374656276700839, 0.2090250046158123, 0.2788555281937315, 0.21098449712565892, 0.36404785502710435, 0.17783894458075644, 0.17667541476765947, 0.7543341160853944, 0.28932723446341146, 0.18569224421860164, 0.1220994350287794, 0.17486220276212627, 0.643047643176514, 0.08946417801303397, 0.3965780420645303, 0.27758261619314517, 0.165833387648755, 0.38794320367259727, 0.21549769536649865, 0.4961795663689399, 0.3321372963397564, 0.31751808410321647, 0.1305584716025574, 0.2721988587050763, 0.2318788238462084, 0.13193061311316956, 0.1181415627680733, 0.06559516984645763, 0.22266308469453566, 0.10188176476195154, 0.03968225182824203, 0.06734801158862025, 0.11236947167295275, 0.07430734326591137, 0.18048861351943812, 0.2910297724519548, 0.08541484040365344, 0.14025177832401547, 0.07581705274876516, 0.07933436595954935, 0.08704391449047666, 0.14681261032506066, 0.2970205468247684, 0.19673616817888262, 0.2614918118250036, 0.06488537286518259, 0.15396003919859214, 0.1112906295975854, 0.1865542952416429, 0.12423976287443805, 0.15340959417299893, 0.1994673222674792, 0.13506248528781595, 0.14259191587717412, 0.15071660542570475, 0.12556687306745884, 0.11294731777626799, 0.3545400780970409, 0.2190147765629774, 0.11480453237881116, 0.1811276337598705, 0.2526340633288432, 0.6382832406331043, 0.5667499411130505, 0.5177968145835997, 0.5329761003756135, 0.5130421980729689, 0.5519663539411426, 0.6398155335575333, 0.5162154690276677, 0.556113352796578, 0.07106990986097428, 0.06498579025776985, 0.06261951024181711, 0.07753758413743672, 0.09616870713380488, 0.1557862906289731, 0.1526564236496779, 0.18347212901169974, 0.0912977523015468, 0.18156040975409582, 0.26923541695523767, 0.29081157613475417, 0.24466264625788825, 0.32072857481225714, 0.2765570654311569, 0.22424103466653766, 0.2856009012056998, 0.1929644562621431, 0.26867366225620093, 0.35327661995215154, 0.4022244003293255, 0.38132735745847346, 0.31932908190605835, 0.25958829228923774, 0.25886651714228714, 0.27751131739911095, 0.37315919137053166, 0.20687012069575672, 0.30297879850476706, 0.36624056639666225, 0.24957694818580956, 0.1935558522470251, 0.2656512209846481, 0.247846138707014, 0.22686880577624913, 0.21530097024307537, 0.20044053105676063, 0.2469921060449748, 0.22666064078866388, 0.23959170298485477, 0.27774082574743075, 0.22653584493072976, 0.25556101510815254, 0.22778254980723145, 0.225337753317696, 0.19747644154903843, 0.19105332412720655, 0.17820314374832247, 0.19857241010407956, 0.19316329921755293, 0.2081242220418269, 0.1755695653653505, 0.2101501060558678, 0.18756445524364806, 0.1531176301431213, 0.18735540384373994, 0.8845885609053665, 0.9034673804325656, 0.1992286589749903, 0.8894563963379676, 0.1422578927914545, 0.17652389091147447, 0.8907308753120227, 0.8526118157946586, 0.21237014242829122, 0.20601914482520434, 0.20934138928023305, 0.1541354941251447, 0.1504822396921789, 0.6743309804043753, 0.7684828745784709, 0.7998158024278585, 0.18777256654272056, 0.21207759711737084, 0.18526920125729762, 0.20680865359573408, 0.20375546704823955, 0.2242542215195673, 0.19441199545284538, 0.2341985875403444, 0.2348795480789937, 0.08629837720187139, 0.13335657336468443, 0.08491841129995059, 0.10222727818450672, 0.08582213452517551, 0.09932768410690462, 0.08499479359999218, 0.09510916795473934, 0.08172402589627614]}, "mutation_prompt": null}
{"id": "10132ce9-795e-4e51-8f22-113d4da1d5bd", "solution": "import numpy as np\n\nclass AdaptiveClusteringPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50  # Reduced for higher individual influence\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight_initial = 0.7  # Decreased for quicker response\n        self.inertia_weight_final = 0.3\n        self.cognitive_weight_initial = 2.5\n        self.cognitive_weight_final = 1.0  # More emphasis on social learning\n        self.social_weight_initial = 1.0\n        self.social_weight_final = 2.5\n        self.mutation_scale = 0.1  # Reduced mutation for finer tuning\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.2, 0.2, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: self.inertia_weight_initial - iter * (self.inertia_weight_initial - self.inertia_weight_final) / (self.budget/self.swarm_size)\n        cognitive_weight = lambda iter: self.cognitive_weight_initial - iter * (self.cognitive_weight_initial - self.cognitive_weight_final) / (self.budget/self.swarm_size)\n        social_weight = lambda iter: self.social_weight_initial + iter * (self.social_weight_final - self.social_weight_initial) / (self.budget/self.swarm_size)\n        phase_threshold = self.budget // 3  # Adjusted phase length\n\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          cognitive_weight(iter_count) * r1 * (personal_best_positions - positions) +\n                          social_weight(iter_count) * r2 * (global_best_position - positions))\n            \n            if evaluations < phase_threshold:\n                velocities *= 0.9  # Balanced initial exploration\n            elif evaluations >= 2 * phase_threshold:\n                velocities *= 1.1  # Accelerated convergence in final phase\n            \n            velocities = np.clip(velocities, -0.5, 0.5)  # Refined velocity limits\n            positions += velocities\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 2 <= self.budget:\n                elite_idxs = np.argsort(personal_best_scores)[:5]  # Focused elite count for deeper local search\n                for i in elite_idxs:\n                    cluster_center = np.mean(personal_best_positions[elite_idxs], axis=0)\n                    mutant = cluster_center + self.mutation_scale * np.random.randn(self.dim)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "AdaptiveClusteringPSO", "description": "Adaptive Particle Swarm Optimization with dynamic clustering and elite particle perturbation to enhance convergence speed.", "configspace": "", "generation": 88, "fitness": 0.2558703775655699, "feedback": "The algorithm AdaptiveClusteringPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.22.", "error": "", "parent_id": "14c3a7f5-dfdf-4817-8de3-c73adf8fb7db", "metadata": {"aucs": [0.880896884337769, 0.8636444551279483, 0.895601550875599, 0.8603306323282389, 0.8518294440792388, 0.865875727551872, 0.8593875054164556, 0.8516213333368796, 0.8162082993840998, 0.19434615246752618, 0.1269281812084604, 0.06209062646233665, 0.10317313606138812, 0.14077021029839143, 0.017145767570179826, 0.05365580384317803, 0.09354640814602622, 0.020869436916354234, 0.09557015307470429, 0.1616798426771593, 0.08186140613706216, 0.1252154335289133, 0.11628828594419138, 0.11791166713800705, 0.10783656068159231, 0.14283933188388231, 0.1232741551333455, 0.09186716092491809, 0.0702660192427802, 0.07173598736445963, 0.08178043408636637, 0.11684753300722384, 0.05331698441882449, 0.10395464877192317, 0.09660070924482478, 0.06258452328269759, 0.8760409771384899, 0.8150244089625032, 0.8254899045357758, 0.8354329118333683, 0.7646761282453683, 0.753470323855556, 0.7981457845624134, 0.7380653991787902, 0.6113958423699188, 0.37155795174094974, 0.3868530157225243, 0.29165241814158616, 0.4381251068233911, 0.45652138297725897, 0.30466136973526003, 0.3649846060167077, 0.3211849752212401, 0.38706329432301956, 0.2289871197123331, 0.2446882980662498, 0.1707598462087241, 0.213345375799586, 0.19556695550448755, 0.27244224712603926, 0.15000679070012557, 0.15117132719885717, 0.17658840131683828, 0.1899274662460131, 0.25606303035875855, 0.10016378743237586, 0.5001381112606083, 0.1868750879555947, 0.14704504576470678, 0.17377156600775912, 0.1562940019913983, 0.12009233905844885, 0.17873845757109863, 0.16671815456258232, 0.13311870712266083, 0.44157111254215986, 0.20741066951128873, 0.1401710941329748, 0.12897653180265856, 0.15909078082554895, 0.13072044553747308, 0.0012576509895146915, 0.07210713731635865, 0.050172582866827575, 0.03119501343217912, 0.06848501272876584, 0.024055044674374804, 0.10274328498723684, 0.0383659088152466, 0.061483621367826036, 0.19149979687967056, 0.14488294887476383, 0.25078948614374097, 0.09931826446573633, 0.04188960681024123, 0.10447377888769804, 0.11938728567221679, 0.15776316349914465, 0.1347640687838979, 0.28318558131611804, 0.12482320308232409, 0.30737666338669656, 0.10502487948358286, 0.18626309026120025, 0.38486463534631443, 0.21388500424570678, 0.2750704636630339, 0.10823581666126414, 0.1296327777057531, 0.22346880299266536, 0.15813059604311785, 0.043280093379296836, 0.15135577151338453, 0.1225306256562051, 0.1132953439883817, 0.24002777757065186, 0.08326711437327317, 0.576674711174072, 0.5914467606569296, 0.5759986692699319, 0.5442591673692003, 0.5297654563932181, 0.4618559288298204, 0.46925714268110075, 0.5158153604036539, 0.47400099349590097, 0.0509206872411041, 0.041602770724798566, 0.058349477806037386, 0.09250290590968413, 0.09717019663095938, 0.10189370746627846, 0.12117393871772819, 0.09858750666289706, 0.08509127092668756, 0.33994432971670463, 0.13240938223730903, 0.17771738565414108, 0.18648672488440943, 0.21522380731250157, 0.1593293260149501, 0.18760867399514758, 0.1990135076011138, 0.21048130869718573, 0.25313131599344385, 0.20175393787355378, 0.22586704156052106, 0.3367920832266803, 0.25544510521849295, 0.47497742968835444, 0.24782877827054595, 0.2334827485610489, 0.1850269665837806, 0.14525194974846922, 0.21957763909663874, 0.2575335855155817, 0.2943688759100549, 0.1897775907663536, 0.27863882605536905, 0.1368927146037806, 0.2500858865017017, 0.18485313621720045, 0.22271500149193457, 0.2592717967184006, 0.22995135336484573, 0.25798678914315554, 0.20107118072035957, 0.3380801601199406, 0.2972825875010485, 0.27633747755661964, 0.2743022101187891, 0.19236227044530985, 0.18172247250426843, 0.1796568010711449, 0.17594725307857118, 0.18611612707773018, 0.19026061810830797, 0.1703015195736176, 0.25258244088249193, 0.17923418755679466, 0.12601654658742933, 0.1765577326310196, 0.1823308675289269, 0.9293236265085023, 0.20056588751066462, 0.19804733249324435, 0.14235118134875813, 0.15838761342831986, 0.9021893966715304, 0.913780278221175, 0.1560452001193151, 0.07353553631721987, 0.527167390237705, 0.1529775183323111, 0.15221654225977288, 0.3829810244729742, 0.10405605579837773, 0.3366300652200225, 0.19372929670184635, 0.20672906999377727, 0.18322097089037104, 0.18293717741854254, 0.24848237552039576, 0.21988404215258261, 0.19610413306817875, 0.2023361633401468, 0.22102712646535316, 0.10884724147435532, 0.100795324906642, 0.09722290231404118, 0.09387051096004839, 0.10633711997560225, 0.1015450266665604, 0.0813282782901752, 0.09890395361555149, 0.0899992453025954]}, "mutation_prompt": null}
{"id": "7f866cbf-25f7-4ae3-9cd9-eefc20497f2b", "solution": "import numpy as np\n\nclass ImprovedAdaptiveHybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 70  # Increased swarm size for a better search space sampling\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight_initial = 0.8\n        self.inertia_weight_final = 0.3\n        self.cognitive_weight_initial = 2.2  # Enhanced cognitive component for balance\n        self.cognitive_weight_final = 1.3\n        self.social_weight_initial = 1.3\n        self.social_weight_final = 2.3\n        self.mutation_scale = 0.25  # Larger mutation scale for diverse local search\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.4, 0.4, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: self.inertia_weight_initial - iter * (self.inertia_weight_initial - self.inertia_weight_final) / (self.budget/self.swarm_size)\n        cognitive_weight = lambda iter: self.cognitive_weight_initial - iter * (self.cognitive_weight_initial - self.cognitive_weight_final) / (self.budget/self.swarm_size)\n        social_weight = lambda iter: self.social_weight_initial + iter * (self.social_weight_final - self.social_weight_initial) / (self.budget/self.swarm_size)\n\n        phase_threshold = self.budget // 3  # Adjusted phase threshold for better adaptation\n\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          cognitive_weight(iter_count) * r1 * (personal_best_positions - positions) +\n                          social_weight(iter_count) * r2 * (global_best_position - positions))\n            \n            if evaluations < phase_threshold:\n                velocities *= 0.75  # More exploration in initial stage\n            elif evaluations >= 2 * phase_threshold:\n                velocities *= 1.25  # Stronger convergence in final stage\n            \n            velocities = np.clip(velocities, -0.5, 0.5)  # Tighter velocity limits for improved control\n            positions += velocities\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size <= self.budget:\n                elite_idxs = np.argsort(personal_best_scores)[:15]  # Broader elite sample for local enhancement\n                for i in elite_idxs:\n                    mutant1 = personal_best_positions[i] + self.mutation_scale * np.random.randn(self.dim)\n                    mutant2 = global_best_position + self.mutation_scale * np.random.randn(self.dim)  # Additional mutation strategy\n                    mutant1 = np.clip(mutant1, self.lb, self.ub)\n                    mutant2 = np.clip(mutant2, self.lb, self.ub)\n                    mutant_score1 = func(mutant1)\n                    mutant_score2 = func(mutant2)\n                    evaluations += 2\n\n                    if mutant_score1 < personal_best_scores[i] or mutant_score2 < personal_best_scores[i]:\n                        if mutant_score1 < mutant_score2:\n                            personal_best_positions[i] = mutant1\n                            personal_best_scores[i] = mutant_score1\n                        else:\n                            personal_best_positions[i] = mutant2\n                            personal_best_scores[i] = mutant_score2\n\n                        if min(mutant_score1, mutant_score2) < global_best_score:\n                            global_best_position = mutant1 if mutant_score1 < mutant_score2 else mutant2\n                            global_best_score = min(mutant_score1, mutant_score2)\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "ImprovedAdaptiveHybridPSO", "description": "Improved Adaptive Hybrid PSO with dynamic learning rates and ensemble mutation for accelerated convergence.", "configspace": "", "generation": 89, "fitness": 0.2862103214623121, "feedback": "The algorithm ImprovedAdaptiveHybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.24.", "error": "", "parent_id": "14c3a7f5-dfdf-4817-8de3-c73adf8fb7db", "metadata": {"aucs": [0.8338229636903024, 0.8087969354012948, 0.8430744182957276, 0.791924044272446, 0.8044898984860962, 0.8050280482389762, 0.8273916359747702, 0.8017029159025502, 0.8179747542441185, 0.36460601517117996, 0.06329444635543291, 0.18664603206172092, 0.10062604417409615, 0.10477008959524015, 0.09491770793330889, 0.16782198520566094, 0.058773527891346156, 0.0922529744241154, 0.14524054744735804, 0.11466266920332269, 0.08991870847760275, 0.09963527012886808, 0.12718479523808035, 0.11837988536801036, 0.10887900948778118, 0.16778439361695385, 0.12745086028549957, 0.11042776143519406, 0.12753457337631757, 0.09356735483315293, 0.0838090780408749, 0.0766427772452144, 0.07414801376897462, 0.12862741390554877, 0.11944384633224858, 0.09017007149821088, 0.8959783515516133, 0.9466725066079067, 0.8654840669659218, 0.7878479829770009, 0.8150151670480732, 0.7998823399671556, 0.9237726413217788, 0.9099976032855956, 0.901590077679176, 0.5326446693098854, 0.5897179040319254, 0.39262881776187586, 0.63335701805291, 0.5391077130692359, 0.6449259112174724, 0.5591020284215247, 0.576422595898598, 0.5230297389804559, 0.3840497254922772, 0.357594709994536, 0.223041614855096, 0.4782186717871474, 0.21608998347164077, 0.19225782397094082, 0.16921110710538856, 0.2378822639840804, 0.31030195540746086, 0.11255871823023733, 0.1326832575795801, 0.1094536099623058, 0.17064653277855635, 0.19218930765813502, 0.15716290301440783, 0.17104732737162154, 0.1207272705504554, 0.14796605176106348, 0.19598945578613036, 0.12951546443876472, 0.12546400734036633, 0.22589115810646976, 0.22464668451271996, 0.14009702298654958, 0.23742651350150867, 0.1667668877087315, 0.12830895561568778, 0.09659701733202053, 0.04237937785529411, 0.005125135176530238, 0.059768013642409246, 0.050714868893832143, 0.01124762471380003, 0.026429948616621513, 9.999999999998899e-05, 9.999999999998899e-05, 0.23839498364473988, 0.10148847071830935, 0.1977680875092993, 0.11860324056242277, 0.09058127659573889, 0.1128020565487744, 0.15839150401976876, 0.16650063183062758, 0.16886073266759904, 0.2242061992303941, 0.05371737714575542, 0.12804783463667313, 0.11819648915837355, 0.11441747229118049, 0.2743843527578528, 0.21296935439450204, 0.11176967731690624, 0.1609247370791962, 0.1595225524232743, 0.05443957601762994, 0.0655427919996362, 0.09737916067409336, 0.08434184405278156, 0.3153036387561621, 0.11190916572417098, 0.25425490787394645, 0.08283111741456273, 0.6114487999612688, 0.6297783211888976, 0.5326176004331797, 0.5220280074462555, 0.5384857135323006, 0.6033157250045429, 0.6318753195633244, 0.5208224073289118, 0.5598656900716408, 0.1124011693125222, 0.08591765684634378, 0.06890001200218243, 0.07653733649316186, 0.09167531746557034, 0.14637082170093074, 0.1058080322859789, 0.10810166625664386, 0.09359227109241341, 0.32388395405749015, 0.32369490974654935, 0.2594720360887691, 0.20201040350400634, 0.26804125073715457, 0.34219704891055824, 0.19932674875415934, 0.44306835838760916, 0.20351290470000538, 0.26980958645688, 0.29284274582919045, 0.42565224722491846, 0.35493284053579177, 0.2771026804227077, 0.41480432488521124, 0.28742358008284996, 0.3459603592632663, 0.2642123625845042, 0.19674005528187188, 0.16396362509053597, 0.31684954599127935, 0.1989491916551116, 0.20243077693714773, 0.36766500962332616, 0.22573402561550393, 0.2976741688371213, 0.18840218658559083, 0.2805936255660775, 0.25827841889807845, 0.21146487423965143, 0.21318055032137018, 0.22299089096630975, 0.22040447446460065, 0.2507603326666241, 0.21145602889865767, 0.21148386881471715, 0.6868806688150029, 0.17818015977387458, 0.19571593621818895, 0.2457893513867696, 0.21552984804884268, 0.17854243184290974, 0.2065648449315607, 0.21503390749149254, 0.2457661241066864, 0.1855097959436548, 0.18810378781578552, 0.9066198352293634, 0.8971235213402579, 0.20108443279601518, 0.20065381820688133, 0.14241478281939213, 0.17701546869937268, 0.21020968185346955, 0.8058465664430093, 0.7658524267025759, 0.6092179481259026, 0.21032798281835263, 0.1555493754351679, 0.8136095697746932, 0.16749881049302529, 0.515055216101425, 0.7164226647670923, 0.2086838741407131, 0.20324521447466937, 0.1801284350450485, 0.24349083808870498, 0.19741824893434168, 0.1958886848865884, 0.206310106609772, 0.23273107816074168, 0.20528858482979628, 0.08710914194545383, 0.07326376334699702, 0.08476662381814093, 0.10860161988545824, 0.09914240174743227, 0.08030070195601235, 0.07238183728078673, 0.10641863491934278, 0.08783002179493937]}, "mutation_prompt": null}
{"id": "865aa29a-3eda-4302-aa1a-be6eab79c401", "solution": "import numpy as np\n\nclass EnhancedDynamicAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 60  # Increased for diversified exploration\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_weight_initial = 2.0  # Adaptive cognitive component\n        self.cognitive_weight_final = 1.5\n        self.social_weight_initial = 1.5  # Adaptive social component\n        self.social_weight_final = 2.0\n        self.mutation_scale = 0.15  # Adjusted mutation scale for finer search\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: self.inertia_weight_initial - iter * (self.inertia_weight_initial - self.inertia_weight_final) / (self.budget/self.swarm_size)\n        cognitive_weight = lambda iter: self.cognitive_weight_initial - iter * (self.cognitive_weight_initial - self.cognitive_weight_final) / (self.budget/self.swarm_size)\n        social_weight = lambda iter: self.social_weight_initial + iter * (self.social_weight_final - self.social_weight_initial) / (self.budget/self.swarm_size)\n        phase_threshold = self.budget // 4  # Modified phase threshold\n\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          cognitive_weight(iter_count) * r1 * (personal_best_positions - positions) +\n                          social_weight(iter_count) * r2 * (global_best_position - positions))\n            \n            if evaluations < phase_threshold:\n                velocities *= 0.85  # Slightly more exploration initially\n            elif evaluations >= 3 * phase_threshold:\n                velocities *= 1.15  # Aggressive convergence in the final phase\n            \n            velocities = np.clip(velocities, -0.6, 0.6)  # Adjusted velocity limits for stability\n            positions += velocities\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            if evaluations + self.swarm_size * 2 <= self.budget:\n                elite_idxs = np.argsort(personal_best_scores)[:10]  # Increased elite count for broader local search\n                for i in elite_idxs:\n                    mutant = personal_best_positions[i] + self.mutation_scale * np.random.randn(self.dim)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    mutant_score = func(mutant)\n                    evaluations += 1\n\n                    if mutant_score < personal_best_scores[i]:\n                        personal_best_positions[i] = mutant\n                        personal_best_scores[i] = mutant_score\n\n                        if mutant_score < global_best_score:\n                            global_best_position = mutant\n                            global_best_score = mutant_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "EnhancedDynamicAdaptivePSO", "description": "Enhanced Dynamic Adaptive PSO with time-varying acceleration coefficients and adaptive learning for improved convergence.", "configspace": "", "generation": 87, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "14c3a7f5-dfdf-4817-8de3-c73adf8fb7db", "metadata": {"aucs": [0.8020471570533934, 0.7949564961683525, 0.8146466866646247, 0.7763275357220406, 0.7929768865490827, 0.7973994338636003, 0.7726775457645403, 0.7540054986511723, 0.8041348587417557, 0.3445172498429281, 0.06048155229427188, 0.20910159701101427, 0.24374567219474685, 0.12421859296891036, 0.1110837885742878, 0.36294992419298244, 0.13911009755718695, 0.16442021067757473, 0.12632852943123474, 0.15424397989275163, 0.1805319027586405, 0.09230166422416874, 0.1136289166400013, 0.09878731116026851, 0.08226435205968319, 0.15566516760771099, 0.10025168141414997, 0.09966408829208995, 0.14529204580707722, 0.14152085477286724, 0.09421641899694655, 0.1093773664466331, 0.09007001082944932, 0.1472665923630051, 0.10375248537575477, 0.07274016431434649, 0.8779702365706996, 0.8763191434603799, 0.8796689986741434, 0.879792894992393, 0.8465373796291675, 0.8751058160304845, 0.8954279560713013, 0.9016455854496092, 0.8690453690929729, 0.4947920315531925, 0.6045024597363504, 0.4113053023020109, 0.49411152989383855, 0.40408666470607235, 0.43301997308136875, 0.3595194095291908, 0.5049667923884684, 0.5528950800296266, 0.3606662711275823, 0.374656276700839, 0.2090250046158123, 0.2788555281937315, 0.21098449712565892, 0.36404785502710435, 0.17783894458075644, 0.17667541476765947, 0.7543341160853944, 0.28932723446341146, 0.18569224421860164, 0.1220994350287794, 0.17486220276212627, 0.643047643176514, 0.08946417801303397, 0.3965780420645303, 0.27758261619314517, 0.165833387648755, 0.38794320367259727, 0.21549769536649865, 0.4961795663689399, 0.3321372963397564, 0.31751808410321647, 0.1305584716025574, 0.2721988587050763, 0.2318788238462084, 0.13193061311316956, 0.1181415627680733, 0.06559516984645763, 0.22266308469453566, 0.10188176476195154, 0.03968225182824203, 0.06734801158862025, 0.11236947167295275, 0.07430734326591137, 0.18048861351943812, 0.2910297724519548, 0.08541484040365344, 0.14025177832401547, 0.07581705274876516, 0.07933436595954935, 0.08704391449047666, 0.14681261032506066, 0.2970205468247684, 0.19673616817888262, 0.2614918118250036, 0.06488537286518259, 0.15396003919859214, 0.1112906295975854, 0.1865542952416429, 0.12423976287443805, 0.15340959417299893, 0.1994673222674792, 0.13506248528781595, 0.14259191587717412, 0.15071660542570475, 0.12556687306745884, 0.11294731777626799, 0.3545400780970409, 0.2190147765629774, 0.11480453237881116, 0.1811276337598705, 0.2526340633288432, 0.6382832406331043, 0.5667499411130505, 0.5177968145835997, 0.5329761003756135, 0.5130421980729689, 0.5519663539411426, 0.6398155335575333, 0.5162154690276677, 0.556113352796578, 0.07106990986097428, 0.06498579025776985, 0.06261951024181711, 0.07753758413743672, 0.09616870713380488, 0.1557862906289731, 0.1526564236496779, 0.18347212901169974, 0.0912977523015468, 0.18156040975409582, 0.26923541695523767, 0.29081157613475417, 0.24466264625788825, 0.32072857481225714, 0.2765570654311569, 0.22424103466653766, 0.2856009012056998, 0.1929644562621431, 0.26867366225620093, 0.35327661995215154, 0.4022244003293255, 0.38132735745847346, 0.31932908190605835, 0.25958829228923774, 0.25886651714228714, 0.27751131739911095, 0.37315919137053166, 0.20687012069575672, 0.30297879850476706, 0.36624056639666225, 0.24957694818580956, 0.1935558522470251, 0.2656512209846481, 0.247846138707014, 0.22686880577624913, 0.21530097024307537, 0.20044053105676063, 0.2469921060449748, 0.22666064078866388, 0.23959170298485477, 0.27774082574743075, 0.22653584493072976, 0.25556101510815254, 0.22778254980723145, 0.225337753317696, 0.19747644154903843, 0.19105332412720655, 0.17820314374832247, 0.19857241010407956, 0.19316329921755293, 0.2081242220418269, 0.1755695653653505, 0.2101501060558678, 0.18756445524364806, 0.1531176301431213, 0.18735540384373994, 0.8845885609053665, 0.9034673804325656, 0.1992286589749903, 0.8894563963379676, 0.1422578927914545, 0.17652389091147447, 0.8907308753120227, 0.8526118157946586, 0.21237014242829122, 0.20601914482520434, 0.20934138928023305, 0.1541354941251447, 0.1504822396921789, 0.6743309804043753, 0.7684828745784709, 0.7998158024278585, 0.18777256654272056, 0.21207759711737084, 0.18526920125729762, 0.20680865359573408, 0.20375546704823955, 0.2242542215195673, 0.19441199545284538, 0.2341985875403444, 0.2348795480789937, 0.08629837720187139, 0.13335657336468443, 0.08491841129995059, 0.10222727818450672, 0.08582213452517551, 0.09932768410690462, 0.08499479359999218, 0.09510916795473934, 0.08172402589627614]}, "mutation_prompt": null}
{"id": "beaa09cb-3205-4a17-9276-3d3a6dc87f23", "solution": "import numpy as np\n\nclass HybridDynamicAdaptivePSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50  # Reduced for quicker convergence\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight_initial = 0.8\n        self.inertia_weight_final = 0.3\n        self.cognitive_weight_initial = 1.4  # Further adaptive cognitive component\n        self.cognitive_weight_final = 1.2\n        self.social_weight_initial = 1.2  # Further adaptive social component\n        self.social_weight_final = 1.8\n        self.mutation_scale = 0.25  # Adjusted for more impactful mutations\n        self.F = 0.5  # Differential evolution scaling factor\n        self.CR = 0.9  # Differential evolution crossover rate\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: self.inertia_weight_initial - iter * (self.inertia_weight_initial - self.inertia_weight_final) / (self.budget/self.swarm_size)\n        cognitive_weight = lambda iter: self.cognitive_weight_initial - iter * (self.cognitive_weight_initial - self.cognitive_weight_final) / (self.budget/self.swarm_size)\n        social_weight = lambda iter: self.social_weight_initial + iter * (self.social_weight_final - self.social_weight_initial) / (self.budget/self.swarm_size)\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          cognitive_weight(iter_count) * r1 * (personal_best_positions - positions) +\n                          social_weight(iter_count) * r2 * (global_best_position - positions))\n            \n            velocities = np.clip(velocities, -0.7, 0.7)  # Adjusted velocity limits\n            positions += velocities\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Differential Evolution-like perturbation for additional diversity\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + self.F * (b - c)\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, personal_best_positions[i])\n                trial = np.clip(trial, self.lb, self.ub)\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "HybridDynamicAdaptivePSO_DE", "description": "Hybrid Dynamic Adaptive PSO and Differential Evolution with adaptive parameters for enhanced convergence speed.", "configspace": "", "generation": 91, "fitness": 0.3898169877539633, "feedback": "The algorithm HybridDynamicAdaptivePSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.24.", "error": "", "parent_id": "14c3a7f5-dfdf-4817-8de3-c73adf8fb7db", "metadata": {"aucs": [0.7837262178630025, 0.749798005597236, 0.7485883600952447, 0.7617920885451106, 0.733767277059648, 0.7377503740118627, 0.7544077696711233, 0.7330888121625447, 0.7278012347167753, 0.46430842870511446, 0.4571582069187564, 0.45824436511557287, 0.4532777216588352, 0.462967805539111, 0.44787193959870286, 0.4726873465875848, 0.4830056717783401, 0.4483114547442477, 0.1296388589274473, 0.16606368338442712, 0.14958184810063335, 0.1397644568372316, 0.3399590122639, 0.2622129866792984, 0.14289168295562593, 0.1508787212991476, 0.12680405319722154, 0.10403283325082702, 0.13730740755451876, 0.13536075619796628, 0.10470444714448424, 0.13232021430225482, 0.10626662904174677, 0.1405444440313064, 0.13207686996079915, 0.1178937740734094, 0.8925376095932811, 0.8971479210061601, 0.8713436429852564, 0.8767679293917203, 0.8726680341730557, 0.8862575926119921, 0.8950992120278612, 0.8938632210325463, 0.9037125432401389, 0.5652534592178536, 0.5049134323583517, 0.49604358824455486, 0.5362441769898474, 0.47510843614836396, 0.512385820895267, 0.5672886907392664, 0.5193194122396761, 0.49457668125991894, 0.8035403079076591, 0.7942572348571526, 0.7939726448971027, 0.8223458099403136, 0.7750456394867403, 0.7566994839490807, 0.7967021526881286, 0.7743404641085396, 0.7614798913922664, 0.5464257714598165, 0.46567618630052676, 0.12364395618018387, 0.4551442813160097, 0.3391298026438432, 0.5025986834796622, 0.4116390715550944, 0.4760814844735304, 0.36319234400601175, 0.45444097572683384, 0.46128786459433035, 0.12802567469000192, 0.3685503864369676, 0.4274201285227146, 0.42352059844785694, 0.41075015827290906, 0.5065313524231518, 0.32264033975030193, 0.3682760346248011, 0.320674822190529, 0.24396344560219363, 0.24634337879666934, 0.3295429733295412, 0.24165637055798717, 0.30533350792588476, 0.23877701119455974, 0.23432012455422846, 0.36793981123390385, 0.33626797836939226, 0.45595298980310084, 0.3232208767199948, 0.3618184103829035, 0.38158991584788005, 0.3693184768269553, 0.3475474758385283, 0.4363640777241773, 0.17748313982266195, 0.09727911277667589, 0.06413155804515458, 0.24348582341092395, 0.16182518882536456, 0.1753414529527123, 0.09654156151925108, 0.09198796753434002, 0.18473700363928436, 0.28611104005642585, 0.25370784328563767, 0.26728627881270517, 0.30145882923175027, 0.26023961514935146, 0.3024074990959037, 0.296513620997334, 0.27528258102531067, 0.2680029340636121, 0.6823828004856765, 0.6442566330834767, 0.6213929647250317, 0.6450512040899992, 0.6253075271401186, 0.6308583885365171, 0.6782203012342422, 0.6061021517974446, 0.6440695272232271, 0.12992120733080703, 0.1343814927362027, 0.12311111767596539, 0.11191942722537951, 0.1233696292267823, 0.14450928485213643, 0.10778981517521402, 0.13015039742603152, 0.10703382750046764, 0.1905114982095697, 0.43581403489553217, 0.3485901263231421, 0.42060352325747075, 0.2478190091610316, 0.18708036888972324, 0.21841385491549925, 0.17750427608187602, 0.22802832896169, 0.45387639740584196, 0.43818898284860086, 0.4294634616619687, 0.4415431761075195, 0.44332121893911924, 0.4346297259075841, 0.44962716493661803, 0.424490101652659, 0.4222227678773046, 0.301018790856456, 0.3416742777412105, 0.3704194066169221, 0.4146551260179868, 0.3585643381536765, 0.3219835606783208, 0.2588295673794462, 0.34955886427443694, 0.3437996594254499, 0.2043333499529678, 0.21386307837530127, 0.2512756799941861, 0.2940170348337846, 0.24043443422541633, 0.2304697107751813, 0.5703426398337541, 0.23625917885987213, 0.22406953152486953, 0.19692500478657604, 0.23187412686371844, 0.2109721604237158, 0.5183693489630542, 0.1949178687432621, 0.21566558814757386, 0.18107926967244192, 0.23299830793327614, 0.21644176357879297, 0.19061760313507936, 0.17389408819522945, 0.8240492496914406, 0.8909405218062731, 0.19801412364866544, 0.863560782036078, 0.8495805152620546, 0.7993568185300116, 0.8592594563534482, 0.8481211476167578, 0.2115700005790373, 0.7873674463898014, 0.7991904515810152, 0.20276901617894605, 0.16331941982910103, 0.6910349826811836, 0.7933112713859849, 0.15428762750198677, 0.19943045783118163, 0.19549448171344785, 0.18229827289945333, 0.19138575902867938, 0.1885460134439655, 0.18801199197536556, 0.19461752535226462, 0.19075532195292255, 0.19550554928646646, 0.12781078803326873, 0.09844776984858894, 0.09963865579327957, 0.10265652127516312, 0.09989558376881014, 0.10016486903353639, 0.09356287624518134, 0.11254562456853967, 0.09788880127421418]}, "mutation_prompt": null}
{"id": "26469cdc-4709-47ab-92fd-cb414552db05", "solution": "import numpy as np\n\nclass HybridDynamicAdaptivePSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50  # Reduced for quicker convergence\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight_initial = 0.8\n        self.inertia_weight_final = 0.3\n        self.cognitive_weight_initial = 1.4  # Further adaptive cognitive component\n        self.cognitive_weight_final = 1.2\n        self.social_weight_initial = 1.2  # Further adaptive social component\n        self.social_weight_final = 1.8\n        self.mutation_scale = 0.25  # Adjusted for more impactful mutations\n        self.F = 0.5  # Differential evolution scaling factor\n        self.CR = 0.9  # Differential evolution crossover rate\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: self.inertia_weight_initial - iter * (self.inertia_weight_initial - self.inertia_weight_final) / (self.budget/self.swarm_size)\n        cognitive_weight = lambda iter: self.cognitive_weight_initial - iter * (self.cognitive_weight_initial - self.cognitive_weight_final) / (self.budget/self.swarm_size)\n        social_weight = lambda iter: self.social_weight_initial + iter * (self.social_weight_final - self.social_weight_initial) / (self.budget/self.swarm_size)\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          cognitive_weight(iter_count) * r1 * (personal_best_positions - positions) +\n                          social_weight(iter_count) * r2 * (global_best_position - positions))\n            \n            velocities = np.clip(velocities, -0.7, 0.7)  # Adjusted velocity limits\n            positions += velocities\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Differential Evolution-like perturbation for additional diversity\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + self.F * (b - c)\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, personal_best_positions[i])\n                trial = np.clip(trial, self.lb, self.ub)\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "HybridDynamicAdaptivePSO_DE", "description": "Hybrid Dynamic Adaptive PSO and Differential Evolution with adaptive parameters for enhanced convergence speed.", "configspace": "", "generation": 92, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "beaa09cb-3205-4a17-9276-3d3a6dc87f23", "metadata": {"aucs": [0.7837262178630025, 0.749798005597236, 0.7485883600952447, 0.7617920885451106, 0.733767277059648, 0.7377503740118627, 0.7544077696711233, 0.7330888121625447, 0.7278012347167753, 0.46430842870511446, 0.4571582069187564, 0.45824436511557287, 0.4532777216588352, 0.462967805539111, 0.44787193959870286, 0.4726873465875848, 0.4830056717783401, 0.4483114547442477, 0.1296388589274473, 0.16606368338442712, 0.14958184810063335, 0.1397644568372316, 0.3399590122639, 0.2622129866792984, 0.14289168295562593, 0.1508787212991476, 0.12680405319722154, 0.10403283325082702, 0.13730740755451876, 0.13536075619796628, 0.10470444714448424, 0.13232021430225482, 0.10626662904174677, 0.1405444440313064, 0.13207686996079915, 0.1178937740734094, 0.8925376095932811, 0.8971479210061601, 0.8713436429852564, 0.8767679293917203, 0.8726680341730557, 0.8862575926119921, 0.8950992120278612, 0.8938632210325463, 0.9037125432401389, 0.5652534592178536, 0.5049134323583517, 0.49604358824455486, 0.5362441769898474, 0.47510843614836396, 0.512385820895267, 0.5672886907392664, 0.5193194122396761, 0.49457668125991894, 0.8035403079076591, 0.7942572348571526, 0.7939726448971027, 0.8223458099403136, 0.7750456394867403, 0.7566994839490807, 0.7967021526881286, 0.7743404641085396, 0.7614798913922664, 0.5464257714598165, 0.46567618630052676, 0.12364395618018387, 0.4551442813160097, 0.3391298026438432, 0.5025986834796622, 0.4116390715550944, 0.4760814844735304, 0.36319234400601175, 0.45444097572683384, 0.46128786459433035, 0.12802567469000192, 0.3685503864369676, 0.4274201285227146, 0.42352059844785694, 0.41075015827290906, 0.5065313524231518, 0.32264033975030193, 0.3682760346248011, 0.320674822190529, 0.24396344560219363, 0.24634337879666934, 0.3295429733295412, 0.24165637055798717, 0.30533350792588476, 0.23877701119455974, 0.23432012455422846, 0.36793981123390385, 0.33626797836939226, 0.45595298980310084, 0.3232208767199948, 0.3618184103829035, 0.38158991584788005, 0.3693184768269553, 0.3475474758385283, 0.4363640777241773, 0.17748313982266195, 0.09727911277667589, 0.06413155804515458, 0.24348582341092395, 0.16182518882536456, 0.1753414529527123, 0.09654156151925108, 0.09198796753434002, 0.18473700363928436, 0.28611104005642585, 0.25370784328563767, 0.26728627881270517, 0.30145882923175027, 0.26023961514935146, 0.3024074990959037, 0.296513620997334, 0.27528258102531067, 0.2680029340636121, 0.6823828004856765, 0.6442566330834767, 0.6213929647250317, 0.6450512040899992, 0.6253075271401186, 0.6308583885365171, 0.6782203012342422, 0.6061021517974446, 0.6440695272232271, 0.12992120733080703, 0.1343814927362027, 0.12311111767596539, 0.11191942722537951, 0.1233696292267823, 0.14450928485213643, 0.10778981517521402, 0.13015039742603152, 0.10703382750046764, 0.1905114982095697, 0.43581403489553217, 0.3485901263231421, 0.42060352325747075, 0.2478190091610316, 0.18708036888972324, 0.21841385491549925, 0.17750427608187602, 0.22802832896169, 0.45387639740584196, 0.43818898284860086, 0.4294634616619687, 0.4415431761075195, 0.44332121893911924, 0.4346297259075841, 0.44962716493661803, 0.424490101652659, 0.4222227678773046, 0.301018790856456, 0.3416742777412105, 0.3704194066169221, 0.4146551260179868, 0.3585643381536765, 0.3219835606783208, 0.2588295673794462, 0.34955886427443694, 0.3437996594254499, 0.2043333499529678, 0.21386307837530127, 0.2512756799941861, 0.2940170348337846, 0.24043443422541633, 0.2304697107751813, 0.5703426398337541, 0.23625917885987213, 0.22406953152486953, 0.19692500478657604, 0.23187412686371844, 0.2109721604237158, 0.5183693489630542, 0.1949178687432621, 0.21566558814757386, 0.18107926967244192, 0.23299830793327614, 0.21644176357879297, 0.19061760313507936, 0.17389408819522945, 0.8240492496914406, 0.8909405218062731, 0.19801412364866544, 0.863560782036078, 0.8495805152620546, 0.7993568185300116, 0.8592594563534482, 0.8481211476167578, 0.2115700005790373, 0.7873674463898014, 0.7991904515810152, 0.20276901617894605, 0.16331941982910103, 0.6910349826811836, 0.7933112713859849, 0.15428762750198677, 0.19943045783118163, 0.19549448171344785, 0.18229827289945333, 0.19138575902867938, 0.1885460134439655, 0.18801199197536556, 0.19461752535226462, 0.19075532195292255, 0.19550554928646646, 0.12781078803326873, 0.09844776984858894, 0.09963865579327957, 0.10265652127516312, 0.09989558376881014, 0.10016486903353639, 0.09356287624518134, 0.11254562456853967, 0.09788880127421418]}, "mutation_prompt": null}
{"id": "13535484-77a4-486d-ad38-9eb865f78b2d", "solution": "import numpy as np\n\nclass HybridDynamicAdaptivePSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50  # Reduced for quicker convergence\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight_initial = 0.8\n        self.inertia_weight_final = 0.3\n        self.cognitive_weight_initial = 1.4  # Further adaptive cognitive component\n        self.cognitive_weight_final = 1.2\n        self.social_weight_initial = 1.2  # Further adaptive social component\n        self.social_weight_final = 1.8\n        self.mutation_scale = 0.25  # Adjusted for more impactful mutations\n        self.F = 0.5  # Differential evolution scaling factor\n        self.CR = 0.9  # Differential evolution crossover rate\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: self.inertia_weight_initial - iter * (self.inertia_weight_initial - self.inertia_weight_final) / (self.budget/self.swarm_size)\n        cognitive_weight = lambda iter: self.cognitive_weight_initial - iter * (self.cognitive_weight_initial - self.cognitive_weight_final) / (self.budget/self.swarm_size)\n        social_weight = lambda iter: self.social_weight_initial + iter * (self.social_weight_final - self.social_weight_initial) / (self.budget/self.swarm_size)\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          cognitive_weight(iter_count) * r1 * (personal_best_positions - positions) +\n                          social_weight(iter_count) * r2 * (global_best_position - positions))\n            \n            velocities = np.clip(velocities, -0.7, 0.7)  # Adjusted velocity limits\n            positions += velocities\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Differential Evolution-like perturbation for additional diversity\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + self.F * (b - c)\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, personal_best_positions[i])\n                trial = np.clip(trial, self.lb, self.ub)\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "HybridDynamicAdaptivePSO_DE", "description": "Hybrid Dynamic Adaptive PSO and Differential Evolution with adaptive parameters for enhanced convergence speed.", "configspace": "", "generation": 92, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "beaa09cb-3205-4a17-9276-3d3a6dc87f23", "metadata": {"aucs": [0.7837262178630025, 0.749798005597236, 0.7485883600952447, 0.7617920885451106, 0.733767277059648, 0.7377503740118627, 0.7544077696711233, 0.7330888121625447, 0.7278012347167753, 0.46430842870511446, 0.4571582069187564, 0.45824436511557287, 0.4532777216588352, 0.462967805539111, 0.44787193959870286, 0.4726873465875848, 0.4830056717783401, 0.4483114547442477, 0.1296388589274473, 0.16606368338442712, 0.14958184810063335, 0.1397644568372316, 0.3399590122639, 0.2622129866792984, 0.14289168295562593, 0.1508787212991476, 0.12680405319722154, 0.10403283325082702, 0.13730740755451876, 0.13536075619796628, 0.10470444714448424, 0.13232021430225482, 0.10626662904174677, 0.1405444440313064, 0.13207686996079915, 0.1178937740734094, 0.8925376095932811, 0.8971479210061601, 0.8713436429852564, 0.8767679293917203, 0.8726680341730557, 0.8862575926119921, 0.8950992120278612, 0.8938632210325463, 0.9037125432401389, 0.5652534592178536, 0.5049134323583517, 0.49604358824455486, 0.5362441769898474, 0.47510843614836396, 0.512385820895267, 0.5672886907392664, 0.5193194122396761, 0.49457668125991894, 0.8035403079076591, 0.7942572348571526, 0.7939726448971027, 0.8223458099403136, 0.7750456394867403, 0.7566994839490807, 0.7967021526881286, 0.7743404641085396, 0.7614798913922664, 0.5464257714598165, 0.46567618630052676, 0.12364395618018387, 0.4551442813160097, 0.3391298026438432, 0.5025986834796622, 0.4116390715550944, 0.4760814844735304, 0.36319234400601175, 0.45444097572683384, 0.46128786459433035, 0.12802567469000192, 0.3685503864369676, 0.4274201285227146, 0.42352059844785694, 0.41075015827290906, 0.5065313524231518, 0.32264033975030193, 0.3682760346248011, 0.320674822190529, 0.24396344560219363, 0.24634337879666934, 0.3295429733295412, 0.24165637055798717, 0.30533350792588476, 0.23877701119455974, 0.23432012455422846, 0.36793981123390385, 0.33626797836939226, 0.45595298980310084, 0.3232208767199948, 0.3618184103829035, 0.38158991584788005, 0.3693184768269553, 0.3475474758385283, 0.4363640777241773, 0.17748313982266195, 0.09727911277667589, 0.06413155804515458, 0.24348582341092395, 0.16182518882536456, 0.1753414529527123, 0.09654156151925108, 0.09198796753434002, 0.18473700363928436, 0.28611104005642585, 0.25370784328563767, 0.26728627881270517, 0.30145882923175027, 0.26023961514935146, 0.3024074990959037, 0.296513620997334, 0.27528258102531067, 0.2680029340636121, 0.6823828004856765, 0.6442566330834767, 0.6213929647250317, 0.6450512040899992, 0.6253075271401186, 0.6308583885365171, 0.6782203012342422, 0.6061021517974446, 0.6440695272232271, 0.12992120733080703, 0.1343814927362027, 0.12311111767596539, 0.11191942722537951, 0.1233696292267823, 0.14450928485213643, 0.10778981517521402, 0.13015039742603152, 0.10703382750046764, 0.1905114982095697, 0.43581403489553217, 0.3485901263231421, 0.42060352325747075, 0.2478190091610316, 0.18708036888972324, 0.21841385491549925, 0.17750427608187602, 0.22802832896169, 0.45387639740584196, 0.43818898284860086, 0.4294634616619687, 0.4415431761075195, 0.44332121893911924, 0.4346297259075841, 0.44962716493661803, 0.424490101652659, 0.4222227678773046, 0.301018790856456, 0.3416742777412105, 0.3704194066169221, 0.4146551260179868, 0.3585643381536765, 0.3219835606783208, 0.2588295673794462, 0.34955886427443694, 0.3437996594254499, 0.2043333499529678, 0.21386307837530127, 0.2512756799941861, 0.2940170348337846, 0.24043443422541633, 0.2304697107751813, 0.5703426398337541, 0.23625917885987213, 0.22406953152486953, 0.19692500478657604, 0.23187412686371844, 0.2109721604237158, 0.5183693489630542, 0.1949178687432621, 0.21566558814757386, 0.18107926967244192, 0.23299830793327614, 0.21644176357879297, 0.19061760313507936, 0.17389408819522945, 0.8240492496914406, 0.8909405218062731, 0.19801412364866544, 0.863560782036078, 0.8495805152620546, 0.7993568185300116, 0.8592594563534482, 0.8481211476167578, 0.2115700005790373, 0.7873674463898014, 0.7991904515810152, 0.20276901617894605, 0.16331941982910103, 0.6910349826811836, 0.7933112713859849, 0.15428762750198677, 0.19943045783118163, 0.19549448171344785, 0.18229827289945333, 0.19138575902867938, 0.1885460134439655, 0.18801199197536556, 0.19461752535226462, 0.19075532195292255, 0.19550554928646646, 0.12781078803326873, 0.09844776984858894, 0.09963865579327957, 0.10265652127516312, 0.09989558376881014, 0.10016486903353639, 0.09356287624518134, 0.11254562456853967, 0.09788880127421418]}, "mutation_prompt": null}
{"id": "4f445751-7c58-4144-a097-99c5e1157fa5", "solution": "import numpy as np\n\nclass HybridDynamicAdaptivePSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50  # Reduced for quicker convergence\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight_initial = 0.8\n        self.inertia_weight_final = 0.3\n        self.cognitive_weight_initial = 1.4  # Further adaptive cognitive component\n        self.cognitive_weight_final = 1.2\n        self.social_weight_initial = 1.2  # Further adaptive social component\n        self.social_weight_final = 1.8\n        self.mutation_scale = 0.25  # Adjusted for more impactful mutations\n        self.F = 0.5  # Differential evolution scaling factor\n        self.CR = 0.9  # Differential evolution crossover rate\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: self.inertia_weight_initial - iter * (self.inertia_weight_initial - self.inertia_weight_final) / (self.budget/self.swarm_size)\n        cognitive_weight = lambda iter: self.cognitive_weight_initial - iter * (self.cognitive_weight_initial - self.cognitive_weight_final) / (self.budget/self.swarm_size)\n        social_weight = lambda iter: self.social_weight_initial + iter * (self.social_weight_final - self.social_weight_initial) / (self.budget/self.swarm_size)\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          cognitive_weight(iter_count) * r1 * (personal_best_positions - positions) +\n                          social_weight(iter_count) * r2 * (global_best_position - positions))\n            \n            velocities = np.clip(velocities, -0.7, 0.7)  # Adjusted velocity limits\n            positions += velocities\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Differential Evolution-like perturbation for additional diversity\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + self.F * (b - c)\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, personal_best_positions[i])\n                trial = np.clip(trial, self.lb, self.ub)\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "HybridDynamicAdaptivePSO_DE", "description": "Hybrid Dynamic Adaptive PSO and Differential Evolution with adaptive parameters for enhanced convergence speed.", "configspace": "", "generation": 92, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "beaa09cb-3205-4a17-9276-3d3a6dc87f23", "metadata": {"aucs": [0.7837262178630025, 0.749798005597236, 0.7485883600952447, 0.7617920885451106, 0.733767277059648, 0.7377503740118627, 0.7544077696711233, 0.7330888121625447, 0.7278012347167753, 0.46430842870511446, 0.4571582069187564, 0.45824436511557287, 0.4532777216588352, 0.462967805539111, 0.44787193959870286, 0.4726873465875848, 0.4830056717783401, 0.4483114547442477, 0.1296388589274473, 0.16606368338442712, 0.14958184810063335, 0.1397644568372316, 0.3399590122639, 0.2622129866792984, 0.14289168295562593, 0.1508787212991476, 0.12680405319722154, 0.10403283325082702, 0.13730740755451876, 0.13536075619796628, 0.10470444714448424, 0.13232021430225482, 0.10626662904174677, 0.1405444440313064, 0.13207686996079915, 0.1178937740734094, 0.8925376095932811, 0.8971479210061601, 0.8713436429852564, 0.8767679293917203, 0.8726680341730557, 0.8862575926119921, 0.8950992120278612, 0.8938632210325463, 0.9037125432401389, 0.5652534592178536, 0.5049134323583517, 0.49604358824455486, 0.5362441769898474, 0.47510843614836396, 0.512385820895267, 0.5672886907392664, 0.5193194122396761, 0.49457668125991894, 0.8035403079076591, 0.7942572348571526, 0.7939726448971027, 0.8223458099403136, 0.7750456394867403, 0.7566994839490807, 0.7967021526881286, 0.7743404641085396, 0.7614798913922664, 0.5464257714598165, 0.46567618630052676, 0.12364395618018387, 0.4551442813160097, 0.3391298026438432, 0.5025986834796622, 0.4116390715550944, 0.4760814844735304, 0.36319234400601175, 0.45444097572683384, 0.46128786459433035, 0.12802567469000192, 0.3685503864369676, 0.4274201285227146, 0.42352059844785694, 0.41075015827290906, 0.5065313524231518, 0.32264033975030193, 0.3682760346248011, 0.320674822190529, 0.24396344560219363, 0.24634337879666934, 0.3295429733295412, 0.24165637055798717, 0.30533350792588476, 0.23877701119455974, 0.23432012455422846, 0.36793981123390385, 0.33626797836939226, 0.45595298980310084, 0.3232208767199948, 0.3618184103829035, 0.38158991584788005, 0.3693184768269553, 0.3475474758385283, 0.4363640777241773, 0.17748313982266195, 0.09727911277667589, 0.06413155804515458, 0.24348582341092395, 0.16182518882536456, 0.1753414529527123, 0.09654156151925108, 0.09198796753434002, 0.18473700363928436, 0.28611104005642585, 0.25370784328563767, 0.26728627881270517, 0.30145882923175027, 0.26023961514935146, 0.3024074990959037, 0.296513620997334, 0.27528258102531067, 0.2680029340636121, 0.6823828004856765, 0.6442566330834767, 0.6213929647250317, 0.6450512040899992, 0.6253075271401186, 0.6308583885365171, 0.6782203012342422, 0.6061021517974446, 0.6440695272232271, 0.12992120733080703, 0.1343814927362027, 0.12311111767596539, 0.11191942722537951, 0.1233696292267823, 0.14450928485213643, 0.10778981517521402, 0.13015039742603152, 0.10703382750046764, 0.1905114982095697, 0.43581403489553217, 0.3485901263231421, 0.42060352325747075, 0.2478190091610316, 0.18708036888972324, 0.21841385491549925, 0.17750427608187602, 0.22802832896169, 0.45387639740584196, 0.43818898284860086, 0.4294634616619687, 0.4415431761075195, 0.44332121893911924, 0.4346297259075841, 0.44962716493661803, 0.424490101652659, 0.4222227678773046, 0.301018790856456, 0.3416742777412105, 0.3704194066169221, 0.4146551260179868, 0.3585643381536765, 0.3219835606783208, 0.2588295673794462, 0.34955886427443694, 0.3437996594254499, 0.2043333499529678, 0.21386307837530127, 0.2512756799941861, 0.2940170348337846, 0.24043443422541633, 0.2304697107751813, 0.5703426398337541, 0.23625917885987213, 0.22406953152486953, 0.19692500478657604, 0.23187412686371844, 0.2109721604237158, 0.5183693489630542, 0.1949178687432621, 0.21566558814757386, 0.18107926967244192, 0.23299830793327614, 0.21644176357879297, 0.19061760313507936, 0.17389408819522945, 0.8240492496914406, 0.8909405218062731, 0.19801412364866544, 0.863560782036078, 0.8495805152620546, 0.7993568185300116, 0.8592594563534482, 0.8481211476167578, 0.2115700005790373, 0.7873674463898014, 0.7991904515810152, 0.20276901617894605, 0.16331941982910103, 0.6910349826811836, 0.7933112713859849, 0.15428762750198677, 0.19943045783118163, 0.19549448171344785, 0.18229827289945333, 0.19138575902867938, 0.1885460134439655, 0.18801199197536556, 0.19461752535226462, 0.19075532195292255, 0.19550554928646646, 0.12781078803326873, 0.09844776984858894, 0.09963865579327957, 0.10265652127516312, 0.09989558376881014, 0.10016486903353639, 0.09356287624518134, 0.11254562456853967, 0.09788880127421418]}, "mutation_prompt": null}
{"id": "e6a70b61-a0a1-4210-ba6a-8bd25e43e778", "solution": "import numpy as np\n\nclass HybridDynamicAdaptivePSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50  # Reduced for quicker convergence\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight_initial = 0.8\n        self.inertia_weight_final = 0.3\n        self.cognitive_weight_initial = 1.4  # Further adaptive cognitive component\n        self.cognitive_weight_final = 1.2\n        self.social_weight_initial = 1.2  # Further adaptive social component\n        self.social_weight_final = 1.8\n        self.mutation_scale = 0.25  # Adjusted for more impactful mutations\n        self.F = 0.5  # Differential evolution scaling factor\n        self.CR = 0.9  # Differential evolution crossover rate\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: self.inertia_weight_initial - iter * (self.inertia_weight_initial - self.inertia_weight_final) / (self.budget/self.swarm_size)\n        cognitive_weight = lambda iter: self.cognitive_weight_initial - iter * (self.cognitive_weight_initial - self.cognitive_weight_final) / (self.budget/self.swarm_size)\n        social_weight = lambda iter: self.social_weight_initial + iter * (self.social_weight_final - self.social_weight_initial) / (self.budget/self.swarm_size)\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          cognitive_weight(iter_count) * r1 * (personal_best_positions - positions) +\n                          social_weight(iter_count) * r2 * (global_best_position - positions))\n            \n            velocities = np.clip(velocities, -0.7, 0.7)  # Adjusted velocity limits\n            positions += velocities\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Differential Evolution-like perturbation for additional diversity\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + self.F * (b - c)\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, personal_best_positions[i])\n                trial = np.clip(trial, self.lb, self.ub)\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "HybridDynamicAdaptivePSO_DE", "description": "Hybrid Dynamic Adaptive PSO and Differential Evolution with adaptive parameters for enhanced convergence speed.", "configspace": "", "generation": 92, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "beaa09cb-3205-4a17-9276-3d3a6dc87f23", "metadata": {"aucs": [0.7837262178630025, 0.749798005597236, 0.7485883600952447, 0.7617920885451106, 0.733767277059648, 0.7377503740118627, 0.7544077696711233, 0.7330888121625447, 0.7278012347167753, 0.46430842870511446, 0.4571582069187564, 0.45824436511557287, 0.4532777216588352, 0.462967805539111, 0.44787193959870286, 0.4726873465875848, 0.4830056717783401, 0.4483114547442477, 0.1296388589274473, 0.16606368338442712, 0.14958184810063335, 0.1397644568372316, 0.3399590122639, 0.2622129866792984, 0.14289168295562593, 0.1508787212991476, 0.12680405319722154, 0.10403283325082702, 0.13730740755451876, 0.13536075619796628, 0.10470444714448424, 0.13232021430225482, 0.10626662904174677, 0.1405444440313064, 0.13207686996079915, 0.1178937740734094, 0.8925376095932811, 0.8971479210061601, 0.8713436429852564, 0.8767679293917203, 0.8726680341730557, 0.8862575926119921, 0.8950992120278612, 0.8938632210325463, 0.9037125432401389, 0.5652534592178536, 0.5049134323583517, 0.49604358824455486, 0.5362441769898474, 0.47510843614836396, 0.512385820895267, 0.5672886907392664, 0.5193194122396761, 0.49457668125991894, 0.8035403079076591, 0.7942572348571526, 0.7939726448971027, 0.8223458099403136, 0.7750456394867403, 0.7566994839490807, 0.7967021526881286, 0.7743404641085396, 0.7614798913922664, 0.5464257714598165, 0.46567618630052676, 0.12364395618018387, 0.4551442813160097, 0.3391298026438432, 0.5025986834796622, 0.4116390715550944, 0.4760814844735304, 0.36319234400601175, 0.45444097572683384, 0.46128786459433035, 0.12802567469000192, 0.3685503864369676, 0.4274201285227146, 0.42352059844785694, 0.41075015827290906, 0.5065313524231518, 0.32264033975030193, 0.3682760346248011, 0.320674822190529, 0.24396344560219363, 0.24634337879666934, 0.3295429733295412, 0.24165637055798717, 0.30533350792588476, 0.23877701119455974, 0.23432012455422846, 0.36793981123390385, 0.33626797836939226, 0.45595298980310084, 0.3232208767199948, 0.3618184103829035, 0.38158991584788005, 0.3693184768269553, 0.3475474758385283, 0.4363640777241773, 0.17748313982266195, 0.09727911277667589, 0.06413155804515458, 0.24348582341092395, 0.16182518882536456, 0.1753414529527123, 0.09654156151925108, 0.09198796753434002, 0.18473700363928436, 0.28611104005642585, 0.25370784328563767, 0.26728627881270517, 0.30145882923175027, 0.26023961514935146, 0.3024074990959037, 0.296513620997334, 0.27528258102531067, 0.2680029340636121, 0.6823828004856765, 0.6442566330834767, 0.6213929647250317, 0.6450512040899992, 0.6253075271401186, 0.6308583885365171, 0.6782203012342422, 0.6061021517974446, 0.6440695272232271, 0.12992120733080703, 0.1343814927362027, 0.12311111767596539, 0.11191942722537951, 0.1233696292267823, 0.14450928485213643, 0.10778981517521402, 0.13015039742603152, 0.10703382750046764, 0.1905114982095697, 0.43581403489553217, 0.3485901263231421, 0.42060352325747075, 0.2478190091610316, 0.18708036888972324, 0.21841385491549925, 0.17750427608187602, 0.22802832896169, 0.45387639740584196, 0.43818898284860086, 0.4294634616619687, 0.4415431761075195, 0.44332121893911924, 0.4346297259075841, 0.44962716493661803, 0.424490101652659, 0.4222227678773046, 0.301018790856456, 0.3416742777412105, 0.3704194066169221, 0.4146551260179868, 0.3585643381536765, 0.3219835606783208, 0.2588295673794462, 0.34955886427443694, 0.3437996594254499, 0.2043333499529678, 0.21386307837530127, 0.2512756799941861, 0.2940170348337846, 0.24043443422541633, 0.2304697107751813, 0.5703426398337541, 0.23625917885987213, 0.22406953152486953, 0.19692500478657604, 0.23187412686371844, 0.2109721604237158, 0.5183693489630542, 0.1949178687432621, 0.21566558814757386, 0.18107926967244192, 0.23299830793327614, 0.21644176357879297, 0.19061760313507936, 0.17389408819522945, 0.8240492496914406, 0.8909405218062731, 0.19801412364866544, 0.863560782036078, 0.8495805152620546, 0.7993568185300116, 0.8592594563534482, 0.8481211476167578, 0.2115700005790373, 0.7873674463898014, 0.7991904515810152, 0.20276901617894605, 0.16331941982910103, 0.6910349826811836, 0.7933112713859849, 0.15428762750198677, 0.19943045783118163, 0.19549448171344785, 0.18229827289945333, 0.19138575902867938, 0.1885460134439655, 0.18801199197536556, 0.19461752535226462, 0.19075532195292255, 0.19550554928646646, 0.12781078803326873, 0.09844776984858894, 0.09963865579327957, 0.10265652127516312, 0.09989558376881014, 0.10016486903353639, 0.09356287624518134, 0.11254562456853967, 0.09788880127421418]}, "mutation_prompt": null}
{"id": "bf6de208-a690-4304-bbcc-4124681993d8", "solution": "import numpy as np\n\nclass HybridGradientEnhancedDynamicAdaptivePSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 45  # Adjusted swarm size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight_initial = 0.9  # Slightly increased to enhance exploration\n        self.inertia_weight_final = 0.4\n        self.cognitive_weight_initial = 1.2\n        self.cognitive_weight_final = 1.0\n        self.social_weight_initial = 1.5\n        self.social_weight_final = 2.0\n        self.mutation_scale = 0.3  # Further increased for diversity\n        self.F = 0.6  # Increased DE scaling factor\n        self.CR = 0.85  # Slightly reduced DE crossover rate\n        self.gradient_step = 0.1  # Step for gradient-based local search\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: self.inertia_weight_initial - iter * (self.inertia_weight_initial - self.inertia_weight_final) / (self.budget/self.swarm_size)\n        cognitive_weight = lambda iter: self.cognitive_weight_initial - iter * (self.cognitive_weight_initial - self.cognitive_weight_final) / (self.budget/self.swarm_size)\n        social_weight = lambda iter: self.social_weight_initial + iter * (self.social_weight_final - self.social_weight_initial) / (self.budget/self.swarm_size)\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          cognitive_weight(iter_count) * r1 * (personal_best_positions - positions) +\n                          social_weight(iter_count) * r2 * (global_best_position - positions))\n            \n            velocities = np.clip(velocities, -0.7, 0.7)\n            positions += velocities\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Differential Evolution-like perturbation and gradient-based local search\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + self.F * (b - c)\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, personal_best_positions[i])\n                trial = np.clip(trial, self.lb, self.ub)\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                # Gradient-based local search\n                gradient = np.zeros(self.dim)\n                for d in range(self.dim):\n                    perturbed = np.copy(personal_best_positions[i])\n                    perturbed[d] += self.gradient_step\n                    gradient[d] = (func(perturbed) - personal_best_scores[i]) / self.gradient_step\n                num_gradients = 1\n                improved_position = personal_best_positions[i] - self.gradient_step * gradient\n                improved_position = np.clip(improved_position, self.lb, self.ub)\n                improved_score = func(improved_position)\n                evaluations += num_gradients\n\n                if improved_score < personal_best_scores[i]:\n                    personal_best_positions[i] = improved_position\n                    personal_best_scores[i] = improved_score\n                    if improved_score < global_best_score:\n                        global_best_position = improved_position\n                        global_best_score = improved_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "HybridGradientEnhancedDynamicAdaptivePSO_DE", "description": "Hybrid Gradient-Enhanced Dynamic Adaptive PSO and DE incorporating gradient-based local search for accelerated convergence.", "configspace": "", "generation": 96, "fitness": 0.20038741711780028, "feedback": "The algorithm HybridGradientEnhancedDynamicAdaptivePSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.18.", "error": "", "parent_id": "beaa09cb-3205-4a17-9276-3d3a6dc87f23", "metadata": {"aucs": [0.4817569662423441, 0.451339557934091, 0.5087563749544461, 0.4894092593529774, 0.4612271227664091, 0.45894946130713454, 0.47047056334188986, 0.48161359916028346, 0.471863138240156, 0.028352465166070595, 0.03947288163382523, 0.061677948690204376, 0.05806654301221004, 0.03962338384114861, 0.03591184923045898, 0.02879724540320472, 0.04861537004832295, 0.03705280399069266, 0.10595395450502598, 0.1030781948187709, 0.09965626561464047, 0.09893934211878153, 0.07872407822269001, 0.10430882591654989, 0.08340306622676275, 0.11214023792067473, 0.10491329743704358, 0.09171550349192925, 0.10030752073245952, 0.09146790922342185, 0.09169069362366644, 0.0839534957445559, 0.07179026882377093, 0.08865454201588419, 0.09471910077227241, 0.07464169510891894, 0.8586857178171023, 0.8563118628654927, 0.8482536070353314, 0.8859919334073763, 0.8064354325003288, 0.8566184445848317, 0.7873346145870114, 0.8741546087895398, 0.8487811816165938, 0.2247459522636185, 0.23225318458616562, 0.2306111217004596, 0.28908203638721364, 0.26947380661215126, 0.2813522735009124, 0.210160157670102, 0.2011668989292481, 0.21472752305964116, 0.3374736824403821, 0.2828361326519625, 0.2589723238729962, 0.28210582269809903, 0.2269595809734436, 0.25969157052889535, 0.22956226989354378, 0.45230698281179993, 0.28933850909299996, 0.13713458168194192, 0.1219311146059937, 0.14957335576466957, 0.11069764511161884, 0.11313610450619471, 0.09357297413196664, 0.11289572021986627, 0.10075841551927933, 0.12219800766120692, 0.10919592925940613, 0.10680167201225399, 0.09821917054767815, 0.15903445822093054, 0.1372316832986209, 0.11146298346131422, 0.0989300973587427, 0.1254226797146767, 0.13696998548822936, 0.010465851233709134, 0.011098041474329134, 0.009078992388542262, 0.006664065779940054, 0.016925966101843937, 9.999999999998899e-05, 0.023735679052462322, 0.006207034948404688, 0.005195940465603011, 0.1028249289376072, 0.11805223107283713, 0.13878857447322845, 0.0796457158139745, 0.07336773230441562, 0.07210022272880523, 0.14138762577639352, 0.07694026648073449, 0.08006794026588049, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05415132024917435, 0.0759401902648591, 0.08679783114983419, 0.06582452952332696, 0.06746858652885823, 0.08568430870498378, 0.06903380929033776, 0.0762299852491839, 0.05694516434643704, 0.393442483568731, 0.39174583013103426, 0.3909979735233826, 0.3825819619469444, 0.35893922917921894, 0.36353666127642426, 0.4056034623627357, 0.392906800419331, 0.39093902400694747, 0.09048300172752965, 0.08933386892422734, 0.10288952570352028, 0.10068952647724527, 0.09995242331972165, 0.10866252488294559, 0.1033466739480926, 0.10085294025202252, 0.09510586924655096, 0.12838651342897245, 0.14273303271862192, 0.14827134321961144, 0.1520009476610965, 0.14946870349008567, 0.13200231582027522, 0.14300446556692004, 0.18883305039531384, 0.13433601286335306, 0.25522200387273786, 0.25824226043039644, 0.2707092459183412, 0.2701909490987092, 0.26401176418698447, 0.26848957885735003, 0.20577325411802272, 0.26621428288286597, 0.24458075735136564, 0.19186480655620752, 0.1862532929824402, 0.20548078913910195, 0.20619999402179634, 0.2196537414082148, 0.20436676677857057, 0.18387309515415295, 0.2023550401015889, 0.1855256603516684, 0.19852010469855386, 0.19073369639837257, 0.21554269859873665, 0.1768456693911954, 0.22278941277228526, 0.19191644583685707, 0.23273868307012913, 0.21073871112553055, 0.20580636166609656, 0.17235360303607228, 0.18178261004963114, 0.16981641926137658, 0.1802937058565932, 0.17990982413776668, 0.1846759420734273, 0.17470238232842272, 0.17137742986416304, 0.18227493082056756, 0.2958192806076818, 0.19623748667395302, 0.194921620147392, 0.5032853084425987, 0.20030545062470495, 0.3380687942533145, 0.4425447536734335, 0.42396032676291073, 0.4931303990818925, 0.5331418979981799, 0.2018380190072846, 0.16324197808300556, 0.28283847160337194, 0.16879374451829832, 0.29891595005793703, 0.1527812557858964, 0.20317001941561907, 0.21102354272198687, 0.16637440044635587, 0.18280799171188955, 0.18362245080434014, 0.1771699754697429, 0.17676558849600565, 0.18628772376896552, 0.17410221620295252, 0.16897603381280657, 0.18309371309703426, 0.08531537351360008, 0.07038845063121102, 0.07433297702366559, 0.076311019439253, 0.07632833247830184, 0.07404490859407142, 0.07562899971179526, 0.07364697919508612, 0.07640371064994511]}, "mutation_prompt": null}
{"id": "7fd9b5f7-41f1-4617-833c-1942025eaed4", "solution": "import numpy as np\n\nclass HybridDynamicAdaptivePSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50  # Reduced for quicker convergence\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight_initial = 0.8\n        self.inertia_weight_final = 0.3\n        self.cognitive_weight_initial = 1.4  # Further adaptive cognitive component\n        self.cognitive_weight_final = 1.2\n        self.social_weight_initial = 1.2  # Further adaptive social component\n        self.social_weight_final = 1.8\n        self.mutation_scale = 0.25  # Adjusted for more impactful mutations\n        self.F = 0.5  # Differential evolution scaling factor\n        self.CR = 0.9  # Differential evolution crossover rate\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: self.inertia_weight_initial - iter * (self.inertia_weight_initial - self.inertia_weight_final) / (self.budget/self.swarm_size)\n        cognitive_weight = lambda iter: self.cognitive_weight_initial - iter * (self.cognitive_weight_initial - self.cognitive_weight_final) / (self.budget/self.swarm_size)\n        social_weight = lambda iter: self.social_weight_initial + iter * (self.social_weight_final - self.social_weight_initial) / (self.budget/self.swarm_size)\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          cognitive_weight(iter_count) * r1 * (personal_best_positions - positions) +\n                          social_weight(iter_count) * r2 * (global_best_position - positions))\n            \n            velocities = np.clip(velocities, -0.7, 0.7)  # Adjusted velocity limits\n            positions += velocities\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Differential Evolution-like perturbation for additional diversity\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + self.F * (b - c)\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, personal_best_positions[i])\n                trial = np.clip(trial, self.lb, self.ub)\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "HybridDynamicAdaptivePSO_DE", "description": "Hybrid Dynamic Adaptive PSO and Differential Evolution with adaptive parameters for enhanced convergence speed.", "configspace": "", "generation": 92, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "beaa09cb-3205-4a17-9276-3d3a6dc87f23", "metadata": {"aucs": [0.7837262178630025, 0.749798005597236, 0.7485883600952447, 0.7617920885451106, 0.733767277059648, 0.7377503740118627, 0.7544077696711233, 0.7330888121625447, 0.7278012347167753, 0.46430842870511446, 0.4571582069187564, 0.45824436511557287, 0.4532777216588352, 0.462967805539111, 0.44787193959870286, 0.4726873465875848, 0.4830056717783401, 0.4483114547442477, 0.1296388589274473, 0.16606368338442712, 0.14958184810063335, 0.1397644568372316, 0.3399590122639, 0.2622129866792984, 0.14289168295562593, 0.1508787212991476, 0.12680405319722154, 0.10403283325082702, 0.13730740755451876, 0.13536075619796628, 0.10470444714448424, 0.13232021430225482, 0.10626662904174677, 0.1405444440313064, 0.13207686996079915, 0.1178937740734094, 0.8925376095932811, 0.8971479210061601, 0.8713436429852564, 0.8767679293917203, 0.8726680341730557, 0.8862575926119921, 0.8950992120278612, 0.8938632210325463, 0.9037125432401389, 0.5652534592178536, 0.5049134323583517, 0.49604358824455486, 0.5362441769898474, 0.47510843614836396, 0.512385820895267, 0.5672886907392664, 0.5193194122396761, 0.49457668125991894, 0.8035403079076591, 0.7942572348571526, 0.7939726448971027, 0.8223458099403136, 0.7750456394867403, 0.7566994839490807, 0.7967021526881286, 0.7743404641085396, 0.7614798913922664, 0.5464257714598165, 0.46567618630052676, 0.12364395618018387, 0.4551442813160097, 0.3391298026438432, 0.5025986834796622, 0.4116390715550944, 0.4760814844735304, 0.36319234400601175, 0.45444097572683384, 0.46128786459433035, 0.12802567469000192, 0.3685503864369676, 0.4274201285227146, 0.42352059844785694, 0.41075015827290906, 0.5065313524231518, 0.32264033975030193, 0.3682760346248011, 0.320674822190529, 0.24396344560219363, 0.24634337879666934, 0.3295429733295412, 0.24165637055798717, 0.30533350792588476, 0.23877701119455974, 0.23432012455422846, 0.36793981123390385, 0.33626797836939226, 0.45595298980310084, 0.3232208767199948, 0.3618184103829035, 0.38158991584788005, 0.3693184768269553, 0.3475474758385283, 0.4363640777241773, 0.17748313982266195, 0.09727911277667589, 0.06413155804515458, 0.24348582341092395, 0.16182518882536456, 0.1753414529527123, 0.09654156151925108, 0.09198796753434002, 0.18473700363928436, 0.28611104005642585, 0.25370784328563767, 0.26728627881270517, 0.30145882923175027, 0.26023961514935146, 0.3024074990959037, 0.296513620997334, 0.27528258102531067, 0.2680029340636121, 0.6823828004856765, 0.6442566330834767, 0.6213929647250317, 0.6450512040899992, 0.6253075271401186, 0.6308583885365171, 0.6782203012342422, 0.6061021517974446, 0.6440695272232271, 0.12992120733080703, 0.1343814927362027, 0.12311111767596539, 0.11191942722537951, 0.1233696292267823, 0.14450928485213643, 0.10778981517521402, 0.13015039742603152, 0.10703382750046764, 0.1905114982095697, 0.43581403489553217, 0.3485901263231421, 0.42060352325747075, 0.2478190091610316, 0.18708036888972324, 0.21841385491549925, 0.17750427608187602, 0.22802832896169, 0.45387639740584196, 0.43818898284860086, 0.4294634616619687, 0.4415431761075195, 0.44332121893911924, 0.4346297259075841, 0.44962716493661803, 0.424490101652659, 0.4222227678773046, 0.301018790856456, 0.3416742777412105, 0.3704194066169221, 0.4146551260179868, 0.3585643381536765, 0.3219835606783208, 0.2588295673794462, 0.34955886427443694, 0.3437996594254499, 0.2043333499529678, 0.21386307837530127, 0.2512756799941861, 0.2940170348337846, 0.24043443422541633, 0.2304697107751813, 0.5703426398337541, 0.23625917885987213, 0.22406953152486953, 0.19692500478657604, 0.23187412686371844, 0.2109721604237158, 0.5183693489630542, 0.1949178687432621, 0.21566558814757386, 0.18107926967244192, 0.23299830793327614, 0.21644176357879297, 0.19061760313507936, 0.17389408819522945, 0.8240492496914406, 0.8909405218062731, 0.19801412364866544, 0.863560782036078, 0.8495805152620546, 0.7993568185300116, 0.8592594563534482, 0.8481211476167578, 0.2115700005790373, 0.7873674463898014, 0.7991904515810152, 0.20276901617894605, 0.16331941982910103, 0.6910349826811836, 0.7933112713859849, 0.15428762750198677, 0.19943045783118163, 0.19549448171344785, 0.18229827289945333, 0.19138575902867938, 0.1885460134439655, 0.18801199197536556, 0.19461752535226462, 0.19075532195292255, 0.19550554928646646, 0.12781078803326873, 0.09844776984858894, 0.09963865579327957, 0.10265652127516312, 0.09989558376881014, 0.10016486903353639, 0.09356287624518134, 0.11254562456853967, 0.09788880127421418]}, "mutation_prompt": null}
{"id": "4ac4a21b-da6a-46c2-ad0f-c764476c19fa", "solution": "import numpy as np\n\nclass HybridDynamicAdaptivePSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50  # Reduced for quicker convergence\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight_initial = 0.8\n        self.inertia_weight_final = 0.3\n        self.cognitive_weight_initial = 1.4  # Further adaptive cognitive component\n        self.cognitive_weight_final = 1.2\n        self.social_weight_initial = 1.2  # Further adaptive social component\n        self.social_weight_final = 1.8\n        self.mutation_scale = 0.25  # Adjusted for more impactful mutations\n        self.F = 0.5  # Differential evolution scaling factor\n        self.CR = 0.9  # Differential evolution crossover rate\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        dynamic_inertia = lambda iter: self.inertia_weight_initial - iter * (self.inertia_weight_initial - self.inertia_weight_final) / (self.budget/self.swarm_size)\n        cognitive_weight = lambda iter: self.cognitive_weight_initial - iter * (self.cognitive_weight_initial - self.cognitive_weight_final) / (self.budget/self.swarm_size)\n        social_weight = lambda iter: self.social_weight_initial + iter * (self.social_weight_final - self.social_weight_initial) / (self.budget/self.swarm_size)\n        iter_count = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (dynamic_inertia(iter_count) * velocities +\n                          cognitive_weight(iter_count) * r1 * (personal_best_positions - positions) +\n                          social_weight(iter_count) * r2 * (global_best_position - positions))\n            \n            velocities = np.clip(velocities, -0.7, 0.7)  # Adjusted velocity limits\n            positions += velocities\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            # Differential Evolution-like perturbation for additional diversity\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + self.F * (b - c)\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, personal_best_positions[i])\n                trial = np.clip(trial, self.lb, self.ub)\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "HybridDynamicAdaptivePSO_DE", "description": "Hybrid Dynamic Adaptive PSO and Differential Evolution with adaptive parameters for enhanced convergence speed.", "configspace": "", "generation": 92, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "beaa09cb-3205-4a17-9276-3d3a6dc87f23", "metadata": {"aucs": [0.7837262178630025, 0.749798005597236, 0.7485883600952447, 0.7617920885451106, 0.733767277059648, 0.7377503740118627, 0.7544077696711233, 0.7330888121625447, 0.7278012347167753, 0.46430842870511446, 0.4571582069187564, 0.45824436511557287, 0.4532777216588352, 0.462967805539111, 0.44787193959870286, 0.4726873465875848, 0.4830056717783401, 0.4483114547442477, 0.1296388589274473, 0.16606368338442712, 0.14958184810063335, 0.1397644568372316, 0.3399590122639, 0.2622129866792984, 0.14289168295562593, 0.1508787212991476, 0.12680405319722154, 0.10403283325082702, 0.13730740755451876, 0.13536075619796628, 0.10470444714448424, 0.13232021430225482, 0.10626662904174677, 0.1405444440313064, 0.13207686996079915, 0.1178937740734094, 0.8925376095932811, 0.8971479210061601, 0.8713436429852564, 0.8767679293917203, 0.8726680341730557, 0.8862575926119921, 0.8950992120278612, 0.8938632210325463, 0.9037125432401389, 0.5652534592178536, 0.5049134323583517, 0.49604358824455486, 0.5362441769898474, 0.47510843614836396, 0.512385820895267, 0.5672886907392664, 0.5193194122396761, 0.49457668125991894, 0.8035403079076591, 0.7942572348571526, 0.7939726448971027, 0.8223458099403136, 0.7750456394867403, 0.7566994839490807, 0.7967021526881286, 0.7743404641085396, 0.7614798913922664, 0.5464257714598165, 0.46567618630052676, 0.12364395618018387, 0.4551442813160097, 0.3391298026438432, 0.5025986834796622, 0.4116390715550944, 0.4760814844735304, 0.36319234400601175, 0.45444097572683384, 0.46128786459433035, 0.12802567469000192, 0.3685503864369676, 0.4274201285227146, 0.42352059844785694, 0.41075015827290906, 0.5065313524231518, 0.32264033975030193, 0.3682760346248011, 0.320674822190529, 0.24396344560219363, 0.24634337879666934, 0.3295429733295412, 0.24165637055798717, 0.30533350792588476, 0.23877701119455974, 0.23432012455422846, 0.36793981123390385, 0.33626797836939226, 0.45595298980310084, 0.3232208767199948, 0.3618184103829035, 0.38158991584788005, 0.3693184768269553, 0.3475474758385283, 0.4363640777241773, 0.17748313982266195, 0.09727911277667589, 0.06413155804515458, 0.24348582341092395, 0.16182518882536456, 0.1753414529527123, 0.09654156151925108, 0.09198796753434002, 0.18473700363928436, 0.28611104005642585, 0.25370784328563767, 0.26728627881270517, 0.30145882923175027, 0.26023961514935146, 0.3024074990959037, 0.296513620997334, 0.27528258102531067, 0.2680029340636121, 0.6823828004856765, 0.6442566330834767, 0.6213929647250317, 0.6450512040899992, 0.6253075271401186, 0.6308583885365171, 0.6782203012342422, 0.6061021517974446, 0.6440695272232271, 0.12992120733080703, 0.1343814927362027, 0.12311111767596539, 0.11191942722537951, 0.1233696292267823, 0.14450928485213643, 0.10778981517521402, 0.13015039742603152, 0.10703382750046764, 0.1905114982095697, 0.43581403489553217, 0.3485901263231421, 0.42060352325747075, 0.2478190091610316, 0.18708036888972324, 0.21841385491549925, 0.17750427608187602, 0.22802832896169, 0.45387639740584196, 0.43818898284860086, 0.4294634616619687, 0.4415431761075195, 0.44332121893911924, 0.4346297259075841, 0.44962716493661803, 0.424490101652659, 0.4222227678773046, 0.301018790856456, 0.3416742777412105, 0.3704194066169221, 0.4146551260179868, 0.3585643381536765, 0.3219835606783208, 0.2588295673794462, 0.34955886427443694, 0.3437996594254499, 0.2043333499529678, 0.21386307837530127, 0.2512756799941861, 0.2940170348337846, 0.24043443422541633, 0.2304697107751813, 0.5703426398337541, 0.23625917885987213, 0.22406953152486953, 0.19692500478657604, 0.23187412686371844, 0.2109721604237158, 0.5183693489630542, 0.1949178687432621, 0.21566558814757386, 0.18107926967244192, 0.23299830793327614, 0.21644176357879297, 0.19061760313507936, 0.17389408819522945, 0.8240492496914406, 0.8909405218062731, 0.19801412364866544, 0.863560782036078, 0.8495805152620546, 0.7993568185300116, 0.8592594563534482, 0.8481211476167578, 0.2115700005790373, 0.7873674463898014, 0.7991904515810152, 0.20276901617894605, 0.16331941982910103, 0.6910349826811836, 0.7933112713859849, 0.15428762750198677, 0.19943045783118163, 0.19549448171344785, 0.18229827289945333, 0.19138575902867938, 0.1885460134439655, 0.18801199197536556, 0.19461752535226462, 0.19075532195292255, 0.19550554928646646, 0.12781078803326873, 0.09844776984858894, 0.09963865579327957, 0.10265652127516312, 0.09989558376881014, 0.10016486903353639, 0.09356287624518134, 0.11254562456853967, 0.09788880127421418]}, "mutation_prompt": null}
{"id": "c868883e-83ff-4195-aa77-91e0a906d757", "solution": "import numpy as np\n\nclass ChaosEnhancedPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40  # Reduced swarm for faster exploration\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n        self.chaotic_map = self._logistic_map\n        self.mutation_scale = 0.4  # Increased for stronger mutations\n        self.F = 0.6  # Slightly larger scaling factor\n        self.CR = 0.8  # Reduced crossover rate for diversity\n\n    def _logistic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def __call__(self, func):\n        chaos_parameter = np.random.rand()\n        positions = np.random.uniform(self.lb, self.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n        iter_count = 0\n\n        while evaluations < self.budget:\n            chaos_parameter = self.chaotic_map(chaos_parameter)\n            r1, r2 = np.random.rand(2)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - positions) +\n                          self.social_weight * r2 * (global_best_position - positions) +\n                          chaos_parameter * np.random.uniform(-0.3, 0.3, velocities.shape))\n            \n            velocities = np.clip(velocities, -0.7, 0.7)\n            positions += velocities\n            positions = np.clip(positions, self.lb, self.ub)\n            scores = np.array([func(p) for p in positions])\n            evaluations += self.swarm_size\n\n            better_idxs = scores < personal_best_scores\n            personal_best_positions[better_idxs] = positions[better_idxs]\n            personal_best_scores[better_idxs] = scores[better_idxs]\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_idx]\n\n            if current_global_best_score < global_best_score:\n                global_best_position = personal_best_positions[current_global_best_idx]\n                global_best_score = current_global_best_score\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + self.F * (b - c)\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, personal_best_positions[i])\n                trial = np.clip(trial, self.lb, self.ub)\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "name": "ChaosEnhancedPSO_DE", "description": "Hybrid PSO-DE with adaptive chaos-enhanced exploration for rapid convergence.", "configspace": "", "generation": 99, "fitness": 0.32010179733796246, "feedback": "The algorithm ChaosEnhancedPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.24.", "error": "", "parent_id": "beaa09cb-3205-4a17-9276-3d3a6dc87f23", "metadata": {"aucs": [0.7641416353264223, 0.7500575298792137, 0.7542745978130169, 0.7366135429497158, 0.7284124223170201, 0.7224484089702878, 0.7256684632764612, 0.7611367758296872, 0.7591494647672867, 0.42762572922410336, 0.42736676246673366, 0.39792122603620383, 0.47124825946292337, 0.4773078632494133, 0.4294747663701626, 0.4196080789400547, 0.42574990612079633, 0.4745672721377636, 0.1357843825031999, 0.20380016117295463, 0.19651841485313148, 0.12755686665986943, 0.12931071529889027, 0.1159069466927114, 0.26326243553379103, 0.12494507886098194, 0.15610565186554082, 0.11052704609403086, 0.12913526979732448, 0.11248048698859114, 0.11262229875269969, 0.1342376501901601, 0.12770252247140945, 0.1377123198471829, 0.10534323207721663, 0.1193907238384927, 0.886095711369854, 0.9332784323947503, 0.9082628247899504, 0.8989481579110269, 0.9334935388755328, 0.9177582389577248, 0.9234419001165313, 0.9067581970516363, 0.9412451338906433, 0.37919311981611215, 0.4005643470070197, 0.42642673622630856, 0.38891305926393593, 0.38746270520988724, 0.38521460955960174, 0.382179645987081, 0.3910665945116346, 0.3937430871230603, 0.7568423867467413, 0.18471347110158964, 0.8093957019708192, 0.7727245818067935, 0.8064018060451449, 0.7985233041586572, 0.787953125998514, 0.6635896064252982, 0.7639252024488331, 0.12855639777394423, 0.23833059498600995, 0.18686989034220236, 0.22622669228742265, 0.18716120773333111, 0.18811937057035377, 0.22466591014885018, 0.1902776802633075, 0.19285207939414273, 0.23700326249490178, 0.21273536968883022, 0.1928789684193456, 0.18631139124478435, 0.2514051034174356, 0.23588760309162837, 0.20831736994805783, 0.3681373828887582, 0.20103976988507033, 0.1132915166169921, 0.07795429020049027, 0.09918898790217101, 0.07785846448378053, 0.06920431695326401, 0.13932716288803626, 0.18359281646679726, 0.11486814426869407, 0.14984143825077112, 0.20446680124113348, 0.21687867809339867, 0.2428401654598521, 0.2150505908506608, 0.20673516810391623, 0.2403271486427877, 0.2640780786589858, 0.22233155321103282, 0.22970290764566847, 0.05106547997928468, 0.07396217886353573, 0.05226563102235815, 0.06066503493322539, 0.07756915646271101, 0.053940861770849224, 0.0380686536990843, 0.056103180867545954, 0.0751686867551854, 0.17943304026437035, 0.18488294269174965, 0.1645573324934927, 0.2048514314611143, 0.19800641850807743, 0.20090984398286316, 0.16032644354034942, 0.1704568503778643, 0.17775392082310204, 0.5473062489120106, 0.5496870252147001, 0.5548197303782325, 0.5270188120666682, 0.5254704557841856, 0.5618638713923428, 0.533978249271424, 0.5607350200558735, 0.5899004530136014, 0.12414995219948832, 0.11521517611804066, 0.14255368365593857, 0.10007982966678175, 0.1457292709485546, 0.12248157863249454, 0.1304616752071357, 0.11584479718055263, 0.12233418239760652, 0.20529188790387953, 0.27955982255682865, 0.34171366095207223, 0.37432702600016077, 0.16969689392732545, 0.20371281793319973, 0.13939816311060838, 0.23444152944094887, 0.3043143546921766, 0.34783378597245584, 0.37237975758433517, 0.3545854331398416, 0.3689116497131666, 0.3571828755857973, 0.3515105234251893, 0.3539908501060479, 0.3598372028101766, 0.3870388204963894, 0.28051843108531493, 0.26595644767253335, 0.26731693202933016, 0.2776105102183052, 0.22660557039582596, 0.27387849149444443, 0.2475441236592617, 0.20009229914974558, 0.23713300027280748, 0.22366500461641514, 0.22419744283984888, 0.22261456977079275, 0.22653097023915114, 0.21962244038299572, 0.21512048801432115, 0.23061143177857735, 0.22934033500110806, 0.23637500379585008, 0.21424875691683243, 0.2912826793234784, 0.32685885540982584, 0.24074029654385432, 0.33544754572725577, 0.21679496409901944, 0.20170332580128159, 0.24101840270190245, 0.206167457844863, 0.18598290604933032, 0.8408856215819178, 0.1815512312185611, 0.14697448658123613, 0.19798120108097705, 0.152644917888477, 0.15247643409549672, 0.699537070191192, 0.16840450476884505, 0.7167620183015013, 0.7846804934223738, 0.743897982136775, 0.7109164536556689, 0.2064735949628459, 0.5787646929787722, 0.666264989272159, 0.714584300889898, 0.20056039965169647, 0.19416727335403594, 0.1803789226250878, 0.18520672402868854, 0.17398070021389722, 0.19026838417389424, 0.17078609357132424, 0.17387370631042054, 0.18768139790459548, 0.18321722037493693, 0.09681221460091383, 0.08840565150253621, 0.09369856951838029, 0.09994777984299053, 0.0857674781567328, 0.09195304934311954, 0.1341237217774387, 0.09055746026383527, 0.08993423606445539]}, "mutation_prompt": null}

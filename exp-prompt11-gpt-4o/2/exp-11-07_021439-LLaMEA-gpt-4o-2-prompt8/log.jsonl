{"id": "f0f1e808-3456-4342-bab6-891e8e352ef8", "solution": "", "name": "", "description": "", "configspace": "", "generation": 0, "fitness": -Infinity, "feedback": "No code was extracted.", "error": "", "parent_id": null, "metadata": {}, "mutation_prompt": null}
{"id": "b33f194a-315d-4f4c-9d80-88dce057c8ad", "solution": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.inertia_weight = 0.9  # initial inertia weight\n        self.inertia_damping = 0.99  # damping factor for inertia\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n    \n    def __call__(self, func):\n        func_calls = 0\n        while func_calls < self.budget:\n            for i in range(self.n_particles):\n                fitness = func(self.positions[i])\n                func_calls += 1\n                if fitness < self.pbest_scores[i]:\n                    self.pbest_scores[i] = fitness\n                    self.pbest_positions[i] = self.positions[i]\n                if fitness < self.gbest_score:\n                    self.gbest_score = fitness\n                    self.gbest_position = self.positions[i]\n                \n            for i in range(self.n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = self.c1 * r1 * (self.pbest_positions[i] - self.positions[i])\n                social_term = self.c2 * r2 * (self.gbest_position - self.positions[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + cognitive_term + social_term\n                # Velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -self.max_velocity, self.max_velocity)\n                \n                self.positions[i] += self.velocities[i]\n                # Ensure position bounds\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Adaptive inertia weight adjustment\n            self.inertia_weight *= self.inertia_damping", "name": "AdaptivePSO", "description": "A particle swarm optimization (PSO) algorithm leveraging adaptive inertia weight and velocity clamping for efficient exploration and exploitation.", "configspace": "", "generation": 1, "fitness": 0.31917412729897826, "feedback": "The algorithm AdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.26.", "error": "", "parent_id": "f0f1e808-3456-4342-bab6-891e8e352ef8", "metadata": {"aucs": [0.8129076191983541, 0.823994045217168, 0.80595461605642, 0.809213001020031, 0.8063572429136947, 0.19039356633432913, 0.8027460002883009, 0.8238756157795895, 0.8017559271503454, 0.6977755614283363, 0.6798377664978996, 0.6890972729154629, 0.6844757861364024, 0.662232259733778, 0.6591245392454749, 0.6840780987104091, 0.6722936381042998, 0.6635068740314938, 0.484501653022954, 0.1228040134944608, 0.16524296054090393, 0.17068886815346063, 0.16635603108698682, 0.1778714900389814, 0.1641500787725395, 0.13813824525917284, 0.6878868908547413, 0.14244217520516467, 0.14071162946172844, 0.14864819091987902, 0.15303758393787448, 0.14253062694549823, 0.15522059600630622, 0.14272100990638215, 0.1039272629910889, 0.14418067868330986, 0.9833641376449656, 0.9836639525748442, 0.985851299135645, 0.9804377258689233, 0.9787735723544941, 0.9808525796195119, 0.9860075758194194, 0.983658460217296, 0.9859573585496524, 0.4296509198714902, 0.5321187116827044, 0.5578564992889856, 0.5044812196210661, 0.5198347171878162, 0.4955366847225203, 0.12654173753228537, 0.3725259313276298, 0.08765718166277625, 0.342259254225193, 0.7469914134822229, 0.5814161382694529, 0.20283242175582483, 0.3157235521508944, 0.2052324347431933, 0.40051425083906467, 0.24409159226577348, 0.5645613058945373, 0.3102946285058188, 0.18539351708431207, 0.17499026808393225, 0.1017027358042365, 0.168233406216179, 0.35370840455292396, 0.17506768906162362, 0.3161648364886309, 0.1572791499075673, 0.1865926692450356, 0.16205085548198617, 0.16652047071778797, 0.128924839299713, 0.1881732119738001, 0.14339053725796724, 0.21905252490392957, 0.21038279829784312, 0.19556352719139614, 9.999999999998899e-05, 0.05606525158801401, 0.04996422552361257, 9.999999999998899e-05, 0.0024742299093454267, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006289867314816511, 0.09369518695738277, 0.06757146369626021, 0.0889384257403022, 0.11305811354306938, 0.03628851041252745, 0.02549860259719683, 0.11445273092477415, 0.07331726716269582, 0.04962926307202975, 0.11727043016426542, 0.12823403775254627, 0.03290100593505563, 0.06657061090455796, 0.06864967491872698, 0.06764275521677132, 0.09180687093731377, 0.1927334781599368, 0.0644440780070521, 0.2265486630244291, 0.22434215240716426, 0.13178225072788297, 0.10430609891858222, 0.23789320856379192, 0.20625084304264252, 0.07915481720334483, 0.1826226134686546, 0.07642487498557982, 0.4830096906838707, 0.48136195720804686, 0.5125452605445939, 0.5056369489717407, 0.520556854953009, 0.5641753535374543, 0.4960458739972212, 0.5359511524112615, 0.5198983085471096, 0.13392382651749535, 0.1449856783345338, 0.09662342231326948, 0.14084573042368287, 0.10525734018728217, 0.09114772901538959, 0.12246148794307188, 0.12473404628105456, 0.12174463544500336, 0.294918046285482, 0.5226544047941581, 0.22928311568954207, 0.19166630339290758, 0.3011836527594093, 0.15833339644398514, 0.36773903630243554, 0.36141169596705125, 0.21089440044537888, 0.3178678883322261, 0.37815460390543365, 0.35273110757233594, 0.3768869576868016, 0.36239150694675315, 0.3358402300833082, 0.34619327225073504, 0.4530418622007485, 0.36912538726101585, 0.2983951153980171, 0.22119237220267207, 0.3314201507198059, 0.2699021270459272, 0.29928536619757473, 0.24981217352041163, 0.23623067843656242, 0.3376748649891498, 0.2518930343534719, 0.2101262656215106, 0.2430629219899847, 0.19774993263464025, 0.24535240163142724, 0.25424368996498203, 0.21228344002664157, 0.292991486724984, 0.24517060462769336, 0.20605905764244048, 0.5816880092108925, 0.2166327914571805, 0.2374112703423571, 0.19722423204046236, 0.22983477726519763, 0.2382554661559102, 0.2230320707216754, 0.24549062856315296, 0.22126168904079946, 0.8475469139474092, 0.18530859308038872, 0.1523469798027114, 0.8506833174862986, 0.19912363906323316, 0.16648925100289724, 0.8587512426852477, 0.8385924766549271, 0.8382756188537736, 0.451473004053344, 0.15504818580322355, 0.579531660332157, 0.6978365488502367, 0.16867944821235836, 0.20940023461261337, 0.63048651616266, 0.10441922786367464, 0.6872970632898822, 0.1949472800648363, 0.21058885317528386, 0.18888249392994116, 0.19369666975350341, 0.2198406778156966, 0.20114240862048527, 0.2172796748256094, 0.19714880595552742, 0.1880691954549456, 0.12483945551097986, 0.08761243395752005, 0.07785408170475316, 0.09506575903333159, 0.09477943512140174, 0.08949229029980765, 0.11253668805780381, 0.08789046429234715, 0.0938764058817646]}, "mutation_prompt": null}
{"id": "d0bd2b4e-7b11-4d37-a47f-970b0eb29a64", "solution": "import numpy as np\n\nclass OptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.inertia_weight = 0.9  # initial inertia weight\n        self.inertia_damping = 0.99  # damping factor for inertia\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n    \n    def __call__(self, func):\n        func_calls = 0\n        while func_calls < self.budget:\n            fitnesses = np.apply_along_axis(func, 1, self.positions)\n            func_calls += self.n_particles\n\n            better_pbest_mask = fitnesses < self.pbest_scores\n            self.pbest_scores = np.where(better_pbest_mask, fitnesses, self.pbest_scores)\n            self.pbest_positions = np.where(better_pbest_mask[:, np.newaxis], self.positions, self.pbest_positions)\n\n            min_fitness_index = np.argmin(fitnesses)\n            if fitnesses[min_fitness_index] < self.gbest_score:\n                self.gbest_score = fitnesses[min_fitness_index]\n                self.gbest_position = self.positions[min_fitness_index]\n            \n            r1 = np.random.rand(self.n_particles, self.dim)\n            r2 = np.random.rand(self.n_particles, self.dim)\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = self.inertia_weight * self.velocities + cognitive_term + social_term\n\n            self.velocities = np.clip(self.velocities, -self.max_velocity, self.max_velocity)\n            self.positions += self.velocities\n            self.positions = np.clip(self.positions, self.lower_bound, self.upper_bound)\n            \n            self.inertia_weight *= self.inertia_damping", "name": "OptimizedAdaptivePSO", "description": "Optimized AdaptivePSO using vectorized operations to enhance runtime efficiency while retaining the core functionality.", "configspace": "", "generation": 2, "fitness": 0.262606619670343, "feedback": "The algorithm OptimizedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.24.", "error": "", "parent_id": "b33f194a-315d-4f4c-9d80-88dce057c8ad", "metadata": {"aucs": [0.760279929912405, 0.3589753079280563, 0.7508273312732779, 0.3196639228874246, 0.726515810676692, 0.7930255252568817, 0.809776945171653, 0.7210252792941403, 0.6961662702822926, 0.655594187858107, 0.4582811006604032, 0.6436314221278224, 0.6562925639445162, 0.03192356220246528, 0.617774569425048, 0.5858688760478905, 0.5722198333310275, 9.999999999998899e-05, 0.1377506958550937, 0.10702040340979402, 0.09218559268863558, 0.08696097260839508, 0.1477495313293402, 0.4214126776929563, 0.10942022452383449, 0.1435670530777301, 0.0875307672757577, 0.12043083792750076, 0.061830559880451386, 0.2778078401680417, 0.10588509634467591, 0.1363350169967643, 0.09850617027130337, 0.14103741807050807, 0.11326898726636425, 0.08737114328136397, 0.9827225016428057, 0.9819316949390162, 0.9857731617439167, 0.9758622083875659, 0.9830169045308665, 0.9810399070873577, 0.9839148966018925, 0.9784817851007276, 0.9853065704301522, 0.4205514077518494, 0.4953945602926296, 0.10930592659422544, 0.496282162589724, 0.45865717713566323, 0.4213935814127877, 0.08789100423243967, 0.41603547062562907, 0.4141510366540955, 0.2935455629970044, 0.3319017140192242, 0.2103693513151741, 0.19153401555609195, 0.17293916964554246, 0.20033421669129325, 0.2278072395161025, 0.12461938655261962, 0.21184373417311886, 0.1707634640419866, 0.11576656539081864, 0.1509744687582033, 0.18435531865958887, 0.1879328897269541, 0.1595418662220749, 0.1758034600032552, 0.15555046202816736, 0.10857864384541738, 0.1818600924378161, 0.1000762606082155, 0.11905234127446251, 0.12141826253160892, 0.15707834856506053, 0.15873885748510097, 0.1976360056113633, 0.2257131875049393, 0.1185763021991666, 0.0007743243063635941, 0.020068918554641435, 0.0003477106904666849, 0.005038233510120338, 0.02928021915066148, 9.999999999998899e-05, 9.999999999998899e-05, 0.03717304850702896, 9.999999999998899e-05, 0.07610353016583393, 0.08023077733483863, 0.09996021850154213, 0.09285362180730006, 0.03625053817104529, 0.003139956478648842, 0.04425708582124421, 0.07568851207104776, 0.07557998973340074, 0.07261964861844739, 0.17821445510290146, 0.09942318512960013, 9.999999999998899e-05, 9.999999999998899e-05, 0.21175867415492589, 0.08520358153132279, 0.0027448950437763964, 0.05954100854264266, 0.23319309958268275, 0.07836650249280541, 0.1953578173174656, 0.040619001134150845, 0.06573707681029262, 0.005349391129975123, 0.06191057377230935, 0.07048417256352713, 0.07486810067532679, 0.4348647900929592, 0.4033093675228724, 0.4541382252222568, 0.41896806492706407, 0.3645679674531369, 0.51204038346731, 0.5130078533344997, 0.4320040404292611, 0.34763874823414564, 0.08164361221776051, 0.1212088392926135, 0.10678861157375685, 0.10805641845598746, 0.08840579549615246, 0.09967778973670716, 0.14828197980615987, 0.081174030238084, 0.14179107498325416, 0.18151412414551638, 0.21145324923671682, 0.1560210375771871, 0.2180470203534175, 0.18281193908208437, 0.17376220252326824, 0.20043193407840365, 0.19666911692055578, 0.2904312427572161, 0.22477039660257792, 0.2576408107143875, 0.24210499439871414, 0.30134861214047426, 0.34533808469538974, 0.33724645364738537, 0.2549265393057917, 0.28218694474245587, 0.2806946963777974, 0.2446296070052868, 0.1896632406756913, 0.17043722413822127, 0.19953068050064982, 0.24433238125330325, 0.23641678400207067, 0.27990471717015375, 0.24690705522092582, 0.19608501448391036, 0.19945377236563622, 0.18698291446614967, 0.19217276251962567, 0.18581959850297303, 0.1843051782962044, 0.21013864778015223, 0.2092286120065976, 0.21731278207619886, 0.19795001786175803, 0.378511726489268, 0.19720199278077222, 0.20576015573433126, 0.19657630241256574, 0.5375811272272242, 0.19677504156773928, 0.2014497335706409, 0.17729363867418801, 0.17498282513813934, 0.7975630162253476, 0.12491234362500947, 0.14315563907069628, 0.7513798738223004, 0.19731227266919504, 0.7476863736696092, 0.7016768890982984, 0.16972862895851815, 0.8210342371373076, 0.4832056783740062, 0.15420605269180654, 0.502840008208645, 0.20675015604859048, 0.16820904701810102, 0.2089934967158732, 0.10459976665931392, 0.6299073805314636, 0.3667874527794225, 0.18392778281957378, 0.18715303994053278, 0.17557452069018853, 0.17236379830020432, 0.21004342473871018, 0.1886131141316405, 0.18647434977806698, 0.19145570087807595, 0.1954145592559836, 0.07792048621584358, 0.08288338192793343, 0.08656571871329488, 0.07726962478144928, 0.08163005690046699, 0.07879976487735552, 0.07719170151767052, 0.08666924298769951, 0.09208630086352765]}, "mutation_prompt": null}
{"id": "3ac69ec7-e2b7-4c4a-a9a8-5a2179fa91b4", "solution": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.inertia_weight = 0.9  # initial inertia weight\n        self.inertia_damping = 0.99  # damping factor for inertia\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n    \n    def __call__(self, func):\n        func_calls = 0\n        while func_calls < self.budget:\n            for i in range(self.n_particles):\n                fitness = func(self.positions[i])\n                func_calls += 1\n                if fitness < self.pbest_scores[i]:\n                    self.pbest_scores[i] = fitness\n                    self.pbest_positions[i] = self.positions[i]\n                if fitness < self.gbest_score:\n                    self.gbest_score = fitness\n                    self.gbest_position = self.positions[i]\n                \n            for i in range(self.n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = self.c1 * r1 * (self.pbest_positions[i] - self.positions[i])\n                social_term = self.c2 * r2 * (self.gbest_position - self.positions[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + cognitive_term + social_term\n                # Velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -self.max_velocity, self.max_velocity)\n                \n                self.positions[i] += self.velocities[i]\n                # Ensure position bounds\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Adaptive inertia weight adjustment\n            self.inertia_weight *= self.inertia_damping", "name": "AdaptivePSO", "description": "A particle swarm optimization (PSO) algorithm leveraging adaptive inertia weight and velocity clamping for efficient exploration and exploitation.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b33f194a-315d-4f4c-9d80-88dce057c8ad", "metadata": {"aucs": [0.8129076191983541, 0.823994045217168, 0.80595461605642, 0.809213001020031, 0.8063572429136947, 0.19039356633432913, 0.8027460002883009, 0.8238756157795895, 0.8017559271503454, 0.6977755614283363, 0.6798377664978996, 0.6890972729154629, 0.6844757861364024, 0.662232259733778, 0.6591245392454749, 0.6840780987104091, 0.6722936381042998, 0.6635068740314938, 0.484501653022954, 0.1228040134944608, 0.16524296054090393, 0.17068886815346063, 0.16635603108698682, 0.1778714900389814, 0.1641500787725395, 0.13813824525917284, 0.6878868908547413, 0.14244217520516467, 0.14071162946172844, 0.14864819091987902, 0.15303758393787448, 0.14253062694549823, 0.15522059600630622, 0.14272100990638215, 0.1039272629910889, 0.14418067868330986, 0.9833641376449656, 0.9836639525748442, 0.985851299135645, 0.9804377258689233, 0.9787735723544941, 0.9808525796195119, 0.9860075758194194, 0.983658460217296, 0.9859573585496524, 0.4296509198714902, 0.5321187116827044, 0.5578564992889856, 0.5044812196210661, 0.5198347171878162, 0.4955366847225203, 0.12654173753228537, 0.3725259313276298, 0.08765718166277625, 0.342259254225193, 0.7469914134822229, 0.5814161382694529, 0.20283242175582483, 0.3157235521508944, 0.2052324347431933, 0.40051425083906467, 0.24409159226577348, 0.5645613058945373, 0.3102946285058188, 0.18539351708431207, 0.17499026808393225, 0.1017027358042365, 0.168233406216179, 0.35370840455292396, 0.17506768906162362, 0.3161648364886309, 0.1572791499075673, 0.1865926692450356, 0.16205085548198617, 0.16652047071778797, 0.128924839299713, 0.1881732119738001, 0.14339053725796724, 0.21905252490392957, 0.21038279829784312, 0.19556352719139614, 9.999999999998899e-05, 0.05606525158801401, 0.04996422552361257, 9.999999999998899e-05, 0.0024742299093454267, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006289867314816511, 0.09369518695738277, 0.06757146369626021, 0.0889384257403022, 0.11305811354306938, 0.03628851041252745, 0.02549860259719683, 0.11445273092477415, 0.07331726716269582, 0.04962926307202975, 0.11727043016426542, 0.12823403775254627, 0.03290100593505563, 0.06657061090455796, 0.06864967491872698, 0.06764275521677132, 0.09180687093731377, 0.1927334781599368, 0.0644440780070521, 0.2265486630244291, 0.22434215240716426, 0.13178225072788297, 0.10430609891858222, 0.23789320856379192, 0.20625084304264252, 0.07915481720334483, 0.1826226134686546, 0.07642487498557982, 0.4830096906838707, 0.48136195720804686, 0.5125452605445939, 0.5056369489717407, 0.520556854953009, 0.5641753535374543, 0.4960458739972212, 0.5359511524112615, 0.5198983085471096, 0.13392382651749535, 0.1449856783345338, 0.09662342231326948, 0.14084573042368287, 0.10525734018728217, 0.09114772901538959, 0.12246148794307188, 0.12473404628105456, 0.12174463544500336, 0.294918046285482, 0.5226544047941581, 0.22928311568954207, 0.19166630339290758, 0.3011836527594093, 0.15833339644398514, 0.36773903630243554, 0.36141169596705125, 0.21089440044537888, 0.3178678883322261, 0.37815460390543365, 0.35273110757233594, 0.3768869576868016, 0.36239150694675315, 0.3358402300833082, 0.34619327225073504, 0.4530418622007485, 0.36912538726101585, 0.2983951153980171, 0.22119237220267207, 0.3314201507198059, 0.2699021270459272, 0.29928536619757473, 0.24981217352041163, 0.23623067843656242, 0.3376748649891498, 0.2518930343534719, 0.2101262656215106, 0.2430629219899847, 0.19774993263464025, 0.24535240163142724, 0.25424368996498203, 0.21228344002664157, 0.292991486724984, 0.24517060462769336, 0.20605905764244048, 0.5816880092108925, 0.2166327914571805, 0.2374112703423571, 0.19722423204046236, 0.22983477726519763, 0.2382554661559102, 0.2230320707216754, 0.24549062856315296, 0.22126168904079946, 0.8475469139474092, 0.18530859308038872, 0.1523469798027114, 0.8506833174862986, 0.19912363906323316, 0.16648925100289724, 0.8587512426852477, 0.8385924766549271, 0.8382756188537736, 0.451473004053344, 0.15504818580322355, 0.579531660332157, 0.6978365488502367, 0.16867944821235836, 0.20940023461261337, 0.63048651616266, 0.10441922786367464, 0.6872970632898822, 0.1949472800648363, 0.21058885317528386, 0.18888249392994116, 0.19369666975350341, 0.2198406778156966, 0.20114240862048527, 0.2172796748256094, 0.19714880595552742, 0.1880691954549456, 0.12483945551097986, 0.08761243395752005, 0.07785408170475316, 0.09506575903333159, 0.09477943512140174, 0.08949229029980765, 0.11253668805780381, 0.08789046429234715, 0.0938764058817646]}, "mutation_prompt": null}
{"id": "ecb3002e-912b-49d9-8fde-9d1a5d9dba97", "solution": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.inertia_weight = 0.9  # initial inertia weight\n        self.inertia_damping = 0.99  # damping factor for inertia\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n    \n    def __call__(self, func):\n        func_calls = 0\n        while func_calls < self.budget:\n            for i in range(self.n_particles):\n                fitness = func(self.positions[i])\n                func_calls += 1\n                if fitness < self.pbest_scores[i]:\n                    self.pbest_scores[i] = fitness\n                    self.pbest_positions[i] = self.positions[i]\n                if fitness < self.gbest_score:\n                    self.gbest_score = fitness\n                    self.gbest_position = self.positions[i]\n                \n            for i in range(self.n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = self.c1 * r1 * (self.pbest_positions[i] - self.positions[i])\n                social_term = self.c2 * r2 * (self.gbest_position - self.positions[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + cognitive_term + social_term\n                # Velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -self.max_velocity, self.max_velocity)\n                \n                self.positions[i] += self.velocities[i]\n                # Ensure position bounds\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Adaptive inertia weight adjustment\n            self.inertia_weight *= self.inertia_damping", "name": "AdaptivePSO", "description": "A particle swarm optimization (PSO) algorithm leveraging adaptive inertia weight and velocity clamping for efficient exploration and exploitation.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b33f194a-315d-4f4c-9d80-88dce057c8ad", "metadata": {"aucs": [0.8129076191983541, 0.823994045217168, 0.80595461605642, 0.809213001020031, 0.8063572429136947, 0.19039356633432913, 0.8027460002883009, 0.8238756157795895, 0.8017559271503454, 0.6977755614283363, 0.6798377664978996, 0.6890972729154629, 0.6844757861364024, 0.662232259733778, 0.6591245392454749, 0.6840780987104091, 0.6722936381042998, 0.6635068740314938, 0.484501653022954, 0.1228040134944608, 0.16524296054090393, 0.17068886815346063, 0.16635603108698682, 0.1778714900389814, 0.1641500787725395, 0.13813824525917284, 0.6878868908547413, 0.14244217520516467, 0.14071162946172844, 0.14864819091987902, 0.15303758393787448, 0.14253062694549823, 0.15522059600630622, 0.14272100990638215, 0.1039272629910889, 0.14418067868330986, 0.9833641376449656, 0.9836639525748442, 0.985851299135645, 0.9804377258689233, 0.9787735723544941, 0.9808525796195119, 0.9860075758194194, 0.983658460217296, 0.9859573585496524, 0.4296509198714902, 0.5321187116827044, 0.5578564992889856, 0.5044812196210661, 0.5198347171878162, 0.4955366847225203, 0.12654173753228537, 0.3725259313276298, 0.08765718166277625, 0.342259254225193, 0.7469914134822229, 0.5814161382694529, 0.20283242175582483, 0.3157235521508944, 0.2052324347431933, 0.40051425083906467, 0.24409159226577348, 0.5645613058945373, 0.3102946285058188, 0.18539351708431207, 0.17499026808393225, 0.1017027358042365, 0.168233406216179, 0.35370840455292396, 0.17506768906162362, 0.3161648364886309, 0.1572791499075673, 0.1865926692450356, 0.16205085548198617, 0.16652047071778797, 0.128924839299713, 0.1881732119738001, 0.14339053725796724, 0.21905252490392957, 0.21038279829784312, 0.19556352719139614, 9.999999999998899e-05, 0.05606525158801401, 0.04996422552361257, 9.999999999998899e-05, 0.0024742299093454267, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006289867314816511, 0.09369518695738277, 0.06757146369626021, 0.0889384257403022, 0.11305811354306938, 0.03628851041252745, 0.02549860259719683, 0.11445273092477415, 0.07331726716269582, 0.04962926307202975, 0.11727043016426542, 0.12823403775254627, 0.03290100593505563, 0.06657061090455796, 0.06864967491872698, 0.06764275521677132, 0.09180687093731377, 0.1927334781599368, 0.0644440780070521, 0.2265486630244291, 0.22434215240716426, 0.13178225072788297, 0.10430609891858222, 0.23789320856379192, 0.20625084304264252, 0.07915481720334483, 0.1826226134686546, 0.07642487498557982, 0.4830096906838707, 0.48136195720804686, 0.5125452605445939, 0.5056369489717407, 0.520556854953009, 0.5641753535374543, 0.4960458739972212, 0.5359511524112615, 0.5198983085471096, 0.13392382651749535, 0.1449856783345338, 0.09662342231326948, 0.14084573042368287, 0.10525734018728217, 0.09114772901538959, 0.12246148794307188, 0.12473404628105456, 0.12174463544500336, 0.294918046285482, 0.5226544047941581, 0.22928311568954207, 0.19166630339290758, 0.3011836527594093, 0.15833339644398514, 0.36773903630243554, 0.36141169596705125, 0.21089440044537888, 0.3178678883322261, 0.37815460390543365, 0.35273110757233594, 0.3768869576868016, 0.36239150694675315, 0.3358402300833082, 0.34619327225073504, 0.4530418622007485, 0.36912538726101585, 0.2983951153980171, 0.22119237220267207, 0.3314201507198059, 0.2699021270459272, 0.29928536619757473, 0.24981217352041163, 0.23623067843656242, 0.3376748649891498, 0.2518930343534719, 0.2101262656215106, 0.2430629219899847, 0.19774993263464025, 0.24535240163142724, 0.25424368996498203, 0.21228344002664157, 0.292991486724984, 0.24517060462769336, 0.20605905764244048, 0.5816880092108925, 0.2166327914571805, 0.2374112703423571, 0.19722423204046236, 0.22983477726519763, 0.2382554661559102, 0.2230320707216754, 0.24549062856315296, 0.22126168904079946, 0.8475469139474092, 0.18530859308038872, 0.1523469798027114, 0.8506833174862986, 0.19912363906323316, 0.16648925100289724, 0.8587512426852477, 0.8385924766549271, 0.8382756188537736, 0.451473004053344, 0.15504818580322355, 0.579531660332157, 0.6978365488502367, 0.16867944821235836, 0.20940023461261337, 0.63048651616266, 0.10441922786367464, 0.6872970632898822, 0.1949472800648363, 0.21058885317528386, 0.18888249392994116, 0.19369666975350341, 0.2198406778156966, 0.20114240862048527, 0.2172796748256094, 0.19714880595552742, 0.1880691954549456, 0.12483945551097986, 0.08761243395752005, 0.07785408170475316, 0.09506575903333159, 0.09477943512140174, 0.08949229029980765, 0.11253668805780381, 0.08789046429234715, 0.0938764058817646]}, "mutation_prompt": null}
{"id": "7674354d-f375-4776-9df6-82ca44d5d887", "solution": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.inertia_weight = 0.9  # initial inertia weight\n        self.inertia_damping = 0.99  # damping factor for inertia\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n    \n    def __call__(self, func):\n        func_calls = 0\n        while func_calls < self.budget:\n            for i in range(self.n_particles):\n                fitness = func(self.positions[i])\n                func_calls += 1\n                if fitness < self.pbest_scores[i]:\n                    self.pbest_scores[i] = fitness\n                    self.pbest_positions[i] = self.positions[i]\n                if fitness < self.gbest_score:\n                    self.gbest_score = fitness\n                    self.gbest_position = self.positions[i]\n                \n            for i in range(self.n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = self.c1 * r1 * (self.pbest_positions[i] - self.positions[i])\n                social_term = self.c2 * r2 * (self.gbest_position - self.positions[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + cognitive_term + social_term\n                # Velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -self.max_velocity, self.max_velocity)\n                \n                self.positions[i] += self.velocities[i]\n                # Ensure position bounds\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Adaptive inertia weight adjustment\n            self.inertia_weight *= self.inertia_damping", "name": "AdaptivePSO", "description": "A particle swarm optimization (PSO) algorithm leveraging adaptive inertia weight and velocity clamping for efficient exploration and exploitation.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b33f194a-315d-4f4c-9d80-88dce057c8ad", "metadata": {"aucs": [0.8129076191983541, 0.823994045217168, 0.80595461605642, 0.809213001020031, 0.8063572429136947, 0.19039356633432913, 0.8027460002883009, 0.8238756157795895, 0.8017559271503454, 0.6977755614283363, 0.6798377664978996, 0.6890972729154629, 0.6844757861364024, 0.662232259733778, 0.6591245392454749, 0.6840780987104091, 0.6722936381042998, 0.6635068740314938, 0.484501653022954, 0.1228040134944608, 0.16524296054090393, 0.17068886815346063, 0.16635603108698682, 0.1778714900389814, 0.1641500787725395, 0.13813824525917284, 0.6878868908547413, 0.14244217520516467, 0.14071162946172844, 0.14864819091987902, 0.15303758393787448, 0.14253062694549823, 0.15522059600630622, 0.14272100990638215, 0.1039272629910889, 0.14418067868330986, 0.9833641376449656, 0.9836639525748442, 0.985851299135645, 0.9804377258689233, 0.9787735723544941, 0.9808525796195119, 0.9860075758194194, 0.983658460217296, 0.9859573585496524, 0.4296509198714902, 0.5321187116827044, 0.5578564992889856, 0.5044812196210661, 0.5198347171878162, 0.4955366847225203, 0.12654173753228537, 0.3725259313276298, 0.08765718166277625, 0.342259254225193, 0.7469914134822229, 0.5814161382694529, 0.20283242175582483, 0.3157235521508944, 0.2052324347431933, 0.40051425083906467, 0.24409159226577348, 0.5645613058945373, 0.3102946285058188, 0.18539351708431207, 0.17499026808393225, 0.1017027358042365, 0.168233406216179, 0.35370840455292396, 0.17506768906162362, 0.3161648364886309, 0.1572791499075673, 0.1865926692450356, 0.16205085548198617, 0.16652047071778797, 0.128924839299713, 0.1881732119738001, 0.14339053725796724, 0.21905252490392957, 0.21038279829784312, 0.19556352719139614, 9.999999999998899e-05, 0.05606525158801401, 0.04996422552361257, 9.999999999998899e-05, 0.0024742299093454267, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006289867314816511, 0.09369518695738277, 0.06757146369626021, 0.0889384257403022, 0.11305811354306938, 0.03628851041252745, 0.02549860259719683, 0.11445273092477415, 0.07331726716269582, 0.04962926307202975, 0.11727043016426542, 0.12823403775254627, 0.03290100593505563, 0.06657061090455796, 0.06864967491872698, 0.06764275521677132, 0.09180687093731377, 0.1927334781599368, 0.0644440780070521, 0.2265486630244291, 0.22434215240716426, 0.13178225072788297, 0.10430609891858222, 0.23789320856379192, 0.20625084304264252, 0.07915481720334483, 0.1826226134686546, 0.07642487498557982, 0.4830096906838707, 0.48136195720804686, 0.5125452605445939, 0.5056369489717407, 0.520556854953009, 0.5641753535374543, 0.4960458739972212, 0.5359511524112615, 0.5198983085471096, 0.13392382651749535, 0.1449856783345338, 0.09662342231326948, 0.14084573042368287, 0.10525734018728217, 0.09114772901538959, 0.12246148794307188, 0.12473404628105456, 0.12174463544500336, 0.294918046285482, 0.5226544047941581, 0.22928311568954207, 0.19166630339290758, 0.3011836527594093, 0.15833339644398514, 0.36773903630243554, 0.36141169596705125, 0.21089440044537888, 0.3178678883322261, 0.37815460390543365, 0.35273110757233594, 0.3768869576868016, 0.36239150694675315, 0.3358402300833082, 0.34619327225073504, 0.4530418622007485, 0.36912538726101585, 0.2983951153980171, 0.22119237220267207, 0.3314201507198059, 0.2699021270459272, 0.29928536619757473, 0.24981217352041163, 0.23623067843656242, 0.3376748649891498, 0.2518930343534719, 0.2101262656215106, 0.2430629219899847, 0.19774993263464025, 0.24535240163142724, 0.25424368996498203, 0.21228344002664157, 0.292991486724984, 0.24517060462769336, 0.20605905764244048, 0.5816880092108925, 0.2166327914571805, 0.2374112703423571, 0.19722423204046236, 0.22983477726519763, 0.2382554661559102, 0.2230320707216754, 0.24549062856315296, 0.22126168904079946, 0.8475469139474092, 0.18530859308038872, 0.1523469798027114, 0.8506833174862986, 0.19912363906323316, 0.16648925100289724, 0.8587512426852477, 0.8385924766549271, 0.8382756188537736, 0.451473004053344, 0.15504818580322355, 0.579531660332157, 0.6978365488502367, 0.16867944821235836, 0.20940023461261337, 0.63048651616266, 0.10441922786367464, 0.6872970632898822, 0.1949472800648363, 0.21058885317528386, 0.18888249392994116, 0.19369666975350341, 0.2198406778156966, 0.20114240862048527, 0.2172796748256094, 0.19714880595552742, 0.1880691954549456, 0.12483945551097986, 0.08761243395752005, 0.07785408170475316, 0.09506575903333159, 0.09477943512140174, 0.08949229029980765, 0.11253668805780381, 0.08789046429234715, 0.0938764058817646]}, "mutation_prompt": null}
{"id": "b7770f2a-e61c-4d23-803c-d0a19c95c362", "solution": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.inertia_weight = 0.9  # initial inertia weight\n        self.inertia_damping = 0.99  # damping factor for inertia\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n    \n    def __call__(self, func):\n        func_calls = 0\n        while func_calls < self.budget:\n            for i in range(self.n_particles):\n                fitness = func(self.positions[i])\n                func_calls += 1\n                if fitness < self.pbest_scores[i]:\n                    self.pbest_scores[i] = fitness\n                    self.pbest_positions[i] = self.positions[i]\n                if fitness < self.gbest_score:\n                    self.gbest_score = fitness\n                    self.gbest_position = self.positions[i]\n                \n            for i in range(self.n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = self.c1 * r1 * (self.pbest_positions[i] - self.positions[i])\n                social_term = self.c2 * r2 * (self.gbest_position - self.positions[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + cognitive_term + social_term\n                # Velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -self.max_velocity, self.max_velocity)\n                \n                self.positions[i] += self.velocities[i]\n                # Ensure position bounds\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Adaptive inertia weight adjustment\n            self.inertia_weight *= self.inertia_damping", "name": "AdaptivePSO", "description": "A particle swarm optimization (PSO) algorithm leveraging adaptive inertia weight and velocity clamping for efficient exploration and exploitation.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b33f194a-315d-4f4c-9d80-88dce057c8ad", "metadata": {"aucs": [0.8129076191983541, 0.823994045217168, 0.80595461605642, 0.809213001020031, 0.8063572429136947, 0.19039356633432913, 0.8027460002883009, 0.8238756157795895, 0.8017559271503454, 0.6977755614283363, 0.6798377664978996, 0.6890972729154629, 0.6844757861364024, 0.662232259733778, 0.6591245392454749, 0.6840780987104091, 0.6722936381042998, 0.6635068740314938, 0.484501653022954, 0.1228040134944608, 0.16524296054090393, 0.17068886815346063, 0.16635603108698682, 0.1778714900389814, 0.1641500787725395, 0.13813824525917284, 0.6878868908547413, 0.14244217520516467, 0.14071162946172844, 0.14864819091987902, 0.15303758393787448, 0.14253062694549823, 0.15522059600630622, 0.14272100990638215, 0.1039272629910889, 0.14418067868330986, 0.9833641376449656, 0.9836639525748442, 0.985851299135645, 0.9804377258689233, 0.9787735723544941, 0.9808525796195119, 0.9860075758194194, 0.983658460217296, 0.9859573585496524, 0.4296509198714902, 0.5321187116827044, 0.5578564992889856, 0.5044812196210661, 0.5198347171878162, 0.4955366847225203, 0.12654173753228537, 0.3725259313276298, 0.08765718166277625, 0.342259254225193, 0.7469914134822229, 0.5814161382694529, 0.20283242175582483, 0.3157235521508944, 0.2052324347431933, 0.40051425083906467, 0.24409159226577348, 0.5645613058945373, 0.3102946285058188, 0.18539351708431207, 0.17499026808393225, 0.1017027358042365, 0.168233406216179, 0.35370840455292396, 0.17506768906162362, 0.3161648364886309, 0.1572791499075673, 0.1865926692450356, 0.16205085548198617, 0.16652047071778797, 0.128924839299713, 0.1881732119738001, 0.14339053725796724, 0.21905252490392957, 0.21038279829784312, 0.19556352719139614, 9.999999999998899e-05, 0.05606525158801401, 0.04996422552361257, 9.999999999998899e-05, 0.0024742299093454267, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006289867314816511, 0.09369518695738277, 0.06757146369626021, 0.0889384257403022, 0.11305811354306938, 0.03628851041252745, 0.02549860259719683, 0.11445273092477415, 0.07331726716269582, 0.04962926307202975, 0.11727043016426542, 0.12823403775254627, 0.03290100593505563, 0.06657061090455796, 0.06864967491872698, 0.06764275521677132, 0.09180687093731377, 0.1927334781599368, 0.0644440780070521, 0.2265486630244291, 0.22434215240716426, 0.13178225072788297, 0.10430609891858222, 0.23789320856379192, 0.20625084304264252, 0.07915481720334483, 0.1826226134686546, 0.07642487498557982, 0.4830096906838707, 0.48136195720804686, 0.5125452605445939, 0.5056369489717407, 0.520556854953009, 0.5641753535374543, 0.4960458739972212, 0.5359511524112615, 0.5198983085471096, 0.13392382651749535, 0.1449856783345338, 0.09662342231326948, 0.14084573042368287, 0.10525734018728217, 0.09114772901538959, 0.12246148794307188, 0.12473404628105456, 0.12174463544500336, 0.294918046285482, 0.5226544047941581, 0.22928311568954207, 0.19166630339290758, 0.3011836527594093, 0.15833339644398514, 0.36773903630243554, 0.36141169596705125, 0.21089440044537888, 0.3178678883322261, 0.37815460390543365, 0.35273110757233594, 0.3768869576868016, 0.36239150694675315, 0.3358402300833082, 0.34619327225073504, 0.4530418622007485, 0.36912538726101585, 0.2983951153980171, 0.22119237220267207, 0.3314201507198059, 0.2699021270459272, 0.29928536619757473, 0.24981217352041163, 0.23623067843656242, 0.3376748649891498, 0.2518930343534719, 0.2101262656215106, 0.2430629219899847, 0.19774993263464025, 0.24535240163142724, 0.25424368996498203, 0.21228344002664157, 0.292991486724984, 0.24517060462769336, 0.20605905764244048, 0.5816880092108925, 0.2166327914571805, 0.2374112703423571, 0.19722423204046236, 0.22983477726519763, 0.2382554661559102, 0.2230320707216754, 0.24549062856315296, 0.22126168904079946, 0.8475469139474092, 0.18530859308038872, 0.1523469798027114, 0.8506833174862986, 0.19912363906323316, 0.16648925100289724, 0.8587512426852477, 0.8385924766549271, 0.8382756188537736, 0.451473004053344, 0.15504818580322355, 0.579531660332157, 0.6978365488502367, 0.16867944821235836, 0.20940023461261337, 0.63048651616266, 0.10441922786367464, 0.6872970632898822, 0.1949472800648363, 0.21058885317528386, 0.18888249392994116, 0.19369666975350341, 0.2198406778156966, 0.20114240862048527, 0.2172796748256094, 0.19714880595552742, 0.1880691954549456, 0.12483945551097986, 0.08761243395752005, 0.07785408170475316, 0.09506575903333159, 0.09477943512140174, 0.08949229029980765, 0.11253668805780381, 0.08789046429234715, 0.0938764058817646]}, "mutation_prompt": null}
{"id": "23f05ce3-39eb-486c-9eb7-df4b90439c0b", "solution": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.inertia_weight = 0.9  # initial inertia weight\n        self.inertia_damping = 0.99  # damping factor for inertia\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n    \n    def __call__(self, func):\n        func_calls = 0\n        while func_calls < self.budget:\n            for i in range(self.n_particles):\n                fitness = func(self.positions[i])\n                func_calls += 1\n                if fitness < self.pbest_scores[i]:\n                    self.pbest_scores[i] = fitness\n                    self.pbest_positions[i] = self.positions[i]\n                if fitness < self.gbest_score:\n                    self.gbest_score = fitness\n                    self.gbest_position = self.positions[i]\n                \n            for i in range(self.n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = self.c1 * r1 * (self.pbest_positions[i] - self.positions[i])\n                social_term = self.c2 * r2 * (self.gbest_position - self.positions[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + cognitive_term + social_term\n                # Velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -self.max_velocity, self.max_velocity)\n                \n                self.positions[i] += self.velocities[i]\n                # Ensure position bounds\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Adaptive inertia weight adjustment\n            self.inertia_weight *= self.inertia_damping", "name": "AdaptivePSO", "description": "A particle swarm optimization (PSO) algorithm leveraging adaptive inertia weight and velocity clamping for efficient exploration and exploitation.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b33f194a-315d-4f4c-9d80-88dce057c8ad", "metadata": {"aucs": [0.8129076191983541, 0.823994045217168, 0.80595461605642, 0.809213001020031, 0.8063572429136947, 0.19039356633432913, 0.8027460002883009, 0.8238756157795895, 0.8017559271503454, 0.6977755614283363, 0.6798377664978996, 0.6890972729154629, 0.6844757861364024, 0.662232259733778, 0.6591245392454749, 0.6840780987104091, 0.6722936381042998, 0.6635068740314938, 0.484501653022954, 0.1228040134944608, 0.16524296054090393, 0.17068886815346063, 0.16635603108698682, 0.1778714900389814, 0.1641500787725395, 0.13813824525917284, 0.6878868908547413, 0.14244217520516467, 0.14071162946172844, 0.14864819091987902, 0.15303758393787448, 0.14253062694549823, 0.15522059600630622, 0.14272100990638215, 0.1039272629910889, 0.14418067868330986, 0.9833641376449656, 0.9836639525748442, 0.985851299135645, 0.9804377258689233, 0.9787735723544941, 0.9808525796195119, 0.9860075758194194, 0.983658460217296, 0.9859573585496524, 0.4296509198714902, 0.5321187116827044, 0.5578564992889856, 0.5044812196210661, 0.5198347171878162, 0.4955366847225203, 0.12654173753228537, 0.3725259313276298, 0.08765718166277625, 0.342259254225193, 0.7469914134822229, 0.5814161382694529, 0.20283242175582483, 0.3157235521508944, 0.2052324347431933, 0.40051425083906467, 0.24409159226577348, 0.5645613058945373, 0.3102946285058188, 0.18539351708431207, 0.17499026808393225, 0.1017027358042365, 0.168233406216179, 0.35370840455292396, 0.17506768906162362, 0.3161648364886309, 0.1572791499075673, 0.1865926692450356, 0.16205085548198617, 0.16652047071778797, 0.128924839299713, 0.1881732119738001, 0.14339053725796724, 0.21905252490392957, 0.21038279829784312, 0.19556352719139614, 9.999999999998899e-05, 0.05606525158801401, 0.04996422552361257, 9.999999999998899e-05, 0.0024742299093454267, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006289867314816511, 0.09369518695738277, 0.06757146369626021, 0.0889384257403022, 0.11305811354306938, 0.03628851041252745, 0.02549860259719683, 0.11445273092477415, 0.07331726716269582, 0.04962926307202975, 0.11727043016426542, 0.12823403775254627, 0.03290100593505563, 0.06657061090455796, 0.06864967491872698, 0.06764275521677132, 0.09180687093731377, 0.1927334781599368, 0.0644440780070521, 0.2265486630244291, 0.22434215240716426, 0.13178225072788297, 0.10430609891858222, 0.23789320856379192, 0.20625084304264252, 0.07915481720334483, 0.1826226134686546, 0.07642487498557982, 0.4830096906838707, 0.48136195720804686, 0.5125452605445939, 0.5056369489717407, 0.520556854953009, 0.5641753535374543, 0.4960458739972212, 0.5359511524112615, 0.5198983085471096, 0.13392382651749535, 0.1449856783345338, 0.09662342231326948, 0.14084573042368287, 0.10525734018728217, 0.09114772901538959, 0.12246148794307188, 0.12473404628105456, 0.12174463544500336, 0.294918046285482, 0.5226544047941581, 0.22928311568954207, 0.19166630339290758, 0.3011836527594093, 0.15833339644398514, 0.36773903630243554, 0.36141169596705125, 0.21089440044537888, 0.3178678883322261, 0.37815460390543365, 0.35273110757233594, 0.3768869576868016, 0.36239150694675315, 0.3358402300833082, 0.34619327225073504, 0.4530418622007485, 0.36912538726101585, 0.2983951153980171, 0.22119237220267207, 0.3314201507198059, 0.2699021270459272, 0.29928536619757473, 0.24981217352041163, 0.23623067843656242, 0.3376748649891498, 0.2518930343534719, 0.2101262656215106, 0.2430629219899847, 0.19774993263464025, 0.24535240163142724, 0.25424368996498203, 0.21228344002664157, 0.292991486724984, 0.24517060462769336, 0.20605905764244048, 0.5816880092108925, 0.2166327914571805, 0.2374112703423571, 0.19722423204046236, 0.22983477726519763, 0.2382554661559102, 0.2230320707216754, 0.24549062856315296, 0.22126168904079946, 0.8475469139474092, 0.18530859308038872, 0.1523469798027114, 0.8506833174862986, 0.19912363906323316, 0.16648925100289724, 0.8587512426852477, 0.8385924766549271, 0.8382756188537736, 0.451473004053344, 0.15504818580322355, 0.579531660332157, 0.6978365488502367, 0.16867944821235836, 0.20940023461261337, 0.63048651616266, 0.10441922786367464, 0.6872970632898822, 0.1949472800648363, 0.21058885317528386, 0.18888249392994116, 0.19369666975350341, 0.2198406778156966, 0.20114240862048527, 0.2172796748256094, 0.19714880595552742, 0.1880691954549456, 0.12483945551097986, 0.08761243395752005, 0.07785408170475316, 0.09506575903333159, 0.09477943512140174, 0.08949229029980765, 0.11253668805780381, 0.08789046429234715, 0.0938764058817646]}, "mutation_prompt": null}
{"id": "49e85927-7336-4010-ab9c-dc9aa1feaf11", "solution": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.inertia_weight = 0.9  # initial inertia weight\n        self.inertia_damping = 0.99  # damping factor for inertia\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n    \n    def __call__(self, func):\n        func_calls = 0\n        while func_calls < self.budget:\n            for i in range(self.n_particles):\n                fitness = func(self.positions[i])\n                func_calls += 1\n                if fitness < self.pbest_scores[i]:\n                    self.pbest_scores[i] = fitness\n                    self.pbest_positions[i] = self.positions[i]\n                if fitness < self.gbest_score:\n                    self.gbest_score = fitness\n                    self.gbest_position = self.positions[i]\n                \n            for i in range(self.n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = self.c1 * r1 * (self.pbest_positions[i] - self.positions[i])\n                social_term = self.c2 * r2 * (self.gbest_position - self.positions[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + cognitive_term + social_term\n                # Velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -self.max_velocity, self.max_velocity)\n                \n                self.positions[i] += self.velocities[i]\n                # Ensure position bounds\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Adaptive inertia weight adjustment\n            self.inertia_weight *= self.inertia_damping", "name": "AdaptivePSO", "description": "A particle swarm optimization (PSO) algorithm leveraging adaptive inertia weight and velocity clamping for efficient exploration and exploitation.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b33f194a-315d-4f4c-9d80-88dce057c8ad", "metadata": {"aucs": [0.8129076191983541, 0.823994045217168, 0.80595461605642, 0.809213001020031, 0.8063572429136947, 0.19039356633432913, 0.8027460002883009, 0.8238756157795895, 0.8017559271503454, 0.6977755614283363, 0.6798377664978996, 0.6890972729154629, 0.6844757861364024, 0.662232259733778, 0.6591245392454749, 0.6840780987104091, 0.6722936381042998, 0.6635068740314938, 0.484501653022954, 0.1228040134944608, 0.16524296054090393, 0.17068886815346063, 0.16635603108698682, 0.1778714900389814, 0.1641500787725395, 0.13813824525917284, 0.6878868908547413, 0.14244217520516467, 0.14071162946172844, 0.14864819091987902, 0.15303758393787448, 0.14253062694549823, 0.15522059600630622, 0.14272100990638215, 0.1039272629910889, 0.14418067868330986, 0.9833641376449656, 0.9836639525748442, 0.985851299135645, 0.9804377258689233, 0.9787735723544941, 0.9808525796195119, 0.9860075758194194, 0.983658460217296, 0.9859573585496524, 0.4296509198714902, 0.5321187116827044, 0.5578564992889856, 0.5044812196210661, 0.5198347171878162, 0.4955366847225203, 0.12654173753228537, 0.3725259313276298, 0.08765718166277625, 0.342259254225193, 0.7469914134822229, 0.5814161382694529, 0.20283242175582483, 0.3157235521508944, 0.2052324347431933, 0.40051425083906467, 0.24409159226577348, 0.5645613058945373, 0.3102946285058188, 0.18539351708431207, 0.17499026808393225, 0.1017027358042365, 0.168233406216179, 0.35370840455292396, 0.17506768906162362, 0.3161648364886309, 0.1572791499075673, 0.1865926692450356, 0.16205085548198617, 0.16652047071778797, 0.128924839299713, 0.1881732119738001, 0.14339053725796724, 0.21905252490392957, 0.21038279829784312, 0.19556352719139614, 9.999999999998899e-05, 0.05606525158801401, 0.04996422552361257, 9.999999999998899e-05, 0.0024742299093454267, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006289867314816511, 0.09369518695738277, 0.06757146369626021, 0.0889384257403022, 0.11305811354306938, 0.03628851041252745, 0.02549860259719683, 0.11445273092477415, 0.07331726716269582, 0.04962926307202975, 0.11727043016426542, 0.12823403775254627, 0.03290100593505563, 0.06657061090455796, 0.06864967491872698, 0.06764275521677132, 0.09180687093731377, 0.1927334781599368, 0.0644440780070521, 0.2265486630244291, 0.22434215240716426, 0.13178225072788297, 0.10430609891858222, 0.23789320856379192, 0.20625084304264252, 0.07915481720334483, 0.1826226134686546, 0.07642487498557982, 0.4830096906838707, 0.48136195720804686, 0.5125452605445939, 0.5056369489717407, 0.520556854953009, 0.5641753535374543, 0.4960458739972212, 0.5359511524112615, 0.5198983085471096, 0.13392382651749535, 0.1449856783345338, 0.09662342231326948, 0.14084573042368287, 0.10525734018728217, 0.09114772901538959, 0.12246148794307188, 0.12473404628105456, 0.12174463544500336, 0.294918046285482, 0.5226544047941581, 0.22928311568954207, 0.19166630339290758, 0.3011836527594093, 0.15833339644398514, 0.36773903630243554, 0.36141169596705125, 0.21089440044537888, 0.3178678883322261, 0.37815460390543365, 0.35273110757233594, 0.3768869576868016, 0.36239150694675315, 0.3358402300833082, 0.34619327225073504, 0.4530418622007485, 0.36912538726101585, 0.2983951153980171, 0.22119237220267207, 0.3314201507198059, 0.2699021270459272, 0.29928536619757473, 0.24981217352041163, 0.23623067843656242, 0.3376748649891498, 0.2518930343534719, 0.2101262656215106, 0.2430629219899847, 0.19774993263464025, 0.24535240163142724, 0.25424368996498203, 0.21228344002664157, 0.292991486724984, 0.24517060462769336, 0.20605905764244048, 0.5816880092108925, 0.2166327914571805, 0.2374112703423571, 0.19722423204046236, 0.22983477726519763, 0.2382554661559102, 0.2230320707216754, 0.24549062856315296, 0.22126168904079946, 0.8475469139474092, 0.18530859308038872, 0.1523469798027114, 0.8506833174862986, 0.19912363906323316, 0.16648925100289724, 0.8587512426852477, 0.8385924766549271, 0.8382756188537736, 0.451473004053344, 0.15504818580322355, 0.579531660332157, 0.6978365488502367, 0.16867944821235836, 0.20940023461261337, 0.63048651616266, 0.10441922786367464, 0.6872970632898822, 0.1949472800648363, 0.21058885317528386, 0.18888249392994116, 0.19369666975350341, 0.2198406778156966, 0.20114240862048527, 0.2172796748256094, 0.19714880595552742, 0.1880691954549456, 0.12483945551097986, 0.08761243395752005, 0.07785408170475316, 0.09506575903333159, 0.09477943512140174, 0.08949229029980765, 0.11253668805780381, 0.08789046429234715, 0.0938764058817646]}, "mutation_prompt": null}
{"id": "dc72435d-19ec-4092-b69b-7802f9a08218", "solution": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.inertia_weight = 0.9  # initial inertia weight\n        self.inertia_damping = 0.99  # damping factor for inertia\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n    \n    def __call__(self, func):\n        func_calls = 0\n        while func_calls < self.budget:\n            for i in range(self.n_particles):\n                fitness = func(self.positions[i])\n                func_calls += 1\n                if fitness < self.pbest_scores[i]:\n                    self.pbest_scores[i] = fitness\n                    self.pbest_positions[i] = self.positions[i]\n                if fitness < self.gbest_score:\n                    self.gbest_score = fitness\n                    self.gbest_position = self.positions[i]\n                \n            for i in range(self.n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = self.c1 * r1 * (self.pbest_positions[i] - self.positions[i])\n                social_term = self.c2 * r2 * (self.gbest_position - self.positions[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + cognitive_term + social_term\n                # Velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -self.max_velocity, self.max_velocity)\n                \n                self.positions[i] += self.velocities[i]\n                # Ensure position bounds\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Adaptive inertia weight adjustment\n            self.inertia_weight *= self.inertia_damping", "name": "AdaptivePSO", "description": "A particle swarm optimization (PSO) algorithm leveraging adaptive inertia weight and velocity clamping for efficient exploration and exploitation.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b33f194a-315d-4f4c-9d80-88dce057c8ad", "metadata": {"aucs": [0.8129076191983541, 0.823994045217168, 0.80595461605642, 0.809213001020031, 0.8063572429136947, 0.19039356633432913, 0.8027460002883009, 0.8238756157795895, 0.8017559271503454, 0.6977755614283363, 0.6798377664978996, 0.6890972729154629, 0.6844757861364024, 0.662232259733778, 0.6591245392454749, 0.6840780987104091, 0.6722936381042998, 0.6635068740314938, 0.484501653022954, 0.1228040134944608, 0.16524296054090393, 0.17068886815346063, 0.16635603108698682, 0.1778714900389814, 0.1641500787725395, 0.13813824525917284, 0.6878868908547413, 0.14244217520516467, 0.14071162946172844, 0.14864819091987902, 0.15303758393787448, 0.14253062694549823, 0.15522059600630622, 0.14272100990638215, 0.1039272629910889, 0.14418067868330986, 0.9833641376449656, 0.9836639525748442, 0.985851299135645, 0.9804377258689233, 0.9787735723544941, 0.9808525796195119, 0.9860075758194194, 0.983658460217296, 0.9859573585496524, 0.4296509198714902, 0.5321187116827044, 0.5578564992889856, 0.5044812196210661, 0.5198347171878162, 0.4955366847225203, 0.12654173753228537, 0.3725259313276298, 0.08765718166277625, 0.342259254225193, 0.7469914134822229, 0.5814161382694529, 0.20283242175582483, 0.3157235521508944, 0.2052324347431933, 0.40051425083906467, 0.24409159226577348, 0.5645613058945373, 0.3102946285058188, 0.18539351708431207, 0.17499026808393225, 0.1017027358042365, 0.168233406216179, 0.35370840455292396, 0.17506768906162362, 0.3161648364886309, 0.1572791499075673, 0.1865926692450356, 0.16205085548198617, 0.16652047071778797, 0.128924839299713, 0.1881732119738001, 0.14339053725796724, 0.21905252490392957, 0.21038279829784312, 0.19556352719139614, 9.999999999998899e-05, 0.05606525158801401, 0.04996422552361257, 9.999999999998899e-05, 0.0024742299093454267, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006289867314816511, 0.09369518695738277, 0.06757146369626021, 0.0889384257403022, 0.11305811354306938, 0.03628851041252745, 0.02549860259719683, 0.11445273092477415, 0.07331726716269582, 0.04962926307202975, 0.11727043016426542, 0.12823403775254627, 0.03290100593505563, 0.06657061090455796, 0.06864967491872698, 0.06764275521677132, 0.09180687093731377, 0.1927334781599368, 0.0644440780070521, 0.2265486630244291, 0.22434215240716426, 0.13178225072788297, 0.10430609891858222, 0.23789320856379192, 0.20625084304264252, 0.07915481720334483, 0.1826226134686546, 0.07642487498557982, 0.4830096906838707, 0.48136195720804686, 0.5125452605445939, 0.5056369489717407, 0.520556854953009, 0.5641753535374543, 0.4960458739972212, 0.5359511524112615, 0.5198983085471096, 0.13392382651749535, 0.1449856783345338, 0.09662342231326948, 0.14084573042368287, 0.10525734018728217, 0.09114772901538959, 0.12246148794307188, 0.12473404628105456, 0.12174463544500336, 0.294918046285482, 0.5226544047941581, 0.22928311568954207, 0.19166630339290758, 0.3011836527594093, 0.15833339644398514, 0.36773903630243554, 0.36141169596705125, 0.21089440044537888, 0.3178678883322261, 0.37815460390543365, 0.35273110757233594, 0.3768869576868016, 0.36239150694675315, 0.3358402300833082, 0.34619327225073504, 0.4530418622007485, 0.36912538726101585, 0.2983951153980171, 0.22119237220267207, 0.3314201507198059, 0.2699021270459272, 0.29928536619757473, 0.24981217352041163, 0.23623067843656242, 0.3376748649891498, 0.2518930343534719, 0.2101262656215106, 0.2430629219899847, 0.19774993263464025, 0.24535240163142724, 0.25424368996498203, 0.21228344002664157, 0.292991486724984, 0.24517060462769336, 0.20605905764244048, 0.5816880092108925, 0.2166327914571805, 0.2374112703423571, 0.19722423204046236, 0.22983477726519763, 0.2382554661559102, 0.2230320707216754, 0.24549062856315296, 0.22126168904079946, 0.8475469139474092, 0.18530859308038872, 0.1523469798027114, 0.8506833174862986, 0.19912363906323316, 0.16648925100289724, 0.8587512426852477, 0.8385924766549271, 0.8382756188537736, 0.451473004053344, 0.15504818580322355, 0.579531660332157, 0.6978365488502367, 0.16867944821235836, 0.20940023461261337, 0.63048651616266, 0.10441922786367464, 0.6872970632898822, 0.1949472800648363, 0.21058885317528386, 0.18888249392994116, 0.19369666975350341, 0.2198406778156966, 0.20114240862048527, 0.2172796748256094, 0.19714880595552742, 0.1880691954549456, 0.12483945551097986, 0.08761243395752005, 0.07785408170475316, 0.09506575903333159, 0.09477943512140174, 0.08949229029980765, 0.11253668805780381, 0.08789046429234715, 0.0938764058817646]}, "mutation_prompt": null}
{"id": "e8d2af20-deb1-41ab-8fba-afc5e10ab4c0", "solution": "import numpy as np\n\nclass ImprovedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n    \n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local copy for quicker access\n        while func_calls < self.budget:\n            fitness_values = np.apply_along_axis(func, 1, self.positions)\n            func_calls += self.n_particles\n            \n            for i in range(self.n_particles):\n                fitness = fitness_values[i]\n                if fitness < self.pbest_scores[i]:\n                    self.pbest_scores[i] = fitness\n                    self.pbest_positions[i] = self.positions[i]\n                if fitness < self.gbest_score:\n                    self.gbest_score = fitness\n                    self.gbest_position = self.positions[i]\n            \n            r1, r2 = np.random.rand(self.n_particles, self.dim), np.random.rand(self.n_particles, self.dim)\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = inertia_weight * self.velocities + cognitive_term + social_term\n            \n            # Velocity clamping\n            np.clip(self.velocities, -self.max_velocity, self.max_velocity, out=self.velocities)\n            self.positions += self.velocities\n            \n            # Ensure position bounds\n            np.clip(self.positions, self.lower_bound, self.upper_bound, out=self.positions)\n            \n            # Adaptive inertia weight adjustment\n            inertia_weight *= self.inertia_damping", "name": "ImprovedAdaptivePSO", "description": "A particle swarm optimization (PSO) algorithm with optimized loop handling and reduced function calls for better runtime efficiency.", "configspace": "", "generation": 10, "fitness": 0.31747320990865674, "feedback": "The algorithm ImprovedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.27.", "error": "", "parent_id": "b33f194a-315d-4f4c-9d80-88dce057c8ad", "metadata": {"aucs": [0.8213912857876584, 0.8409796347570903, 0.8149765644433363, 0.7937980611004581, 0.8231818205507542, 0.8269034210509266, 0.8158049194245488, 0.8099803757495705, 0.8151739412549615, 0.7122703790793359, 0.7007204024300275, 0.6696083608767649, 0.696150206683841, 0.6750706981053015, 0.6564666190845285, 0.6726318849734901, 0.7009410106618811, 0.6786353433494112, 0.14639199120609936, 0.12279256066836697, 0.16143868928214433, 0.5153229407602276, 0.17784361014765693, 0.16567515139904643, 0.17123515217114105, 0.5850301298849623, 0.15865755274609528, 0.10861837305642241, 0.10719299715230135, 0.14896404118641637, 0.12459360541273778, 0.11297440094499911, 0.10898886250050088, 0.13900145998962976, 0.1140315308301002, 0.12443038718082611, 0.9827225016428057, 0.9819316949390162, 0.9857731617439167, 0.9758622083875659, 0.9830169045308665, 0.9810399070873577, 0.9839148966018925, 0.9784817851007276, 0.9853065704301522, 0.5283261697654167, 0.6051756299294768, 0.4403559243633517, 0.5436263068779656, 0.5815304629324147, 0.5381793319349606, 0.5207024242360219, 0.5046217328773088, 0.4708815854180206, 0.3371140637671671, 0.6884278357986671, 0.6882601810560005, 0.1922709918765798, 0.2769343323496355, 0.1929322575384026, 0.2341251828278147, 0.4503572625312817, 0.23069869647911745, 0.17997957768634643, 0.16657752693766292, 0.18577116193690668, 0.16864957901506972, 0.17846040734401591, 0.16891813080443574, 0.25415858045720763, 0.23048246342695156, 0.21816305488175858, 0.12834325437414829, 0.1736388664832601, 0.190960824011572, 0.17994248297343618, 0.17150343252479594, 0.18361795604230258, 0.18808094643694562, 0.29884399263845973, 0.11346819851239509, 9.999999999998899e-05, 0.00020992745196635187, 9.999999999998899e-05, 0.00017668600198361695, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.022470422697214, 0.19331189893052758, 0.07254598204162288, 0.07937843716691695, 0.09331178352512892, 0.07910447572401358, 0.01914500730226587, 0.11160395683052249, 0.10459423938207879, 0.12265889422761289, 0.12323473491882342, 0.06890653420582726, 0.18502314597175074, 0.12164726538377835, 0.10312721067041641, 0.06832846667924874, 0.12188768436696795, 0.06456645418893148, 0.06347112678226075, 0.170462371120374, 0.07628764314457692, 0.07968538727987273, 0.12991044641244975, 0.08557110185289696, 0.2363579863038483, 0.07859012769106011, 0.07578862881115633, 0.07953200316648579, 0.4951009166407657, 0.5008198958644793, 0.5134528989649874, 0.5202130676392078, 0.5649685117647996, 0.542412489778841, 0.52201186261413, 0.5139272384747728, 0.5196288078208924, 0.11014308289659636, 0.11741115829591486, 0.13471557980172988, 0.1360486864791235, 0.12246044449397431, 0.11971112593567867, 0.15011800553600496, 0.09857909383466246, 0.10743685087799626, 0.3015602945462478, 0.24347282124948744, 0.3390035854782574, 0.18858426635765546, 0.19673506472452384, 0.17036984070306227, 0.21173552412570984, 0.2580113185245514, 0.2114135043299491, 0.3776857386858915, 0.41584473569986613, 0.2904477208195466, 0.27020317980144315, 0.33366509999384375, 0.332664669508006, 0.3802582700075676, 0.4491718272216917, 0.3415732011463546, 0.30646878082550943, 0.2470176229806722, 0.25024421245841477, 0.293104887292274, 0.27674333823835673, 0.24256591815302897, 0.3395947774261405, 0.3205793192612332, 0.2665197804131356, 0.23808120289680013, 0.20951656906253613, 0.21357837318712924, 0.2304642538969146, 0.2119194810367232, 0.21542652751166358, 0.2149119370972713, 0.19140661271765524, 0.19695973955899404, 0.238143982564762, 0.21878505144092664, 0.24122112753296343, 0.2171709727042902, 0.21657933301023946, 0.19183304417543245, 0.23937322657372806, 0.21611007770078527, 0.7028729074374189, 0.865330442293526, 0.7517708596093984, 0.18571831784092896, 0.8712181348324348, 0.19833298153807588, 0.8395352409639489, 0.12194337802192601, 0.16978895536446015, 0.8748159181678921, 0.8297703673311169, 0.1548837017195116, 0.7851271111510923, 0.209912835579797, 0.16814772902325936, 0.21053962291236306, 0.10397072032379018, 0.16573072849039305, 0.4912340159142141, 0.22642493746038805, 0.1838964739128035, 0.22061974323478983, 0.17064952660442445, 0.20133661978413098, 0.21796337145921618, 0.19281349191554897, 0.2106338825266002, 0.18941770160318483, 0.09950645467464603, 0.10003878896600815, 0.0916205549343333, 0.08067203985676585, 0.08437597369988303, 0.09064341182736158, 0.08908739596153825, 0.09838226377882897, 0.08811737357034477]}, "mutation_prompt": null}
{"id": "11300f81-1972-47b4-ab45-a9e6934615e9", "solution": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.inertia_weight = 0.9  # initial inertia weight\n        self.inertia_damping = 0.99  # damping factor for inertia\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n    \n    def __call__(self, func):\n        func_calls = 0\n        while func_calls < self.budget:\n            fitness_values = np.apply_along_axis(func, 1, self.positions)\n            func_calls += self.n_particles\n\n            for i in range(self.n_particles):\n                fitness = fitness_values[i]\n                if fitness < self.pbest_scores[i]:\n                    self.pbest_scores[i] = fitness\n                    self.pbest_positions[i] = self.positions[i]\n                if fitness < self.gbest_score:\n                    self.gbest_score = fitness\n                    self.gbest_position = self.positions[i]\n\n            r1, r2 = np.random.rand(2, self.n_particles, self.dim)\n            cognitive_terms = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_terms = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = self.inertia_weight * self.velocities + cognitive_terms + social_terms\n\n            self.velocities = np.clip(self.velocities, -self.max_velocity, self.max_velocity)\n            self.positions += self.velocities\n            self.positions = np.clip(self.positions, self.lower_bound, self.upper_bound)\n\n            self.inertia_weight *= self.inertia_damping", "name": "AdaptivePSO", "description": "An optimized version of AdaptivePSO with enhanced runtime efficiency through reduced redundant computations and improved loop structure.", "configspace": "", "generation": 11, "fitness": 0.262606619670343, "feedback": "The algorithm AdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.24.", "error": "", "parent_id": "b33f194a-315d-4f4c-9d80-88dce057c8ad", "metadata": {"aucs": [0.760279929912405, 0.3589753079280563, 0.7508273312732779, 0.3196639228874246, 0.726515810676692, 0.7930255252568817, 0.809776945171653, 0.7210252792941403, 0.6961662702822926, 0.655594187858107, 0.4582811006604032, 0.6436314221278224, 0.6562925639445162, 0.03192356220246528, 0.617774569425048, 0.5858688760478905, 0.5722198333310275, 9.999999999998899e-05, 0.1377506958550937, 0.10702040340979402, 0.09218559268863558, 0.08696097260839508, 0.1477495313293402, 0.4214126776929563, 0.10942022452383449, 0.1435670530777301, 0.0875307672757577, 0.12043083792750076, 0.061830559880451386, 0.2778078401680417, 0.10588509634467591, 0.1363350169967643, 0.09850617027130337, 0.14103741807050807, 0.11326898726636425, 0.08737114328136397, 0.9827225016428057, 0.9819316949390162, 0.9857731617439167, 0.9758622083875659, 0.9830169045308665, 0.9810399070873577, 0.9839148966018925, 0.9784817851007276, 0.9853065704301522, 0.4205514077518494, 0.4953945602926296, 0.10930592659422544, 0.496282162589724, 0.45865717713566323, 0.4213935814127877, 0.08789100423243967, 0.41603547062562907, 0.4141510366540955, 0.2935455629970044, 0.3319017140192242, 0.2103693513151741, 0.19153401555609195, 0.17293916964554246, 0.20033421669129325, 0.2278072395161025, 0.12461938655261962, 0.21184373417311886, 0.1707634640419866, 0.11576656539081864, 0.1509744687582033, 0.18435531865958887, 0.1879328897269541, 0.1595418662220749, 0.1758034600032552, 0.15555046202816736, 0.10857864384541738, 0.1818600924378161, 0.1000762606082155, 0.11905234127446251, 0.12141826253160892, 0.15707834856506053, 0.15873885748510097, 0.1976360056113633, 0.2257131875049393, 0.1185763021991666, 0.0007743243063635941, 0.020068918554641435, 0.0003477106904666849, 0.005038233510120338, 0.02928021915066148, 9.999999999998899e-05, 9.999999999998899e-05, 0.03717304850702896, 9.999999999998899e-05, 0.07610353016583393, 0.08023077733483863, 0.09996021850154213, 0.09285362180730006, 0.03625053817104529, 0.003139956478648842, 0.04425708582124421, 0.07568851207104776, 0.07557998973340074, 0.07261964861844739, 0.17821445510290146, 0.09942318512960013, 9.999999999998899e-05, 9.999999999998899e-05, 0.21175867415492589, 0.08520358153132279, 0.0027448950437763964, 0.05954100854264266, 0.23319309958268275, 0.07836650249280541, 0.1953578173174656, 0.040619001134150845, 0.06573707681029262, 0.005349391129975123, 0.06191057377230935, 0.07048417256352713, 0.07486810067532679, 0.4348647900929592, 0.4033093675228724, 0.4541382252222568, 0.41896806492706407, 0.3645679674531369, 0.51204038346731, 0.5130078533344997, 0.4320040404292611, 0.34763874823414564, 0.08164361221776051, 0.1212088392926135, 0.10678861157375685, 0.10805641845598746, 0.08840579549615246, 0.09967778973670716, 0.14828197980615987, 0.081174030238084, 0.14179107498325416, 0.18151412414551638, 0.21145324923671682, 0.1560210375771871, 0.2180470203534175, 0.18281193908208437, 0.17376220252326824, 0.20043193407840365, 0.19666911692055578, 0.2904312427572161, 0.22477039660257792, 0.2576408107143875, 0.24210499439871414, 0.30134861214047426, 0.34533808469538974, 0.33724645364738537, 0.2549265393057917, 0.28218694474245587, 0.2806946963777974, 0.2446296070052868, 0.1896632406756913, 0.17043722413822127, 0.19953068050064982, 0.24433238125330325, 0.23641678400207067, 0.27990471717015375, 0.24690705522092582, 0.19608501448391036, 0.19945377236563622, 0.18698291446614967, 0.19217276251962567, 0.18581959850297303, 0.1843051782962044, 0.21013864778015223, 0.2092286120065976, 0.21731278207619886, 0.19795001786175803, 0.378511726489268, 0.19720199278077222, 0.20576015573433126, 0.19657630241256574, 0.5375811272272242, 0.19677504156773928, 0.2014497335706409, 0.17729363867418801, 0.17498282513813934, 0.7975630162253476, 0.12491234362500947, 0.14315563907069628, 0.7513798738223004, 0.19731227266919504, 0.7476863736696092, 0.7016768890982984, 0.16972862895851815, 0.8210342371373076, 0.4832056783740062, 0.15420605269180654, 0.502840008208645, 0.20675015604859048, 0.16820904701810102, 0.2089934967158732, 0.10459976665931392, 0.6299073805314636, 0.3667874527794225, 0.18392778281957378, 0.18715303994053278, 0.17557452069018853, 0.17236379830020432, 0.21004342473871018, 0.1886131141316405, 0.18647434977806698, 0.19145570087807595, 0.1954145592559836, 0.07792048621584358, 0.08288338192793343, 0.08656571871329488, 0.07726962478144928, 0.08163005690046699, 0.07879976487735552, 0.07719170151767052, 0.08666924298769951, 0.09208630086352765]}, "mutation_prompt": null}
{"id": "1f32a1e2-adee-4277-ba4b-92d137c4bb10", "solution": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.inertia_weight = 0.9  # initial inertia weight\n        self.inertia_damping = 0.99  # damping factor for inertia\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n    \n    def __call__(self, func):\n        func_calls = 0\n        while func_calls < self.budget:\n            for i in range(self.n_particles):\n                fitness = func(self.positions[i])\n                func_calls += 1\n                if fitness < self.pbest_scores[i]:\n                    self.pbest_scores[i] = fitness\n                    self.pbest_positions[i] = self.positions[i]\n                if fitness < self.gbest_score:\n                    self.gbest_score = fitness\n                    self.gbest_position = self.positions[i]\n                \n            for i in range(self.n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = self.c1 * r1 * (self.pbest_positions[i] - self.positions[i])\n                social_term = self.c2 * r2 * (self.gbest_position - self.positions[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + cognitive_term + social_term\n                # Velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -self.max_velocity, self.max_velocity)\n                \n                self.positions[i] += self.velocities[i]\n                # Ensure position bounds\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Adaptive inertia weight adjustment\n            self.inertia_weight *= self.inertia_damping", "name": "AdaptivePSO", "description": "A particle swarm optimization (PSO) algorithm leveraging adaptive inertia weight and velocity clamping for efficient exploration and exploitation.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b33f194a-315d-4f4c-9d80-88dce057c8ad", "metadata": {"aucs": [0.8129076191983541, 0.823994045217168, 0.80595461605642, 0.809213001020031, 0.8063572429136947, 0.19039356633432913, 0.8027460002883009, 0.8238756157795895, 0.8017559271503454, 0.6977755614283363, 0.6798377664978996, 0.6890972729154629, 0.6844757861364024, 0.662232259733778, 0.6591245392454749, 0.6840780987104091, 0.6722936381042998, 0.6635068740314938, 0.484501653022954, 0.1228040134944608, 0.16524296054090393, 0.17068886815346063, 0.16635603108698682, 0.1778714900389814, 0.1641500787725395, 0.13813824525917284, 0.6878868908547413, 0.14244217520516467, 0.14071162946172844, 0.14864819091987902, 0.15303758393787448, 0.14253062694549823, 0.15522059600630622, 0.14272100990638215, 0.1039272629910889, 0.14418067868330986, 0.9833641376449656, 0.9836639525748442, 0.985851299135645, 0.9804377258689233, 0.9787735723544941, 0.9808525796195119, 0.9860075758194194, 0.983658460217296, 0.9859573585496524, 0.4296509198714902, 0.5321187116827044, 0.5578564992889856, 0.5044812196210661, 0.5198347171878162, 0.4955366847225203, 0.12654173753228537, 0.3725259313276298, 0.08765718166277625, 0.342259254225193, 0.7469914134822229, 0.5814161382694529, 0.20283242175582483, 0.3157235521508944, 0.2052324347431933, 0.40051425083906467, 0.24409159226577348, 0.5645613058945373, 0.3102946285058188, 0.18539351708431207, 0.17499026808393225, 0.1017027358042365, 0.168233406216179, 0.35370840455292396, 0.17506768906162362, 0.3161648364886309, 0.1572791499075673, 0.1865926692450356, 0.16205085548198617, 0.16652047071778797, 0.128924839299713, 0.1881732119738001, 0.14339053725796724, 0.21905252490392957, 0.21038279829784312, 0.19556352719139614, 9.999999999998899e-05, 0.05606525158801401, 0.04996422552361257, 9.999999999998899e-05, 0.0024742299093454267, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006289867314816511, 0.09369518695738277, 0.06757146369626021, 0.0889384257403022, 0.11305811354306938, 0.03628851041252745, 0.02549860259719683, 0.11445273092477415, 0.07331726716269582, 0.04962926307202975, 0.11727043016426542, 0.12823403775254627, 0.03290100593505563, 0.06657061090455796, 0.06864967491872698, 0.06764275521677132, 0.09180687093731377, 0.1927334781599368, 0.0644440780070521, 0.2265486630244291, 0.22434215240716426, 0.13178225072788297, 0.10430609891858222, 0.23789320856379192, 0.20625084304264252, 0.07915481720334483, 0.1826226134686546, 0.07642487498557982, 0.4830096906838707, 0.48136195720804686, 0.5125452605445939, 0.5056369489717407, 0.520556854953009, 0.5641753535374543, 0.4960458739972212, 0.5359511524112615, 0.5198983085471096, 0.13392382651749535, 0.1449856783345338, 0.09662342231326948, 0.14084573042368287, 0.10525734018728217, 0.09114772901538959, 0.12246148794307188, 0.12473404628105456, 0.12174463544500336, 0.294918046285482, 0.5226544047941581, 0.22928311568954207, 0.19166630339290758, 0.3011836527594093, 0.15833339644398514, 0.36773903630243554, 0.36141169596705125, 0.21089440044537888, 0.3178678883322261, 0.37815460390543365, 0.35273110757233594, 0.3768869576868016, 0.36239150694675315, 0.3358402300833082, 0.34619327225073504, 0.4530418622007485, 0.36912538726101585, 0.2983951153980171, 0.22119237220267207, 0.3314201507198059, 0.2699021270459272, 0.29928536619757473, 0.24981217352041163, 0.23623067843656242, 0.3376748649891498, 0.2518930343534719, 0.2101262656215106, 0.2430629219899847, 0.19774993263464025, 0.24535240163142724, 0.25424368996498203, 0.21228344002664157, 0.292991486724984, 0.24517060462769336, 0.20605905764244048, 0.5816880092108925, 0.2166327914571805, 0.2374112703423571, 0.19722423204046236, 0.22983477726519763, 0.2382554661559102, 0.2230320707216754, 0.24549062856315296, 0.22126168904079946, 0.8475469139474092, 0.18530859308038872, 0.1523469798027114, 0.8506833174862986, 0.19912363906323316, 0.16648925100289724, 0.8587512426852477, 0.8385924766549271, 0.8382756188537736, 0.451473004053344, 0.15504818580322355, 0.579531660332157, 0.6978365488502367, 0.16867944821235836, 0.20940023461261337, 0.63048651616266, 0.10441922786367464, 0.6872970632898822, 0.1949472800648363, 0.21058885317528386, 0.18888249392994116, 0.19369666975350341, 0.2198406778156966, 0.20114240862048527, 0.2172796748256094, 0.19714880595552742, 0.1880691954549456, 0.12483945551097986, 0.08761243395752005, 0.07785408170475316, 0.09506575903333159, 0.09477943512140174, 0.08949229029980765, 0.11253668805780381, 0.08789046429234715, 0.0938764058817646]}, "mutation_prompt": null}
{"id": "21a8acd7-3ace-4418-9f8d-f92856bf6c4e", "solution": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.inertia_weight = 0.9  # initial inertia weight\n        self.inertia_damping = 0.99  # damping factor for inertia\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n    \n    def __call__(self, func):\n        func_calls = 0\n        while func_calls < self.budget:\n            for i in range(self.n_particles):\n                fitness = func(self.positions[i])\n                func_calls += 1\n                if fitness < self.pbest_scores[i]:\n                    self.pbest_scores[i] = fitness\n                    self.pbest_positions[i] = self.positions[i]\n                if fitness < self.gbest_score:\n                    self.gbest_score = fitness\n                    self.gbest_position = self.positions[i]\n                \n            for i in range(self.n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = self.c1 * r1 * (self.pbest_positions[i] - self.positions[i])\n                social_term = self.c2 * r2 * (self.gbest_position - self.positions[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + cognitive_term + social_term\n                # Velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -self.max_velocity, self.max_velocity)\n                \n                self.positions[i] += self.velocities[i]\n                # Ensure position bounds\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Adaptive inertia weight adjustment\n            self.inertia_weight *= self.inertia_damping", "name": "AdaptivePSO", "description": "A particle swarm optimization (PSO) algorithm leveraging adaptive inertia weight and velocity clamping for efficient exploration and exploitation.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b33f194a-315d-4f4c-9d80-88dce057c8ad", "metadata": {"aucs": [0.8129076191983541, 0.823994045217168, 0.80595461605642, 0.809213001020031, 0.8063572429136947, 0.19039356633432913, 0.8027460002883009, 0.8238756157795895, 0.8017559271503454, 0.6977755614283363, 0.6798377664978996, 0.6890972729154629, 0.6844757861364024, 0.662232259733778, 0.6591245392454749, 0.6840780987104091, 0.6722936381042998, 0.6635068740314938, 0.484501653022954, 0.1228040134944608, 0.16524296054090393, 0.17068886815346063, 0.16635603108698682, 0.1778714900389814, 0.1641500787725395, 0.13813824525917284, 0.6878868908547413, 0.14244217520516467, 0.14071162946172844, 0.14864819091987902, 0.15303758393787448, 0.14253062694549823, 0.15522059600630622, 0.14272100990638215, 0.1039272629910889, 0.14418067868330986, 0.9833641376449656, 0.9836639525748442, 0.985851299135645, 0.9804377258689233, 0.9787735723544941, 0.9808525796195119, 0.9860075758194194, 0.983658460217296, 0.9859573585496524, 0.4296509198714902, 0.5321187116827044, 0.5578564992889856, 0.5044812196210661, 0.5198347171878162, 0.4955366847225203, 0.12654173753228537, 0.3725259313276298, 0.08765718166277625, 0.342259254225193, 0.7469914134822229, 0.5814161382694529, 0.20283242175582483, 0.3157235521508944, 0.2052324347431933, 0.40051425083906467, 0.24409159226577348, 0.5645613058945373, 0.3102946285058188, 0.18539351708431207, 0.17499026808393225, 0.1017027358042365, 0.168233406216179, 0.35370840455292396, 0.17506768906162362, 0.3161648364886309, 0.1572791499075673, 0.1865926692450356, 0.16205085548198617, 0.16652047071778797, 0.128924839299713, 0.1881732119738001, 0.14339053725796724, 0.21905252490392957, 0.21038279829784312, 0.19556352719139614, 9.999999999998899e-05, 0.05606525158801401, 0.04996422552361257, 9.999999999998899e-05, 0.0024742299093454267, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006289867314816511, 0.09369518695738277, 0.06757146369626021, 0.0889384257403022, 0.11305811354306938, 0.03628851041252745, 0.02549860259719683, 0.11445273092477415, 0.07331726716269582, 0.04962926307202975, 0.11727043016426542, 0.12823403775254627, 0.03290100593505563, 0.06657061090455796, 0.06864967491872698, 0.06764275521677132, 0.09180687093731377, 0.1927334781599368, 0.0644440780070521, 0.2265486630244291, 0.22434215240716426, 0.13178225072788297, 0.10430609891858222, 0.23789320856379192, 0.20625084304264252, 0.07915481720334483, 0.1826226134686546, 0.07642487498557982, 0.4830096906838707, 0.48136195720804686, 0.5125452605445939, 0.5056369489717407, 0.520556854953009, 0.5641753535374543, 0.4960458739972212, 0.5359511524112615, 0.5198983085471096, 0.13392382651749535, 0.1449856783345338, 0.09662342231326948, 0.14084573042368287, 0.10525734018728217, 0.09114772901538959, 0.12246148794307188, 0.12473404628105456, 0.12174463544500336, 0.294918046285482, 0.5226544047941581, 0.22928311568954207, 0.19166630339290758, 0.3011836527594093, 0.15833339644398514, 0.36773903630243554, 0.36141169596705125, 0.21089440044537888, 0.3178678883322261, 0.37815460390543365, 0.35273110757233594, 0.3768869576868016, 0.36239150694675315, 0.3358402300833082, 0.34619327225073504, 0.4530418622007485, 0.36912538726101585, 0.2983951153980171, 0.22119237220267207, 0.3314201507198059, 0.2699021270459272, 0.29928536619757473, 0.24981217352041163, 0.23623067843656242, 0.3376748649891498, 0.2518930343534719, 0.2101262656215106, 0.2430629219899847, 0.19774993263464025, 0.24535240163142724, 0.25424368996498203, 0.21228344002664157, 0.292991486724984, 0.24517060462769336, 0.20605905764244048, 0.5816880092108925, 0.2166327914571805, 0.2374112703423571, 0.19722423204046236, 0.22983477726519763, 0.2382554661559102, 0.2230320707216754, 0.24549062856315296, 0.22126168904079946, 0.8475469139474092, 0.18530859308038872, 0.1523469798027114, 0.8506833174862986, 0.19912363906323316, 0.16648925100289724, 0.8587512426852477, 0.8385924766549271, 0.8382756188537736, 0.451473004053344, 0.15504818580322355, 0.579531660332157, 0.6978365488502367, 0.16867944821235836, 0.20940023461261337, 0.63048651616266, 0.10441922786367464, 0.6872970632898822, 0.1949472800648363, 0.21058885317528386, 0.18888249392994116, 0.19369666975350341, 0.2198406778156966, 0.20114240862048527, 0.2172796748256094, 0.19714880595552742, 0.1880691954549456, 0.12483945551097986, 0.08761243395752005, 0.07785408170475316, 0.09506575903333159, 0.09477943512140174, 0.08949229029980765, 0.11253668805780381, 0.08789046429234715, 0.0938764058817646]}, "mutation_prompt": null}
{"id": "feb2f330-8193-4843-b0ea-7055c0dd757c", "solution": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.inertia_weight = 0.9  # initial inertia weight\n        self.inertia_damping = 0.99  # damping factor for inertia\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n    \n    def __call__(self, func):\n        func_calls = 0\n        while func_calls < self.budget:\n            for i in range(self.n_particles):\n                fitness = func(self.positions[i])\n                func_calls += 1\n                if fitness < self.pbest_scores[i]:\n                    self.pbest_scores[i] = fitness\n                    self.pbest_positions[i] = self.positions[i]\n                if fitness < self.gbest_score:\n                    self.gbest_score = fitness\n                    self.gbest_position = self.positions[i]\n                \n            for i in range(self.n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = self.c1 * r1 * (self.pbest_positions[i] - self.positions[i])\n                social_term = self.c2 * r2 * (self.gbest_position - self.positions[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + cognitive_term + social_term\n                # Velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -self.max_velocity, self.max_velocity)\n                \n                self.positions[i] += self.velocities[i]\n                # Ensure position bounds\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Adaptive inertia weight adjustment\n            self.inertia_weight *= self.inertia_damping", "name": "AdaptivePSO", "description": "A particle swarm optimization (PSO) algorithm leveraging adaptive inertia weight and velocity clamping for efficient exploration and exploitation.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b33f194a-315d-4f4c-9d80-88dce057c8ad", "metadata": {"aucs": [0.8129076191983541, 0.823994045217168, 0.80595461605642, 0.809213001020031, 0.8063572429136947, 0.19039356633432913, 0.8027460002883009, 0.8238756157795895, 0.8017559271503454, 0.6977755614283363, 0.6798377664978996, 0.6890972729154629, 0.6844757861364024, 0.662232259733778, 0.6591245392454749, 0.6840780987104091, 0.6722936381042998, 0.6635068740314938, 0.484501653022954, 0.1228040134944608, 0.16524296054090393, 0.17068886815346063, 0.16635603108698682, 0.1778714900389814, 0.1641500787725395, 0.13813824525917284, 0.6878868908547413, 0.14244217520516467, 0.14071162946172844, 0.14864819091987902, 0.15303758393787448, 0.14253062694549823, 0.15522059600630622, 0.14272100990638215, 0.1039272629910889, 0.14418067868330986, 0.9833641376449656, 0.9836639525748442, 0.985851299135645, 0.9804377258689233, 0.9787735723544941, 0.9808525796195119, 0.9860075758194194, 0.983658460217296, 0.9859573585496524, 0.4296509198714902, 0.5321187116827044, 0.5578564992889856, 0.5044812196210661, 0.5198347171878162, 0.4955366847225203, 0.12654173753228537, 0.3725259313276298, 0.08765718166277625, 0.342259254225193, 0.7469914134822229, 0.5814161382694529, 0.20283242175582483, 0.3157235521508944, 0.2052324347431933, 0.40051425083906467, 0.24409159226577348, 0.5645613058945373, 0.3102946285058188, 0.18539351708431207, 0.17499026808393225, 0.1017027358042365, 0.168233406216179, 0.35370840455292396, 0.17506768906162362, 0.3161648364886309, 0.1572791499075673, 0.1865926692450356, 0.16205085548198617, 0.16652047071778797, 0.128924839299713, 0.1881732119738001, 0.14339053725796724, 0.21905252490392957, 0.21038279829784312, 0.19556352719139614, 9.999999999998899e-05, 0.05606525158801401, 0.04996422552361257, 9.999999999998899e-05, 0.0024742299093454267, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006289867314816511, 0.09369518695738277, 0.06757146369626021, 0.0889384257403022, 0.11305811354306938, 0.03628851041252745, 0.02549860259719683, 0.11445273092477415, 0.07331726716269582, 0.04962926307202975, 0.11727043016426542, 0.12823403775254627, 0.03290100593505563, 0.06657061090455796, 0.06864967491872698, 0.06764275521677132, 0.09180687093731377, 0.1927334781599368, 0.0644440780070521, 0.2265486630244291, 0.22434215240716426, 0.13178225072788297, 0.10430609891858222, 0.23789320856379192, 0.20625084304264252, 0.07915481720334483, 0.1826226134686546, 0.07642487498557982, 0.4830096906838707, 0.48136195720804686, 0.5125452605445939, 0.5056369489717407, 0.520556854953009, 0.5641753535374543, 0.4960458739972212, 0.5359511524112615, 0.5198983085471096, 0.13392382651749535, 0.1449856783345338, 0.09662342231326948, 0.14084573042368287, 0.10525734018728217, 0.09114772901538959, 0.12246148794307188, 0.12473404628105456, 0.12174463544500336, 0.294918046285482, 0.5226544047941581, 0.22928311568954207, 0.19166630339290758, 0.3011836527594093, 0.15833339644398514, 0.36773903630243554, 0.36141169596705125, 0.21089440044537888, 0.3178678883322261, 0.37815460390543365, 0.35273110757233594, 0.3768869576868016, 0.36239150694675315, 0.3358402300833082, 0.34619327225073504, 0.4530418622007485, 0.36912538726101585, 0.2983951153980171, 0.22119237220267207, 0.3314201507198059, 0.2699021270459272, 0.29928536619757473, 0.24981217352041163, 0.23623067843656242, 0.3376748649891498, 0.2518930343534719, 0.2101262656215106, 0.2430629219899847, 0.19774993263464025, 0.24535240163142724, 0.25424368996498203, 0.21228344002664157, 0.292991486724984, 0.24517060462769336, 0.20605905764244048, 0.5816880092108925, 0.2166327914571805, 0.2374112703423571, 0.19722423204046236, 0.22983477726519763, 0.2382554661559102, 0.2230320707216754, 0.24549062856315296, 0.22126168904079946, 0.8475469139474092, 0.18530859308038872, 0.1523469798027114, 0.8506833174862986, 0.19912363906323316, 0.16648925100289724, 0.8587512426852477, 0.8385924766549271, 0.8382756188537736, 0.451473004053344, 0.15504818580322355, 0.579531660332157, 0.6978365488502367, 0.16867944821235836, 0.20940023461261337, 0.63048651616266, 0.10441922786367464, 0.6872970632898822, 0.1949472800648363, 0.21058885317528386, 0.18888249392994116, 0.19369666975350341, 0.2198406778156966, 0.20114240862048527, 0.2172796748256094, 0.19714880595552742, 0.1880691954549456, 0.12483945551097986, 0.08761243395752005, 0.07785408170475316, 0.09506575903333159, 0.09477943512140174, 0.08949229029980765, 0.11253668805780381, 0.08789046429234715, 0.0938764058817646]}, "mutation_prompt": null}
{"id": "6bd8ad5a-1d65-4d09-abca-3ca4eda35fb1", "solution": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.inertia_weight = 0.9  # initial inertia weight\n        self.inertia_damping = 0.99  # damping factor for inertia\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n    \n    def __call__(self, func):\n        func_calls = 0\n        while func_calls < self.budget:\n            for i in range(self.n_particles):\n                fitness = func(self.positions[i])\n                func_calls += 1\n                if fitness < self.pbest_scores[i]:\n                    self.pbest_scores[i] = fitness\n                    self.pbest_positions[i] = self.positions[i]\n                if fitness < self.gbest_score:\n                    self.gbest_score = fitness\n                    self.gbest_position = self.positions[i]\n                \n            for i in range(self.n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = self.c1 * r1 * (self.pbest_positions[i] - self.positions[i])\n                social_term = self.c2 * r2 * (self.gbest_position - self.positions[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + cognitive_term + social_term\n                # Velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -self.max_velocity, self.max_velocity)\n                \n                self.positions[i] += self.velocities[i]\n                # Ensure position bounds\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Adaptive inertia weight adjustment\n            self.inertia_weight *= self.inertia_damping", "name": "AdaptivePSO", "description": "A particle swarm optimization (PSO) algorithm leveraging adaptive inertia weight and velocity clamping for efficient exploration and exploitation.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b33f194a-315d-4f4c-9d80-88dce057c8ad", "metadata": {"aucs": [0.8129076191983541, 0.823994045217168, 0.80595461605642, 0.809213001020031, 0.8063572429136947, 0.19039356633432913, 0.8027460002883009, 0.8238756157795895, 0.8017559271503454, 0.6977755614283363, 0.6798377664978996, 0.6890972729154629, 0.6844757861364024, 0.662232259733778, 0.6591245392454749, 0.6840780987104091, 0.6722936381042998, 0.6635068740314938, 0.484501653022954, 0.1228040134944608, 0.16524296054090393, 0.17068886815346063, 0.16635603108698682, 0.1778714900389814, 0.1641500787725395, 0.13813824525917284, 0.6878868908547413, 0.14244217520516467, 0.14071162946172844, 0.14864819091987902, 0.15303758393787448, 0.14253062694549823, 0.15522059600630622, 0.14272100990638215, 0.1039272629910889, 0.14418067868330986, 0.9833641376449656, 0.9836639525748442, 0.985851299135645, 0.9804377258689233, 0.9787735723544941, 0.9808525796195119, 0.9860075758194194, 0.983658460217296, 0.9859573585496524, 0.4296509198714902, 0.5321187116827044, 0.5578564992889856, 0.5044812196210661, 0.5198347171878162, 0.4955366847225203, 0.12654173753228537, 0.3725259313276298, 0.08765718166277625, 0.342259254225193, 0.7469914134822229, 0.5814161382694529, 0.20283242175582483, 0.3157235521508944, 0.2052324347431933, 0.40051425083906467, 0.24409159226577348, 0.5645613058945373, 0.3102946285058188, 0.18539351708431207, 0.17499026808393225, 0.1017027358042365, 0.168233406216179, 0.35370840455292396, 0.17506768906162362, 0.3161648364886309, 0.1572791499075673, 0.1865926692450356, 0.16205085548198617, 0.16652047071778797, 0.128924839299713, 0.1881732119738001, 0.14339053725796724, 0.21905252490392957, 0.21038279829784312, 0.19556352719139614, 9.999999999998899e-05, 0.05606525158801401, 0.04996422552361257, 9.999999999998899e-05, 0.0024742299093454267, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006289867314816511, 0.09369518695738277, 0.06757146369626021, 0.0889384257403022, 0.11305811354306938, 0.03628851041252745, 0.02549860259719683, 0.11445273092477415, 0.07331726716269582, 0.04962926307202975, 0.11727043016426542, 0.12823403775254627, 0.03290100593505563, 0.06657061090455796, 0.06864967491872698, 0.06764275521677132, 0.09180687093731377, 0.1927334781599368, 0.0644440780070521, 0.2265486630244291, 0.22434215240716426, 0.13178225072788297, 0.10430609891858222, 0.23789320856379192, 0.20625084304264252, 0.07915481720334483, 0.1826226134686546, 0.07642487498557982, 0.4830096906838707, 0.48136195720804686, 0.5125452605445939, 0.5056369489717407, 0.520556854953009, 0.5641753535374543, 0.4960458739972212, 0.5359511524112615, 0.5198983085471096, 0.13392382651749535, 0.1449856783345338, 0.09662342231326948, 0.14084573042368287, 0.10525734018728217, 0.09114772901538959, 0.12246148794307188, 0.12473404628105456, 0.12174463544500336, 0.294918046285482, 0.5226544047941581, 0.22928311568954207, 0.19166630339290758, 0.3011836527594093, 0.15833339644398514, 0.36773903630243554, 0.36141169596705125, 0.21089440044537888, 0.3178678883322261, 0.37815460390543365, 0.35273110757233594, 0.3768869576868016, 0.36239150694675315, 0.3358402300833082, 0.34619327225073504, 0.4530418622007485, 0.36912538726101585, 0.2983951153980171, 0.22119237220267207, 0.3314201507198059, 0.2699021270459272, 0.29928536619757473, 0.24981217352041163, 0.23623067843656242, 0.3376748649891498, 0.2518930343534719, 0.2101262656215106, 0.2430629219899847, 0.19774993263464025, 0.24535240163142724, 0.25424368996498203, 0.21228344002664157, 0.292991486724984, 0.24517060462769336, 0.20605905764244048, 0.5816880092108925, 0.2166327914571805, 0.2374112703423571, 0.19722423204046236, 0.22983477726519763, 0.2382554661559102, 0.2230320707216754, 0.24549062856315296, 0.22126168904079946, 0.8475469139474092, 0.18530859308038872, 0.1523469798027114, 0.8506833174862986, 0.19912363906323316, 0.16648925100289724, 0.8587512426852477, 0.8385924766549271, 0.8382756188537736, 0.451473004053344, 0.15504818580322355, 0.579531660332157, 0.6978365488502367, 0.16867944821235836, 0.20940023461261337, 0.63048651616266, 0.10441922786367464, 0.6872970632898822, 0.1949472800648363, 0.21058885317528386, 0.18888249392994116, 0.19369666975350341, 0.2198406778156966, 0.20114240862048527, 0.2172796748256094, 0.19714880595552742, 0.1880691954549456, 0.12483945551097986, 0.08761243395752005, 0.07785408170475316, 0.09506575903333159, 0.09477943512140174, 0.08949229029980765, 0.11253668805780381, 0.08789046429234715, 0.0938764058817646]}, "mutation_prompt": null}
{"id": "84353da1-ce92-4b5f-977d-25fdef3530b7", "solution": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.inertia_weight = 0.9  # initial inertia weight\n        self.inertia_damping = 0.99  # damping factor for inertia\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n    \n    def __call__(self, func):\n        func_calls = 0\n        while func_calls < self.budget:\n            for i in range(self.n_particles):\n                fitness = func(self.positions[i])\n                func_calls += 1\n                if fitness < self.pbest_scores[i]:\n                    self.pbest_scores[i] = fitness\n                    self.pbest_positions[i] = self.positions[i]\n                if fitness < self.gbest_score:\n                    self.gbest_score = fitness\n                    self.gbest_position = self.positions[i]\n                \n            for i in range(self.n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = self.c1 * r1 * (self.pbest_positions[i] - self.positions[i])\n                social_term = self.c2 * r2 * (self.gbest_position - self.positions[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + cognitive_term + social_term\n                # Velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -self.max_velocity, self.max_velocity)\n                \n                self.positions[i] += self.velocities[i]\n                # Ensure position bounds\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Adaptive inertia weight adjustment\n            self.inertia_weight *= self.inertia_damping", "name": "AdaptivePSO", "description": "A particle swarm optimization (PSO) algorithm leveraging adaptive inertia weight and velocity clamping for efficient exploration and exploitation.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b33f194a-315d-4f4c-9d80-88dce057c8ad", "metadata": {"aucs": [0.8129076191983541, 0.823994045217168, 0.80595461605642, 0.809213001020031, 0.8063572429136947, 0.19039356633432913, 0.8027460002883009, 0.8238756157795895, 0.8017559271503454, 0.6977755614283363, 0.6798377664978996, 0.6890972729154629, 0.6844757861364024, 0.662232259733778, 0.6591245392454749, 0.6840780987104091, 0.6722936381042998, 0.6635068740314938, 0.484501653022954, 0.1228040134944608, 0.16524296054090393, 0.17068886815346063, 0.16635603108698682, 0.1778714900389814, 0.1641500787725395, 0.13813824525917284, 0.6878868908547413, 0.14244217520516467, 0.14071162946172844, 0.14864819091987902, 0.15303758393787448, 0.14253062694549823, 0.15522059600630622, 0.14272100990638215, 0.1039272629910889, 0.14418067868330986, 0.9833641376449656, 0.9836639525748442, 0.985851299135645, 0.9804377258689233, 0.9787735723544941, 0.9808525796195119, 0.9860075758194194, 0.983658460217296, 0.9859573585496524, 0.4296509198714902, 0.5321187116827044, 0.5578564992889856, 0.5044812196210661, 0.5198347171878162, 0.4955366847225203, 0.12654173753228537, 0.3725259313276298, 0.08765718166277625, 0.342259254225193, 0.7469914134822229, 0.5814161382694529, 0.20283242175582483, 0.3157235521508944, 0.2052324347431933, 0.40051425083906467, 0.24409159226577348, 0.5645613058945373, 0.3102946285058188, 0.18539351708431207, 0.17499026808393225, 0.1017027358042365, 0.168233406216179, 0.35370840455292396, 0.17506768906162362, 0.3161648364886309, 0.1572791499075673, 0.1865926692450356, 0.16205085548198617, 0.16652047071778797, 0.128924839299713, 0.1881732119738001, 0.14339053725796724, 0.21905252490392957, 0.21038279829784312, 0.19556352719139614, 9.999999999998899e-05, 0.05606525158801401, 0.04996422552361257, 9.999999999998899e-05, 0.0024742299093454267, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006289867314816511, 0.09369518695738277, 0.06757146369626021, 0.0889384257403022, 0.11305811354306938, 0.03628851041252745, 0.02549860259719683, 0.11445273092477415, 0.07331726716269582, 0.04962926307202975, 0.11727043016426542, 0.12823403775254627, 0.03290100593505563, 0.06657061090455796, 0.06864967491872698, 0.06764275521677132, 0.09180687093731377, 0.1927334781599368, 0.0644440780070521, 0.2265486630244291, 0.22434215240716426, 0.13178225072788297, 0.10430609891858222, 0.23789320856379192, 0.20625084304264252, 0.07915481720334483, 0.1826226134686546, 0.07642487498557982, 0.4830096906838707, 0.48136195720804686, 0.5125452605445939, 0.5056369489717407, 0.520556854953009, 0.5641753535374543, 0.4960458739972212, 0.5359511524112615, 0.5198983085471096, 0.13392382651749535, 0.1449856783345338, 0.09662342231326948, 0.14084573042368287, 0.10525734018728217, 0.09114772901538959, 0.12246148794307188, 0.12473404628105456, 0.12174463544500336, 0.294918046285482, 0.5226544047941581, 0.22928311568954207, 0.19166630339290758, 0.3011836527594093, 0.15833339644398514, 0.36773903630243554, 0.36141169596705125, 0.21089440044537888, 0.3178678883322261, 0.37815460390543365, 0.35273110757233594, 0.3768869576868016, 0.36239150694675315, 0.3358402300833082, 0.34619327225073504, 0.4530418622007485, 0.36912538726101585, 0.2983951153980171, 0.22119237220267207, 0.3314201507198059, 0.2699021270459272, 0.29928536619757473, 0.24981217352041163, 0.23623067843656242, 0.3376748649891498, 0.2518930343534719, 0.2101262656215106, 0.2430629219899847, 0.19774993263464025, 0.24535240163142724, 0.25424368996498203, 0.21228344002664157, 0.292991486724984, 0.24517060462769336, 0.20605905764244048, 0.5816880092108925, 0.2166327914571805, 0.2374112703423571, 0.19722423204046236, 0.22983477726519763, 0.2382554661559102, 0.2230320707216754, 0.24549062856315296, 0.22126168904079946, 0.8475469139474092, 0.18530859308038872, 0.1523469798027114, 0.8506833174862986, 0.19912363906323316, 0.16648925100289724, 0.8587512426852477, 0.8385924766549271, 0.8382756188537736, 0.451473004053344, 0.15504818580322355, 0.579531660332157, 0.6978365488502367, 0.16867944821235836, 0.20940023461261337, 0.63048651616266, 0.10441922786367464, 0.6872970632898822, 0.1949472800648363, 0.21058885317528386, 0.18888249392994116, 0.19369666975350341, 0.2198406778156966, 0.20114240862048527, 0.2172796748256094, 0.19714880595552742, 0.1880691954549456, 0.12483945551097986, 0.08761243395752005, 0.07785408170475316, 0.09506575903333159, 0.09477943512140174, 0.08949229029980765, 0.11253668805780381, 0.08789046429234715, 0.0938764058817646]}, "mutation_prompt": null}
{"id": "67a25ca0-3aca-49a1-be73-130384df81a5", "solution": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.inertia_weight = 0.9  # initial inertia weight\n        self.inertia_damping = 0.99  # damping factor for inertia\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n    \n    def __call__(self, func):\n        func_calls = 0\n        while func_calls < self.budget:\n            for i in range(self.n_particles):\n                fitness = func(self.positions[i])\n                func_calls += 1\n                if fitness < self.pbest_scores[i]:\n                    self.pbest_scores[i] = fitness\n                    self.pbest_positions[i] = self.positions[i]\n                if fitness < self.gbest_score:\n                    self.gbest_score = fitness\n                    self.gbest_position = self.positions[i]\n                \n            for i in range(self.n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = self.c1 * r1 * (self.pbest_positions[i] - self.positions[i])\n                social_term = self.c2 * r2 * (self.gbest_position - self.positions[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + cognitive_term + social_term\n                # Velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -self.max_velocity, self.max_velocity)\n                \n                self.positions[i] += self.velocities[i]\n                # Ensure position bounds\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Adaptive inertia weight adjustment\n            self.inertia_weight *= self.inertia_damping", "name": "AdaptivePSO", "description": "A particle swarm optimization (PSO) algorithm leveraging adaptive inertia weight and velocity clamping for efficient exploration and exploitation.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b33f194a-315d-4f4c-9d80-88dce057c8ad", "metadata": {"aucs": [0.8129076191983541, 0.823994045217168, 0.80595461605642, 0.809213001020031, 0.8063572429136947, 0.19039356633432913, 0.8027460002883009, 0.8238756157795895, 0.8017559271503454, 0.6977755614283363, 0.6798377664978996, 0.6890972729154629, 0.6844757861364024, 0.662232259733778, 0.6591245392454749, 0.6840780987104091, 0.6722936381042998, 0.6635068740314938, 0.484501653022954, 0.1228040134944608, 0.16524296054090393, 0.17068886815346063, 0.16635603108698682, 0.1778714900389814, 0.1641500787725395, 0.13813824525917284, 0.6878868908547413, 0.14244217520516467, 0.14071162946172844, 0.14864819091987902, 0.15303758393787448, 0.14253062694549823, 0.15522059600630622, 0.14272100990638215, 0.1039272629910889, 0.14418067868330986, 0.9833641376449656, 0.9836639525748442, 0.985851299135645, 0.9804377258689233, 0.9787735723544941, 0.9808525796195119, 0.9860075758194194, 0.983658460217296, 0.9859573585496524, 0.4296509198714902, 0.5321187116827044, 0.5578564992889856, 0.5044812196210661, 0.5198347171878162, 0.4955366847225203, 0.12654173753228537, 0.3725259313276298, 0.08765718166277625, 0.342259254225193, 0.7469914134822229, 0.5814161382694529, 0.20283242175582483, 0.3157235521508944, 0.2052324347431933, 0.40051425083906467, 0.24409159226577348, 0.5645613058945373, 0.3102946285058188, 0.18539351708431207, 0.17499026808393225, 0.1017027358042365, 0.168233406216179, 0.35370840455292396, 0.17506768906162362, 0.3161648364886309, 0.1572791499075673, 0.1865926692450356, 0.16205085548198617, 0.16652047071778797, 0.128924839299713, 0.1881732119738001, 0.14339053725796724, 0.21905252490392957, 0.21038279829784312, 0.19556352719139614, 9.999999999998899e-05, 0.05606525158801401, 0.04996422552361257, 9.999999999998899e-05, 0.0024742299093454267, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006289867314816511, 0.09369518695738277, 0.06757146369626021, 0.0889384257403022, 0.11305811354306938, 0.03628851041252745, 0.02549860259719683, 0.11445273092477415, 0.07331726716269582, 0.04962926307202975, 0.11727043016426542, 0.12823403775254627, 0.03290100593505563, 0.06657061090455796, 0.06864967491872698, 0.06764275521677132, 0.09180687093731377, 0.1927334781599368, 0.0644440780070521, 0.2265486630244291, 0.22434215240716426, 0.13178225072788297, 0.10430609891858222, 0.23789320856379192, 0.20625084304264252, 0.07915481720334483, 0.1826226134686546, 0.07642487498557982, 0.4830096906838707, 0.48136195720804686, 0.5125452605445939, 0.5056369489717407, 0.520556854953009, 0.5641753535374543, 0.4960458739972212, 0.5359511524112615, 0.5198983085471096, 0.13392382651749535, 0.1449856783345338, 0.09662342231326948, 0.14084573042368287, 0.10525734018728217, 0.09114772901538959, 0.12246148794307188, 0.12473404628105456, 0.12174463544500336, 0.294918046285482, 0.5226544047941581, 0.22928311568954207, 0.19166630339290758, 0.3011836527594093, 0.15833339644398514, 0.36773903630243554, 0.36141169596705125, 0.21089440044537888, 0.3178678883322261, 0.37815460390543365, 0.35273110757233594, 0.3768869576868016, 0.36239150694675315, 0.3358402300833082, 0.34619327225073504, 0.4530418622007485, 0.36912538726101585, 0.2983951153980171, 0.22119237220267207, 0.3314201507198059, 0.2699021270459272, 0.29928536619757473, 0.24981217352041163, 0.23623067843656242, 0.3376748649891498, 0.2518930343534719, 0.2101262656215106, 0.2430629219899847, 0.19774993263464025, 0.24535240163142724, 0.25424368996498203, 0.21228344002664157, 0.292991486724984, 0.24517060462769336, 0.20605905764244048, 0.5816880092108925, 0.2166327914571805, 0.2374112703423571, 0.19722423204046236, 0.22983477726519763, 0.2382554661559102, 0.2230320707216754, 0.24549062856315296, 0.22126168904079946, 0.8475469139474092, 0.18530859308038872, 0.1523469798027114, 0.8506833174862986, 0.19912363906323316, 0.16648925100289724, 0.8587512426852477, 0.8385924766549271, 0.8382756188537736, 0.451473004053344, 0.15504818580322355, 0.579531660332157, 0.6978365488502367, 0.16867944821235836, 0.20940023461261337, 0.63048651616266, 0.10441922786367464, 0.6872970632898822, 0.1949472800648363, 0.21058885317528386, 0.18888249392994116, 0.19369666975350341, 0.2198406778156966, 0.20114240862048527, 0.2172796748256094, 0.19714880595552742, 0.1880691954549456, 0.12483945551097986, 0.08761243395752005, 0.07785408170475316, 0.09506575903333159, 0.09477943512140174, 0.08949229029980765, 0.11253668805780381, 0.08789046429234715, 0.0938764058817646]}, "mutation_prompt": null}
{"id": "a77eaf46-a2c4-4839-b864-f4c5a48e5b12", "solution": "import numpy as np\n\nclass OptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n\n    def __call__(self, func):\n        func_calls = 0\n        while func_calls < self.budget:\n            fitness_values = np.apply_along_axis(func, 1, self.positions)\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = np.random.rand(self.n_particles, self.dim), np.random.rand(self.n_particles, self.dim)\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = self.inertia_weight * self.velocities + cognitive_term + social_term\n            self.velocities = np.clip(self.velocities, -self.max_velocity, self.max_velocity)\n            self.positions += self.velocities\n            self.positions = np.clip(self.positions, self.lower_bound, self.upper_bound)\n            \n            self.inertia_weight *= self.inertia_damping", "name": "OptimizedAdaptivePSO", "description": "An optimized version of AdaptivePSO with reduced computational overhead by minimizing redundant calculations and more efficient loop structures.", "configspace": "", "generation": 18, "fitness": 0.32037855649167896, "feedback": "The algorithm OptimizedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.27.", "error": "", "parent_id": "b33f194a-315d-4f4c-9d80-88dce057c8ad", "metadata": {"aucs": [0.8558239462519294, 0.8509916724182549, 0.8399413179561979, 0.8446828128572699, 0.8440088033487392, 0.840436545643882, 0.8553248566376483, 0.8389427423078013, 0.8511326457546893, 0.7351670706244203, 0.6977803125530264, 0.7159914690248101, 0.7376260997346057, 0.724407319819464, 0.7142999354809814, 0.7358804805831409, 0.7352102801543174, 0.7382615962178669, 0.17054650853261888, 0.1772479186182223, 0.16011665473918146, 0.15629791612310762, 0.6009568373624434, 0.49048101916085274, 0.16363956352449172, 0.1598415383522157, 0.16232503037280166, 0.13566325204339302, 0.15563151311255663, 0.12952882657316134, 0.17885376897269722, 0.11343752809037233, 0.13836362697120985, 0.12494650770891169, 0.27207584295060894, 0.1476804181141601, 0.9827225016428057, 0.9819316949390162, 0.9857731617439167, 0.9758622083875659, 0.9830169045308665, 0.9810399070873577, 0.9839148966018925, 0.9784817851007276, 0.9853065704301522, 0.5688624168568301, 0.6162955532745108, 0.42445687972677426, 0.5724085519054514, 0.4464044186677284, 0.5431059080782581, 0.5660178863349775, 0.48548942752252855, 0.5338070504197452, 0.381371038843621, 0.5648213603959936, 0.22932399438716444, 0.19422848859309227, 0.3693003251012926, 0.2784678538195591, 0.2915373379235453, 0.22153498429722684, 0.6056693817869128, 0.21497402480794547, 0.18637178013265643, 0.16948020128942498, 0.1776416691166498, 0.18548416841738258, 0.18918880379720182, 0.18229857429993768, 0.1841135245195743, 0.18508374569740393, 0.13221948235650338, 0.11268622638420567, 0.18940022788976407, 0.17184797253523632, 0.21172651237396012, 0.1735153445514438, 0.20092643300662516, 0.19102141633494674, 0.10212378945582112, 9.999999999998899e-05, 0.16727164333519973, 9.999999999998899e-05, 0.046954614162993846, 9.999999999998899e-05, 0.07440864712355322, 9.999999999998899e-05, 0.03651837792548285, 0.00041242676343777873, 0.09815748000913993, 0.06383002923179482, 0.06507269720196962, 0.09835191273668553, 0.04427301297728059, 0.011799174619192665, 0.1039344252897283, 0.09623078222154313, 0.06898107709708456, 0.10626516263413233, 0.16281819272508946, 0.08874850632276687, 0.15312425957758713, 0.23466415673807817, 0.07457481401971877, 0.11604759419267574, 0.06952181010207481, 0.07436412267282178, 0.12730175562726764, 0.10651717220231671, 0.1610346756054547, 0.06040317559953634, 0.16941304529825396, 0.16399947864668174, 0.07881569529967125, 0.08059442161769548, 0.08156104001073383, 0.48537511133895184, 0.5011831768721317, 0.4836113453699291, 0.6347290054483403, 0.5103256471803184, 0.5381156789600892, 0.5375905245642498, 0.5351808057681817, 0.5700873706854377, 0.12027724031040599, 0.10504311805873279, 0.10775622927656481, 0.11242019361396238, 0.1277956113633978, 0.10287817316963044, 0.07310199031605047, 0.09554067869885963, 0.09117347134776155, 0.25792073411241034, 0.200215555703107, 0.19650698668684607, 0.2951508381988067, 0.22218366013779944, 0.19240257306299913, 0.2950617929879501, 0.21197054625116984, 0.16614158731630901, 0.3682283779582498, 0.4392801116954501, 0.3451161086882133, 0.37549264840555885, 0.3813082021877121, 0.42036820255367535, 0.5534793737876269, 0.4455411020866574, 0.470049833965681, 0.2673028317208366, 0.20099953839474916, 0.32221676252644615, 0.3172526266790051, 0.2208142350624125, 0.2879028062964041, 0.3130892743703805, 0.28322523946847133, 0.24513039534428804, 0.2278827956899907, 0.2035038217271108, 0.20757770436416823, 0.21597181925369868, 0.2515992797957961, 0.20759028040026672, 0.23608175605431614, 0.20485210541929177, 0.25359813037789414, 0.22508229656281942, 0.20647760125417924, 0.21594562808761897, 0.22073826522194417, 0.24325919991715306, 0.2169663883565548, 0.20744888412567097, 0.19690915586826974, 0.7372889043837295, 0.8919888776728203, 0.1254052042982401, 0.14764036489197063, 0.8980587413881278, 0.19997359666762837, 0.8513287696254834, 0.12243385120846473, 0.1701038679451713, 0.8924527101276019, 0.6546762578983492, 0.15649086790731837, 0.6255792179533863, 0.2124063533082472, 0.16885314473494273, 0.2125158753823173, 0.10416239518462045, 0.16873358741609668, 0.7195761584857097, 0.18398440656462223, 0.20782751187681847, 0.19672125796461581, 0.20057208836081886, 0.1896505524371871, 0.19600735838077143, 0.21701895304772556, 0.18435159573396476, 0.20077915101069044, 0.09091555580922528, 0.08594644235838766, 0.0951771397168868, 0.08806694924261971, 0.08705546669843967, 0.08670677343500632, 0.08238840089758492, 0.10155503836457902, 0.10818643970764208]}, "mutation_prompt": null}
{"id": "47ba0397-2e61-4377-ad30-ae50e5a0a734", "solution": "import numpy as np\n\nclass OptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n\n    def __call__(self, func):\n        func_calls = 0\n        while func_calls < self.budget:\n            fitness_values = np.apply_along_axis(func, 1, self.positions)\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = np.random.rand(self.n_particles, self.dim), np.random.rand(self.n_particles, self.dim)\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = self.inertia_weight * self.velocities + cognitive_term + social_term\n            self.velocities = np.clip(self.velocities, -self.max_velocity, self.max_velocity)\n            self.positions += self.velocities\n            self.positions = np.clip(self.positions, self.lower_bound, self.upper_bound)\n            \n            self.inertia_weight *= self.inertia_damping", "name": "OptimizedAdaptivePSO", "description": "An optimized version of AdaptivePSO with reduced computational overhead by minimizing redundant calculations and more efficient loop structures.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a77eaf46-a2c4-4839-b864-f4c5a48e5b12", "metadata": {"aucs": [0.8558239462519294, 0.8509916724182549, 0.8399413179561979, 0.8446828128572699, 0.8440088033487392, 0.840436545643882, 0.8553248566376483, 0.8389427423078013, 0.8511326457546893, 0.7351670706244203, 0.6977803125530264, 0.7159914690248101, 0.7376260997346057, 0.724407319819464, 0.7142999354809814, 0.7358804805831409, 0.7352102801543174, 0.7382615962178669, 0.17054650853261888, 0.1772479186182223, 0.16011665473918146, 0.15629791612310762, 0.6009568373624434, 0.49048101916085274, 0.16363956352449172, 0.1598415383522157, 0.16232503037280166, 0.13566325204339302, 0.15563151311255663, 0.12952882657316134, 0.17885376897269722, 0.11343752809037233, 0.13836362697120985, 0.12494650770891169, 0.27207584295060894, 0.1476804181141601, 0.9827225016428057, 0.9819316949390162, 0.9857731617439167, 0.9758622083875659, 0.9830169045308665, 0.9810399070873577, 0.9839148966018925, 0.9784817851007276, 0.9853065704301522, 0.5688624168568301, 0.6162955532745108, 0.42445687972677426, 0.5724085519054514, 0.4464044186677284, 0.5431059080782581, 0.5660178863349775, 0.48548942752252855, 0.5338070504197452, 0.381371038843621, 0.5648213603959936, 0.22932399438716444, 0.19422848859309227, 0.3693003251012926, 0.2784678538195591, 0.2915373379235453, 0.22153498429722684, 0.6056693817869128, 0.21497402480794547, 0.18637178013265643, 0.16948020128942498, 0.1776416691166498, 0.18548416841738258, 0.18918880379720182, 0.18229857429993768, 0.1841135245195743, 0.18508374569740393, 0.13221948235650338, 0.11268622638420567, 0.18940022788976407, 0.17184797253523632, 0.21172651237396012, 0.1735153445514438, 0.20092643300662516, 0.19102141633494674, 0.10212378945582112, 9.999999999998899e-05, 0.16727164333519973, 9.999999999998899e-05, 0.046954614162993846, 9.999999999998899e-05, 0.07440864712355322, 9.999999999998899e-05, 0.03651837792548285, 0.00041242676343777873, 0.09815748000913993, 0.06383002923179482, 0.06507269720196962, 0.09835191273668553, 0.04427301297728059, 0.011799174619192665, 0.1039344252897283, 0.09623078222154313, 0.06898107709708456, 0.10626516263413233, 0.16281819272508946, 0.08874850632276687, 0.15312425957758713, 0.23466415673807817, 0.07457481401971877, 0.11604759419267574, 0.06952181010207481, 0.07436412267282178, 0.12730175562726764, 0.10651717220231671, 0.1610346756054547, 0.06040317559953634, 0.16941304529825396, 0.16399947864668174, 0.07881569529967125, 0.08059442161769548, 0.08156104001073383, 0.48537511133895184, 0.5011831768721317, 0.4836113453699291, 0.6347290054483403, 0.5103256471803184, 0.5381156789600892, 0.5375905245642498, 0.5351808057681817, 0.5700873706854377, 0.12027724031040599, 0.10504311805873279, 0.10775622927656481, 0.11242019361396238, 0.1277956113633978, 0.10287817316963044, 0.07310199031605047, 0.09554067869885963, 0.09117347134776155, 0.25792073411241034, 0.200215555703107, 0.19650698668684607, 0.2951508381988067, 0.22218366013779944, 0.19240257306299913, 0.2950617929879501, 0.21197054625116984, 0.16614158731630901, 0.3682283779582498, 0.4392801116954501, 0.3451161086882133, 0.37549264840555885, 0.3813082021877121, 0.42036820255367535, 0.5534793737876269, 0.4455411020866574, 0.470049833965681, 0.2673028317208366, 0.20099953839474916, 0.32221676252644615, 0.3172526266790051, 0.2208142350624125, 0.2879028062964041, 0.3130892743703805, 0.28322523946847133, 0.24513039534428804, 0.2278827956899907, 0.2035038217271108, 0.20757770436416823, 0.21597181925369868, 0.2515992797957961, 0.20759028040026672, 0.23608175605431614, 0.20485210541929177, 0.25359813037789414, 0.22508229656281942, 0.20647760125417924, 0.21594562808761897, 0.22073826522194417, 0.24325919991715306, 0.2169663883565548, 0.20744888412567097, 0.19690915586826974, 0.7372889043837295, 0.8919888776728203, 0.1254052042982401, 0.14764036489197063, 0.8980587413881278, 0.19997359666762837, 0.8513287696254834, 0.12243385120846473, 0.1701038679451713, 0.8924527101276019, 0.6546762578983492, 0.15649086790731837, 0.6255792179533863, 0.2124063533082472, 0.16885314473494273, 0.2125158753823173, 0.10416239518462045, 0.16873358741609668, 0.7195761584857097, 0.18398440656462223, 0.20782751187681847, 0.19672125796461581, 0.20057208836081886, 0.1896505524371871, 0.19600735838077143, 0.21701895304772556, 0.18435159573396476, 0.20077915101069044, 0.09091555580922528, 0.08594644235838766, 0.0951771397168868, 0.08806694924261971, 0.08705546669843967, 0.08670677343500632, 0.08238840089758492, 0.10155503836457902, 0.10818643970764208]}, "mutation_prompt": null}
{"id": "61631b31-b792-4ef3-8dfa-19641deac127", "solution": "import numpy as np\n\nclass OptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n\n    def __call__(self, func):\n        func_calls = 0\n        while func_calls < self.budget:\n            fitness_values = np.apply_along_axis(func, 1, self.positions)\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = np.random.rand(self.n_particles, self.dim), np.random.rand(self.n_particles, self.dim)\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = self.inertia_weight * self.velocities + cognitive_term + social_term\n            self.velocities = np.clip(self.velocities, -self.max_velocity, self.max_velocity)\n            self.positions += self.velocities\n            self.positions = np.clip(self.positions, self.lower_bound, self.upper_bound)\n            \n            self.inertia_weight *= self.inertia_damping", "name": "OptimizedAdaptivePSO", "description": "An optimized version of AdaptivePSO with reduced computational overhead by minimizing redundant calculations and more efficient loop structures.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a77eaf46-a2c4-4839-b864-f4c5a48e5b12", "metadata": {"aucs": [0.8558239462519294, 0.8509916724182549, 0.8399413179561979, 0.8446828128572699, 0.8440088033487392, 0.840436545643882, 0.8553248566376483, 0.8389427423078013, 0.8511326457546893, 0.7351670706244203, 0.6977803125530264, 0.7159914690248101, 0.7376260997346057, 0.724407319819464, 0.7142999354809814, 0.7358804805831409, 0.7352102801543174, 0.7382615962178669, 0.17054650853261888, 0.1772479186182223, 0.16011665473918146, 0.15629791612310762, 0.6009568373624434, 0.49048101916085274, 0.16363956352449172, 0.1598415383522157, 0.16232503037280166, 0.13566325204339302, 0.15563151311255663, 0.12952882657316134, 0.17885376897269722, 0.11343752809037233, 0.13836362697120985, 0.12494650770891169, 0.27207584295060894, 0.1476804181141601, 0.9827225016428057, 0.9819316949390162, 0.9857731617439167, 0.9758622083875659, 0.9830169045308665, 0.9810399070873577, 0.9839148966018925, 0.9784817851007276, 0.9853065704301522, 0.5688624168568301, 0.6162955532745108, 0.42445687972677426, 0.5724085519054514, 0.4464044186677284, 0.5431059080782581, 0.5660178863349775, 0.48548942752252855, 0.5338070504197452, 0.381371038843621, 0.5648213603959936, 0.22932399438716444, 0.19422848859309227, 0.3693003251012926, 0.2784678538195591, 0.2915373379235453, 0.22153498429722684, 0.6056693817869128, 0.21497402480794547, 0.18637178013265643, 0.16948020128942498, 0.1776416691166498, 0.18548416841738258, 0.18918880379720182, 0.18229857429993768, 0.1841135245195743, 0.18508374569740393, 0.13221948235650338, 0.11268622638420567, 0.18940022788976407, 0.17184797253523632, 0.21172651237396012, 0.1735153445514438, 0.20092643300662516, 0.19102141633494674, 0.10212378945582112, 9.999999999998899e-05, 0.16727164333519973, 9.999999999998899e-05, 0.046954614162993846, 9.999999999998899e-05, 0.07440864712355322, 9.999999999998899e-05, 0.03651837792548285, 0.00041242676343777873, 0.09815748000913993, 0.06383002923179482, 0.06507269720196962, 0.09835191273668553, 0.04427301297728059, 0.011799174619192665, 0.1039344252897283, 0.09623078222154313, 0.06898107709708456, 0.10626516263413233, 0.16281819272508946, 0.08874850632276687, 0.15312425957758713, 0.23466415673807817, 0.07457481401971877, 0.11604759419267574, 0.06952181010207481, 0.07436412267282178, 0.12730175562726764, 0.10651717220231671, 0.1610346756054547, 0.06040317559953634, 0.16941304529825396, 0.16399947864668174, 0.07881569529967125, 0.08059442161769548, 0.08156104001073383, 0.48537511133895184, 0.5011831768721317, 0.4836113453699291, 0.6347290054483403, 0.5103256471803184, 0.5381156789600892, 0.5375905245642498, 0.5351808057681817, 0.5700873706854377, 0.12027724031040599, 0.10504311805873279, 0.10775622927656481, 0.11242019361396238, 0.1277956113633978, 0.10287817316963044, 0.07310199031605047, 0.09554067869885963, 0.09117347134776155, 0.25792073411241034, 0.200215555703107, 0.19650698668684607, 0.2951508381988067, 0.22218366013779944, 0.19240257306299913, 0.2950617929879501, 0.21197054625116984, 0.16614158731630901, 0.3682283779582498, 0.4392801116954501, 0.3451161086882133, 0.37549264840555885, 0.3813082021877121, 0.42036820255367535, 0.5534793737876269, 0.4455411020866574, 0.470049833965681, 0.2673028317208366, 0.20099953839474916, 0.32221676252644615, 0.3172526266790051, 0.2208142350624125, 0.2879028062964041, 0.3130892743703805, 0.28322523946847133, 0.24513039534428804, 0.2278827956899907, 0.2035038217271108, 0.20757770436416823, 0.21597181925369868, 0.2515992797957961, 0.20759028040026672, 0.23608175605431614, 0.20485210541929177, 0.25359813037789414, 0.22508229656281942, 0.20647760125417924, 0.21594562808761897, 0.22073826522194417, 0.24325919991715306, 0.2169663883565548, 0.20744888412567097, 0.19690915586826974, 0.7372889043837295, 0.8919888776728203, 0.1254052042982401, 0.14764036489197063, 0.8980587413881278, 0.19997359666762837, 0.8513287696254834, 0.12243385120846473, 0.1701038679451713, 0.8924527101276019, 0.6546762578983492, 0.15649086790731837, 0.6255792179533863, 0.2124063533082472, 0.16885314473494273, 0.2125158753823173, 0.10416239518462045, 0.16873358741609668, 0.7195761584857097, 0.18398440656462223, 0.20782751187681847, 0.19672125796461581, 0.20057208836081886, 0.1896505524371871, 0.19600735838077143, 0.21701895304772556, 0.18435159573396476, 0.20077915101069044, 0.09091555580922528, 0.08594644235838766, 0.0951771397168868, 0.08806694924261971, 0.08705546669843967, 0.08670677343500632, 0.08238840089758492, 0.10155503836457902, 0.10818643970764208]}, "mutation_prompt": null}
{"id": "72d348da-e3f3-48af-846c-93b5ec1cdb3c", "solution": "import numpy as np\n\nclass OptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n\n    def __call__(self, func):\n        func_calls = 0\n        while func_calls < self.budget:\n            fitness_values = np.apply_along_axis(func, 1, self.positions)\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = np.random.rand(self.n_particles, self.dim), np.random.rand(self.n_particles, self.dim)\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = self.inertia_weight * self.velocities + cognitive_term + social_term\n            self.velocities = np.clip(self.velocities, -self.max_velocity, self.max_velocity)\n            self.positions += self.velocities\n            self.positions = np.clip(self.positions, self.lower_bound, self.upper_bound)\n            \n            self.inertia_weight *= self.inertia_damping", "name": "OptimizedAdaptivePSO", "description": "An optimized version of AdaptivePSO with reduced computational overhead by minimizing redundant calculations and more efficient loop structures.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a77eaf46-a2c4-4839-b864-f4c5a48e5b12", "metadata": {"aucs": [0.8558239462519294, 0.8509916724182549, 0.8399413179561979, 0.8446828128572699, 0.8440088033487392, 0.840436545643882, 0.8553248566376483, 0.8389427423078013, 0.8511326457546893, 0.7351670706244203, 0.6977803125530264, 0.7159914690248101, 0.7376260997346057, 0.724407319819464, 0.7142999354809814, 0.7358804805831409, 0.7352102801543174, 0.7382615962178669, 0.17054650853261888, 0.1772479186182223, 0.16011665473918146, 0.15629791612310762, 0.6009568373624434, 0.49048101916085274, 0.16363956352449172, 0.1598415383522157, 0.16232503037280166, 0.13566325204339302, 0.15563151311255663, 0.12952882657316134, 0.17885376897269722, 0.11343752809037233, 0.13836362697120985, 0.12494650770891169, 0.27207584295060894, 0.1476804181141601, 0.9827225016428057, 0.9819316949390162, 0.9857731617439167, 0.9758622083875659, 0.9830169045308665, 0.9810399070873577, 0.9839148966018925, 0.9784817851007276, 0.9853065704301522, 0.5688624168568301, 0.6162955532745108, 0.42445687972677426, 0.5724085519054514, 0.4464044186677284, 0.5431059080782581, 0.5660178863349775, 0.48548942752252855, 0.5338070504197452, 0.381371038843621, 0.5648213603959936, 0.22932399438716444, 0.19422848859309227, 0.3693003251012926, 0.2784678538195591, 0.2915373379235453, 0.22153498429722684, 0.6056693817869128, 0.21497402480794547, 0.18637178013265643, 0.16948020128942498, 0.1776416691166498, 0.18548416841738258, 0.18918880379720182, 0.18229857429993768, 0.1841135245195743, 0.18508374569740393, 0.13221948235650338, 0.11268622638420567, 0.18940022788976407, 0.17184797253523632, 0.21172651237396012, 0.1735153445514438, 0.20092643300662516, 0.19102141633494674, 0.10212378945582112, 9.999999999998899e-05, 0.16727164333519973, 9.999999999998899e-05, 0.046954614162993846, 9.999999999998899e-05, 0.07440864712355322, 9.999999999998899e-05, 0.03651837792548285, 0.00041242676343777873, 0.09815748000913993, 0.06383002923179482, 0.06507269720196962, 0.09835191273668553, 0.04427301297728059, 0.011799174619192665, 0.1039344252897283, 0.09623078222154313, 0.06898107709708456, 0.10626516263413233, 0.16281819272508946, 0.08874850632276687, 0.15312425957758713, 0.23466415673807817, 0.07457481401971877, 0.11604759419267574, 0.06952181010207481, 0.07436412267282178, 0.12730175562726764, 0.10651717220231671, 0.1610346756054547, 0.06040317559953634, 0.16941304529825396, 0.16399947864668174, 0.07881569529967125, 0.08059442161769548, 0.08156104001073383, 0.48537511133895184, 0.5011831768721317, 0.4836113453699291, 0.6347290054483403, 0.5103256471803184, 0.5381156789600892, 0.5375905245642498, 0.5351808057681817, 0.5700873706854377, 0.12027724031040599, 0.10504311805873279, 0.10775622927656481, 0.11242019361396238, 0.1277956113633978, 0.10287817316963044, 0.07310199031605047, 0.09554067869885963, 0.09117347134776155, 0.25792073411241034, 0.200215555703107, 0.19650698668684607, 0.2951508381988067, 0.22218366013779944, 0.19240257306299913, 0.2950617929879501, 0.21197054625116984, 0.16614158731630901, 0.3682283779582498, 0.4392801116954501, 0.3451161086882133, 0.37549264840555885, 0.3813082021877121, 0.42036820255367535, 0.5534793737876269, 0.4455411020866574, 0.470049833965681, 0.2673028317208366, 0.20099953839474916, 0.32221676252644615, 0.3172526266790051, 0.2208142350624125, 0.2879028062964041, 0.3130892743703805, 0.28322523946847133, 0.24513039534428804, 0.2278827956899907, 0.2035038217271108, 0.20757770436416823, 0.21597181925369868, 0.2515992797957961, 0.20759028040026672, 0.23608175605431614, 0.20485210541929177, 0.25359813037789414, 0.22508229656281942, 0.20647760125417924, 0.21594562808761897, 0.22073826522194417, 0.24325919991715306, 0.2169663883565548, 0.20744888412567097, 0.19690915586826974, 0.7372889043837295, 0.8919888776728203, 0.1254052042982401, 0.14764036489197063, 0.8980587413881278, 0.19997359666762837, 0.8513287696254834, 0.12243385120846473, 0.1701038679451713, 0.8924527101276019, 0.6546762578983492, 0.15649086790731837, 0.6255792179533863, 0.2124063533082472, 0.16885314473494273, 0.2125158753823173, 0.10416239518462045, 0.16873358741609668, 0.7195761584857097, 0.18398440656462223, 0.20782751187681847, 0.19672125796461581, 0.20057208836081886, 0.1896505524371871, 0.19600735838077143, 0.21701895304772556, 0.18435159573396476, 0.20077915101069044, 0.09091555580922528, 0.08594644235838766, 0.0951771397168868, 0.08806694924261971, 0.08705546669843967, 0.08670677343500632, 0.08238840089758492, 0.10155503836457902, 0.10818643970764208]}, "mutation_prompt": null}
{"id": "8c37016c-0d80-47f1-b12a-b8e9d5b8756c", "solution": "import numpy as np\n\nclass OptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n\n    def __call__(self, func):\n        func_calls = 0\n        while func_calls < self.budget:\n            fitness_values = np.apply_along_axis(func, 1, self.positions)\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = np.random.rand(self.n_particles, self.dim), np.random.rand(self.n_particles, self.dim)\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = self.inertia_weight * self.velocities + cognitive_term + social_term\n            self.velocities = np.clip(self.velocities, -self.max_velocity, self.max_velocity)\n            self.positions += self.velocities\n            self.positions = np.clip(self.positions, self.lower_bound, self.upper_bound)\n            \n            self.inertia_weight *= self.inertia_damping", "name": "OptimizedAdaptivePSO", "description": "An optimized version of AdaptivePSO with reduced computational overhead by minimizing redundant calculations and more efficient loop structures.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a77eaf46-a2c4-4839-b864-f4c5a48e5b12", "metadata": {"aucs": [0.8558239462519294, 0.8509916724182549, 0.8399413179561979, 0.8446828128572699, 0.8440088033487392, 0.840436545643882, 0.8553248566376483, 0.8389427423078013, 0.8511326457546893, 0.7351670706244203, 0.6977803125530264, 0.7159914690248101, 0.7376260997346057, 0.724407319819464, 0.7142999354809814, 0.7358804805831409, 0.7352102801543174, 0.7382615962178669, 0.17054650853261888, 0.1772479186182223, 0.16011665473918146, 0.15629791612310762, 0.6009568373624434, 0.49048101916085274, 0.16363956352449172, 0.1598415383522157, 0.16232503037280166, 0.13566325204339302, 0.15563151311255663, 0.12952882657316134, 0.17885376897269722, 0.11343752809037233, 0.13836362697120985, 0.12494650770891169, 0.27207584295060894, 0.1476804181141601, 0.9827225016428057, 0.9819316949390162, 0.9857731617439167, 0.9758622083875659, 0.9830169045308665, 0.9810399070873577, 0.9839148966018925, 0.9784817851007276, 0.9853065704301522, 0.5688624168568301, 0.6162955532745108, 0.42445687972677426, 0.5724085519054514, 0.4464044186677284, 0.5431059080782581, 0.5660178863349775, 0.48548942752252855, 0.5338070504197452, 0.381371038843621, 0.5648213603959936, 0.22932399438716444, 0.19422848859309227, 0.3693003251012926, 0.2784678538195591, 0.2915373379235453, 0.22153498429722684, 0.6056693817869128, 0.21497402480794547, 0.18637178013265643, 0.16948020128942498, 0.1776416691166498, 0.18548416841738258, 0.18918880379720182, 0.18229857429993768, 0.1841135245195743, 0.18508374569740393, 0.13221948235650338, 0.11268622638420567, 0.18940022788976407, 0.17184797253523632, 0.21172651237396012, 0.1735153445514438, 0.20092643300662516, 0.19102141633494674, 0.10212378945582112, 9.999999999998899e-05, 0.16727164333519973, 9.999999999998899e-05, 0.046954614162993846, 9.999999999998899e-05, 0.07440864712355322, 9.999999999998899e-05, 0.03651837792548285, 0.00041242676343777873, 0.09815748000913993, 0.06383002923179482, 0.06507269720196962, 0.09835191273668553, 0.04427301297728059, 0.011799174619192665, 0.1039344252897283, 0.09623078222154313, 0.06898107709708456, 0.10626516263413233, 0.16281819272508946, 0.08874850632276687, 0.15312425957758713, 0.23466415673807817, 0.07457481401971877, 0.11604759419267574, 0.06952181010207481, 0.07436412267282178, 0.12730175562726764, 0.10651717220231671, 0.1610346756054547, 0.06040317559953634, 0.16941304529825396, 0.16399947864668174, 0.07881569529967125, 0.08059442161769548, 0.08156104001073383, 0.48537511133895184, 0.5011831768721317, 0.4836113453699291, 0.6347290054483403, 0.5103256471803184, 0.5381156789600892, 0.5375905245642498, 0.5351808057681817, 0.5700873706854377, 0.12027724031040599, 0.10504311805873279, 0.10775622927656481, 0.11242019361396238, 0.1277956113633978, 0.10287817316963044, 0.07310199031605047, 0.09554067869885963, 0.09117347134776155, 0.25792073411241034, 0.200215555703107, 0.19650698668684607, 0.2951508381988067, 0.22218366013779944, 0.19240257306299913, 0.2950617929879501, 0.21197054625116984, 0.16614158731630901, 0.3682283779582498, 0.4392801116954501, 0.3451161086882133, 0.37549264840555885, 0.3813082021877121, 0.42036820255367535, 0.5534793737876269, 0.4455411020866574, 0.470049833965681, 0.2673028317208366, 0.20099953839474916, 0.32221676252644615, 0.3172526266790051, 0.2208142350624125, 0.2879028062964041, 0.3130892743703805, 0.28322523946847133, 0.24513039534428804, 0.2278827956899907, 0.2035038217271108, 0.20757770436416823, 0.21597181925369868, 0.2515992797957961, 0.20759028040026672, 0.23608175605431614, 0.20485210541929177, 0.25359813037789414, 0.22508229656281942, 0.20647760125417924, 0.21594562808761897, 0.22073826522194417, 0.24325919991715306, 0.2169663883565548, 0.20744888412567097, 0.19690915586826974, 0.7372889043837295, 0.8919888776728203, 0.1254052042982401, 0.14764036489197063, 0.8980587413881278, 0.19997359666762837, 0.8513287696254834, 0.12243385120846473, 0.1701038679451713, 0.8924527101276019, 0.6546762578983492, 0.15649086790731837, 0.6255792179533863, 0.2124063533082472, 0.16885314473494273, 0.2125158753823173, 0.10416239518462045, 0.16873358741609668, 0.7195761584857097, 0.18398440656462223, 0.20782751187681847, 0.19672125796461581, 0.20057208836081886, 0.1896505524371871, 0.19600735838077143, 0.21701895304772556, 0.18435159573396476, 0.20077915101069044, 0.09091555580922528, 0.08594644235838766, 0.0951771397168868, 0.08806694924261971, 0.08705546669843967, 0.08670677343500632, 0.08238840089758492, 0.10155503836457902, 0.10818643970764208]}, "mutation_prompt": null}
{"id": "c6e192ad-2782-4aef-af74-5d1a30fe8fb0", "solution": "import numpy as np\n\nclass OptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n\n    def __call__(self, func):\n        func_calls = 0\n        while func_calls < self.budget:\n            fitness_values = np.apply_along_axis(func, 1, self.positions)\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = np.random.rand(self.n_particles, self.dim), np.random.rand(self.n_particles, self.dim)\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = self.inertia_weight * self.velocities + cognitive_term + social_term\n            self.velocities = np.clip(self.velocities, -self.max_velocity, self.max_velocity)\n            self.positions += self.velocities\n            self.positions = np.clip(self.positions, self.lower_bound, self.upper_bound)\n            \n            self.inertia_weight *= self.inertia_damping", "name": "OptimizedAdaptivePSO", "description": "An optimized version of AdaptivePSO with reduced computational overhead by minimizing redundant calculations and more efficient loop structures.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a77eaf46-a2c4-4839-b864-f4c5a48e5b12", "metadata": {"aucs": [0.8558239462519294, 0.8509916724182549, 0.8399413179561979, 0.8446828128572699, 0.8440088033487392, 0.840436545643882, 0.8553248566376483, 0.8389427423078013, 0.8511326457546893, 0.7351670706244203, 0.6977803125530264, 0.7159914690248101, 0.7376260997346057, 0.724407319819464, 0.7142999354809814, 0.7358804805831409, 0.7352102801543174, 0.7382615962178669, 0.17054650853261888, 0.1772479186182223, 0.16011665473918146, 0.15629791612310762, 0.6009568373624434, 0.49048101916085274, 0.16363956352449172, 0.1598415383522157, 0.16232503037280166, 0.13566325204339302, 0.15563151311255663, 0.12952882657316134, 0.17885376897269722, 0.11343752809037233, 0.13836362697120985, 0.12494650770891169, 0.27207584295060894, 0.1476804181141601, 0.9827225016428057, 0.9819316949390162, 0.9857731617439167, 0.9758622083875659, 0.9830169045308665, 0.9810399070873577, 0.9839148966018925, 0.9784817851007276, 0.9853065704301522, 0.5688624168568301, 0.6162955532745108, 0.42445687972677426, 0.5724085519054514, 0.4464044186677284, 0.5431059080782581, 0.5660178863349775, 0.48548942752252855, 0.5338070504197452, 0.381371038843621, 0.5648213603959936, 0.22932399438716444, 0.19422848859309227, 0.3693003251012926, 0.2784678538195591, 0.2915373379235453, 0.22153498429722684, 0.6056693817869128, 0.21497402480794547, 0.18637178013265643, 0.16948020128942498, 0.1776416691166498, 0.18548416841738258, 0.18918880379720182, 0.18229857429993768, 0.1841135245195743, 0.18508374569740393, 0.13221948235650338, 0.11268622638420567, 0.18940022788976407, 0.17184797253523632, 0.21172651237396012, 0.1735153445514438, 0.20092643300662516, 0.19102141633494674, 0.10212378945582112, 9.999999999998899e-05, 0.16727164333519973, 9.999999999998899e-05, 0.046954614162993846, 9.999999999998899e-05, 0.07440864712355322, 9.999999999998899e-05, 0.03651837792548285, 0.00041242676343777873, 0.09815748000913993, 0.06383002923179482, 0.06507269720196962, 0.09835191273668553, 0.04427301297728059, 0.011799174619192665, 0.1039344252897283, 0.09623078222154313, 0.06898107709708456, 0.10626516263413233, 0.16281819272508946, 0.08874850632276687, 0.15312425957758713, 0.23466415673807817, 0.07457481401971877, 0.11604759419267574, 0.06952181010207481, 0.07436412267282178, 0.12730175562726764, 0.10651717220231671, 0.1610346756054547, 0.06040317559953634, 0.16941304529825396, 0.16399947864668174, 0.07881569529967125, 0.08059442161769548, 0.08156104001073383, 0.48537511133895184, 0.5011831768721317, 0.4836113453699291, 0.6347290054483403, 0.5103256471803184, 0.5381156789600892, 0.5375905245642498, 0.5351808057681817, 0.5700873706854377, 0.12027724031040599, 0.10504311805873279, 0.10775622927656481, 0.11242019361396238, 0.1277956113633978, 0.10287817316963044, 0.07310199031605047, 0.09554067869885963, 0.09117347134776155, 0.25792073411241034, 0.200215555703107, 0.19650698668684607, 0.2951508381988067, 0.22218366013779944, 0.19240257306299913, 0.2950617929879501, 0.21197054625116984, 0.16614158731630901, 0.3682283779582498, 0.4392801116954501, 0.3451161086882133, 0.37549264840555885, 0.3813082021877121, 0.42036820255367535, 0.5534793737876269, 0.4455411020866574, 0.470049833965681, 0.2673028317208366, 0.20099953839474916, 0.32221676252644615, 0.3172526266790051, 0.2208142350624125, 0.2879028062964041, 0.3130892743703805, 0.28322523946847133, 0.24513039534428804, 0.2278827956899907, 0.2035038217271108, 0.20757770436416823, 0.21597181925369868, 0.2515992797957961, 0.20759028040026672, 0.23608175605431614, 0.20485210541929177, 0.25359813037789414, 0.22508229656281942, 0.20647760125417924, 0.21594562808761897, 0.22073826522194417, 0.24325919991715306, 0.2169663883565548, 0.20744888412567097, 0.19690915586826974, 0.7372889043837295, 0.8919888776728203, 0.1254052042982401, 0.14764036489197063, 0.8980587413881278, 0.19997359666762837, 0.8513287696254834, 0.12243385120846473, 0.1701038679451713, 0.8924527101276019, 0.6546762578983492, 0.15649086790731837, 0.6255792179533863, 0.2124063533082472, 0.16885314473494273, 0.2125158753823173, 0.10416239518462045, 0.16873358741609668, 0.7195761584857097, 0.18398440656462223, 0.20782751187681847, 0.19672125796461581, 0.20057208836081886, 0.1896505524371871, 0.19600735838077143, 0.21701895304772556, 0.18435159573396476, 0.20077915101069044, 0.09091555580922528, 0.08594644235838766, 0.0951771397168868, 0.08806694924261971, 0.08705546669843967, 0.08670677343500632, 0.08238840089758492, 0.10155503836457902, 0.10818643970764208]}, "mutation_prompt": null}
{"id": "a65422fc-8639-4478-8cd9-beb6b7b7f9e2", "solution": "import numpy as np\n\nclass OptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n\n    def __call__(self, func):\n        func_calls = 0\n        while func_calls < self.budget:\n            fitness_values = np.apply_along_axis(func, 1, self.positions)\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = np.random.rand(self.n_particles, self.dim), np.random.rand(self.n_particles, self.dim)\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = self.inertia_weight * self.velocities + cognitive_term + social_term\n            self.velocities = np.clip(self.velocities, -self.max_velocity, self.max_velocity)\n            self.positions += self.velocities\n            self.positions = np.clip(self.positions, self.lower_bound, self.upper_bound)\n            \n            self.inertia_weight *= self.inertia_damping", "name": "OptimizedAdaptivePSO", "description": "An optimized version of AdaptivePSO with reduced computational overhead by minimizing redundant calculations and more efficient loop structures.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a77eaf46-a2c4-4839-b864-f4c5a48e5b12", "metadata": {"aucs": [0.8558239462519294, 0.8509916724182549, 0.8399413179561979, 0.8446828128572699, 0.8440088033487392, 0.840436545643882, 0.8553248566376483, 0.8389427423078013, 0.8511326457546893, 0.7351670706244203, 0.6977803125530264, 0.7159914690248101, 0.7376260997346057, 0.724407319819464, 0.7142999354809814, 0.7358804805831409, 0.7352102801543174, 0.7382615962178669, 0.17054650853261888, 0.1772479186182223, 0.16011665473918146, 0.15629791612310762, 0.6009568373624434, 0.49048101916085274, 0.16363956352449172, 0.1598415383522157, 0.16232503037280166, 0.13566325204339302, 0.15563151311255663, 0.12952882657316134, 0.17885376897269722, 0.11343752809037233, 0.13836362697120985, 0.12494650770891169, 0.27207584295060894, 0.1476804181141601, 0.9827225016428057, 0.9819316949390162, 0.9857731617439167, 0.9758622083875659, 0.9830169045308665, 0.9810399070873577, 0.9839148966018925, 0.9784817851007276, 0.9853065704301522, 0.5688624168568301, 0.6162955532745108, 0.42445687972677426, 0.5724085519054514, 0.4464044186677284, 0.5431059080782581, 0.5660178863349775, 0.48548942752252855, 0.5338070504197452, 0.381371038843621, 0.5648213603959936, 0.22932399438716444, 0.19422848859309227, 0.3693003251012926, 0.2784678538195591, 0.2915373379235453, 0.22153498429722684, 0.6056693817869128, 0.21497402480794547, 0.18637178013265643, 0.16948020128942498, 0.1776416691166498, 0.18548416841738258, 0.18918880379720182, 0.18229857429993768, 0.1841135245195743, 0.18508374569740393, 0.13221948235650338, 0.11268622638420567, 0.18940022788976407, 0.17184797253523632, 0.21172651237396012, 0.1735153445514438, 0.20092643300662516, 0.19102141633494674, 0.10212378945582112, 9.999999999998899e-05, 0.16727164333519973, 9.999999999998899e-05, 0.046954614162993846, 9.999999999998899e-05, 0.07440864712355322, 9.999999999998899e-05, 0.03651837792548285, 0.00041242676343777873, 0.09815748000913993, 0.06383002923179482, 0.06507269720196962, 0.09835191273668553, 0.04427301297728059, 0.011799174619192665, 0.1039344252897283, 0.09623078222154313, 0.06898107709708456, 0.10626516263413233, 0.16281819272508946, 0.08874850632276687, 0.15312425957758713, 0.23466415673807817, 0.07457481401971877, 0.11604759419267574, 0.06952181010207481, 0.07436412267282178, 0.12730175562726764, 0.10651717220231671, 0.1610346756054547, 0.06040317559953634, 0.16941304529825396, 0.16399947864668174, 0.07881569529967125, 0.08059442161769548, 0.08156104001073383, 0.48537511133895184, 0.5011831768721317, 0.4836113453699291, 0.6347290054483403, 0.5103256471803184, 0.5381156789600892, 0.5375905245642498, 0.5351808057681817, 0.5700873706854377, 0.12027724031040599, 0.10504311805873279, 0.10775622927656481, 0.11242019361396238, 0.1277956113633978, 0.10287817316963044, 0.07310199031605047, 0.09554067869885963, 0.09117347134776155, 0.25792073411241034, 0.200215555703107, 0.19650698668684607, 0.2951508381988067, 0.22218366013779944, 0.19240257306299913, 0.2950617929879501, 0.21197054625116984, 0.16614158731630901, 0.3682283779582498, 0.4392801116954501, 0.3451161086882133, 0.37549264840555885, 0.3813082021877121, 0.42036820255367535, 0.5534793737876269, 0.4455411020866574, 0.470049833965681, 0.2673028317208366, 0.20099953839474916, 0.32221676252644615, 0.3172526266790051, 0.2208142350624125, 0.2879028062964041, 0.3130892743703805, 0.28322523946847133, 0.24513039534428804, 0.2278827956899907, 0.2035038217271108, 0.20757770436416823, 0.21597181925369868, 0.2515992797957961, 0.20759028040026672, 0.23608175605431614, 0.20485210541929177, 0.25359813037789414, 0.22508229656281942, 0.20647760125417924, 0.21594562808761897, 0.22073826522194417, 0.24325919991715306, 0.2169663883565548, 0.20744888412567097, 0.19690915586826974, 0.7372889043837295, 0.8919888776728203, 0.1254052042982401, 0.14764036489197063, 0.8980587413881278, 0.19997359666762837, 0.8513287696254834, 0.12243385120846473, 0.1701038679451713, 0.8924527101276019, 0.6546762578983492, 0.15649086790731837, 0.6255792179533863, 0.2124063533082472, 0.16885314473494273, 0.2125158753823173, 0.10416239518462045, 0.16873358741609668, 0.7195761584857097, 0.18398440656462223, 0.20782751187681847, 0.19672125796461581, 0.20057208836081886, 0.1896505524371871, 0.19600735838077143, 0.21701895304772556, 0.18435159573396476, 0.20077915101069044, 0.09091555580922528, 0.08594644235838766, 0.0951771397168868, 0.08806694924261971, 0.08705546669843967, 0.08670677343500632, 0.08238840089758492, 0.10155503836457902, 0.10818643970764208]}, "mutation_prompt": null}
{"id": "528d77cc-8a81-4ae7-9729-713548ae4162", "solution": "import numpy as np\n\nclass OptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n\n    def __call__(self, func):\n        func_calls = 0\n        while func_calls < self.budget:\n            fitness_values = np.apply_along_axis(func, 1, self.positions)\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = np.random.rand(self.n_particles, self.dim), np.random.rand(self.n_particles, self.dim)\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = self.inertia_weight * self.velocities + cognitive_term + social_term\n            self.velocities = np.clip(self.velocities, -self.max_velocity, self.max_velocity)\n            self.positions += self.velocities\n            self.positions = np.clip(self.positions, self.lower_bound, self.upper_bound)\n            \n            self.inertia_weight *= self.inertia_damping", "name": "OptimizedAdaptivePSO", "description": "An optimized version of AdaptivePSO with reduced computational overhead by minimizing redundant calculations and more efficient loop structures.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a77eaf46-a2c4-4839-b864-f4c5a48e5b12", "metadata": {"aucs": [0.8558239462519294, 0.8509916724182549, 0.8399413179561979, 0.8446828128572699, 0.8440088033487392, 0.840436545643882, 0.8553248566376483, 0.8389427423078013, 0.8511326457546893, 0.7351670706244203, 0.6977803125530264, 0.7159914690248101, 0.7376260997346057, 0.724407319819464, 0.7142999354809814, 0.7358804805831409, 0.7352102801543174, 0.7382615962178669, 0.17054650853261888, 0.1772479186182223, 0.16011665473918146, 0.15629791612310762, 0.6009568373624434, 0.49048101916085274, 0.16363956352449172, 0.1598415383522157, 0.16232503037280166, 0.13566325204339302, 0.15563151311255663, 0.12952882657316134, 0.17885376897269722, 0.11343752809037233, 0.13836362697120985, 0.12494650770891169, 0.27207584295060894, 0.1476804181141601, 0.9827225016428057, 0.9819316949390162, 0.9857731617439167, 0.9758622083875659, 0.9830169045308665, 0.9810399070873577, 0.9839148966018925, 0.9784817851007276, 0.9853065704301522, 0.5688624168568301, 0.6162955532745108, 0.42445687972677426, 0.5724085519054514, 0.4464044186677284, 0.5431059080782581, 0.5660178863349775, 0.48548942752252855, 0.5338070504197452, 0.381371038843621, 0.5648213603959936, 0.22932399438716444, 0.19422848859309227, 0.3693003251012926, 0.2784678538195591, 0.2915373379235453, 0.22153498429722684, 0.6056693817869128, 0.21497402480794547, 0.18637178013265643, 0.16948020128942498, 0.1776416691166498, 0.18548416841738258, 0.18918880379720182, 0.18229857429993768, 0.1841135245195743, 0.18508374569740393, 0.13221948235650338, 0.11268622638420567, 0.18940022788976407, 0.17184797253523632, 0.21172651237396012, 0.1735153445514438, 0.20092643300662516, 0.19102141633494674, 0.10212378945582112, 9.999999999998899e-05, 0.16727164333519973, 9.999999999998899e-05, 0.046954614162993846, 9.999999999998899e-05, 0.07440864712355322, 9.999999999998899e-05, 0.03651837792548285, 0.00041242676343777873, 0.09815748000913993, 0.06383002923179482, 0.06507269720196962, 0.09835191273668553, 0.04427301297728059, 0.011799174619192665, 0.1039344252897283, 0.09623078222154313, 0.06898107709708456, 0.10626516263413233, 0.16281819272508946, 0.08874850632276687, 0.15312425957758713, 0.23466415673807817, 0.07457481401971877, 0.11604759419267574, 0.06952181010207481, 0.07436412267282178, 0.12730175562726764, 0.10651717220231671, 0.1610346756054547, 0.06040317559953634, 0.16941304529825396, 0.16399947864668174, 0.07881569529967125, 0.08059442161769548, 0.08156104001073383, 0.48537511133895184, 0.5011831768721317, 0.4836113453699291, 0.6347290054483403, 0.5103256471803184, 0.5381156789600892, 0.5375905245642498, 0.5351808057681817, 0.5700873706854377, 0.12027724031040599, 0.10504311805873279, 0.10775622927656481, 0.11242019361396238, 0.1277956113633978, 0.10287817316963044, 0.07310199031605047, 0.09554067869885963, 0.09117347134776155, 0.25792073411241034, 0.200215555703107, 0.19650698668684607, 0.2951508381988067, 0.22218366013779944, 0.19240257306299913, 0.2950617929879501, 0.21197054625116984, 0.16614158731630901, 0.3682283779582498, 0.4392801116954501, 0.3451161086882133, 0.37549264840555885, 0.3813082021877121, 0.42036820255367535, 0.5534793737876269, 0.4455411020866574, 0.470049833965681, 0.2673028317208366, 0.20099953839474916, 0.32221676252644615, 0.3172526266790051, 0.2208142350624125, 0.2879028062964041, 0.3130892743703805, 0.28322523946847133, 0.24513039534428804, 0.2278827956899907, 0.2035038217271108, 0.20757770436416823, 0.21597181925369868, 0.2515992797957961, 0.20759028040026672, 0.23608175605431614, 0.20485210541929177, 0.25359813037789414, 0.22508229656281942, 0.20647760125417924, 0.21594562808761897, 0.22073826522194417, 0.24325919991715306, 0.2169663883565548, 0.20744888412567097, 0.19690915586826974, 0.7372889043837295, 0.8919888776728203, 0.1254052042982401, 0.14764036489197063, 0.8980587413881278, 0.19997359666762837, 0.8513287696254834, 0.12243385120846473, 0.1701038679451713, 0.8924527101276019, 0.6546762578983492, 0.15649086790731837, 0.6255792179533863, 0.2124063533082472, 0.16885314473494273, 0.2125158753823173, 0.10416239518462045, 0.16873358741609668, 0.7195761584857097, 0.18398440656462223, 0.20782751187681847, 0.19672125796461581, 0.20057208836081886, 0.1896505524371871, 0.19600735838077143, 0.21701895304772556, 0.18435159573396476, 0.20077915101069044, 0.09091555580922528, 0.08594644235838766, 0.0951771397168868, 0.08806694924261971, 0.08705546669843967, 0.08670677343500632, 0.08238840089758492, 0.10155503836457902, 0.10818643970764208]}, "mutation_prompt": null}
{"id": "4c9d2cb9-d41b-4a04-8c3f-004b5dc4f8fc", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        while func_calls < self.budget:\n            fitness_values = np.apply_along_axis(func, 1, self.positions)\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(self.inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            self.inertia_weight *= self.inertia_damping", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined version of OptimizedAdaptivePSO with reduced loop overhead and optimized numpy operations for enhanced efficiency.", "configspace": "", "generation": 26, "fitness": 0.3215710133490391, "feedback": "The algorithm EnhancedOptimizedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.26.", "error": "", "parent_id": "a77eaf46-a2c4-4839-b864-f4c5a48e5b12", "metadata": {"aucs": [0.8557549476182937, 0.8475171285036693, 0.8536105078429863, 0.8507064002525568, 0.850343376313152, 0.8398146802431917, 0.8529082471662224, 0.857086151549064, 0.8342118375020605, 0.7348427522747882, 0.7162832222907194, 0.7442231006734343, 0.7305020981691666, 0.7299806171996082, 0.7214473476113707, 0.048078220481730716, 0.7181460175609061, 0.7288343875731005, 0.162137312994465, 0.540072501502404, 0.5575826263373954, 0.500088584251174, 0.4761986973307627, 0.17209037673117777, 0.15966455824542913, 0.14870811529646855, 0.5351023382474314, 0.1345012381858054, 0.16999904800417298, 0.1449742786181648, 0.15026824603131828, 0.12794082197330314, 0.14668452250454533, 0.11561770106103153, 0.13580269092636754, 0.1697266585417858, 0.9836535023422585, 0.9860140323351525, 0.9856237791389117, 0.9785335258185546, 0.9835175695441696, 0.9833393505354857, 0.9836507546062551, 0.9782047414610068, 0.9832795763412069, 0.5823945766921036, 0.5011476252932768, 0.5884518303526042, 0.49308818465722104, 0.5956553776315267, 0.38711386211916077, 0.4900296170369015, 0.08867464924887458, 0.4831416591784601, 0.3516029404145803, 0.30852514477150184, 0.2892562142720967, 0.20759739691954293, 0.276288811385905, 0.20920695597458783, 0.2207054890668021, 0.22613956802613966, 0.23613492643167033, 0.17680189150802494, 0.1750929358206038, 0.19575365503818698, 0.18073120782653118, 0.1969445682510642, 0.1729226880023279, 0.18984150964780522, 0.26823553329586536, 0.19912158630825105, 0.18876710725112156, 0.20942847643264217, 0.12906602966133474, 0.19280742994506095, 0.1326606605170293, 0.2013466597536211, 0.20812487805926916, 0.16353010233858145, 0.22147920841683733, 9.999999999998899e-05, 9.999999999998899e-05, 0.07118857562383074, 0.04065224727357308, 0.012480726965406364, 0.022248948277352465, 9.999999999998899e-05, 0.007964411787736214, 0.0012906413020393748, 0.11756720736343707, 0.11449435452157863, 0.0630979709798295, 0.1786078176069339, 0.02945800874119009, 0.04732694147422789, 0.1335603186232882, 0.15988093088244348, 0.1026161441796305, 0.1009600991547317, 0.14948825807365262, 0.04549708669737906, 0.21306677823703735, 0.07240384819802947, 0.08055286657256877, 0.09054664453133832, 0.1619481695909697, 0.17330509668588534, 0.1901257622871324, 0.15389827809002543, 0.030703693527856957, 0.09967375423587532, 0.006216123472267077, 0.11036590614259256, 0.08229463205137344, 0.08027039075694431, 0.08308359594105719, 0.508822391392955, 0.5030743637306276, 0.5384665061850664, 0.5508017556879286, 0.5339889194211281, 0.48934217485093423, 0.5417760077107472, 0.5635867791431783, 0.5513855178417653, 0.09399253383020312, 0.09505788785955172, 0.12069222310409389, 0.1503776537696504, 0.113065195444773, 0.13136983437369631, 0.12498083590119058, 0.1482479371648593, 0.13748988581166122, 0.4679525905898879, 0.1944033029084068, 0.16870046764666602, 0.1750025396532352, 0.27959887892103674, 0.38944836220268275, 0.23377684145291178, 0.2412051644503903, 0.36588525539129135, 0.3684591291386654, 0.3069611214197362, 0.34107657895840604, 0.5098448658162169, 0.3508036578853836, 0.3753121333516487, 0.47204044652987653, 0.47636880833183803, 0.45984604297700593, 0.29691193228872925, 0.36171256728718704, 0.23021606561418673, 0.2047297906346115, 0.2108640021689132, 0.25982542364022143, 0.3128302014904043, 0.2813591231174871, 0.4204156424564308, 0.21990326746804645, 0.2752022248553342, 0.24195815709808954, 0.2280715439183525, 0.23548781098486893, 0.2275319235014468, 0.22290195018316794, 0.23740020059032962, 0.21613794965647337, 0.24404506070843035, 0.20609215493305844, 0.6892638946931693, 0.2072737087507801, 0.24229280367845962, 0.22007089115536138, 0.7148484224593105, 0.6301770830589708, 0.20310239728338542, 0.18754529532433784, 0.17660875959026034, 0.15289368477822685, 0.8061690276582345, 0.20058571687994653, 0.8802251945760537, 0.15039786212305428, 0.1700192478337592, 0.886068885799772, 0.8588741097347085, 0.1565400372741873, 0.5389634356603581, 0.2899159497925953, 0.1695915874327555, 0.2117275936374634, 0.10502445038548136, 0.16809927729761442, 0.674723128700518, 0.19501407061682385, 0.22358095633548325, 0.21322169132340085, 0.17950007876878282, 0.19013493268409087, 0.21162659749429857, 0.2067465134091785, 0.18924167568759753, 0.20556847782921484, 0.1414713983713609, 0.09559339059503857, 0.0873254985437838, 0.09855267495038655, 0.0945421287752346, 0.08320070355810871, 0.09009658138844057, 0.08939037292426255, 0.0945117340045768]}, "mutation_prompt": null}
{"id": "b9efdd0d-f1ca-4b8e-b134-337adc1671ba", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        while func_calls < self.budget:\n            fitness_values = np.apply_along_axis(func, 1, self.positions)\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(self.inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            self.inertia_weight *= self.inertia_damping", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined version of OptimizedAdaptivePSO with reduced loop overhead and optimized numpy operations for enhanced efficiency.", "configspace": "", "generation": 27, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4c9d2cb9-d41b-4a04-8c3f-004b5dc4f8fc", "metadata": {"aucs": [0.8557549476182937, 0.8475171285036693, 0.8536105078429863, 0.8507064002525568, 0.850343376313152, 0.8398146802431917, 0.8529082471662224, 0.857086151549064, 0.8342118375020605, 0.7348427522747882, 0.7162832222907194, 0.7442231006734343, 0.7305020981691666, 0.7299806171996082, 0.7214473476113707, 0.048078220481730716, 0.7181460175609061, 0.7288343875731005, 0.162137312994465, 0.540072501502404, 0.5575826263373954, 0.500088584251174, 0.4761986973307627, 0.17209037673117777, 0.15966455824542913, 0.14870811529646855, 0.5351023382474314, 0.1345012381858054, 0.16999904800417298, 0.1449742786181648, 0.15026824603131828, 0.12794082197330314, 0.14668452250454533, 0.11561770106103153, 0.13580269092636754, 0.1697266585417858, 0.9836535023422585, 0.9860140323351525, 0.9856237791389117, 0.9785335258185546, 0.9835175695441696, 0.9833393505354857, 0.9836507546062551, 0.9782047414610068, 0.9832795763412069, 0.5823945766921036, 0.5011476252932768, 0.5884518303526042, 0.49308818465722104, 0.5956553776315267, 0.38711386211916077, 0.4900296170369015, 0.08867464924887458, 0.4831416591784601, 0.3516029404145803, 0.30852514477150184, 0.2892562142720967, 0.20759739691954293, 0.276288811385905, 0.20920695597458783, 0.2207054890668021, 0.22613956802613966, 0.23613492643167033, 0.17680189150802494, 0.1750929358206038, 0.19575365503818698, 0.18073120782653118, 0.1969445682510642, 0.1729226880023279, 0.18984150964780522, 0.26823553329586536, 0.19912158630825105, 0.18876710725112156, 0.20942847643264217, 0.12906602966133474, 0.19280742994506095, 0.1326606605170293, 0.2013466597536211, 0.20812487805926916, 0.16353010233858145, 0.22147920841683733, 9.999999999998899e-05, 9.999999999998899e-05, 0.07118857562383074, 0.04065224727357308, 0.012480726965406364, 0.022248948277352465, 9.999999999998899e-05, 0.007964411787736214, 0.0012906413020393748, 0.11756720736343707, 0.11449435452157863, 0.0630979709798295, 0.1786078176069339, 0.02945800874119009, 0.04732694147422789, 0.1335603186232882, 0.15988093088244348, 0.1026161441796305, 0.1009600991547317, 0.14948825807365262, 0.04549708669737906, 0.21306677823703735, 0.07240384819802947, 0.08055286657256877, 0.09054664453133832, 0.1619481695909697, 0.17330509668588534, 0.1901257622871324, 0.15389827809002543, 0.030703693527856957, 0.09967375423587532, 0.006216123472267077, 0.11036590614259256, 0.08229463205137344, 0.08027039075694431, 0.08308359594105719, 0.508822391392955, 0.5030743637306276, 0.5384665061850664, 0.5508017556879286, 0.5339889194211281, 0.48934217485093423, 0.5417760077107472, 0.5635867791431783, 0.5513855178417653, 0.09399253383020312, 0.09505788785955172, 0.12069222310409389, 0.1503776537696504, 0.113065195444773, 0.13136983437369631, 0.12498083590119058, 0.1482479371648593, 0.13748988581166122, 0.4679525905898879, 0.1944033029084068, 0.16870046764666602, 0.1750025396532352, 0.27959887892103674, 0.38944836220268275, 0.23377684145291178, 0.2412051644503903, 0.36588525539129135, 0.3684591291386654, 0.3069611214197362, 0.34107657895840604, 0.5098448658162169, 0.3508036578853836, 0.3753121333516487, 0.47204044652987653, 0.47636880833183803, 0.45984604297700593, 0.29691193228872925, 0.36171256728718704, 0.23021606561418673, 0.2047297906346115, 0.2108640021689132, 0.25982542364022143, 0.3128302014904043, 0.2813591231174871, 0.4204156424564308, 0.21990326746804645, 0.2752022248553342, 0.24195815709808954, 0.2280715439183525, 0.23548781098486893, 0.2275319235014468, 0.22290195018316794, 0.23740020059032962, 0.21613794965647337, 0.24404506070843035, 0.20609215493305844, 0.6892638946931693, 0.2072737087507801, 0.24229280367845962, 0.22007089115536138, 0.7148484224593105, 0.6301770830589708, 0.20310239728338542, 0.18754529532433784, 0.17660875959026034, 0.15289368477822685, 0.8061690276582345, 0.20058571687994653, 0.8802251945760537, 0.15039786212305428, 0.1700192478337592, 0.886068885799772, 0.8588741097347085, 0.1565400372741873, 0.5389634356603581, 0.2899159497925953, 0.1695915874327555, 0.2117275936374634, 0.10502445038548136, 0.16809927729761442, 0.674723128700518, 0.19501407061682385, 0.22358095633548325, 0.21322169132340085, 0.17950007876878282, 0.19013493268409087, 0.21162659749429857, 0.2067465134091785, 0.18924167568759753, 0.20556847782921484, 0.1414713983713609, 0.09559339059503857, 0.0873254985437838, 0.09855267495038655, 0.0945421287752346, 0.08320070355810871, 0.09009658138844057, 0.08939037292426255, 0.0945117340045768]}, "mutation_prompt": null}
{"id": "11c42935-aba0-4832-aec9-924ec7f2d195", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        while func_calls < self.budget:\n            fitness_values = np.apply_along_axis(func, 1, self.positions)\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(self.inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            self.inertia_weight *= self.inertia_damping", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined version of OptimizedAdaptivePSO with reduced loop overhead and optimized numpy operations for enhanced efficiency.", "configspace": "", "generation": 27, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4c9d2cb9-d41b-4a04-8c3f-004b5dc4f8fc", "metadata": {"aucs": [0.8557549476182937, 0.8475171285036693, 0.8536105078429863, 0.8507064002525568, 0.850343376313152, 0.8398146802431917, 0.8529082471662224, 0.857086151549064, 0.8342118375020605, 0.7348427522747882, 0.7162832222907194, 0.7442231006734343, 0.7305020981691666, 0.7299806171996082, 0.7214473476113707, 0.048078220481730716, 0.7181460175609061, 0.7288343875731005, 0.162137312994465, 0.540072501502404, 0.5575826263373954, 0.500088584251174, 0.4761986973307627, 0.17209037673117777, 0.15966455824542913, 0.14870811529646855, 0.5351023382474314, 0.1345012381858054, 0.16999904800417298, 0.1449742786181648, 0.15026824603131828, 0.12794082197330314, 0.14668452250454533, 0.11561770106103153, 0.13580269092636754, 0.1697266585417858, 0.9836535023422585, 0.9860140323351525, 0.9856237791389117, 0.9785335258185546, 0.9835175695441696, 0.9833393505354857, 0.9836507546062551, 0.9782047414610068, 0.9832795763412069, 0.5823945766921036, 0.5011476252932768, 0.5884518303526042, 0.49308818465722104, 0.5956553776315267, 0.38711386211916077, 0.4900296170369015, 0.08867464924887458, 0.4831416591784601, 0.3516029404145803, 0.30852514477150184, 0.2892562142720967, 0.20759739691954293, 0.276288811385905, 0.20920695597458783, 0.2207054890668021, 0.22613956802613966, 0.23613492643167033, 0.17680189150802494, 0.1750929358206038, 0.19575365503818698, 0.18073120782653118, 0.1969445682510642, 0.1729226880023279, 0.18984150964780522, 0.26823553329586536, 0.19912158630825105, 0.18876710725112156, 0.20942847643264217, 0.12906602966133474, 0.19280742994506095, 0.1326606605170293, 0.2013466597536211, 0.20812487805926916, 0.16353010233858145, 0.22147920841683733, 9.999999999998899e-05, 9.999999999998899e-05, 0.07118857562383074, 0.04065224727357308, 0.012480726965406364, 0.022248948277352465, 9.999999999998899e-05, 0.007964411787736214, 0.0012906413020393748, 0.11756720736343707, 0.11449435452157863, 0.0630979709798295, 0.1786078176069339, 0.02945800874119009, 0.04732694147422789, 0.1335603186232882, 0.15988093088244348, 0.1026161441796305, 0.1009600991547317, 0.14948825807365262, 0.04549708669737906, 0.21306677823703735, 0.07240384819802947, 0.08055286657256877, 0.09054664453133832, 0.1619481695909697, 0.17330509668588534, 0.1901257622871324, 0.15389827809002543, 0.030703693527856957, 0.09967375423587532, 0.006216123472267077, 0.11036590614259256, 0.08229463205137344, 0.08027039075694431, 0.08308359594105719, 0.508822391392955, 0.5030743637306276, 0.5384665061850664, 0.5508017556879286, 0.5339889194211281, 0.48934217485093423, 0.5417760077107472, 0.5635867791431783, 0.5513855178417653, 0.09399253383020312, 0.09505788785955172, 0.12069222310409389, 0.1503776537696504, 0.113065195444773, 0.13136983437369631, 0.12498083590119058, 0.1482479371648593, 0.13748988581166122, 0.4679525905898879, 0.1944033029084068, 0.16870046764666602, 0.1750025396532352, 0.27959887892103674, 0.38944836220268275, 0.23377684145291178, 0.2412051644503903, 0.36588525539129135, 0.3684591291386654, 0.3069611214197362, 0.34107657895840604, 0.5098448658162169, 0.3508036578853836, 0.3753121333516487, 0.47204044652987653, 0.47636880833183803, 0.45984604297700593, 0.29691193228872925, 0.36171256728718704, 0.23021606561418673, 0.2047297906346115, 0.2108640021689132, 0.25982542364022143, 0.3128302014904043, 0.2813591231174871, 0.4204156424564308, 0.21990326746804645, 0.2752022248553342, 0.24195815709808954, 0.2280715439183525, 0.23548781098486893, 0.2275319235014468, 0.22290195018316794, 0.23740020059032962, 0.21613794965647337, 0.24404506070843035, 0.20609215493305844, 0.6892638946931693, 0.2072737087507801, 0.24229280367845962, 0.22007089115536138, 0.7148484224593105, 0.6301770830589708, 0.20310239728338542, 0.18754529532433784, 0.17660875959026034, 0.15289368477822685, 0.8061690276582345, 0.20058571687994653, 0.8802251945760537, 0.15039786212305428, 0.1700192478337592, 0.886068885799772, 0.8588741097347085, 0.1565400372741873, 0.5389634356603581, 0.2899159497925953, 0.1695915874327555, 0.2117275936374634, 0.10502445038548136, 0.16809927729761442, 0.674723128700518, 0.19501407061682385, 0.22358095633548325, 0.21322169132340085, 0.17950007876878282, 0.19013493268409087, 0.21162659749429857, 0.2067465134091785, 0.18924167568759753, 0.20556847782921484, 0.1414713983713609, 0.09559339059503857, 0.0873254985437838, 0.09855267495038655, 0.0945421287752346, 0.08320070355810871, 0.09009658138844057, 0.08939037292426255, 0.0945117340045768]}, "mutation_prompt": null}
{"id": "1eca04f5-484a-4621-9891-4ae9abf85067", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        while func_calls < self.budget:\n            fitness_values = np.apply_along_axis(func, 1, self.positions)\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(self.inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            self.inertia_weight *= self.inertia_damping", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined version of OptimizedAdaptivePSO with reduced loop overhead and optimized numpy operations for enhanced efficiency.", "configspace": "", "generation": 27, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4c9d2cb9-d41b-4a04-8c3f-004b5dc4f8fc", "metadata": {"aucs": [0.8557549476182937, 0.8475171285036693, 0.8536105078429863, 0.8507064002525568, 0.850343376313152, 0.8398146802431917, 0.8529082471662224, 0.857086151549064, 0.8342118375020605, 0.7348427522747882, 0.7162832222907194, 0.7442231006734343, 0.7305020981691666, 0.7299806171996082, 0.7214473476113707, 0.048078220481730716, 0.7181460175609061, 0.7288343875731005, 0.162137312994465, 0.540072501502404, 0.5575826263373954, 0.500088584251174, 0.4761986973307627, 0.17209037673117777, 0.15966455824542913, 0.14870811529646855, 0.5351023382474314, 0.1345012381858054, 0.16999904800417298, 0.1449742786181648, 0.15026824603131828, 0.12794082197330314, 0.14668452250454533, 0.11561770106103153, 0.13580269092636754, 0.1697266585417858, 0.9836535023422585, 0.9860140323351525, 0.9856237791389117, 0.9785335258185546, 0.9835175695441696, 0.9833393505354857, 0.9836507546062551, 0.9782047414610068, 0.9832795763412069, 0.5823945766921036, 0.5011476252932768, 0.5884518303526042, 0.49308818465722104, 0.5956553776315267, 0.38711386211916077, 0.4900296170369015, 0.08867464924887458, 0.4831416591784601, 0.3516029404145803, 0.30852514477150184, 0.2892562142720967, 0.20759739691954293, 0.276288811385905, 0.20920695597458783, 0.2207054890668021, 0.22613956802613966, 0.23613492643167033, 0.17680189150802494, 0.1750929358206038, 0.19575365503818698, 0.18073120782653118, 0.1969445682510642, 0.1729226880023279, 0.18984150964780522, 0.26823553329586536, 0.19912158630825105, 0.18876710725112156, 0.20942847643264217, 0.12906602966133474, 0.19280742994506095, 0.1326606605170293, 0.2013466597536211, 0.20812487805926916, 0.16353010233858145, 0.22147920841683733, 9.999999999998899e-05, 9.999999999998899e-05, 0.07118857562383074, 0.04065224727357308, 0.012480726965406364, 0.022248948277352465, 9.999999999998899e-05, 0.007964411787736214, 0.0012906413020393748, 0.11756720736343707, 0.11449435452157863, 0.0630979709798295, 0.1786078176069339, 0.02945800874119009, 0.04732694147422789, 0.1335603186232882, 0.15988093088244348, 0.1026161441796305, 0.1009600991547317, 0.14948825807365262, 0.04549708669737906, 0.21306677823703735, 0.07240384819802947, 0.08055286657256877, 0.09054664453133832, 0.1619481695909697, 0.17330509668588534, 0.1901257622871324, 0.15389827809002543, 0.030703693527856957, 0.09967375423587532, 0.006216123472267077, 0.11036590614259256, 0.08229463205137344, 0.08027039075694431, 0.08308359594105719, 0.508822391392955, 0.5030743637306276, 0.5384665061850664, 0.5508017556879286, 0.5339889194211281, 0.48934217485093423, 0.5417760077107472, 0.5635867791431783, 0.5513855178417653, 0.09399253383020312, 0.09505788785955172, 0.12069222310409389, 0.1503776537696504, 0.113065195444773, 0.13136983437369631, 0.12498083590119058, 0.1482479371648593, 0.13748988581166122, 0.4679525905898879, 0.1944033029084068, 0.16870046764666602, 0.1750025396532352, 0.27959887892103674, 0.38944836220268275, 0.23377684145291178, 0.2412051644503903, 0.36588525539129135, 0.3684591291386654, 0.3069611214197362, 0.34107657895840604, 0.5098448658162169, 0.3508036578853836, 0.3753121333516487, 0.47204044652987653, 0.47636880833183803, 0.45984604297700593, 0.29691193228872925, 0.36171256728718704, 0.23021606561418673, 0.2047297906346115, 0.2108640021689132, 0.25982542364022143, 0.3128302014904043, 0.2813591231174871, 0.4204156424564308, 0.21990326746804645, 0.2752022248553342, 0.24195815709808954, 0.2280715439183525, 0.23548781098486893, 0.2275319235014468, 0.22290195018316794, 0.23740020059032962, 0.21613794965647337, 0.24404506070843035, 0.20609215493305844, 0.6892638946931693, 0.2072737087507801, 0.24229280367845962, 0.22007089115536138, 0.7148484224593105, 0.6301770830589708, 0.20310239728338542, 0.18754529532433784, 0.17660875959026034, 0.15289368477822685, 0.8061690276582345, 0.20058571687994653, 0.8802251945760537, 0.15039786212305428, 0.1700192478337592, 0.886068885799772, 0.8588741097347085, 0.1565400372741873, 0.5389634356603581, 0.2899159497925953, 0.1695915874327555, 0.2117275936374634, 0.10502445038548136, 0.16809927729761442, 0.674723128700518, 0.19501407061682385, 0.22358095633548325, 0.21322169132340085, 0.17950007876878282, 0.19013493268409087, 0.21162659749429857, 0.2067465134091785, 0.18924167568759753, 0.20556847782921484, 0.1414713983713609, 0.09559339059503857, 0.0873254985437838, 0.09855267495038655, 0.0945421287752346, 0.08320070355810871, 0.09009658138844057, 0.08939037292426255, 0.0945117340045768]}, "mutation_prompt": null}
{"id": "0699738b-6265-4c06-bc33-0fcf4a170793", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        while func_calls < self.budget:\n            fitness_values = np.apply_along_axis(func, 1, self.positions)\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(self.inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            self.inertia_weight *= self.inertia_damping", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined version of OptimizedAdaptivePSO with reduced loop overhead and optimized numpy operations for enhanced efficiency.", "configspace": "", "generation": 27, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4c9d2cb9-d41b-4a04-8c3f-004b5dc4f8fc", "metadata": {"aucs": [0.8557549476182937, 0.8475171285036693, 0.8536105078429863, 0.8507064002525568, 0.850343376313152, 0.8398146802431917, 0.8529082471662224, 0.857086151549064, 0.8342118375020605, 0.7348427522747882, 0.7162832222907194, 0.7442231006734343, 0.7305020981691666, 0.7299806171996082, 0.7214473476113707, 0.048078220481730716, 0.7181460175609061, 0.7288343875731005, 0.162137312994465, 0.540072501502404, 0.5575826263373954, 0.500088584251174, 0.4761986973307627, 0.17209037673117777, 0.15966455824542913, 0.14870811529646855, 0.5351023382474314, 0.1345012381858054, 0.16999904800417298, 0.1449742786181648, 0.15026824603131828, 0.12794082197330314, 0.14668452250454533, 0.11561770106103153, 0.13580269092636754, 0.1697266585417858, 0.9836535023422585, 0.9860140323351525, 0.9856237791389117, 0.9785335258185546, 0.9835175695441696, 0.9833393505354857, 0.9836507546062551, 0.9782047414610068, 0.9832795763412069, 0.5823945766921036, 0.5011476252932768, 0.5884518303526042, 0.49308818465722104, 0.5956553776315267, 0.38711386211916077, 0.4900296170369015, 0.08867464924887458, 0.4831416591784601, 0.3516029404145803, 0.30852514477150184, 0.2892562142720967, 0.20759739691954293, 0.276288811385905, 0.20920695597458783, 0.2207054890668021, 0.22613956802613966, 0.23613492643167033, 0.17680189150802494, 0.1750929358206038, 0.19575365503818698, 0.18073120782653118, 0.1969445682510642, 0.1729226880023279, 0.18984150964780522, 0.26823553329586536, 0.19912158630825105, 0.18876710725112156, 0.20942847643264217, 0.12906602966133474, 0.19280742994506095, 0.1326606605170293, 0.2013466597536211, 0.20812487805926916, 0.16353010233858145, 0.22147920841683733, 9.999999999998899e-05, 9.999999999998899e-05, 0.07118857562383074, 0.04065224727357308, 0.012480726965406364, 0.022248948277352465, 9.999999999998899e-05, 0.007964411787736214, 0.0012906413020393748, 0.11756720736343707, 0.11449435452157863, 0.0630979709798295, 0.1786078176069339, 0.02945800874119009, 0.04732694147422789, 0.1335603186232882, 0.15988093088244348, 0.1026161441796305, 0.1009600991547317, 0.14948825807365262, 0.04549708669737906, 0.21306677823703735, 0.07240384819802947, 0.08055286657256877, 0.09054664453133832, 0.1619481695909697, 0.17330509668588534, 0.1901257622871324, 0.15389827809002543, 0.030703693527856957, 0.09967375423587532, 0.006216123472267077, 0.11036590614259256, 0.08229463205137344, 0.08027039075694431, 0.08308359594105719, 0.508822391392955, 0.5030743637306276, 0.5384665061850664, 0.5508017556879286, 0.5339889194211281, 0.48934217485093423, 0.5417760077107472, 0.5635867791431783, 0.5513855178417653, 0.09399253383020312, 0.09505788785955172, 0.12069222310409389, 0.1503776537696504, 0.113065195444773, 0.13136983437369631, 0.12498083590119058, 0.1482479371648593, 0.13748988581166122, 0.4679525905898879, 0.1944033029084068, 0.16870046764666602, 0.1750025396532352, 0.27959887892103674, 0.38944836220268275, 0.23377684145291178, 0.2412051644503903, 0.36588525539129135, 0.3684591291386654, 0.3069611214197362, 0.34107657895840604, 0.5098448658162169, 0.3508036578853836, 0.3753121333516487, 0.47204044652987653, 0.47636880833183803, 0.45984604297700593, 0.29691193228872925, 0.36171256728718704, 0.23021606561418673, 0.2047297906346115, 0.2108640021689132, 0.25982542364022143, 0.3128302014904043, 0.2813591231174871, 0.4204156424564308, 0.21990326746804645, 0.2752022248553342, 0.24195815709808954, 0.2280715439183525, 0.23548781098486893, 0.2275319235014468, 0.22290195018316794, 0.23740020059032962, 0.21613794965647337, 0.24404506070843035, 0.20609215493305844, 0.6892638946931693, 0.2072737087507801, 0.24229280367845962, 0.22007089115536138, 0.7148484224593105, 0.6301770830589708, 0.20310239728338542, 0.18754529532433784, 0.17660875959026034, 0.15289368477822685, 0.8061690276582345, 0.20058571687994653, 0.8802251945760537, 0.15039786212305428, 0.1700192478337592, 0.886068885799772, 0.8588741097347085, 0.1565400372741873, 0.5389634356603581, 0.2899159497925953, 0.1695915874327555, 0.2117275936374634, 0.10502445038548136, 0.16809927729761442, 0.674723128700518, 0.19501407061682385, 0.22358095633548325, 0.21322169132340085, 0.17950007876878282, 0.19013493268409087, 0.21162659749429857, 0.2067465134091785, 0.18924167568759753, 0.20556847782921484, 0.1414713983713609, 0.09559339059503857, 0.0873254985437838, 0.09855267495038655, 0.0945421287752346, 0.08320070355810871, 0.09009658138844057, 0.08939037292426255, 0.0945117340045768]}, "mutation_prompt": null}
{"id": "396db418-396a-4d6f-9df4-b145c3d18a4f", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        while func_calls < self.budget:\n            fitness_values = np.apply_along_axis(func, 1, self.positions)\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(self.inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            self.inertia_weight *= self.inertia_damping", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined version of OptimizedAdaptivePSO with reduced loop overhead and optimized numpy operations for enhanced efficiency.", "configspace": "", "generation": 27, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4c9d2cb9-d41b-4a04-8c3f-004b5dc4f8fc", "metadata": {"aucs": [0.8557549476182937, 0.8475171285036693, 0.8536105078429863, 0.8507064002525568, 0.850343376313152, 0.8398146802431917, 0.8529082471662224, 0.857086151549064, 0.8342118375020605, 0.7348427522747882, 0.7162832222907194, 0.7442231006734343, 0.7305020981691666, 0.7299806171996082, 0.7214473476113707, 0.048078220481730716, 0.7181460175609061, 0.7288343875731005, 0.162137312994465, 0.540072501502404, 0.5575826263373954, 0.500088584251174, 0.4761986973307627, 0.17209037673117777, 0.15966455824542913, 0.14870811529646855, 0.5351023382474314, 0.1345012381858054, 0.16999904800417298, 0.1449742786181648, 0.15026824603131828, 0.12794082197330314, 0.14668452250454533, 0.11561770106103153, 0.13580269092636754, 0.1697266585417858, 0.9836535023422585, 0.9860140323351525, 0.9856237791389117, 0.9785335258185546, 0.9835175695441696, 0.9833393505354857, 0.9836507546062551, 0.9782047414610068, 0.9832795763412069, 0.5823945766921036, 0.5011476252932768, 0.5884518303526042, 0.49308818465722104, 0.5956553776315267, 0.38711386211916077, 0.4900296170369015, 0.08867464924887458, 0.4831416591784601, 0.3516029404145803, 0.30852514477150184, 0.2892562142720967, 0.20759739691954293, 0.276288811385905, 0.20920695597458783, 0.2207054890668021, 0.22613956802613966, 0.23613492643167033, 0.17680189150802494, 0.1750929358206038, 0.19575365503818698, 0.18073120782653118, 0.1969445682510642, 0.1729226880023279, 0.18984150964780522, 0.26823553329586536, 0.19912158630825105, 0.18876710725112156, 0.20942847643264217, 0.12906602966133474, 0.19280742994506095, 0.1326606605170293, 0.2013466597536211, 0.20812487805926916, 0.16353010233858145, 0.22147920841683733, 9.999999999998899e-05, 9.999999999998899e-05, 0.07118857562383074, 0.04065224727357308, 0.012480726965406364, 0.022248948277352465, 9.999999999998899e-05, 0.007964411787736214, 0.0012906413020393748, 0.11756720736343707, 0.11449435452157863, 0.0630979709798295, 0.1786078176069339, 0.02945800874119009, 0.04732694147422789, 0.1335603186232882, 0.15988093088244348, 0.1026161441796305, 0.1009600991547317, 0.14948825807365262, 0.04549708669737906, 0.21306677823703735, 0.07240384819802947, 0.08055286657256877, 0.09054664453133832, 0.1619481695909697, 0.17330509668588534, 0.1901257622871324, 0.15389827809002543, 0.030703693527856957, 0.09967375423587532, 0.006216123472267077, 0.11036590614259256, 0.08229463205137344, 0.08027039075694431, 0.08308359594105719, 0.508822391392955, 0.5030743637306276, 0.5384665061850664, 0.5508017556879286, 0.5339889194211281, 0.48934217485093423, 0.5417760077107472, 0.5635867791431783, 0.5513855178417653, 0.09399253383020312, 0.09505788785955172, 0.12069222310409389, 0.1503776537696504, 0.113065195444773, 0.13136983437369631, 0.12498083590119058, 0.1482479371648593, 0.13748988581166122, 0.4679525905898879, 0.1944033029084068, 0.16870046764666602, 0.1750025396532352, 0.27959887892103674, 0.38944836220268275, 0.23377684145291178, 0.2412051644503903, 0.36588525539129135, 0.3684591291386654, 0.3069611214197362, 0.34107657895840604, 0.5098448658162169, 0.3508036578853836, 0.3753121333516487, 0.47204044652987653, 0.47636880833183803, 0.45984604297700593, 0.29691193228872925, 0.36171256728718704, 0.23021606561418673, 0.2047297906346115, 0.2108640021689132, 0.25982542364022143, 0.3128302014904043, 0.2813591231174871, 0.4204156424564308, 0.21990326746804645, 0.2752022248553342, 0.24195815709808954, 0.2280715439183525, 0.23548781098486893, 0.2275319235014468, 0.22290195018316794, 0.23740020059032962, 0.21613794965647337, 0.24404506070843035, 0.20609215493305844, 0.6892638946931693, 0.2072737087507801, 0.24229280367845962, 0.22007089115536138, 0.7148484224593105, 0.6301770830589708, 0.20310239728338542, 0.18754529532433784, 0.17660875959026034, 0.15289368477822685, 0.8061690276582345, 0.20058571687994653, 0.8802251945760537, 0.15039786212305428, 0.1700192478337592, 0.886068885799772, 0.8588741097347085, 0.1565400372741873, 0.5389634356603581, 0.2899159497925953, 0.1695915874327555, 0.2117275936374634, 0.10502445038548136, 0.16809927729761442, 0.674723128700518, 0.19501407061682385, 0.22358095633548325, 0.21322169132340085, 0.17950007876878282, 0.19013493268409087, 0.21162659749429857, 0.2067465134091785, 0.18924167568759753, 0.20556847782921484, 0.1414713983713609, 0.09559339059503857, 0.0873254985437838, 0.09855267495038655, 0.0945421287752346, 0.08320070355810871, 0.09009658138844057, 0.08939037292426255, 0.0945117340045768]}, "mutation_prompt": null}
{"id": "c2336709-9466-48ee-990b-87aff23aa4d1", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        while func_calls < self.budget:\n            fitness_values = np.apply_along_axis(func, 1, self.positions)\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(self.inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            self.inertia_weight *= self.inertia_damping", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined version of OptimizedAdaptivePSO with reduced loop overhead and optimized numpy operations for enhanced efficiency.", "configspace": "", "generation": 27, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4c9d2cb9-d41b-4a04-8c3f-004b5dc4f8fc", "metadata": {"aucs": [0.8557549476182937, 0.8475171285036693, 0.8536105078429863, 0.8507064002525568, 0.850343376313152, 0.8398146802431917, 0.8529082471662224, 0.857086151549064, 0.8342118375020605, 0.7348427522747882, 0.7162832222907194, 0.7442231006734343, 0.7305020981691666, 0.7299806171996082, 0.7214473476113707, 0.048078220481730716, 0.7181460175609061, 0.7288343875731005, 0.162137312994465, 0.540072501502404, 0.5575826263373954, 0.500088584251174, 0.4761986973307627, 0.17209037673117777, 0.15966455824542913, 0.14870811529646855, 0.5351023382474314, 0.1345012381858054, 0.16999904800417298, 0.1449742786181648, 0.15026824603131828, 0.12794082197330314, 0.14668452250454533, 0.11561770106103153, 0.13580269092636754, 0.1697266585417858, 0.9836535023422585, 0.9860140323351525, 0.9856237791389117, 0.9785335258185546, 0.9835175695441696, 0.9833393505354857, 0.9836507546062551, 0.9782047414610068, 0.9832795763412069, 0.5823945766921036, 0.5011476252932768, 0.5884518303526042, 0.49308818465722104, 0.5956553776315267, 0.38711386211916077, 0.4900296170369015, 0.08867464924887458, 0.4831416591784601, 0.3516029404145803, 0.30852514477150184, 0.2892562142720967, 0.20759739691954293, 0.276288811385905, 0.20920695597458783, 0.2207054890668021, 0.22613956802613966, 0.23613492643167033, 0.17680189150802494, 0.1750929358206038, 0.19575365503818698, 0.18073120782653118, 0.1969445682510642, 0.1729226880023279, 0.18984150964780522, 0.26823553329586536, 0.19912158630825105, 0.18876710725112156, 0.20942847643264217, 0.12906602966133474, 0.19280742994506095, 0.1326606605170293, 0.2013466597536211, 0.20812487805926916, 0.16353010233858145, 0.22147920841683733, 9.999999999998899e-05, 9.999999999998899e-05, 0.07118857562383074, 0.04065224727357308, 0.012480726965406364, 0.022248948277352465, 9.999999999998899e-05, 0.007964411787736214, 0.0012906413020393748, 0.11756720736343707, 0.11449435452157863, 0.0630979709798295, 0.1786078176069339, 0.02945800874119009, 0.04732694147422789, 0.1335603186232882, 0.15988093088244348, 0.1026161441796305, 0.1009600991547317, 0.14948825807365262, 0.04549708669737906, 0.21306677823703735, 0.07240384819802947, 0.08055286657256877, 0.09054664453133832, 0.1619481695909697, 0.17330509668588534, 0.1901257622871324, 0.15389827809002543, 0.030703693527856957, 0.09967375423587532, 0.006216123472267077, 0.11036590614259256, 0.08229463205137344, 0.08027039075694431, 0.08308359594105719, 0.508822391392955, 0.5030743637306276, 0.5384665061850664, 0.5508017556879286, 0.5339889194211281, 0.48934217485093423, 0.5417760077107472, 0.5635867791431783, 0.5513855178417653, 0.09399253383020312, 0.09505788785955172, 0.12069222310409389, 0.1503776537696504, 0.113065195444773, 0.13136983437369631, 0.12498083590119058, 0.1482479371648593, 0.13748988581166122, 0.4679525905898879, 0.1944033029084068, 0.16870046764666602, 0.1750025396532352, 0.27959887892103674, 0.38944836220268275, 0.23377684145291178, 0.2412051644503903, 0.36588525539129135, 0.3684591291386654, 0.3069611214197362, 0.34107657895840604, 0.5098448658162169, 0.3508036578853836, 0.3753121333516487, 0.47204044652987653, 0.47636880833183803, 0.45984604297700593, 0.29691193228872925, 0.36171256728718704, 0.23021606561418673, 0.2047297906346115, 0.2108640021689132, 0.25982542364022143, 0.3128302014904043, 0.2813591231174871, 0.4204156424564308, 0.21990326746804645, 0.2752022248553342, 0.24195815709808954, 0.2280715439183525, 0.23548781098486893, 0.2275319235014468, 0.22290195018316794, 0.23740020059032962, 0.21613794965647337, 0.24404506070843035, 0.20609215493305844, 0.6892638946931693, 0.2072737087507801, 0.24229280367845962, 0.22007089115536138, 0.7148484224593105, 0.6301770830589708, 0.20310239728338542, 0.18754529532433784, 0.17660875959026034, 0.15289368477822685, 0.8061690276582345, 0.20058571687994653, 0.8802251945760537, 0.15039786212305428, 0.1700192478337592, 0.886068885799772, 0.8588741097347085, 0.1565400372741873, 0.5389634356603581, 0.2899159497925953, 0.1695915874327555, 0.2117275936374634, 0.10502445038548136, 0.16809927729761442, 0.674723128700518, 0.19501407061682385, 0.22358095633548325, 0.21322169132340085, 0.17950007876878282, 0.19013493268409087, 0.21162659749429857, 0.2067465134091785, 0.18924167568759753, 0.20556847782921484, 0.1414713983713609, 0.09559339059503857, 0.0873254985437838, 0.09855267495038655, 0.0945421287752346, 0.08320070355810871, 0.09009658138844057, 0.08939037292426255, 0.0945117340045768]}, "mutation_prompt": null}
{"id": "2a451977-fb19-4e6f-9fd2-84075a97f9ec", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        while func_calls < self.budget:\n            fitness_values = np.apply_along_axis(func, 1, self.positions)\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(self.inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            self.inertia_weight *= self.inertia_damping", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined version of OptimizedAdaptivePSO with reduced loop overhead and optimized numpy operations for enhanced efficiency.", "configspace": "", "generation": 27, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4c9d2cb9-d41b-4a04-8c3f-004b5dc4f8fc", "metadata": {"aucs": [0.8557549476182937, 0.8475171285036693, 0.8536105078429863, 0.8507064002525568, 0.850343376313152, 0.8398146802431917, 0.8529082471662224, 0.857086151549064, 0.8342118375020605, 0.7348427522747882, 0.7162832222907194, 0.7442231006734343, 0.7305020981691666, 0.7299806171996082, 0.7214473476113707, 0.048078220481730716, 0.7181460175609061, 0.7288343875731005, 0.162137312994465, 0.540072501502404, 0.5575826263373954, 0.500088584251174, 0.4761986973307627, 0.17209037673117777, 0.15966455824542913, 0.14870811529646855, 0.5351023382474314, 0.1345012381858054, 0.16999904800417298, 0.1449742786181648, 0.15026824603131828, 0.12794082197330314, 0.14668452250454533, 0.11561770106103153, 0.13580269092636754, 0.1697266585417858, 0.9836535023422585, 0.9860140323351525, 0.9856237791389117, 0.9785335258185546, 0.9835175695441696, 0.9833393505354857, 0.9836507546062551, 0.9782047414610068, 0.9832795763412069, 0.5823945766921036, 0.5011476252932768, 0.5884518303526042, 0.49308818465722104, 0.5956553776315267, 0.38711386211916077, 0.4900296170369015, 0.08867464924887458, 0.4831416591784601, 0.3516029404145803, 0.30852514477150184, 0.2892562142720967, 0.20759739691954293, 0.276288811385905, 0.20920695597458783, 0.2207054890668021, 0.22613956802613966, 0.23613492643167033, 0.17680189150802494, 0.1750929358206038, 0.19575365503818698, 0.18073120782653118, 0.1969445682510642, 0.1729226880023279, 0.18984150964780522, 0.26823553329586536, 0.19912158630825105, 0.18876710725112156, 0.20942847643264217, 0.12906602966133474, 0.19280742994506095, 0.1326606605170293, 0.2013466597536211, 0.20812487805926916, 0.16353010233858145, 0.22147920841683733, 9.999999999998899e-05, 9.999999999998899e-05, 0.07118857562383074, 0.04065224727357308, 0.012480726965406364, 0.022248948277352465, 9.999999999998899e-05, 0.007964411787736214, 0.0012906413020393748, 0.11756720736343707, 0.11449435452157863, 0.0630979709798295, 0.1786078176069339, 0.02945800874119009, 0.04732694147422789, 0.1335603186232882, 0.15988093088244348, 0.1026161441796305, 0.1009600991547317, 0.14948825807365262, 0.04549708669737906, 0.21306677823703735, 0.07240384819802947, 0.08055286657256877, 0.09054664453133832, 0.1619481695909697, 0.17330509668588534, 0.1901257622871324, 0.15389827809002543, 0.030703693527856957, 0.09967375423587532, 0.006216123472267077, 0.11036590614259256, 0.08229463205137344, 0.08027039075694431, 0.08308359594105719, 0.508822391392955, 0.5030743637306276, 0.5384665061850664, 0.5508017556879286, 0.5339889194211281, 0.48934217485093423, 0.5417760077107472, 0.5635867791431783, 0.5513855178417653, 0.09399253383020312, 0.09505788785955172, 0.12069222310409389, 0.1503776537696504, 0.113065195444773, 0.13136983437369631, 0.12498083590119058, 0.1482479371648593, 0.13748988581166122, 0.4679525905898879, 0.1944033029084068, 0.16870046764666602, 0.1750025396532352, 0.27959887892103674, 0.38944836220268275, 0.23377684145291178, 0.2412051644503903, 0.36588525539129135, 0.3684591291386654, 0.3069611214197362, 0.34107657895840604, 0.5098448658162169, 0.3508036578853836, 0.3753121333516487, 0.47204044652987653, 0.47636880833183803, 0.45984604297700593, 0.29691193228872925, 0.36171256728718704, 0.23021606561418673, 0.2047297906346115, 0.2108640021689132, 0.25982542364022143, 0.3128302014904043, 0.2813591231174871, 0.4204156424564308, 0.21990326746804645, 0.2752022248553342, 0.24195815709808954, 0.2280715439183525, 0.23548781098486893, 0.2275319235014468, 0.22290195018316794, 0.23740020059032962, 0.21613794965647337, 0.24404506070843035, 0.20609215493305844, 0.6892638946931693, 0.2072737087507801, 0.24229280367845962, 0.22007089115536138, 0.7148484224593105, 0.6301770830589708, 0.20310239728338542, 0.18754529532433784, 0.17660875959026034, 0.15289368477822685, 0.8061690276582345, 0.20058571687994653, 0.8802251945760537, 0.15039786212305428, 0.1700192478337592, 0.886068885799772, 0.8588741097347085, 0.1565400372741873, 0.5389634356603581, 0.2899159497925953, 0.1695915874327555, 0.2117275936374634, 0.10502445038548136, 0.16809927729761442, 0.674723128700518, 0.19501407061682385, 0.22358095633548325, 0.21322169132340085, 0.17950007876878282, 0.19013493268409087, 0.21162659749429857, 0.2067465134091785, 0.18924167568759753, 0.20556847782921484, 0.1414713983713609, 0.09559339059503857, 0.0873254985437838, 0.09855267495038655, 0.0945421287752346, 0.08320070355810871, 0.09009658138844057, 0.08939037292426255, 0.0945117340045768]}, "mutation_prompt": null}
{"id": "9a22ce84-78a6-4008-931b-fd5cc6d39077", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        while func_calls < self.budget:\n            fitness_values = np.apply_along_axis(func, 1, self.positions)\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(self.inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            self.inertia_weight *= self.inertia_damping", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined version of OptimizedAdaptivePSO with reduced loop overhead and optimized numpy operations for enhanced efficiency.", "configspace": "", "generation": 27, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4c9d2cb9-d41b-4a04-8c3f-004b5dc4f8fc", "metadata": {"aucs": [0.8557549476182937, 0.8475171285036693, 0.8536105078429863, 0.8507064002525568, 0.850343376313152, 0.8398146802431917, 0.8529082471662224, 0.857086151549064, 0.8342118375020605, 0.7348427522747882, 0.7162832222907194, 0.7442231006734343, 0.7305020981691666, 0.7299806171996082, 0.7214473476113707, 0.048078220481730716, 0.7181460175609061, 0.7288343875731005, 0.162137312994465, 0.540072501502404, 0.5575826263373954, 0.500088584251174, 0.4761986973307627, 0.17209037673117777, 0.15966455824542913, 0.14870811529646855, 0.5351023382474314, 0.1345012381858054, 0.16999904800417298, 0.1449742786181648, 0.15026824603131828, 0.12794082197330314, 0.14668452250454533, 0.11561770106103153, 0.13580269092636754, 0.1697266585417858, 0.9836535023422585, 0.9860140323351525, 0.9856237791389117, 0.9785335258185546, 0.9835175695441696, 0.9833393505354857, 0.9836507546062551, 0.9782047414610068, 0.9832795763412069, 0.5823945766921036, 0.5011476252932768, 0.5884518303526042, 0.49308818465722104, 0.5956553776315267, 0.38711386211916077, 0.4900296170369015, 0.08867464924887458, 0.4831416591784601, 0.3516029404145803, 0.30852514477150184, 0.2892562142720967, 0.20759739691954293, 0.276288811385905, 0.20920695597458783, 0.2207054890668021, 0.22613956802613966, 0.23613492643167033, 0.17680189150802494, 0.1750929358206038, 0.19575365503818698, 0.18073120782653118, 0.1969445682510642, 0.1729226880023279, 0.18984150964780522, 0.26823553329586536, 0.19912158630825105, 0.18876710725112156, 0.20942847643264217, 0.12906602966133474, 0.19280742994506095, 0.1326606605170293, 0.2013466597536211, 0.20812487805926916, 0.16353010233858145, 0.22147920841683733, 9.999999999998899e-05, 9.999999999998899e-05, 0.07118857562383074, 0.04065224727357308, 0.012480726965406364, 0.022248948277352465, 9.999999999998899e-05, 0.007964411787736214, 0.0012906413020393748, 0.11756720736343707, 0.11449435452157863, 0.0630979709798295, 0.1786078176069339, 0.02945800874119009, 0.04732694147422789, 0.1335603186232882, 0.15988093088244348, 0.1026161441796305, 0.1009600991547317, 0.14948825807365262, 0.04549708669737906, 0.21306677823703735, 0.07240384819802947, 0.08055286657256877, 0.09054664453133832, 0.1619481695909697, 0.17330509668588534, 0.1901257622871324, 0.15389827809002543, 0.030703693527856957, 0.09967375423587532, 0.006216123472267077, 0.11036590614259256, 0.08229463205137344, 0.08027039075694431, 0.08308359594105719, 0.508822391392955, 0.5030743637306276, 0.5384665061850664, 0.5508017556879286, 0.5339889194211281, 0.48934217485093423, 0.5417760077107472, 0.5635867791431783, 0.5513855178417653, 0.09399253383020312, 0.09505788785955172, 0.12069222310409389, 0.1503776537696504, 0.113065195444773, 0.13136983437369631, 0.12498083590119058, 0.1482479371648593, 0.13748988581166122, 0.4679525905898879, 0.1944033029084068, 0.16870046764666602, 0.1750025396532352, 0.27959887892103674, 0.38944836220268275, 0.23377684145291178, 0.2412051644503903, 0.36588525539129135, 0.3684591291386654, 0.3069611214197362, 0.34107657895840604, 0.5098448658162169, 0.3508036578853836, 0.3753121333516487, 0.47204044652987653, 0.47636880833183803, 0.45984604297700593, 0.29691193228872925, 0.36171256728718704, 0.23021606561418673, 0.2047297906346115, 0.2108640021689132, 0.25982542364022143, 0.3128302014904043, 0.2813591231174871, 0.4204156424564308, 0.21990326746804645, 0.2752022248553342, 0.24195815709808954, 0.2280715439183525, 0.23548781098486893, 0.2275319235014468, 0.22290195018316794, 0.23740020059032962, 0.21613794965647337, 0.24404506070843035, 0.20609215493305844, 0.6892638946931693, 0.2072737087507801, 0.24229280367845962, 0.22007089115536138, 0.7148484224593105, 0.6301770830589708, 0.20310239728338542, 0.18754529532433784, 0.17660875959026034, 0.15289368477822685, 0.8061690276582345, 0.20058571687994653, 0.8802251945760537, 0.15039786212305428, 0.1700192478337592, 0.886068885799772, 0.8588741097347085, 0.1565400372741873, 0.5389634356603581, 0.2899159497925953, 0.1695915874327555, 0.2117275936374634, 0.10502445038548136, 0.16809927729761442, 0.674723128700518, 0.19501407061682385, 0.22358095633548325, 0.21322169132340085, 0.17950007876878282, 0.19013493268409087, 0.21162659749429857, 0.2067465134091785, 0.18924167568759753, 0.20556847782921484, 0.1414713983713609, 0.09559339059503857, 0.0873254985437838, 0.09855267495038655, 0.0945421287752346, 0.08320070355810871, 0.09009658138844057, 0.08939037292426255, 0.0945117340045768]}, "mutation_prompt": null}
{"id": "28bfce56-afab-4dc4-9c0f-4c52732d9924", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        while func_calls < self.budget:\n            fitness_values = np.apply_along_axis(func, 1, self.positions)\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(self.inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            self.inertia_weight *= self.inertia_damping", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined version of OptimizedAdaptivePSO with reduced loop overhead and optimized numpy operations for enhanced efficiency.", "configspace": "", "generation": 27, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4c9d2cb9-d41b-4a04-8c3f-004b5dc4f8fc", "metadata": {"aucs": [0.8557549476182937, 0.8475171285036693, 0.8536105078429863, 0.8507064002525568, 0.850343376313152, 0.8398146802431917, 0.8529082471662224, 0.857086151549064, 0.8342118375020605, 0.7348427522747882, 0.7162832222907194, 0.7442231006734343, 0.7305020981691666, 0.7299806171996082, 0.7214473476113707, 0.048078220481730716, 0.7181460175609061, 0.7288343875731005, 0.162137312994465, 0.540072501502404, 0.5575826263373954, 0.500088584251174, 0.4761986973307627, 0.17209037673117777, 0.15966455824542913, 0.14870811529646855, 0.5351023382474314, 0.1345012381858054, 0.16999904800417298, 0.1449742786181648, 0.15026824603131828, 0.12794082197330314, 0.14668452250454533, 0.11561770106103153, 0.13580269092636754, 0.1697266585417858, 0.9836535023422585, 0.9860140323351525, 0.9856237791389117, 0.9785335258185546, 0.9835175695441696, 0.9833393505354857, 0.9836507546062551, 0.9782047414610068, 0.9832795763412069, 0.5823945766921036, 0.5011476252932768, 0.5884518303526042, 0.49308818465722104, 0.5956553776315267, 0.38711386211916077, 0.4900296170369015, 0.08867464924887458, 0.4831416591784601, 0.3516029404145803, 0.30852514477150184, 0.2892562142720967, 0.20759739691954293, 0.276288811385905, 0.20920695597458783, 0.2207054890668021, 0.22613956802613966, 0.23613492643167033, 0.17680189150802494, 0.1750929358206038, 0.19575365503818698, 0.18073120782653118, 0.1969445682510642, 0.1729226880023279, 0.18984150964780522, 0.26823553329586536, 0.19912158630825105, 0.18876710725112156, 0.20942847643264217, 0.12906602966133474, 0.19280742994506095, 0.1326606605170293, 0.2013466597536211, 0.20812487805926916, 0.16353010233858145, 0.22147920841683733, 9.999999999998899e-05, 9.999999999998899e-05, 0.07118857562383074, 0.04065224727357308, 0.012480726965406364, 0.022248948277352465, 9.999999999998899e-05, 0.007964411787736214, 0.0012906413020393748, 0.11756720736343707, 0.11449435452157863, 0.0630979709798295, 0.1786078176069339, 0.02945800874119009, 0.04732694147422789, 0.1335603186232882, 0.15988093088244348, 0.1026161441796305, 0.1009600991547317, 0.14948825807365262, 0.04549708669737906, 0.21306677823703735, 0.07240384819802947, 0.08055286657256877, 0.09054664453133832, 0.1619481695909697, 0.17330509668588534, 0.1901257622871324, 0.15389827809002543, 0.030703693527856957, 0.09967375423587532, 0.006216123472267077, 0.11036590614259256, 0.08229463205137344, 0.08027039075694431, 0.08308359594105719, 0.508822391392955, 0.5030743637306276, 0.5384665061850664, 0.5508017556879286, 0.5339889194211281, 0.48934217485093423, 0.5417760077107472, 0.5635867791431783, 0.5513855178417653, 0.09399253383020312, 0.09505788785955172, 0.12069222310409389, 0.1503776537696504, 0.113065195444773, 0.13136983437369631, 0.12498083590119058, 0.1482479371648593, 0.13748988581166122, 0.4679525905898879, 0.1944033029084068, 0.16870046764666602, 0.1750025396532352, 0.27959887892103674, 0.38944836220268275, 0.23377684145291178, 0.2412051644503903, 0.36588525539129135, 0.3684591291386654, 0.3069611214197362, 0.34107657895840604, 0.5098448658162169, 0.3508036578853836, 0.3753121333516487, 0.47204044652987653, 0.47636880833183803, 0.45984604297700593, 0.29691193228872925, 0.36171256728718704, 0.23021606561418673, 0.2047297906346115, 0.2108640021689132, 0.25982542364022143, 0.3128302014904043, 0.2813591231174871, 0.4204156424564308, 0.21990326746804645, 0.2752022248553342, 0.24195815709808954, 0.2280715439183525, 0.23548781098486893, 0.2275319235014468, 0.22290195018316794, 0.23740020059032962, 0.21613794965647337, 0.24404506070843035, 0.20609215493305844, 0.6892638946931693, 0.2072737087507801, 0.24229280367845962, 0.22007089115536138, 0.7148484224593105, 0.6301770830589708, 0.20310239728338542, 0.18754529532433784, 0.17660875959026034, 0.15289368477822685, 0.8061690276582345, 0.20058571687994653, 0.8802251945760537, 0.15039786212305428, 0.1700192478337592, 0.886068885799772, 0.8588741097347085, 0.1565400372741873, 0.5389634356603581, 0.2899159497925953, 0.1695915874327555, 0.2117275936374634, 0.10502445038548136, 0.16809927729761442, 0.674723128700518, 0.19501407061682385, 0.22358095633548325, 0.21322169132340085, 0.17950007876878282, 0.19013493268409087, 0.21162659749429857, 0.2067465134091785, 0.18924167568759753, 0.20556847782921484, 0.1414713983713609, 0.09559339059503857, 0.0873254985437838, 0.09855267495038655, 0.0945421287752346, 0.08320070355810871, 0.09009658138844057, 0.08939037292426255, 0.0945117340045768]}, "mutation_prompt": null}
{"id": "cdcde78b-dc97-4ae4-a96b-f4f61e5d21c9", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        while func_calls < self.budget:\n            fitness_values = np.apply_along_axis(func, 1, self.positions)\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(self.inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            self.inertia_weight *= self.inertia_damping", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined version of OptimizedAdaptivePSO with reduced loop overhead and optimized numpy operations for enhanced efficiency.", "configspace": "", "generation": 27, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4c9d2cb9-d41b-4a04-8c3f-004b5dc4f8fc", "metadata": {"aucs": [0.8557549476182937, 0.8475171285036693, 0.8536105078429863, 0.8507064002525568, 0.850343376313152, 0.8398146802431917, 0.8529082471662224, 0.857086151549064, 0.8342118375020605, 0.7348427522747882, 0.7162832222907194, 0.7442231006734343, 0.7305020981691666, 0.7299806171996082, 0.7214473476113707, 0.048078220481730716, 0.7181460175609061, 0.7288343875731005, 0.162137312994465, 0.540072501502404, 0.5575826263373954, 0.500088584251174, 0.4761986973307627, 0.17209037673117777, 0.15966455824542913, 0.14870811529646855, 0.5351023382474314, 0.1345012381858054, 0.16999904800417298, 0.1449742786181648, 0.15026824603131828, 0.12794082197330314, 0.14668452250454533, 0.11561770106103153, 0.13580269092636754, 0.1697266585417858, 0.9836535023422585, 0.9860140323351525, 0.9856237791389117, 0.9785335258185546, 0.9835175695441696, 0.9833393505354857, 0.9836507546062551, 0.9782047414610068, 0.9832795763412069, 0.5823945766921036, 0.5011476252932768, 0.5884518303526042, 0.49308818465722104, 0.5956553776315267, 0.38711386211916077, 0.4900296170369015, 0.08867464924887458, 0.4831416591784601, 0.3516029404145803, 0.30852514477150184, 0.2892562142720967, 0.20759739691954293, 0.276288811385905, 0.20920695597458783, 0.2207054890668021, 0.22613956802613966, 0.23613492643167033, 0.17680189150802494, 0.1750929358206038, 0.19575365503818698, 0.18073120782653118, 0.1969445682510642, 0.1729226880023279, 0.18984150964780522, 0.26823553329586536, 0.19912158630825105, 0.18876710725112156, 0.20942847643264217, 0.12906602966133474, 0.19280742994506095, 0.1326606605170293, 0.2013466597536211, 0.20812487805926916, 0.16353010233858145, 0.22147920841683733, 9.999999999998899e-05, 9.999999999998899e-05, 0.07118857562383074, 0.04065224727357308, 0.012480726965406364, 0.022248948277352465, 9.999999999998899e-05, 0.007964411787736214, 0.0012906413020393748, 0.11756720736343707, 0.11449435452157863, 0.0630979709798295, 0.1786078176069339, 0.02945800874119009, 0.04732694147422789, 0.1335603186232882, 0.15988093088244348, 0.1026161441796305, 0.1009600991547317, 0.14948825807365262, 0.04549708669737906, 0.21306677823703735, 0.07240384819802947, 0.08055286657256877, 0.09054664453133832, 0.1619481695909697, 0.17330509668588534, 0.1901257622871324, 0.15389827809002543, 0.030703693527856957, 0.09967375423587532, 0.006216123472267077, 0.11036590614259256, 0.08229463205137344, 0.08027039075694431, 0.08308359594105719, 0.508822391392955, 0.5030743637306276, 0.5384665061850664, 0.5508017556879286, 0.5339889194211281, 0.48934217485093423, 0.5417760077107472, 0.5635867791431783, 0.5513855178417653, 0.09399253383020312, 0.09505788785955172, 0.12069222310409389, 0.1503776537696504, 0.113065195444773, 0.13136983437369631, 0.12498083590119058, 0.1482479371648593, 0.13748988581166122, 0.4679525905898879, 0.1944033029084068, 0.16870046764666602, 0.1750025396532352, 0.27959887892103674, 0.38944836220268275, 0.23377684145291178, 0.2412051644503903, 0.36588525539129135, 0.3684591291386654, 0.3069611214197362, 0.34107657895840604, 0.5098448658162169, 0.3508036578853836, 0.3753121333516487, 0.47204044652987653, 0.47636880833183803, 0.45984604297700593, 0.29691193228872925, 0.36171256728718704, 0.23021606561418673, 0.2047297906346115, 0.2108640021689132, 0.25982542364022143, 0.3128302014904043, 0.2813591231174871, 0.4204156424564308, 0.21990326746804645, 0.2752022248553342, 0.24195815709808954, 0.2280715439183525, 0.23548781098486893, 0.2275319235014468, 0.22290195018316794, 0.23740020059032962, 0.21613794965647337, 0.24404506070843035, 0.20609215493305844, 0.6892638946931693, 0.2072737087507801, 0.24229280367845962, 0.22007089115536138, 0.7148484224593105, 0.6301770830589708, 0.20310239728338542, 0.18754529532433784, 0.17660875959026034, 0.15289368477822685, 0.8061690276582345, 0.20058571687994653, 0.8802251945760537, 0.15039786212305428, 0.1700192478337592, 0.886068885799772, 0.8588741097347085, 0.1565400372741873, 0.5389634356603581, 0.2899159497925953, 0.1695915874327555, 0.2117275936374634, 0.10502445038548136, 0.16809927729761442, 0.674723128700518, 0.19501407061682385, 0.22358095633548325, 0.21322169132340085, 0.17950007876878282, 0.19013493268409087, 0.21162659749429857, 0.2067465134091785, 0.18924167568759753, 0.20556847782921484, 0.1414713983713609, 0.09559339059503857, 0.0873254985437838, 0.09855267495038655, 0.0945421287752346, 0.08320070355810871, 0.09009658138844057, 0.08939037292426255, 0.0945117340045768]}, "mutation_prompt": null}
{"id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 37, "fitness": 0.3276618413283123, "feedback": "The algorithm EnhancedOptimizedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.27.", "error": "", "parent_id": "4c9d2cb9-d41b-4a04-8c3f-004b5dc4f8fc", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "18750da4-b20b-40bd-9067-ec51f56131b3", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "bddf8bdc-0442-4980-bda7-c59cf28e6fd9", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "1bce9605-778e-4c27-8265-6fe3ee212ae3", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "b611f3a2-e983-478c-8ea4-b6dc40c64590", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "d88edde0-bfd5-4a99-8068-1f5e7937f3eb", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "dedea1d7-3473-40f4-a193-6cc08799991c", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "689e7280-bcbf-4b9d-8a76-943f3d8b01ba", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "25534136-3330-4e58-9bef-668f99187de1", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "f468d91d-812e-40b6-86c9-878534f863c9", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "06660964-86a5-4c80-a46d-30726d910a93", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight\n        \n        while func_calls < self.budget:\n            fitness_values = np.apply_along_axis(func, 1, self.positions)\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = r1 * (self.pbest_positions - self.positions)\n            social_term = r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + self.c1 * cognitive_term + self.c2 * social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping", "name": "EnhancedOptimizedAdaptivePSO", "description": "EnhancedOptimizedAdaptivePSO with vectorized operations and reduced computation for constant terms.", "configspace": "", "generation": 47, "fitness": 0.3258139121240558, "feedback": "The algorithm EnhancedOptimizedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.27.", "error": "", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8471293081559447, 0.8528816369506251, 0.8421245546333544, 0.8432246019874446, 0.8601214143694905, 0.8481776438057632, 0.8504043024693251, 0.8377802248896815, 0.8395256190909439, 0.7392123651288172, 0.736576438451957, 0.7361873950486066, 0.7279932604254649, 0.6879419634685466, 0.4497649254225835, 0.051706706103780364, 0.7254841907170582, 0.715767307972585, 0.10160319809513407, 0.1785568130257278, 0.4721248031349786, 0.1502848926001843, 0.1663909765950795, 0.14364952771803996, 0.5849424662159919, 0.4168516365784858, 0.1328953459207236, 0.12915768057870225, 0.111764838093109, 0.11238898942552855, 0.1358374400989094, 0.16383131277232277, 0.14806683414906652, 0.13785508000748636, 0.148721516518031, 0.10704495612264331, 0.982919105975983, 0.9861697519782006, 0.9834644618022185, 0.9778927073482105, 0.9824350333706336, 0.9783989920904956, 0.9834625217904865, 0.9801742949550093, 0.9822268130306843, 0.5997095357997968, 0.6494171610973192, 0.6544117124662027, 0.6049354678683323, 0.5766559710464156, 0.5178550503747732, 0.5008399408991853, 0.5360161324261157, 0.08833843560940968, 0.22476628444835356, 0.4555787139337967, 0.2258483084373344, 0.21385461238452508, 0.2748505316833979, 0.21359071123735962, 0.22936299368272484, 0.23527442654168373, 0.23351955107243616, 0.17450767940033984, 0.17717444196226984, 0.19114977062528815, 0.17604589487808042, 0.1779335844490919, 0.12256193096053536, 0.36091899589104803, 0.24401579849794874, 0.1832755668605619, 0.20574390174278223, 0.14260172425226447, 0.1981482694977429, 0.18950284382732685, 0.1944854836400418, 0.129866323138776, 0.22414893607988373, 0.1696294113137643, 0.20570263099008979, 9.999999999998899e-05, 0.050228918011471224, 0.03051316669704396, 0.0021504847081651457, 0.03291737831077313, 9.999999999998899e-05, 0.018187474993659136, 9.999999999998899e-05, 0.06707551933929301, 0.16704547430009697, 0.06485128777527749, 0.0824684006597779, 0.07567999660004265, 0.059502504669199485, 0.049954625421448906, 0.12780339893798587, 0.10677214469264995, 0.039273365546729444, 0.056060488773166384, 9.999999999998899e-05, 0.04587369427360066, 0.07430452065332627, 0.27057512953323026, 0.16122805731591783, 0.09237172980561503, 0.192404129774146, 0.06663846125860906, 0.2796141503571362, 0.13634660091895545, 0.03819182051221126, 0.20613129429517252, 0.06483918604402061, 0.16070032243223975, 0.07917630172520718, 0.04812564468710023, 0.11786533943880917, 0.4834557897888251, 0.5151148730282236, 0.503712521163074, 0.5232755794654504, 0.5612820480926487, 0.5376893834787293, 0.5426288899839729, 0.5325776169200274, 0.5203427827588873, 0.07408753700016169, 0.7038002336375278, 0.1364447992692165, 0.14203495433594815, 0.12640885599808294, 0.10897424287514257, 0.10340737157272784, 0.13967744160539242, 0.11335185597596542, 0.26524332770364956, 0.18158531187955884, 0.1923055882389756, 0.3226093853826596, 0.4318139735676566, 0.25839116498065273, 0.2533170223310993, 0.17966571494658823, 0.27224263478877797, 0.3696582612543592, 0.3788225014483295, 0.36245182290047984, 0.2943319290239591, 0.2796481807042105, 0.46288851208883075, 0.4424990473231395, 0.4657490494053914, 0.25537419744586276, 0.18959702825758096, 0.2488458830941338, 0.23135842449379074, 0.3351374753780141, 0.3306626350876478, 0.2693012604165318, 0.25775992523067404, 0.27005330721691967, 0.29851064672147465, 0.23613724795523683, 0.20448661705674076, 0.20247215983848788, 0.23388167377993596, 0.22839529096436906, 0.2195684993830428, 0.28437654234266196, 0.2195014728988549, 0.23932904594756854, 0.24399227938732615, 0.24381396413485412, 0.2466338387002307, 0.769249692767521, 0.20843026816995236, 0.20515811465502576, 0.6718464478825437, 0.2132612689067377, 0.3152642065769461, 0.8773033521074208, 0.17621859660064532, 0.15360767848680823, 0.897954425626688, 0.2014176054324004, 0.8553090653310906, 0.11827692672245316, 0.8780251680431691, 0.8716480165547797, 0.5524510900532599, 0.1567848706679128, 0.7310491138550339, 0.40256685811705895, 0.16839695380945996, 0.5687320239235399, 0.5590151894039472, 0.09683494676200843, 0.5867896836876648, 0.2118561169451726, 0.2001064353504587, 0.19643802262155163, 0.20698029010869512, 0.21369236493526356, 0.19378053545237306, 0.20692950183590164, 0.202918849660351, 0.20552865044455093, 0.11935201173105692, 0.09555800202640508, 0.10698042315708423, 0.10419541243082364, 0.0807777405890876, 0.10260902108985648, 0.08537643065508327, 0.1014324716801801, 0.09639596272472395]}, "mutation_prompt": null}
{"id": "8f4abb23-b5a7-40f9-8fb1-c093aa5695f8", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n        self.r1, self.r2 = self.rng.random((2, self.n_particles, dim))\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n\n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n\n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n\n            cognitive_term = self.c1 * self.r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * self.r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, \n                                      -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n\n            if func_calls % self.n_particles == 0:  # Re-generate random numbers after each batch\n                self.r1, self.r2 = self.rng.random((2, self.n_particles, self.dim))\n\n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "EnhancedOptimizedAdaptivePSO with improved efficiency by reducing random number generation and optimizing velocity updates.", "configspace": "", "generation": 48, "fitness": 0.326914660280454, "feedback": "The algorithm EnhancedOptimizedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.27.", "error": "", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.857021847076852, 0.8567395478046032, 0.8597077569347651, 0.8482408157716412, 0.8524117851803973, 0.8429593523077948, 0.8506042483690639, 0.8413787234419652, 0.8640277747314161, 0.7363231247497806, 0.7004389764498009, 0.7301959574056756, 0.7351466776001447, 0.7139653877208287, 0.6974613588750671, 0.7240226263403988, 0.7291653513317762, 0.04992709738538614, 0.17929188026561893, 0.5850068358031532, 0.507383903556123, 0.15676482144028792, 0.14853033046966047, 0.1592941650942532, 0.1441922537674314, 0.17133962018968674, 0.15520686880443735, 0.16769424756272422, 0.13011088459723197, 0.11034768691303398, 0.17398266080291247, 0.1260113078188837, 0.13818959239415196, 0.4569996492621533, 0.15281904498680632, 0.11314864035098093, 0.9833316312105598, 0.9861023370356, 0.9803331180038196, 0.978545365516662, 0.9751856440344644, 0.9838231080846944, 0.9866615326678487, 0.9786114499064361, 0.9827974014262157, 0.6239223211507459, 0.5399111853589595, 0.5436279594884864, 0.5521006372529849, 0.5187322989561968, 0.3735800842787579, 0.5228399482490134, 0.5530834693059048, 0.08791534736612161, 0.8136347961074964, 0.35440489817043497, 0.38319112687089196, 0.27454994176373315, 0.1929681354242444, 0.2133549178959353, 0.2354872125023798, 0.7021083973101656, 0.7866315443060401, 0.22012291451600696, 0.11807251033439659, 0.20074942519765937, 0.0985816940448716, 0.174635222632059, 0.2649583808125282, 0.19767401321933809, 0.17463632893567616, 0.18585671157726524, 0.20414250120711241, 0.19079269493158202, 0.16089116973677098, 0.19900673306023786, 0.17089608019474123, 0.202971340484716, 0.22621348131698682, 0.11172892587323513, 0.22159949792972822, 0.06475240502407886, 9.999999999998899e-05, 0.05052997763617606, 0.02425598373167337, 9.999999999998899e-05, 0.025430813691678877, 9.999999999998899e-05, 9.999999999998899e-05, 0.11589153061864799, 0.1374289597595496, 0.11251280848582579, 0.13300063232748527, 0.11311743504391447, 0.04260416884657936, 0.030803007231785196, 0.207172172333136, 0.07088606973153377, 0.10269501612373988, 0.10582249117377818, 0.03305040454468822, 0.18797069412542167, 0.10310564739817196, 0.07302103756649791, 0.0880888044842495, 0.094040531969808, 0.06801906318800921, 0.10071834304175786, 0.24237861512076508, 0.09210008271985448, 0.17808942919781534, 0.19972304899270976, 0.191479704872073, 0.09949742782870585, 0.0807090297929508, 0.19108527762166594, 0.08037386966174487, 0.5028555762361286, 0.51599031240563, 0.5334967531446959, 0.49642746224486634, 0.5353072026409312, 0.537951440421006, 0.5371066619849432, 0.5013638055793107, 0.4924099468259625, 0.11248957640916946, 0.13006572288419083, 0.11633462386603954, 0.1204751067468014, 0.16145511450313077, 0.10186193265640198, 0.08384591153610677, 0.09431546450948858, 0.1513115663783723, 0.2267727364291534, 0.2858886309481192, 0.167952213047612, 0.23381635803626677, 0.30936204815473545, 0.2169162719459914, 0.22446707379480824, 0.2465522782179126, 0.18553855060880886, 0.327632985157425, 0.353596806828671, 0.30103675794753215, 0.47259060102905803, 0.421332504099038, 0.4813398226847746, 0.4509218020804344, 0.6141085458750074, 0.43240605669797516, 0.22548906973891514, 0.3657108410953953, 0.2134309302521209, 0.22164688903484386, 0.2564251016218736, 0.2570622012234721, 0.3307577813929323, 0.33292770879353606, 0.23772988886047086, 0.22967542841941202, 0.20325566965728425, 0.19730676803618885, 0.23642721148901746, 0.2324485372069034, 0.18976982451797808, 0.2568462751971089, 0.20500347770859262, 0.22165973175224352, 0.22392926361206544, 0.24580409926864044, 0.23501789882792046, 0.29939071652438665, 0.7602885807581459, 0.20286166558964114, 0.20835408910027875, 0.24371392452667895, 0.2489335403999362, 0.1881510465916365, 0.18654633866630166, 0.14726067976876167, 0.8819391026927089, 0.19897057597368673, 0.8735344682437595, 0.11370294946367998, 0.1702329096242149, 0.9148976285610251, 0.7290533893102858, 0.4360302425459175, 0.5746140027064393, 0.21040296990093954, 0.17029425497729755, 0.21218284772188523, 0.6763348198336679, 0.6833617483057108, 0.6666706875721735, 0.17962296634354347, 0.20706920037080934, 0.2171804452202446, 0.21478595123087596, 0.22882128240329125, 0.1811115782586762, 0.20475949363205637, 0.18361961022066675, 0.17940203650409325, 0.1381714047099698, 0.09122157670234521, 0.09396315194531812, 0.08759615706843726, 0.09759893870034209, 0.09133407230196566, 0.0988499990613998, 0.09545355343619599, 0.09188847775219888]}, "mutation_prompt": null}
{"id": "e42eef37-f5b9-4c4b-85c9-2883368cf32e", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "357f88f3-dbbc-4895-b147-b237d7f4c1a8", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        calculate_fitness = lambda pos: np.array([func(p) for p in pos])  # Reused lambda for fitness evaluation\n\n        while func_calls < self.budget:\n            fitness_values = calculate_fitness(self.positions)\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.dim))\n            cognitive_term = self.c1 * r1[np.newaxis, :] * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2[np.newaxis, :] * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "Optimized EnhancedOptimizedAdaptivePSO by restructuring random number generation and caching repeated terms.", "configspace": "", "generation": 50, "fitness": 0.29316861583564535, "feedback": "The algorithm EnhancedOptimizedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.26.", "error": "", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8230345611385579, 0.8448709993928071, 0.8306386194410391, 0.830123352741384, 0.8436374654256363, 0.8202030423318754, 0.8471316917200009, 0.8378755230431079, 0.8616444153175874, 0.7121002352010186, 0.6942403275792404, 0.06474427764062052, 0.1628711599947683, 0.7238128492500501, 0.716663767393005, 0.049671996585214595, 0.743360862069343, 0.7545279331975727, 0.21400342269660744, 0.6227358548386963, 0.1595883660409081, 0.1549151942562097, 0.1302221684051783, 0.14707346122233955, 0.14566099559941503, 0.14117824202918927, 0.17724577740016734, 0.13476177826785274, 0.1291605840352964, 0.14982704572277905, 0.14556177259317737, 0.1286843487652679, 0.13164883070983147, 0.13524141063429174, 0.11237032014996562, 0.23300894890380364, 0.9814062414410671, 0.9830764841084281, 0.9858699723352664, 0.9758221740974259, 0.9837041081167391, 0.9783484998973014, 0.9839754423893893, 0.9828804224814885, 0.9786445227034088, 0.5010357526365093, 0.47330647153405836, 0.4190668725257757, 0.4733895841709309, 0.45378068252985526, 0.3899387848189876, 0.08806850455442838, 0.09628257858366507, 0.08851457104869698, 0.35157493389217387, 0.2244615865227031, 0.2912342022293156, 0.2696715016184592, 0.2657276744849929, 0.19419669989699095, 0.1998950501910689, 0.12636597991046294, 0.233343793063589, 0.15859811899052656, 0.18131973407088464, 0.16732540741430135, 0.19687190550160083, 0.1718799756128797, 0.10167184022707643, 0.13423986223272044, 0.1680904160494905, 0.16759367832691374, 0.19372369392284083, 0.127990982520921, 0.16415729162075732, 0.12760434733022652, 0.20244955668921327, 0.34603288464888415, 0.18798287554882842, 0.18161671363838217, 0.1467209726985944, 0.03544350741755353, 0.07413428708177128, 9.999999999998899e-05, 0.007983590301388399, 0.023984490586680285, 0.048536237504790525, 9.999999999998899e-05, 9.999999999998899e-05, 0.10843679410628337, 0.18417086492423995, 0.05027075445667617, 0.08526637424925643, 0.09467917814027149, 0.022601163149108427, 0.0407821148457711, 0.16085566894531445, 0.17195048225445497, 0.059767397173152714, 0.056712079244139235, 0.21016325755346754, 9.999999999998899e-05, 0.11232928895272998, 0.07256142099693075, 0.07305060734069702, 0.09315687395436545, 0.07714018302224335, 0.0667365736437947, 0.14136796386629724, 0.01675990996382648, 0.4305006479627492, 0.11220889491677322, 0.26735080960743607, 0.18355025392107494, 0.048951689762481876, 0.05238240588340792, 0.08038177174931227, 0.5001778202499861, 0.49802590010764103, 0.4937428223670193, 0.5027261044839432, 0.556361824746243, 0.5306240563366127, 0.5432048114429899, 0.544879303024983, 0.5496928414088923, 0.07485766061980281, 0.12624411559380766, 0.14132217983727335, 0.10755570168705797, 0.1268827842907021, 0.10699552300248527, 0.17904353862164424, 0.14068003625970937, 0.13783139918827347, 0.33749918244013877, 0.235863975218079, 0.3230308322359803, 0.24595456476377942, 0.31845205282340094, 0.2884930521785358, 0.1911606335059991, 0.2892607150648282, 0.26152735696136675, 0.4012657484558567, 0.3260600725435825, 0.3992295112387849, 0.36214087249250293, 0.3930090747565931, 0.3572523654394576, 0.3809453764900027, 0.4496658675620422, 0.36278900137622416, 0.2588554025978357, 0.2660577366376151, 0.24784181727891974, 0.2698332180738192, 0.20160764854807212, 0.2249520363840536, 0.3013241740810043, 0.3624942464069125, 0.27436315089240804, 0.24339768958659191, 0.19042125107695096, 0.22402526400517997, 0.2040029268314788, 0.22094502802782479, 0.23589111040774946, 0.23533063275886268, 0.23200878269776348, 0.23960961973334927, 0.21651648767565346, 0.19953290964007941, 0.2099543301597493, 0.2257359933609816, 0.22557383656426933, 0.2037711697815381, 0.24083182538745573, 0.7710886523669698, 0.21054201142198647, 0.17435698681092204, 0.1263894091055905, 0.15336914569072924, 0.8873055312952891, 0.20030228649086002, 0.899124181133512, 0.8849895802151033, 0.1697286455786714, 0.1588290787549882, 0.6876117598817213, 0.14592745959402142, 0.12228080973300381, 0.4719116332450023, 0.1695228694498312, 0.21105375839871454, 0.10422896780879509, 0.1678558506520229, 0.5122695466716032, 0.19380586015566825, 0.18747991515507823, 0.19371794942937715, 0.19238202680324912, 0.1868052534307566, 0.21055308371538073, 0.18614671033398011, 0.2084919796193475, 0.2044365142948109, 0.11741590748731268, 0.07368875533048325, 0.11418764844484797, 0.09101405416579234, 0.09728192880319952, 0.08838127294542841, 0.12342615855623407, 0.08651588023893564, 0.08261250183736901]}, "mutation_prompt": null}
{"id": "6a934abd-f767-45eb-97e2-f5b892b4f94e", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "c223fa52-c560-43ea-a312-2693dc8a3ef0", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "2d705a3e-e3f9-4449-b153-7402c0ad8547", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "3cafe307-5e11-4b51-911a-bcec74159dcf", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "64daba03-ed45-42c8-baaf-bdce0380eabf", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "9ada23a8-fc6e-427c-831d-2e84383b3e7d", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.empty(self.n_particles)\n            for i, p in enumerate(self.positions):\n                fitness_values[i] = func(p)\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index].copy()\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            np.add(inertia_weight * self.velocities, cognitive_term + social_term, out=self.velocities)\n            np.clip(self.velocities, -self.max_velocity, self.max_velocity, out=self.velocities)\n            np.add(self.positions, self.velocities, out=self.positions)\n            np.clip(self.positions, self.lower_bound, self.upper_bound, out=self.positions)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by optimizing random number generation and leveraging in-place operations.", "configspace": "", "generation": 56, "fitness": 0.32205352572060425, "feedback": "The algorithm EnhancedOptimizedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.27.", "error": "", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8426158555817608, 0.851324158097031, 0.8488790766155554, 0.8411746006931456, 0.8596678041800496, 0.850165369201255, 0.8558546573421878, 0.8498902322293871, 0.8517694039346224, 0.687664848485541, 0.7113837700703746, 0.7535231214754863, 0.7202299300836307, 0.7227249738260004, 0.731994059569063, 0.04883600874706351, 0.7472185441118461, 0.6544992121529165, 0.16733004677316754, 0.17394443619629985, 0.16176307551498326, 0.11701973268046983, 0.144661699996129, 0.12851089386017722, 0.13905580255558248, 0.6100208194219867, 0.17126892437141228, 0.15099424577670306, 0.1587428617306712, 0.16769680370104012, 0.14917119735961037, 0.16699608234945185, 0.13573084875250785, 0.12288262422450713, 0.17528092947092677, 0.15144767453956465, 0.9854379185841811, 0.9837220911562585, 0.9831077704036691, 0.9785609088646782, 0.9808209090226903, 0.9746505127518393, 0.9863867131879037, 0.9779230338762912, 0.9801985792837138, 0.5902923950725683, 0.5510889117097204, 0.6014443347753604, 0.5745625747582179, 0.2803228173794109, 0.511867929703588, 0.5538077787231469, 0.08893918368080866, 0.5300574133472459, 0.6866492020284809, 0.7966521482419611, 0.6679284701990611, 0.194243330269397, 0.27056695825936283, 0.19314166544461275, 0.23079710450889002, 0.2170272459938436, 0.2328725266370847, 0.17546118347491169, 0.2054747415483975, 0.19473803193877015, 0.17047434455036525, 0.20681537962390562, 0.17374742526282572, 0.19339961799196215, 0.20604418935880908, 0.1883568341630022, 0.19814111971209536, 0.20549813832033448, 0.19201219184344032, 0.12939288034174856, 0.2774491985862775, 0.18682754036089466, 0.21045276752791564, 0.22091226585559065, 0.20979910237635357, 0.04842204778238046, 9.999999999998899e-05, 0.02302547064521787, 0.0005276619824097217, 9.999999999998899e-05, 0.045604536373361815, 0.01664897493094364, 9.999999999998899e-05, 0.0982976952253406, 0.12127484478713102, 0.03933335078576983, 0.10744074481911581, 0.10726898946347085, 0.04099713793629267, 0.027341404550949466, 0.11319437199631788, 0.0814456126829809, 0.05617292571118693, 0.03310533417365513, 0.0765586304027358, 0.1462764635067595, 0.07278492861302166, 0.28307148134824534, 0.07360134053066614, 0.09484375867273287, 0.17325163053071924, 0.06783282995616735, 0.18250963687211585, 0.08987008088252224, 0.14477690215707173, 0.006256969711788574, 0.09237930927290394, 0.20106805924566984, 0.12866532873939907, 0.12009801977000989, 0.10692822066273788, 0.5059708528639163, 0.51799607332323, 0.5913965525230134, 0.5396425151425006, 0.49236525057192226, 0.5009405933436479, 0.6088950893806471, 0.5669875776671714, 0.5790556575242666, 0.07672927513288264, 0.08495705553624833, 0.07113731647288168, 0.14096724530504856, 0.1104765501409336, 0.17253121402813054, 0.17628141002243647, 0.10191870462862518, 0.12486001019031356, 0.42680172276011386, 0.19269058588600763, 0.21534660385153315, 0.22073343340462748, 0.3149428363004577, 0.312003130024058, 0.17249392751760917, 0.2461842750603166, 0.2119292024187852, 0.38092444178411655, 0.3035337506577873, 0.36413253295105974, 0.41011772397504687, 0.3791812333132526, 0.4683783546354975, 0.4930299576588201, 0.4773167816224688, 0.3244452513982119, 0.1711261875482598, 0.3721603569238793, 0.2891668178943819, 0.22409043091960024, 0.31258278916136417, 0.3203497572778904, 0.2704975890831761, 0.2513236547361749, 0.23250020283334238, 0.23829233969988295, 0.20189619866898556, 0.23345930377685775, 0.20146562520668387, 0.19273291818634275, 0.23650481793460632, 0.21025131301612876, 0.21278052091955657, 0.23134372969120987, 0.2445834735548278, 0.2440141167781099, 0.25010574381794026, 0.2233474977417561, 0.21692780743589724, 0.21832232884460467, 0.2072904935608717, 0.2211178309264612, 0.5373486990563439, 0.9124262005565139, 0.12577751247528612, 0.15391128708414004, 0.8896958115598109, 0.20015668676220777, 0.1699322600578531, 0.12223273213546049, 0.8807950929230902, 0.8871408167483953, 0.8730535826203734, 0.15700960090628724, 0.46596850152719194, 0.5351088875262235, 0.16873359286340506, 0.6355724262871391, 0.5826195281520727, 0.10501126757864554, 0.6216553765577869, 0.201438389519787, 0.19670480201602214, 0.1820297382916506, 0.21304667914590214, 0.19218145115895702, 0.20385231282276328, 0.20107236919752458, 0.20433278336562766, 0.18963997812408528, 0.13470834479336458, 0.0960217771011056, 0.08674371510531198, 0.08780054330576204, 0.09719519280087208, 0.0829430161378375, 0.0964604483982483, 0.0892977023291136, 0.08723751240649269]}, "mutation_prompt": null}
{"id": "fdb2c3f2-f697-4eea-8eb2-bf056fd0d12f", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "5e307687-21a2-4e0e-856d-d59dcaf540d1", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight\n        random_cache = self.rng.random((2, self.n_particles, self.dim, int(self.budget / self.n_particles)))\n        iteration = 0\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = random_cache[0, :, :, iteration % random_cache.shape[3]], random_cache[1, :, :, iteration % random_cache.shape[3]]\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = inertia_weight * self.velocities + cognitive_term + social_term\n            np.clip(self.velocities, -self.max_velocity, self.max_velocity, out=self.velocities)\n            self.positions += self.velocities\n            np.clip(self.positions, self.lower_bound, self.upper_bound, out=self.positions)\n            \n            inertia_weight *= self.inertia_damping\n            iteration += 1", "name": "EnhancedOptimizedAdaptivePSO", "description": "Improved EnhancedOptimizedAdaptivePSO with pre-computed random values for velocity updates and reduced boundary checks.", "configspace": "", "generation": 58, "fitness": 0.3264617963790079, "feedback": "The algorithm EnhancedOptimizedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.27.", "error": "", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474723696418783, 0.8489423236861042, 0.838329002215133, 0.8437578530068233, 0.8595159270310224, 0.8511197199964187, 0.8508462994947649, 0.8420432580374555, 0.8433030491574122, 0.7243687425371212, 0.038755259025153865, 0.7229709411787992, 0.736729296215158, 0.7357884915940145, 0.043625540859996925, 0.7017864008171273, 0.054944124926130655, 0.7107418964081667, 0.16884632813948153, 0.6775156391764232, 0.15019216536852387, 0.1669538432493879, 0.6414968482699069, 0.168066863494425, 0.24529945213487425, 0.5799018505371559, 0.6511400091333002, 0.12487917939869697, 0.16390780646021286, 0.13335927419160143, 0.16752797059217828, 0.17319830632152622, 0.13271763000498593, 0.1303732836406143, 0.14713461259271576, 0.11728083059440397, 0.9837801407268236, 0.9836051916014238, 0.9812393592728207, 0.9785176002552436, 0.9810074942282246, 0.9756128321585354, 0.9864605565317539, 0.9785555022152759, 0.9759048604876469, 0.6036039163057788, 0.6172649056534866, 0.617169964472932, 0.43842810992093395, 0.15376983792614551, 0.15156079520573862, 0.5136145879179901, 0.5346589731440763, 0.08881672638362126, 0.3790575622728315, 0.3522512693998615, 0.8191541263593154, 0.19463357924356073, 0.37264210600832226, 0.2033802358760317, 0.2350350384361385, 0.8119640094351497, 0.3257307448847325, 0.18254938039128488, 0.19464706026146372, 0.1712710047898055, 0.17753858395287703, 0.1342284685913986, 0.18438046872327163, 0.17880910554154594, 0.12577325214320756, 0.1844481301824572, 0.13097186942859096, 0.23020723329120119, 0.19271946368641657, 0.1340519159255622, 0.28142251128861884, 0.14641900224241466, 0.21461206579141257, 0.12418456902998876, 0.22226826255114085, 0.001985376373861647, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05049846544917491, 0.006619010166410977, 0.04488442441574969, 0.07969610607157152, 9.999999999998899e-05, 0.11168655347754053, 0.05164407302949714, 0.0717848394051136, 0.07155896813117613, 0.024640172159209217, 0.037802858492582025, 0.10466725226939166, 0.08750041173950796, 0.12479671990812491, 0.11241416794909798, 0.06859506891458389, 0.06697861385919845, 0.45987397620009973, 0.12505198012365293, 0.1122241341158211, 0.09270660636151329, 0.06771135078009993, 0.06636121634052483, 0.26722317756233727, 0.1358015188928655, 0.23620418029144852, 0.1444172535553102, 0.006244671622871789, 0.20633023980582677, 0.08034994373811566, 0.11439179953491274, 0.08188414227824092, 0.5241547566182128, 0.529497312182506, 0.5137399492007741, 0.5363674078623257, 0.5169109602462378, 0.5038873653054334, 0.5533703651031675, 0.5295448234386225, 0.5638707109814529, 0.10920729595208645, 0.12365926374590586, 0.6620445787338729, 0.09549887774199628, 0.12975312903905034, 0.09173340235732774, 0.10619038843829243, 0.1523427816823858, 0.10590322385986584, 0.19789671180205737, 0.34068015187798295, 0.24866829362027643, 0.24522463084433044, 0.25083626172990403, 0.3307115239998888, 0.348063389318214, 0.23860464233071366, 0.21299512649093377, 0.3405755405101417, 0.35811842485807155, 0.35183256436487165, 0.37166197790662614, 0.46190809517760434, 0.37392342386293753, 0.5385220227309877, 0.38728963713293063, 0.4409183563635769, 0.24819417792037435, 0.19028909328741306, 0.2731802862669732, 0.29418613288632367, 0.2375027183454217, 0.2884323648439996, 0.23321755137468303, 0.31362992167814463, 0.23250298853498919, 0.27118789050450365, 0.2407964677024802, 0.2198529824049984, 0.24990969846834998, 0.22593809396209696, 0.20779125874217486, 0.2437781157370671, 0.2285743323492756, 0.23036857841645042, 0.20507638094225755, 0.6188636945758711, 0.7021880728627365, 0.24946097045086868, 0.22155498064368162, 0.2192840071147889, 0.2135413415480063, 0.20597108258732555, 0.6421198359677132, 0.18469559744798392, 0.17708262303861388, 0.15344315124413133, 0.8765387208093545, 0.20029740179303268, 0.20028585231890095, 0.1225717173184534, 0.8808648442302599, 0.8885910948160288, 0.8486408957322036, 0.15735929800557347, 0.5388600731321905, 0.8050622914786812, 0.39076992130579535, 0.2118214934677739, 0.10523651807880341, 0.7287247689536855, 0.6697367499119619, 0.1931032902846016, 0.20252216972210046, 0.19113150198713147, 0.22525535629985227, 0.21614204272736326, 0.19150852367094462, 0.1896365949352028, 0.20582337332118605, 0.22676562823896618, 0.08674906004470062, 0.08825866293859652, 0.08910854737108753, 0.09884846215850862, 0.08907363616685249, 0.08736062517701926, 0.12156025773518775, 0.08990705023979462, 0.09122579795106356]}, "mutation_prompt": null}
{"id": "2395d299-6b60-4f2b-8c56-e235cd018e70", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "48c6c433-eb4b-4d88-99ce-29863e212287", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "4f5a6544-f3eb-4dcd-8ac0-8f5c1bf666c3", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "058243ed-053e-4947-835b-450265d177d3", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "7b538413-4f45-469f-a1e1-dfa8668f1f11", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "979d52eb-cff7-454c-a474-34a3a6c42b09", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "7a977f15-80b6-4f15-95fb-8afec608751f", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "f839f1e1-0331-4d0b-a242-ab2f452c9e35", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "e345cf3a-11a0-4382-8a64-b28aa99648d7", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "863a76d5-97d0-4cba-930b-568c94ebaa4d", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "ea9acab9-3689-4e77-b40a-403235fd9fa3", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "e9a4ef39-12af-4a34-a0fe-bd1fe2b799fc", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "1663e73e-8445-43bb-bd46-25222afa0ca6", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "3187a3ae-d26a-4468-9c8a-c9c870cd7990", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "be119aaf-326a-40b5-83a1-48f4ee54aca6", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "21fb3d79-2634-41e3-b553-bfc5a10b3006", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "1dc8124f-cdb8-45df-a22d-c1491f3b1fa6", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "3ad53255-ec8d-4776-a318-d54b6267adc0", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "60e9e73e-d58e-446c-a011-f68d69680d90", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "0341131d-3922-44bf-838c-da5a46049b53", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "dc2ea2ad-2cf4-4d8a-ad31-087d19d63aa3", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "4e99e9ea-8552-4cfc-a352-ab20c405825d", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "e5edcb4e-8a3d-47f8-9dca-d536dc331f89", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "f86abeab-52ef-4765-b693-3fdb4829f6c7", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight\n        \n        while func_calls < self.budget:\n            fitness_values = np.apply_along_axis(func, 1, self.positions)\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping", "name": "EnhancedOptimizedAdaptivePSO", "description": "Enhanced PSO with optimized loop and vectorized updates for improved computational speed.", "configspace": "", "generation": 82, "fitness": 0.3202757034192296, "feedback": "The algorithm EnhancedOptimizedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.26.", "error": "", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8311734602125486, 0.8363763557423982, 0.8393589257393353, 0.8436246143338846, 0.8507139266142193, 0.8470388757447963, 0.8576701933668461, 0.850705384040626, 0.8524267598753996, 0.7206896099921609, 0.7108669596331074, 0.03908659877983445, 0.7266496012275918, 0.7448267026623357, 0.7197910203495674, 0.7235106451784308, 0.7282485367025544, 0.6899864898336847, 0.15096047213001407, 0.1709639451668309, 0.12080153818977302, 0.16128054039856965, 0.20089699737418065, 0.1401807654348538, 0.16004721815178402, 0.16610520832584263, 0.21294735482113714, 0.1604099208223292, 0.11435563393782011, 0.11914147822548526, 0.13043444563987738, 0.11225676326585832, 0.366093908502223, 0.13610609512285932, 0.13328089064902238, 0.30868626412243116, 0.9850477966803589, 0.9847713227137329, 0.9849138895959764, 0.9811189264993956, 0.980282523119595, 0.9772224871708403, 0.9864309286978464, 0.9757348819788506, 0.9751863496936953, 0.5932455984315217, 0.4661418668366826, 0.5955438290122536, 0.48138898540569974, 0.5803685094569961, 0.6178957780074877, 0.5130372818093784, 0.38764390327668863, 0.5265273906779953, 0.7627305980346694, 0.34809593316194143, 0.22939199500563012, 0.218539287603012, 0.2751368929774338, 0.20787475852710535, 0.34377499295932634, 0.6858585968533975, 0.24548512269497325, 0.37884170586257926, 0.1242853630751517, 0.186028050397142, 0.13483558030168807, 0.17326000754418514, 0.16750355920840088, 0.18289305705037107, 0.19584472291277966, 0.1837211594999244, 0.20774109147582198, 0.21091206518838335, 0.19254657630242322, 0.13289359374627652, 0.2846008883632939, 0.21994857232611353, 0.2008043189392501, 0.3808608793283058, 0.23050034634481886, 9.999999999998899e-05, 9.999999999998899e-05, 0.019821275421484263, 0.05084581888959949, 9.999999999998899e-05, 9.999999999998899e-05, 0.013330478539221424, 9.999999999998899e-05, 0.012895487791747318, 0.08192570451515424, 0.07774949014120469, 0.09361982456790596, 0.11400198280049245, 0.049513140861551674, 0.06581456085713422, 0.12435020840451905, 0.1000926355749181, 0.09996382520935077, 0.15770077191837029, 0.06496945009833255, 0.1127940135566281, 0.18456875143770957, 0.07512536095474354, 0.16709834702293191, 0.10868151386441038, 0.10602911785843605, 0.06720831574055552, 0.2402677476104763, 0.08445784187500027, 0.1156715952487326, 0.056049878658922525, 0.006235907290627396, 0.08604054668576266, 0.08045537838931416, 0.10103361574700287, 0.08043262675356289, 0.49781272560932943, 0.491816205240572, 0.5296445077677855, 0.5149666442225707, 0.5266604522718334, 0.5270215923530961, 0.5317996070590045, 0.5290397150381949, 0.5403524397825064, 0.1136978497715514, 0.11511088763999999, 0.12856944182631636, 0.1067936461464829, 0.11370265212088093, 0.09673380825203859, 0.14825049250624978, 0.1587272403006066, 0.1483825741275253, 0.2774348074059637, 0.2491944239294075, 0.27612244744335335, 0.23803043368655186, 0.37935307475263336, 0.19875704691506302, 0.36399400455503095, 0.29166895888148503, 0.2627380456877568, 0.3417605033139861, 0.3293582125525397, 0.3198179545025226, 0.43578713484822507, 0.3498226908178287, 0.40960230698488176, 0.5272996462504418, 0.43623138778564297, 0.5115656932406916, 0.2548987863309593, 0.30737940494245664, 0.23891345858452906, 0.30287892856513954, 0.2189454713072445, 0.2765497537808639, 0.24815367734295746, 0.3567839642409474, 0.239344835655123, 0.22275903853250312, 0.23223953549903575, 0.2120588161492133, 0.22503174355053035, 0.25336743613824597, 0.2150302243773784, 0.2444165447917923, 0.2411228805022292, 0.22583171682852698, 0.19598172860535445, 0.7905700465018947, 0.24782869231680194, 0.2100685832099164, 0.2799985184293624, 0.22385580520858006, 0.6592277740280084, 0.6762103159258883, 0.758337457054911, 0.18733953167748585, 0.185925756317027, 0.15387326534395884, 0.8965240254513314, 0.2010736195033681, 0.17255016626571307, 0.09892470635922146, 0.21049683842444133, 0.16886520017745954, 0.848127509697715, 0.156618623450684, 0.610989828952401, 0.21113174499472875, 0.1693020639136048, 0.21192630175332727, 0.711304482153184, 0.16617207757166086, 0.5859385638120298, 0.19862269513056185, 0.1870128682379545, 0.19993090856622675, 0.19509813860488978, 0.2077385912258709, 0.22046656739882164, 0.18661927099107323, 0.21407843954972217, 0.19116994496409478, 0.09141921548856702, 0.09062306064172376, 0.14320956501525017, 0.09394861608196714, 0.10270267055758575, 0.08488200424455139, 0.08057227424438917, 0.09304463407032415, 0.10157049438432808]}, "mutation_prompt": null}
{"id": "2da0a5f0-b946-4ffc-9116-0e7f6d153ed5", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))  # Batch generate random numbers\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(self.inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            self.inertia_weight *= self.inertia_damping  # Directly update inertia weight\n            \n# Note: The above changes aim to optimize runtime efficiency by reducing redundant calculations and restructuring operations within the existing framework.", "name": "EnhancedOptimizedAdaptivePSO", "description": "Slightly optimized PSO with batched random numbers and improved inertia weight update for better runtime efficiency.", "configspace": "", "generation": 83, "fitness": 0.3234688567146127, "feedback": "The algorithm EnhancedOptimizedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.27.", "error": "", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8479378177349777, 0.8491411989899396, 0.8403064342841162, 0.8571313813005754, 0.8391258961259143, 0.8616385569977832, 0.8505409421389224, 0.844814931402906, 0.8442896134776294, 0.7198631810382881, 0.7175019228713934, 0.7069251727536459, 0.7296390934486985, 0.7113788591577623, 9.999999999998899e-05, 0.728342640116038, 0.7231883982436675, 0.05048984883580665, 0.13606249449980712, 0.3773643733130867, 0.555065678506284, 0.15258379326844462, 0.1502529566880556, 0.1467618858653612, 0.5469658238403818, 0.15222455824919268, 0.3204963374052665, 0.10853263836625371, 0.14960676110387972, 0.12349600524797566, 0.1471518433474237, 0.13580129521037743, 0.18038117126745234, 0.11280606754470168, 0.1419681135565426, 0.12132939154886813, 0.9832215568442816, 0.9878478618808783, 0.9860455299546854, 0.9758207823692954, 0.9827025515564234, 0.9836079321065352, 0.9847713632125386, 0.9785599811872691, 0.9727690651687874, 0.4431863645402617, 0.6012808675930392, 0.594582593806861, 0.4877489612292275, 0.5661939892330603, 0.533043073647187, 0.47823463396582955, 0.08878442937342457, 0.0883036492036181, 0.2277196193161558, 0.7472207511878071, 0.22391991118425847, 0.2068910403276213, 0.250938964283668, 0.19486403059670487, 0.2125275037911697, 0.22884136240000852, 0.23551559711000092, 0.28690093294372687, 0.17849166971379526, 0.17131483393774738, 0.1729315585838369, 0.23028787898058323, 0.2077000686892051, 0.19069220081104077, 0.1841001598409664, 0.17524582514410436, 0.2396507173818624, 0.20331200651704462, 0.21022276113550542, 0.15505203675699886, 0.18733982462674925, 0.19258826511126537, 0.21659109674974475, 0.2420046840473734, 0.2858390602241009, 0.005090234531144211, 0.000593197684368163, 0.06367001178374154, 9.999999999998899e-05, 0.028082863575259798, 0.006076594486814635, 0.012699355161506332, 0.012942335498173474, 0.0035995989022763464, 0.1178622379971781, 0.05899904422904856, 0.12824930525193012, 0.08197795937291319, 0.009464732467963533, 0.03144209216026739, 0.12102802623624209, 0.1420342042820767, 0.11723517355996171, 0.22799126727348817, 0.09876449727111725, 0.10419398583690254, 0.0727680483052322, 0.07025410347746797, 0.17826084434489897, 0.09325977982847888, 0.22576334977096224, 0.06636003002029922, 0.37268904790182844, 0.14037297845090946, 0.1956981493711607, 0.1030805070765477, 0.006249433478577537, 0.17802501652964098, 0.08128318200843054, 0.08000434311057691, 0.08063863515842207, 0.5004180147180946, 0.5217018748060098, 0.48830512726410513, 0.5588313563625675, 0.5070692527341975, 0.5632926631294288, 0.5375158357771408, 0.5147010614047781, 0.527879733484235, 0.12166991068480315, 0.08092815932630404, 0.12731006914092047, 0.14319187177406567, 0.1382091748936236, 0.1295600346278768, 0.10073362878035097, 0.1261070406608511, 0.12256759160642794, 0.38361151576580654, 0.1863527206860619, 0.2560726296782746, 0.3831634129063366, 0.41382616644107606, 0.31715846903680656, 0.27303917742718253, 0.2224206159080181, 0.23257942737307058, 0.25202267490958385, 0.43996652655282176, 0.40381224048699127, 0.3962043904000824, 0.41861859666909707, 0.3400783734077659, 0.468973630235631, 0.4103555758613757, 0.4426463884479145, 0.2887978235733665, 0.3269596305191651, 0.37387758944136074, 0.3412064652318414, 0.31066203628500166, 0.27355500966834845, 0.21046802295416311, 0.2733942795584131, 0.25157778827222954, 0.21053183615562043, 0.23945244719152703, 0.21233730461141165, 0.2281396608905455, 0.2581068987702726, 0.19982397949528174, 0.2481090504615584, 0.22156332248949184, 0.2360858058974168, 0.21795472650549808, 0.24938329600751163, 0.2461715160829635, 0.20826189270436257, 0.24619667767532138, 0.23661139492660177, 0.6978702849011313, 0.19885212962197962, 0.6886217197201742, 0.868124920813096, 0.18788682266212564, 0.15414358567410014, 0.9175387452456041, 0.2008056835348786, 0.8898515191997602, 0.8890907464282262, 0.170093149250098, 0.8851734795852697, 0.59090849903972, 0.5055867464192558, 0.5734340512283731, 0.6470378333582412, 0.16846494610054674, 0.21251479730033063, 0.10469586303653233, 0.10471917788373686, 0.6061799118618973, 0.18304156265050808, 0.19875530383242435, 0.20228521462778226, 0.18534167970137128, 0.21265692546647108, 0.22412847778241252, 0.1994478733396995, 0.20934616643625192, 0.19263175435970803, 0.1099249680528035, 0.10573551724343322, 0.09067039985930714, 0.093190487490725, 0.0845804096653412, 0.09965706083233905, 0.09329910471383451, 0.10382305713336715, 0.08561829315505565]}, "mutation_prompt": null}
{"id": "ec536b81-ddb5-486b-a3a9-988bc4d7c199", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "fe0ae497-d096-4d12-bef2-0dd3e258351a", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "2e20bacf-8372-4cdb-910b-64fddbc6da62", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "f2d2e23d-792c-402f-a5a0-41618f79b8e3", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "57ecad40-454d-4403-b58d-c89932e6ba68", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "512c9af9-bc84-4934-945e-3b993e06e210", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "ad477e3b-0ca4-4773-9ffb-260a23e15236", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "2228288c-ae28-44a8-9fe5-d83382223b20", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            batch_size = min(self.n_particles, self.budget - func_calls)\n            fitness_values = np.apply_along_axis(func, 1, self.positions[:batch_size])\n            func_calls += batch_size\n            \n            improved = fitness_values < self.pbest_scores[:batch_size]\n            self.pbest_scores[:batch_size][improved] = fitness_values[improved]\n            self.pbest_positions[:batch_size][improved] = self.positions[:batch_size][improved]\n            \n            min_index = np.argmin(self.pbest_scores[:batch_size])\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, batch_size, self.dim))  # Reduce redundant RNG calls\n            cognitive_term = self.c1 * r1 * (self.pbest_positions[:batch_size] - self.positions[:batch_size])\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions[:batch_size])\n            self.velocities[:batch_size] = np.clip(inertia_weight * self.velocities[:batch_size] + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions[:batch_size] = np.clip(self.positions[:batch_size] + self.velocities[:batch_size], self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by optimizing fitness evaluation batching and reducing random number generation redundancy.", "configspace": "", "generation": 91, "fitness": 0.3248663111042158, "feedback": "The algorithm EnhancedOptimizedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.27.", "error": "", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8548212943226773, 0.8391326149050078, 0.8580135692778201, 0.8597025810279215, 0.8402441018612826, 0.8464906138268631, 0.8506889281453502, 0.8597234142243596, 0.8478340041666279, 0.7485090119681304, 0.7297411078187038, 0.7078369786030847, 0.747188358542231, 0.04596701184704144, 0.7279199933883436, 0.7271714978458361, 0.7243466703370587, 9.999999999998899e-05, 0.6048537626909474, 0.1337452609945633, 0.17650938450343623, 0.17823284831994624, 0.35370811658685275, 0.16698133768018764, 0.15314024576088248, 0.16459857993246774, 0.5360997790071458, 0.17109868230764935, 0.6695180754067935, 0.1474190616406753, 0.15092251455835248, 0.13239858693308926, 0.12547553964209202, 0.144037183176691, 0.1465720441328291, 0.13064203113377082, 0.9834313131644303, 0.9838851854829371, 0.9856735368886965, 0.9807023012659873, 0.9808671658191205, 0.9827870651073546, 0.9838339191332448, 0.9781512230383298, 0.9858566312692054, 0.5841862929038466, 0.5578214046046633, 0.495548732123012, 0.5742938031624922, 0.5047268825467175, 0.4866034734467889, 0.5434438395895296, 0.5362832035336337, 0.5322736371985458, 0.2272002825150008, 0.22675170263709543, 0.37857993443554694, 0.2073266864986475, 0.36721873259800575, 0.19329292502604667, 0.22315498991001081, 0.22899158309440204, 0.8533076888630824, 0.36414790459957946, 0.2516683181961916, 0.17464070882878802, 0.1797347058391653, 0.3256946514664666, 0.116365166144479, 0.18313119968279612, 0.1802788900633181, 0.18686221520376367, 0.20512215972599002, 0.18825904922402392, 0.19175835301888677, 0.17886438047699615, 0.3759660328700115, 0.1296892983729635, 0.2116943119487802, 0.033936930548322364, 0.22808599341923996, 0.08798212250003001, 0.08365752377286406, 0.06805430910773047, 0.00036683942291515503, 9.999999999998899e-05, 0.04378823415725308, 0.0004156118847389312, 9.999999999998899e-05, 0.08022515578957101, 0.09179000691980332, 0.08640990637009749, 0.11755064614655764, 0.0856903568594446, 0.027667065590137874, 0.039432347102584586, 0.1397436684678489, 0.12840656851729548, 0.057974743477048785, 0.1942093310497799, 0.06441951064279239, 0.09651945185877486, 0.0721131352491835, 0.10306995478799597, 0.1271319239503892, 0.109778653887463, 0.15796663003166267, 0.06871215780845563, 0.37537650483979257, 0.13075983235120725, 0.23451267908545537, 0.006254415476147579, 0.14983701321317022, 0.13960004931267267, 0.08022248782012797, 0.09329550576381296, 0.08009324750730962, 0.532038025754483, 0.5099882623347405, 0.5281843508007871, 0.5137241322622992, 0.5232485444007842, 0.5630005151506264, 0.5545595541179442, 0.5224118150065289, 0.5290999239729318, 0.11723034713005998, 0.13309219147618967, 0.0702977706736958, 0.13699522377879514, 0.09326205110787977, 0.10106722996422779, 0.13904014089241046, 0.1400207356602201, 0.10095344290311425, 0.25583937454997185, 0.2968776906281523, 0.381710844244207, 0.25079435839298825, 0.26102005423476626, 0.32123784586167126, 0.20356132412061323, 0.2656420234968976, 0.3944241237060616, 0.34099521326777704, 0.3599203858313834, 0.3758541567056166, 0.4422424674729295, 0.3915415854351748, 0.2942192917743234, 0.4239861816031929, 0.3631454195239564, 0.4138114977408959, 0.2725000163507335, 0.1849263946433215, 0.30262870325236113, 0.28684172847095646, 0.19350572237389374, 0.3177503181135599, 0.3218943048244296, 0.24464774065887362, 0.2777565873499337, 0.2093393590863849, 0.23365202207834734, 0.2444804598762117, 0.18707319932429145, 0.2334424659930594, 0.23458684610272507, 0.2795587138123582, 0.21136539793638265, 0.2268558678232082, 0.20513352804048035, 0.20114092881381973, 0.20421180094360392, 0.2416169605911218, 0.20638062701274662, 0.24157964064272763, 0.21193549420761426, 0.41436113839661515, 0.21911212961933002, 0.8665161771657366, 0.17547942741214406, 0.15422693950167776, 0.906241150188347, 0.20044742997132692, 0.16751277489685212, 0.8900618963885603, 0.17003385731713572, 0.8669581072756589, 0.5574088400201869, 0.14635323024158842, 0.5517778402566242, 0.5436894536566224, 0.16871853775361956, 0.2122407577150075, 0.7832291456125883, 0.10373372294795569, 0.7762420747572873, 0.19225917659557967, 0.209717608913647, 0.20546649625277524, 0.1891168972462266, 0.21047002400692283, 0.19212551822001434, 0.18595705664919715, 0.19329582102254828, 0.19499245624446226, 0.09668815658321561, 0.10930565434292416, 0.08884405419010433, 0.10010087180594163, 0.10507879183542013, 0.09077335581971002, 0.12666452462920263, 0.09289916546848054, 0.09647323056297008]}, "mutation_prompt": null}
{"id": "f70bceba-aea8-4113-bcdd-41f29722afa3", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "cbb5e4e1-6594-457f-a783-79f41a7e5d0d", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "018282c6-719f-4c44-a45f-67cea03a0a1d", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "32697bf6-77bf-4bb7-805b-c3841ded4625", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "97bb57d7-a035-4c1d-8bba-4ef5b6af60bb", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight\n        velocity_update_coefficient = inertia_weight * self.inertia_damping\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities *= velocity_update_coefficient\n            self.velocities += cognitive_term + social_term\n            self.velocities = np.clip(self.velocities, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with streamlined velocity updates and improved inertia weight management for enhanced runtime efficiency.", "configspace": "", "generation": 96, "fitness": 0.18858604236493678, "feedback": "The algorithm EnhancedOptimizedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.20.", "error": "", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.34155176426641465, 0.3085094885441463, 0.3533643924214377, 0.3195378380280687, 0.3637610717309141, 0.34765231550292996, 0.32631502646271937, 0.3509390904928904, 0.35188531932621636, 9.999999999998899e-05, 0.025885343418774243, 0.03478871779847181, 0.009557154702245274, 0.01088886373987552, 0.0018061102019826247, 0.020861409845359558, 0.0006065115396136633, 9.999999999998899e-05, 0.08437575395094732, 0.1435943529968381, 0.10311732731708578, 0.0992695189244005, 0.08716727311597205, 0.09097710239933132, 0.08940372544992514, 0.10949200004367465, 0.10227936390908621, 0.0804107937865981, 0.09288917902724192, 0.07933619975243633, 0.07467967051384272, 0.07755998360670824, 0.07290671640749224, 0.08105305098920979, 0.08376061364752407, 0.0965056067944774, 0.9809111584527469, 0.9856374777082275, 0.9860592853977695, 0.9780158596801388, 0.9806564710070483, 0.9811245938342942, 0.9838269349018021, 0.9734071227272714, 0.9780908395897587, 0.19338245803490706, 0.18823998386490093, 0.1817193324096188, 0.2221290086335187, 0.2061656697011952, 0.14408837879571856, 0.11848132241791887, 0.08909393359962792, 0.18866430199265538, 0.2494121242653884, 0.21468214218036485, 0.2453312963114721, 0.22771898417013614, 0.20903505625245322, 0.19450897273722612, 0.22764496514225574, 0.12593723876696772, 0.22733239085414725, 0.11413048915601376, 0.11945314784766325, 0.11840039894077059, 0.09686950455767784, 0.13090110822008305, 0.09937982659792177, 0.13053353647534527, 0.11184595362133298, 0.1379467300521392, 0.11623614471916466, 0.12554902429916326, 0.12412765346095622, 0.11884171700002844, 0.1384012888344841, 0.12328732679118892, 0.12905783663894088, 0.1399464097305292, 0.11460650377441362, 0.0019371137356954948, 0.003527453465632213, 0.03440060371151976, 0.0010049140264424272, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05027722161916304, 0.0377292556574772, 0.1476401383876711, 0.06934419576638284, 0.02775076982154656, 0.04198467560008978, 0.12273569292298958, 0.048195967135988615, 0.05816894849124088, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06459783993617729, 0.050040987225353994, 0.042682401191457164, 0.0015095324156418899, 0.07122155157922916, 0.001169400013853683, 0.044940323728835385, 0.043839515715807686, 0.05767695727629729, 0.32664405499966565, 0.3527516129170033, 0.3131817179950084, 0.3421213524828697, 0.3380001783830935, 0.3235798731222548, 0.36327465191536923, 0.3228928135371666, 0.33557982646823425, 0.08554315741530938, 0.0875478121497586, 0.07909724571403398, 0.09835382311029373, 0.11317274258670895, 0.09394946023449924, 0.07889640700973577, 0.10526704193275982, 0.08519803584313945, 0.14412357674188947, 0.15794239523432296, 0.1477468224328693, 0.2041534469041909, 0.2494242696157989, 0.19540652874713582, 0.1625644655134394, 0.16255218297418939, 0.1526919014844199, 0.23645625880992804, 0.20969909373603535, 0.2354396905511248, 0.24631515185937325, 0.22102319930011227, 0.2551488679855426, 0.24996415969325858, 0.2468041943572884, 0.2610647426102749, 0.18178980950306323, 0.1622307198106906, 0.18473407248551044, 0.1861689700881517, 0.21511150838095472, 0.1867912842886602, 0.21172649792872156, 0.19876416418623744, 0.17183482782564696, 0.20962083857634028, 0.20054590180875587, 0.23169238663245662, 0.20554583692518336, 0.2350838455680756, 0.2084006264986933, 0.20739695196571561, 0.18532108210852927, 0.20803477844162876, 0.17987040152106215, 0.18976418459390465, 0.18615004617354425, 0.20211190249310618, 0.20451164312067327, 0.17831858646455057, 0.1761650180883142, 0.17522114541060851, 0.18483944952391562, 0.18018749987017801, 0.18416559288366474, 0.15231990563861797, 0.4450348520381292, 0.19921967400336216, 0.1690537869535439, 0.1582739743493914, 0.16933446592826762, 0.49606635279103894, 0.37628453379378, 0.14548214731769926, 0.57895565533877, 0.2996358416800181, 0.2247462273483276, 0.20670193640640655, 0.3971791091560578, 0.3889393535714173, 0.3626613977293368, 0.18808245322589678, 0.17993883636845553, 0.18762849565230444, 0.19467832875538138, 0.19993001006992095, 0.18654459843444748, 0.18011115618371643, 0.19181986779445692, 0.18032516957256028, 0.08326024514038521, 0.08103793188263952, 0.08706346054291425, 0.08233384238398989, 0.08639745575398738, 0.0869146889500364, 0.0833863411207536, 0.07315238839149174, 0.08494232279752156]}, "mutation_prompt": null}
{"id": "b061a2fe-4d90-4532-8ea6-414a59cc3b94", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "4d9870e0-2097-4984-890d-9c0e56208309", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.array([func(p) for p in self.positions])  # Batch process fitness evaluations\n            func_calls += self.n_particles\n            \n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n            \n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n            \n            r1, r2 = self.rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n            \n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with improved runtime efficiency by batch processing fitness evaluations and reducing inertia weight recalculations.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8474532599108913, 0.8482038858363199, 0.8503303618587661, 0.8311372190523606, 0.8425087930024002, 0.8473649915306745, 0.8575196501191577, 0.8497555073283793, 0.8415208248129206, 0.7284573193032022, 0.748118161751659, 0.7137643531648077, 0.7345458175422267, 0.715806675321603, 0.7445474347904231, 0.7228952732465612, 0.7291527710812344, 0.7353746152323042, 0.6428700725829803, 0.16823409763048636, 0.14330821318599452, 0.42649976925850686, 0.1652092129388416, 0.1457198810350011, 0.14856637729396993, 0.43424363079648065, 0.6540413134256836, 0.1672381574967552, 0.110968451028717, 0.12676661228350328, 0.12537339298330263, 0.14627535544192705, 0.13674637492406017, 0.14096392643691036, 0.14330906147639688, 0.13253937645028946, 0.978117009379684, 0.9800347435082872, 0.9826842750985474, 0.9785794040899144, 0.9804312783587465, 0.9784006678556644, 0.9855743450524999, 0.9800025920046401, 0.9812236266571422, 0.6234544768364512, 0.5494735335985363, 0.6168361491437531, 0.5533941312232489, 0.542733055728968, 0.5510626879412428, 0.1278232984362212, 0.08909653404667428, 0.08352063146748001, 0.8655881212525031, 0.22319635484052458, 0.22287690222162748, 0.19468245208396529, 0.2797603094144584, 0.19312390443661798, 0.4702021452249606, 0.3852740024614749, 0.8234607574204386, 0.1745619808698835, 0.1801278443873383, 0.18074006090148165, 0.18388975727161927, 0.18302310000332778, 0.13173168403967817, 0.18856853276277985, 0.18534610465862456, 0.17713944683161498, 0.20620568491499014, 0.20002750959200266, 0.22701885578607883, 0.18603974161659653, 0.19480211136677084, 0.18772727694007185, 0.12785759791974272, 0.22819799261952445, 0.11176127877933972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008341722355213466, 9.999999999998899e-05, 0.045062912629322605, 0.04043368577766504, 9.999999999998899e-05, 0.05379310503524759, 0.14747952976130818, 0.06319349546395991, 0.14990877271863579, 0.04964693848914903, 0.011506574773019196, 0.0435651886564723, 0.25254200727272424, 0.10892688172846376, 0.10885284248033877, 0.1079315253242239, 0.09213695833107327, 0.055874088406218325, 0.14519667929023095, 0.07250939936906053, 0.11000193517138923, 0.09548454724071764, 0.28061556702568435, 0.06756322141610327, 0.10996838234520889, 0.10242090247892044, 0.07471440173643573, 0.12312115829163428, 0.15117365595094057, 0.02917300282130797, 0.08039667328173417, 0.08097523986664823, 0.4024557249139106, 0.50130251516869, 0.5373119661422311, 0.5392303259713846, 0.540656799799219, 0.5505794484741539, 0.5254447054215413, 0.5030560215567215, 0.5464844836502691, 0.558642848943504, 0.12717423980123566, 0.08228739813479091, 0.13007211567369614, 0.11472953347465087, 0.10964982187366146, 0.1139324880349093, 0.15015124089203213, 0.12313598965604944, 0.1488495799543933, 0.2613477257977692, 0.1940139562539468, 0.40955099151428, 0.23943793217308373, 0.2554041275176562, 0.24389389973581377, 0.24460576829876524, 0.23482956688258871, 0.3434243986069354, 0.44851396044200087, 0.3536453466270343, 0.426257650054899, 0.38663280564524916, 0.24193985577185217, 0.38094044545631145, 0.38283635712553865, 0.4019055833505423, 0.3555766972088329, 0.18147693016948419, 0.3000131604976054, 0.2367659484875505, 0.2991299092704983, 0.24712087373849712, 0.3736585148970286, 0.2338467791079053, 0.30354772364118854, 0.2553317617817157, 0.24848284537821508, 0.22886847572155433, 0.21859318528421967, 0.23562517180777676, 0.2295284526209701, 0.22851029662858247, 0.22708050239115385, 0.2373849489371922, 0.24444349344226846, 0.2219036591074709, 0.21242641874810264, 0.2403462392432052, 0.21563982664632153, 0.22430297110224662, 0.24301846202805866, 0.21054246660549214, 0.6890728680459447, 0.23902671012978183, 0.17763523255315472, 0.12644724336351953, 0.1532292951469557, 0.8542499405274259, 0.19956311399880378, 0.19846039454615072, 0.12235355162945671, 0.8827842533565776, 0.8949105653998202, 0.8117609057310736, 0.15591280701542054, 0.5803567187450953, 0.8522795207582476, 0.2221029505646065, 0.6157229258827206, 0.592866718825358, 0.16728927458522302, 0.645451896962604, 0.20522520091878949, 0.19267353685544075, 0.18980200930465674, 0.20817748138522196, 0.1856386852843278, 0.19605817125144376, 0.20391340662042534, 0.22618444835363527, 0.20729524110630992, 0.09611334516082803, 0.09695098248211709, 0.0945798872400666, 0.09491057903891564, 0.08407915100588326, 0.08551030786377067, 0.14967148346086834, 0.09441343867015162, 0.08907501176971377]}, "mutation_prompt": null}
{"id": "ca7b6a77-82f3-4ad5-aac4-3ff94bc9bc34", "solution": "import numpy as np\n\nclass EnhancedOptimizedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.n_particles = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.max_velocity = (self.upper_bound - self.lower_bound) * 0.2\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.n_particles, dim))\n        self.velocities = np.zeros((self.n_particles, dim))\n        self.pbest_positions = self.positions.copy()\n        self.pbest_scores = np.full(self.n_particles, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        func_calls = 0\n        inertia_weight = self.inertia_weight  # Local caching for performance\n        rng = self.rng  # Local caching for performance\n        while func_calls < self.budget:\n            fitness_values = np.apply_along_axis(func, 1, self.positions)  # Using apply_along_axis for clarity\n            func_calls += self.n_particles\n\n            improved = fitness_values < self.pbest_scores\n            self.pbest_scores[improved] = fitness_values[improved]\n            self.pbest_positions[improved] = self.positions[improved]\n\n            min_index = np.argmin(self.pbest_scores)\n            if self.pbest_scores[min_index] < self.gbest_score:\n                self.gbest_score = self.pbest_scores[min_index]\n                self.gbest_position = self.pbest_positions[min_index]\n\n            r1, r2 = rng.random((2, self.n_particles, self.dim))\n            cognitive_term = self.c1 * r1 * (self.pbest_positions - self.positions)\n            social_term = self.c2 * r2 * (self.gbest_position - self.positions)\n            self.velocities = np.clip(inertia_weight * self.velocities + cognitive_term + social_term, -self.max_velocity, self.max_velocity)\n            self.positions = np.clip(self.positions + self.velocities, self.lower_bound, self.upper_bound)\n\n            inertia_weight *= self.inertia_damping  # Update local cached inertia weight", "name": "EnhancedOptimizedAdaptivePSO", "description": "A refined EnhancedOptimizedAdaptivePSO with enhanced vectorized operations to minimize redundant calculations and improve runtime efficiency.", "configspace": "", "generation": 99, "fitness": 0.3113757367196054, "feedback": "The algorithm EnhancedOptimizedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.26.", "error": "", "parent_id": "a3cd0701-676a-48bb-9353-09ff01a831b6", "metadata": {"aucs": [0.8508930964931142, 0.8454957132444564, 0.856043344059191, 0.8470905530846484, 0.8565719047140228, 0.8529264408028198, 0.8625990584233252, 0.8342614210244559, 0.8546562880624309, 0.7322508529681186, 0.038792818858401024, 0.7325035871469183, 0.7233752418117501, 0.7394077408472777, 0.7540037871741461, 0.7252905922916124, 0.7373626516508867, 0.7408853719525104, 0.16259963786082932, 0.17344282796485677, 0.18242260322979964, 0.34111691506987585, 0.1747814414863731, 0.1490306826640373, 0.16579771735370052, 0.6517796939377054, 0.14183506249896727, 0.11980240996401481, 0.16037962847209142, 0.11784714845771271, 0.13438599578518517, 0.15033154489676126, 0.1466125525038815, 0.12044786665509533, 0.14680215290335397, 0.1181722437961591, 0.980666306747468, 0.986085606715078, 0.9834898665377054, 0.9785647558083465, 0.9836886455367837, 0.9854158090311622, 0.9866088438242369, 0.9801926395716077, 0.980879633555843, 0.5266829223585127, 0.5655556299726108, 0.6103914298990857, 0.5796669666330843, 0.6202933263266336, 0.4168440763814406, 0.12437283990882897, 0.08905808565661444, 0.5090491370572983, 0.17249896984981428, 0.37410982833060846, 0.22756449193573103, 0.22191596923415446, 0.3690443638997266, 0.19403171344721015, 0.3871380750613427, 0.2333375968845678, 0.698534849928212, 0.1848893235268778, 0.1751468834521518, 0.32093079241474454, 0.18262450671959618, 0.19783279461470915, 0.18242762168050874, 0.17575931760173658, 0.22030252721153654, 0.18581574791044542, 0.19285461223873324, 0.1244879007856754, 0.1842609467170343, 0.2016968609522285, 0.17989080878749097, 0.1799490456656958, 0.12757498615182317, 0.2286453762622387, 0.21996769074683498, 9.999999999998899e-05, 0.008759368371470733, 9.999999999998899e-05, 0.052154743534056025, 0.0017562901142560428, 0.05721733147365282, 0.0004081706590600698, 0.15557518998090547, 9.999999999998899e-05, 0.15178387241400493, 0.04806779847967679, 0.09361604001426826, 0.07498030715819437, 0.0457270620248742, 0.03080540531923548, 0.1093238423790921, 0.0819388863768491, 0.1204729145545822, 0.20112010055263685, 0.25101135469489166, 0.29748810076554866, 0.12663546216368649, 0.07328662204672687, 0.21168750158398375, 0.09434422435976608, 0.08955831317150365, 0.10289584188222234, 0.1992117920890475, 0.12135608741969894, 0.15499664673718816, 0.18786356139604066, 0.12086298569537735, 0.05599009140880151, 0.08126554336378145, 0.04877814905043687, 0.08254480237216943, 0.5405042948707438, 0.5500993327539542, 0.4895868825532438, 0.5181667808259023, 0.5428867667630233, 0.5271892235987191, 0.5246066994600689, 0.565321818340604, 0.5421797254846585, 0.11277822416786298, 0.11550301127445706, 0.07281736865651678, 0.10779207000307522, 0.13421144045759303, 0.1206968049875129, 0.14099845345859863, 0.11949711568273147, 0.14006415092065438, 0.25585713513515584, 0.40426482532969155, 0.1713407914548477, 0.23723407310410183, 0.394033811515181, 0.26047619496691266, 0.22868031892930918, 0.26585312563200447, 0.20984941908585608, 0.3808501177035061, 0.26166448917662644, 0.4292688458590602, 0.3617935580371835, 0.41786291541329434, 0.3215790836043738, 0.24811252072677348, 0.28195473990144715, 0.42731425145722934, 0.2195632170073193, 0.21270568660528022, 0.28402751719253305, 0.29888279999644707, 0.28632889225567315, 0.25670971940846343, 0.21676998276902892, 0.27387543342981424, 0.29007314914715643, 0.21731781315537768, 0.19581350363411665, 0.2229304505367622, 0.24394602830163514, 0.2677504332150128, 0.21892641253749512, 0.20351637850304582, 0.2173325184853485, 0.21845558942420185, 0.24784071431772914, 0.23473313246128158, 0.23440593330152504, 0.2193044671833716, 0.22120679179182845, 0.2439586493181033, 0.220644637908339, 0.20359736528899142, 0.24252272864030966, 0.17754685298888584, 0.12680484625921984, 0.15350591141064773, 0.8845904599893214, 0.20073009415016763, 0.16995509550029342, 0.8799776481139802, 0.1700095386483823, 0.8972224438893777, 0.7686427107503929, 0.1557345921409724, 0.6180806678450692, 0.6423828994424441, 0.16939886609933297, 0.21199394769346058, 0.10487749638983856, 0.10493915368083273, 0.6034617489452232, 0.21734445604204888, 0.202806826400723, 0.20598192685718664, 0.20203115916217418, 0.19048550050734447, 0.19187169429590167, 0.20410660812474868, 0.19852287159160587, 0.18154109775528782, 0.11632692002702993, 0.08360983314186121, 0.09237777586326135, 0.10238814142093011, 0.09808779961056713, 0.0849100731791903, 0.10720034205592, 0.10635145539005786, 0.08880623171048041]}, "mutation_prompt": null}

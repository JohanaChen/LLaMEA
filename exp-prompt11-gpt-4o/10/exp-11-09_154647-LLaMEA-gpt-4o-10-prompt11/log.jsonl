{"id": "72de5b7e-8993-4555-a3c2-d23dc3418c2d", "solution": "import numpy as np\n\nclass APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(50, 10 * dim)  # Dynamic population size\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.w = 0.9  # Inertia weight\n        self.decay_rate = 0.99  # Inertia decay rate\n    \n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "APSO", "description": "The Adaptive Particle Swarm Optimization (APSO) algorithm dynamically adjusts particle velocities and inertia to efficiently explore and exploit the search space.", "configspace": "", "generation": 0, "fitness": 0.26595219226430217, "feedback": "The algorithm APSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.23.", "error": "", "parent_id": null, "metadata": {"aucs": [0.7360051051708216, 0.7360051051708216, 0.7360051051708216, 0.18645685806465528, 0.18645685806465528, 0.18645685806465528, 0.7713921523870435, 0.7713921523870435, 0.7713921523870435, 0.550031578914033, 0.550031578914033, 0.550031578914033, 0.5500055242283628, 0.5500055242283628, 0.5500055242283628, 0.6032875954746266, 0.6032875954746266, 0.6032875954746266, 0.16128428344542667, 0.16128428344542667, 0.16128428344542667, 0.15554574782388375, 0.15554574782388375, 0.15554574782388375, 0.1411369750681586, 0.1411369750681586, 0.1411369750681586, 0.13534350689186736, 0.13534350689186736, 0.13534350689186736, 0.1424206231688766, 0.1424206231688766, 0.1424206231688766, 0.11667754209145897, 0.11667754209145897, 0.11667754209145897, 0.9886292780367639, 0.9886292780367639, 0.9886292780367639, 0.9887925581561708, 0.9887925581561708, 0.9887925581561708, 0.9885421486121282, 0.9885421486121282, 0.9885421486121282, 0.635611251394016, 0.635611251394016, 0.635611251394016, 0.19980882661796473, 0.19980882661796473, 0.19980882661796473, 0.6237603166707808, 0.6237603166707808, 0.6237603166707808, 0.21547027627083892, 0.21547027627083892, 0.21547027627083892, 0.3182781263041514, 0.3182781263041514, 0.3182781263041514, 0.22065311071522686, 0.22065311071522686, 0.22065311071522686, 0.19969481429101532, 0.19969481429101532, 0.19969481429101532, 0.18759222512419782, 0.18759222512419782, 0.18759222512419782, 0.3034142248365673, 0.3034142248365673, 0.3034142248365673, 0.17710468078518427, 0.17710468078518427, 0.17710468078518427, 0.2085214181547973, 0.2085214181547973, 0.2085214181547973, 0.22421920664958628, 0.22421920664958628, 0.22421920664958628, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09285956004593077, 0.09285956004593077, 0.09285956004593077, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05813384306994651, 0.05813384306994651, 0.05813384306994651, 0.025090263255342138, 0.025090263255342138, 0.025090263255342138, 0.03570461986651785, 0.03570461986651785, 0.03570461986651785, 0.04037714421043381, 0.04037714421043381, 0.04037714421043381, 0.10532559587605939, 0.10532559587605939, 0.10532559587605939, 0.07875350717208418, 0.07875350717208418, 0.07875350717208418, 0.03390465931808029, 0.03390465931808029, 0.03390465931808029, 0.12802969935465336, 0.12802969935465336, 0.12802969935465336, 0.05513371740931794, 0.05513371740931794, 0.05513371740931794, 0.4939408292640395, 0.4939408292640395, 0.4939408292640395, 0.4685885375052731, 0.4685885375052731, 0.4685885375052731, 0.521814708822842, 0.521814708822842, 0.521814708822842, 0.10850915839109132, 0.10850915839109132, 0.10850915839109132, 0.1434957805577265, 0.1434957805577265, 0.1434957805577265, 0.12444479398567765, 0.12444479398567765, 0.12444479398567765, 0.19682788175846577, 0.19682788175846577, 0.19682788175846577, 0.15154394345854305, 0.15154394345854305, 0.15154394345854305, 0.2011976429451129, 0.2011976429451129, 0.2011976429451129, 0.35818352429604094, 0.35818352429604094, 0.35818352429604094, 0.31896043741863567, 0.31896043741863567, 0.31896043741863567, 0.26914436839468714, 0.26914436839468714, 0.26914436839468714, 0.3198923395060509, 0.3198923395060509, 0.3198923395060509, 0.1816934326005496, 0.1816934326005496, 0.1816934326005496, 0.14825817013523934, 0.14825817013523934, 0.14825817013523934, 0.19990874786405366, 0.19990874786405366, 0.19990874786405366, 0.19553590903458618, 0.19553590903458618, 0.19553590903458618, 0.18797459843108422, 0.18797459843108422, 0.18797459843108422, 0.20014934637304216, 0.20014934637304216, 0.20014934637304216, 0.19865486024107004, 0.19865486024107004, 0.19865486024107004, 0.19007383648880005, 0.19007383648880005, 0.19007383648880005, 0.7812316845624572, 0.7812316845624572, 0.7812316845624572, 0.1548246042432918, 0.1548246042432918, 0.1548246042432918, 0.17728680087073156, 0.17728680087073156, 0.17728680087073156, 0.16648479425097773, 0.16648479425097773, 0.16648479425097773, 0.20366033522394045, 0.20366033522394045, 0.20366033522394045, 0.15424093668480232, 0.15424093668480232, 0.15424093668480232, 0.21600064521487083, 0.21600064521487083, 0.21600064521487083, 0.1994012581688811, 0.1994012581688811, 0.1994012581688811, 0.1788673361931571, 0.1788673361931571, 0.1788673361931571, 0.12657584329867044, 0.12657584329867044, 0.12657584329867044, 0.09016664277771413, 0.09016664277771413, 0.09016664277771413, 0.13783154914067508, 0.13783154914067508, 0.13783154914067508]}, "mutation_prompt": null}
{"id": "9826d27e-2851-47be-907e-8a79a2ad446b", "solution": "import numpy as np\n\nclass APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(50, 10 * dim)  # Dynamic population size\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.w = 0.9  # Inertia weight\n        self.decay_rate = 0.99  # Inertia decay rate\n    \n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "APSO", "description": "The Adaptive Particle Swarm Optimization (APSO) algorithm dynamically adjusts particle velocities and inertia to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "72de5b7e-8993-4555-a3c2-d23dc3418c2d", "metadata": {"aucs": [0.7360051051708216, 0.7360051051708216, 0.7360051051708216, 0.18645685806465528, 0.18645685806465528, 0.18645685806465528, 0.7713921523870435, 0.7713921523870435, 0.7713921523870435, 0.550031578914033, 0.550031578914033, 0.550031578914033, 0.5500055242283628, 0.5500055242283628, 0.5500055242283628, 0.6032875954746266, 0.6032875954746266, 0.6032875954746266, 0.16128428344542667, 0.16128428344542667, 0.16128428344542667, 0.15554574782388375, 0.15554574782388375, 0.15554574782388375, 0.1411369750681586, 0.1411369750681586, 0.1411369750681586, 0.13534350689186736, 0.13534350689186736, 0.13534350689186736, 0.1424206231688766, 0.1424206231688766, 0.1424206231688766, 0.11667754209145897, 0.11667754209145897, 0.11667754209145897, 0.9886292780367639, 0.9886292780367639, 0.9886292780367639, 0.9887925581561708, 0.9887925581561708, 0.9887925581561708, 0.9885421486121282, 0.9885421486121282, 0.9885421486121282, 0.635611251394016, 0.635611251394016, 0.635611251394016, 0.19980882661796473, 0.19980882661796473, 0.19980882661796473, 0.6237603166707808, 0.6237603166707808, 0.6237603166707808, 0.21547027627083892, 0.21547027627083892, 0.21547027627083892, 0.3182781263041514, 0.3182781263041514, 0.3182781263041514, 0.22065311071522686, 0.22065311071522686, 0.22065311071522686, 0.19969481429101532, 0.19969481429101532, 0.19969481429101532, 0.18759222512419782, 0.18759222512419782, 0.18759222512419782, 0.3034142248365673, 0.3034142248365673, 0.3034142248365673, 0.17710468078518427, 0.17710468078518427, 0.17710468078518427, 0.2085214181547973, 0.2085214181547973, 0.2085214181547973, 0.22421920664958628, 0.22421920664958628, 0.22421920664958628, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09285956004593077, 0.09285956004593077, 0.09285956004593077, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05813384306994651, 0.05813384306994651, 0.05813384306994651, 0.025090263255342138, 0.025090263255342138, 0.025090263255342138, 0.03570461986651785, 0.03570461986651785, 0.03570461986651785, 0.04037714421043381, 0.04037714421043381, 0.04037714421043381, 0.10532559587605939, 0.10532559587605939, 0.10532559587605939, 0.07875350717208418, 0.07875350717208418, 0.07875350717208418, 0.03390465931808029, 0.03390465931808029, 0.03390465931808029, 0.12802969935465336, 0.12802969935465336, 0.12802969935465336, 0.05513371740931794, 0.05513371740931794, 0.05513371740931794, 0.4939408292640395, 0.4939408292640395, 0.4939408292640395, 0.4685885375052731, 0.4685885375052731, 0.4685885375052731, 0.521814708822842, 0.521814708822842, 0.521814708822842, 0.10850915839109132, 0.10850915839109132, 0.10850915839109132, 0.1434957805577265, 0.1434957805577265, 0.1434957805577265, 0.12444479398567765, 0.12444479398567765, 0.12444479398567765, 0.19682788175846577, 0.19682788175846577, 0.19682788175846577, 0.15154394345854305, 0.15154394345854305, 0.15154394345854305, 0.2011976429451129, 0.2011976429451129, 0.2011976429451129, 0.35818352429604094, 0.35818352429604094, 0.35818352429604094, 0.31896043741863567, 0.31896043741863567, 0.31896043741863567, 0.26914436839468714, 0.26914436839468714, 0.26914436839468714, 0.3198923395060509, 0.3198923395060509, 0.3198923395060509, 0.1816934326005496, 0.1816934326005496, 0.1816934326005496, 0.14825817013523934, 0.14825817013523934, 0.14825817013523934, 0.19990874786405366, 0.19990874786405366, 0.19990874786405366, 0.19553590903458618, 0.19553590903458618, 0.19553590903458618, 0.18797459843108422, 0.18797459843108422, 0.18797459843108422, 0.20014934637304216, 0.20014934637304216, 0.20014934637304216, 0.19865486024107004, 0.19865486024107004, 0.19865486024107004, 0.19007383648880005, 0.19007383648880005, 0.19007383648880005, 0.7812316845624572, 0.7812316845624572, 0.7812316845624572, 0.1548246042432918, 0.1548246042432918, 0.1548246042432918, 0.17728680087073156, 0.17728680087073156, 0.17728680087073156, 0.16648479425097773, 0.16648479425097773, 0.16648479425097773, 0.20366033522394045, 0.20366033522394045, 0.20366033522394045, 0.15424093668480232, 0.15424093668480232, 0.15424093668480232, 0.21600064521487083, 0.21600064521487083, 0.21600064521487083, 0.1994012581688811, 0.1994012581688811, 0.1994012581688811, 0.1788673361931571, 0.1788673361931571, 0.1788673361931571, 0.12657584329867044, 0.12657584329867044, 0.12657584329867044, 0.09016664277771413, 0.09016664277771413, 0.09016664277771413, 0.13783154914067508, 0.13783154914067508, 0.13783154914067508]}, "mutation_prompt": null}
{"id": "ccd17dbb-1092-4da8-af1e-c610d344e0d3", "solution": "import numpy as np\n\nclass APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(50, 10 * dim)  # Dynamic population size\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.w = 0.9  # Inertia weight\n        self.decay_rate = 0.99  # Inertia decay rate\n    \n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "APSO", "description": "The Adaptive Particle Swarm Optimization (APSO) algorithm dynamically adjusts particle velocities and inertia to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "72de5b7e-8993-4555-a3c2-d23dc3418c2d", "metadata": {"aucs": [0.7360051051708216, 0.7360051051708216, 0.7360051051708216, 0.18645685806465528, 0.18645685806465528, 0.18645685806465528, 0.7713921523870435, 0.7713921523870435, 0.7713921523870435, 0.550031578914033, 0.550031578914033, 0.550031578914033, 0.5500055242283628, 0.5500055242283628, 0.5500055242283628, 0.6032875954746266, 0.6032875954746266, 0.6032875954746266, 0.16128428344542667, 0.16128428344542667, 0.16128428344542667, 0.15554574782388375, 0.15554574782388375, 0.15554574782388375, 0.1411369750681586, 0.1411369750681586, 0.1411369750681586, 0.13534350689186736, 0.13534350689186736, 0.13534350689186736, 0.1424206231688766, 0.1424206231688766, 0.1424206231688766, 0.11667754209145897, 0.11667754209145897, 0.11667754209145897, 0.9886292780367639, 0.9886292780367639, 0.9886292780367639, 0.9887925581561708, 0.9887925581561708, 0.9887925581561708, 0.9885421486121282, 0.9885421486121282, 0.9885421486121282, 0.635611251394016, 0.635611251394016, 0.635611251394016, 0.19980882661796473, 0.19980882661796473, 0.19980882661796473, 0.6237603166707808, 0.6237603166707808, 0.6237603166707808, 0.21547027627083892, 0.21547027627083892, 0.21547027627083892, 0.3182781263041514, 0.3182781263041514, 0.3182781263041514, 0.22065311071522686, 0.22065311071522686, 0.22065311071522686, 0.19969481429101532, 0.19969481429101532, 0.19969481429101532, 0.18759222512419782, 0.18759222512419782, 0.18759222512419782, 0.3034142248365673, 0.3034142248365673, 0.3034142248365673, 0.17710468078518427, 0.17710468078518427, 0.17710468078518427, 0.2085214181547973, 0.2085214181547973, 0.2085214181547973, 0.22421920664958628, 0.22421920664958628, 0.22421920664958628, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09285956004593077, 0.09285956004593077, 0.09285956004593077, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05813384306994651, 0.05813384306994651, 0.05813384306994651, 0.025090263255342138, 0.025090263255342138, 0.025090263255342138, 0.03570461986651785, 0.03570461986651785, 0.03570461986651785, 0.04037714421043381, 0.04037714421043381, 0.04037714421043381, 0.10532559587605939, 0.10532559587605939, 0.10532559587605939, 0.07875350717208418, 0.07875350717208418, 0.07875350717208418, 0.03390465931808029, 0.03390465931808029, 0.03390465931808029, 0.12802969935465336, 0.12802969935465336, 0.12802969935465336, 0.05513371740931794, 0.05513371740931794, 0.05513371740931794, 0.4939408292640395, 0.4939408292640395, 0.4939408292640395, 0.4685885375052731, 0.4685885375052731, 0.4685885375052731, 0.521814708822842, 0.521814708822842, 0.521814708822842, 0.10850915839109132, 0.10850915839109132, 0.10850915839109132, 0.1434957805577265, 0.1434957805577265, 0.1434957805577265, 0.12444479398567765, 0.12444479398567765, 0.12444479398567765, 0.19682788175846577, 0.19682788175846577, 0.19682788175846577, 0.15154394345854305, 0.15154394345854305, 0.15154394345854305, 0.2011976429451129, 0.2011976429451129, 0.2011976429451129, 0.35818352429604094, 0.35818352429604094, 0.35818352429604094, 0.31896043741863567, 0.31896043741863567, 0.31896043741863567, 0.26914436839468714, 0.26914436839468714, 0.26914436839468714, 0.3198923395060509, 0.3198923395060509, 0.3198923395060509, 0.1816934326005496, 0.1816934326005496, 0.1816934326005496, 0.14825817013523934, 0.14825817013523934, 0.14825817013523934, 0.19990874786405366, 0.19990874786405366, 0.19990874786405366, 0.19553590903458618, 0.19553590903458618, 0.19553590903458618, 0.18797459843108422, 0.18797459843108422, 0.18797459843108422, 0.20014934637304216, 0.20014934637304216, 0.20014934637304216, 0.19865486024107004, 0.19865486024107004, 0.19865486024107004, 0.19007383648880005, 0.19007383648880005, 0.19007383648880005, 0.7812316845624572, 0.7812316845624572, 0.7812316845624572, 0.1548246042432918, 0.1548246042432918, 0.1548246042432918, 0.17728680087073156, 0.17728680087073156, 0.17728680087073156, 0.16648479425097773, 0.16648479425097773, 0.16648479425097773, 0.20366033522394045, 0.20366033522394045, 0.20366033522394045, 0.15424093668480232, 0.15424093668480232, 0.15424093668480232, 0.21600064521487083, 0.21600064521487083, 0.21600064521487083, 0.1994012581688811, 0.1994012581688811, 0.1994012581688811, 0.1788673361931571, 0.1788673361931571, 0.1788673361931571, 0.12657584329867044, 0.12657584329867044, 0.12657584329867044, 0.09016664277771413, 0.09016664277771413, 0.09016664277771413, 0.13783154914067508, 0.13783154914067508, 0.13783154914067508]}, "mutation_prompt": null}
{"id": "26408d10-dfe3-4dd0-be19-6cbc1241067e", "solution": "import numpy as np\n\nclass APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(50, 10 * dim)  # Dynamic population size\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.w = 0.9  # Inertia weight\n        self.decay_rate = 0.99  # Inertia decay rate\n    \n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "APSO", "description": "The Adaptive Particle Swarm Optimization (APSO) algorithm dynamically adjusts particle velocities and inertia to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "72de5b7e-8993-4555-a3c2-d23dc3418c2d", "metadata": {"aucs": [0.7360051051708216, 0.7360051051708216, 0.7360051051708216, 0.18645685806465528, 0.18645685806465528, 0.18645685806465528, 0.7713921523870435, 0.7713921523870435, 0.7713921523870435, 0.550031578914033, 0.550031578914033, 0.550031578914033, 0.5500055242283628, 0.5500055242283628, 0.5500055242283628, 0.6032875954746266, 0.6032875954746266, 0.6032875954746266, 0.16128428344542667, 0.16128428344542667, 0.16128428344542667, 0.15554574782388375, 0.15554574782388375, 0.15554574782388375, 0.1411369750681586, 0.1411369750681586, 0.1411369750681586, 0.13534350689186736, 0.13534350689186736, 0.13534350689186736, 0.1424206231688766, 0.1424206231688766, 0.1424206231688766, 0.11667754209145897, 0.11667754209145897, 0.11667754209145897, 0.9886292780367639, 0.9886292780367639, 0.9886292780367639, 0.9887925581561708, 0.9887925581561708, 0.9887925581561708, 0.9885421486121282, 0.9885421486121282, 0.9885421486121282, 0.635611251394016, 0.635611251394016, 0.635611251394016, 0.19980882661796473, 0.19980882661796473, 0.19980882661796473, 0.6237603166707808, 0.6237603166707808, 0.6237603166707808, 0.21547027627083892, 0.21547027627083892, 0.21547027627083892, 0.3182781263041514, 0.3182781263041514, 0.3182781263041514, 0.22065311071522686, 0.22065311071522686, 0.22065311071522686, 0.19969481429101532, 0.19969481429101532, 0.19969481429101532, 0.18759222512419782, 0.18759222512419782, 0.18759222512419782, 0.3034142248365673, 0.3034142248365673, 0.3034142248365673, 0.17710468078518427, 0.17710468078518427, 0.17710468078518427, 0.2085214181547973, 0.2085214181547973, 0.2085214181547973, 0.22421920664958628, 0.22421920664958628, 0.22421920664958628, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09285956004593077, 0.09285956004593077, 0.09285956004593077, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05813384306994651, 0.05813384306994651, 0.05813384306994651, 0.025090263255342138, 0.025090263255342138, 0.025090263255342138, 0.03570461986651785, 0.03570461986651785, 0.03570461986651785, 0.04037714421043381, 0.04037714421043381, 0.04037714421043381, 0.10532559587605939, 0.10532559587605939, 0.10532559587605939, 0.07875350717208418, 0.07875350717208418, 0.07875350717208418, 0.03390465931808029, 0.03390465931808029, 0.03390465931808029, 0.12802969935465336, 0.12802969935465336, 0.12802969935465336, 0.05513371740931794, 0.05513371740931794, 0.05513371740931794, 0.4939408292640395, 0.4939408292640395, 0.4939408292640395, 0.4685885375052731, 0.4685885375052731, 0.4685885375052731, 0.521814708822842, 0.521814708822842, 0.521814708822842, 0.10850915839109132, 0.10850915839109132, 0.10850915839109132, 0.1434957805577265, 0.1434957805577265, 0.1434957805577265, 0.12444479398567765, 0.12444479398567765, 0.12444479398567765, 0.19682788175846577, 0.19682788175846577, 0.19682788175846577, 0.15154394345854305, 0.15154394345854305, 0.15154394345854305, 0.2011976429451129, 0.2011976429451129, 0.2011976429451129, 0.35818352429604094, 0.35818352429604094, 0.35818352429604094, 0.31896043741863567, 0.31896043741863567, 0.31896043741863567, 0.26914436839468714, 0.26914436839468714, 0.26914436839468714, 0.3198923395060509, 0.3198923395060509, 0.3198923395060509, 0.1816934326005496, 0.1816934326005496, 0.1816934326005496, 0.14825817013523934, 0.14825817013523934, 0.14825817013523934, 0.19990874786405366, 0.19990874786405366, 0.19990874786405366, 0.19553590903458618, 0.19553590903458618, 0.19553590903458618, 0.18797459843108422, 0.18797459843108422, 0.18797459843108422, 0.20014934637304216, 0.20014934637304216, 0.20014934637304216, 0.19865486024107004, 0.19865486024107004, 0.19865486024107004, 0.19007383648880005, 0.19007383648880005, 0.19007383648880005, 0.7812316845624572, 0.7812316845624572, 0.7812316845624572, 0.1548246042432918, 0.1548246042432918, 0.1548246042432918, 0.17728680087073156, 0.17728680087073156, 0.17728680087073156, 0.16648479425097773, 0.16648479425097773, 0.16648479425097773, 0.20366033522394045, 0.20366033522394045, 0.20366033522394045, 0.15424093668480232, 0.15424093668480232, 0.15424093668480232, 0.21600064521487083, 0.21600064521487083, 0.21600064521487083, 0.1994012581688811, 0.1994012581688811, 0.1994012581688811, 0.1788673361931571, 0.1788673361931571, 0.1788673361931571, 0.12657584329867044, 0.12657584329867044, 0.12657584329867044, 0.09016664277771413, 0.09016664277771413, 0.09016664277771413, 0.13783154914067508, 0.13783154914067508, 0.13783154914067508]}, "mutation_prompt": null}
{"id": "416ce9ef-a55d-4327-939b-ffd1219ac21c", "solution": "import numpy as np\n\nclass APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(50, 10 * dim)  # Dynamic population size\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.w = 0.9  # Inertia weight\n        self.decay_rate = 0.99  # Inertia decay rate\n    \n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "APSO", "description": "The Adaptive Particle Swarm Optimization (APSO) algorithm dynamically adjusts particle velocities and inertia to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "72de5b7e-8993-4555-a3c2-d23dc3418c2d", "metadata": {"aucs": [0.7360051051708216, 0.7360051051708216, 0.7360051051708216, 0.18645685806465528, 0.18645685806465528, 0.18645685806465528, 0.7713921523870435, 0.7713921523870435, 0.7713921523870435, 0.550031578914033, 0.550031578914033, 0.550031578914033, 0.5500055242283628, 0.5500055242283628, 0.5500055242283628, 0.6032875954746266, 0.6032875954746266, 0.6032875954746266, 0.16128428344542667, 0.16128428344542667, 0.16128428344542667, 0.15554574782388375, 0.15554574782388375, 0.15554574782388375, 0.1411369750681586, 0.1411369750681586, 0.1411369750681586, 0.13534350689186736, 0.13534350689186736, 0.13534350689186736, 0.1424206231688766, 0.1424206231688766, 0.1424206231688766, 0.11667754209145897, 0.11667754209145897, 0.11667754209145897, 0.9886292780367639, 0.9886292780367639, 0.9886292780367639, 0.9887925581561708, 0.9887925581561708, 0.9887925581561708, 0.9885421486121282, 0.9885421486121282, 0.9885421486121282, 0.635611251394016, 0.635611251394016, 0.635611251394016, 0.19980882661796473, 0.19980882661796473, 0.19980882661796473, 0.6237603166707808, 0.6237603166707808, 0.6237603166707808, 0.21547027627083892, 0.21547027627083892, 0.21547027627083892, 0.3182781263041514, 0.3182781263041514, 0.3182781263041514, 0.22065311071522686, 0.22065311071522686, 0.22065311071522686, 0.19969481429101532, 0.19969481429101532, 0.19969481429101532, 0.18759222512419782, 0.18759222512419782, 0.18759222512419782, 0.3034142248365673, 0.3034142248365673, 0.3034142248365673, 0.17710468078518427, 0.17710468078518427, 0.17710468078518427, 0.2085214181547973, 0.2085214181547973, 0.2085214181547973, 0.22421920664958628, 0.22421920664958628, 0.22421920664958628, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09285956004593077, 0.09285956004593077, 0.09285956004593077, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05813384306994651, 0.05813384306994651, 0.05813384306994651, 0.025090263255342138, 0.025090263255342138, 0.025090263255342138, 0.03570461986651785, 0.03570461986651785, 0.03570461986651785, 0.04037714421043381, 0.04037714421043381, 0.04037714421043381, 0.10532559587605939, 0.10532559587605939, 0.10532559587605939, 0.07875350717208418, 0.07875350717208418, 0.07875350717208418, 0.03390465931808029, 0.03390465931808029, 0.03390465931808029, 0.12802969935465336, 0.12802969935465336, 0.12802969935465336, 0.05513371740931794, 0.05513371740931794, 0.05513371740931794, 0.4939408292640395, 0.4939408292640395, 0.4939408292640395, 0.4685885375052731, 0.4685885375052731, 0.4685885375052731, 0.521814708822842, 0.521814708822842, 0.521814708822842, 0.10850915839109132, 0.10850915839109132, 0.10850915839109132, 0.1434957805577265, 0.1434957805577265, 0.1434957805577265, 0.12444479398567765, 0.12444479398567765, 0.12444479398567765, 0.19682788175846577, 0.19682788175846577, 0.19682788175846577, 0.15154394345854305, 0.15154394345854305, 0.15154394345854305, 0.2011976429451129, 0.2011976429451129, 0.2011976429451129, 0.35818352429604094, 0.35818352429604094, 0.35818352429604094, 0.31896043741863567, 0.31896043741863567, 0.31896043741863567, 0.26914436839468714, 0.26914436839468714, 0.26914436839468714, 0.3198923395060509, 0.3198923395060509, 0.3198923395060509, 0.1816934326005496, 0.1816934326005496, 0.1816934326005496, 0.14825817013523934, 0.14825817013523934, 0.14825817013523934, 0.19990874786405366, 0.19990874786405366, 0.19990874786405366, 0.19553590903458618, 0.19553590903458618, 0.19553590903458618, 0.18797459843108422, 0.18797459843108422, 0.18797459843108422, 0.20014934637304216, 0.20014934637304216, 0.20014934637304216, 0.19865486024107004, 0.19865486024107004, 0.19865486024107004, 0.19007383648880005, 0.19007383648880005, 0.19007383648880005, 0.7812316845624572, 0.7812316845624572, 0.7812316845624572, 0.1548246042432918, 0.1548246042432918, 0.1548246042432918, 0.17728680087073156, 0.17728680087073156, 0.17728680087073156, 0.16648479425097773, 0.16648479425097773, 0.16648479425097773, 0.20366033522394045, 0.20366033522394045, 0.20366033522394045, 0.15424093668480232, 0.15424093668480232, 0.15424093668480232, 0.21600064521487083, 0.21600064521487083, 0.21600064521487083, 0.1994012581688811, 0.1994012581688811, 0.1994012581688811, 0.1788673361931571, 0.1788673361931571, 0.1788673361931571, 0.12657584329867044, 0.12657584329867044, 0.12657584329867044, 0.09016664277771413, 0.09016664277771413, 0.09016664277771413, 0.13783154914067508, 0.13783154914067508, 0.13783154914067508]}, "mutation_prompt": null}
{"id": "7ab2ff0c-5d1e-4f3f-b32b-7a8e71597974", "solution": "import numpy as np\n\nclass APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(50, 10 * dim)  # Dynamic population size\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.w = 0.9  # Inertia weight\n        self.decay_rate = 0.99  # Inertia decay rate\n    \n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "APSO", "description": "The Adaptive Particle Swarm Optimization (APSO) algorithm dynamically adjusts particle velocities and inertia to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "72de5b7e-8993-4555-a3c2-d23dc3418c2d", "metadata": {"aucs": [0.7360051051708216, 0.7360051051708216, 0.7360051051708216, 0.18645685806465528, 0.18645685806465528, 0.18645685806465528, 0.7713921523870435, 0.7713921523870435, 0.7713921523870435, 0.550031578914033, 0.550031578914033, 0.550031578914033, 0.5500055242283628, 0.5500055242283628, 0.5500055242283628, 0.6032875954746266, 0.6032875954746266, 0.6032875954746266, 0.16128428344542667, 0.16128428344542667, 0.16128428344542667, 0.15554574782388375, 0.15554574782388375, 0.15554574782388375, 0.1411369750681586, 0.1411369750681586, 0.1411369750681586, 0.13534350689186736, 0.13534350689186736, 0.13534350689186736, 0.1424206231688766, 0.1424206231688766, 0.1424206231688766, 0.11667754209145897, 0.11667754209145897, 0.11667754209145897, 0.9886292780367639, 0.9886292780367639, 0.9886292780367639, 0.9887925581561708, 0.9887925581561708, 0.9887925581561708, 0.9885421486121282, 0.9885421486121282, 0.9885421486121282, 0.635611251394016, 0.635611251394016, 0.635611251394016, 0.19980882661796473, 0.19980882661796473, 0.19980882661796473, 0.6237603166707808, 0.6237603166707808, 0.6237603166707808, 0.21547027627083892, 0.21547027627083892, 0.21547027627083892, 0.3182781263041514, 0.3182781263041514, 0.3182781263041514, 0.22065311071522686, 0.22065311071522686, 0.22065311071522686, 0.19969481429101532, 0.19969481429101532, 0.19969481429101532, 0.18759222512419782, 0.18759222512419782, 0.18759222512419782, 0.3034142248365673, 0.3034142248365673, 0.3034142248365673, 0.17710468078518427, 0.17710468078518427, 0.17710468078518427, 0.2085214181547973, 0.2085214181547973, 0.2085214181547973, 0.22421920664958628, 0.22421920664958628, 0.22421920664958628, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09285956004593077, 0.09285956004593077, 0.09285956004593077, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05813384306994651, 0.05813384306994651, 0.05813384306994651, 0.025090263255342138, 0.025090263255342138, 0.025090263255342138, 0.03570461986651785, 0.03570461986651785, 0.03570461986651785, 0.04037714421043381, 0.04037714421043381, 0.04037714421043381, 0.10532559587605939, 0.10532559587605939, 0.10532559587605939, 0.07875350717208418, 0.07875350717208418, 0.07875350717208418, 0.03390465931808029, 0.03390465931808029, 0.03390465931808029, 0.12802969935465336, 0.12802969935465336, 0.12802969935465336, 0.05513371740931794, 0.05513371740931794, 0.05513371740931794, 0.4939408292640395, 0.4939408292640395, 0.4939408292640395, 0.4685885375052731, 0.4685885375052731, 0.4685885375052731, 0.521814708822842, 0.521814708822842, 0.521814708822842, 0.10850915839109132, 0.10850915839109132, 0.10850915839109132, 0.1434957805577265, 0.1434957805577265, 0.1434957805577265, 0.12444479398567765, 0.12444479398567765, 0.12444479398567765, 0.19682788175846577, 0.19682788175846577, 0.19682788175846577, 0.15154394345854305, 0.15154394345854305, 0.15154394345854305, 0.2011976429451129, 0.2011976429451129, 0.2011976429451129, 0.35818352429604094, 0.35818352429604094, 0.35818352429604094, 0.31896043741863567, 0.31896043741863567, 0.31896043741863567, 0.26914436839468714, 0.26914436839468714, 0.26914436839468714, 0.3198923395060509, 0.3198923395060509, 0.3198923395060509, 0.1816934326005496, 0.1816934326005496, 0.1816934326005496, 0.14825817013523934, 0.14825817013523934, 0.14825817013523934, 0.19990874786405366, 0.19990874786405366, 0.19990874786405366, 0.19553590903458618, 0.19553590903458618, 0.19553590903458618, 0.18797459843108422, 0.18797459843108422, 0.18797459843108422, 0.20014934637304216, 0.20014934637304216, 0.20014934637304216, 0.19865486024107004, 0.19865486024107004, 0.19865486024107004, 0.19007383648880005, 0.19007383648880005, 0.19007383648880005, 0.7812316845624572, 0.7812316845624572, 0.7812316845624572, 0.1548246042432918, 0.1548246042432918, 0.1548246042432918, 0.17728680087073156, 0.17728680087073156, 0.17728680087073156, 0.16648479425097773, 0.16648479425097773, 0.16648479425097773, 0.20366033522394045, 0.20366033522394045, 0.20366033522394045, 0.15424093668480232, 0.15424093668480232, 0.15424093668480232, 0.21600064521487083, 0.21600064521487083, 0.21600064521487083, 0.1994012581688811, 0.1994012581688811, 0.1994012581688811, 0.1788673361931571, 0.1788673361931571, 0.1788673361931571, 0.12657584329867044, 0.12657584329867044, 0.12657584329867044, 0.09016664277771413, 0.09016664277771413, 0.09016664277771413, 0.13783154914067508, 0.13783154914067508, 0.13783154914067508]}, "mutation_prompt": null}
{"id": "d6d895e3-d275-4063-9018-64a1013479e6", "solution": "import numpy as np\n\nclass APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(50, 10 * dim)  # Dynamic population size\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.w = 0.9  # Inertia weight\n        self.decay_rate = 0.99  # Inertia decay rate\n    \n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "APSO", "description": "The Adaptive Particle Swarm Optimization (APSO) algorithm dynamically adjusts particle velocities and inertia to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "72de5b7e-8993-4555-a3c2-d23dc3418c2d", "metadata": {"aucs": [0.7360051051708216, 0.7360051051708216, 0.7360051051708216, 0.18645685806465528, 0.18645685806465528, 0.18645685806465528, 0.7713921523870435, 0.7713921523870435, 0.7713921523870435, 0.550031578914033, 0.550031578914033, 0.550031578914033, 0.5500055242283628, 0.5500055242283628, 0.5500055242283628, 0.6032875954746266, 0.6032875954746266, 0.6032875954746266, 0.16128428344542667, 0.16128428344542667, 0.16128428344542667, 0.15554574782388375, 0.15554574782388375, 0.15554574782388375, 0.1411369750681586, 0.1411369750681586, 0.1411369750681586, 0.13534350689186736, 0.13534350689186736, 0.13534350689186736, 0.1424206231688766, 0.1424206231688766, 0.1424206231688766, 0.11667754209145897, 0.11667754209145897, 0.11667754209145897, 0.9886292780367639, 0.9886292780367639, 0.9886292780367639, 0.9887925581561708, 0.9887925581561708, 0.9887925581561708, 0.9885421486121282, 0.9885421486121282, 0.9885421486121282, 0.635611251394016, 0.635611251394016, 0.635611251394016, 0.19980882661796473, 0.19980882661796473, 0.19980882661796473, 0.6237603166707808, 0.6237603166707808, 0.6237603166707808, 0.21547027627083892, 0.21547027627083892, 0.21547027627083892, 0.3182781263041514, 0.3182781263041514, 0.3182781263041514, 0.22065311071522686, 0.22065311071522686, 0.22065311071522686, 0.19969481429101532, 0.19969481429101532, 0.19969481429101532, 0.18759222512419782, 0.18759222512419782, 0.18759222512419782, 0.3034142248365673, 0.3034142248365673, 0.3034142248365673, 0.17710468078518427, 0.17710468078518427, 0.17710468078518427, 0.2085214181547973, 0.2085214181547973, 0.2085214181547973, 0.22421920664958628, 0.22421920664958628, 0.22421920664958628, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09285956004593077, 0.09285956004593077, 0.09285956004593077, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05813384306994651, 0.05813384306994651, 0.05813384306994651, 0.025090263255342138, 0.025090263255342138, 0.025090263255342138, 0.03570461986651785, 0.03570461986651785, 0.03570461986651785, 0.04037714421043381, 0.04037714421043381, 0.04037714421043381, 0.10532559587605939, 0.10532559587605939, 0.10532559587605939, 0.07875350717208418, 0.07875350717208418, 0.07875350717208418, 0.03390465931808029, 0.03390465931808029, 0.03390465931808029, 0.12802969935465336, 0.12802969935465336, 0.12802969935465336, 0.05513371740931794, 0.05513371740931794, 0.05513371740931794, 0.4939408292640395, 0.4939408292640395, 0.4939408292640395, 0.4685885375052731, 0.4685885375052731, 0.4685885375052731, 0.521814708822842, 0.521814708822842, 0.521814708822842, 0.10850915839109132, 0.10850915839109132, 0.10850915839109132, 0.1434957805577265, 0.1434957805577265, 0.1434957805577265, 0.12444479398567765, 0.12444479398567765, 0.12444479398567765, 0.19682788175846577, 0.19682788175846577, 0.19682788175846577, 0.15154394345854305, 0.15154394345854305, 0.15154394345854305, 0.2011976429451129, 0.2011976429451129, 0.2011976429451129, 0.35818352429604094, 0.35818352429604094, 0.35818352429604094, 0.31896043741863567, 0.31896043741863567, 0.31896043741863567, 0.26914436839468714, 0.26914436839468714, 0.26914436839468714, 0.3198923395060509, 0.3198923395060509, 0.3198923395060509, 0.1816934326005496, 0.1816934326005496, 0.1816934326005496, 0.14825817013523934, 0.14825817013523934, 0.14825817013523934, 0.19990874786405366, 0.19990874786405366, 0.19990874786405366, 0.19553590903458618, 0.19553590903458618, 0.19553590903458618, 0.18797459843108422, 0.18797459843108422, 0.18797459843108422, 0.20014934637304216, 0.20014934637304216, 0.20014934637304216, 0.19865486024107004, 0.19865486024107004, 0.19865486024107004, 0.19007383648880005, 0.19007383648880005, 0.19007383648880005, 0.7812316845624572, 0.7812316845624572, 0.7812316845624572, 0.1548246042432918, 0.1548246042432918, 0.1548246042432918, 0.17728680087073156, 0.17728680087073156, 0.17728680087073156, 0.16648479425097773, 0.16648479425097773, 0.16648479425097773, 0.20366033522394045, 0.20366033522394045, 0.20366033522394045, 0.15424093668480232, 0.15424093668480232, 0.15424093668480232, 0.21600064521487083, 0.21600064521487083, 0.21600064521487083, 0.1994012581688811, 0.1994012581688811, 0.1994012581688811, 0.1788673361931571, 0.1788673361931571, 0.1788673361931571, 0.12657584329867044, 0.12657584329867044, 0.12657584329867044, 0.09016664277771413, 0.09016664277771413, 0.09016664277771413, 0.13783154914067508, 0.13783154914067508, 0.13783154914067508]}, "mutation_prompt": null}
{"id": "86a29476-5e99-4bee-b51a-088f05111dda", "solution": "import numpy as np\n\nclass APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(50, 10 * dim)  # Dynamic population size\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.w = 0.9  # Inertia weight\n        self.decay_rate = 0.99  # Inertia decay rate\n    \n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "APSO", "description": "The Adaptive Particle Swarm Optimization (APSO) algorithm dynamically adjusts particle velocities and inertia to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "72de5b7e-8993-4555-a3c2-d23dc3418c2d", "metadata": {"aucs": [0.7360051051708216, 0.7360051051708216, 0.7360051051708216, 0.18645685806465528, 0.18645685806465528, 0.18645685806465528, 0.7713921523870435, 0.7713921523870435, 0.7713921523870435, 0.550031578914033, 0.550031578914033, 0.550031578914033, 0.5500055242283628, 0.5500055242283628, 0.5500055242283628, 0.6032875954746266, 0.6032875954746266, 0.6032875954746266, 0.16128428344542667, 0.16128428344542667, 0.16128428344542667, 0.15554574782388375, 0.15554574782388375, 0.15554574782388375, 0.1411369750681586, 0.1411369750681586, 0.1411369750681586, 0.13534350689186736, 0.13534350689186736, 0.13534350689186736, 0.1424206231688766, 0.1424206231688766, 0.1424206231688766, 0.11667754209145897, 0.11667754209145897, 0.11667754209145897, 0.9886292780367639, 0.9886292780367639, 0.9886292780367639, 0.9887925581561708, 0.9887925581561708, 0.9887925581561708, 0.9885421486121282, 0.9885421486121282, 0.9885421486121282, 0.635611251394016, 0.635611251394016, 0.635611251394016, 0.19980882661796473, 0.19980882661796473, 0.19980882661796473, 0.6237603166707808, 0.6237603166707808, 0.6237603166707808, 0.21547027627083892, 0.21547027627083892, 0.21547027627083892, 0.3182781263041514, 0.3182781263041514, 0.3182781263041514, 0.22065311071522686, 0.22065311071522686, 0.22065311071522686, 0.19969481429101532, 0.19969481429101532, 0.19969481429101532, 0.18759222512419782, 0.18759222512419782, 0.18759222512419782, 0.3034142248365673, 0.3034142248365673, 0.3034142248365673, 0.17710468078518427, 0.17710468078518427, 0.17710468078518427, 0.2085214181547973, 0.2085214181547973, 0.2085214181547973, 0.22421920664958628, 0.22421920664958628, 0.22421920664958628, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09285956004593077, 0.09285956004593077, 0.09285956004593077, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05813384306994651, 0.05813384306994651, 0.05813384306994651, 0.025090263255342138, 0.025090263255342138, 0.025090263255342138, 0.03570461986651785, 0.03570461986651785, 0.03570461986651785, 0.04037714421043381, 0.04037714421043381, 0.04037714421043381, 0.10532559587605939, 0.10532559587605939, 0.10532559587605939, 0.07875350717208418, 0.07875350717208418, 0.07875350717208418, 0.03390465931808029, 0.03390465931808029, 0.03390465931808029, 0.12802969935465336, 0.12802969935465336, 0.12802969935465336, 0.05513371740931794, 0.05513371740931794, 0.05513371740931794, 0.4939408292640395, 0.4939408292640395, 0.4939408292640395, 0.4685885375052731, 0.4685885375052731, 0.4685885375052731, 0.521814708822842, 0.521814708822842, 0.521814708822842, 0.10850915839109132, 0.10850915839109132, 0.10850915839109132, 0.1434957805577265, 0.1434957805577265, 0.1434957805577265, 0.12444479398567765, 0.12444479398567765, 0.12444479398567765, 0.19682788175846577, 0.19682788175846577, 0.19682788175846577, 0.15154394345854305, 0.15154394345854305, 0.15154394345854305, 0.2011976429451129, 0.2011976429451129, 0.2011976429451129, 0.35818352429604094, 0.35818352429604094, 0.35818352429604094, 0.31896043741863567, 0.31896043741863567, 0.31896043741863567, 0.26914436839468714, 0.26914436839468714, 0.26914436839468714, 0.3198923395060509, 0.3198923395060509, 0.3198923395060509, 0.1816934326005496, 0.1816934326005496, 0.1816934326005496, 0.14825817013523934, 0.14825817013523934, 0.14825817013523934, 0.19990874786405366, 0.19990874786405366, 0.19990874786405366, 0.19553590903458618, 0.19553590903458618, 0.19553590903458618, 0.18797459843108422, 0.18797459843108422, 0.18797459843108422, 0.20014934637304216, 0.20014934637304216, 0.20014934637304216, 0.19865486024107004, 0.19865486024107004, 0.19865486024107004, 0.19007383648880005, 0.19007383648880005, 0.19007383648880005, 0.7812316845624572, 0.7812316845624572, 0.7812316845624572, 0.1548246042432918, 0.1548246042432918, 0.1548246042432918, 0.17728680087073156, 0.17728680087073156, 0.17728680087073156, 0.16648479425097773, 0.16648479425097773, 0.16648479425097773, 0.20366033522394045, 0.20366033522394045, 0.20366033522394045, 0.15424093668480232, 0.15424093668480232, 0.15424093668480232, 0.21600064521487083, 0.21600064521487083, 0.21600064521487083, 0.1994012581688811, 0.1994012581688811, 0.1994012581688811, 0.1788673361931571, 0.1788673361931571, 0.1788673361931571, 0.12657584329867044, 0.12657584329867044, 0.12657584329867044, 0.09016664277771413, 0.09016664277771413, 0.09016664277771413, 0.13783154914067508, 0.13783154914067508, 0.13783154914067508]}, "mutation_prompt": null}
{"id": "3c78a6ee-80d6-47ff-89b7-302d7f093822", "solution": "import numpy as np\n\nclass APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(50, 10 * dim)  # Dynamic population size\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.w = 0.9  # Inertia weight\n        self.decay_rate = 0.99  # Inertia decay rate\n    \n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "APSO", "description": "The Adaptive Particle Swarm Optimization (APSO) algorithm dynamically adjusts particle velocities and inertia to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "72de5b7e-8993-4555-a3c2-d23dc3418c2d", "metadata": {"aucs": [0.7360051051708216, 0.7360051051708216, 0.7360051051708216, 0.18645685806465528, 0.18645685806465528, 0.18645685806465528, 0.7713921523870435, 0.7713921523870435, 0.7713921523870435, 0.550031578914033, 0.550031578914033, 0.550031578914033, 0.5500055242283628, 0.5500055242283628, 0.5500055242283628, 0.6032875954746266, 0.6032875954746266, 0.6032875954746266, 0.16128428344542667, 0.16128428344542667, 0.16128428344542667, 0.15554574782388375, 0.15554574782388375, 0.15554574782388375, 0.1411369750681586, 0.1411369750681586, 0.1411369750681586, 0.13534350689186736, 0.13534350689186736, 0.13534350689186736, 0.1424206231688766, 0.1424206231688766, 0.1424206231688766, 0.11667754209145897, 0.11667754209145897, 0.11667754209145897, 0.9886292780367639, 0.9886292780367639, 0.9886292780367639, 0.9887925581561708, 0.9887925581561708, 0.9887925581561708, 0.9885421486121282, 0.9885421486121282, 0.9885421486121282, 0.635611251394016, 0.635611251394016, 0.635611251394016, 0.19980882661796473, 0.19980882661796473, 0.19980882661796473, 0.6237603166707808, 0.6237603166707808, 0.6237603166707808, 0.21547027627083892, 0.21547027627083892, 0.21547027627083892, 0.3182781263041514, 0.3182781263041514, 0.3182781263041514, 0.22065311071522686, 0.22065311071522686, 0.22065311071522686, 0.19969481429101532, 0.19969481429101532, 0.19969481429101532, 0.18759222512419782, 0.18759222512419782, 0.18759222512419782, 0.3034142248365673, 0.3034142248365673, 0.3034142248365673, 0.17710468078518427, 0.17710468078518427, 0.17710468078518427, 0.2085214181547973, 0.2085214181547973, 0.2085214181547973, 0.22421920664958628, 0.22421920664958628, 0.22421920664958628, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09285956004593077, 0.09285956004593077, 0.09285956004593077, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05813384306994651, 0.05813384306994651, 0.05813384306994651, 0.025090263255342138, 0.025090263255342138, 0.025090263255342138, 0.03570461986651785, 0.03570461986651785, 0.03570461986651785, 0.04037714421043381, 0.04037714421043381, 0.04037714421043381, 0.10532559587605939, 0.10532559587605939, 0.10532559587605939, 0.07875350717208418, 0.07875350717208418, 0.07875350717208418, 0.03390465931808029, 0.03390465931808029, 0.03390465931808029, 0.12802969935465336, 0.12802969935465336, 0.12802969935465336, 0.05513371740931794, 0.05513371740931794, 0.05513371740931794, 0.4939408292640395, 0.4939408292640395, 0.4939408292640395, 0.4685885375052731, 0.4685885375052731, 0.4685885375052731, 0.521814708822842, 0.521814708822842, 0.521814708822842, 0.10850915839109132, 0.10850915839109132, 0.10850915839109132, 0.1434957805577265, 0.1434957805577265, 0.1434957805577265, 0.12444479398567765, 0.12444479398567765, 0.12444479398567765, 0.19682788175846577, 0.19682788175846577, 0.19682788175846577, 0.15154394345854305, 0.15154394345854305, 0.15154394345854305, 0.2011976429451129, 0.2011976429451129, 0.2011976429451129, 0.35818352429604094, 0.35818352429604094, 0.35818352429604094, 0.31896043741863567, 0.31896043741863567, 0.31896043741863567, 0.26914436839468714, 0.26914436839468714, 0.26914436839468714, 0.3198923395060509, 0.3198923395060509, 0.3198923395060509, 0.1816934326005496, 0.1816934326005496, 0.1816934326005496, 0.14825817013523934, 0.14825817013523934, 0.14825817013523934, 0.19990874786405366, 0.19990874786405366, 0.19990874786405366, 0.19553590903458618, 0.19553590903458618, 0.19553590903458618, 0.18797459843108422, 0.18797459843108422, 0.18797459843108422, 0.20014934637304216, 0.20014934637304216, 0.20014934637304216, 0.19865486024107004, 0.19865486024107004, 0.19865486024107004, 0.19007383648880005, 0.19007383648880005, 0.19007383648880005, 0.7812316845624572, 0.7812316845624572, 0.7812316845624572, 0.1548246042432918, 0.1548246042432918, 0.1548246042432918, 0.17728680087073156, 0.17728680087073156, 0.17728680087073156, 0.16648479425097773, 0.16648479425097773, 0.16648479425097773, 0.20366033522394045, 0.20366033522394045, 0.20366033522394045, 0.15424093668480232, 0.15424093668480232, 0.15424093668480232, 0.21600064521487083, 0.21600064521487083, 0.21600064521487083, 0.1994012581688811, 0.1994012581688811, 0.1994012581688811, 0.1788673361931571, 0.1788673361931571, 0.1788673361931571, 0.12657584329867044, 0.12657584329867044, 0.12657584329867044, 0.09016664277771413, 0.09016664277771413, 0.09016664277771413, 0.13783154914067508, 0.13783154914067508, 0.13783154914067508]}, "mutation_prompt": null}
{"id": "daf0de26-c0ca-4f4a-be08-01d44817e0f5", "solution": "import numpy as np\n\nclass APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(50, 10 * dim)  # Dynamic population size\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.w = 0.9  # Inertia weight\n        self.decay_rate = 0.99  # Inertia decay rate\n    \n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "APSO", "description": "The Adaptive Particle Swarm Optimization (APSO) algorithm dynamically adjusts particle velocities and inertia to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "72de5b7e-8993-4555-a3c2-d23dc3418c2d", "metadata": {"aucs": [0.7360051051708216, 0.7360051051708216, 0.7360051051708216, 0.18645685806465528, 0.18645685806465528, 0.18645685806465528, 0.7713921523870435, 0.7713921523870435, 0.7713921523870435, 0.550031578914033, 0.550031578914033, 0.550031578914033, 0.5500055242283628, 0.5500055242283628, 0.5500055242283628, 0.6032875954746266, 0.6032875954746266, 0.6032875954746266, 0.16128428344542667, 0.16128428344542667, 0.16128428344542667, 0.15554574782388375, 0.15554574782388375, 0.15554574782388375, 0.1411369750681586, 0.1411369750681586, 0.1411369750681586, 0.13534350689186736, 0.13534350689186736, 0.13534350689186736, 0.1424206231688766, 0.1424206231688766, 0.1424206231688766, 0.11667754209145897, 0.11667754209145897, 0.11667754209145897, 0.9886292780367639, 0.9886292780367639, 0.9886292780367639, 0.9887925581561708, 0.9887925581561708, 0.9887925581561708, 0.9885421486121282, 0.9885421486121282, 0.9885421486121282, 0.635611251394016, 0.635611251394016, 0.635611251394016, 0.19980882661796473, 0.19980882661796473, 0.19980882661796473, 0.6237603166707808, 0.6237603166707808, 0.6237603166707808, 0.21547027627083892, 0.21547027627083892, 0.21547027627083892, 0.3182781263041514, 0.3182781263041514, 0.3182781263041514, 0.22065311071522686, 0.22065311071522686, 0.22065311071522686, 0.19969481429101532, 0.19969481429101532, 0.19969481429101532, 0.18759222512419782, 0.18759222512419782, 0.18759222512419782, 0.3034142248365673, 0.3034142248365673, 0.3034142248365673, 0.17710468078518427, 0.17710468078518427, 0.17710468078518427, 0.2085214181547973, 0.2085214181547973, 0.2085214181547973, 0.22421920664958628, 0.22421920664958628, 0.22421920664958628, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09285956004593077, 0.09285956004593077, 0.09285956004593077, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05813384306994651, 0.05813384306994651, 0.05813384306994651, 0.025090263255342138, 0.025090263255342138, 0.025090263255342138, 0.03570461986651785, 0.03570461986651785, 0.03570461986651785, 0.04037714421043381, 0.04037714421043381, 0.04037714421043381, 0.10532559587605939, 0.10532559587605939, 0.10532559587605939, 0.07875350717208418, 0.07875350717208418, 0.07875350717208418, 0.03390465931808029, 0.03390465931808029, 0.03390465931808029, 0.12802969935465336, 0.12802969935465336, 0.12802969935465336, 0.05513371740931794, 0.05513371740931794, 0.05513371740931794, 0.4939408292640395, 0.4939408292640395, 0.4939408292640395, 0.4685885375052731, 0.4685885375052731, 0.4685885375052731, 0.521814708822842, 0.521814708822842, 0.521814708822842, 0.10850915839109132, 0.10850915839109132, 0.10850915839109132, 0.1434957805577265, 0.1434957805577265, 0.1434957805577265, 0.12444479398567765, 0.12444479398567765, 0.12444479398567765, 0.19682788175846577, 0.19682788175846577, 0.19682788175846577, 0.15154394345854305, 0.15154394345854305, 0.15154394345854305, 0.2011976429451129, 0.2011976429451129, 0.2011976429451129, 0.35818352429604094, 0.35818352429604094, 0.35818352429604094, 0.31896043741863567, 0.31896043741863567, 0.31896043741863567, 0.26914436839468714, 0.26914436839468714, 0.26914436839468714, 0.3198923395060509, 0.3198923395060509, 0.3198923395060509, 0.1816934326005496, 0.1816934326005496, 0.1816934326005496, 0.14825817013523934, 0.14825817013523934, 0.14825817013523934, 0.19990874786405366, 0.19990874786405366, 0.19990874786405366, 0.19553590903458618, 0.19553590903458618, 0.19553590903458618, 0.18797459843108422, 0.18797459843108422, 0.18797459843108422, 0.20014934637304216, 0.20014934637304216, 0.20014934637304216, 0.19865486024107004, 0.19865486024107004, 0.19865486024107004, 0.19007383648880005, 0.19007383648880005, 0.19007383648880005, 0.7812316845624572, 0.7812316845624572, 0.7812316845624572, 0.1548246042432918, 0.1548246042432918, 0.1548246042432918, 0.17728680087073156, 0.17728680087073156, 0.17728680087073156, 0.16648479425097773, 0.16648479425097773, 0.16648479425097773, 0.20366033522394045, 0.20366033522394045, 0.20366033522394045, 0.15424093668480232, 0.15424093668480232, 0.15424093668480232, 0.21600064521487083, 0.21600064521487083, 0.21600064521487083, 0.1994012581688811, 0.1994012581688811, 0.1994012581688811, 0.1788673361931571, 0.1788673361931571, 0.1788673361931571, 0.12657584329867044, 0.12657584329867044, 0.12657584329867044, 0.09016664277771413, 0.09016664277771413, 0.09016664277771413, 0.13783154914067508, 0.13783154914067508, 0.13783154914067508]}, "mutation_prompt": null}
{"id": "efd62c53-8209-428f-b7ab-70f60cb32186", "solution": "import numpy as np\n\nclass APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(50, 12 * dim)  # Slightly larger dynamic population size\n        self.c1 = 1.7  # Increased cognitive component\n        self.c2 = 1.7  # Increased social component\n        self.w = 0.8  # Reduced initial inertia weight for faster convergence\n        self.decay_rate = 0.96  # Faster inertia decay rate\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.05  # Added velocity limit\n    \n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)  # Limit velocity\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "APSO", "description": "Enhanced APSO with adaptive velocity limits and inertia weight adjustment to improve convergence speed.", "configspace": "", "generation": 10, "fitness": 0.3271043143305126, "feedback": "The algorithm APSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.29.", "error": "", "parent_id": "72de5b7e-8993-4555-a3c2-d23dc3418c2d", "metadata": {"aucs": [0.9026872546202871, 0.9026872546202871, 0.9026872546202871, 0.8929590282525381, 0.8929590282525381, 0.8929590282525381, 0.9026832744111498, 0.9026832744111498, 0.9026832744111498, 0.8060553440347592, 0.8060553440347592, 0.8060553440347592, 0.8184025817238518, 0.8184025817238518, 0.8184025817238518, 0.8127430872902957, 0.8127430872902957, 0.8127430872902957, 0.18361135858705824, 0.18361135858705824, 0.18361135858705824, 0.12111447759365401, 0.12111447759365401, 0.12111447759365401, 0.16130138275372496, 0.16130138275372496, 0.16130138275372496, 0.07422109649773867, 0.07422109649773867, 0.07422109649773867, 0.09053284216160151, 0.09053284216160151, 0.09053284216160151, 0.0860523672023924, 0.0860523672023924, 0.0860523672023924, 0.8984246247611002, 0.8984246247611002, 0.8984246247611002, 0.8835262563797867, 0.8835262563797867, 0.8835262563797867, 0.9002674408566516, 0.9002674408566516, 0.9002674408566516, 0.7714650506718093, 0.7714650506718093, 0.7714650506718093, 0.5421755508811371, 0.5421755508811371, 0.5421755508811371, 0.6854265262260381, 0.6854265262260381, 0.6854265262260381, 0.16933975798371792, 0.16933975798371792, 0.16933975798371792, 0.21295822894571914, 0.21295822894571914, 0.21295822894571914, 0.21916585657770238, 0.21916585657770238, 0.21916585657770238, 0.12819236269809187, 0.12819236269809187, 0.12819236269809187, 0.2057064172338291, 0.2057064172338291, 0.2057064172338291, 0.19636348759427458, 0.19636348759427458, 0.19636348759427458, 0.13326009035516784, 0.13326009035516784, 0.13326009035516784, 0.2401023900231598, 0.2401023900231598, 0.2401023900231598, 0.2621225807046119, 0.2621225807046119, 0.2621225807046119, 0.03323729008288301, 0.03323729008288301, 0.03323729008288301, 0.051222783533298566, 0.051222783533298566, 0.051222783533298566, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09756881240794679, 0.09756881240794679, 0.09756881240794679, 0.046240075974902206, 0.046240075974902206, 0.046240075974902206, 0.09785390211468037, 0.09785390211468037, 0.09785390211468037, 0.05012531110930396, 0.05012531110930396, 0.05012531110930396, 0.1355220378384936, 0.1355220378384936, 0.1355220378384936, 0.10025298189529697, 0.10025298189529697, 0.10025298189529697, 0.4433463008801527, 0.4433463008801527, 0.4433463008801527, 0.06255697548105277, 0.06255697548105277, 0.06255697548105277, 0.17668307615484213, 0.17668307615484213, 0.17668307615484213, 0.5509111272935963, 0.5509111272935963, 0.5509111272935963, 0.5535115389080278, 0.5535115389080278, 0.5535115389080278, 0.5955666587006804, 0.5955666587006804, 0.5955666587006804, 0.10319517163915337, 0.10319517163915337, 0.10319517163915337, 0.07381451816322493, 0.07381451816322493, 0.07381451816322493, 0.12304109567285593, 0.12304109567285593, 0.12304109567285593, 0.18053341310645488, 0.18053341310645488, 0.18053341310645488, 0.22426156957097987, 0.22426156957097987, 0.22426156957097987, 0.19887152713788359, 0.19887152713788359, 0.19887152713788359, 0.3079142534973748, 0.3079142534973748, 0.3079142534973748, 0.5010011725569159, 0.5010011725569159, 0.5010011725569159, 0.28625663065247986, 0.28625663065247986, 0.28625663065247986, 0.21129464882528537, 0.21129464882528537, 0.21129464882528537, 0.20139417002799165, 0.20139417002799165, 0.20139417002799165, 0.34379582619458915, 0.34379582619458915, 0.34379582619458915, 0.26066310774222634, 0.26066310774222634, 0.26066310774222634, 0.2258827149017849, 0.2258827149017849, 0.2258827149017849, 0.2418289407246993, 0.2418289407246993, 0.2418289407246993, 0.19230058282451445, 0.19230058282451445, 0.19230058282451445, 0.17257581268676803, 0.17257581268676803, 0.17257581268676803, 0.2263598417895979, 0.2263598417895979, 0.2263598417895979, 0.9327383768332356, 0.9327383768332356, 0.9327383768332356, 0.1574311172546612, 0.1574311172546612, 0.1574311172546612, 0.9120504986135982, 0.9120504986135982, 0.9120504986135982, 0.15527014727040644, 0.15527014727040644, 0.15527014727040644, 0.21278318884129777, 0.21278318884129777, 0.21278318884129777, 0.8459655449492324, 0.8459655449492324, 0.8459655449492324, 0.22221971134511487, 0.22221971134511487, 0.22221971134511487, 0.18286201644155498, 0.18286201644155498, 0.18286201644155498, 0.22134460072207918, 0.22134460072207918, 0.22134460072207918, 0.11566203723510027, 0.11566203723510027, 0.11566203723510027, 0.0860601420060082, 0.0860601420060082, 0.0860601420060082, 0.13657866317283718, 0.13657866317283718, 0.13657866317283718]}, "mutation_prompt": null}
{"id": "e9ec0bc6-e7a1-4654-acc5-8c992f43cae1", "solution": "import numpy as np\n\nclass APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(50, 12 * dim)  # Slightly larger dynamic population size\n        self.c1 = 1.7  # Increased cognitive component\n        self.c2 = 1.7  # Increased social component\n        self.w = 0.8  # Reduced initial inertia weight for faster convergence\n        self.decay_rate = 0.96  # Faster inertia decay rate\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.05  # Added velocity limit\n    \n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)  # Limit velocity\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "APSO", "description": "Enhanced APSO with adaptive velocity limits and inertia weight adjustment to improve convergence speed.", "configspace": "", "generation": 11, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "efd62c53-8209-428f-b7ab-70f60cb32186", "metadata": {"aucs": [0.9026872546202871, 0.9026872546202871, 0.9026872546202871, 0.8929590282525381, 0.8929590282525381, 0.8929590282525381, 0.9026832744111498, 0.9026832744111498, 0.9026832744111498, 0.8060553440347592, 0.8060553440347592, 0.8060553440347592, 0.8184025817238518, 0.8184025817238518, 0.8184025817238518, 0.8127430872902957, 0.8127430872902957, 0.8127430872902957, 0.18361135858705824, 0.18361135858705824, 0.18361135858705824, 0.12111447759365401, 0.12111447759365401, 0.12111447759365401, 0.16130138275372496, 0.16130138275372496, 0.16130138275372496, 0.07422109649773867, 0.07422109649773867, 0.07422109649773867, 0.09053284216160151, 0.09053284216160151, 0.09053284216160151, 0.0860523672023924, 0.0860523672023924, 0.0860523672023924, 0.8984246247611002, 0.8984246247611002, 0.8984246247611002, 0.8835262563797867, 0.8835262563797867, 0.8835262563797867, 0.9002674408566516, 0.9002674408566516, 0.9002674408566516, 0.7714650506718093, 0.7714650506718093, 0.7714650506718093, 0.5421755508811371, 0.5421755508811371, 0.5421755508811371, 0.6854265262260381, 0.6854265262260381, 0.6854265262260381, 0.16933975798371792, 0.16933975798371792, 0.16933975798371792, 0.21295822894571914, 0.21295822894571914, 0.21295822894571914, 0.21916585657770238, 0.21916585657770238, 0.21916585657770238, 0.12819236269809187, 0.12819236269809187, 0.12819236269809187, 0.2057064172338291, 0.2057064172338291, 0.2057064172338291, 0.19636348759427458, 0.19636348759427458, 0.19636348759427458, 0.13326009035516784, 0.13326009035516784, 0.13326009035516784, 0.2401023900231598, 0.2401023900231598, 0.2401023900231598, 0.2621225807046119, 0.2621225807046119, 0.2621225807046119, 0.03323729008288301, 0.03323729008288301, 0.03323729008288301, 0.051222783533298566, 0.051222783533298566, 0.051222783533298566, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09756881240794679, 0.09756881240794679, 0.09756881240794679, 0.046240075974902206, 0.046240075974902206, 0.046240075974902206, 0.09785390211468037, 0.09785390211468037, 0.09785390211468037, 0.05012531110930396, 0.05012531110930396, 0.05012531110930396, 0.1355220378384936, 0.1355220378384936, 0.1355220378384936, 0.10025298189529697, 0.10025298189529697, 0.10025298189529697, 0.4433463008801527, 0.4433463008801527, 0.4433463008801527, 0.06255697548105277, 0.06255697548105277, 0.06255697548105277, 0.17668307615484213, 0.17668307615484213, 0.17668307615484213, 0.5509111272935963, 0.5509111272935963, 0.5509111272935963, 0.5535115389080278, 0.5535115389080278, 0.5535115389080278, 0.5955666587006804, 0.5955666587006804, 0.5955666587006804, 0.10319517163915337, 0.10319517163915337, 0.10319517163915337, 0.07381451816322493, 0.07381451816322493, 0.07381451816322493, 0.12304109567285593, 0.12304109567285593, 0.12304109567285593, 0.18053341310645488, 0.18053341310645488, 0.18053341310645488, 0.22426156957097987, 0.22426156957097987, 0.22426156957097987, 0.19887152713788359, 0.19887152713788359, 0.19887152713788359, 0.3079142534973748, 0.3079142534973748, 0.3079142534973748, 0.5010011725569159, 0.5010011725569159, 0.5010011725569159, 0.28625663065247986, 0.28625663065247986, 0.28625663065247986, 0.21129464882528537, 0.21129464882528537, 0.21129464882528537, 0.20139417002799165, 0.20139417002799165, 0.20139417002799165, 0.34379582619458915, 0.34379582619458915, 0.34379582619458915, 0.26066310774222634, 0.26066310774222634, 0.26066310774222634, 0.2258827149017849, 0.2258827149017849, 0.2258827149017849, 0.2418289407246993, 0.2418289407246993, 0.2418289407246993, 0.19230058282451445, 0.19230058282451445, 0.19230058282451445, 0.17257581268676803, 0.17257581268676803, 0.17257581268676803, 0.2263598417895979, 0.2263598417895979, 0.2263598417895979, 0.9327383768332356, 0.9327383768332356, 0.9327383768332356, 0.1574311172546612, 0.1574311172546612, 0.1574311172546612, 0.9120504986135982, 0.9120504986135982, 0.9120504986135982, 0.15527014727040644, 0.15527014727040644, 0.15527014727040644, 0.21278318884129777, 0.21278318884129777, 0.21278318884129777, 0.8459655449492324, 0.8459655449492324, 0.8459655449492324, 0.22221971134511487, 0.22221971134511487, 0.22221971134511487, 0.18286201644155498, 0.18286201644155498, 0.18286201644155498, 0.22134460072207918, 0.22134460072207918, 0.22134460072207918, 0.11566203723510027, 0.11566203723510027, 0.11566203723510027, 0.0860601420060082, 0.0860601420060082, 0.0860601420060082, 0.13657866317283718, 0.13657866317283718, 0.13657866317283718]}, "mutation_prompt": null}
{"id": "cbf47163-39d4-4946-8ba8-3c419bd6a07e", "solution": "import numpy as np\n\nclass APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(50, 12 * dim)  # Slightly larger dynamic population size\n        self.c1 = 1.7  # Increased cognitive component\n        self.c2 = 1.7  # Increased social component\n        self.w = 0.8  # Reduced initial inertia weight for faster convergence\n        self.decay_rate = 0.96  # Faster inertia decay rate\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.05  # Added velocity limit\n    \n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)  # Limit velocity\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "APSO", "description": "Enhanced APSO with adaptive velocity limits and inertia weight adjustment to improve convergence speed.", "configspace": "", "generation": 11, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "efd62c53-8209-428f-b7ab-70f60cb32186", "metadata": {"aucs": [0.9026872546202871, 0.9026872546202871, 0.9026872546202871, 0.8929590282525381, 0.8929590282525381, 0.8929590282525381, 0.9026832744111498, 0.9026832744111498, 0.9026832744111498, 0.8060553440347592, 0.8060553440347592, 0.8060553440347592, 0.8184025817238518, 0.8184025817238518, 0.8184025817238518, 0.8127430872902957, 0.8127430872902957, 0.8127430872902957, 0.18361135858705824, 0.18361135858705824, 0.18361135858705824, 0.12111447759365401, 0.12111447759365401, 0.12111447759365401, 0.16130138275372496, 0.16130138275372496, 0.16130138275372496, 0.07422109649773867, 0.07422109649773867, 0.07422109649773867, 0.09053284216160151, 0.09053284216160151, 0.09053284216160151, 0.0860523672023924, 0.0860523672023924, 0.0860523672023924, 0.8984246247611002, 0.8984246247611002, 0.8984246247611002, 0.8835262563797867, 0.8835262563797867, 0.8835262563797867, 0.9002674408566516, 0.9002674408566516, 0.9002674408566516, 0.7714650506718093, 0.7714650506718093, 0.7714650506718093, 0.5421755508811371, 0.5421755508811371, 0.5421755508811371, 0.6854265262260381, 0.6854265262260381, 0.6854265262260381, 0.16933975798371792, 0.16933975798371792, 0.16933975798371792, 0.21295822894571914, 0.21295822894571914, 0.21295822894571914, 0.21916585657770238, 0.21916585657770238, 0.21916585657770238, 0.12819236269809187, 0.12819236269809187, 0.12819236269809187, 0.2057064172338291, 0.2057064172338291, 0.2057064172338291, 0.19636348759427458, 0.19636348759427458, 0.19636348759427458, 0.13326009035516784, 0.13326009035516784, 0.13326009035516784, 0.2401023900231598, 0.2401023900231598, 0.2401023900231598, 0.2621225807046119, 0.2621225807046119, 0.2621225807046119, 0.03323729008288301, 0.03323729008288301, 0.03323729008288301, 0.051222783533298566, 0.051222783533298566, 0.051222783533298566, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09756881240794679, 0.09756881240794679, 0.09756881240794679, 0.046240075974902206, 0.046240075974902206, 0.046240075974902206, 0.09785390211468037, 0.09785390211468037, 0.09785390211468037, 0.05012531110930396, 0.05012531110930396, 0.05012531110930396, 0.1355220378384936, 0.1355220378384936, 0.1355220378384936, 0.10025298189529697, 0.10025298189529697, 0.10025298189529697, 0.4433463008801527, 0.4433463008801527, 0.4433463008801527, 0.06255697548105277, 0.06255697548105277, 0.06255697548105277, 0.17668307615484213, 0.17668307615484213, 0.17668307615484213, 0.5509111272935963, 0.5509111272935963, 0.5509111272935963, 0.5535115389080278, 0.5535115389080278, 0.5535115389080278, 0.5955666587006804, 0.5955666587006804, 0.5955666587006804, 0.10319517163915337, 0.10319517163915337, 0.10319517163915337, 0.07381451816322493, 0.07381451816322493, 0.07381451816322493, 0.12304109567285593, 0.12304109567285593, 0.12304109567285593, 0.18053341310645488, 0.18053341310645488, 0.18053341310645488, 0.22426156957097987, 0.22426156957097987, 0.22426156957097987, 0.19887152713788359, 0.19887152713788359, 0.19887152713788359, 0.3079142534973748, 0.3079142534973748, 0.3079142534973748, 0.5010011725569159, 0.5010011725569159, 0.5010011725569159, 0.28625663065247986, 0.28625663065247986, 0.28625663065247986, 0.21129464882528537, 0.21129464882528537, 0.21129464882528537, 0.20139417002799165, 0.20139417002799165, 0.20139417002799165, 0.34379582619458915, 0.34379582619458915, 0.34379582619458915, 0.26066310774222634, 0.26066310774222634, 0.26066310774222634, 0.2258827149017849, 0.2258827149017849, 0.2258827149017849, 0.2418289407246993, 0.2418289407246993, 0.2418289407246993, 0.19230058282451445, 0.19230058282451445, 0.19230058282451445, 0.17257581268676803, 0.17257581268676803, 0.17257581268676803, 0.2263598417895979, 0.2263598417895979, 0.2263598417895979, 0.9327383768332356, 0.9327383768332356, 0.9327383768332356, 0.1574311172546612, 0.1574311172546612, 0.1574311172546612, 0.9120504986135982, 0.9120504986135982, 0.9120504986135982, 0.15527014727040644, 0.15527014727040644, 0.15527014727040644, 0.21278318884129777, 0.21278318884129777, 0.21278318884129777, 0.8459655449492324, 0.8459655449492324, 0.8459655449492324, 0.22221971134511487, 0.22221971134511487, 0.22221971134511487, 0.18286201644155498, 0.18286201644155498, 0.18286201644155498, 0.22134460072207918, 0.22134460072207918, 0.22134460072207918, 0.11566203723510027, 0.11566203723510027, 0.11566203723510027, 0.0860601420060082, 0.0860601420060082, 0.0860601420060082, 0.13657866317283718, 0.13657866317283718, 0.13657866317283718]}, "mutation_prompt": null}
{"id": "0d022a5d-5c4d-4b8e-98e3-0a9cd3648934", "solution": "import numpy as np\n\nclass APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(50, 12 * dim)  # Slightly larger dynamic population size\n        self.c1 = 1.7  # Increased cognitive component\n        self.c2 = 1.7  # Increased social component\n        self.w = 0.8  # Reduced initial inertia weight for faster convergence\n        self.decay_rate = 0.96  # Faster inertia decay rate\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.05  # Added velocity limit\n    \n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)  # Limit velocity\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "APSO", "description": "Enhanced APSO with adaptive velocity limits and inertia weight adjustment to improve convergence speed.", "configspace": "", "generation": 11, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "efd62c53-8209-428f-b7ab-70f60cb32186", "metadata": {"aucs": [0.9026872546202871, 0.9026872546202871, 0.9026872546202871, 0.8929590282525381, 0.8929590282525381, 0.8929590282525381, 0.9026832744111498, 0.9026832744111498, 0.9026832744111498, 0.8060553440347592, 0.8060553440347592, 0.8060553440347592, 0.8184025817238518, 0.8184025817238518, 0.8184025817238518, 0.8127430872902957, 0.8127430872902957, 0.8127430872902957, 0.18361135858705824, 0.18361135858705824, 0.18361135858705824, 0.12111447759365401, 0.12111447759365401, 0.12111447759365401, 0.16130138275372496, 0.16130138275372496, 0.16130138275372496, 0.07422109649773867, 0.07422109649773867, 0.07422109649773867, 0.09053284216160151, 0.09053284216160151, 0.09053284216160151, 0.0860523672023924, 0.0860523672023924, 0.0860523672023924, 0.8984246247611002, 0.8984246247611002, 0.8984246247611002, 0.8835262563797867, 0.8835262563797867, 0.8835262563797867, 0.9002674408566516, 0.9002674408566516, 0.9002674408566516, 0.7714650506718093, 0.7714650506718093, 0.7714650506718093, 0.5421755508811371, 0.5421755508811371, 0.5421755508811371, 0.6854265262260381, 0.6854265262260381, 0.6854265262260381, 0.16933975798371792, 0.16933975798371792, 0.16933975798371792, 0.21295822894571914, 0.21295822894571914, 0.21295822894571914, 0.21916585657770238, 0.21916585657770238, 0.21916585657770238, 0.12819236269809187, 0.12819236269809187, 0.12819236269809187, 0.2057064172338291, 0.2057064172338291, 0.2057064172338291, 0.19636348759427458, 0.19636348759427458, 0.19636348759427458, 0.13326009035516784, 0.13326009035516784, 0.13326009035516784, 0.2401023900231598, 0.2401023900231598, 0.2401023900231598, 0.2621225807046119, 0.2621225807046119, 0.2621225807046119, 0.03323729008288301, 0.03323729008288301, 0.03323729008288301, 0.051222783533298566, 0.051222783533298566, 0.051222783533298566, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09756881240794679, 0.09756881240794679, 0.09756881240794679, 0.046240075974902206, 0.046240075974902206, 0.046240075974902206, 0.09785390211468037, 0.09785390211468037, 0.09785390211468037, 0.05012531110930396, 0.05012531110930396, 0.05012531110930396, 0.1355220378384936, 0.1355220378384936, 0.1355220378384936, 0.10025298189529697, 0.10025298189529697, 0.10025298189529697, 0.4433463008801527, 0.4433463008801527, 0.4433463008801527, 0.06255697548105277, 0.06255697548105277, 0.06255697548105277, 0.17668307615484213, 0.17668307615484213, 0.17668307615484213, 0.5509111272935963, 0.5509111272935963, 0.5509111272935963, 0.5535115389080278, 0.5535115389080278, 0.5535115389080278, 0.5955666587006804, 0.5955666587006804, 0.5955666587006804, 0.10319517163915337, 0.10319517163915337, 0.10319517163915337, 0.07381451816322493, 0.07381451816322493, 0.07381451816322493, 0.12304109567285593, 0.12304109567285593, 0.12304109567285593, 0.18053341310645488, 0.18053341310645488, 0.18053341310645488, 0.22426156957097987, 0.22426156957097987, 0.22426156957097987, 0.19887152713788359, 0.19887152713788359, 0.19887152713788359, 0.3079142534973748, 0.3079142534973748, 0.3079142534973748, 0.5010011725569159, 0.5010011725569159, 0.5010011725569159, 0.28625663065247986, 0.28625663065247986, 0.28625663065247986, 0.21129464882528537, 0.21129464882528537, 0.21129464882528537, 0.20139417002799165, 0.20139417002799165, 0.20139417002799165, 0.34379582619458915, 0.34379582619458915, 0.34379582619458915, 0.26066310774222634, 0.26066310774222634, 0.26066310774222634, 0.2258827149017849, 0.2258827149017849, 0.2258827149017849, 0.2418289407246993, 0.2418289407246993, 0.2418289407246993, 0.19230058282451445, 0.19230058282451445, 0.19230058282451445, 0.17257581268676803, 0.17257581268676803, 0.17257581268676803, 0.2263598417895979, 0.2263598417895979, 0.2263598417895979, 0.9327383768332356, 0.9327383768332356, 0.9327383768332356, 0.1574311172546612, 0.1574311172546612, 0.1574311172546612, 0.9120504986135982, 0.9120504986135982, 0.9120504986135982, 0.15527014727040644, 0.15527014727040644, 0.15527014727040644, 0.21278318884129777, 0.21278318884129777, 0.21278318884129777, 0.8459655449492324, 0.8459655449492324, 0.8459655449492324, 0.22221971134511487, 0.22221971134511487, 0.22221971134511487, 0.18286201644155498, 0.18286201644155498, 0.18286201644155498, 0.22134460072207918, 0.22134460072207918, 0.22134460072207918, 0.11566203723510027, 0.11566203723510027, 0.11566203723510027, 0.0860601420060082, 0.0860601420060082, 0.0860601420060082, 0.13657866317283718, 0.13657866317283718, 0.13657866317283718]}, "mutation_prompt": null}
{"id": "93e41d6f-41bd-4130-9092-eaf9f524a0dc", "solution": "import numpy as np\n\nclass APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(50, 12 * dim)  # Slightly larger dynamic population size\n        self.c1 = 1.7  # Increased cognitive component\n        self.c2 = 1.7  # Increased social component\n        self.w = 0.8  # Reduced initial inertia weight for faster convergence\n        self.decay_rate = 0.96  # Faster inertia decay rate\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.05  # Added velocity limit\n    \n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)  # Limit velocity\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "APSO", "description": "Enhanced APSO with adaptive velocity limits and inertia weight adjustment to improve convergence speed.", "configspace": "", "generation": 11, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "efd62c53-8209-428f-b7ab-70f60cb32186", "metadata": {"aucs": [0.9026872546202871, 0.9026872546202871, 0.9026872546202871, 0.8929590282525381, 0.8929590282525381, 0.8929590282525381, 0.9026832744111498, 0.9026832744111498, 0.9026832744111498, 0.8060553440347592, 0.8060553440347592, 0.8060553440347592, 0.8184025817238518, 0.8184025817238518, 0.8184025817238518, 0.8127430872902957, 0.8127430872902957, 0.8127430872902957, 0.18361135858705824, 0.18361135858705824, 0.18361135858705824, 0.12111447759365401, 0.12111447759365401, 0.12111447759365401, 0.16130138275372496, 0.16130138275372496, 0.16130138275372496, 0.07422109649773867, 0.07422109649773867, 0.07422109649773867, 0.09053284216160151, 0.09053284216160151, 0.09053284216160151, 0.0860523672023924, 0.0860523672023924, 0.0860523672023924, 0.8984246247611002, 0.8984246247611002, 0.8984246247611002, 0.8835262563797867, 0.8835262563797867, 0.8835262563797867, 0.9002674408566516, 0.9002674408566516, 0.9002674408566516, 0.7714650506718093, 0.7714650506718093, 0.7714650506718093, 0.5421755508811371, 0.5421755508811371, 0.5421755508811371, 0.6854265262260381, 0.6854265262260381, 0.6854265262260381, 0.16933975798371792, 0.16933975798371792, 0.16933975798371792, 0.21295822894571914, 0.21295822894571914, 0.21295822894571914, 0.21916585657770238, 0.21916585657770238, 0.21916585657770238, 0.12819236269809187, 0.12819236269809187, 0.12819236269809187, 0.2057064172338291, 0.2057064172338291, 0.2057064172338291, 0.19636348759427458, 0.19636348759427458, 0.19636348759427458, 0.13326009035516784, 0.13326009035516784, 0.13326009035516784, 0.2401023900231598, 0.2401023900231598, 0.2401023900231598, 0.2621225807046119, 0.2621225807046119, 0.2621225807046119, 0.03323729008288301, 0.03323729008288301, 0.03323729008288301, 0.051222783533298566, 0.051222783533298566, 0.051222783533298566, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09756881240794679, 0.09756881240794679, 0.09756881240794679, 0.046240075974902206, 0.046240075974902206, 0.046240075974902206, 0.09785390211468037, 0.09785390211468037, 0.09785390211468037, 0.05012531110930396, 0.05012531110930396, 0.05012531110930396, 0.1355220378384936, 0.1355220378384936, 0.1355220378384936, 0.10025298189529697, 0.10025298189529697, 0.10025298189529697, 0.4433463008801527, 0.4433463008801527, 0.4433463008801527, 0.06255697548105277, 0.06255697548105277, 0.06255697548105277, 0.17668307615484213, 0.17668307615484213, 0.17668307615484213, 0.5509111272935963, 0.5509111272935963, 0.5509111272935963, 0.5535115389080278, 0.5535115389080278, 0.5535115389080278, 0.5955666587006804, 0.5955666587006804, 0.5955666587006804, 0.10319517163915337, 0.10319517163915337, 0.10319517163915337, 0.07381451816322493, 0.07381451816322493, 0.07381451816322493, 0.12304109567285593, 0.12304109567285593, 0.12304109567285593, 0.18053341310645488, 0.18053341310645488, 0.18053341310645488, 0.22426156957097987, 0.22426156957097987, 0.22426156957097987, 0.19887152713788359, 0.19887152713788359, 0.19887152713788359, 0.3079142534973748, 0.3079142534973748, 0.3079142534973748, 0.5010011725569159, 0.5010011725569159, 0.5010011725569159, 0.28625663065247986, 0.28625663065247986, 0.28625663065247986, 0.21129464882528537, 0.21129464882528537, 0.21129464882528537, 0.20139417002799165, 0.20139417002799165, 0.20139417002799165, 0.34379582619458915, 0.34379582619458915, 0.34379582619458915, 0.26066310774222634, 0.26066310774222634, 0.26066310774222634, 0.2258827149017849, 0.2258827149017849, 0.2258827149017849, 0.2418289407246993, 0.2418289407246993, 0.2418289407246993, 0.19230058282451445, 0.19230058282451445, 0.19230058282451445, 0.17257581268676803, 0.17257581268676803, 0.17257581268676803, 0.2263598417895979, 0.2263598417895979, 0.2263598417895979, 0.9327383768332356, 0.9327383768332356, 0.9327383768332356, 0.1574311172546612, 0.1574311172546612, 0.1574311172546612, 0.9120504986135982, 0.9120504986135982, 0.9120504986135982, 0.15527014727040644, 0.15527014727040644, 0.15527014727040644, 0.21278318884129777, 0.21278318884129777, 0.21278318884129777, 0.8459655449492324, 0.8459655449492324, 0.8459655449492324, 0.22221971134511487, 0.22221971134511487, 0.22221971134511487, 0.18286201644155498, 0.18286201644155498, 0.18286201644155498, 0.22134460072207918, 0.22134460072207918, 0.22134460072207918, 0.11566203723510027, 0.11566203723510027, 0.11566203723510027, 0.0860601420060082, 0.0860601420060082, 0.0860601420060082, 0.13657866317283718, 0.13657866317283718, 0.13657866317283718]}, "mutation_prompt": null}
{"id": "11c7b7a7-7763-4ec5-ac2b-0796307d0937", "solution": "import numpy as np\n\nclass APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(50, 12 * dim)  # Slightly larger dynamic population size\n        self.c1 = 1.7  # Increased cognitive component\n        self.c2 = 1.7  # Increased social component\n        self.w = 0.8  # Reduced initial inertia weight for faster convergence\n        self.decay_rate = 0.96  # Faster inertia decay rate\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.05  # Added velocity limit\n    \n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)  # Limit velocity\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "APSO", "description": "Enhanced APSO with adaptive velocity limits and inertia weight adjustment to improve convergence speed.", "configspace": "", "generation": 11, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "efd62c53-8209-428f-b7ab-70f60cb32186", "metadata": {"aucs": [0.9026872546202871, 0.9026872546202871, 0.9026872546202871, 0.8929590282525381, 0.8929590282525381, 0.8929590282525381, 0.9026832744111498, 0.9026832744111498, 0.9026832744111498, 0.8060553440347592, 0.8060553440347592, 0.8060553440347592, 0.8184025817238518, 0.8184025817238518, 0.8184025817238518, 0.8127430872902957, 0.8127430872902957, 0.8127430872902957, 0.18361135858705824, 0.18361135858705824, 0.18361135858705824, 0.12111447759365401, 0.12111447759365401, 0.12111447759365401, 0.16130138275372496, 0.16130138275372496, 0.16130138275372496, 0.07422109649773867, 0.07422109649773867, 0.07422109649773867, 0.09053284216160151, 0.09053284216160151, 0.09053284216160151, 0.0860523672023924, 0.0860523672023924, 0.0860523672023924, 0.8984246247611002, 0.8984246247611002, 0.8984246247611002, 0.8835262563797867, 0.8835262563797867, 0.8835262563797867, 0.9002674408566516, 0.9002674408566516, 0.9002674408566516, 0.7714650506718093, 0.7714650506718093, 0.7714650506718093, 0.5421755508811371, 0.5421755508811371, 0.5421755508811371, 0.6854265262260381, 0.6854265262260381, 0.6854265262260381, 0.16933975798371792, 0.16933975798371792, 0.16933975798371792, 0.21295822894571914, 0.21295822894571914, 0.21295822894571914, 0.21916585657770238, 0.21916585657770238, 0.21916585657770238, 0.12819236269809187, 0.12819236269809187, 0.12819236269809187, 0.2057064172338291, 0.2057064172338291, 0.2057064172338291, 0.19636348759427458, 0.19636348759427458, 0.19636348759427458, 0.13326009035516784, 0.13326009035516784, 0.13326009035516784, 0.2401023900231598, 0.2401023900231598, 0.2401023900231598, 0.2621225807046119, 0.2621225807046119, 0.2621225807046119, 0.03323729008288301, 0.03323729008288301, 0.03323729008288301, 0.051222783533298566, 0.051222783533298566, 0.051222783533298566, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09756881240794679, 0.09756881240794679, 0.09756881240794679, 0.046240075974902206, 0.046240075974902206, 0.046240075974902206, 0.09785390211468037, 0.09785390211468037, 0.09785390211468037, 0.05012531110930396, 0.05012531110930396, 0.05012531110930396, 0.1355220378384936, 0.1355220378384936, 0.1355220378384936, 0.10025298189529697, 0.10025298189529697, 0.10025298189529697, 0.4433463008801527, 0.4433463008801527, 0.4433463008801527, 0.06255697548105277, 0.06255697548105277, 0.06255697548105277, 0.17668307615484213, 0.17668307615484213, 0.17668307615484213, 0.5509111272935963, 0.5509111272935963, 0.5509111272935963, 0.5535115389080278, 0.5535115389080278, 0.5535115389080278, 0.5955666587006804, 0.5955666587006804, 0.5955666587006804, 0.10319517163915337, 0.10319517163915337, 0.10319517163915337, 0.07381451816322493, 0.07381451816322493, 0.07381451816322493, 0.12304109567285593, 0.12304109567285593, 0.12304109567285593, 0.18053341310645488, 0.18053341310645488, 0.18053341310645488, 0.22426156957097987, 0.22426156957097987, 0.22426156957097987, 0.19887152713788359, 0.19887152713788359, 0.19887152713788359, 0.3079142534973748, 0.3079142534973748, 0.3079142534973748, 0.5010011725569159, 0.5010011725569159, 0.5010011725569159, 0.28625663065247986, 0.28625663065247986, 0.28625663065247986, 0.21129464882528537, 0.21129464882528537, 0.21129464882528537, 0.20139417002799165, 0.20139417002799165, 0.20139417002799165, 0.34379582619458915, 0.34379582619458915, 0.34379582619458915, 0.26066310774222634, 0.26066310774222634, 0.26066310774222634, 0.2258827149017849, 0.2258827149017849, 0.2258827149017849, 0.2418289407246993, 0.2418289407246993, 0.2418289407246993, 0.19230058282451445, 0.19230058282451445, 0.19230058282451445, 0.17257581268676803, 0.17257581268676803, 0.17257581268676803, 0.2263598417895979, 0.2263598417895979, 0.2263598417895979, 0.9327383768332356, 0.9327383768332356, 0.9327383768332356, 0.1574311172546612, 0.1574311172546612, 0.1574311172546612, 0.9120504986135982, 0.9120504986135982, 0.9120504986135982, 0.15527014727040644, 0.15527014727040644, 0.15527014727040644, 0.21278318884129777, 0.21278318884129777, 0.21278318884129777, 0.8459655449492324, 0.8459655449492324, 0.8459655449492324, 0.22221971134511487, 0.22221971134511487, 0.22221971134511487, 0.18286201644155498, 0.18286201644155498, 0.18286201644155498, 0.22134460072207918, 0.22134460072207918, 0.22134460072207918, 0.11566203723510027, 0.11566203723510027, 0.11566203723510027, 0.0860601420060082, 0.0860601420060082, 0.0860601420060082, 0.13657866317283718, 0.13657866317283718, 0.13657866317283718]}, "mutation_prompt": null}
{"id": "d3f7b276-cc15-4689-b8f8-8d15e29c6810", "solution": "import numpy as np\n\nclass APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(50, 12 * dim)  # Slightly larger dynamic population size\n        self.c1 = 1.7  # Increased cognitive component\n        self.c2 = 1.7  # Increased social component\n        self.w = 0.8  # Reduced initial inertia weight for faster convergence\n        self.decay_rate = 0.96  # Faster inertia decay rate\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.05  # Added velocity limit\n    \n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)  # Limit velocity\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "APSO", "description": "Enhanced APSO with adaptive velocity limits and inertia weight adjustment to improve convergence speed.", "configspace": "", "generation": 11, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "efd62c53-8209-428f-b7ab-70f60cb32186", "metadata": {"aucs": [0.9026872546202871, 0.9026872546202871, 0.9026872546202871, 0.8929590282525381, 0.8929590282525381, 0.8929590282525381, 0.9026832744111498, 0.9026832744111498, 0.9026832744111498, 0.8060553440347592, 0.8060553440347592, 0.8060553440347592, 0.8184025817238518, 0.8184025817238518, 0.8184025817238518, 0.8127430872902957, 0.8127430872902957, 0.8127430872902957, 0.18361135858705824, 0.18361135858705824, 0.18361135858705824, 0.12111447759365401, 0.12111447759365401, 0.12111447759365401, 0.16130138275372496, 0.16130138275372496, 0.16130138275372496, 0.07422109649773867, 0.07422109649773867, 0.07422109649773867, 0.09053284216160151, 0.09053284216160151, 0.09053284216160151, 0.0860523672023924, 0.0860523672023924, 0.0860523672023924, 0.8984246247611002, 0.8984246247611002, 0.8984246247611002, 0.8835262563797867, 0.8835262563797867, 0.8835262563797867, 0.9002674408566516, 0.9002674408566516, 0.9002674408566516, 0.7714650506718093, 0.7714650506718093, 0.7714650506718093, 0.5421755508811371, 0.5421755508811371, 0.5421755508811371, 0.6854265262260381, 0.6854265262260381, 0.6854265262260381, 0.16933975798371792, 0.16933975798371792, 0.16933975798371792, 0.21295822894571914, 0.21295822894571914, 0.21295822894571914, 0.21916585657770238, 0.21916585657770238, 0.21916585657770238, 0.12819236269809187, 0.12819236269809187, 0.12819236269809187, 0.2057064172338291, 0.2057064172338291, 0.2057064172338291, 0.19636348759427458, 0.19636348759427458, 0.19636348759427458, 0.13326009035516784, 0.13326009035516784, 0.13326009035516784, 0.2401023900231598, 0.2401023900231598, 0.2401023900231598, 0.2621225807046119, 0.2621225807046119, 0.2621225807046119, 0.03323729008288301, 0.03323729008288301, 0.03323729008288301, 0.051222783533298566, 0.051222783533298566, 0.051222783533298566, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09756881240794679, 0.09756881240794679, 0.09756881240794679, 0.046240075974902206, 0.046240075974902206, 0.046240075974902206, 0.09785390211468037, 0.09785390211468037, 0.09785390211468037, 0.05012531110930396, 0.05012531110930396, 0.05012531110930396, 0.1355220378384936, 0.1355220378384936, 0.1355220378384936, 0.10025298189529697, 0.10025298189529697, 0.10025298189529697, 0.4433463008801527, 0.4433463008801527, 0.4433463008801527, 0.06255697548105277, 0.06255697548105277, 0.06255697548105277, 0.17668307615484213, 0.17668307615484213, 0.17668307615484213, 0.5509111272935963, 0.5509111272935963, 0.5509111272935963, 0.5535115389080278, 0.5535115389080278, 0.5535115389080278, 0.5955666587006804, 0.5955666587006804, 0.5955666587006804, 0.10319517163915337, 0.10319517163915337, 0.10319517163915337, 0.07381451816322493, 0.07381451816322493, 0.07381451816322493, 0.12304109567285593, 0.12304109567285593, 0.12304109567285593, 0.18053341310645488, 0.18053341310645488, 0.18053341310645488, 0.22426156957097987, 0.22426156957097987, 0.22426156957097987, 0.19887152713788359, 0.19887152713788359, 0.19887152713788359, 0.3079142534973748, 0.3079142534973748, 0.3079142534973748, 0.5010011725569159, 0.5010011725569159, 0.5010011725569159, 0.28625663065247986, 0.28625663065247986, 0.28625663065247986, 0.21129464882528537, 0.21129464882528537, 0.21129464882528537, 0.20139417002799165, 0.20139417002799165, 0.20139417002799165, 0.34379582619458915, 0.34379582619458915, 0.34379582619458915, 0.26066310774222634, 0.26066310774222634, 0.26066310774222634, 0.2258827149017849, 0.2258827149017849, 0.2258827149017849, 0.2418289407246993, 0.2418289407246993, 0.2418289407246993, 0.19230058282451445, 0.19230058282451445, 0.19230058282451445, 0.17257581268676803, 0.17257581268676803, 0.17257581268676803, 0.2263598417895979, 0.2263598417895979, 0.2263598417895979, 0.9327383768332356, 0.9327383768332356, 0.9327383768332356, 0.1574311172546612, 0.1574311172546612, 0.1574311172546612, 0.9120504986135982, 0.9120504986135982, 0.9120504986135982, 0.15527014727040644, 0.15527014727040644, 0.15527014727040644, 0.21278318884129777, 0.21278318884129777, 0.21278318884129777, 0.8459655449492324, 0.8459655449492324, 0.8459655449492324, 0.22221971134511487, 0.22221971134511487, 0.22221971134511487, 0.18286201644155498, 0.18286201644155498, 0.18286201644155498, 0.22134460072207918, 0.22134460072207918, 0.22134460072207918, 0.11566203723510027, 0.11566203723510027, 0.11566203723510027, 0.0860601420060082, 0.0860601420060082, 0.0860601420060082, 0.13657866317283718, 0.13657866317283718, 0.13657866317283718]}, "mutation_prompt": null}
{"id": "622a3581-e3d3-4bd7-9abe-fd761f48da1b", "solution": "import numpy as np\n\nclass APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(50, 12 * dim)  # Slightly larger dynamic population size\n        self.c1 = 1.7  # Increased cognitive component\n        self.c2 = 1.7  # Increased social component\n        self.w = 0.8  # Reduced initial inertia weight for faster convergence\n        self.decay_rate = 0.96  # Faster inertia decay rate\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.05  # Added velocity limit\n    \n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)  # Limit velocity\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "APSO", "description": "Enhanced APSO with adaptive velocity limits and inertia weight adjustment to improve convergence speed.", "configspace": "", "generation": 11, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "efd62c53-8209-428f-b7ab-70f60cb32186", "metadata": {"aucs": [0.9026872546202871, 0.9026872546202871, 0.9026872546202871, 0.8929590282525381, 0.8929590282525381, 0.8929590282525381, 0.9026832744111498, 0.9026832744111498, 0.9026832744111498, 0.8060553440347592, 0.8060553440347592, 0.8060553440347592, 0.8184025817238518, 0.8184025817238518, 0.8184025817238518, 0.8127430872902957, 0.8127430872902957, 0.8127430872902957, 0.18361135858705824, 0.18361135858705824, 0.18361135858705824, 0.12111447759365401, 0.12111447759365401, 0.12111447759365401, 0.16130138275372496, 0.16130138275372496, 0.16130138275372496, 0.07422109649773867, 0.07422109649773867, 0.07422109649773867, 0.09053284216160151, 0.09053284216160151, 0.09053284216160151, 0.0860523672023924, 0.0860523672023924, 0.0860523672023924, 0.8984246247611002, 0.8984246247611002, 0.8984246247611002, 0.8835262563797867, 0.8835262563797867, 0.8835262563797867, 0.9002674408566516, 0.9002674408566516, 0.9002674408566516, 0.7714650506718093, 0.7714650506718093, 0.7714650506718093, 0.5421755508811371, 0.5421755508811371, 0.5421755508811371, 0.6854265262260381, 0.6854265262260381, 0.6854265262260381, 0.16933975798371792, 0.16933975798371792, 0.16933975798371792, 0.21295822894571914, 0.21295822894571914, 0.21295822894571914, 0.21916585657770238, 0.21916585657770238, 0.21916585657770238, 0.12819236269809187, 0.12819236269809187, 0.12819236269809187, 0.2057064172338291, 0.2057064172338291, 0.2057064172338291, 0.19636348759427458, 0.19636348759427458, 0.19636348759427458, 0.13326009035516784, 0.13326009035516784, 0.13326009035516784, 0.2401023900231598, 0.2401023900231598, 0.2401023900231598, 0.2621225807046119, 0.2621225807046119, 0.2621225807046119, 0.03323729008288301, 0.03323729008288301, 0.03323729008288301, 0.051222783533298566, 0.051222783533298566, 0.051222783533298566, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09756881240794679, 0.09756881240794679, 0.09756881240794679, 0.046240075974902206, 0.046240075974902206, 0.046240075974902206, 0.09785390211468037, 0.09785390211468037, 0.09785390211468037, 0.05012531110930396, 0.05012531110930396, 0.05012531110930396, 0.1355220378384936, 0.1355220378384936, 0.1355220378384936, 0.10025298189529697, 0.10025298189529697, 0.10025298189529697, 0.4433463008801527, 0.4433463008801527, 0.4433463008801527, 0.06255697548105277, 0.06255697548105277, 0.06255697548105277, 0.17668307615484213, 0.17668307615484213, 0.17668307615484213, 0.5509111272935963, 0.5509111272935963, 0.5509111272935963, 0.5535115389080278, 0.5535115389080278, 0.5535115389080278, 0.5955666587006804, 0.5955666587006804, 0.5955666587006804, 0.10319517163915337, 0.10319517163915337, 0.10319517163915337, 0.07381451816322493, 0.07381451816322493, 0.07381451816322493, 0.12304109567285593, 0.12304109567285593, 0.12304109567285593, 0.18053341310645488, 0.18053341310645488, 0.18053341310645488, 0.22426156957097987, 0.22426156957097987, 0.22426156957097987, 0.19887152713788359, 0.19887152713788359, 0.19887152713788359, 0.3079142534973748, 0.3079142534973748, 0.3079142534973748, 0.5010011725569159, 0.5010011725569159, 0.5010011725569159, 0.28625663065247986, 0.28625663065247986, 0.28625663065247986, 0.21129464882528537, 0.21129464882528537, 0.21129464882528537, 0.20139417002799165, 0.20139417002799165, 0.20139417002799165, 0.34379582619458915, 0.34379582619458915, 0.34379582619458915, 0.26066310774222634, 0.26066310774222634, 0.26066310774222634, 0.2258827149017849, 0.2258827149017849, 0.2258827149017849, 0.2418289407246993, 0.2418289407246993, 0.2418289407246993, 0.19230058282451445, 0.19230058282451445, 0.19230058282451445, 0.17257581268676803, 0.17257581268676803, 0.17257581268676803, 0.2263598417895979, 0.2263598417895979, 0.2263598417895979, 0.9327383768332356, 0.9327383768332356, 0.9327383768332356, 0.1574311172546612, 0.1574311172546612, 0.1574311172546612, 0.9120504986135982, 0.9120504986135982, 0.9120504986135982, 0.15527014727040644, 0.15527014727040644, 0.15527014727040644, 0.21278318884129777, 0.21278318884129777, 0.21278318884129777, 0.8459655449492324, 0.8459655449492324, 0.8459655449492324, 0.22221971134511487, 0.22221971134511487, 0.22221971134511487, 0.18286201644155498, 0.18286201644155498, 0.18286201644155498, 0.22134460072207918, 0.22134460072207918, 0.22134460072207918, 0.11566203723510027, 0.11566203723510027, 0.11566203723510027, 0.0860601420060082, 0.0860601420060082, 0.0860601420060082, 0.13657866317283718, 0.13657866317283718, 0.13657866317283718]}, "mutation_prompt": null}
{"id": "3114b6a9-769c-4263-a7e5-c2905f8eabe6", "solution": "import numpy as np\n\nclass APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(50, 12 * dim)  # Slightly larger dynamic population size\n        self.c1 = 1.7  # Increased cognitive component\n        self.c2 = 1.7  # Increased social component\n        self.w = 0.8  # Reduced initial inertia weight for faster convergence\n        self.decay_rate = 0.96  # Faster inertia decay rate\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.05  # Added velocity limit\n    \n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)  # Limit velocity\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "APSO", "description": "Enhanced APSO with adaptive velocity limits and inertia weight adjustment to improve convergence speed.", "configspace": "", "generation": 11, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "efd62c53-8209-428f-b7ab-70f60cb32186", "metadata": {"aucs": [0.9026872546202871, 0.9026872546202871, 0.9026872546202871, 0.8929590282525381, 0.8929590282525381, 0.8929590282525381, 0.9026832744111498, 0.9026832744111498, 0.9026832744111498, 0.8060553440347592, 0.8060553440347592, 0.8060553440347592, 0.8184025817238518, 0.8184025817238518, 0.8184025817238518, 0.8127430872902957, 0.8127430872902957, 0.8127430872902957, 0.18361135858705824, 0.18361135858705824, 0.18361135858705824, 0.12111447759365401, 0.12111447759365401, 0.12111447759365401, 0.16130138275372496, 0.16130138275372496, 0.16130138275372496, 0.07422109649773867, 0.07422109649773867, 0.07422109649773867, 0.09053284216160151, 0.09053284216160151, 0.09053284216160151, 0.0860523672023924, 0.0860523672023924, 0.0860523672023924, 0.8984246247611002, 0.8984246247611002, 0.8984246247611002, 0.8835262563797867, 0.8835262563797867, 0.8835262563797867, 0.9002674408566516, 0.9002674408566516, 0.9002674408566516, 0.7714650506718093, 0.7714650506718093, 0.7714650506718093, 0.5421755508811371, 0.5421755508811371, 0.5421755508811371, 0.6854265262260381, 0.6854265262260381, 0.6854265262260381, 0.16933975798371792, 0.16933975798371792, 0.16933975798371792, 0.21295822894571914, 0.21295822894571914, 0.21295822894571914, 0.21916585657770238, 0.21916585657770238, 0.21916585657770238, 0.12819236269809187, 0.12819236269809187, 0.12819236269809187, 0.2057064172338291, 0.2057064172338291, 0.2057064172338291, 0.19636348759427458, 0.19636348759427458, 0.19636348759427458, 0.13326009035516784, 0.13326009035516784, 0.13326009035516784, 0.2401023900231598, 0.2401023900231598, 0.2401023900231598, 0.2621225807046119, 0.2621225807046119, 0.2621225807046119, 0.03323729008288301, 0.03323729008288301, 0.03323729008288301, 0.051222783533298566, 0.051222783533298566, 0.051222783533298566, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09756881240794679, 0.09756881240794679, 0.09756881240794679, 0.046240075974902206, 0.046240075974902206, 0.046240075974902206, 0.09785390211468037, 0.09785390211468037, 0.09785390211468037, 0.05012531110930396, 0.05012531110930396, 0.05012531110930396, 0.1355220378384936, 0.1355220378384936, 0.1355220378384936, 0.10025298189529697, 0.10025298189529697, 0.10025298189529697, 0.4433463008801527, 0.4433463008801527, 0.4433463008801527, 0.06255697548105277, 0.06255697548105277, 0.06255697548105277, 0.17668307615484213, 0.17668307615484213, 0.17668307615484213, 0.5509111272935963, 0.5509111272935963, 0.5509111272935963, 0.5535115389080278, 0.5535115389080278, 0.5535115389080278, 0.5955666587006804, 0.5955666587006804, 0.5955666587006804, 0.10319517163915337, 0.10319517163915337, 0.10319517163915337, 0.07381451816322493, 0.07381451816322493, 0.07381451816322493, 0.12304109567285593, 0.12304109567285593, 0.12304109567285593, 0.18053341310645488, 0.18053341310645488, 0.18053341310645488, 0.22426156957097987, 0.22426156957097987, 0.22426156957097987, 0.19887152713788359, 0.19887152713788359, 0.19887152713788359, 0.3079142534973748, 0.3079142534973748, 0.3079142534973748, 0.5010011725569159, 0.5010011725569159, 0.5010011725569159, 0.28625663065247986, 0.28625663065247986, 0.28625663065247986, 0.21129464882528537, 0.21129464882528537, 0.21129464882528537, 0.20139417002799165, 0.20139417002799165, 0.20139417002799165, 0.34379582619458915, 0.34379582619458915, 0.34379582619458915, 0.26066310774222634, 0.26066310774222634, 0.26066310774222634, 0.2258827149017849, 0.2258827149017849, 0.2258827149017849, 0.2418289407246993, 0.2418289407246993, 0.2418289407246993, 0.19230058282451445, 0.19230058282451445, 0.19230058282451445, 0.17257581268676803, 0.17257581268676803, 0.17257581268676803, 0.2263598417895979, 0.2263598417895979, 0.2263598417895979, 0.9327383768332356, 0.9327383768332356, 0.9327383768332356, 0.1574311172546612, 0.1574311172546612, 0.1574311172546612, 0.9120504986135982, 0.9120504986135982, 0.9120504986135982, 0.15527014727040644, 0.15527014727040644, 0.15527014727040644, 0.21278318884129777, 0.21278318884129777, 0.21278318884129777, 0.8459655449492324, 0.8459655449492324, 0.8459655449492324, 0.22221971134511487, 0.22221971134511487, 0.22221971134511487, 0.18286201644155498, 0.18286201644155498, 0.18286201644155498, 0.22134460072207918, 0.22134460072207918, 0.22134460072207918, 0.11566203723510027, 0.11566203723510027, 0.11566203723510027, 0.0860601420060082, 0.0860601420060082, 0.0860601420060082, 0.13657866317283718, 0.13657866317283718, 0.13657866317283718]}, "mutation_prompt": null}
{"id": "fdf592b0-1b5c-4d32-8af7-9e3c093a9bee", "solution": "import numpy as np\n\nclass APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(50, 12 * dim)  # Slightly larger dynamic population size\n        self.c1 = 1.7  # Increased cognitive component\n        self.c2 = 1.7  # Increased social component\n        self.w = 0.8  # Reduced initial inertia weight for faster convergence\n        self.decay_rate = 0.96  # Faster inertia decay rate\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.05  # Added velocity limit\n    \n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)  # Limit velocity\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "APSO", "description": "Enhanced APSO with adaptive velocity limits and inertia weight adjustment to improve convergence speed.", "configspace": "", "generation": 11, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "efd62c53-8209-428f-b7ab-70f60cb32186", "metadata": {"aucs": [0.9026872546202871, 0.9026872546202871, 0.9026872546202871, 0.8929590282525381, 0.8929590282525381, 0.8929590282525381, 0.9026832744111498, 0.9026832744111498, 0.9026832744111498, 0.8060553440347592, 0.8060553440347592, 0.8060553440347592, 0.8184025817238518, 0.8184025817238518, 0.8184025817238518, 0.8127430872902957, 0.8127430872902957, 0.8127430872902957, 0.18361135858705824, 0.18361135858705824, 0.18361135858705824, 0.12111447759365401, 0.12111447759365401, 0.12111447759365401, 0.16130138275372496, 0.16130138275372496, 0.16130138275372496, 0.07422109649773867, 0.07422109649773867, 0.07422109649773867, 0.09053284216160151, 0.09053284216160151, 0.09053284216160151, 0.0860523672023924, 0.0860523672023924, 0.0860523672023924, 0.8984246247611002, 0.8984246247611002, 0.8984246247611002, 0.8835262563797867, 0.8835262563797867, 0.8835262563797867, 0.9002674408566516, 0.9002674408566516, 0.9002674408566516, 0.7714650506718093, 0.7714650506718093, 0.7714650506718093, 0.5421755508811371, 0.5421755508811371, 0.5421755508811371, 0.6854265262260381, 0.6854265262260381, 0.6854265262260381, 0.16933975798371792, 0.16933975798371792, 0.16933975798371792, 0.21295822894571914, 0.21295822894571914, 0.21295822894571914, 0.21916585657770238, 0.21916585657770238, 0.21916585657770238, 0.12819236269809187, 0.12819236269809187, 0.12819236269809187, 0.2057064172338291, 0.2057064172338291, 0.2057064172338291, 0.19636348759427458, 0.19636348759427458, 0.19636348759427458, 0.13326009035516784, 0.13326009035516784, 0.13326009035516784, 0.2401023900231598, 0.2401023900231598, 0.2401023900231598, 0.2621225807046119, 0.2621225807046119, 0.2621225807046119, 0.03323729008288301, 0.03323729008288301, 0.03323729008288301, 0.051222783533298566, 0.051222783533298566, 0.051222783533298566, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09756881240794679, 0.09756881240794679, 0.09756881240794679, 0.046240075974902206, 0.046240075974902206, 0.046240075974902206, 0.09785390211468037, 0.09785390211468037, 0.09785390211468037, 0.05012531110930396, 0.05012531110930396, 0.05012531110930396, 0.1355220378384936, 0.1355220378384936, 0.1355220378384936, 0.10025298189529697, 0.10025298189529697, 0.10025298189529697, 0.4433463008801527, 0.4433463008801527, 0.4433463008801527, 0.06255697548105277, 0.06255697548105277, 0.06255697548105277, 0.17668307615484213, 0.17668307615484213, 0.17668307615484213, 0.5509111272935963, 0.5509111272935963, 0.5509111272935963, 0.5535115389080278, 0.5535115389080278, 0.5535115389080278, 0.5955666587006804, 0.5955666587006804, 0.5955666587006804, 0.10319517163915337, 0.10319517163915337, 0.10319517163915337, 0.07381451816322493, 0.07381451816322493, 0.07381451816322493, 0.12304109567285593, 0.12304109567285593, 0.12304109567285593, 0.18053341310645488, 0.18053341310645488, 0.18053341310645488, 0.22426156957097987, 0.22426156957097987, 0.22426156957097987, 0.19887152713788359, 0.19887152713788359, 0.19887152713788359, 0.3079142534973748, 0.3079142534973748, 0.3079142534973748, 0.5010011725569159, 0.5010011725569159, 0.5010011725569159, 0.28625663065247986, 0.28625663065247986, 0.28625663065247986, 0.21129464882528537, 0.21129464882528537, 0.21129464882528537, 0.20139417002799165, 0.20139417002799165, 0.20139417002799165, 0.34379582619458915, 0.34379582619458915, 0.34379582619458915, 0.26066310774222634, 0.26066310774222634, 0.26066310774222634, 0.2258827149017849, 0.2258827149017849, 0.2258827149017849, 0.2418289407246993, 0.2418289407246993, 0.2418289407246993, 0.19230058282451445, 0.19230058282451445, 0.19230058282451445, 0.17257581268676803, 0.17257581268676803, 0.17257581268676803, 0.2263598417895979, 0.2263598417895979, 0.2263598417895979, 0.9327383768332356, 0.9327383768332356, 0.9327383768332356, 0.1574311172546612, 0.1574311172546612, 0.1574311172546612, 0.9120504986135982, 0.9120504986135982, 0.9120504986135982, 0.15527014727040644, 0.15527014727040644, 0.15527014727040644, 0.21278318884129777, 0.21278318884129777, 0.21278318884129777, 0.8459655449492324, 0.8459655449492324, 0.8459655449492324, 0.22221971134511487, 0.22221971134511487, 0.22221971134511487, 0.18286201644155498, 0.18286201644155498, 0.18286201644155498, 0.22134460072207918, 0.22134460072207918, 0.22134460072207918, 0.11566203723510027, 0.11566203723510027, 0.11566203723510027, 0.0860601420060082, 0.0860601420060082, 0.0860601420060082, 0.13657866317283718, 0.13657866317283718, 0.13657866317283718]}, "mutation_prompt": null}
{"id": "74e85f22-1ee2-4ebe-8d1f-a64768925813", "solution": "import numpy as np\n\nclass APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(50, 12 * dim)  # Slightly larger dynamic population size\n        self.c1 = 1.7  # Increased cognitive component\n        self.c2 = 1.7  # Increased social component\n        self.w = 0.8  # Reduced initial inertia weight for faster convergence\n        self.decay_rate = 0.96  # Faster inertia decay rate\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.05  # Added velocity limit\n    \n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)  # Limit velocity\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "APSO", "description": "Enhanced APSO with adaptive velocity limits and inertia weight adjustment to improve convergence speed.", "configspace": "", "generation": 11, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "efd62c53-8209-428f-b7ab-70f60cb32186", "metadata": {"aucs": [0.9026872546202871, 0.9026872546202871, 0.9026872546202871, 0.8929590282525381, 0.8929590282525381, 0.8929590282525381, 0.9026832744111498, 0.9026832744111498, 0.9026832744111498, 0.8060553440347592, 0.8060553440347592, 0.8060553440347592, 0.8184025817238518, 0.8184025817238518, 0.8184025817238518, 0.8127430872902957, 0.8127430872902957, 0.8127430872902957, 0.18361135858705824, 0.18361135858705824, 0.18361135858705824, 0.12111447759365401, 0.12111447759365401, 0.12111447759365401, 0.16130138275372496, 0.16130138275372496, 0.16130138275372496, 0.07422109649773867, 0.07422109649773867, 0.07422109649773867, 0.09053284216160151, 0.09053284216160151, 0.09053284216160151, 0.0860523672023924, 0.0860523672023924, 0.0860523672023924, 0.8984246247611002, 0.8984246247611002, 0.8984246247611002, 0.8835262563797867, 0.8835262563797867, 0.8835262563797867, 0.9002674408566516, 0.9002674408566516, 0.9002674408566516, 0.7714650506718093, 0.7714650506718093, 0.7714650506718093, 0.5421755508811371, 0.5421755508811371, 0.5421755508811371, 0.6854265262260381, 0.6854265262260381, 0.6854265262260381, 0.16933975798371792, 0.16933975798371792, 0.16933975798371792, 0.21295822894571914, 0.21295822894571914, 0.21295822894571914, 0.21916585657770238, 0.21916585657770238, 0.21916585657770238, 0.12819236269809187, 0.12819236269809187, 0.12819236269809187, 0.2057064172338291, 0.2057064172338291, 0.2057064172338291, 0.19636348759427458, 0.19636348759427458, 0.19636348759427458, 0.13326009035516784, 0.13326009035516784, 0.13326009035516784, 0.2401023900231598, 0.2401023900231598, 0.2401023900231598, 0.2621225807046119, 0.2621225807046119, 0.2621225807046119, 0.03323729008288301, 0.03323729008288301, 0.03323729008288301, 0.051222783533298566, 0.051222783533298566, 0.051222783533298566, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09756881240794679, 0.09756881240794679, 0.09756881240794679, 0.046240075974902206, 0.046240075974902206, 0.046240075974902206, 0.09785390211468037, 0.09785390211468037, 0.09785390211468037, 0.05012531110930396, 0.05012531110930396, 0.05012531110930396, 0.1355220378384936, 0.1355220378384936, 0.1355220378384936, 0.10025298189529697, 0.10025298189529697, 0.10025298189529697, 0.4433463008801527, 0.4433463008801527, 0.4433463008801527, 0.06255697548105277, 0.06255697548105277, 0.06255697548105277, 0.17668307615484213, 0.17668307615484213, 0.17668307615484213, 0.5509111272935963, 0.5509111272935963, 0.5509111272935963, 0.5535115389080278, 0.5535115389080278, 0.5535115389080278, 0.5955666587006804, 0.5955666587006804, 0.5955666587006804, 0.10319517163915337, 0.10319517163915337, 0.10319517163915337, 0.07381451816322493, 0.07381451816322493, 0.07381451816322493, 0.12304109567285593, 0.12304109567285593, 0.12304109567285593, 0.18053341310645488, 0.18053341310645488, 0.18053341310645488, 0.22426156957097987, 0.22426156957097987, 0.22426156957097987, 0.19887152713788359, 0.19887152713788359, 0.19887152713788359, 0.3079142534973748, 0.3079142534973748, 0.3079142534973748, 0.5010011725569159, 0.5010011725569159, 0.5010011725569159, 0.28625663065247986, 0.28625663065247986, 0.28625663065247986, 0.21129464882528537, 0.21129464882528537, 0.21129464882528537, 0.20139417002799165, 0.20139417002799165, 0.20139417002799165, 0.34379582619458915, 0.34379582619458915, 0.34379582619458915, 0.26066310774222634, 0.26066310774222634, 0.26066310774222634, 0.2258827149017849, 0.2258827149017849, 0.2258827149017849, 0.2418289407246993, 0.2418289407246993, 0.2418289407246993, 0.19230058282451445, 0.19230058282451445, 0.19230058282451445, 0.17257581268676803, 0.17257581268676803, 0.17257581268676803, 0.2263598417895979, 0.2263598417895979, 0.2263598417895979, 0.9327383768332356, 0.9327383768332356, 0.9327383768332356, 0.1574311172546612, 0.1574311172546612, 0.1574311172546612, 0.9120504986135982, 0.9120504986135982, 0.9120504986135982, 0.15527014727040644, 0.15527014727040644, 0.15527014727040644, 0.21278318884129777, 0.21278318884129777, 0.21278318884129777, 0.8459655449492324, 0.8459655449492324, 0.8459655449492324, 0.22221971134511487, 0.22221971134511487, 0.22221971134511487, 0.18286201644155498, 0.18286201644155498, 0.18286201644155498, 0.22134460072207918, 0.22134460072207918, 0.22134460072207918, 0.11566203723510027, 0.11566203723510027, 0.11566203723510027, 0.0860601420060082, 0.0860601420060082, 0.0860601420060082, 0.13657866317283718, 0.13657866317283718, 0.13657866317283718]}, "mutation_prompt": null}
{"id": "ae31e9bc-6317-48c9-92c9-9f9f2fd6e919", "solution": "import numpy as np\n\nclass APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(60, 15 * dim)  # Further increased dynamic population size\n        self.c1 = 1.5  # Slightly reduced cognitive component for more social learning\n        self.c2 = 2.0  # Increased social component to enhance convergence\n        self.w = 0.9  # Increased initial inertia weight to enhance exploration\n        self.decay_rate = 0.95  # Slightly slower inertia decay\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.07  # Increased velocity limit for broader exploration\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "APSO", "description": "Adaptive APSO with dynamically adjusted population size and enhanced exploration to improve convergence speed.", "configspace": "", "generation": 21, "fitness": 0.3305475300182638, "feedback": "The algorithm APSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.28.", "error": "", "parent_id": "efd62c53-8209-428f-b7ab-70f60cb32186", "metadata": {"aucs": [0.8750695916460762, 0.8750695916460762, 0.8750695916460762, 0.867766464271437, 0.867766464271437, 0.867766464271437, 0.8829216776694785, 0.8829216776694785, 0.8829216776694785, 0.7757312735333037, 0.7757312735333037, 0.7757312735333037, 0.760834238877702, 0.760834238877702, 0.760834238877702, 0.7822709434546018, 0.7822709434546018, 0.7822709434546018, 0.15660956782012303, 0.15660956782012303, 0.15660956782012303, 0.10310055453791889, 0.10310055453791889, 0.10310055453791889, 0.12999328707116875, 0.12999328707116875, 0.12999328707116875, 0.08769744498306375, 0.08769744498306375, 0.08769744498306375, 0.08909644904168834, 0.08909644904168834, 0.08909644904168834, 0.12925285687278443, 0.12925285687278443, 0.12925285687278443, 0.9054531320518405, 0.9054531320518405, 0.9054531320518405, 0.9239681555586648, 0.9239681555586648, 0.9239681555586648, 0.9277225917837737, 0.9277225917837737, 0.9277225917837737, 0.6838220528383288, 0.6838220528383288, 0.6838220528383288, 0.7074305755104074, 0.7074305755104074, 0.7074305755104074, 0.7137399340868286, 0.7137399340868286, 0.7137399340868286, 0.21819883069516222, 0.21819883069516222, 0.21819883069516222, 0.2757299909744302, 0.2757299909744302, 0.2757299909744302, 0.23918681438939415, 0.23918681438939415, 0.23918681438939415, 0.21174752724787615, 0.21174752724787615, 0.21174752724787615, 0.19453424222589144, 0.19453424222589144, 0.19453424222589144, 0.1288254650247984, 0.1288254650247984, 0.1288254650247984, 0.12971528326511939, 0.12971528326511939, 0.12971528326511939, 0.3646399771232234, 0.3646399771232234, 0.3646399771232234, 0.20192581126764864, 0.20192581126764864, 0.20192581126764864, 0.13896483125401615, 0.13896483125401615, 0.13896483125401615, 0.025902763703198994, 0.025902763703198994, 0.025902763703198994, 0.08871875983821997, 0.08871875983821997, 0.08871875983821997, 0.09989049097755687, 0.09989049097755687, 0.09989049097755687, 0.017987003204588792, 0.017987003204588792, 0.017987003204588792, 0.16023766976933607, 0.16023766976933607, 0.16023766976933607, 0.048225951927364674, 0.048225951927364674, 0.048225951927364674, 0.10836137970088022, 0.10836137970088022, 0.10836137970088022, 0.13259767120704924, 0.13259767120704924, 0.13259767120704924, 0.13944312791183433, 0.13944312791183433, 0.13944312791183433, 0.11385118586870102, 0.11385118586870102, 0.11385118586870102, 0.15236180270529753, 0.15236180270529753, 0.15236180270529753, 0.5762079010197634, 0.5762079010197634, 0.5762079010197634, 0.5517842009410614, 0.5517842009410614, 0.5517842009410614, 0.5528154242562424, 0.5528154242562424, 0.5528154242562424, 0.05455393348018356, 0.05455393348018356, 0.05455393348018356, 0.07187768499278557, 0.07187768499278557, 0.07187768499278557, 0.09098367439597788, 0.09098367439597788, 0.09098367439597788, 0.20070702153348607, 0.20070702153348607, 0.20070702153348607, 0.22857113568388754, 0.22857113568388754, 0.22857113568388754, 0.19537533380853866, 0.19537533380853866, 0.19537533380853866, 0.4424289380915063, 0.4424289380915063, 0.4424289380915063, 0.44588187995616513, 0.44588187995616513, 0.44588187995616513, 0.5021992546222733, 0.5021992546222733, 0.5021992546222733, 0.31831640789940996, 0.31831640789940996, 0.31831640789940996, 0.25619831479308086, 0.25619831479308086, 0.25619831479308086, 0.252471222512342, 0.252471222512342, 0.252471222512342, 0.23502864768240828, 0.23502864768240828, 0.23502864768240828, 0.22824125606259704, 0.22824125606259704, 0.22824125606259704, 0.22142924825832344, 0.22142924825832344, 0.22142924825832344, 0.17432015730641637, 0.17432015730641637, 0.17432015730641637, 0.21383604064488404, 0.21383604064488404, 0.21383604064488404, 0.1991222893581408, 0.1991222893581408, 0.1991222893581408, 0.9214519758708095, 0.9214519758708095, 0.9214519758708095, 0.19782873815407265, 0.19782873815407265, 0.19782873815407265, 0.16703423081725155, 0.16703423081725155, 0.16703423081725155, 0.7813079495778156, 0.7813079495778156, 0.7813079495778156, 0.8772670236555625, 0.8772670236555625, 0.8772670236555625, 0.1278019200030267, 0.1278019200030267, 0.1278019200030267, 0.19595385197274784, 0.19595385197274784, 0.19595385197274784, 0.2321366206474731, 0.2321366206474731, 0.2321366206474731, 0.30476932940259593, 0.30476932940259593, 0.30476932940259593, 0.10377785814755647, 0.10377785814755647, 0.10377785814755647, 0.0997191293234988, 0.0997191293234988, 0.0997191293234988, 0.08449619455232937, 0.08449619455232937, 0.08449619455232937]}, "mutation_prompt": null}
{"id": "48bca2f6-a9d8-4cc1-b9a3-61a90c98f8d9", "solution": "import numpy as np\n\nclass APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(60, 15 * dim)  # Further increased dynamic population size\n        self.c1 = 1.5  # Slightly reduced cognitive component for more social learning\n        self.c2 = 2.0  # Increased social component to enhance convergence\n        self.w = 0.9  # Increased initial inertia weight to enhance exploration\n        self.decay_rate = 0.95  # Slightly slower inertia decay\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.07  # Increased velocity limit for broader exploration\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "APSO", "description": "Adaptive APSO with dynamically adjusted population size and enhanced exploration to improve convergence speed.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ae31e9bc-6317-48c9-92c9-9f9f2fd6e919", "metadata": {"aucs": [0.8750695916460762, 0.8750695916460762, 0.8750695916460762, 0.867766464271437, 0.867766464271437, 0.867766464271437, 0.8829216776694785, 0.8829216776694785, 0.8829216776694785, 0.7757312735333037, 0.7757312735333037, 0.7757312735333037, 0.760834238877702, 0.760834238877702, 0.760834238877702, 0.7822709434546018, 0.7822709434546018, 0.7822709434546018, 0.15660956782012303, 0.15660956782012303, 0.15660956782012303, 0.10310055453791889, 0.10310055453791889, 0.10310055453791889, 0.12999328707116875, 0.12999328707116875, 0.12999328707116875, 0.08769744498306375, 0.08769744498306375, 0.08769744498306375, 0.08909644904168834, 0.08909644904168834, 0.08909644904168834, 0.12925285687278443, 0.12925285687278443, 0.12925285687278443, 0.9054531320518405, 0.9054531320518405, 0.9054531320518405, 0.9239681555586648, 0.9239681555586648, 0.9239681555586648, 0.9277225917837737, 0.9277225917837737, 0.9277225917837737, 0.6838220528383288, 0.6838220528383288, 0.6838220528383288, 0.7074305755104074, 0.7074305755104074, 0.7074305755104074, 0.7137399340868286, 0.7137399340868286, 0.7137399340868286, 0.21819883069516222, 0.21819883069516222, 0.21819883069516222, 0.2757299909744302, 0.2757299909744302, 0.2757299909744302, 0.23918681438939415, 0.23918681438939415, 0.23918681438939415, 0.21174752724787615, 0.21174752724787615, 0.21174752724787615, 0.19453424222589144, 0.19453424222589144, 0.19453424222589144, 0.1288254650247984, 0.1288254650247984, 0.1288254650247984, 0.12971528326511939, 0.12971528326511939, 0.12971528326511939, 0.3646399771232234, 0.3646399771232234, 0.3646399771232234, 0.20192581126764864, 0.20192581126764864, 0.20192581126764864, 0.13896483125401615, 0.13896483125401615, 0.13896483125401615, 0.025902763703198994, 0.025902763703198994, 0.025902763703198994, 0.08871875983821997, 0.08871875983821997, 0.08871875983821997, 0.09989049097755687, 0.09989049097755687, 0.09989049097755687, 0.017987003204588792, 0.017987003204588792, 0.017987003204588792, 0.16023766976933607, 0.16023766976933607, 0.16023766976933607, 0.048225951927364674, 0.048225951927364674, 0.048225951927364674, 0.10836137970088022, 0.10836137970088022, 0.10836137970088022, 0.13259767120704924, 0.13259767120704924, 0.13259767120704924, 0.13944312791183433, 0.13944312791183433, 0.13944312791183433, 0.11385118586870102, 0.11385118586870102, 0.11385118586870102, 0.15236180270529753, 0.15236180270529753, 0.15236180270529753, 0.5762079010197634, 0.5762079010197634, 0.5762079010197634, 0.5517842009410614, 0.5517842009410614, 0.5517842009410614, 0.5528154242562424, 0.5528154242562424, 0.5528154242562424, 0.05455393348018356, 0.05455393348018356, 0.05455393348018356, 0.07187768499278557, 0.07187768499278557, 0.07187768499278557, 0.09098367439597788, 0.09098367439597788, 0.09098367439597788, 0.20070702153348607, 0.20070702153348607, 0.20070702153348607, 0.22857113568388754, 0.22857113568388754, 0.22857113568388754, 0.19537533380853866, 0.19537533380853866, 0.19537533380853866, 0.4424289380915063, 0.4424289380915063, 0.4424289380915063, 0.44588187995616513, 0.44588187995616513, 0.44588187995616513, 0.5021992546222733, 0.5021992546222733, 0.5021992546222733, 0.31831640789940996, 0.31831640789940996, 0.31831640789940996, 0.25619831479308086, 0.25619831479308086, 0.25619831479308086, 0.252471222512342, 0.252471222512342, 0.252471222512342, 0.23502864768240828, 0.23502864768240828, 0.23502864768240828, 0.22824125606259704, 0.22824125606259704, 0.22824125606259704, 0.22142924825832344, 0.22142924825832344, 0.22142924825832344, 0.17432015730641637, 0.17432015730641637, 0.17432015730641637, 0.21383604064488404, 0.21383604064488404, 0.21383604064488404, 0.1991222893581408, 0.1991222893581408, 0.1991222893581408, 0.9214519758708095, 0.9214519758708095, 0.9214519758708095, 0.19782873815407265, 0.19782873815407265, 0.19782873815407265, 0.16703423081725155, 0.16703423081725155, 0.16703423081725155, 0.7813079495778156, 0.7813079495778156, 0.7813079495778156, 0.8772670236555625, 0.8772670236555625, 0.8772670236555625, 0.1278019200030267, 0.1278019200030267, 0.1278019200030267, 0.19595385197274784, 0.19595385197274784, 0.19595385197274784, 0.2321366206474731, 0.2321366206474731, 0.2321366206474731, 0.30476932940259593, 0.30476932940259593, 0.30476932940259593, 0.10377785814755647, 0.10377785814755647, 0.10377785814755647, 0.0997191293234988, 0.0997191293234988, 0.0997191293234988, 0.08449619455232937, 0.08449619455232937, 0.08449619455232937]}, "mutation_prompt": null}
{"id": "5c4ebed0-c4ef-4f1a-87bd-a0a903b21d39", "solution": "import numpy as np\n\nclass APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(60, 15 * dim)  # Further increased dynamic population size\n        self.c1 = 1.5  # Slightly reduced cognitive component for more social learning\n        self.c2 = 2.0  # Increased social component to enhance convergence\n        self.w = 0.9  # Increased initial inertia weight to enhance exploration\n        self.decay_rate = 0.95  # Slightly slower inertia decay\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.07  # Increased velocity limit for broader exploration\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "APSO", "description": "Adaptive APSO with dynamically adjusted population size and enhanced exploration to improve convergence speed.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ae31e9bc-6317-48c9-92c9-9f9f2fd6e919", "metadata": {"aucs": [0.8750695916460762, 0.8750695916460762, 0.8750695916460762, 0.867766464271437, 0.867766464271437, 0.867766464271437, 0.8829216776694785, 0.8829216776694785, 0.8829216776694785, 0.7757312735333037, 0.7757312735333037, 0.7757312735333037, 0.760834238877702, 0.760834238877702, 0.760834238877702, 0.7822709434546018, 0.7822709434546018, 0.7822709434546018, 0.15660956782012303, 0.15660956782012303, 0.15660956782012303, 0.10310055453791889, 0.10310055453791889, 0.10310055453791889, 0.12999328707116875, 0.12999328707116875, 0.12999328707116875, 0.08769744498306375, 0.08769744498306375, 0.08769744498306375, 0.08909644904168834, 0.08909644904168834, 0.08909644904168834, 0.12925285687278443, 0.12925285687278443, 0.12925285687278443, 0.9054531320518405, 0.9054531320518405, 0.9054531320518405, 0.9239681555586648, 0.9239681555586648, 0.9239681555586648, 0.9277225917837737, 0.9277225917837737, 0.9277225917837737, 0.6838220528383288, 0.6838220528383288, 0.6838220528383288, 0.7074305755104074, 0.7074305755104074, 0.7074305755104074, 0.7137399340868286, 0.7137399340868286, 0.7137399340868286, 0.21819883069516222, 0.21819883069516222, 0.21819883069516222, 0.2757299909744302, 0.2757299909744302, 0.2757299909744302, 0.23918681438939415, 0.23918681438939415, 0.23918681438939415, 0.21174752724787615, 0.21174752724787615, 0.21174752724787615, 0.19453424222589144, 0.19453424222589144, 0.19453424222589144, 0.1288254650247984, 0.1288254650247984, 0.1288254650247984, 0.12971528326511939, 0.12971528326511939, 0.12971528326511939, 0.3646399771232234, 0.3646399771232234, 0.3646399771232234, 0.20192581126764864, 0.20192581126764864, 0.20192581126764864, 0.13896483125401615, 0.13896483125401615, 0.13896483125401615, 0.025902763703198994, 0.025902763703198994, 0.025902763703198994, 0.08871875983821997, 0.08871875983821997, 0.08871875983821997, 0.09989049097755687, 0.09989049097755687, 0.09989049097755687, 0.017987003204588792, 0.017987003204588792, 0.017987003204588792, 0.16023766976933607, 0.16023766976933607, 0.16023766976933607, 0.048225951927364674, 0.048225951927364674, 0.048225951927364674, 0.10836137970088022, 0.10836137970088022, 0.10836137970088022, 0.13259767120704924, 0.13259767120704924, 0.13259767120704924, 0.13944312791183433, 0.13944312791183433, 0.13944312791183433, 0.11385118586870102, 0.11385118586870102, 0.11385118586870102, 0.15236180270529753, 0.15236180270529753, 0.15236180270529753, 0.5762079010197634, 0.5762079010197634, 0.5762079010197634, 0.5517842009410614, 0.5517842009410614, 0.5517842009410614, 0.5528154242562424, 0.5528154242562424, 0.5528154242562424, 0.05455393348018356, 0.05455393348018356, 0.05455393348018356, 0.07187768499278557, 0.07187768499278557, 0.07187768499278557, 0.09098367439597788, 0.09098367439597788, 0.09098367439597788, 0.20070702153348607, 0.20070702153348607, 0.20070702153348607, 0.22857113568388754, 0.22857113568388754, 0.22857113568388754, 0.19537533380853866, 0.19537533380853866, 0.19537533380853866, 0.4424289380915063, 0.4424289380915063, 0.4424289380915063, 0.44588187995616513, 0.44588187995616513, 0.44588187995616513, 0.5021992546222733, 0.5021992546222733, 0.5021992546222733, 0.31831640789940996, 0.31831640789940996, 0.31831640789940996, 0.25619831479308086, 0.25619831479308086, 0.25619831479308086, 0.252471222512342, 0.252471222512342, 0.252471222512342, 0.23502864768240828, 0.23502864768240828, 0.23502864768240828, 0.22824125606259704, 0.22824125606259704, 0.22824125606259704, 0.22142924825832344, 0.22142924825832344, 0.22142924825832344, 0.17432015730641637, 0.17432015730641637, 0.17432015730641637, 0.21383604064488404, 0.21383604064488404, 0.21383604064488404, 0.1991222893581408, 0.1991222893581408, 0.1991222893581408, 0.9214519758708095, 0.9214519758708095, 0.9214519758708095, 0.19782873815407265, 0.19782873815407265, 0.19782873815407265, 0.16703423081725155, 0.16703423081725155, 0.16703423081725155, 0.7813079495778156, 0.7813079495778156, 0.7813079495778156, 0.8772670236555625, 0.8772670236555625, 0.8772670236555625, 0.1278019200030267, 0.1278019200030267, 0.1278019200030267, 0.19595385197274784, 0.19595385197274784, 0.19595385197274784, 0.2321366206474731, 0.2321366206474731, 0.2321366206474731, 0.30476932940259593, 0.30476932940259593, 0.30476932940259593, 0.10377785814755647, 0.10377785814755647, 0.10377785814755647, 0.0997191293234988, 0.0997191293234988, 0.0997191293234988, 0.08449619455232937, 0.08449619455232937, 0.08449619455232937]}, "mutation_prompt": null}
{"id": "749c2cfe-944a-4fac-925c-cd0da5f0ffa9", "solution": "import numpy as np\n\nclass APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(60, 15 * dim)  # Further increased dynamic population size\n        self.c1 = 1.5  # Slightly reduced cognitive component for more social learning\n        self.c2 = 2.0  # Increased social component to enhance convergence\n        self.w = 0.9  # Increased initial inertia weight to enhance exploration\n        self.decay_rate = 0.95  # Slightly slower inertia decay\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.07  # Increased velocity limit for broader exploration\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "APSO", "description": "Adaptive APSO with dynamically adjusted population size and enhanced exploration to improve convergence speed.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ae31e9bc-6317-48c9-92c9-9f9f2fd6e919", "metadata": {"aucs": [0.8750695916460762, 0.8750695916460762, 0.8750695916460762, 0.867766464271437, 0.867766464271437, 0.867766464271437, 0.8829216776694785, 0.8829216776694785, 0.8829216776694785, 0.7757312735333037, 0.7757312735333037, 0.7757312735333037, 0.760834238877702, 0.760834238877702, 0.760834238877702, 0.7822709434546018, 0.7822709434546018, 0.7822709434546018, 0.15660956782012303, 0.15660956782012303, 0.15660956782012303, 0.10310055453791889, 0.10310055453791889, 0.10310055453791889, 0.12999328707116875, 0.12999328707116875, 0.12999328707116875, 0.08769744498306375, 0.08769744498306375, 0.08769744498306375, 0.08909644904168834, 0.08909644904168834, 0.08909644904168834, 0.12925285687278443, 0.12925285687278443, 0.12925285687278443, 0.9054531320518405, 0.9054531320518405, 0.9054531320518405, 0.9239681555586648, 0.9239681555586648, 0.9239681555586648, 0.9277225917837737, 0.9277225917837737, 0.9277225917837737, 0.6838220528383288, 0.6838220528383288, 0.6838220528383288, 0.7074305755104074, 0.7074305755104074, 0.7074305755104074, 0.7137399340868286, 0.7137399340868286, 0.7137399340868286, 0.21819883069516222, 0.21819883069516222, 0.21819883069516222, 0.2757299909744302, 0.2757299909744302, 0.2757299909744302, 0.23918681438939415, 0.23918681438939415, 0.23918681438939415, 0.21174752724787615, 0.21174752724787615, 0.21174752724787615, 0.19453424222589144, 0.19453424222589144, 0.19453424222589144, 0.1288254650247984, 0.1288254650247984, 0.1288254650247984, 0.12971528326511939, 0.12971528326511939, 0.12971528326511939, 0.3646399771232234, 0.3646399771232234, 0.3646399771232234, 0.20192581126764864, 0.20192581126764864, 0.20192581126764864, 0.13896483125401615, 0.13896483125401615, 0.13896483125401615, 0.025902763703198994, 0.025902763703198994, 0.025902763703198994, 0.08871875983821997, 0.08871875983821997, 0.08871875983821997, 0.09989049097755687, 0.09989049097755687, 0.09989049097755687, 0.017987003204588792, 0.017987003204588792, 0.017987003204588792, 0.16023766976933607, 0.16023766976933607, 0.16023766976933607, 0.048225951927364674, 0.048225951927364674, 0.048225951927364674, 0.10836137970088022, 0.10836137970088022, 0.10836137970088022, 0.13259767120704924, 0.13259767120704924, 0.13259767120704924, 0.13944312791183433, 0.13944312791183433, 0.13944312791183433, 0.11385118586870102, 0.11385118586870102, 0.11385118586870102, 0.15236180270529753, 0.15236180270529753, 0.15236180270529753, 0.5762079010197634, 0.5762079010197634, 0.5762079010197634, 0.5517842009410614, 0.5517842009410614, 0.5517842009410614, 0.5528154242562424, 0.5528154242562424, 0.5528154242562424, 0.05455393348018356, 0.05455393348018356, 0.05455393348018356, 0.07187768499278557, 0.07187768499278557, 0.07187768499278557, 0.09098367439597788, 0.09098367439597788, 0.09098367439597788, 0.20070702153348607, 0.20070702153348607, 0.20070702153348607, 0.22857113568388754, 0.22857113568388754, 0.22857113568388754, 0.19537533380853866, 0.19537533380853866, 0.19537533380853866, 0.4424289380915063, 0.4424289380915063, 0.4424289380915063, 0.44588187995616513, 0.44588187995616513, 0.44588187995616513, 0.5021992546222733, 0.5021992546222733, 0.5021992546222733, 0.31831640789940996, 0.31831640789940996, 0.31831640789940996, 0.25619831479308086, 0.25619831479308086, 0.25619831479308086, 0.252471222512342, 0.252471222512342, 0.252471222512342, 0.23502864768240828, 0.23502864768240828, 0.23502864768240828, 0.22824125606259704, 0.22824125606259704, 0.22824125606259704, 0.22142924825832344, 0.22142924825832344, 0.22142924825832344, 0.17432015730641637, 0.17432015730641637, 0.17432015730641637, 0.21383604064488404, 0.21383604064488404, 0.21383604064488404, 0.1991222893581408, 0.1991222893581408, 0.1991222893581408, 0.9214519758708095, 0.9214519758708095, 0.9214519758708095, 0.19782873815407265, 0.19782873815407265, 0.19782873815407265, 0.16703423081725155, 0.16703423081725155, 0.16703423081725155, 0.7813079495778156, 0.7813079495778156, 0.7813079495778156, 0.8772670236555625, 0.8772670236555625, 0.8772670236555625, 0.1278019200030267, 0.1278019200030267, 0.1278019200030267, 0.19595385197274784, 0.19595385197274784, 0.19595385197274784, 0.2321366206474731, 0.2321366206474731, 0.2321366206474731, 0.30476932940259593, 0.30476932940259593, 0.30476932940259593, 0.10377785814755647, 0.10377785814755647, 0.10377785814755647, 0.0997191293234988, 0.0997191293234988, 0.0997191293234988, 0.08449619455232937, 0.08449619455232937, 0.08449619455232937]}, "mutation_prompt": null}
{"id": "f9e72422-8973-4eb8-94ef-e5c2afb7ecf5", "solution": "import numpy as np\n\nclass APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(60, 15 * dim)  # Further increased dynamic population size\n        self.c1 = 1.5  # Slightly reduced cognitive component for more social learning\n        self.c2 = 2.0  # Increased social component to enhance convergence\n        self.w = 0.9  # Increased initial inertia weight to enhance exploration\n        self.decay_rate = 0.95  # Slightly slower inertia decay\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.07  # Increased velocity limit for broader exploration\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "APSO", "description": "Adaptive APSO with dynamically adjusted population size and enhanced exploration to improve convergence speed.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ae31e9bc-6317-48c9-92c9-9f9f2fd6e919", "metadata": {"aucs": [0.8750695916460762, 0.8750695916460762, 0.8750695916460762, 0.867766464271437, 0.867766464271437, 0.867766464271437, 0.8829216776694785, 0.8829216776694785, 0.8829216776694785, 0.7757312735333037, 0.7757312735333037, 0.7757312735333037, 0.760834238877702, 0.760834238877702, 0.760834238877702, 0.7822709434546018, 0.7822709434546018, 0.7822709434546018, 0.15660956782012303, 0.15660956782012303, 0.15660956782012303, 0.10310055453791889, 0.10310055453791889, 0.10310055453791889, 0.12999328707116875, 0.12999328707116875, 0.12999328707116875, 0.08769744498306375, 0.08769744498306375, 0.08769744498306375, 0.08909644904168834, 0.08909644904168834, 0.08909644904168834, 0.12925285687278443, 0.12925285687278443, 0.12925285687278443, 0.9054531320518405, 0.9054531320518405, 0.9054531320518405, 0.9239681555586648, 0.9239681555586648, 0.9239681555586648, 0.9277225917837737, 0.9277225917837737, 0.9277225917837737, 0.6838220528383288, 0.6838220528383288, 0.6838220528383288, 0.7074305755104074, 0.7074305755104074, 0.7074305755104074, 0.7137399340868286, 0.7137399340868286, 0.7137399340868286, 0.21819883069516222, 0.21819883069516222, 0.21819883069516222, 0.2757299909744302, 0.2757299909744302, 0.2757299909744302, 0.23918681438939415, 0.23918681438939415, 0.23918681438939415, 0.21174752724787615, 0.21174752724787615, 0.21174752724787615, 0.19453424222589144, 0.19453424222589144, 0.19453424222589144, 0.1288254650247984, 0.1288254650247984, 0.1288254650247984, 0.12971528326511939, 0.12971528326511939, 0.12971528326511939, 0.3646399771232234, 0.3646399771232234, 0.3646399771232234, 0.20192581126764864, 0.20192581126764864, 0.20192581126764864, 0.13896483125401615, 0.13896483125401615, 0.13896483125401615, 0.025902763703198994, 0.025902763703198994, 0.025902763703198994, 0.08871875983821997, 0.08871875983821997, 0.08871875983821997, 0.09989049097755687, 0.09989049097755687, 0.09989049097755687, 0.017987003204588792, 0.017987003204588792, 0.017987003204588792, 0.16023766976933607, 0.16023766976933607, 0.16023766976933607, 0.048225951927364674, 0.048225951927364674, 0.048225951927364674, 0.10836137970088022, 0.10836137970088022, 0.10836137970088022, 0.13259767120704924, 0.13259767120704924, 0.13259767120704924, 0.13944312791183433, 0.13944312791183433, 0.13944312791183433, 0.11385118586870102, 0.11385118586870102, 0.11385118586870102, 0.15236180270529753, 0.15236180270529753, 0.15236180270529753, 0.5762079010197634, 0.5762079010197634, 0.5762079010197634, 0.5517842009410614, 0.5517842009410614, 0.5517842009410614, 0.5528154242562424, 0.5528154242562424, 0.5528154242562424, 0.05455393348018356, 0.05455393348018356, 0.05455393348018356, 0.07187768499278557, 0.07187768499278557, 0.07187768499278557, 0.09098367439597788, 0.09098367439597788, 0.09098367439597788, 0.20070702153348607, 0.20070702153348607, 0.20070702153348607, 0.22857113568388754, 0.22857113568388754, 0.22857113568388754, 0.19537533380853866, 0.19537533380853866, 0.19537533380853866, 0.4424289380915063, 0.4424289380915063, 0.4424289380915063, 0.44588187995616513, 0.44588187995616513, 0.44588187995616513, 0.5021992546222733, 0.5021992546222733, 0.5021992546222733, 0.31831640789940996, 0.31831640789940996, 0.31831640789940996, 0.25619831479308086, 0.25619831479308086, 0.25619831479308086, 0.252471222512342, 0.252471222512342, 0.252471222512342, 0.23502864768240828, 0.23502864768240828, 0.23502864768240828, 0.22824125606259704, 0.22824125606259704, 0.22824125606259704, 0.22142924825832344, 0.22142924825832344, 0.22142924825832344, 0.17432015730641637, 0.17432015730641637, 0.17432015730641637, 0.21383604064488404, 0.21383604064488404, 0.21383604064488404, 0.1991222893581408, 0.1991222893581408, 0.1991222893581408, 0.9214519758708095, 0.9214519758708095, 0.9214519758708095, 0.19782873815407265, 0.19782873815407265, 0.19782873815407265, 0.16703423081725155, 0.16703423081725155, 0.16703423081725155, 0.7813079495778156, 0.7813079495778156, 0.7813079495778156, 0.8772670236555625, 0.8772670236555625, 0.8772670236555625, 0.1278019200030267, 0.1278019200030267, 0.1278019200030267, 0.19595385197274784, 0.19595385197274784, 0.19595385197274784, 0.2321366206474731, 0.2321366206474731, 0.2321366206474731, 0.30476932940259593, 0.30476932940259593, 0.30476932940259593, 0.10377785814755647, 0.10377785814755647, 0.10377785814755647, 0.0997191293234988, 0.0997191293234988, 0.0997191293234988, 0.08449619455232937, 0.08449619455232937, 0.08449619455232937]}, "mutation_prompt": null}
{"id": "fc4cafd4-e5c1-466e-831e-81502b3587d9", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(60, 15 * dim)\n        self.c1 = 1.6  # Slightly increased cognitive component for better individual learning\n        self.c2 = 1.9  # Reduced social component to encourage diverse solutions\n        self.w_max = 0.9  # Adjusted inertia weight range for dynamic control\n        self.w_min = 0.4\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.07\n        self.mutation_prob = 0.1  # Introduce mutation probability for velocity\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            current_iter = evaluations // self.num_particles\n            w = self.w_max - (self.w_max - self.w_min) * (current_iter / (self.budget // self.num_particles))\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation = np.random.normal(0, 0.1, self.dim)  \n                    vel[i] += mutation\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced Adaptive APSO with dynamic inertia weight adjustment and velocity mutation to improve convergence.", "configspace": "", "generation": 26, "fitness": 0.22817313139831408, "feedback": "The algorithm EnhancedAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "ae31e9bc-6317-48c9-92c9-9f9f2fd6e919", "metadata": {"aucs": [0.4411393592192022, 0.4411393592192022, 0.4411393592192022, 0.5008160862108311, 0.5008160862108311, 0.5008160862108311, 0.4805835223153847, 0.4805835223153847, 0.4805835223153847, 0.035930775819105865, 0.035930775819105865, 0.035930775819105865, 0.027697619598305412, 0.027697619598305412, 0.027697619598305412, 0.02490208678548811, 0.02490208678548811, 0.02490208678548811, 0.10671507588312723, 0.10671507588312723, 0.10671507588312723, 0.1284802227367683, 0.1284802227367683, 0.1284802227367683, 0.12477652742675494, 0.12477652742675494, 0.12477652742675494, 0.0759133933157431, 0.0759133933157431, 0.0759133933157431, 0.09228618955498369, 0.09228618955498369, 0.09228618955498369, 0.09769773256176317, 0.09769773256176317, 0.09769773256176317, 0.8919637844886872, 0.8919637844886872, 0.8919637844886872, 0.9320329295790416, 0.9320329295790416, 0.9320329295790416, 0.9199214786752368, 0.9199214786752368, 0.9199214786752368, 0.2989662695152545, 0.2989662695152545, 0.2989662695152545, 0.2940035597848246, 0.2940035597848246, 0.2940035597848246, 0.2846313803337456, 0.2846313803337456, 0.2846313803337456, 0.21813314275391427, 0.21813314275391427, 0.21813314275391427, 0.2566924664080965, 0.2566924664080965, 0.2566924664080965, 0.5559906295237876, 0.5559906295237876, 0.5559906295237876, 0.12646644432573484, 0.12646644432573484, 0.12646644432573484, 0.16138022479015746, 0.16138022479015746, 0.16138022479015746, 0.16303287070037809, 0.16303287070037809, 0.16303287070037809, 0.0999644974085695, 0.0999644974085695, 0.0999644974085695, 0.1569944824497994, 0.1569944824497994, 0.1569944824497994, 0.18097905628793987, 0.18097905628793987, 0.18097905628793987, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.033676147832341075, 0.033676147832341075, 0.033676147832341075, 0.05244994994582397, 0.05244994994582397, 0.05244994994582397, 0.09097322707448585, 0.09097322707448585, 0.09097322707448585, 0.07444577285372467, 0.07444577285372467, 0.07444577285372467, 0.12736486917112866, 0.12736486917112866, 0.12736486917112866, 0.007378509872074224, 0.007378509872074224, 0.007378509872074224, 0.02226118165625124, 0.02226118165625124, 0.02226118165625124, 0.029458067489839923, 0.029458067489839923, 0.029458067489839923, 0.12729133423776762, 0.12729133423776762, 0.12729133423776762, 0.08330708744823767, 0.08330708744823767, 0.08330708744823767, 0.06740603171709991, 0.06740603171709991, 0.06740603171709991, 0.39145434135246415, 0.39145434135246415, 0.39145434135246415, 0.4294972991271495, 0.4294972991271495, 0.4294972991271495, 0.4178108949047571, 0.4178108949047571, 0.4178108949047571, 0.1234772477480145, 0.1234772477480145, 0.1234772477480145, 0.12023880048700253, 0.12023880048700253, 0.12023880048700253, 0.12975691397597944, 0.12975691397597944, 0.12975691397597944, 0.15649261292545857, 0.15649261292545857, 0.15649261292545857, 0.2304517603403714, 0.2304517603403714, 0.2304517603403714, 0.2821939425217923, 0.2821939425217923, 0.2821939425217923, 0.3138440814398554, 0.3138440814398554, 0.3138440814398554, 0.2929004883149895, 0.2929004883149895, 0.2929004883149895, 0.31159470420870405, 0.31159470420870405, 0.31159470420870405, 0.22467387943117467, 0.22467387943117467, 0.22467387943117467, 0.24724278611091854, 0.24724278611091854, 0.24724278611091854, 0.23384528929734183, 0.23384528929734183, 0.23384528929734183, 0.26635629902724567, 0.26635629902724567, 0.26635629902724567, 0.26762525686726046, 0.26762525686726046, 0.26762525686726046, 0.20430188564580498, 0.20430188564580498, 0.20430188564580498, 0.20417942915644594, 0.20417942915644594, 0.20417942915644594, 0.2781447708511664, 0.2781447708511664, 0.2781447708511664, 0.20828038169768348, 0.20828038169768348, 0.20828038169768348, 0.7042077350570617, 0.7042077350570617, 0.7042077350570617, 0.1564843121328935, 0.1564843121328935, 0.1564843121328935, 0.13522186125008806, 0.13522186125008806, 0.13522186125008806, 0.5202573939195898, 0.5202573939195898, 0.5202573939195898, 0.16717722945190894, 0.16717722945190894, 0.16717722945190894, 0.12708868082115476, 0.12708868082115476, 0.12708868082115476, 0.2030318397587102, 0.2030318397587102, 0.2030318397587102, 0.19405185553886994, 0.19405185553886994, 0.19405185553886994, 0.19447242317072666, 0.19447242317072666, 0.19447242317072666, 0.08487124458965734, 0.08487124458965734, 0.08487124458965734, 0.09945314914882453, 0.09945314914882453, 0.09945314914882453, 0.11358068265614873, 0.11358068265614873, 0.11358068265614873]}, "mutation_prompt": null}
{"id": "3a2e1d07-ccee-4c25-9ff4-c174fe6cf29c", "solution": "import numpy as np\n\nclass APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(60, 15 * dim)  # Further increased dynamic population size\n        self.c1 = 1.5  # Slightly reduced cognitive component for more social learning\n        self.c2 = 2.0  # Increased social component to enhance convergence\n        self.w = 0.9  # Increased initial inertia weight to enhance exploration\n        self.decay_rate = 0.95  # Slightly slower inertia decay\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.07  # Increased velocity limit for broader exploration\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "APSO", "description": "Adaptive APSO with dynamically adjusted population size and enhanced exploration to improve convergence speed.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ae31e9bc-6317-48c9-92c9-9f9f2fd6e919", "metadata": {"aucs": [0.8750695916460762, 0.8750695916460762, 0.8750695916460762, 0.867766464271437, 0.867766464271437, 0.867766464271437, 0.8829216776694785, 0.8829216776694785, 0.8829216776694785, 0.7757312735333037, 0.7757312735333037, 0.7757312735333037, 0.760834238877702, 0.760834238877702, 0.760834238877702, 0.7822709434546018, 0.7822709434546018, 0.7822709434546018, 0.15660956782012303, 0.15660956782012303, 0.15660956782012303, 0.10310055453791889, 0.10310055453791889, 0.10310055453791889, 0.12999328707116875, 0.12999328707116875, 0.12999328707116875, 0.08769744498306375, 0.08769744498306375, 0.08769744498306375, 0.08909644904168834, 0.08909644904168834, 0.08909644904168834, 0.12925285687278443, 0.12925285687278443, 0.12925285687278443, 0.9054531320518405, 0.9054531320518405, 0.9054531320518405, 0.9239681555586648, 0.9239681555586648, 0.9239681555586648, 0.9277225917837737, 0.9277225917837737, 0.9277225917837737, 0.6838220528383288, 0.6838220528383288, 0.6838220528383288, 0.7074305755104074, 0.7074305755104074, 0.7074305755104074, 0.7137399340868286, 0.7137399340868286, 0.7137399340868286, 0.21819883069516222, 0.21819883069516222, 0.21819883069516222, 0.2757299909744302, 0.2757299909744302, 0.2757299909744302, 0.23918681438939415, 0.23918681438939415, 0.23918681438939415, 0.21174752724787615, 0.21174752724787615, 0.21174752724787615, 0.19453424222589144, 0.19453424222589144, 0.19453424222589144, 0.1288254650247984, 0.1288254650247984, 0.1288254650247984, 0.12971528326511939, 0.12971528326511939, 0.12971528326511939, 0.3646399771232234, 0.3646399771232234, 0.3646399771232234, 0.20192581126764864, 0.20192581126764864, 0.20192581126764864, 0.13896483125401615, 0.13896483125401615, 0.13896483125401615, 0.025902763703198994, 0.025902763703198994, 0.025902763703198994, 0.08871875983821997, 0.08871875983821997, 0.08871875983821997, 0.09989049097755687, 0.09989049097755687, 0.09989049097755687, 0.017987003204588792, 0.017987003204588792, 0.017987003204588792, 0.16023766976933607, 0.16023766976933607, 0.16023766976933607, 0.048225951927364674, 0.048225951927364674, 0.048225951927364674, 0.10836137970088022, 0.10836137970088022, 0.10836137970088022, 0.13259767120704924, 0.13259767120704924, 0.13259767120704924, 0.13944312791183433, 0.13944312791183433, 0.13944312791183433, 0.11385118586870102, 0.11385118586870102, 0.11385118586870102, 0.15236180270529753, 0.15236180270529753, 0.15236180270529753, 0.5762079010197634, 0.5762079010197634, 0.5762079010197634, 0.5517842009410614, 0.5517842009410614, 0.5517842009410614, 0.5528154242562424, 0.5528154242562424, 0.5528154242562424, 0.05455393348018356, 0.05455393348018356, 0.05455393348018356, 0.07187768499278557, 0.07187768499278557, 0.07187768499278557, 0.09098367439597788, 0.09098367439597788, 0.09098367439597788, 0.20070702153348607, 0.20070702153348607, 0.20070702153348607, 0.22857113568388754, 0.22857113568388754, 0.22857113568388754, 0.19537533380853866, 0.19537533380853866, 0.19537533380853866, 0.4424289380915063, 0.4424289380915063, 0.4424289380915063, 0.44588187995616513, 0.44588187995616513, 0.44588187995616513, 0.5021992546222733, 0.5021992546222733, 0.5021992546222733, 0.31831640789940996, 0.31831640789940996, 0.31831640789940996, 0.25619831479308086, 0.25619831479308086, 0.25619831479308086, 0.252471222512342, 0.252471222512342, 0.252471222512342, 0.23502864768240828, 0.23502864768240828, 0.23502864768240828, 0.22824125606259704, 0.22824125606259704, 0.22824125606259704, 0.22142924825832344, 0.22142924825832344, 0.22142924825832344, 0.17432015730641637, 0.17432015730641637, 0.17432015730641637, 0.21383604064488404, 0.21383604064488404, 0.21383604064488404, 0.1991222893581408, 0.1991222893581408, 0.1991222893581408, 0.9214519758708095, 0.9214519758708095, 0.9214519758708095, 0.19782873815407265, 0.19782873815407265, 0.19782873815407265, 0.16703423081725155, 0.16703423081725155, 0.16703423081725155, 0.7813079495778156, 0.7813079495778156, 0.7813079495778156, 0.8772670236555625, 0.8772670236555625, 0.8772670236555625, 0.1278019200030267, 0.1278019200030267, 0.1278019200030267, 0.19595385197274784, 0.19595385197274784, 0.19595385197274784, 0.2321366206474731, 0.2321366206474731, 0.2321366206474731, 0.30476932940259593, 0.30476932940259593, 0.30476932940259593, 0.10377785814755647, 0.10377785814755647, 0.10377785814755647, 0.0997191293234988, 0.0997191293234988, 0.0997191293234988, 0.08449619455232937, 0.08449619455232937, 0.08449619455232937]}, "mutation_prompt": null}
{"id": "de9fd5d1-00e1-4c27-ad3c-45338918aeec", "solution": "import numpy as np\n\nclass APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(60, 15 * dim)  # Further increased dynamic population size\n        self.c1 = 1.5  # Slightly reduced cognitive component for more social learning\n        self.c2 = 2.0  # Increased social component to enhance convergence\n        self.w = 0.9  # Increased initial inertia weight to enhance exploration\n        self.decay_rate = 0.95  # Slightly slower inertia decay\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.07  # Increased velocity limit for broader exploration\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "APSO", "description": "Adaptive APSO with dynamically adjusted population size and enhanced exploration to improve convergence speed.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ae31e9bc-6317-48c9-92c9-9f9f2fd6e919", "metadata": {"aucs": [0.8750695916460762, 0.8750695916460762, 0.8750695916460762, 0.867766464271437, 0.867766464271437, 0.867766464271437, 0.8829216776694785, 0.8829216776694785, 0.8829216776694785, 0.7757312735333037, 0.7757312735333037, 0.7757312735333037, 0.760834238877702, 0.760834238877702, 0.760834238877702, 0.7822709434546018, 0.7822709434546018, 0.7822709434546018, 0.15660956782012303, 0.15660956782012303, 0.15660956782012303, 0.10310055453791889, 0.10310055453791889, 0.10310055453791889, 0.12999328707116875, 0.12999328707116875, 0.12999328707116875, 0.08769744498306375, 0.08769744498306375, 0.08769744498306375, 0.08909644904168834, 0.08909644904168834, 0.08909644904168834, 0.12925285687278443, 0.12925285687278443, 0.12925285687278443, 0.9054531320518405, 0.9054531320518405, 0.9054531320518405, 0.9239681555586648, 0.9239681555586648, 0.9239681555586648, 0.9277225917837737, 0.9277225917837737, 0.9277225917837737, 0.6838220528383288, 0.6838220528383288, 0.6838220528383288, 0.7074305755104074, 0.7074305755104074, 0.7074305755104074, 0.7137399340868286, 0.7137399340868286, 0.7137399340868286, 0.21819883069516222, 0.21819883069516222, 0.21819883069516222, 0.2757299909744302, 0.2757299909744302, 0.2757299909744302, 0.23918681438939415, 0.23918681438939415, 0.23918681438939415, 0.21174752724787615, 0.21174752724787615, 0.21174752724787615, 0.19453424222589144, 0.19453424222589144, 0.19453424222589144, 0.1288254650247984, 0.1288254650247984, 0.1288254650247984, 0.12971528326511939, 0.12971528326511939, 0.12971528326511939, 0.3646399771232234, 0.3646399771232234, 0.3646399771232234, 0.20192581126764864, 0.20192581126764864, 0.20192581126764864, 0.13896483125401615, 0.13896483125401615, 0.13896483125401615, 0.025902763703198994, 0.025902763703198994, 0.025902763703198994, 0.08871875983821997, 0.08871875983821997, 0.08871875983821997, 0.09989049097755687, 0.09989049097755687, 0.09989049097755687, 0.017987003204588792, 0.017987003204588792, 0.017987003204588792, 0.16023766976933607, 0.16023766976933607, 0.16023766976933607, 0.048225951927364674, 0.048225951927364674, 0.048225951927364674, 0.10836137970088022, 0.10836137970088022, 0.10836137970088022, 0.13259767120704924, 0.13259767120704924, 0.13259767120704924, 0.13944312791183433, 0.13944312791183433, 0.13944312791183433, 0.11385118586870102, 0.11385118586870102, 0.11385118586870102, 0.15236180270529753, 0.15236180270529753, 0.15236180270529753, 0.5762079010197634, 0.5762079010197634, 0.5762079010197634, 0.5517842009410614, 0.5517842009410614, 0.5517842009410614, 0.5528154242562424, 0.5528154242562424, 0.5528154242562424, 0.05455393348018356, 0.05455393348018356, 0.05455393348018356, 0.07187768499278557, 0.07187768499278557, 0.07187768499278557, 0.09098367439597788, 0.09098367439597788, 0.09098367439597788, 0.20070702153348607, 0.20070702153348607, 0.20070702153348607, 0.22857113568388754, 0.22857113568388754, 0.22857113568388754, 0.19537533380853866, 0.19537533380853866, 0.19537533380853866, 0.4424289380915063, 0.4424289380915063, 0.4424289380915063, 0.44588187995616513, 0.44588187995616513, 0.44588187995616513, 0.5021992546222733, 0.5021992546222733, 0.5021992546222733, 0.31831640789940996, 0.31831640789940996, 0.31831640789940996, 0.25619831479308086, 0.25619831479308086, 0.25619831479308086, 0.252471222512342, 0.252471222512342, 0.252471222512342, 0.23502864768240828, 0.23502864768240828, 0.23502864768240828, 0.22824125606259704, 0.22824125606259704, 0.22824125606259704, 0.22142924825832344, 0.22142924825832344, 0.22142924825832344, 0.17432015730641637, 0.17432015730641637, 0.17432015730641637, 0.21383604064488404, 0.21383604064488404, 0.21383604064488404, 0.1991222893581408, 0.1991222893581408, 0.1991222893581408, 0.9214519758708095, 0.9214519758708095, 0.9214519758708095, 0.19782873815407265, 0.19782873815407265, 0.19782873815407265, 0.16703423081725155, 0.16703423081725155, 0.16703423081725155, 0.7813079495778156, 0.7813079495778156, 0.7813079495778156, 0.8772670236555625, 0.8772670236555625, 0.8772670236555625, 0.1278019200030267, 0.1278019200030267, 0.1278019200030267, 0.19595385197274784, 0.19595385197274784, 0.19595385197274784, 0.2321366206474731, 0.2321366206474731, 0.2321366206474731, 0.30476932940259593, 0.30476932940259593, 0.30476932940259593, 0.10377785814755647, 0.10377785814755647, 0.10377785814755647, 0.0997191293234988, 0.0997191293234988, 0.0997191293234988, 0.08449619455232937, 0.08449619455232937, 0.08449619455232937]}, "mutation_prompt": null}
{"id": "20df6b0b-e2eb-48d3-baed-6cf43b66ff89", "solution": "import numpy as np\n\nclass APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(60, 15 * dim)  # Further increased dynamic population size\n        self.c1 = 1.5  # Slightly reduced cognitive component for more social learning\n        self.c2 = 2.0  # Increased social component to enhance convergence\n        self.w = 0.9  # Increased initial inertia weight to enhance exploration\n        self.decay_rate = 0.95  # Slightly slower inertia decay\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.07  # Increased velocity limit for broader exploration\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "APSO", "description": "Adaptive APSO with dynamically adjusted population size and enhanced exploration to improve convergence speed.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ae31e9bc-6317-48c9-92c9-9f9f2fd6e919", "metadata": {"aucs": [0.8750695916460762, 0.8750695916460762, 0.8750695916460762, 0.867766464271437, 0.867766464271437, 0.867766464271437, 0.8829216776694785, 0.8829216776694785, 0.8829216776694785, 0.7757312735333037, 0.7757312735333037, 0.7757312735333037, 0.760834238877702, 0.760834238877702, 0.760834238877702, 0.7822709434546018, 0.7822709434546018, 0.7822709434546018, 0.15660956782012303, 0.15660956782012303, 0.15660956782012303, 0.10310055453791889, 0.10310055453791889, 0.10310055453791889, 0.12999328707116875, 0.12999328707116875, 0.12999328707116875, 0.08769744498306375, 0.08769744498306375, 0.08769744498306375, 0.08909644904168834, 0.08909644904168834, 0.08909644904168834, 0.12925285687278443, 0.12925285687278443, 0.12925285687278443, 0.9054531320518405, 0.9054531320518405, 0.9054531320518405, 0.9239681555586648, 0.9239681555586648, 0.9239681555586648, 0.9277225917837737, 0.9277225917837737, 0.9277225917837737, 0.6838220528383288, 0.6838220528383288, 0.6838220528383288, 0.7074305755104074, 0.7074305755104074, 0.7074305755104074, 0.7137399340868286, 0.7137399340868286, 0.7137399340868286, 0.21819883069516222, 0.21819883069516222, 0.21819883069516222, 0.2757299909744302, 0.2757299909744302, 0.2757299909744302, 0.23918681438939415, 0.23918681438939415, 0.23918681438939415, 0.21174752724787615, 0.21174752724787615, 0.21174752724787615, 0.19453424222589144, 0.19453424222589144, 0.19453424222589144, 0.1288254650247984, 0.1288254650247984, 0.1288254650247984, 0.12971528326511939, 0.12971528326511939, 0.12971528326511939, 0.3646399771232234, 0.3646399771232234, 0.3646399771232234, 0.20192581126764864, 0.20192581126764864, 0.20192581126764864, 0.13896483125401615, 0.13896483125401615, 0.13896483125401615, 0.025902763703198994, 0.025902763703198994, 0.025902763703198994, 0.08871875983821997, 0.08871875983821997, 0.08871875983821997, 0.09989049097755687, 0.09989049097755687, 0.09989049097755687, 0.017987003204588792, 0.017987003204588792, 0.017987003204588792, 0.16023766976933607, 0.16023766976933607, 0.16023766976933607, 0.048225951927364674, 0.048225951927364674, 0.048225951927364674, 0.10836137970088022, 0.10836137970088022, 0.10836137970088022, 0.13259767120704924, 0.13259767120704924, 0.13259767120704924, 0.13944312791183433, 0.13944312791183433, 0.13944312791183433, 0.11385118586870102, 0.11385118586870102, 0.11385118586870102, 0.15236180270529753, 0.15236180270529753, 0.15236180270529753, 0.5762079010197634, 0.5762079010197634, 0.5762079010197634, 0.5517842009410614, 0.5517842009410614, 0.5517842009410614, 0.5528154242562424, 0.5528154242562424, 0.5528154242562424, 0.05455393348018356, 0.05455393348018356, 0.05455393348018356, 0.07187768499278557, 0.07187768499278557, 0.07187768499278557, 0.09098367439597788, 0.09098367439597788, 0.09098367439597788, 0.20070702153348607, 0.20070702153348607, 0.20070702153348607, 0.22857113568388754, 0.22857113568388754, 0.22857113568388754, 0.19537533380853866, 0.19537533380853866, 0.19537533380853866, 0.4424289380915063, 0.4424289380915063, 0.4424289380915063, 0.44588187995616513, 0.44588187995616513, 0.44588187995616513, 0.5021992546222733, 0.5021992546222733, 0.5021992546222733, 0.31831640789940996, 0.31831640789940996, 0.31831640789940996, 0.25619831479308086, 0.25619831479308086, 0.25619831479308086, 0.252471222512342, 0.252471222512342, 0.252471222512342, 0.23502864768240828, 0.23502864768240828, 0.23502864768240828, 0.22824125606259704, 0.22824125606259704, 0.22824125606259704, 0.22142924825832344, 0.22142924825832344, 0.22142924825832344, 0.17432015730641637, 0.17432015730641637, 0.17432015730641637, 0.21383604064488404, 0.21383604064488404, 0.21383604064488404, 0.1991222893581408, 0.1991222893581408, 0.1991222893581408, 0.9214519758708095, 0.9214519758708095, 0.9214519758708095, 0.19782873815407265, 0.19782873815407265, 0.19782873815407265, 0.16703423081725155, 0.16703423081725155, 0.16703423081725155, 0.7813079495778156, 0.7813079495778156, 0.7813079495778156, 0.8772670236555625, 0.8772670236555625, 0.8772670236555625, 0.1278019200030267, 0.1278019200030267, 0.1278019200030267, 0.19595385197274784, 0.19595385197274784, 0.19595385197274784, 0.2321366206474731, 0.2321366206474731, 0.2321366206474731, 0.30476932940259593, 0.30476932940259593, 0.30476932940259593, 0.10377785814755647, 0.10377785814755647, 0.10377785814755647, 0.0997191293234988, 0.0997191293234988, 0.0997191293234988, 0.08449619455232937, 0.08449619455232937, 0.08449619455232937]}, "mutation_prompt": null}
{"id": "8626b560-a567-459c-9c9f-16841d56d99a", "solution": "import numpy as np\n\nclass APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(60, 15 * dim)  # Further increased dynamic population size\n        self.c1 = 1.5  # Slightly reduced cognitive component for more social learning\n        self.c2 = 2.0  # Increased social component to enhance convergence\n        self.w = 0.9  # Increased initial inertia weight to enhance exploration\n        self.decay_rate = 0.95  # Slightly slower inertia decay\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.07  # Increased velocity limit for broader exploration\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "APSO", "description": "Adaptive APSO with dynamically adjusted population size and enhanced exploration to improve convergence speed.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ae31e9bc-6317-48c9-92c9-9f9f2fd6e919", "metadata": {"aucs": [0.8750695916460762, 0.8750695916460762, 0.8750695916460762, 0.867766464271437, 0.867766464271437, 0.867766464271437, 0.8829216776694785, 0.8829216776694785, 0.8829216776694785, 0.7757312735333037, 0.7757312735333037, 0.7757312735333037, 0.760834238877702, 0.760834238877702, 0.760834238877702, 0.7822709434546018, 0.7822709434546018, 0.7822709434546018, 0.15660956782012303, 0.15660956782012303, 0.15660956782012303, 0.10310055453791889, 0.10310055453791889, 0.10310055453791889, 0.12999328707116875, 0.12999328707116875, 0.12999328707116875, 0.08769744498306375, 0.08769744498306375, 0.08769744498306375, 0.08909644904168834, 0.08909644904168834, 0.08909644904168834, 0.12925285687278443, 0.12925285687278443, 0.12925285687278443, 0.9054531320518405, 0.9054531320518405, 0.9054531320518405, 0.9239681555586648, 0.9239681555586648, 0.9239681555586648, 0.9277225917837737, 0.9277225917837737, 0.9277225917837737, 0.6838220528383288, 0.6838220528383288, 0.6838220528383288, 0.7074305755104074, 0.7074305755104074, 0.7074305755104074, 0.7137399340868286, 0.7137399340868286, 0.7137399340868286, 0.21819883069516222, 0.21819883069516222, 0.21819883069516222, 0.2757299909744302, 0.2757299909744302, 0.2757299909744302, 0.23918681438939415, 0.23918681438939415, 0.23918681438939415, 0.21174752724787615, 0.21174752724787615, 0.21174752724787615, 0.19453424222589144, 0.19453424222589144, 0.19453424222589144, 0.1288254650247984, 0.1288254650247984, 0.1288254650247984, 0.12971528326511939, 0.12971528326511939, 0.12971528326511939, 0.3646399771232234, 0.3646399771232234, 0.3646399771232234, 0.20192581126764864, 0.20192581126764864, 0.20192581126764864, 0.13896483125401615, 0.13896483125401615, 0.13896483125401615, 0.025902763703198994, 0.025902763703198994, 0.025902763703198994, 0.08871875983821997, 0.08871875983821997, 0.08871875983821997, 0.09989049097755687, 0.09989049097755687, 0.09989049097755687, 0.017987003204588792, 0.017987003204588792, 0.017987003204588792, 0.16023766976933607, 0.16023766976933607, 0.16023766976933607, 0.048225951927364674, 0.048225951927364674, 0.048225951927364674, 0.10836137970088022, 0.10836137970088022, 0.10836137970088022, 0.13259767120704924, 0.13259767120704924, 0.13259767120704924, 0.13944312791183433, 0.13944312791183433, 0.13944312791183433, 0.11385118586870102, 0.11385118586870102, 0.11385118586870102, 0.15236180270529753, 0.15236180270529753, 0.15236180270529753, 0.5762079010197634, 0.5762079010197634, 0.5762079010197634, 0.5517842009410614, 0.5517842009410614, 0.5517842009410614, 0.5528154242562424, 0.5528154242562424, 0.5528154242562424, 0.05455393348018356, 0.05455393348018356, 0.05455393348018356, 0.07187768499278557, 0.07187768499278557, 0.07187768499278557, 0.09098367439597788, 0.09098367439597788, 0.09098367439597788, 0.20070702153348607, 0.20070702153348607, 0.20070702153348607, 0.22857113568388754, 0.22857113568388754, 0.22857113568388754, 0.19537533380853866, 0.19537533380853866, 0.19537533380853866, 0.4424289380915063, 0.4424289380915063, 0.4424289380915063, 0.44588187995616513, 0.44588187995616513, 0.44588187995616513, 0.5021992546222733, 0.5021992546222733, 0.5021992546222733, 0.31831640789940996, 0.31831640789940996, 0.31831640789940996, 0.25619831479308086, 0.25619831479308086, 0.25619831479308086, 0.252471222512342, 0.252471222512342, 0.252471222512342, 0.23502864768240828, 0.23502864768240828, 0.23502864768240828, 0.22824125606259704, 0.22824125606259704, 0.22824125606259704, 0.22142924825832344, 0.22142924825832344, 0.22142924825832344, 0.17432015730641637, 0.17432015730641637, 0.17432015730641637, 0.21383604064488404, 0.21383604064488404, 0.21383604064488404, 0.1991222893581408, 0.1991222893581408, 0.1991222893581408, 0.9214519758708095, 0.9214519758708095, 0.9214519758708095, 0.19782873815407265, 0.19782873815407265, 0.19782873815407265, 0.16703423081725155, 0.16703423081725155, 0.16703423081725155, 0.7813079495778156, 0.7813079495778156, 0.7813079495778156, 0.8772670236555625, 0.8772670236555625, 0.8772670236555625, 0.1278019200030267, 0.1278019200030267, 0.1278019200030267, 0.19595385197274784, 0.19595385197274784, 0.19595385197274784, 0.2321366206474731, 0.2321366206474731, 0.2321366206474731, 0.30476932940259593, 0.30476932940259593, 0.30476932940259593, 0.10377785814755647, 0.10377785814755647, 0.10377785814755647, 0.0997191293234988, 0.0997191293234988, 0.0997191293234988, 0.08449619455232937, 0.08449619455232937, 0.08449619455232937]}, "mutation_prompt": null}
{"id": "ee06694f-961c-4e92-90b3-25cf06a1c076", "solution": "import numpy as np\n\nclass APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(60, 15 * dim)  # Further increased dynamic population size\n        self.c1 = 1.5  # Slightly reduced cognitive component for more social learning\n        self.c2 = 2.0  # Increased social component to enhance convergence\n        self.w = 0.9  # Increased initial inertia weight to enhance exploration\n        self.decay_rate = 0.95  # Slightly slower inertia decay\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.07  # Increased velocity limit for broader exploration\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "APSO", "description": "Adaptive APSO with dynamically adjusted population size and enhanced exploration to improve convergence speed.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ae31e9bc-6317-48c9-92c9-9f9f2fd6e919", "metadata": {"aucs": [0.8750695916460762, 0.8750695916460762, 0.8750695916460762, 0.867766464271437, 0.867766464271437, 0.867766464271437, 0.8829216776694785, 0.8829216776694785, 0.8829216776694785, 0.7757312735333037, 0.7757312735333037, 0.7757312735333037, 0.760834238877702, 0.760834238877702, 0.760834238877702, 0.7822709434546018, 0.7822709434546018, 0.7822709434546018, 0.15660956782012303, 0.15660956782012303, 0.15660956782012303, 0.10310055453791889, 0.10310055453791889, 0.10310055453791889, 0.12999328707116875, 0.12999328707116875, 0.12999328707116875, 0.08769744498306375, 0.08769744498306375, 0.08769744498306375, 0.08909644904168834, 0.08909644904168834, 0.08909644904168834, 0.12925285687278443, 0.12925285687278443, 0.12925285687278443, 0.9054531320518405, 0.9054531320518405, 0.9054531320518405, 0.9239681555586648, 0.9239681555586648, 0.9239681555586648, 0.9277225917837737, 0.9277225917837737, 0.9277225917837737, 0.6838220528383288, 0.6838220528383288, 0.6838220528383288, 0.7074305755104074, 0.7074305755104074, 0.7074305755104074, 0.7137399340868286, 0.7137399340868286, 0.7137399340868286, 0.21819883069516222, 0.21819883069516222, 0.21819883069516222, 0.2757299909744302, 0.2757299909744302, 0.2757299909744302, 0.23918681438939415, 0.23918681438939415, 0.23918681438939415, 0.21174752724787615, 0.21174752724787615, 0.21174752724787615, 0.19453424222589144, 0.19453424222589144, 0.19453424222589144, 0.1288254650247984, 0.1288254650247984, 0.1288254650247984, 0.12971528326511939, 0.12971528326511939, 0.12971528326511939, 0.3646399771232234, 0.3646399771232234, 0.3646399771232234, 0.20192581126764864, 0.20192581126764864, 0.20192581126764864, 0.13896483125401615, 0.13896483125401615, 0.13896483125401615, 0.025902763703198994, 0.025902763703198994, 0.025902763703198994, 0.08871875983821997, 0.08871875983821997, 0.08871875983821997, 0.09989049097755687, 0.09989049097755687, 0.09989049097755687, 0.017987003204588792, 0.017987003204588792, 0.017987003204588792, 0.16023766976933607, 0.16023766976933607, 0.16023766976933607, 0.048225951927364674, 0.048225951927364674, 0.048225951927364674, 0.10836137970088022, 0.10836137970088022, 0.10836137970088022, 0.13259767120704924, 0.13259767120704924, 0.13259767120704924, 0.13944312791183433, 0.13944312791183433, 0.13944312791183433, 0.11385118586870102, 0.11385118586870102, 0.11385118586870102, 0.15236180270529753, 0.15236180270529753, 0.15236180270529753, 0.5762079010197634, 0.5762079010197634, 0.5762079010197634, 0.5517842009410614, 0.5517842009410614, 0.5517842009410614, 0.5528154242562424, 0.5528154242562424, 0.5528154242562424, 0.05455393348018356, 0.05455393348018356, 0.05455393348018356, 0.07187768499278557, 0.07187768499278557, 0.07187768499278557, 0.09098367439597788, 0.09098367439597788, 0.09098367439597788, 0.20070702153348607, 0.20070702153348607, 0.20070702153348607, 0.22857113568388754, 0.22857113568388754, 0.22857113568388754, 0.19537533380853866, 0.19537533380853866, 0.19537533380853866, 0.4424289380915063, 0.4424289380915063, 0.4424289380915063, 0.44588187995616513, 0.44588187995616513, 0.44588187995616513, 0.5021992546222733, 0.5021992546222733, 0.5021992546222733, 0.31831640789940996, 0.31831640789940996, 0.31831640789940996, 0.25619831479308086, 0.25619831479308086, 0.25619831479308086, 0.252471222512342, 0.252471222512342, 0.252471222512342, 0.23502864768240828, 0.23502864768240828, 0.23502864768240828, 0.22824125606259704, 0.22824125606259704, 0.22824125606259704, 0.22142924825832344, 0.22142924825832344, 0.22142924825832344, 0.17432015730641637, 0.17432015730641637, 0.17432015730641637, 0.21383604064488404, 0.21383604064488404, 0.21383604064488404, 0.1991222893581408, 0.1991222893581408, 0.1991222893581408, 0.9214519758708095, 0.9214519758708095, 0.9214519758708095, 0.19782873815407265, 0.19782873815407265, 0.19782873815407265, 0.16703423081725155, 0.16703423081725155, 0.16703423081725155, 0.7813079495778156, 0.7813079495778156, 0.7813079495778156, 0.8772670236555625, 0.8772670236555625, 0.8772670236555625, 0.1278019200030267, 0.1278019200030267, 0.1278019200030267, 0.19595385197274784, 0.19595385197274784, 0.19595385197274784, 0.2321366206474731, 0.2321366206474731, 0.2321366206474731, 0.30476932940259593, 0.30476932940259593, 0.30476932940259593, 0.10377785814755647, 0.10377785814755647, 0.10377785814755647, 0.0997191293234988, 0.0997191293234988, 0.0997191293234988, 0.08449619455232937, 0.08449619455232937, 0.08449619455232937]}, "mutation_prompt": null}
{"id": "ace7c303-bc69-4462-899e-a2109a26d5f2", "solution": "import numpy as np\n\nclass APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(60, 15 * dim)  # Further increased dynamic population size\n        self.c1 = 1.5  # Slightly reduced cognitive component for more social learning\n        self.c2 = 2.0  # Increased social component to enhance convergence\n        self.w = 0.9  # Increased initial inertia weight to enhance exploration\n        self.decay_rate = 0.95  # Slightly slower inertia decay\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.07  # Increased velocity limit for broader exploration\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "APSO", "description": "Adaptive APSO with dynamically adjusted population size and enhanced exploration to improve convergence speed.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ae31e9bc-6317-48c9-92c9-9f9f2fd6e919", "metadata": {"aucs": [0.8750695916460762, 0.8750695916460762, 0.8750695916460762, 0.867766464271437, 0.867766464271437, 0.867766464271437, 0.8829216776694785, 0.8829216776694785, 0.8829216776694785, 0.7757312735333037, 0.7757312735333037, 0.7757312735333037, 0.760834238877702, 0.760834238877702, 0.760834238877702, 0.7822709434546018, 0.7822709434546018, 0.7822709434546018, 0.15660956782012303, 0.15660956782012303, 0.15660956782012303, 0.10310055453791889, 0.10310055453791889, 0.10310055453791889, 0.12999328707116875, 0.12999328707116875, 0.12999328707116875, 0.08769744498306375, 0.08769744498306375, 0.08769744498306375, 0.08909644904168834, 0.08909644904168834, 0.08909644904168834, 0.12925285687278443, 0.12925285687278443, 0.12925285687278443, 0.9054531320518405, 0.9054531320518405, 0.9054531320518405, 0.9239681555586648, 0.9239681555586648, 0.9239681555586648, 0.9277225917837737, 0.9277225917837737, 0.9277225917837737, 0.6838220528383288, 0.6838220528383288, 0.6838220528383288, 0.7074305755104074, 0.7074305755104074, 0.7074305755104074, 0.7137399340868286, 0.7137399340868286, 0.7137399340868286, 0.21819883069516222, 0.21819883069516222, 0.21819883069516222, 0.2757299909744302, 0.2757299909744302, 0.2757299909744302, 0.23918681438939415, 0.23918681438939415, 0.23918681438939415, 0.21174752724787615, 0.21174752724787615, 0.21174752724787615, 0.19453424222589144, 0.19453424222589144, 0.19453424222589144, 0.1288254650247984, 0.1288254650247984, 0.1288254650247984, 0.12971528326511939, 0.12971528326511939, 0.12971528326511939, 0.3646399771232234, 0.3646399771232234, 0.3646399771232234, 0.20192581126764864, 0.20192581126764864, 0.20192581126764864, 0.13896483125401615, 0.13896483125401615, 0.13896483125401615, 0.025902763703198994, 0.025902763703198994, 0.025902763703198994, 0.08871875983821997, 0.08871875983821997, 0.08871875983821997, 0.09989049097755687, 0.09989049097755687, 0.09989049097755687, 0.017987003204588792, 0.017987003204588792, 0.017987003204588792, 0.16023766976933607, 0.16023766976933607, 0.16023766976933607, 0.048225951927364674, 0.048225951927364674, 0.048225951927364674, 0.10836137970088022, 0.10836137970088022, 0.10836137970088022, 0.13259767120704924, 0.13259767120704924, 0.13259767120704924, 0.13944312791183433, 0.13944312791183433, 0.13944312791183433, 0.11385118586870102, 0.11385118586870102, 0.11385118586870102, 0.15236180270529753, 0.15236180270529753, 0.15236180270529753, 0.5762079010197634, 0.5762079010197634, 0.5762079010197634, 0.5517842009410614, 0.5517842009410614, 0.5517842009410614, 0.5528154242562424, 0.5528154242562424, 0.5528154242562424, 0.05455393348018356, 0.05455393348018356, 0.05455393348018356, 0.07187768499278557, 0.07187768499278557, 0.07187768499278557, 0.09098367439597788, 0.09098367439597788, 0.09098367439597788, 0.20070702153348607, 0.20070702153348607, 0.20070702153348607, 0.22857113568388754, 0.22857113568388754, 0.22857113568388754, 0.19537533380853866, 0.19537533380853866, 0.19537533380853866, 0.4424289380915063, 0.4424289380915063, 0.4424289380915063, 0.44588187995616513, 0.44588187995616513, 0.44588187995616513, 0.5021992546222733, 0.5021992546222733, 0.5021992546222733, 0.31831640789940996, 0.31831640789940996, 0.31831640789940996, 0.25619831479308086, 0.25619831479308086, 0.25619831479308086, 0.252471222512342, 0.252471222512342, 0.252471222512342, 0.23502864768240828, 0.23502864768240828, 0.23502864768240828, 0.22824125606259704, 0.22824125606259704, 0.22824125606259704, 0.22142924825832344, 0.22142924825832344, 0.22142924825832344, 0.17432015730641637, 0.17432015730641637, 0.17432015730641637, 0.21383604064488404, 0.21383604064488404, 0.21383604064488404, 0.1991222893581408, 0.1991222893581408, 0.1991222893581408, 0.9214519758708095, 0.9214519758708095, 0.9214519758708095, 0.19782873815407265, 0.19782873815407265, 0.19782873815407265, 0.16703423081725155, 0.16703423081725155, 0.16703423081725155, 0.7813079495778156, 0.7813079495778156, 0.7813079495778156, 0.8772670236555625, 0.8772670236555625, 0.8772670236555625, 0.1278019200030267, 0.1278019200030267, 0.1278019200030267, 0.19595385197274784, 0.19595385197274784, 0.19595385197274784, 0.2321366206474731, 0.2321366206474731, 0.2321366206474731, 0.30476932940259593, 0.30476932940259593, 0.30476932940259593, 0.10377785814755647, 0.10377785814755647, 0.10377785814755647, 0.0997191293234988, 0.0997191293234988, 0.0997191293234988, 0.08449619455232937, 0.08449619455232937, 0.08449619455232937]}, "mutation_prompt": null}
{"id": "5054f489-54a1-4e53-967c-edb8592800cb", "solution": "import numpy as np\n\nclass APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(60, 15 * dim)  # Further increased dynamic population size\n        self.c1 = 1.5  # Slightly reduced cognitive component for more social learning\n        self.c2 = 2.0  # Increased social component to enhance convergence\n        self.w = 0.9  # Increased initial inertia weight to enhance exploration\n        self.decay_rate = 0.95  # Slightly slower inertia decay\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.07  # Increased velocity limit for broader exploration\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "APSO", "description": "Adaptive APSO with dynamically adjusted population size and enhanced exploration to improve convergence speed.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ae31e9bc-6317-48c9-92c9-9f9f2fd6e919", "metadata": {"aucs": [0.8750695916460762, 0.8750695916460762, 0.8750695916460762, 0.867766464271437, 0.867766464271437, 0.867766464271437, 0.8829216776694785, 0.8829216776694785, 0.8829216776694785, 0.7757312735333037, 0.7757312735333037, 0.7757312735333037, 0.760834238877702, 0.760834238877702, 0.760834238877702, 0.7822709434546018, 0.7822709434546018, 0.7822709434546018, 0.15660956782012303, 0.15660956782012303, 0.15660956782012303, 0.10310055453791889, 0.10310055453791889, 0.10310055453791889, 0.12999328707116875, 0.12999328707116875, 0.12999328707116875, 0.08769744498306375, 0.08769744498306375, 0.08769744498306375, 0.08909644904168834, 0.08909644904168834, 0.08909644904168834, 0.12925285687278443, 0.12925285687278443, 0.12925285687278443, 0.9054531320518405, 0.9054531320518405, 0.9054531320518405, 0.9239681555586648, 0.9239681555586648, 0.9239681555586648, 0.9277225917837737, 0.9277225917837737, 0.9277225917837737, 0.6838220528383288, 0.6838220528383288, 0.6838220528383288, 0.7074305755104074, 0.7074305755104074, 0.7074305755104074, 0.7137399340868286, 0.7137399340868286, 0.7137399340868286, 0.21819883069516222, 0.21819883069516222, 0.21819883069516222, 0.2757299909744302, 0.2757299909744302, 0.2757299909744302, 0.23918681438939415, 0.23918681438939415, 0.23918681438939415, 0.21174752724787615, 0.21174752724787615, 0.21174752724787615, 0.19453424222589144, 0.19453424222589144, 0.19453424222589144, 0.1288254650247984, 0.1288254650247984, 0.1288254650247984, 0.12971528326511939, 0.12971528326511939, 0.12971528326511939, 0.3646399771232234, 0.3646399771232234, 0.3646399771232234, 0.20192581126764864, 0.20192581126764864, 0.20192581126764864, 0.13896483125401615, 0.13896483125401615, 0.13896483125401615, 0.025902763703198994, 0.025902763703198994, 0.025902763703198994, 0.08871875983821997, 0.08871875983821997, 0.08871875983821997, 0.09989049097755687, 0.09989049097755687, 0.09989049097755687, 0.017987003204588792, 0.017987003204588792, 0.017987003204588792, 0.16023766976933607, 0.16023766976933607, 0.16023766976933607, 0.048225951927364674, 0.048225951927364674, 0.048225951927364674, 0.10836137970088022, 0.10836137970088022, 0.10836137970088022, 0.13259767120704924, 0.13259767120704924, 0.13259767120704924, 0.13944312791183433, 0.13944312791183433, 0.13944312791183433, 0.11385118586870102, 0.11385118586870102, 0.11385118586870102, 0.15236180270529753, 0.15236180270529753, 0.15236180270529753, 0.5762079010197634, 0.5762079010197634, 0.5762079010197634, 0.5517842009410614, 0.5517842009410614, 0.5517842009410614, 0.5528154242562424, 0.5528154242562424, 0.5528154242562424, 0.05455393348018356, 0.05455393348018356, 0.05455393348018356, 0.07187768499278557, 0.07187768499278557, 0.07187768499278557, 0.09098367439597788, 0.09098367439597788, 0.09098367439597788, 0.20070702153348607, 0.20070702153348607, 0.20070702153348607, 0.22857113568388754, 0.22857113568388754, 0.22857113568388754, 0.19537533380853866, 0.19537533380853866, 0.19537533380853866, 0.4424289380915063, 0.4424289380915063, 0.4424289380915063, 0.44588187995616513, 0.44588187995616513, 0.44588187995616513, 0.5021992546222733, 0.5021992546222733, 0.5021992546222733, 0.31831640789940996, 0.31831640789940996, 0.31831640789940996, 0.25619831479308086, 0.25619831479308086, 0.25619831479308086, 0.252471222512342, 0.252471222512342, 0.252471222512342, 0.23502864768240828, 0.23502864768240828, 0.23502864768240828, 0.22824125606259704, 0.22824125606259704, 0.22824125606259704, 0.22142924825832344, 0.22142924825832344, 0.22142924825832344, 0.17432015730641637, 0.17432015730641637, 0.17432015730641637, 0.21383604064488404, 0.21383604064488404, 0.21383604064488404, 0.1991222893581408, 0.1991222893581408, 0.1991222893581408, 0.9214519758708095, 0.9214519758708095, 0.9214519758708095, 0.19782873815407265, 0.19782873815407265, 0.19782873815407265, 0.16703423081725155, 0.16703423081725155, 0.16703423081725155, 0.7813079495778156, 0.7813079495778156, 0.7813079495778156, 0.8772670236555625, 0.8772670236555625, 0.8772670236555625, 0.1278019200030267, 0.1278019200030267, 0.1278019200030267, 0.19595385197274784, 0.19595385197274784, 0.19595385197274784, 0.2321366206474731, 0.2321366206474731, 0.2321366206474731, 0.30476932940259593, 0.30476932940259593, 0.30476932940259593, 0.10377785814755647, 0.10377785814755647, 0.10377785814755647, 0.0997191293234988, 0.0997191293234988, 0.0997191293234988, 0.08449619455232937, 0.08449619455232937, 0.08449619455232937]}, "mutation_prompt": null}
{"id": "1c5742e6-da3e-4ee5-8580-6d22118d84fc", "solution": "import numpy as np\n\nclass APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(60, 15 * dim)  # Further increased dynamic population size\n        self.c1 = 1.5  # Slightly reduced cognitive component for more social learning\n        self.c2 = 2.0  # Increased social component to enhance convergence\n        self.w = 0.9  # Increased initial inertia weight to enhance exploration\n        self.decay_rate = 0.95  # Slightly slower inertia decay\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.07  # Increased velocity limit for broader exploration\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "APSO", "description": "Adaptive APSO with dynamically adjusted population size and enhanced exploration to improve convergence speed.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ae31e9bc-6317-48c9-92c9-9f9f2fd6e919", "metadata": {"aucs": [0.8750695916460762, 0.8750695916460762, 0.8750695916460762, 0.867766464271437, 0.867766464271437, 0.867766464271437, 0.8829216776694785, 0.8829216776694785, 0.8829216776694785, 0.7757312735333037, 0.7757312735333037, 0.7757312735333037, 0.760834238877702, 0.760834238877702, 0.760834238877702, 0.7822709434546018, 0.7822709434546018, 0.7822709434546018, 0.15660956782012303, 0.15660956782012303, 0.15660956782012303, 0.10310055453791889, 0.10310055453791889, 0.10310055453791889, 0.12999328707116875, 0.12999328707116875, 0.12999328707116875, 0.08769744498306375, 0.08769744498306375, 0.08769744498306375, 0.08909644904168834, 0.08909644904168834, 0.08909644904168834, 0.12925285687278443, 0.12925285687278443, 0.12925285687278443, 0.9054531320518405, 0.9054531320518405, 0.9054531320518405, 0.9239681555586648, 0.9239681555586648, 0.9239681555586648, 0.9277225917837737, 0.9277225917837737, 0.9277225917837737, 0.6838220528383288, 0.6838220528383288, 0.6838220528383288, 0.7074305755104074, 0.7074305755104074, 0.7074305755104074, 0.7137399340868286, 0.7137399340868286, 0.7137399340868286, 0.21819883069516222, 0.21819883069516222, 0.21819883069516222, 0.2757299909744302, 0.2757299909744302, 0.2757299909744302, 0.23918681438939415, 0.23918681438939415, 0.23918681438939415, 0.21174752724787615, 0.21174752724787615, 0.21174752724787615, 0.19453424222589144, 0.19453424222589144, 0.19453424222589144, 0.1288254650247984, 0.1288254650247984, 0.1288254650247984, 0.12971528326511939, 0.12971528326511939, 0.12971528326511939, 0.3646399771232234, 0.3646399771232234, 0.3646399771232234, 0.20192581126764864, 0.20192581126764864, 0.20192581126764864, 0.13896483125401615, 0.13896483125401615, 0.13896483125401615, 0.025902763703198994, 0.025902763703198994, 0.025902763703198994, 0.08871875983821997, 0.08871875983821997, 0.08871875983821997, 0.09989049097755687, 0.09989049097755687, 0.09989049097755687, 0.017987003204588792, 0.017987003204588792, 0.017987003204588792, 0.16023766976933607, 0.16023766976933607, 0.16023766976933607, 0.048225951927364674, 0.048225951927364674, 0.048225951927364674, 0.10836137970088022, 0.10836137970088022, 0.10836137970088022, 0.13259767120704924, 0.13259767120704924, 0.13259767120704924, 0.13944312791183433, 0.13944312791183433, 0.13944312791183433, 0.11385118586870102, 0.11385118586870102, 0.11385118586870102, 0.15236180270529753, 0.15236180270529753, 0.15236180270529753, 0.5762079010197634, 0.5762079010197634, 0.5762079010197634, 0.5517842009410614, 0.5517842009410614, 0.5517842009410614, 0.5528154242562424, 0.5528154242562424, 0.5528154242562424, 0.05455393348018356, 0.05455393348018356, 0.05455393348018356, 0.07187768499278557, 0.07187768499278557, 0.07187768499278557, 0.09098367439597788, 0.09098367439597788, 0.09098367439597788, 0.20070702153348607, 0.20070702153348607, 0.20070702153348607, 0.22857113568388754, 0.22857113568388754, 0.22857113568388754, 0.19537533380853866, 0.19537533380853866, 0.19537533380853866, 0.4424289380915063, 0.4424289380915063, 0.4424289380915063, 0.44588187995616513, 0.44588187995616513, 0.44588187995616513, 0.5021992546222733, 0.5021992546222733, 0.5021992546222733, 0.31831640789940996, 0.31831640789940996, 0.31831640789940996, 0.25619831479308086, 0.25619831479308086, 0.25619831479308086, 0.252471222512342, 0.252471222512342, 0.252471222512342, 0.23502864768240828, 0.23502864768240828, 0.23502864768240828, 0.22824125606259704, 0.22824125606259704, 0.22824125606259704, 0.22142924825832344, 0.22142924825832344, 0.22142924825832344, 0.17432015730641637, 0.17432015730641637, 0.17432015730641637, 0.21383604064488404, 0.21383604064488404, 0.21383604064488404, 0.1991222893581408, 0.1991222893581408, 0.1991222893581408, 0.9214519758708095, 0.9214519758708095, 0.9214519758708095, 0.19782873815407265, 0.19782873815407265, 0.19782873815407265, 0.16703423081725155, 0.16703423081725155, 0.16703423081725155, 0.7813079495778156, 0.7813079495778156, 0.7813079495778156, 0.8772670236555625, 0.8772670236555625, 0.8772670236555625, 0.1278019200030267, 0.1278019200030267, 0.1278019200030267, 0.19595385197274784, 0.19595385197274784, 0.19595385197274784, 0.2321366206474731, 0.2321366206474731, 0.2321366206474731, 0.30476932940259593, 0.30476932940259593, 0.30476932940259593, 0.10377785814755647, 0.10377785814755647, 0.10377785814755647, 0.0997191293234988, 0.0997191293234988, 0.0997191293234988, 0.08449619455232937, 0.08449619455232937, 0.08449619455232937]}, "mutation_prompt": null}
{"id": "0ef59342-b857-427c-97ec-7a5c60bfc400", "solution": "import numpy as np\n\nclass APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(60, 15 * dim)  # Further increased dynamic population size\n        self.c1 = 1.5  # Slightly reduced cognitive component for more social learning\n        self.c2 = 2.0  # Increased social component to enhance convergence\n        self.w = 0.9  # Increased initial inertia weight to enhance exploration\n        self.decay_rate = 0.95  # Slightly slower inertia decay\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.07  # Increased velocity limit for broader exploration\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "APSO", "description": "Adaptive APSO with dynamically adjusted population size and enhanced exploration to improve convergence speed.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ae31e9bc-6317-48c9-92c9-9f9f2fd6e919", "metadata": {"aucs": [0.8750695916460762, 0.8750695916460762, 0.8750695916460762, 0.867766464271437, 0.867766464271437, 0.867766464271437, 0.8829216776694785, 0.8829216776694785, 0.8829216776694785, 0.7757312735333037, 0.7757312735333037, 0.7757312735333037, 0.760834238877702, 0.760834238877702, 0.760834238877702, 0.7822709434546018, 0.7822709434546018, 0.7822709434546018, 0.15660956782012303, 0.15660956782012303, 0.15660956782012303, 0.10310055453791889, 0.10310055453791889, 0.10310055453791889, 0.12999328707116875, 0.12999328707116875, 0.12999328707116875, 0.08769744498306375, 0.08769744498306375, 0.08769744498306375, 0.08909644904168834, 0.08909644904168834, 0.08909644904168834, 0.12925285687278443, 0.12925285687278443, 0.12925285687278443, 0.9054531320518405, 0.9054531320518405, 0.9054531320518405, 0.9239681555586648, 0.9239681555586648, 0.9239681555586648, 0.9277225917837737, 0.9277225917837737, 0.9277225917837737, 0.6838220528383288, 0.6838220528383288, 0.6838220528383288, 0.7074305755104074, 0.7074305755104074, 0.7074305755104074, 0.7137399340868286, 0.7137399340868286, 0.7137399340868286, 0.21819883069516222, 0.21819883069516222, 0.21819883069516222, 0.2757299909744302, 0.2757299909744302, 0.2757299909744302, 0.23918681438939415, 0.23918681438939415, 0.23918681438939415, 0.21174752724787615, 0.21174752724787615, 0.21174752724787615, 0.19453424222589144, 0.19453424222589144, 0.19453424222589144, 0.1288254650247984, 0.1288254650247984, 0.1288254650247984, 0.12971528326511939, 0.12971528326511939, 0.12971528326511939, 0.3646399771232234, 0.3646399771232234, 0.3646399771232234, 0.20192581126764864, 0.20192581126764864, 0.20192581126764864, 0.13896483125401615, 0.13896483125401615, 0.13896483125401615, 0.025902763703198994, 0.025902763703198994, 0.025902763703198994, 0.08871875983821997, 0.08871875983821997, 0.08871875983821997, 0.09989049097755687, 0.09989049097755687, 0.09989049097755687, 0.017987003204588792, 0.017987003204588792, 0.017987003204588792, 0.16023766976933607, 0.16023766976933607, 0.16023766976933607, 0.048225951927364674, 0.048225951927364674, 0.048225951927364674, 0.10836137970088022, 0.10836137970088022, 0.10836137970088022, 0.13259767120704924, 0.13259767120704924, 0.13259767120704924, 0.13944312791183433, 0.13944312791183433, 0.13944312791183433, 0.11385118586870102, 0.11385118586870102, 0.11385118586870102, 0.15236180270529753, 0.15236180270529753, 0.15236180270529753, 0.5762079010197634, 0.5762079010197634, 0.5762079010197634, 0.5517842009410614, 0.5517842009410614, 0.5517842009410614, 0.5528154242562424, 0.5528154242562424, 0.5528154242562424, 0.05455393348018356, 0.05455393348018356, 0.05455393348018356, 0.07187768499278557, 0.07187768499278557, 0.07187768499278557, 0.09098367439597788, 0.09098367439597788, 0.09098367439597788, 0.20070702153348607, 0.20070702153348607, 0.20070702153348607, 0.22857113568388754, 0.22857113568388754, 0.22857113568388754, 0.19537533380853866, 0.19537533380853866, 0.19537533380853866, 0.4424289380915063, 0.4424289380915063, 0.4424289380915063, 0.44588187995616513, 0.44588187995616513, 0.44588187995616513, 0.5021992546222733, 0.5021992546222733, 0.5021992546222733, 0.31831640789940996, 0.31831640789940996, 0.31831640789940996, 0.25619831479308086, 0.25619831479308086, 0.25619831479308086, 0.252471222512342, 0.252471222512342, 0.252471222512342, 0.23502864768240828, 0.23502864768240828, 0.23502864768240828, 0.22824125606259704, 0.22824125606259704, 0.22824125606259704, 0.22142924825832344, 0.22142924825832344, 0.22142924825832344, 0.17432015730641637, 0.17432015730641637, 0.17432015730641637, 0.21383604064488404, 0.21383604064488404, 0.21383604064488404, 0.1991222893581408, 0.1991222893581408, 0.1991222893581408, 0.9214519758708095, 0.9214519758708095, 0.9214519758708095, 0.19782873815407265, 0.19782873815407265, 0.19782873815407265, 0.16703423081725155, 0.16703423081725155, 0.16703423081725155, 0.7813079495778156, 0.7813079495778156, 0.7813079495778156, 0.8772670236555625, 0.8772670236555625, 0.8772670236555625, 0.1278019200030267, 0.1278019200030267, 0.1278019200030267, 0.19595385197274784, 0.19595385197274784, 0.19595385197274784, 0.2321366206474731, 0.2321366206474731, 0.2321366206474731, 0.30476932940259593, 0.30476932940259593, 0.30476932940259593, 0.10377785814755647, 0.10377785814755647, 0.10377785814755647, 0.0997191293234988, 0.0997191293234988, 0.0997191293234988, 0.08449619455232937, 0.08449619455232937, 0.08449619455232937]}, "mutation_prompt": null}
{"id": "f4fbb4c8-7a98-4823-bb17-fdabf42f784a", "solution": "import numpy as np\n\nclass APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(60, 15 * dim)  # Further increased dynamic population size\n        self.c1 = 1.5  # Slightly reduced cognitive component for more social learning\n        self.c2 = 2.0  # Increased social component to enhance convergence\n        self.w = 0.9  # Increased initial inertia weight to enhance exploration\n        self.decay_rate = 0.95  # Slightly slower inertia decay\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.07  # Increased velocity limit for broader exploration\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "APSO", "description": "Adaptive APSO with dynamically adjusted population size and enhanced exploration to improve convergence speed.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ae31e9bc-6317-48c9-92c9-9f9f2fd6e919", "metadata": {"aucs": [0.8750695916460762, 0.8750695916460762, 0.8750695916460762, 0.867766464271437, 0.867766464271437, 0.867766464271437, 0.8829216776694785, 0.8829216776694785, 0.8829216776694785, 0.7757312735333037, 0.7757312735333037, 0.7757312735333037, 0.760834238877702, 0.760834238877702, 0.760834238877702, 0.7822709434546018, 0.7822709434546018, 0.7822709434546018, 0.15660956782012303, 0.15660956782012303, 0.15660956782012303, 0.10310055453791889, 0.10310055453791889, 0.10310055453791889, 0.12999328707116875, 0.12999328707116875, 0.12999328707116875, 0.08769744498306375, 0.08769744498306375, 0.08769744498306375, 0.08909644904168834, 0.08909644904168834, 0.08909644904168834, 0.12925285687278443, 0.12925285687278443, 0.12925285687278443, 0.9054531320518405, 0.9054531320518405, 0.9054531320518405, 0.9239681555586648, 0.9239681555586648, 0.9239681555586648, 0.9277225917837737, 0.9277225917837737, 0.9277225917837737, 0.6838220528383288, 0.6838220528383288, 0.6838220528383288, 0.7074305755104074, 0.7074305755104074, 0.7074305755104074, 0.7137399340868286, 0.7137399340868286, 0.7137399340868286, 0.21819883069516222, 0.21819883069516222, 0.21819883069516222, 0.2757299909744302, 0.2757299909744302, 0.2757299909744302, 0.23918681438939415, 0.23918681438939415, 0.23918681438939415, 0.21174752724787615, 0.21174752724787615, 0.21174752724787615, 0.19453424222589144, 0.19453424222589144, 0.19453424222589144, 0.1288254650247984, 0.1288254650247984, 0.1288254650247984, 0.12971528326511939, 0.12971528326511939, 0.12971528326511939, 0.3646399771232234, 0.3646399771232234, 0.3646399771232234, 0.20192581126764864, 0.20192581126764864, 0.20192581126764864, 0.13896483125401615, 0.13896483125401615, 0.13896483125401615, 0.025902763703198994, 0.025902763703198994, 0.025902763703198994, 0.08871875983821997, 0.08871875983821997, 0.08871875983821997, 0.09989049097755687, 0.09989049097755687, 0.09989049097755687, 0.017987003204588792, 0.017987003204588792, 0.017987003204588792, 0.16023766976933607, 0.16023766976933607, 0.16023766976933607, 0.048225951927364674, 0.048225951927364674, 0.048225951927364674, 0.10836137970088022, 0.10836137970088022, 0.10836137970088022, 0.13259767120704924, 0.13259767120704924, 0.13259767120704924, 0.13944312791183433, 0.13944312791183433, 0.13944312791183433, 0.11385118586870102, 0.11385118586870102, 0.11385118586870102, 0.15236180270529753, 0.15236180270529753, 0.15236180270529753, 0.5762079010197634, 0.5762079010197634, 0.5762079010197634, 0.5517842009410614, 0.5517842009410614, 0.5517842009410614, 0.5528154242562424, 0.5528154242562424, 0.5528154242562424, 0.05455393348018356, 0.05455393348018356, 0.05455393348018356, 0.07187768499278557, 0.07187768499278557, 0.07187768499278557, 0.09098367439597788, 0.09098367439597788, 0.09098367439597788, 0.20070702153348607, 0.20070702153348607, 0.20070702153348607, 0.22857113568388754, 0.22857113568388754, 0.22857113568388754, 0.19537533380853866, 0.19537533380853866, 0.19537533380853866, 0.4424289380915063, 0.4424289380915063, 0.4424289380915063, 0.44588187995616513, 0.44588187995616513, 0.44588187995616513, 0.5021992546222733, 0.5021992546222733, 0.5021992546222733, 0.31831640789940996, 0.31831640789940996, 0.31831640789940996, 0.25619831479308086, 0.25619831479308086, 0.25619831479308086, 0.252471222512342, 0.252471222512342, 0.252471222512342, 0.23502864768240828, 0.23502864768240828, 0.23502864768240828, 0.22824125606259704, 0.22824125606259704, 0.22824125606259704, 0.22142924825832344, 0.22142924825832344, 0.22142924825832344, 0.17432015730641637, 0.17432015730641637, 0.17432015730641637, 0.21383604064488404, 0.21383604064488404, 0.21383604064488404, 0.1991222893581408, 0.1991222893581408, 0.1991222893581408, 0.9214519758708095, 0.9214519758708095, 0.9214519758708095, 0.19782873815407265, 0.19782873815407265, 0.19782873815407265, 0.16703423081725155, 0.16703423081725155, 0.16703423081725155, 0.7813079495778156, 0.7813079495778156, 0.7813079495778156, 0.8772670236555625, 0.8772670236555625, 0.8772670236555625, 0.1278019200030267, 0.1278019200030267, 0.1278019200030267, 0.19595385197274784, 0.19595385197274784, 0.19595385197274784, 0.2321366206474731, 0.2321366206474731, 0.2321366206474731, 0.30476932940259593, 0.30476932940259593, 0.30476932940259593, 0.10377785814755647, 0.10377785814755647, 0.10377785814755647, 0.0997191293234988, 0.0997191293234988, 0.0997191293234988, 0.08449619455232937, 0.08449619455232937, 0.08449619455232937]}, "mutation_prompt": null}
{"id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(70, 12 * dim)  # Increased particles slightly for diversity\n        self.c1 = 1.4  # Further reduced cognitive component for better balance\n        self.c2 = 2.2  # Further increased social component to leverage collective intelligence\n        self.w = 0.85  # Adjusted inertia weight to balance exploration and exploitation\n        self.decay_rate = 0.93  # Faster decay to reduce inertia over time\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.1  # Increased velocity limit for more aggressive movement\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced APSO with adaptive learning components and improved velocity dynamics for faster convergence.", "configspace": "", "generation": 37, "fitness": 0.3489124961731721, "feedback": "The algorithm EnhancedAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.29.", "error": "", "parent_id": "ae31e9bc-6317-48c9-92c9-9f9f2fd6e919", "metadata": {"aucs": [0.8890345554254235, 0.8890345554254235, 0.8890345554254235, 0.8812898909220918, 0.8812898909220918, 0.8812898909220918, 0.885169648507018, 0.885169648507018, 0.885169648507018, 0.7943252300909807, 0.7943252300909807, 0.7943252300909807, 0.7992832977617781, 0.7992832977617781, 0.7992832977617781, 0.806978601700252, 0.806978601700252, 0.806978601700252, 0.141836067863071, 0.141836067863071, 0.141836067863071, 0.09072257940144113, 0.09072257940144113, 0.09072257940144113, 0.11538296000510384, 0.11538296000510384, 0.11538296000510384, 0.09182634705732529, 0.09182634705732529, 0.09182634705732529, 0.10396507449566983, 0.10396507449566983, 0.10396507449566983, 0.12877403769140183, 0.12877403769140183, 0.12877403769140183, 0.9171003036492754, 0.9171003036492754, 0.9171003036492754, 0.9426071411196885, 0.9426071411196885, 0.9426071411196885, 0.947537189438548, 0.947537189438548, 0.947537189438548, 0.6001545147287968, 0.6001545147287968, 0.6001545147287968, 0.684584432385599, 0.684584432385599, 0.684584432385599, 0.5898963208656243, 0.5898963208656243, 0.5898963208656243, 0.19375146093521256, 0.19375146093521256, 0.19375146093521256, 0.8693944340969452, 0.8693944340969452, 0.8693944340969452, 0.748951913666398, 0.748951913666398, 0.748951913666398, 0.21327141745353018, 0.21327141745353018, 0.21327141745353018, 0.20118277962625464, 0.20118277962625464, 0.20118277962625464, 0.22068388192974941, 0.22068388192974941, 0.22068388192974941, 0.23075865172070587, 0.23075865172070587, 0.23075865172070587, 0.2135229554500695, 0.2135229554500695, 0.2135229554500695, 0.23668946202621444, 0.23668946202621444, 0.23668946202621444, 0.005148868860398448, 0.005148868860398448, 0.005148868860398448, 0.08177194701312396, 0.08177194701312396, 0.08177194701312396, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08208764747391684, 0.08208764747391684, 0.08208764747391684, 0.05568690635405671, 0.05568690635405671, 0.05568690635405671, 0.11343134532868715, 0.11343134532868715, 0.11343134532868715, 0.04909694094295114, 0.04909694094295114, 0.04909694094295114, 0.11383841177004017, 0.11383841177004017, 0.11383841177004017, 0.26109733429390813, 0.26109733429390813, 0.26109733429390813, 0.25317053091270736, 0.25317053091270736, 0.25317053091270736, 0.10090994703812939, 0.10090994703812939, 0.10090994703812939, 0.11422164786062972, 0.11422164786062972, 0.11422164786062972, 0.5212488269937966, 0.5212488269937966, 0.5212488269937966, 0.6092900456626009, 0.6092900456626009, 0.6092900456626009, 0.5657986694000723, 0.5657986694000723, 0.5657986694000723, 0.07625858721913681, 0.07625858721913681, 0.07625858721913681, 0.11353684310069889, 0.11353684310069889, 0.11353684310069889, 0.13349225556029598, 0.13349225556029598, 0.13349225556029598, 0.2923087655110267, 0.2923087655110267, 0.2923087655110267, 0.17058849530006337, 0.17058849530006337, 0.17058849530006337, 0.36867958361848363, 0.36867958361848363, 0.36867958361848363, 0.40865239548570576, 0.40865239548570576, 0.40865239548570576, 0.39714577174572396, 0.39714577174572396, 0.39714577174572396, 0.2695926147327291, 0.2695926147327291, 0.2695926147327291, 0.21811446266173207, 0.21811446266173207, 0.21811446266173207, 0.34268712567274884, 0.34268712567274884, 0.34268712567274884, 0.22874659868451208, 0.22874659868451208, 0.22874659868451208, 0.21928541749058428, 0.21928541749058428, 0.21928541749058428, 0.22679558567235403, 0.22679558567235403, 0.22679558567235403, 0.2801068714944557, 0.2801068714944557, 0.2801068714944557, 0.24859292531735677, 0.24859292531735677, 0.24859292531735677, 0.22841934362266458, 0.22841934362266458, 0.22841934362266458, 0.2168144089226336, 0.2168144089226336, 0.2168144089226336, 0.9271356183668746, 0.9271356183668746, 0.9271356183668746, 0.11420627305427256, 0.11420627305427256, 0.11420627305427256, 0.1366109952920993, 0.1366109952920993, 0.1366109952920993, 0.6716788495300214, 0.6716788495300214, 0.6716788495300214, 0.6525119270873981, 0.6525119270873981, 0.6525119270873981, 0.7335310158747503, 0.7335310158747503, 0.7335310158747503, 0.22509205180813374, 0.22509205180813374, 0.22509205180813374, 0.23846259715961882, 0.23846259715961882, 0.23846259715961882, 0.23026115778748257, 0.23026115778748257, 0.23026115778748257, 0.10729408229532489, 0.10729408229532489, 0.10729408229532489, 0.08707462555969336, 0.08707462555969336, 0.08707462555969336, 0.09244825892062858, 0.09244825892062858, 0.09244825892062858]}, "mutation_prompt": null}
{"id": "f65c8975-24fc-4724-aff1-ab6f604c7b86", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(70, 12 * dim)  # Increased particles slightly for diversity\n        self.c1 = 1.4  # Further reduced cognitive component for better balance\n        self.c2 = 2.2  # Further increased social component to leverage collective intelligence\n        self.w = 0.85  # Adjusted inertia weight to balance exploration and exploitation\n        self.decay_rate = 0.93  # Faster decay to reduce inertia over time\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.1  # Increased velocity limit for more aggressive movement\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced APSO with adaptive learning components and improved velocity dynamics for faster convergence.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.8890345554254235, 0.8890345554254235, 0.8890345554254235, 0.8812898909220918, 0.8812898909220918, 0.8812898909220918, 0.885169648507018, 0.885169648507018, 0.885169648507018, 0.7943252300909807, 0.7943252300909807, 0.7943252300909807, 0.7992832977617781, 0.7992832977617781, 0.7992832977617781, 0.806978601700252, 0.806978601700252, 0.806978601700252, 0.141836067863071, 0.141836067863071, 0.141836067863071, 0.09072257940144113, 0.09072257940144113, 0.09072257940144113, 0.11538296000510384, 0.11538296000510384, 0.11538296000510384, 0.09182634705732529, 0.09182634705732529, 0.09182634705732529, 0.10396507449566983, 0.10396507449566983, 0.10396507449566983, 0.12877403769140183, 0.12877403769140183, 0.12877403769140183, 0.9171003036492754, 0.9171003036492754, 0.9171003036492754, 0.9426071411196885, 0.9426071411196885, 0.9426071411196885, 0.947537189438548, 0.947537189438548, 0.947537189438548, 0.6001545147287968, 0.6001545147287968, 0.6001545147287968, 0.684584432385599, 0.684584432385599, 0.684584432385599, 0.5898963208656243, 0.5898963208656243, 0.5898963208656243, 0.19375146093521256, 0.19375146093521256, 0.19375146093521256, 0.8693944340969452, 0.8693944340969452, 0.8693944340969452, 0.748951913666398, 0.748951913666398, 0.748951913666398, 0.21327141745353018, 0.21327141745353018, 0.21327141745353018, 0.20118277962625464, 0.20118277962625464, 0.20118277962625464, 0.22068388192974941, 0.22068388192974941, 0.22068388192974941, 0.23075865172070587, 0.23075865172070587, 0.23075865172070587, 0.2135229554500695, 0.2135229554500695, 0.2135229554500695, 0.23668946202621444, 0.23668946202621444, 0.23668946202621444, 0.005148868860398448, 0.005148868860398448, 0.005148868860398448, 0.08177194701312396, 0.08177194701312396, 0.08177194701312396, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08208764747391684, 0.08208764747391684, 0.08208764747391684, 0.05568690635405671, 0.05568690635405671, 0.05568690635405671, 0.11343134532868715, 0.11343134532868715, 0.11343134532868715, 0.04909694094295114, 0.04909694094295114, 0.04909694094295114, 0.11383841177004017, 0.11383841177004017, 0.11383841177004017, 0.26109733429390813, 0.26109733429390813, 0.26109733429390813, 0.25317053091270736, 0.25317053091270736, 0.25317053091270736, 0.10090994703812939, 0.10090994703812939, 0.10090994703812939, 0.11422164786062972, 0.11422164786062972, 0.11422164786062972, 0.5212488269937966, 0.5212488269937966, 0.5212488269937966, 0.6092900456626009, 0.6092900456626009, 0.6092900456626009, 0.5657986694000723, 0.5657986694000723, 0.5657986694000723, 0.07625858721913681, 0.07625858721913681, 0.07625858721913681, 0.11353684310069889, 0.11353684310069889, 0.11353684310069889, 0.13349225556029598, 0.13349225556029598, 0.13349225556029598, 0.2923087655110267, 0.2923087655110267, 0.2923087655110267, 0.17058849530006337, 0.17058849530006337, 0.17058849530006337, 0.36867958361848363, 0.36867958361848363, 0.36867958361848363, 0.40865239548570576, 0.40865239548570576, 0.40865239548570576, 0.39714577174572396, 0.39714577174572396, 0.39714577174572396, 0.2695926147327291, 0.2695926147327291, 0.2695926147327291, 0.21811446266173207, 0.21811446266173207, 0.21811446266173207, 0.34268712567274884, 0.34268712567274884, 0.34268712567274884, 0.22874659868451208, 0.22874659868451208, 0.22874659868451208, 0.21928541749058428, 0.21928541749058428, 0.21928541749058428, 0.22679558567235403, 0.22679558567235403, 0.22679558567235403, 0.2801068714944557, 0.2801068714944557, 0.2801068714944557, 0.24859292531735677, 0.24859292531735677, 0.24859292531735677, 0.22841934362266458, 0.22841934362266458, 0.22841934362266458, 0.2168144089226336, 0.2168144089226336, 0.2168144089226336, 0.9271356183668746, 0.9271356183668746, 0.9271356183668746, 0.11420627305427256, 0.11420627305427256, 0.11420627305427256, 0.1366109952920993, 0.1366109952920993, 0.1366109952920993, 0.6716788495300214, 0.6716788495300214, 0.6716788495300214, 0.6525119270873981, 0.6525119270873981, 0.6525119270873981, 0.7335310158747503, 0.7335310158747503, 0.7335310158747503, 0.22509205180813374, 0.22509205180813374, 0.22509205180813374, 0.23846259715961882, 0.23846259715961882, 0.23846259715961882, 0.23026115778748257, 0.23026115778748257, 0.23026115778748257, 0.10729408229532489, 0.10729408229532489, 0.10729408229532489, 0.08707462555969336, 0.08707462555969336, 0.08707462555969336, 0.09244825892062858, 0.09244825892062858, 0.09244825892062858]}, "mutation_prompt": null}
{"id": "fc99fa0a-9d5a-4821-aded-6dad8024ac24", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(80, 10 * dim)  # Adjusted particles for dynamic exploration\n        self.c1 = 1.5  # Adjusted cognitive component for better individual exploration\n        self.c2 = 2.1  # Slightly reduced social component for more controlled convergence\n        self.w = 0.8  # Further reduced inertia weight for quicker convergence\n        self.decay_rate = 0.95  # Slowed decay to maintain momentum longer\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.15  # Increased velocity limit for more aggressive movement\n        self.max_swarm_size = min(100, 15 * dim)  # New dynamic maximum swarm size\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        adaptive_c1 = self.c1  # Introduce adaptive c1\n        adaptive_c2 = self.c2  # Introduce adaptive c2\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          adaptive_c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          adaptive_c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            adaptive_c1 = self.c1 * (1 - evaluations / self.budget)  # Decrease c1 over time\n            adaptive_c2 = self.c2 * (1 + evaluations / self.budget)  # Increase c2 over time\n            self.w *= self.decay_rate  # Decay inertia weight\n            \n            # Dynamic swarm size adjustment\n            if evaluations < self.budget * 0.5:\n                self.num_particles = min(self.max_swarm_size, self.num_particles + 1)\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced APSO with adaptive acceleration coefficients and a dynamic swarm size to boost convergence speed.", "configspace": "", "generation": 39, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 50 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 50 is out of bounds for axis 0 with size 50')", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {}, "mutation_prompt": null}
{"id": "8dc39284-e707-431a-b111-f0e267b40f73", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(70, 12 * dim)  # Increased particles slightly for diversity\n        self.c1 = 1.4  # Further reduced cognitive component for better balance\n        self.c2 = 2.2  # Further increased social component to leverage collective intelligence\n        self.w = 0.85  # Adjusted inertia weight to balance exploration and exploitation\n        self.decay_rate = 0.93  # Faster decay to reduce inertia over time\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.1  # Increased velocity limit for more aggressive movement\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced APSO with adaptive learning components and improved velocity dynamics for faster convergence.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.8890345554254235, 0.8890345554254235, 0.8890345554254235, 0.8812898909220918, 0.8812898909220918, 0.8812898909220918, 0.885169648507018, 0.885169648507018, 0.885169648507018, 0.7943252300909807, 0.7943252300909807, 0.7943252300909807, 0.7992832977617781, 0.7992832977617781, 0.7992832977617781, 0.806978601700252, 0.806978601700252, 0.806978601700252, 0.141836067863071, 0.141836067863071, 0.141836067863071, 0.09072257940144113, 0.09072257940144113, 0.09072257940144113, 0.11538296000510384, 0.11538296000510384, 0.11538296000510384, 0.09182634705732529, 0.09182634705732529, 0.09182634705732529, 0.10396507449566983, 0.10396507449566983, 0.10396507449566983, 0.12877403769140183, 0.12877403769140183, 0.12877403769140183, 0.9171003036492754, 0.9171003036492754, 0.9171003036492754, 0.9426071411196885, 0.9426071411196885, 0.9426071411196885, 0.947537189438548, 0.947537189438548, 0.947537189438548, 0.6001545147287968, 0.6001545147287968, 0.6001545147287968, 0.684584432385599, 0.684584432385599, 0.684584432385599, 0.5898963208656243, 0.5898963208656243, 0.5898963208656243, 0.19375146093521256, 0.19375146093521256, 0.19375146093521256, 0.8693944340969452, 0.8693944340969452, 0.8693944340969452, 0.748951913666398, 0.748951913666398, 0.748951913666398, 0.21327141745353018, 0.21327141745353018, 0.21327141745353018, 0.20118277962625464, 0.20118277962625464, 0.20118277962625464, 0.22068388192974941, 0.22068388192974941, 0.22068388192974941, 0.23075865172070587, 0.23075865172070587, 0.23075865172070587, 0.2135229554500695, 0.2135229554500695, 0.2135229554500695, 0.23668946202621444, 0.23668946202621444, 0.23668946202621444, 0.005148868860398448, 0.005148868860398448, 0.005148868860398448, 0.08177194701312396, 0.08177194701312396, 0.08177194701312396, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08208764747391684, 0.08208764747391684, 0.08208764747391684, 0.05568690635405671, 0.05568690635405671, 0.05568690635405671, 0.11343134532868715, 0.11343134532868715, 0.11343134532868715, 0.04909694094295114, 0.04909694094295114, 0.04909694094295114, 0.11383841177004017, 0.11383841177004017, 0.11383841177004017, 0.26109733429390813, 0.26109733429390813, 0.26109733429390813, 0.25317053091270736, 0.25317053091270736, 0.25317053091270736, 0.10090994703812939, 0.10090994703812939, 0.10090994703812939, 0.11422164786062972, 0.11422164786062972, 0.11422164786062972, 0.5212488269937966, 0.5212488269937966, 0.5212488269937966, 0.6092900456626009, 0.6092900456626009, 0.6092900456626009, 0.5657986694000723, 0.5657986694000723, 0.5657986694000723, 0.07625858721913681, 0.07625858721913681, 0.07625858721913681, 0.11353684310069889, 0.11353684310069889, 0.11353684310069889, 0.13349225556029598, 0.13349225556029598, 0.13349225556029598, 0.2923087655110267, 0.2923087655110267, 0.2923087655110267, 0.17058849530006337, 0.17058849530006337, 0.17058849530006337, 0.36867958361848363, 0.36867958361848363, 0.36867958361848363, 0.40865239548570576, 0.40865239548570576, 0.40865239548570576, 0.39714577174572396, 0.39714577174572396, 0.39714577174572396, 0.2695926147327291, 0.2695926147327291, 0.2695926147327291, 0.21811446266173207, 0.21811446266173207, 0.21811446266173207, 0.34268712567274884, 0.34268712567274884, 0.34268712567274884, 0.22874659868451208, 0.22874659868451208, 0.22874659868451208, 0.21928541749058428, 0.21928541749058428, 0.21928541749058428, 0.22679558567235403, 0.22679558567235403, 0.22679558567235403, 0.2801068714944557, 0.2801068714944557, 0.2801068714944557, 0.24859292531735677, 0.24859292531735677, 0.24859292531735677, 0.22841934362266458, 0.22841934362266458, 0.22841934362266458, 0.2168144089226336, 0.2168144089226336, 0.2168144089226336, 0.9271356183668746, 0.9271356183668746, 0.9271356183668746, 0.11420627305427256, 0.11420627305427256, 0.11420627305427256, 0.1366109952920993, 0.1366109952920993, 0.1366109952920993, 0.6716788495300214, 0.6716788495300214, 0.6716788495300214, 0.6525119270873981, 0.6525119270873981, 0.6525119270873981, 0.7335310158747503, 0.7335310158747503, 0.7335310158747503, 0.22509205180813374, 0.22509205180813374, 0.22509205180813374, 0.23846259715961882, 0.23846259715961882, 0.23846259715961882, 0.23026115778748257, 0.23026115778748257, 0.23026115778748257, 0.10729408229532489, 0.10729408229532489, 0.10729408229532489, 0.08707462555969336, 0.08707462555969336, 0.08707462555969336, 0.09244825892062858, 0.09244825892062858, 0.09244825892062858]}, "mutation_prompt": null}
{"id": "8ba0122d-05c4-4bb8-b6a7-2791280a1429", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(70, 12 * dim)  # Increased particles slightly for diversity\n        self.c1 = 1.4  # Further reduced cognitive component for better balance\n        self.c2 = 2.2  # Further increased social component to leverage collective intelligence\n        self.w = 0.85  # Adjusted inertia weight to balance exploration and exploitation\n        self.decay_rate = 0.93  # Faster decay to reduce inertia over time\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.1  # Increased velocity limit for more aggressive movement\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced APSO with adaptive learning components and improved velocity dynamics for faster convergence.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.8890345554254235, 0.8890345554254235, 0.8890345554254235, 0.8812898909220918, 0.8812898909220918, 0.8812898909220918, 0.885169648507018, 0.885169648507018, 0.885169648507018, 0.7943252300909807, 0.7943252300909807, 0.7943252300909807, 0.7992832977617781, 0.7992832977617781, 0.7992832977617781, 0.806978601700252, 0.806978601700252, 0.806978601700252, 0.141836067863071, 0.141836067863071, 0.141836067863071, 0.09072257940144113, 0.09072257940144113, 0.09072257940144113, 0.11538296000510384, 0.11538296000510384, 0.11538296000510384, 0.09182634705732529, 0.09182634705732529, 0.09182634705732529, 0.10396507449566983, 0.10396507449566983, 0.10396507449566983, 0.12877403769140183, 0.12877403769140183, 0.12877403769140183, 0.9171003036492754, 0.9171003036492754, 0.9171003036492754, 0.9426071411196885, 0.9426071411196885, 0.9426071411196885, 0.947537189438548, 0.947537189438548, 0.947537189438548, 0.6001545147287968, 0.6001545147287968, 0.6001545147287968, 0.684584432385599, 0.684584432385599, 0.684584432385599, 0.5898963208656243, 0.5898963208656243, 0.5898963208656243, 0.19375146093521256, 0.19375146093521256, 0.19375146093521256, 0.8693944340969452, 0.8693944340969452, 0.8693944340969452, 0.748951913666398, 0.748951913666398, 0.748951913666398, 0.21327141745353018, 0.21327141745353018, 0.21327141745353018, 0.20118277962625464, 0.20118277962625464, 0.20118277962625464, 0.22068388192974941, 0.22068388192974941, 0.22068388192974941, 0.23075865172070587, 0.23075865172070587, 0.23075865172070587, 0.2135229554500695, 0.2135229554500695, 0.2135229554500695, 0.23668946202621444, 0.23668946202621444, 0.23668946202621444, 0.005148868860398448, 0.005148868860398448, 0.005148868860398448, 0.08177194701312396, 0.08177194701312396, 0.08177194701312396, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08208764747391684, 0.08208764747391684, 0.08208764747391684, 0.05568690635405671, 0.05568690635405671, 0.05568690635405671, 0.11343134532868715, 0.11343134532868715, 0.11343134532868715, 0.04909694094295114, 0.04909694094295114, 0.04909694094295114, 0.11383841177004017, 0.11383841177004017, 0.11383841177004017, 0.26109733429390813, 0.26109733429390813, 0.26109733429390813, 0.25317053091270736, 0.25317053091270736, 0.25317053091270736, 0.10090994703812939, 0.10090994703812939, 0.10090994703812939, 0.11422164786062972, 0.11422164786062972, 0.11422164786062972, 0.5212488269937966, 0.5212488269937966, 0.5212488269937966, 0.6092900456626009, 0.6092900456626009, 0.6092900456626009, 0.5657986694000723, 0.5657986694000723, 0.5657986694000723, 0.07625858721913681, 0.07625858721913681, 0.07625858721913681, 0.11353684310069889, 0.11353684310069889, 0.11353684310069889, 0.13349225556029598, 0.13349225556029598, 0.13349225556029598, 0.2923087655110267, 0.2923087655110267, 0.2923087655110267, 0.17058849530006337, 0.17058849530006337, 0.17058849530006337, 0.36867958361848363, 0.36867958361848363, 0.36867958361848363, 0.40865239548570576, 0.40865239548570576, 0.40865239548570576, 0.39714577174572396, 0.39714577174572396, 0.39714577174572396, 0.2695926147327291, 0.2695926147327291, 0.2695926147327291, 0.21811446266173207, 0.21811446266173207, 0.21811446266173207, 0.34268712567274884, 0.34268712567274884, 0.34268712567274884, 0.22874659868451208, 0.22874659868451208, 0.22874659868451208, 0.21928541749058428, 0.21928541749058428, 0.21928541749058428, 0.22679558567235403, 0.22679558567235403, 0.22679558567235403, 0.2801068714944557, 0.2801068714944557, 0.2801068714944557, 0.24859292531735677, 0.24859292531735677, 0.24859292531735677, 0.22841934362266458, 0.22841934362266458, 0.22841934362266458, 0.2168144089226336, 0.2168144089226336, 0.2168144089226336, 0.9271356183668746, 0.9271356183668746, 0.9271356183668746, 0.11420627305427256, 0.11420627305427256, 0.11420627305427256, 0.1366109952920993, 0.1366109952920993, 0.1366109952920993, 0.6716788495300214, 0.6716788495300214, 0.6716788495300214, 0.6525119270873981, 0.6525119270873981, 0.6525119270873981, 0.7335310158747503, 0.7335310158747503, 0.7335310158747503, 0.22509205180813374, 0.22509205180813374, 0.22509205180813374, 0.23846259715961882, 0.23846259715961882, 0.23846259715961882, 0.23026115778748257, 0.23026115778748257, 0.23026115778748257, 0.10729408229532489, 0.10729408229532489, 0.10729408229532489, 0.08707462555969336, 0.08707462555969336, 0.08707462555969336, 0.09244825892062858, 0.09244825892062858, 0.09244825892062858]}, "mutation_prompt": null}
{"id": "cc670ea7-38e1-4e5e-b1fb-e5b8f6488d53", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(70, 12 * dim)  # Increased particles slightly for diversity\n        self.c1 = 1.4  # Further reduced cognitive component for better balance\n        self.c2 = 2.2  # Further increased social component to leverage collective intelligence\n        self.w = 0.85  # Adjusted inertia weight to balance exploration and exploitation\n        self.decay_rate = 0.93  # Faster decay to reduce inertia over time\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.1  # Increased velocity limit for more aggressive movement\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced APSO with adaptive learning components and improved velocity dynamics for faster convergence.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.8890345554254235, 0.8890345554254235, 0.8890345554254235, 0.8812898909220918, 0.8812898909220918, 0.8812898909220918, 0.885169648507018, 0.885169648507018, 0.885169648507018, 0.7943252300909807, 0.7943252300909807, 0.7943252300909807, 0.7992832977617781, 0.7992832977617781, 0.7992832977617781, 0.806978601700252, 0.806978601700252, 0.806978601700252, 0.141836067863071, 0.141836067863071, 0.141836067863071, 0.09072257940144113, 0.09072257940144113, 0.09072257940144113, 0.11538296000510384, 0.11538296000510384, 0.11538296000510384, 0.09182634705732529, 0.09182634705732529, 0.09182634705732529, 0.10396507449566983, 0.10396507449566983, 0.10396507449566983, 0.12877403769140183, 0.12877403769140183, 0.12877403769140183, 0.9171003036492754, 0.9171003036492754, 0.9171003036492754, 0.9426071411196885, 0.9426071411196885, 0.9426071411196885, 0.947537189438548, 0.947537189438548, 0.947537189438548, 0.6001545147287968, 0.6001545147287968, 0.6001545147287968, 0.684584432385599, 0.684584432385599, 0.684584432385599, 0.5898963208656243, 0.5898963208656243, 0.5898963208656243, 0.19375146093521256, 0.19375146093521256, 0.19375146093521256, 0.8693944340969452, 0.8693944340969452, 0.8693944340969452, 0.748951913666398, 0.748951913666398, 0.748951913666398, 0.21327141745353018, 0.21327141745353018, 0.21327141745353018, 0.20118277962625464, 0.20118277962625464, 0.20118277962625464, 0.22068388192974941, 0.22068388192974941, 0.22068388192974941, 0.23075865172070587, 0.23075865172070587, 0.23075865172070587, 0.2135229554500695, 0.2135229554500695, 0.2135229554500695, 0.23668946202621444, 0.23668946202621444, 0.23668946202621444, 0.005148868860398448, 0.005148868860398448, 0.005148868860398448, 0.08177194701312396, 0.08177194701312396, 0.08177194701312396, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08208764747391684, 0.08208764747391684, 0.08208764747391684, 0.05568690635405671, 0.05568690635405671, 0.05568690635405671, 0.11343134532868715, 0.11343134532868715, 0.11343134532868715, 0.04909694094295114, 0.04909694094295114, 0.04909694094295114, 0.11383841177004017, 0.11383841177004017, 0.11383841177004017, 0.26109733429390813, 0.26109733429390813, 0.26109733429390813, 0.25317053091270736, 0.25317053091270736, 0.25317053091270736, 0.10090994703812939, 0.10090994703812939, 0.10090994703812939, 0.11422164786062972, 0.11422164786062972, 0.11422164786062972, 0.5212488269937966, 0.5212488269937966, 0.5212488269937966, 0.6092900456626009, 0.6092900456626009, 0.6092900456626009, 0.5657986694000723, 0.5657986694000723, 0.5657986694000723, 0.07625858721913681, 0.07625858721913681, 0.07625858721913681, 0.11353684310069889, 0.11353684310069889, 0.11353684310069889, 0.13349225556029598, 0.13349225556029598, 0.13349225556029598, 0.2923087655110267, 0.2923087655110267, 0.2923087655110267, 0.17058849530006337, 0.17058849530006337, 0.17058849530006337, 0.36867958361848363, 0.36867958361848363, 0.36867958361848363, 0.40865239548570576, 0.40865239548570576, 0.40865239548570576, 0.39714577174572396, 0.39714577174572396, 0.39714577174572396, 0.2695926147327291, 0.2695926147327291, 0.2695926147327291, 0.21811446266173207, 0.21811446266173207, 0.21811446266173207, 0.34268712567274884, 0.34268712567274884, 0.34268712567274884, 0.22874659868451208, 0.22874659868451208, 0.22874659868451208, 0.21928541749058428, 0.21928541749058428, 0.21928541749058428, 0.22679558567235403, 0.22679558567235403, 0.22679558567235403, 0.2801068714944557, 0.2801068714944557, 0.2801068714944557, 0.24859292531735677, 0.24859292531735677, 0.24859292531735677, 0.22841934362266458, 0.22841934362266458, 0.22841934362266458, 0.2168144089226336, 0.2168144089226336, 0.2168144089226336, 0.9271356183668746, 0.9271356183668746, 0.9271356183668746, 0.11420627305427256, 0.11420627305427256, 0.11420627305427256, 0.1366109952920993, 0.1366109952920993, 0.1366109952920993, 0.6716788495300214, 0.6716788495300214, 0.6716788495300214, 0.6525119270873981, 0.6525119270873981, 0.6525119270873981, 0.7335310158747503, 0.7335310158747503, 0.7335310158747503, 0.22509205180813374, 0.22509205180813374, 0.22509205180813374, 0.23846259715961882, 0.23846259715961882, 0.23846259715961882, 0.23026115778748257, 0.23026115778748257, 0.23026115778748257, 0.10729408229532489, 0.10729408229532489, 0.10729408229532489, 0.08707462555969336, 0.08707462555969336, 0.08707462555969336, 0.09244825892062858, 0.09244825892062858, 0.09244825892062858]}, "mutation_prompt": null}
{"id": "63a76d88-ddc6-4131-a0f3-7f3afb1ac218", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(70, 12 * dim)  # Increased particles slightly for diversity\n        self.c1 = 1.4  # Further reduced cognitive component for better balance\n        self.c2 = 2.2  # Further increased social component to leverage collective intelligence\n        self.w = 0.85  # Adjusted inertia weight to balance exploration and exploitation\n        self.decay_rate = 0.93  # Faster decay to reduce inertia over time\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.1  # Increased velocity limit for more aggressive movement\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced APSO with adaptive learning components and improved velocity dynamics for faster convergence.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.8890345554254235, 0.8890345554254235, 0.8890345554254235, 0.8812898909220918, 0.8812898909220918, 0.8812898909220918, 0.885169648507018, 0.885169648507018, 0.885169648507018, 0.7943252300909807, 0.7943252300909807, 0.7943252300909807, 0.7992832977617781, 0.7992832977617781, 0.7992832977617781, 0.806978601700252, 0.806978601700252, 0.806978601700252, 0.141836067863071, 0.141836067863071, 0.141836067863071, 0.09072257940144113, 0.09072257940144113, 0.09072257940144113, 0.11538296000510384, 0.11538296000510384, 0.11538296000510384, 0.09182634705732529, 0.09182634705732529, 0.09182634705732529, 0.10396507449566983, 0.10396507449566983, 0.10396507449566983, 0.12877403769140183, 0.12877403769140183, 0.12877403769140183, 0.9171003036492754, 0.9171003036492754, 0.9171003036492754, 0.9426071411196885, 0.9426071411196885, 0.9426071411196885, 0.947537189438548, 0.947537189438548, 0.947537189438548, 0.6001545147287968, 0.6001545147287968, 0.6001545147287968, 0.684584432385599, 0.684584432385599, 0.684584432385599, 0.5898963208656243, 0.5898963208656243, 0.5898963208656243, 0.19375146093521256, 0.19375146093521256, 0.19375146093521256, 0.8693944340969452, 0.8693944340969452, 0.8693944340969452, 0.748951913666398, 0.748951913666398, 0.748951913666398, 0.21327141745353018, 0.21327141745353018, 0.21327141745353018, 0.20118277962625464, 0.20118277962625464, 0.20118277962625464, 0.22068388192974941, 0.22068388192974941, 0.22068388192974941, 0.23075865172070587, 0.23075865172070587, 0.23075865172070587, 0.2135229554500695, 0.2135229554500695, 0.2135229554500695, 0.23668946202621444, 0.23668946202621444, 0.23668946202621444, 0.005148868860398448, 0.005148868860398448, 0.005148868860398448, 0.08177194701312396, 0.08177194701312396, 0.08177194701312396, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08208764747391684, 0.08208764747391684, 0.08208764747391684, 0.05568690635405671, 0.05568690635405671, 0.05568690635405671, 0.11343134532868715, 0.11343134532868715, 0.11343134532868715, 0.04909694094295114, 0.04909694094295114, 0.04909694094295114, 0.11383841177004017, 0.11383841177004017, 0.11383841177004017, 0.26109733429390813, 0.26109733429390813, 0.26109733429390813, 0.25317053091270736, 0.25317053091270736, 0.25317053091270736, 0.10090994703812939, 0.10090994703812939, 0.10090994703812939, 0.11422164786062972, 0.11422164786062972, 0.11422164786062972, 0.5212488269937966, 0.5212488269937966, 0.5212488269937966, 0.6092900456626009, 0.6092900456626009, 0.6092900456626009, 0.5657986694000723, 0.5657986694000723, 0.5657986694000723, 0.07625858721913681, 0.07625858721913681, 0.07625858721913681, 0.11353684310069889, 0.11353684310069889, 0.11353684310069889, 0.13349225556029598, 0.13349225556029598, 0.13349225556029598, 0.2923087655110267, 0.2923087655110267, 0.2923087655110267, 0.17058849530006337, 0.17058849530006337, 0.17058849530006337, 0.36867958361848363, 0.36867958361848363, 0.36867958361848363, 0.40865239548570576, 0.40865239548570576, 0.40865239548570576, 0.39714577174572396, 0.39714577174572396, 0.39714577174572396, 0.2695926147327291, 0.2695926147327291, 0.2695926147327291, 0.21811446266173207, 0.21811446266173207, 0.21811446266173207, 0.34268712567274884, 0.34268712567274884, 0.34268712567274884, 0.22874659868451208, 0.22874659868451208, 0.22874659868451208, 0.21928541749058428, 0.21928541749058428, 0.21928541749058428, 0.22679558567235403, 0.22679558567235403, 0.22679558567235403, 0.2801068714944557, 0.2801068714944557, 0.2801068714944557, 0.24859292531735677, 0.24859292531735677, 0.24859292531735677, 0.22841934362266458, 0.22841934362266458, 0.22841934362266458, 0.2168144089226336, 0.2168144089226336, 0.2168144089226336, 0.9271356183668746, 0.9271356183668746, 0.9271356183668746, 0.11420627305427256, 0.11420627305427256, 0.11420627305427256, 0.1366109952920993, 0.1366109952920993, 0.1366109952920993, 0.6716788495300214, 0.6716788495300214, 0.6716788495300214, 0.6525119270873981, 0.6525119270873981, 0.6525119270873981, 0.7335310158747503, 0.7335310158747503, 0.7335310158747503, 0.22509205180813374, 0.22509205180813374, 0.22509205180813374, 0.23846259715961882, 0.23846259715961882, 0.23846259715961882, 0.23026115778748257, 0.23026115778748257, 0.23026115778748257, 0.10729408229532489, 0.10729408229532489, 0.10729408229532489, 0.08707462555969336, 0.08707462555969336, 0.08707462555969336, 0.09244825892062858, 0.09244825892062858, 0.09244825892062858]}, "mutation_prompt": null}
{"id": "5e4ee905-7eea-49eb-8354-802a989f2413", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(70, 12 * dim)  # Increased particles slightly for diversity\n        self.c1 = 1.4  # Further reduced cognitive component for better balance\n        self.c2 = 2.2  # Further increased social component to leverage collective intelligence\n        self.w = 0.85  # Adjusted inertia weight to balance exploration and exploitation\n        self.decay_rate = 0.93  # Faster decay to reduce inertia over time\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.1  # Increased velocity limit for more aggressive movement\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced APSO with adaptive learning components and improved velocity dynamics for faster convergence.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.8890345554254235, 0.8890345554254235, 0.8890345554254235, 0.8812898909220918, 0.8812898909220918, 0.8812898909220918, 0.885169648507018, 0.885169648507018, 0.885169648507018, 0.7943252300909807, 0.7943252300909807, 0.7943252300909807, 0.7992832977617781, 0.7992832977617781, 0.7992832977617781, 0.806978601700252, 0.806978601700252, 0.806978601700252, 0.141836067863071, 0.141836067863071, 0.141836067863071, 0.09072257940144113, 0.09072257940144113, 0.09072257940144113, 0.11538296000510384, 0.11538296000510384, 0.11538296000510384, 0.09182634705732529, 0.09182634705732529, 0.09182634705732529, 0.10396507449566983, 0.10396507449566983, 0.10396507449566983, 0.12877403769140183, 0.12877403769140183, 0.12877403769140183, 0.9171003036492754, 0.9171003036492754, 0.9171003036492754, 0.9426071411196885, 0.9426071411196885, 0.9426071411196885, 0.947537189438548, 0.947537189438548, 0.947537189438548, 0.6001545147287968, 0.6001545147287968, 0.6001545147287968, 0.684584432385599, 0.684584432385599, 0.684584432385599, 0.5898963208656243, 0.5898963208656243, 0.5898963208656243, 0.19375146093521256, 0.19375146093521256, 0.19375146093521256, 0.8693944340969452, 0.8693944340969452, 0.8693944340969452, 0.748951913666398, 0.748951913666398, 0.748951913666398, 0.21327141745353018, 0.21327141745353018, 0.21327141745353018, 0.20118277962625464, 0.20118277962625464, 0.20118277962625464, 0.22068388192974941, 0.22068388192974941, 0.22068388192974941, 0.23075865172070587, 0.23075865172070587, 0.23075865172070587, 0.2135229554500695, 0.2135229554500695, 0.2135229554500695, 0.23668946202621444, 0.23668946202621444, 0.23668946202621444, 0.005148868860398448, 0.005148868860398448, 0.005148868860398448, 0.08177194701312396, 0.08177194701312396, 0.08177194701312396, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08208764747391684, 0.08208764747391684, 0.08208764747391684, 0.05568690635405671, 0.05568690635405671, 0.05568690635405671, 0.11343134532868715, 0.11343134532868715, 0.11343134532868715, 0.04909694094295114, 0.04909694094295114, 0.04909694094295114, 0.11383841177004017, 0.11383841177004017, 0.11383841177004017, 0.26109733429390813, 0.26109733429390813, 0.26109733429390813, 0.25317053091270736, 0.25317053091270736, 0.25317053091270736, 0.10090994703812939, 0.10090994703812939, 0.10090994703812939, 0.11422164786062972, 0.11422164786062972, 0.11422164786062972, 0.5212488269937966, 0.5212488269937966, 0.5212488269937966, 0.6092900456626009, 0.6092900456626009, 0.6092900456626009, 0.5657986694000723, 0.5657986694000723, 0.5657986694000723, 0.07625858721913681, 0.07625858721913681, 0.07625858721913681, 0.11353684310069889, 0.11353684310069889, 0.11353684310069889, 0.13349225556029598, 0.13349225556029598, 0.13349225556029598, 0.2923087655110267, 0.2923087655110267, 0.2923087655110267, 0.17058849530006337, 0.17058849530006337, 0.17058849530006337, 0.36867958361848363, 0.36867958361848363, 0.36867958361848363, 0.40865239548570576, 0.40865239548570576, 0.40865239548570576, 0.39714577174572396, 0.39714577174572396, 0.39714577174572396, 0.2695926147327291, 0.2695926147327291, 0.2695926147327291, 0.21811446266173207, 0.21811446266173207, 0.21811446266173207, 0.34268712567274884, 0.34268712567274884, 0.34268712567274884, 0.22874659868451208, 0.22874659868451208, 0.22874659868451208, 0.21928541749058428, 0.21928541749058428, 0.21928541749058428, 0.22679558567235403, 0.22679558567235403, 0.22679558567235403, 0.2801068714944557, 0.2801068714944557, 0.2801068714944557, 0.24859292531735677, 0.24859292531735677, 0.24859292531735677, 0.22841934362266458, 0.22841934362266458, 0.22841934362266458, 0.2168144089226336, 0.2168144089226336, 0.2168144089226336, 0.9271356183668746, 0.9271356183668746, 0.9271356183668746, 0.11420627305427256, 0.11420627305427256, 0.11420627305427256, 0.1366109952920993, 0.1366109952920993, 0.1366109952920993, 0.6716788495300214, 0.6716788495300214, 0.6716788495300214, 0.6525119270873981, 0.6525119270873981, 0.6525119270873981, 0.7335310158747503, 0.7335310158747503, 0.7335310158747503, 0.22509205180813374, 0.22509205180813374, 0.22509205180813374, 0.23846259715961882, 0.23846259715961882, 0.23846259715961882, 0.23026115778748257, 0.23026115778748257, 0.23026115778748257, 0.10729408229532489, 0.10729408229532489, 0.10729408229532489, 0.08707462555969336, 0.08707462555969336, 0.08707462555969336, 0.09244825892062858, 0.09244825892062858, 0.09244825892062858]}, "mutation_prompt": null}
{"id": "d43e5c10-e2ea-4047-b828-39fc77682706", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(70, 12 * dim)  # Increased particles slightly for diversity\n        self.c1 = 1.4  # Further reduced cognitive component for better balance\n        self.c2 = 2.2  # Further increased social component to leverage collective intelligence\n        self.w = 0.85  # Adjusted inertia weight to balance exploration and exploitation\n        self.decay_rate = 0.93  # Faster decay to reduce inertia over time\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.1  # Increased velocity limit for more aggressive movement\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced APSO with adaptive learning components and improved velocity dynamics for faster convergence.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.8890345554254235, 0.8890345554254235, 0.8890345554254235, 0.8812898909220918, 0.8812898909220918, 0.8812898909220918, 0.885169648507018, 0.885169648507018, 0.885169648507018, 0.7943252300909807, 0.7943252300909807, 0.7943252300909807, 0.7992832977617781, 0.7992832977617781, 0.7992832977617781, 0.806978601700252, 0.806978601700252, 0.806978601700252, 0.141836067863071, 0.141836067863071, 0.141836067863071, 0.09072257940144113, 0.09072257940144113, 0.09072257940144113, 0.11538296000510384, 0.11538296000510384, 0.11538296000510384, 0.09182634705732529, 0.09182634705732529, 0.09182634705732529, 0.10396507449566983, 0.10396507449566983, 0.10396507449566983, 0.12877403769140183, 0.12877403769140183, 0.12877403769140183, 0.9171003036492754, 0.9171003036492754, 0.9171003036492754, 0.9426071411196885, 0.9426071411196885, 0.9426071411196885, 0.947537189438548, 0.947537189438548, 0.947537189438548, 0.6001545147287968, 0.6001545147287968, 0.6001545147287968, 0.684584432385599, 0.684584432385599, 0.684584432385599, 0.5898963208656243, 0.5898963208656243, 0.5898963208656243, 0.19375146093521256, 0.19375146093521256, 0.19375146093521256, 0.8693944340969452, 0.8693944340969452, 0.8693944340969452, 0.748951913666398, 0.748951913666398, 0.748951913666398, 0.21327141745353018, 0.21327141745353018, 0.21327141745353018, 0.20118277962625464, 0.20118277962625464, 0.20118277962625464, 0.22068388192974941, 0.22068388192974941, 0.22068388192974941, 0.23075865172070587, 0.23075865172070587, 0.23075865172070587, 0.2135229554500695, 0.2135229554500695, 0.2135229554500695, 0.23668946202621444, 0.23668946202621444, 0.23668946202621444, 0.005148868860398448, 0.005148868860398448, 0.005148868860398448, 0.08177194701312396, 0.08177194701312396, 0.08177194701312396, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08208764747391684, 0.08208764747391684, 0.08208764747391684, 0.05568690635405671, 0.05568690635405671, 0.05568690635405671, 0.11343134532868715, 0.11343134532868715, 0.11343134532868715, 0.04909694094295114, 0.04909694094295114, 0.04909694094295114, 0.11383841177004017, 0.11383841177004017, 0.11383841177004017, 0.26109733429390813, 0.26109733429390813, 0.26109733429390813, 0.25317053091270736, 0.25317053091270736, 0.25317053091270736, 0.10090994703812939, 0.10090994703812939, 0.10090994703812939, 0.11422164786062972, 0.11422164786062972, 0.11422164786062972, 0.5212488269937966, 0.5212488269937966, 0.5212488269937966, 0.6092900456626009, 0.6092900456626009, 0.6092900456626009, 0.5657986694000723, 0.5657986694000723, 0.5657986694000723, 0.07625858721913681, 0.07625858721913681, 0.07625858721913681, 0.11353684310069889, 0.11353684310069889, 0.11353684310069889, 0.13349225556029598, 0.13349225556029598, 0.13349225556029598, 0.2923087655110267, 0.2923087655110267, 0.2923087655110267, 0.17058849530006337, 0.17058849530006337, 0.17058849530006337, 0.36867958361848363, 0.36867958361848363, 0.36867958361848363, 0.40865239548570576, 0.40865239548570576, 0.40865239548570576, 0.39714577174572396, 0.39714577174572396, 0.39714577174572396, 0.2695926147327291, 0.2695926147327291, 0.2695926147327291, 0.21811446266173207, 0.21811446266173207, 0.21811446266173207, 0.34268712567274884, 0.34268712567274884, 0.34268712567274884, 0.22874659868451208, 0.22874659868451208, 0.22874659868451208, 0.21928541749058428, 0.21928541749058428, 0.21928541749058428, 0.22679558567235403, 0.22679558567235403, 0.22679558567235403, 0.2801068714944557, 0.2801068714944557, 0.2801068714944557, 0.24859292531735677, 0.24859292531735677, 0.24859292531735677, 0.22841934362266458, 0.22841934362266458, 0.22841934362266458, 0.2168144089226336, 0.2168144089226336, 0.2168144089226336, 0.9271356183668746, 0.9271356183668746, 0.9271356183668746, 0.11420627305427256, 0.11420627305427256, 0.11420627305427256, 0.1366109952920993, 0.1366109952920993, 0.1366109952920993, 0.6716788495300214, 0.6716788495300214, 0.6716788495300214, 0.6525119270873981, 0.6525119270873981, 0.6525119270873981, 0.7335310158747503, 0.7335310158747503, 0.7335310158747503, 0.22509205180813374, 0.22509205180813374, 0.22509205180813374, 0.23846259715961882, 0.23846259715961882, 0.23846259715961882, 0.23026115778748257, 0.23026115778748257, 0.23026115778748257, 0.10729408229532489, 0.10729408229532489, 0.10729408229532489, 0.08707462555969336, 0.08707462555969336, 0.08707462555969336, 0.09244825892062858, 0.09244825892062858, 0.09244825892062858]}, "mutation_prompt": null}
{"id": "fdca2b61-41c9-4190-b05f-d06d7a0c13a1", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(70, 12 * dim)  # Increased particles slightly for diversity\n        self.c1 = 1.4  # Further reduced cognitive component for better balance\n        self.c2 = 2.2  # Further increased social component to leverage collective intelligence\n        self.w = 0.85  # Adjusted inertia weight to balance exploration and exploitation\n        self.decay_rate = 0.93  # Faster decay to reduce inertia over time\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.1  # Increased velocity limit for more aggressive movement\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced APSO with adaptive learning components and improved velocity dynamics for faster convergence.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.8890345554254235, 0.8890345554254235, 0.8890345554254235, 0.8812898909220918, 0.8812898909220918, 0.8812898909220918, 0.885169648507018, 0.885169648507018, 0.885169648507018, 0.7943252300909807, 0.7943252300909807, 0.7943252300909807, 0.7992832977617781, 0.7992832977617781, 0.7992832977617781, 0.806978601700252, 0.806978601700252, 0.806978601700252, 0.141836067863071, 0.141836067863071, 0.141836067863071, 0.09072257940144113, 0.09072257940144113, 0.09072257940144113, 0.11538296000510384, 0.11538296000510384, 0.11538296000510384, 0.09182634705732529, 0.09182634705732529, 0.09182634705732529, 0.10396507449566983, 0.10396507449566983, 0.10396507449566983, 0.12877403769140183, 0.12877403769140183, 0.12877403769140183, 0.9171003036492754, 0.9171003036492754, 0.9171003036492754, 0.9426071411196885, 0.9426071411196885, 0.9426071411196885, 0.947537189438548, 0.947537189438548, 0.947537189438548, 0.6001545147287968, 0.6001545147287968, 0.6001545147287968, 0.684584432385599, 0.684584432385599, 0.684584432385599, 0.5898963208656243, 0.5898963208656243, 0.5898963208656243, 0.19375146093521256, 0.19375146093521256, 0.19375146093521256, 0.8693944340969452, 0.8693944340969452, 0.8693944340969452, 0.748951913666398, 0.748951913666398, 0.748951913666398, 0.21327141745353018, 0.21327141745353018, 0.21327141745353018, 0.20118277962625464, 0.20118277962625464, 0.20118277962625464, 0.22068388192974941, 0.22068388192974941, 0.22068388192974941, 0.23075865172070587, 0.23075865172070587, 0.23075865172070587, 0.2135229554500695, 0.2135229554500695, 0.2135229554500695, 0.23668946202621444, 0.23668946202621444, 0.23668946202621444, 0.005148868860398448, 0.005148868860398448, 0.005148868860398448, 0.08177194701312396, 0.08177194701312396, 0.08177194701312396, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08208764747391684, 0.08208764747391684, 0.08208764747391684, 0.05568690635405671, 0.05568690635405671, 0.05568690635405671, 0.11343134532868715, 0.11343134532868715, 0.11343134532868715, 0.04909694094295114, 0.04909694094295114, 0.04909694094295114, 0.11383841177004017, 0.11383841177004017, 0.11383841177004017, 0.26109733429390813, 0.26109733429390813, 0.26109733429390813, 0.25317053091270736, 0.25317053091270736, 0.25317053091270736, 0.10090994703812939, 0.10090994703812939, 0.10090994703812939, 0.11422164786062972, 0.11422164786062972, 0.11422164786062972, 0.5212488269937966, 0.5212488269937966, 0.5212488269937966, 0.6092900456626009, 0.6092900456626009, 0.6092900456626009, 0.5657986694000723, 0.5657986694000723, 0.5657986694000723, 0.07625858721913681, 0.07625858721913681, 0.07625858721913681, 0.11353684310069889, 0.11353684310069889, 0.11353684310069889, 0.13349225556029598, 0.13349225556029598, 0.13349225556029598, 0.2923087655110267, 0.2923087655110267, 0.2923087655110267, 0.17058849530006337, 0.17058849530006337, 0.17058849530006337, 0.36867958361848363, 0.36867958361848363, 0.36867958361848363, 0.40865239548570576, 0.40865239548570576, 0.40865239548570576, 0.39714577174572396, 0.39714577174572396, 0.39714577174572396, 0.2695926147327291, 0.2695926147327291, 0.2695926147327291, 0.21811446266173207, 0.21811446266173207, 0.21811446266173207, 0.34268712567274884, 0.34268712567274884, 0.34268712567274884, 0.22874659868451208, 0.22874659868451208, 0.22874659868451208, 0.21928541749058428, 0.21928541749058428, 0.21928541749058428, 0.22679558567235403, 0.22679558567235403, 0.22679558567235403, 0.2801068714944557, 0.2801068714944557, 0.2801068714944557, 0.24859292531735677, 0.24859292531735677, 0.24859292531735677, 0.22841934362266458, 0.22841934362266458, 0.22841934362266458, 0.2168144089226336, 0.2168144089226336, 0.2168144089226336, 0.9271356183668746, 0.9271356183668746, 0.9271356183668746, 0.11420627305427256, 0.11420627305427256, 0.11420627305427256, 0.1366109952920993, 0.1366109952920993, 0.1366109952920993, 0.6716788495300214, 0.6716788495300214, 0.6716788495300214, 0.6525119270873981, 0.6525119270873981, 0.6525119270873981, 0.7335310158747503, 0.7335310158747503, 0.7335310158747503, 0.22509205180813374, 0.22509205180813374, 0.22509205180813374, 0.23846259715961882, 0.23846259715961882, 0.23846259715961882, 0.23026115778748257, 0.23026115778748257, 0.23026115778748257, 0.10729408229532489, 0.10729408229532489, 0.10729408229532489, 0.08707462555969336, 0.08707462555969336, 0.08707462555969336, 0.09244825892062858, 0.09244825892062858, 0.09244825892062858]}, "mutation_prompt": null}
{"id": "70d045c5-0740-413d-9c6f-5793a7b7bb70", "solution": "import numpy as np\n\nclass AdaptiveDynamicSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(80, 13 * dim)  # Slightly increased for more exploration\n        self.c1_ini = 1.5  # Initial cognitive component\n        self.c2_ini = 2.0  # Initial social component\n        self.c1_final = 1.0  # Final cognitive component for precision\n        self.c2_final = 2.5  # Final social component for convergence\n        self.w = 0.9  # Increased initial inertia for exploration\n        self.w_min = 0.4  # Minimum inertia weight for exploitation\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.15  # Increase for more reach\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            progress_ratio = evaluations / self.budget\n            self.c1 = self.c1_ini + progress_ratio * (self.c1_final - self.c1_ini)\n            self.c2 = self.c2_ini + progress_ratio * (self.c2_final - self.c2_ini)\n            self.w = self.w - progress_ratio * (self.w - self.w_min)\n\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n        \n        return global_best_position, global_best_score", "name": "AdaptiveDynamicSwarm", "description": "Adaptive Dynamic Swarm with time-varying parameter adaptation for enhanced convergence speed.", "configspace": "", "generation": 47, "fitness": 0.31665469234430327, "feedback": "The algorithm AdaptiveDynamicSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.25.", "error": "", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.8076588196769308, 0.8076588196769308, 0.8076588196769308, 0.7963158107142685, 0.7963158107142685, 0.7963158107142685, 0.7619328825409137, 0.7619328825409137, 0.7619328825409137, 0.5794498625834552, 0.5794498625834552, 0.5794498625834552, 0.6008613693481535, 0.6008613693481535, 0.6008613693481535, 0.5566989503965356, 0.5566989503965356, 0.5566989503965356, 0.23813964030885804, 0.23813964030885804, 0.23813964030885804, 0.15833678021137876, 0.15833678021137876, 0.15833678021137876, 0.17685046988630615, 0.17685046988630615, 0.17685046988630615, 0.14345743974505198, 0.14345743974505198, 0.14345743974505198, 0.10622828374945292, 0.10622828374945292, 0.10622828374945292, 0.1418273811316243, 0.1418273811316243, 0.1418273811316243, 0.9633356822100227, 0.9633356822100227, 0.9633356822100227, 0.9572911261951018, 0.9572911261951018, 0.9572911261951018, 0.9568142811915699, 0.9568142811915699, 0.9568142811915699, 0.5252568016057608, 0.5252568016057608, 0.5252568016057608, 0.5976297165537081, 0.5976297165537081, 0.5976297165537081, 0.5290424639343552, 0.5290424639343552, 0.5290424639343552, 0.17046551420775946, 0.17046551420775946, 0.17046551420775946, 0.26860995522240416, 0.26860995522240416, 0.26860995522240416, 0.23169355709043227, 0.23169355709043227, 0.23169355709043227, 0.23058317807766648, 0.23058317807766648, 0.23058317807766648, 0.18604759908266066, 0.18604759908266066, 0.18604759908266066, 0.19194789451131788, 0.19194789451131788, 0.19194789451131788, 0.20404365359194576, 0.20404365359194576, 0.20404365359194576, 0.2021102990147713, 0.2021102990147713, 0.2021102990147713, 0.2328183781101275, 0.2328183781101275, 0.2328183781101275, 0.13957307088212145, 0.13957307088212145, 0.13957307088212145, 0.0891674662679447, 0.0891674662679447, 0.0891674662679447, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12656144579480078, 0.12656144579480078, 0.12656144579480078, 0.08303178246627174, 0.08303178246627174, 0.08303178246627174, 0.08566417677100469, 0.08566417677100469, 0.08566417677100469, 0.04285771494944879, 0.04285771494944879, 0.04285771494944879, 0.20958269004124974, 0.20958269004124974, 0.20958269004124974, 0.21622626411905033, 0.21622626411905033, 0.21622626411905033, 0.19680899842756316, 0.19680899842756316, 0.19680899842756316, 0.1739088979168435, 0.1739088979168435, 0.1739088979168435, 0.14099628495816852, 0.14099628495816852, 0.14099628495816852, 0.5423752322074937, 0.5423752322074937, 0.5423752322074937, 0.5325812152995835, 0.5325812152995835, 0.5325812152995835, 0.5462248532479608, 0.5462248532479608, 0.5462248532479608, 0.09961600975108709, 0.09961600975108709, 0.09961600975108709, 0.13089450542596948, 0.13089450542596948, 0.13089450542596948, 0.11047032204671503, 0.11047032204671503, 0.11047032204671503, 0.2919657638730485, 0.2919657638730485, 0.2919657638730485, 0.2987268642373735, 0.2987268642373735, 0.2987268642373735, 0.19525402493372923, 0.19525402493372923, 0.19525402493372923, 0.3738151256320206, 0.3738151256320206, 0.3738151256320206, 0.507602905631239, 0.507602905631239, 0.507602905631239, 0.3941977021690053, 0.3941977021690053, 0.3941977021690053, 0.22869248221960103, 0.22869248221960103, 0.22869248221960103, 0.31859051786043047, 0.31859051786043047, 0.31859051786043047, 0.14572519845666354, 0.14572519845666354, 0.14572519845666354, 0.2312546813005768, 0.2312546813005768, 0.2312546813005768, 0.2715391346408994, 0.2715391346408994, 0.2715391346408994, 0.22720466625081748, 0.22720466625081748, 0.22720466625081748, 0.24039363288685567, 0.24039363288685567, 0.24039363288685567, 0.20873002204989066, 0.20873002204989066, 0.20873002204989066, 0.21516301706715735, 0.21516301706715735, 0.21516301706715735, 0.8318851275976582, 0.8318851275976582, 0.8318851275976582, 0.164982249006716, 0.164982249006716, 0.164982249006716, 0.14631049003892183, 0.14631049003892183, 0.14631049003892183, 0.6828993178307997, 0.6828993178307997, 0.6828993178307997, 0.12647602445211126, 0.12647602445211126, 0.12647602445211126, 0.7944407324395735, 0.7944407324395735, 0.7944407324395735, 0.21167122106396508, 0.21167122106396508, 0.21167122106396508, 0.20639846320251898, 0.20639846320251898, 0.20639846320251898, 0.19095580027676307, 0.19095580027676307, 0.19095580027676307, 0.10434972876041515, 0.10434972876041515, 0.10434972876041515, 0.1072769976738206, 0.1072769976738206, 0.1072769976738206, 0.10054723577145452, 0.10054723577145452, 0.10054723577145452]}, "mutation_prompt": null}
{"id": "ea5afa85-588f-4878-9a37-8560a5ca9ffe", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(70, 12 * dim)\n        self.c_min = 1.2  # Introduce dynamic learning coefficients\n        self.c_max = 2.5\n        self.w = 0.8  # Adjusted inertia weight for faster exploitation\n        self.decay_rate = 0.92  # Slightly faster decay\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.15  # Increased velocity limit\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            adaptive_factor = evaluations / self.budget\n            c1 = self.c_min + (self.c_max - self.c_min) * adaptive_factor\n            c2 = self.c_max - (self.c_max - self.c_min) * adaptive_factor\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced APSO with dynamic learning coefficients and adaptive velocity to improve convergence speed.", "configspace": "", "generation": 48, "fitness": 0.31684648155680256, "feedback": "The algorithm EnhancedAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.26.", "error": "", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.8837809218006065, 0.8837809218006065, 0.8837809218006065, 0.8964364637824082, 0.8964364637824082, 0.8964364637824082, 0.8903396545784078, 0.8903396545784078, 0.8903396545784078, 0.7917998896659095, 0.7917998896659095, 0.7917998896659095, 0.7885511347518509, 0.7885511347518509, 0.7885511347518509, 0.8151343581008997, 0.8151343581008997, 0.8151343581008997, 0.15642062539977064, 0.15642062539977064, 0.15642062539977064, 0.15639250077707934, 0.15639250077707934, 0.15639250077707934, 0.1841126424620272, 0.1841126424620272, 0.1841126424620272, 0.14532908488179297, 0.14532908488179297, 0.14532908488179297, 0.13196573089957597, 0.13196573089957597, 0.13196573089957597, 0.16041292237167804, 0.16041292237167804, 0.16041292237167804, 0.947798912854044, 0.947798912854044, 0.947798912854044, 0.9601976894355241, 0.9601976894355241, 0.9601976894355241, 0.9617874548207433, 0.9617874548207433, 0.9617874548207433, 0.4809656101225658, 0.4809656101225658, 0.4809656101225658, 0.5987441605132628, 0.5987441605132628, 0.5987441605132628, 0.49168729644224973, 0.49168729644224973, 0.49168729644224973, 0.22574121779216105, 0.22574121779216105, 0.22574121779216105, 0.24036720174460202, 0.24036720174460202, 0.24036720174460202, 0.2351918915596185, 0.2351918915596185, 0.2351918915596185, 0.21607173510408995, 0.21607173510408995, 0.21607173510408995, 0.19358625556519826, 0.19358625556519826, 0.19358625556519826, 0.13068266083123403, 0.13068266083123403, 0.13068266083123403, 0.211866002113961, 0.211866002113961, 0.211866002113961, 0.13015227910574145, 0.13015227910574145, 0.13015227910574145, 0.21565186662705138, 0.21565186662705138, 0.21565186662705138, 0.015293123823340138, 0.015293123823340138, 0.015293123823340138, 0.010027779614412258, 0.010027779614412258, 0.010027779614412258, 0.012536491655840698, 0.012536491655840698, 0.012536491655840698, 0.04619425886865414, 0.04619425886865414, 0.04619425886865414, 0.060438621241608925, 0.060438621241608925, 0.060438621241608925, 0.10346818934740354, 0.10346818934740354, 0.10346818934740354, 0.1092602697951014, 0.1092602697951014, 0.1092602697951014, 0.17587205113645032, 0.17587205113645032, 0.17587205113645032, 0.2026615177026434, 0.2026615177026434, 0.2026615177026434, 0.252574193110794, 0.252574193110794, 0.252574193110794, 0.25731523959984826, 0.25731523959984826, 0.25731523959984826, 0.186157657650448, 0.186157657650448, 0.186157657650448, 0.5988834396244649, 0.5988834396244649, 0.5988834396244649, 0.5172286487229636, 0.5172286487229636, 0.5172286487229636, 0.5608642999461395, 0.5608642999461395, 0.5608642999461395, 0.1572995924161742, 0.1572995924161742, 0.1572995924161742, 0.11296607518232471, 0.11296607518232471, 0.11296607518232471, 0.12231484763433886, 0.12231484763433886, 0.12231484763433886, 0.3385304780730565, 0.3385304780730565, 0.3385304780730565, 0.1350893042920588, 0.1350893042920588, 0.1350893042920588, 0.3530109970346137, 0.3530109970346137, 0.3530109970346137, 0.4072726032608047, 0.4072726032608047, 0.4072726032608047, 0.4612405762936136, 0.4612405762936136, 0.4612405762936136, 0.36049607683714835, 0.36049607683714835, 0.36049607683714835, 0.19153500188564498, 0.19153500188564498, 0.19153500188564498, 0.3331307118598762, 0.3331307118598762, 0.3331307118598762, 0.2751184847888529, 0.2751184847888529, 0.2751184847888529, 0.2318162499040909, 0.2318162499040909, 0.2318162499040909, 0.229853833516932, 0.229853833516932, 0.229853833516932, 0.2241170126196207, 0.2241170126196207, 0.2241170126196207, 0.1994995038507279, 0.1994995038507279, 0.1994995038507279, 0.19225100827430808, 0.19225100827430808, 0.19225100827430808, 0.22509813025395353, 0.22509813025395353, 0.22509813025395353, 0.9177872466978624, 0.9177872466978624, 0.9177872466978624, 0.15822552989394245, 0.15822552989394245, 0.15822552989394245, 0.1366519698989439, 0.1366519698989439, 0.1366519698989439, 0.48495386868373735, 0.48495386868373735, 0.48495386868373735, 0.21166007582630475, 0.21166007582630475, 0.21166007582630475, 0.16855753447783084, 0.16855753447783084, 0.16855753447783084, 0.19055546082388186, 0.19055546082388186, 0.19055546082388186, 0.17731455742216806, 0.17731455742216806, 0.17731455742216806, 0.17579371141757094, 0.17579371141757094, 0.17579371141757094, 0.0900254777792856, 0.0900254777792856, 0.0900254777792856, 0.10496439531720647, 0.10496439531720647, 0.10496439531720647, 0.09587240992874269, 0.09587240992874269, 0.09587240992874269]}, "mutation_prompt": null}
{"id": "cdca378b-9f4c-4910-bf92-e945b36f385a", "solution": "import numpy as np\n\nclass EnhancedHybridAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(72, 12 * dim)  # Slight increase in the number of particles\n        self.c1 = 1.5  # Balancing cognitive component\n        self.c2 = 2.0  # Reduced social component to focus on personal learning\n        self.w = 0.9  # Higher initial inertia for exploration\n        self.w_min = 0.4  # Minimum inertia weight\n        self.decay_rate = 0.92  # Slightly faster decay for inertia\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.12  # Increase in velocity limit\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]) +\n                          np.random.normal(0, 0.05, self.dim))  # Introduce stochastic perturbation\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w = max(self.w * self.decay_rate, self.w_min)  # Decay inertia weight with a minimum threshold\n        \n        return global_best_position, global_best_score", "name": "EnhancedHybridAPSO", "description": "Adaptive hybrid strategy combining dynamic inertia and stochastic perturbation for enhanced convergence speed.", "configspace": "", "generation": 49, "fitness": 0.23332062447867136, "feedback": "The algorithm EnhancedHybridAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.47894335932265686, 0.47894335932265686, 0.47894335932265686, 0.4502489785078234, 0.4502489785078234, 0.4502489785078234, 0.4476093612009907, 0.4476093612009907, 0.4476093612009907, 0.08745950700988159, 0.08745950700988159, 0.08745950700988159, 0.026054400879766182, 0.026054400879766182, 0.026054400879766182, 0.054991268491750955, 0.054991268491750955, 0.054991268491750955, 0.1340424416759275, 0.1340424416759275, 0.1340424416759275, 0.1468240081948361, 0.1468240081948361, 0.1468240081948361, 0.14663779173736458, 0.14663779173736458, 0.14663779173736458, 0.1195473105443956, 0.1195473105443956, 0.1195473105443956, 0.10272005751119595, 0.10272005751119595, 0.10272005751119595, 0.12075279181503396, 0.12075279181503396, 0.12075279181503396, 0.9541976797989873, 0.9541976797989873, 0.9541976797989873, 0.9247528085993113, 0.9247528085993113, 0.9247528085993113, 0.9387303283313333, 0.9387303283313333, 0.9387303283313333, 0.3340703665373208, 0.3340703665373208, 0.3340703665373208, 0.3396345853778985, 0.3396345853778985, 0.3396345853778985, 0.3097495302783394, 0.3097495302783394, 0.3097495302783394, 0.22018145713180448, 0.22018145713180448, 0.22018145713180448, 0.16149820848355234, 0.16149820848355234, 0.16149820848355234, 0.2749510012511338, 0.2749510012511338, 0.2749510012511338, 0.1612997350987918, 0.1612997350987918, 0.1612997350987918, 0.21396000246569358, 0.21396000246569358, 0.21396000246569358, 0.1472606995609873, 0.1472606995609873, 0.1472606995609873, 0.1406596838562325, 0.1406596838562325, 0.1406596838562325, 0.12668059340465299, 0.12668059340465299, 0.12668059340465299, 0.17166560666627828, 0.17166560666627828, 0.17166560666627828, 0.06232274862353604, 0.06232274862353604, 0.06232274862353604, 0.046538067926259474, 0.046538067926259474, 0.046538067926259474, 0.0248798071607087, 0.0248798071607087, 0.0248798071607087, 0.10894099064910734, 0.10894099064910734, 0.10894099064910734, 0.04600586184021627, 0.04600586184021627, 0.04600586184021627, 0.1227953394101392, 0.1227953394101392, 0.1227953394101392, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13261138359171587, 0.13261138359171587, 0.13261138359171587, 0.11296958431115312, 0.11296958431115312, 0.11296958431115312, 0.10708371125329064, 0.10708371125329064, 0.10708371125329064, 0.430353057722899, 0.430353057722899, 0.430353057722899, 0.4144874202374621, 0.4144874202374621, 0.4144874202374621, 0.42202546193608725, 0.42202546193608725, 0.42202546193608725, 0.09467368390827757, 0.09467368390827757, 0.09467368390827757, 0.1346941559427034, 0.1346941559427034, 0.1346941559427034, 0.109052574732323, 0.109052574732323, 0.109052574732323, 0.25188866431093004, 0.25188866431093004, 0.25188866431093004, 0.2697364212904717, 0.2697364212904717, 0.2697364212904717, 0.21431984486115763, 0.21431984486115763, 0.21431984486115763, 0.3052451304128806, 0.3052451304128806, 0.3052451304128806, 0.23637145052946906, 0.23637145052946906, 0.23637145052946906, 0.27238978258530533, 0.27238978258530533, 0.27238978258530533, 0.21945016843792986, 0.21945016843792986, 0.21945016843792986, 0.15599202843603432, 0.15599202843603432, 0.15599202843603432, 0.2033632897734169, 0.2033632897734169, 0.2033632897734169, 0.20579777640902908, 0.20579777640902908, 0.20579777640902908, 0.1953850545446807, 0.1953850545446807, 0.1953850545446807, 0.2643868061691407, 0.2643868061691407, 0.2643868061691407, 0.1939329840621138, 0.1939329840621138, 0.1939329840621138, 0.2013442694792137, 0.2013442694792137, 0.2013442694792137, 0.2157406685785178, 0.2157406685785178, 0.2157406685785178, 0.7190046512452635, 0.7190046512452635, 0.7190046512452635, 0.15821153640513874, 0.15821153640513874, 0.15821153640513874, 0.13648360989022112, 0.13648360989022112, 0.13648360989022112, 0.6332159481348001, 0.6332159481348001, 0.6332159481348001, 0.21111984228422864, 0.21111984228422864, 0.21111984228422864, 0.5282546210040517, 0.5282546210040517, 0.5282546210040517, 0.18444733655115442, 0.18444733655115442, 0.18444733655115442, 0.18085040998287472, 0.18085040998287472, 0.18085040998287472, 0.21353993400451254, 0.21353993400451254, 0.21353993400451254, 0.12091306336167729, 0.12091306336167729, 0.12091306336167729, 0.08804271530738572, 0.08804271530738572, 0.08804271530738572, 0.11479954143291815, 0.11479954143291815, 0.11479954143291815]}, "mutation_prompt": null}
{"id": "2be69cf0-4fe2-4832-a916-2658b46780de", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(70, 12 * dim)  # Increased particles slightly for diversity\n        self.c1 = 1.4  # Further reduced cognitive component for better balance\n        self.c2 = 2.2  # Further increased social component to leverage collective intelligence\n        self.w = 0.85  # Adjusted inertia weight to balance exploration and exploitation\n        self.decay_rate = 0.93  # Faster decay to reduce inertia over time\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.1  # Increased velocity limit for more aggressive movement\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced APSO with adaptive learning components and improved velocity dynamics for faster convergence.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.8890345554254235, 0.8890345554254235, 0.8890345554254235, 0.8812898909220918, 0.8812898909220918, 0.8812898909220918, 0.885169648507018, 0.885169648507018, 0.885169648507018, 0.7943252300909807, 0.7943252300909807, 0.7943252300909807, 0.7992832977617781, 0.7992832977617781, 0.7992832977617781, 0.806978601700252, 0.806978601700252, 0.806978601700252, 0.141836067863071, 0.141836067863071, 0.141836067863071, 0.09072257940144113, 0.09072257940144113, 0.09072257940144113, 0.11538296000510384, 0.11538296000510384, 0.11538296000510384, 0.09182634705732529, 0.09182634705732529, 0.09182634705732529, 0.10396507449566983, 0.10396507449566983, 0.10396507449566983, 0.12877403769140183, 0.12877403769140183, 0.12877403769140183, 0.9171003036492754, 0.9171003036492754, 0.9171003036492754, 0.9426071411196885, 0.9426071411196885, 0.9426071411196885, 0.947537189438548, 0.947537189438548, 0.947537189438548, 0.6001545147287968, 0.6001545147287968, 0.6001545147287968, 0.684584432385599, 0.684584432385599, 0.684584432385599, 0.5898963208656243, 0.5898963208656243, 0.5898963208656243, 0.19375146093521256, 0.19375146093521256, 0.19375146093521256, 0.8693944340969452, 0.8693944340969452, 0.8693944340969452, 0.748951913666398, 0.748951913666398, 0.748951913666398, 0.21327141745353018, 0.21327141745353018, 0.21327141745353018, 0.20118277962625464, 0.20118277962625464, 0.20118277962625464, 0.22068388192974941, 0.22068388192974941, 0.22068388192974941, 0.23075865172070587, 0.23075865172070587, 0.23075865172070587, 0.2135229554500695, 0.2135229554500695, 0.2135229554500695, 0.23668946202621444, 0.23668946202621444, 0.23668946202621444, 0.005148868860398448, 0.005148868860398448, 0.005148868860398448, 0.08177194701312396, 0.08177194701312396, 0.08177194701312396, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08208764747391684, 0.08208764747391684, 0.08208764747391684, 0.05568690635405671, 0.05568690635405671, 0.05568690635405671, 0.11343134532868715, 0.11343134532868715, 0.11343134532868715, 0.04909694094295114, 0.04909694094295114, 0.04909694094295114, 0.11383841177004017, 0.11383841177004017, 0.11383841177004017, 0.26109733429390813, 0.26109733429390813, 0.26109733429390813, 0.25317053091270736, 0.25317053091270736, 0.25317053091270736, 0.10090994703812939, 0.10090994703812939, 0.10090994703812939, 0.11422164786062972, 0.11422164786062972, 0.11422164786062972, 0.5212488269937966, 0.5212488269937966, 0.5212488269937966, 0.6092900456626009, 0.6092900456626009, 0.6092900456626009, 0.5657986694000723, 0.5657986694000723, 0.5657986694000723, 0.07625858721913681, 0.07625858721913681, 0.07625858721913681, 0.11353684310069889, 0.11353684310069889, 0.11353684310069889, 0.13349225556029598, 0.13349225556029598, 0.13349225556029598, 0.2923087655110267, 0.2923087655110267, 0.2923087655110267, 0.17058849530006337, 0.17058849530006337, 0.17058849530006337, 0.36867958361848363, 0.36867958361848363, 0.36867958361848363, 0.40865239548570576, 0.40865239548570576, 0.40865239548570576, 0.39714577174572396, 0.39714577174572396, 0.39714577174572396, 0.2695926147327291, 0.2695926147327291, 0.2695926147327291, 0.21811446266173207, 0.21811446266173207, 0.21811446266173207, 0.34268712567274884, 0.34268712567274884, 0.34268712567274884, 0.22874659868451208, 0.22874659868451208, 0.22874659868451208, 0.21928541749058428, 0.21928541749058428, 0.21928541749058428, 0.22679558567235403, 0.22679558567235403, 0.22679558567235403, 0.2801068714944557, 0.2801068714944557, 0.2801068714944557, 0.24859292531735677, 0.24859292531735677, 0.24859292531735677, 0.22841934362266458, 0.22841934362266458, 0.22841934362266458, 0.2168144089226336, 0.2168144089226336, 0.2168144089226336, 0.9271356183668746, 0.9271356183668746, 0.9271356183668746, 0.11420627305427256, 0.11420627305427256, 0.11420627305427256, 0.1366109952920993, 0.1366109952920993, 0.1366109952920993, 0.6716788495300214, 0.6716788495300214, 0.6716788495300214, 0.6525119270873981, 0.6525119270873981, 0.6525119270873981, 0.7335310158747503, 0.7335310158747503, 0.7335310158747503, 0.22509205180813374, 0.22509205180813374, 0.22509205180813374, 0.23846259715961882, 0.23846259715961882, 0.23846259715961882, 0.23026115778748257, 0.23026115778748257, 0.23026115778748257, 0.10729408229532489, 0.10729408229532489, 0.10729408229532489, 0.08707462555969336, 0.08707462555969336, 0.08707462555969336, 0.09244825892062858, 0.09244825892062858, 0.09244825892062858]}, "mutation_prompt": null}
{"id": "4a8a0431-6735-44c4-8ca1-af8bb91a5b0e", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(70, 12 * dim)  # Increased particles slightly for diversity\n        self.c1 = 1.4  # Further reduced cognitive component for better balance\n        self.c2 = 2.2  # Further increased social component to leverage collective intelligence\n        self.w = 0.85  # Adjusted inertia weight to balance exploration and exploitation\n        self.decay_rate = 0.93  # Faster decay to reduce inertia over time\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.1  # Increased velocity limit for more aggressive movement\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced APSO with adaptive learning components and improved velocity dynamics for faster convergence.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.8890345554254235, 0.8890345554254235, 0.8890345554254235, 0.8812898909220918, 0.8812898909220918, 0.8812898909220918, 0.885169648507018, 0.885169648507018, 0.885169648507018, 0.7943252300909807, 0.7943252300909807, 0.7943252300909807, 0.7992832977617781, 0.7992832977617781, 0.7992832977617781, 0.806978601700252, 0.806978601700252, 0.806978601700252, 0.141836067863071, 0.141836067863071, 0.141836067863071, 0.09072257940144113, 0.09072257940144113, 0.09072257940144113, 0.11538296000510384, 0.11538296000510384, 0.11538296000510384, 0.09182634705732529, 0.09182634705732529, 0.09182634705732529, 0.10396507449566983, 0.10396507449566983, 0.10396507449566983, 0.12877403769140183, 0.12877403769140183, 0.12877403769140183, 0.9171003036492754, 0.9171003036492754, 0.9171003036492754, 0.9426071411196885, 0.9426071411196885, 0.9426071411196885, 0.947537189438548, 0.947537189438548, 0.947537189438548, 0.6001545147287968, 0.6001545147287968, 0.6001545147287968, 0.684584432385599, 0.684584432385599, 0.684584432385599, 0.5898963208656243, 0.5898963208656243, 0.5898963208656243, 0.19375146093521256, 0.19375146093521256, 0.19375146093521256, 0.8693944340969452, 0.8693944340969452, 0.8693944340969452, 0.748951913666398, 0.748951913666398, 0.748951913666398, 0.21327141745353018, 0.21327141745353018, 0.21327141745353018, 0.20118277962625464, 0.20118277962625464, 0.20118277962625464, 0.22068388192974941, 0.22068388192974941, 0.22068388192974941, 0.23075865172070587, 0.23075865172070587, 0.23075865172070587, 0.2135229554500695, 0.2135229554500695, 0.2135229554500695, 0.23668946202621444, 0.23668946202621444, 0.23668946202621444, 0.005148868860398448, 0.005148868860398448, 0.005148868860398448, 0.08177194701312396, 0.08177194701312396, 0.08177194701312396, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08208764747391684, 0.08208764747391684, 0.08208764747391684, 0.05568690635405671, 0.05568690635405671, 0.05568690635405671, 0.11343134532868715, 0.11343134532868715, 0.11343134532868715, 0.04909694094295114, 0.04909694094295114, 0.04909694094295114, 0.11383841177004017, 0.11383841177004017, 0.11383841177004017, 0.26109733429390813, 0.26109733429390813, 0.26109733429390813, 0.25317053091270736, 0.25317053091270736, 0.25317053091270736, 0.10090994703812939, 0.10090994703812939, 0.10090994703812939, 0.11422164786062972, 0.11422164786062972, 0.11422164786062972, 0.5212488269937966, 0.5212488269937966, 0.5212488269937966, 0.6092900456626009, 0.6092900456626009, 0.6092900456626009, 0.5657986694000723, 0.5657986694000723, 0.5657986694000723, 0.07625858721913681, 0.07625858721913681, 0.07625858721913681, 0.11353684310069889, 0.11353684310069889, 0.11353684310069889, 0.13349225556029598, 0.13349225556029598, 0.13349225556029598, 0.2923087655110267, 0.2923087655110267, 0.2923087655110267, 0.17058849530006337, 0.17058849530006337, 0.17058849530006337, 0.36867958361848363, 0.36867958361848363, 0.36867958361848363, 0.40865239548570576, 0.40865239548570576, 0.40865239548570576, 0.39714577174572396, 0.39714577174572396, 0.39714577174572396, 0.2695926147327291, 0.2695926147327291, 0.2695926147327291, 0.21811446266173207, 0.21811446266173207, 0.21811446266173207, 0.34268712567274884, 0.34268712567274884, 0.34268712567274884, 0.22874659868451208, 0.22874659868451208, 0.22874659868451208, 0.21928541749058428, 0.21928541749058428, 0.21928541749058428, 0.22679558567235403, 0.22679558567235403, 0.22679558567235403, 0.2801068714944557, 0.2801068714944557, 0.2801068714944557, 0.24859292531735677, 0.24859292531735677, 0.24859292531735677, 0.22841934362266458, 0.22841934362266458, 0.22841934362266458, 0.2168144089226336, 0.2168144089226336, 0.2168144089226336, 0.9271356183668746, 0.9271356183668746, 0.9271356183668746, 0.11420627305427256, 0.11420627305427256, 0.11420627305427256, 0.1366109952920993, 0.1366109952920993, 0.1366109952920993, 0.6716788495300214, 0.6716788495300214, 0.6716788495300214, 0.6525119270873981, 0.6525119270873981, 0.6525119270873981, 0.7335310158747503, 0.7335310158747503, 0.7335310158747503, 0.22509205180813374, 0.22509205180813374, 0.22509205180813374, 0.23846259715961882, 0.23846259715961882, 0.23846259715961882, 0.23026115778748257, 0.23026115778748257, 0.23026115778748257, 0.10729408229532489, 0.10729408229532489, 0.10729408229532489, 0.08707462555969336, 0.08707462555969336, 0.08707462555969336, 0.09244825892062858, 0.09244825892062858, 0.09244825892062858]}, "mutation_prompt": null}
{"id": "52bc2b00-fa8b-4c41-9cbe-a4a69770c39c", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(70, 12 * dim)  # Increased particles slightly for diversity\n        self.c1 = 1.4  # Further reduced cognitive component for better balance\n        self.c2 = 2.2  # Further increased social component to leverage collective intelligence\n        self.w = 0.85  # Adjusted inertia weight to balance exploration and exploitation\n        self.decay_rate = 0.93  # Faster decay to reduce inertia over time\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.1  # Increased velocity limit for more aggressive movement\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced APSO with adaptive learning components and improved velocity dynamics for faster convergence.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.8890345554254235, 0.8890345554254235, 0.8890345554254235, 0.8812898909220918, 0.8812898909220918, 0.8812898909220918, 0.885169648507018, 0.885169648507018, 0.885169648507018, 0.7943252300909807, 0.7943252300909807, 0.7943252300909807, 0.7992832977617781, 0.7992832977617781, 0.7992832977617781, 0.806978601700252, 0.806978601700252, 0.806978601700252, 0.141836067863071, 0.141836067863071, 0.141836067863071, 0.09072257940144113, 0.09072257940144113, 0.09072257940144113, 0.11538296000510384, 0.11538296000510384, 0.11538296000510384, 0.09182634705732529, 0.09182634705732529, 0.09182634705732529, 0.10396507449566983, 0.10396507449566983, 0.10396507449566983, 0.12877403769140183, 0.12877403769140183, 0.12877403769140183, 0.9171003036492754, 0.9171003036492754, 0.9171003036492754, 0.9426071411196885, 0.9426071411196885, 0.9426071411196885, 0.947537189438548, 0.947537189438548, 0.947537189438548, 0.6001545147287968, 0.6001545147287968, 0.6001545147287968, 0.684584432385599, 0.684584432385599, 0.684584432385599, 0.5898963208656243, 0.5898963208656243, 0.5898963208656243, 0.19375146093521256, 0.19375146093521256, 0.19375146093521256, 0.8693944340969452, 0.8693944340969452, 0.8693944340969452, 0.748951913666398, 0.748951913666398, 0.748951913666398, 0.21327141745353018, 0.21327141745353018, 0.21327141745353018, 0.20118277962625464, 0.20118277962625464, 0.20118277962625464, 0.22068388192974941, 0.22068388192974941, 0.22068388192974941, 0.23075865172070587, 0.23075865172070587, 0.23075865172070587, 0.2135229554500695, 0.2135229554500695, 0.2135229554500695, 0.23668946202621444, 0.23668946202621444, 0.23668946202621444, 0.005148868860398448, 0.005148868860398448, 0.005148868860398448, 0.08177194701312396, 0.08177194701312396, 0.08177194701312396, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08208764747391684, 0.08208764747391684, 0.08208764747391684, 0.05568690635405671, 0.05568690635405671, 0.05568690635405671, 0.11343134532868715, 0.11343134532868715, 0.11343134532868715, 0.04909694094295114, 0.04909694094295114, 0.04909694094295114, 0.11383841177004017, 0.11383841177004017, 0.11383841177004017, 0.26109733429390813, 0.26109733429390813, 0.26109733429390813, 0.25317053091270736, 0.25317053091270736, 0.25317053091270736, 0.10090994703812939, 0.10090994703812939, 0.10090994703812939, 0.11422164786062972, 0.11422164786062972, 0.11422164786062972, 0.5212488269937966, 0.5212488269937966, 0.5212488269937966, 0.6092900456626009, 0.6092900456626009, 0.6092900456626009, 0.5657986694000723, 0.5657986694000723, 0.5657986694000723, 0.07625858721913681, 0.07625858721913681, 0.07625858721913681, 0.11353684310069889, 0.11353684310069889, 0.11353684310069889, 0.13349225556029598, 0.13349225556029598, 0.13349225556029598, 0.2923087655110267, 0.2923087655110267, 0.2923087655110267, 0.17058849530006337, 0.17058849530006337, 0.17058849530006337, 0.36867958361848363, 0.36867958361848363, 0.36867958361848363, 0.40865239548570576, 0.40865239548570576, 0.40865239548570576, 0.39714577174572396, 0.39714577174572396, 0.39714577174572396, 0.2695926147327291, 0.2695926147327291, 0.2695926147327291, 0.21811446266173207, 0.21811446266173207, 0.21811446266173207, 0.34268712567274884, 0.34268712567274884, 0.34268712567274884, 0.22874659868451208, 0.22874659868451208, 0.22874659868451208, 0.21928541749058428, 0.21928541749058428, 0.21928541749058428, 0.22679558567235403, 0.22679558567235403, 0.22679558567235403, 0.2801068714944557, 0.2801068714944557, 0.2801068714944557, 0.24859292531735677, 0.24859292531735677, 0.24859292531735677, 0.22841934362266458, 0.22841934362266458, 0.22841934362266458, 0.2168144089226336, 0.2168144089226336, 0.2168144089226336, 0.9271356183668746, 0.9271356183668746, 0.9271356183668746, 0.11420627305427256, 0.11420627305427256, 0.11420627305427256, 0.1366109952920993, 0.1366109952920993, 0.1366109952920993, 0.6716788495300214, 0.6716788495300214, 0.6716788495300214, 0.6525119270873981, 0.6525119270873981, 0.6525119270873981, 0.7335310158747503, 0.7335310158747503, 0.7335310158747503, 0.22509205180813374, 0.22509205180813374, 0.22509205180813374, 0.23846259715961882, 0.23846259715961882, 0.23846259715961882, 0.23026115778748257, 0.23026115778748257, 0.23026115778748257, 0.10729408229532489, 0.10729408229532489, 0.10729408229532489, 0.08707462555969336, 0.08707462555969336, 0.08707462555969336, 0.09244825892062858, 0.09244825892062858, 0.09244825892062858]}, "mutation_prompt": null}
{"id": "3ee25c5e-5ccf-4a72-bb06-b4a4078909d0", "solution": "import numpy as np\n\nclass AcceleratedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(65, 14 * dim)  # Slightly adjusted particle count for initial diversity\n        self.c1 = 1.3  # Small reduction in cognitive component to enhance social impact\n        self.c2 = 2.4  # Further increase in social component for stronger collective pull\n        self.w = 0.9  # Increased initial inertia weight for exploration\n        self.decay_rate = 0.92  # Adjusted decay for gradual inertia reduction\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.09  # Slightly reduced velocity limit for control\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                neighborhood_best_position = pos[np.random.choice(range(self.num_particles))]\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]) + \n                          0.5 * np.random.rand(self.dim) * (neighborhood_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight gradually\n        \n        return global_best_position, global_best_score", "name": "AcceleratedAPSO", "description": "Accelerated APSO with dynamic neighborhood influence and adaptive inertia for improved convergence.", "configspace": "", "generation": 53, "fitness": 0.22418109161202385, "feedback": "The algorithm AcceleratedAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.20.", "error": "", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.421782015592822, 0.421782015592822, 0.421782015592822, 0.4897620202620192, 0.4897620202620192, 0.4897620202620192, 0.42536178915035705, 0.42536178915035705, 0.42536178915035705, 0.0502752125760233, 0.0502752125760233, 0.0502752125760233, 0.00383623752665585, 0.00383623752665585, 0.00383623752665585, 0.05081676140037761, 0.05081676140037761, 0.05081676140037761, 0.11010305125960551, 0.11010305125960551, 0.11010305125960551, 0.1058917117577225, 0.1058917117577225, 0.1058917117577225, 0.1298348334757644, 0.1298348334757644, 0.1298348334757644, 0.09060116792387929, 0.09060116792387929, 0.09060116792387929, 0.10855792707934686, 0.10855792707934686, 0.10855792707934686, 0.08194888561072333, 0.08194888561072333, 0.08194888561072333, 0.9254757773888653, 0.9254757773888653, 0.9254757773888653, 0.9282663376352533, 0.9282663376352533, 0.9282663376352533, 0.9285825755659259, 0.9285825755659259, 0.9285825755659259, 0.2995107968175825, 0.2995107968175825, 0.2995107968175825, 0.30662083249682615, 0.30662083249682615, 0.30662083249682615, 0.2727999212380219, 0.2727999212380219, 0.2727999212380219, 0.21295286321536444, 0.21295286321536444, 0.21295286321536444, 0.22772977011398132, 0.22772977011398132, 0.22772977011398132, 0.33441668361847, 0.33441668361847, 0.33441668361847, 0.16117789356887846, 0.16117789356887846, 0.16117789356887846, 0.15715113976611284, 0.15715113976611284, 0.15715113976611284, 0.14626578622405773, 0.14626578622405773, 0.14626578622405773, 0.15599335448879337, 0.15599335448879337, 0.15599335448879337, 0.16230687231162688, 0.16230687231162688, 0.16230687231162688, 0.14179337201544517, 0.14179337201544517, 0.14179337201544517, 0.020213216493031316, 0.020213216493031316, 0.020213216493031316, 0.005870599977680135, 0.005870599977680135, 0.005870599977680135, 0.03717515041079822, 0.03717515041079822, 0.03717515041079822, 0.11242437333787969, 0.11242437333787969, 0.11242437333787969, 0.05250433321266812, 0.05250433321266812, 0.05250433321266812, 0.10383734759487429, 0.10383734759487429, 0.10383734759487429, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0008702944379042066, 0.0008702944379042066, 0.0008702944379042066, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.111918234672582, 0.111918234672582, 0.111918234672582, 0.12296556152965255, 0.12296556152965255, 0.12296556152965255, 0.10386697246675536, 0.10386697246675536, 0.10386697246675536, 0.3889335330992644, 0.3889335330992644, 0.3889335330992644, 0.4088551660055434, 0.4088551660055434, 0.4088551660055434, 0.38021741541084697, 0.38021741541084697, 0.38021741541084697, 0.10758721152968065, 0.10758721152968065, 0.10758721152968065, 0.1018183310584907, 0.1018183310584907, 0.1018183310584907, 0.11718650198970448, 0.11718650198970448, 0.11718650198970448, 0.19491019290421963, 0.19491019290421963, 0.19491019290421963, 0.2256995779534131, 0.2256995779534131, 0.2256995779534131, 0.2378398338236315, 0.2378398338236315, 0.2378398338236315, 0.29064453648771615, 0.29064453648771615, 0.29064453648771615, 0.2971869912506029, 0.2971869912506029, 0.2971869912506029, 0.23116821499318896, 0.23116821499318896, 0.23116821499318896, 0.22739604269837277, 0.22739604269837277, 0.22739604269837277, 0.22601819954863966, 0.22601819954863966, 0.22601819954863966, 0.18212481675428993, 0.18212481675428993, 0.18212481675428993, 0.23463979449043293, 0.23463979449043293, 0.23463979449043293, 0.26137047960547666, 0.26137047960547666, 0.26137047960547666, 0.2358904521779709, 0.2358904521779709, 0.2358904521779709, 0.18595655484716211, 0.18595655484716211, 0.18595655484716211, 0.19693432711066894, 0.19693432711066894, 0.19693432711066894, 0.20919443303772778, 0.20919443303772778, 0.20919443303772778, 0.6486980385760373, 0.6486980385760373, 0.6486980385760373, 0.1647028554769644, 0.1647028554769644, 0.1647028554769644, 0.6739683527215403, 0.6739683527215403, 0.6739683527215403, 0.4988894745136294, 0.4988894745136294, 0.4988894745136294, 0.2088382697965837, 0.2088382697965837, 0.2088382697965837, 0.12651005394974002, 0.12651005394974002, 0.12651005394974002, 0.17966599599798627, 0.17966599599798627, 0.17966599599798627, 0.17810909057289825, 0.17810909057289825, 0.17810909057289825, 0.1852249083820744, 0.1852249083820744, 0.1852249083820744, 0.0848961812742195, 0.0848961812742195, 0.0848961812742195, 0.0859001207450597, 0.0859001207450597, 0.0859001207450597, 0.06240097306761294, 0.06240097306761294, 0.06240097306761294]}, "mutation_prompt": null}
{"id": "0458b038-771f-4307-b2f5-9983488f22d1", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(70, 12 * dim)  # Increased particles slightly for diversity\n        self.c1 = 1.4  # Further reduced cognitive component for better balance\n        self.c2 = 2.2  # Further increased social component to leverage collective intelligence\n        self.w = 0.85  # Adjusted inertia weight to balance exploration and exploitation\n        self.decay_rate = 0.93  # Faster decay to reduce inertia over time\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.1  # Increased velocity limit for more aggressive movement\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced APSO with adaptive learning components and improved velocity dynamics for faster convergence.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.8890345554254235, 0.8890345554254235, 0.8890345554254235, 0.8812898909220918, 0.8812898909220918, 0.8812898909220918, 0.885169648507018, 0.885169648507018, 0.885169648507018, 0.7943252300909807, 0.7943252300909807, 0.7943252300909807, 0.7992832977617781, 0.7992832977617781, 0.7992832977617781, 0.806978601700252, 0.806978601700252, 0.806978601700252, 0.141836067863071, 0.141836067863071, 0.141836067863071, 0.09072257940144113, 0.09072257940144113, 0.09072257940144113, 0.11538296000510384, 0.11538296000510384, 0.11538296000510384, 0.09182634705732529, 0.09182634705732529, 0.09182634705732529, 0.10396507449566983, 0.10396507449566983, 0.10396507449566983, 0.12877403769140183, 0.12877403769140183, 0.12877403769140183, 0.9171003036492754, 0.9171003036492754, 0.9171003036492754, 0.9426071411196885, 0.9426071411196885, 0.9426071411196885, 0.947537189438548, 0.947537189438548, 0.947537189438548, 0.6001545147287968, 0.6001545147287968, 0.6001545147287968, 0.684584432385599, 0.684584432385599, 0.684584432385599, 0.5898963208656243, 0.5898963208656243, 0.5898963208656243, 0.19375146093521256, 0.19375146093521256, 0.19375146093521256, 0.8693944340969452, 0.8693944340969452, 0.8693944340969452, 0.748951913666398, 0.748951913666398, 0.748951913666398, 0.21327141745353018, 0.21327141745353018, 0.21327141745353018, 0.20118277962625464, 0.20118277962625464, 0.20118277962625464, 0.22068388192974941, 0.22068388192974941, 0.22068388192974941, 0.23075865172070587, 0.23075865172070587, 0.23075865172070587, 0.2135229554500695, 0.2135229554500695, 0.2135229554500695, 0.23668946202621444, 0.23668946202621444, 0.23668946202621444, 0.005148868860398448, 0.005148868860398448, 0.005148868860398448, 0.08177194701312396, 0.08177194701312396, 0.08177194701312396, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08208764747391684, 0.08208764747391684, 0.08208764747391684, 0.05568690635405671, 0.05568690635405671, 0.05568690635405671, 0.11343134532868715, 0.11343134532868715, 0.11343134532868715, 0.04909694094295114, 0.04909694094295114, 0.04909694094295114, 0.11383841177004017, 0.11383841177004017, 0.11383841177004017, 0.26109733429390813, 0.26109733429390813, 0.26109733429390813, 0.25317053091270736, 0.25317053091270736, 0.25317053091270736, 0.10090994703812939, 0.10090994703812939, 0.10090994703812939, 0.11422164786062972, 0.11422164786062972, 0.11422164786062972, 0.5212488269937966, 0.5212488269937966, 0.5212488269937966, 0.6092900456626009, 0.6092900456626009, 0.6092900456626009, 0.5657986694000723, 0.5657986694000723, 0.5657986694000723, 0.07625858721913681, 0.07625858721913681, 0.07625858721913681, 0.11353684310069889, 0.11353684310069889, 0.11353684310069889, 0.13349225556029598, 0.13349225556029598, 0.13349225556029598, 0.2923087655110267, 0.2923087655110267, 0.2923087655110267, 0.17058849530006337, 0.17058849530006337, 0.17058849530006337, 0.36867958361848363, 0.36867958361848363, 0.36867958361848363, 0.40865239548570576, 0.40865239548570576, 0.40865239548570576, 0.39714577174572396, 0.39714577174572396, 0.39714577174572396, 0.2695926147327291, 0.2695926147327291, 0.2695926147327291, 0.21811446266173207, 0.21811446266173207, 0.21811446266173207, 0.34268712567274884, 0.34268712567274884, 0.34268712567274884, 0.22874659868451208, 0.22874659868451208, 0.22874659868451208, 0.21928541749058428, 0.21928541749058428, 0.21928541749058428, 0.22679558567235403, 0.22679558567235403, 0.22679558567235403, 0.2801068714944557, 0.2801068714944557, 0.2801068714944557, 0.24859292531735677, 0.24859292531735677, 0.24859292531735677, 0.22841934362266458, 0.22841934362266458, 0.22841934362266458, 0.2168144089226336, 0.2168144089226336, 0.2168144089226336, 0.9271356183668746, 0.9271356183668746, 0.9271356183668746, 0.11420627305427256, 0.11420627305427256, 0.11420627305427256, 0.1366109952920993, 0.1366109952920993, 0.1366109952920993, 0.6716788495300214, 0.6716788495300214, 0.6716788495300214, 0.6525119270873981, 0.6525119270873981, 0.6525119270873981, 0.7335310158747503, 0.7335310158747503, 0.7335310158747503, 0.22509205180813374, 0.22509205180813374, 0.22509205180813374, 0.23846259715961882, 0.23846259715961882, 0.23846259715961882, 0.23026115778748257, 0.23026115778748257, 0.23026115778748257, 0.10729408229532489, 0.10729408229532489, 0.10729408229532489, 0.08707462555969336, 0.08707462555969336, 0.08707462555969336, 0.09244825892062858, 0.09244825892062858, 0.09244825892062858]}, "mutation_prompt": null}
{"id": "378b2152-1874-4d73-9c30-4bd09713c52f", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_num_particles = min(70, 12 * dim)  # Initial number of particles\n        self.c1 = 1.5  # Adjusted cognitive component for improved balance\n        self.c2 = 2.0  # Adjusted social component for better collaboration\n        self.w = 0.80  # Adjusted inertia weight for improved convergence\n        self.decay_rate = 0.95  # Slower decay for sustained exploration\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.15  # Increased velocity limit for dynamic responses\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        num_particles = self.initial_num_particles\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            # Adaptively adjust swarm size\n            if evaluations % (self.budget // 5) == 0:\n                num_particles = min(num_particles + 5, self.budget - evaluations)\n\n            for i in range(num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Adaptive velocity calculation\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "EnhancedAPSO with adaptive dynamic swarm size and adaptive velocity to improve convergence speed.", "configspace": "", "generation": 55, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 60 is out of bounds for axis 0 with size 60').", "error": "IndexError('index 60 is out of bounds for axis 0 with size 60')", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {}, "mutation_prompt": null}
{"id": "cb8be55c-a2ae-4343-893f-b6447805d3a9", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(70, 12 * dim)  # Increased particles slightly for diversity\n        self.c1 = 1.4  # Further reduced cognitive component for better balance\n        self.c2 = 2.2  # Further increased social component to leverage collective intelligence\n        self.w = 0.85  # Adjusted inertia weight to balance exploration and exploitation\n        self.decay_rate = 0.93  # Faster decay to reduce inertia over time\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.1  # Increased velocity limit for more aggressive movement\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced APSO with adaptive learning components and improved velocity dynamics for faster convergence.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.8890345554254235, 0.8890345554254235, 0.8890345554254235, 0.8812898909220918, 0.8812898909220918, 0.8812898909220918, 0.885169648507018, 0.885169648507018, 0.885169648507018, 0.7943252300909807, 0.7943252300909807, 0.7943252300909807, 0.7992832977617781, 0.7992832977617781, 0.7992832977617781, 0.806978601700252, 0.806978601700252, 0.806978601700252, 0.141836067863071, 0.141836067863071, 0.141836067863071, 0.09072257940144113, 0.09072257940144113, 0.09072257940144113, 0.11538296000510384, 0.11538296000510384, 0.11538296000510384, 0.09182634705732529, 0.09182634705732529, 0.09182634705732529, 0.10396507449566983, 0.10396507449566983, 0.10396507449566983, 0.12877403769140183, 0.12877403769140183, 0.12877403769140183, 0.9171003036492754, 0.9171003036492754, 0.9171003036492754, 0.9426071411196885, 0.9426071411196885, 0.9426071411196885, 0.947537189438548, 0.947537189438548, 0.947537189438548, 0.6001545147287968, 0.6001545147287968, 0.6001545147287968, 0.684584432385599, 0.684584432385599, 0.684584432385599, 0.5898963208656243, 0.5898963208656243, 0.5898963208656243, 0.19375146093521256, 0.19375146093521256, 0.19375146093521256, 0.8693944340969452, 0.8693944340969452, 0.8693944340969452, 0.748951913666398, 0.748951913666398, 0.748951913666398, 0.21327141745353018, 0.21327141745353018, 0.21327141745353018, 0.20118277962625464, 0.20118277962625464, 0.20118277962625464, 0.22068388192974941, 0.22068388192974941, 0.22068388192974941, 0.23075865172070587, 0.23075865172070587, 0.23075865172070587, 0.2135229554500695, 0.2135229554500695, 0.2135229554500695, 0.23668946202621444, 0.23668946202621444, 0.23668946202621444, 0.005148868860398448, 0.005148868860398448, 0.005148868860398448, 0.08177194701312396, 0.08177194701312396, 0.08177194701312396, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08208764747391684, 0.08208764747391684, 0.08208764747391684, 0.05568690635405671, 0.05568690635405671, 0.05568690635405671, 0.11343134532868715, 0.11343134532868715, 0.11343134532868715, 0.04909694094295114, 0.04909694094295114, 0.04909694094295114, 0.11383841177004017, 0.11383841177004017, 0.11383841177004017, 0.26109733429390813, 0.26109733429390813, 0.26109733429390813, 0.25317053091270736, 0.25317053091270736, 0.25317053091270736, 0.10090994703812939, 0.10090994703812939, 0.10090994703812939, 0.11422164786062972, 0.11422164786062972, 0.11422164786062972, 0.5212488269937966, 0.5212488269937966, 0.5212488269937966, 0.6092900456626009, 0.6092900456626009, 0.6092900456626009, 0.5657986694000723, 0.5657986694000723, 0.5657986694000723, 0.07625858721913681, 0.07625858721913681, 0.07625858721913681, 0.11353684310069889, 0.11353684310069889, 0.11353684310069889, 0.13349225556029598, 0.13349225556029598, 0.13349225556029598, 0.2923087655110267, 0.2923087655110267, 0.2923087655110267, 0.17058849530006337, 0.17058849530006337, 0.17058849530006337, 0.36867958361848363, 0.36867958361848363, 0.36867958361848363, 0.40865239548570576, 0.40865239548570576, 0.40865239548570576, 0.39714577174572396, 0.39714577174572396, 0.39714577174572396, 0.2695926147327291, 0.2695926147327291, 0.2695926147327291, 0.21811446266173207, 0.21811446266173207, 0.21811446266173207, 0.34268712567274884, 0.34268712567274884, 0.34268712567274884, 0.22874659868451208, 0.22874659868451208, 0.22874659868451208, 0.21928541749058428, 0.21928541749058428, 0.21928541749058428, 0.22679558567235403, 0.22679558567235403, 0.22679558567235403, 0.2801068714944557, 0.2801068714944557, 0.2801068714944557, 0.24859292531735677, 0.24859292531735677, 0.24859292531735677, 0.22841934362266458, 0.22841934362266458, 0.22841934362266458, 0.2168144089226336, 0.2168144089226336, 0.2168144089226336, 0.9271356183668746, 0.9271356183668746, 0.9271356183668746, 0.11420627305427256, 0.11420627305427256, 0.11420627305427256, 0.1366109952920993, 0.1366109952920993, 0.1366109952920993, 0.6716788495300214, 0.6716788495300214, 0.6716788495300214, 0.6525119270873981, 0.6525119270873981, 0.6525119270873981, 0.7335310158747503, 0.7335310158747503, 0.7335310158747503, 0.22509205180813374, 0.22509205180813374, 0.22509205180813374, 0.23846259715961882, 0.23846259715961882, 0.23846259715961882, 0.23026115778748257, 0.23026115778748257, 0.23026115778748257, 0.10729408229532489, 0.10729408229532489, 0.10729408229532489, 0.08707462555969336, 0.08707462555969336, 0.08707462555969336, 0.09244825892062858, 0.09244825892062858, 0.09244825892062858]}, "mutation_prompt": null}
{"id": "cfc2d3a8-482f-4219-924d-0c4bdd70597b", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(70, 12 * dim)  # Increased particles slightly for diversity\n        self.c1 = 1.4  # Further reduced cognitive component for better balance\n        self.c2 = 2.2  # Further increased social component to leverage collective intelligence\n        self.w = 0.85  # Adjusted inertia weight to balance exploration and exploitation\n        self.decay_rate = 0.93  # Faster decay to reduce inertia over time\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.1  # Increased velocity limit for more aggressive movement\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced APSO with adaptive learning components and improved velocity dynamics for faster convergence.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.8890345554254235, 0.8890345554254235, 0.8890345554254235, 0.8812898909220918, 0.8812898909220918, 0.8812898909220918, 0.885169648507018, 0.885169648507018, 0.885169648507018, 0.7943252300909807, 0.7943252300909807, 0.7943252300909807, 0.7992832977617781, 0.7992832977617781, 0.7992832977617781, 0.806978601700252, 0.806978601700252, 0.806978601700252, 0.141836067863071, 0.141836067863071, 0.141836067863071, 0.09072257940144113, 0.09072257940144113, 0.09072257940144113, 0.11538296000510384, 0.11538296000510384, 0.11538296000510384, 0.09182634705732529, 0.09182634705732529, 0.09182634705732529, 0.10396507449566983, 0.10396507449566983, 0.10396507449566983, 0.12877403769140183, 0.12877403769140183, 0.12877403769140183, 0.9171003036492754, 0.9171003036492754, 0.9171003036492754, 0.9426071411196885, 0.9426071411196885, 0.9426071411196885, 0.947537189438548, 0.947537189438548, 0.947537189438548, 0.6001545147287968, 0.6001545147287968, 0.6001545147287968, 0.684584432385599, 0.684584432385599, 0.684584432385599, 0.5898963208656243, 0.5898963208656243, 0.5898963208656243, 0.19375146093521256, 0.19375146093521256, 0.19375146093521256, 0.8693944340969452, 0.8693944340969452, 0.8693944340969452, 0.748951913666398, 0.748951913666398, 0.748951913666398, 0.21327141745353018, 0.21327141745353018, 0.21327141745353018, 0.20118277962625464, 0.20118277962625464, 0.20118277962625464, 0.22068388192974941, 0.22068388192974941, 0.22068388192974941, 0.23075865172070587, 0.23075865172070587, 0.23075865172070587, 0.2135229554500695, 0.2135229554500695, 0.2135229554500695, 0.23668946202621444, 0.23668946202621444, 0.23668946202621444, 0.005148868860398448, 0.005148868860398448, 0.005148868860398448, 0.08177194701312396, 0.08177194701312396, 0.08177194701312396, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08208764747391684, 0.08208764747391684, 0.08208764747391684, 0.05568690635405671, 0.05568690635405671, 0.05568690635405671, 0.11343134532868715, 0.11343134532868715, 0.11343134532868715, 0.04909694094295114, 0.04909694094295114, 0.04909694094295114, 0.11383841177004017, 0.11383841177004017, 0.11383841177004017, 0.26109733429390813, 0.26109733429390813, 0.26109733429390813, 0.25317053091270736, 0.25317053091270736, 0.25317053091270736, 0.10090994703812939, 0.10090994703812939, 0.10090994703812939, 0.11422164786062972, 0.11422164786062972, 0.11422164786062972, 0.5212488269937966, 0.5212488269937966, 0.5212488269937966, 0.6092900456626009, 0.6092900456626009, 0.6092900456626009, 0.5657986694000723, 0.5657986694000723, 0.5657986694000723, 0.07625858721913681, 0.07625858721913681, 0.07625858721913681, 0.11353684310069889, 0.11353684310069889, 0.11353684310069889, 0.13349225556029598, 0.13349225556029598, 0.13349225556029598, 0.2923087655110267, 0.2923087655110267, 0.2923087655110267, 0.17058849530006337, 0.17058849530006337, 0.17058849530006337, 0.36867958361848363, 0.36867958361848363, 0.36867958361848363, 0.40865239548570576, 0.40865239548570576, 0.40865239548570576, 0.39714577174572396, 0.39714577174572396, 0.39714577174572396, 0.2695926147327291, 0.2695926147327291, 0.2695926147327291, 0.21811446266173207, 0.21811446266173207, 0.21811446266173207, 0.34268712567274884, 0.34268712567274884, 0.34268712567274884, 0.22874659868451208, 0.22874659868451208, 0.22874659868451208, 0.21928541749058428, 0.21928541749058428, 0.21928541749058428, 0.22679558567235403, 0.22679558567235403, 0.22679558567235403, 0.2801068714944557, 0.2801068714944557, 0.2801068714944557, 0.24859292531735677, 0.24859292531735677, 0.24859292531735677, 0.22841934362266458, 0.22841934362266458, 0.22841934362266458, 0.2168144089226336, 0.2168144089226336, 0.2168144089226336, 0.9271356183668746, 0.9271356183668746, 0.9271356183668746, 0.11420627305427256, 0.11420627305427256, 0.11420627305427256, 0.1366109952920993, 0.1366109952920993, 0.1366109952920993, 0.6716788495300214, 0.6716788495300214, 0.6716788495300214, 0.6525119270873981, 0.6525119270873981, 0.6525119270873981, 0.7335310158747503, 0.7335310158747503, 0.7335310158747503, 0.22509205180813374, 0.22509205180813374, 0.22509205180813374, 0.23846259715961882, 0.23846259715961882, 0.23846259715961882, 0.23026115778748257, 0.23026115778748257, 0.23026115778748257, 0.10729408229532489, 0.10729408229532489, 0.10729408229532489, 0.08707462555969336, 0.08707462555969336, 0.08707462555969336, 0.09244825892062858, 0.09244825892062858, 0.09244825892062858]}, "mutation_prompt": null}
{"id": "a97183c1-541e-42ab-8f5d-6a56373a7953", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(70, 12 * dim)  # Increased particles slightly for diversity\n        self.c1 = 1.4  # Further reduced cognitive component for better balance\n        self.c2 = 2.2  # Further increased social component to leverage collective intelligence\n        self.w = 0.85  # Adjusted inertia weight to balance exploration and exploitation\n        self.decay_rate = 0.93  # Faster decay to reduce inertia over time\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.1  # Increased velocity limit for more aggressive movement\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced APSO with adaptive learning components and improved velocity dynamics for faster convergence.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.8890345554254235, 0.8890345554254235, 0.8890345554254235, 0.8812898909220918, 0.8812898909220918, 0.8812898909220918, 0.885169648507018, 0.885169648507018, 0.885169648507018, 0.7943252300909807, 0.7943252300909807, 0.7943252300909807, 0.7992832977617781, 0.7992832977617781, 0.7992832977617781, 0.806978601700252, 0.806978601700252, 0.806978601700252, 0.141836067863071, 0.141836067863071, 0.141836067863071, 0.09072257940144113, 0.09072257940144113, 0.09072257940144113, 0.11538296000510384, 0.11538296000510384, 0.11538296000510384, 0.09182634705732529, 0.09182634705732529, 0.09182634705732529, 0.10396507449566983, 0.10396507449566983, 0.10396507449566983, 0.12877403769140183, 0.12877403769140183, 0.12877403769140183, 0.9171003036492754, 0.9171003036492754, 0.9171003036492754, 0.9426071411196885, 0.9426071411196885, 0.9426071411196885, 0.947537189438548, 0.947537189438548, 0.947537189438548, 0.6001545147287968, 0.6001545147287968, 0.6001545147287968, 0.684584432385599, 0.684584432385599, 0.684584432385599, 0.5898963208656243, 0.5898963208656243, 0.5898963208656243, 0.19375146093521256, 0.19375146093521256, 0.19375146093521256, 0.8693944340969452, 0.8693944340969452, 0.8693944340969452, 0.748951913666398, 0.748951913666398, 0.748951913666398, 0.21327141745353018, 0.21327141745353018, 0.21327141745353018, 0.20118277962625464, 0.20118277962625464, 0.20118277962625464, 0.22068388192974941, 0.22068388192974941, 0.22068388192974941, 0.23075865172070587, 0.23075865172070587, 0.23075865172070587, 0.2135229554500695, 0.2135229554500695, 0.2135229554500695, 0.23668946202621444, 0.23668946202621444, 0.23668946202621444, 0.005148868860398448, 0.005148868860398448, 0.005148868860398448, 0.08177194701312396, 0.08177194701312396, 0.08177194701312396, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08208764747391684, 0.08208764747391684, 0.08208764747391684, 0.05568690635405671, 0.05568690635405671, 0.05568690635405671, 0.11343134532868715, 0.11343134532868715, 0.11343134532868715, 0.04909694094295114, 0.04909694094295114, 0.04909694094295114, 0.11383841177004017, 0.11383841177004017, 0.11383841177004017, 0.26109733429390813, 0.26109733429390813, 0.26109733429390813, 0.25317053091270736, 0.25317053091270736, 0.25317053091270736, 0.10090994703812939, 0.10090994703812939, 0.10090994703812939, 0.11422164786062972, 0.11422164786062972, 0.11422164786062972, 0.5212488269937966, 0.5212488269937966, 0.5212488269937966, 0.6092900456626009, 0.6092900456626009, 0.6092900456626009, 0.5657986694000723, 0.5657986694000723, 0.5657986694000723, 0.07625858721913681, 0.07625858721913681, 0.07625858721913681, 0.11353684310069889, 0.11353684310069889, 0.11353684310069889, 0.13349225556029598, 0.13349225556029598, 0.13349225556029598, 0.2923087655110267, 0.2923087655110267, 0.2923087655110267, 0.17058849530006337, 0.17058849530006337, 0.17058849530006337, 0.36867958361848363, 0.36867958361848363, 0.36867958361848363, 0.40865239548570576, 0.40865239548570576, 0.40865239548570576, 0.39714577174572396, 0.39714577174572396, 0.39714577174572396, 0.2695926147327291, 0.2695926147327291, 0.2695926147327291, 0.21811446266173207, 0.21811446266173207, 0.21811446266173207, 0.34268712567274884, 0.34268712567274884, 0.34268712567274884, 0.22874659868451208, 0.22874659868451208, 0.22874659868451208, 0.21928541749058428, 0.21928541749058428, 0.21928541749058428, 0.22679558567235403, 0.22679558567235403, 0.22679558567235403, 0.2801068714944557, 0.2801068714944557, 0.2801068714944557, 0.24859292531735677, 0.24859292531735677, 0.24859292531735677, 0.22841934362266458, 0.22841934362266458, 0.22841934362266458, 0.2168144089226336, 0.2168144089226336, 0.2168144089226336, 0.9271356183668746, 0.9271356183668746, 0.9271356183668746, 0.11420627305427256, 0.11420627305427256, 0.11420627305427256, 0.1366109952920993, 0.1366109952920993, 0.1366109952920993, 0.6716788495300214, 0.6716788495300214, 0.6716788495300214, 0.6525119270873981, 0.6525119270873981, 0.6525119270873981, 0.7335310158747503, 0.7335310158747503, 0.7335310158747503, 0.22509205180813374, 0.22509205180813374, 0.22509205180813374, 0.23846259715961882, 0.23846259715961882, 0.23846259715961882, 0.23026115778748257, 0.23026115778748257, 0.23026115778748257, 0.10729408229532489, 0.10729408229532489, 0.10729408229532489, 0.08707462555969336, 0.08707462555969336, 0.08707462555969336, 0.09244825892062858, 0.09244825892062858, 0.09244825892062858]}, "mutation_prompt": null}
{"id": "ec72c1cc-cea2-45a9-9b46-cac6c6c55d8b", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(70, 12 * dim)  # Increased particles slightly for diversity\n        self.c1 = 1.4  # Further reduced cognitive component for better balance\n        self.c2 = 2.2  # Further increased social component to leverage collective intelligence\n        self.w = 0.85  # Adjusted inertia weight to balance exploration and exploitation\n        self.decay_rate = 0.93  # Faster decay to reduce inertia over time\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.1  # Increased velocity limit for more aggressive movement\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced APSO with adaptive learning components and improved velocity dynamics for faster convergence.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.8890345554254235, 0.8890345554254235, 0.8890345554254235, 0.8812898909220918, 0.8812898909220918, 0.8812898909220918, 0.885169648507018, 0.885169648507018, 0.885169648507018, 0.7943252300909807, 0.7943252300909807, 0.7943252300909807, 0.7992832977617781, 0.7992832977617781, 0.7992832977617781, 0.806978601700252, 0.806978601700252, 0.806978601700252, 0.141836067863071, 0.141836067863071, 0.141836067863071, 0.09072257940144113, 0.09072257940144113, 0.09072257940144113, 0.11538296000510384, 0.11538296000510384, 0.11538296000510384, 0.09182634705732529, 0.09182634705732529, 0.09182634705732529, 0.10396507449566983, 0.10396507449566983, 0.10396507449566983, 0.12877403769140183, 0.12877403769140183, 0.12877403769140183, 0.9171003036492754, 0.9171003036492754, 0.9171003036492754, 0.9426071411196885, 0.9426071411196885, 0.9426071411196885, 0.947537189438548, 0.947537189438548, 0.947537189438548, 0.6001545147287968, 0.6001545147287968, 0.6001545147287968, 0.684584432385599, 0.684584432385599, 0.684584432385599, 0.5898963208656243, 0.5898963208656243, 0.5898963208656243, 0.19375146093521256, 0.19375146093521256, 0.19375146093521256, 0.8693944340969452, 0.8693944340969452, 0.8693944340969452, 0.748951913666398, 0.748951913666398, 0.748951913666398, 0.21327141745353018, 0.21327141745353018, 0.21327141745353018, 0.20118277962625464, 0.20118277962625464, 0.20118277962625464, 0.22068388192974941, 0.22068388192974941, 0.22068388192974941, 0.23075865172070587, 0.23075865172070587, 0.23075865172070587, 0.2135229554500695, 0.2135229554500695, 0.2135229554500695, 0.23668946202621444, 0.23668946202621444, 0.23668946202621444, 0.005148868860398448, 0.005148868860398448, 0.005148868860398448, 0.08177194701312396, 0.08177194701312396, 0.08177194701312396, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08208764747391684, 0.08208764747391684, 0.08208764747391684, 0.05568690635405671, 0.05568690635405671, 0.05568690635405671, 0.11343134532868715, 0.11343134532868715, 0.11343134532868715, 0.04909694094295114, 0.04909694094295114, 0.04909694094295114, 0.11383841177004017, 0.11383841177004017, 0.11383841177004017, 0.26109733429390813, 0.26109733429390813, 0.26109733429390813, 0.25317053091270736, 0.25317053091270736, 0.25317053091270736, 0.10090994703812939, 0.10090994703812939, 0.10090994703812939, 0.11422164786062972, 0.11422164786062972, 0.11422164786062972, 0.5212488269937966, 0.5212488269937966, 0.5212488269937966, 0.6092900456626009, 0.6092900456626009, 0.6092900456626009, 0.5657986694000723, 0.5657986694000723, 0.5657986694000723, 0.07625858721913681, 0.07625858721913681, 0.07625858721913681, 0.11353684310069889, 0.11353684310069889, 0.11353684310069889, 0.13349225556029598, 0.13349225556029598, 0.13349225556029598, 0.2923087655110267, 0.2923087655110267, 0.2923087655110267, 0.17058849530006337, 0.17058849530006337, 0.17058849530006337, 0.36867958361848363, 0.36867958361848363, 0.36867958361848363, 0.40865239548570576, 0.40865239548570576, 0.40865239548570576, 0.39714577174572396, 0.39714577174572396, 0.39714577174572396, 0.2695926147327291, 0.2695926147327291, 0.2695926147327291, 0.21811446266173207, 0.21811446266173207, 0.21811446266173207, 0.34268712567274884, 0.34268712567274884, 0.34268712567274884, 0.22874659868451208, 0.22874659868451208, 0.22874659868451208, 0.21928541749058428, 0.21928541749058428, 0.21928541749058428, 0.22679558567235403, 0.22679558567235403, 0.22679558567235403, 0.2801068714944557, 0.2801068714944557, 0.2801068714944557, 0.24859292531735677, 0.24859292531735677, 0.24859292531735677, 0.22841934362266458, 0.22841934362266458, 0.22841934362266458, 0.2168144089226336, 0.2168144089226336, 0.2168144089226336, 0.9271356183668746, 0.9271356183668746, 0.9271356183668746, 0.11420627305427256, 0.11420627305427256, 0.11420627305427256, 0.1366109952920993, 0.1366109952920993, 0.1366109952920993, 0.6716788495300214, 0.6716788495300214, 0.6716788495300214, 0.6525119270873981, 0.6525119270873981, 0.6525119270873981, 0.7335310158747503, 0.7335310158747503, 0.7335310158747503, 0.22509205180813374, 0.22509205180813374, 0.22509205180813374, 0.23846259715961882, 0.23846259715961882, 0.23846259715961882, 0.23026115778748257, 0.23026115778748257, 0.23026115778748257, 0.10729408229532489, 0.10729408229532489, 0.10729408229532489, 0.08707462555969336, 0.08707462555969336, 0.08707462555969336, 0.09244825892062858, 0.09244825892062858, 0.09244825892062858]}, "mutation_prompt": null}
{"id": "0674fd36-2cba-48cf-b4d9-3c426f4f1da3", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(70, 12 * dim)  # Increased particles slightly for diversity\n        self.c1 = 1.4  # Further reduced cognitive component for better balance\n        self.c2 = 2.2  # Further increased social component to leverage collective intelligence\n        self.w = 0.85  # Adjusted inertia weight to balance exploration and exploitation\n        self.decay_rate = 0.93  # Faster decay to reduce inertia over time\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.1  # Increased velocity limit for more aggressive movement\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced APSO with adaptive learning components and improved velocity dynamics for faster convergence.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.8890345554254235, 0.8890345554254235, 0.8890345554254235, 0.8812898909220918, 0.8812898909220918, 0.8812898909220918, 0.885169648507018, 0.885169648507018, 0.885169648507018, 0.7943252300909807, 0.7943252300909807, 0.7943252300909807, 0.7992832977617781, 0.7992832977617781, 0.7992832977617781, 0.806978601700252, 0.806978601700252, 0.806978601700252, 0.141836067863071, 0.141836067863071, 0.141836067863071, 0.09072257940144113, 0.09072257940144113, 0.09072257940144113, 0.11538296000510384, 0.11538296000510384, 0.11538296000510384, 0.09182634705732529, 0.09182634705732529, 0.09182634705732529, 0.10396507449566983, 0.10396507449566983, 0.10396507449566983, 0.12877403769140183, 0.12877403769140183, 0.12877403769140183, 0.9171003036492754, 0.9171003036492754, 0.9171003036492754, 0.9426071411196885, 0.9426071411196885, 0.9426071411196885, 0.947537189438548, 0.947537189438548, 0.947537189438548, 0.6001545147287968, 0.6001545147287968, 0.6001545147287968, 0.684584432385599, 0.684584432385599, 0.684584432385599, 0.5898963208656243, 0.5898963208656243, 0.5898963208656243, 0.19375146093521256, 0.19375146093521256, 0.19375146093521256, 0.8693944340969452, 0.8693944340969452, 0.8693944340969452, 0.748951913666398, 0.748951913666398, 0.748951913666398, 0.21327141745353018, 0.21327141745353018, 0.21327141745353018, 0.20118277962625464, 0.20118277962625464, 0.20118277962625464, 0.22068388192974941, 0.22068388192974941, 0.22068388192974941, 0.23075865172070587, 0.23075865172070587, 0.23075865172070587, 0.2135229554500695, 0.2135229554500695, 0.2135229554500695, 0.23668946202621444, 0.23668946202621444, 0.23668946202621444, 0.005148868860398448, 0.005148868860398448, 0.005148868860398448, 0.08177194701312396, 0.08177194701312396, 0.08177194701312396, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08208764747391684, 0.08208764747391684, 0.08208764747391684, 0.05568690635405671, 0.05568690635405671, 0.05568690635405671, 0.11343134532868715, 0.11343134532868715, 0.11343134532868715, 0.04909694094295114, 0.04909694094295114, 0.04909694094295114, 0.11383841177004017, 0.11383841177004017, 0.11383841177004017, 0.26109733429390813, 0.26109733429390813, 0.26109733429390813, 0.25317053091270736, 0.25317053091270736, 0.25317053091270736, 0.10090994703812939, 0.10090994703812939, 0.10090994703812939, 0.11422164786062972, 0.11422164786062972, 0.11422164786062972, 0.5212488269937966, 0.5212488269937966, 0.5212488269937966, 0.6092900456626009, 0.6092900456626009, 0.6092900456626009, 0.5657986694000723, 0.5657986694000723, 0.5657986694000723, 0.07625858721913681, 0.07625858721913681, 0.07625858721913681, 0.11353684310069889, 0.11353684310069889, 0.11353684310069889, 0.13349225556029598, 0.13349225556029598, 0.13349225556029598, 0.2923087655110267, 0.2923087655110267, 0.2923087655110267, 0.17058849530006337, 0.17058849530006337, 0.17058849530006337, 0.36867958361848363, 0.36867958361848363, 0.36867958361848363, 0.40865239548570576, 0.40865239548570576, 0.40865239548570576, 0.39714577174572396, 0.39714577174572396, 0.39714577174572396, 0.2695926147327291, 0.2695926147327291, 0.2695926147327291, 0.21811446266173207, 0.21811446266173207, 0.21811446266173207, 0.34268712567274884, 0.34268712567274884, 0.34268712567274884, 0.22874659868451208, 0.22874659868451208, 0.22874659868451208, 0.21928541749058428, 0.21928541749058428, 0.21928541749058428, 0.22679558567235403, 0.22679558567235403, 0.22679558567235403, 0.2801068714944557, 0.2801068714944557, 0.2801068714944557, 0.24859292531735677, 0.24859292531735677, 0.24859292531735677, 0.22841934362266458, 0.22841934362266458, 0.22841934362266458, 0.2168144089226336, 0.2168144089226336, 0.2168144089226336, 0.9271356183668746, 0.9271356183668746, 0.9271356183668746, 0.11420627305427256, 0.11420627305427256, 0.11420627305427256, 0.1366109952920993, 0.1366109952920993, 0.1366109952920993, 0.6716788495300214, 0.6716788495300214, 0.6716788495300214, 0.6525119270873981, 0.6525119270873981, 0.6525119270873981, 0.7335310158747503, 0.7335310158747503, 0.7335310158747503, 0.22509205180813374, 0.22509205180813374, 0.22509205180813374, 0.23846259715961882, 0.23846259715961882, 0.23846259715961882, 0.23026115778748257, 0.23026115778748257, 0.23026115778748257, 0.10729408229532489, 0.10729408229532489, 0.10729408229532489, 0.08707462555969336, 0.08707462555969336, 0.08707462555969336, 0.09244825892062858, 0.09244825892062858, 0.09244825892062858]}, "mutation_prompt": null}
{"id": "5fc8e971-35d5-48d0-9543-5bd1112ccbe3", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(70, 12 * dim)  # Increased particles slightly for diversity\n        self.c1 = 1.4  # Further reduced cognitive component for better balance\n        self.c2 = 2.2  # Further increased social component to leverage collective intelligence\n        self.w = 0.85  # Adjusted inertia weight to balance exploration and exploitation\n        self.decay_rate = 0.93  # Faster decay to reduce inertia over time\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.1  # Increased velocity limit for more aggressive movement\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced APSO with adaptive learning components and improved velocity dynamics for faster convergence.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.8890345554254235, 0.8890345554254235, 0.8890345554254235, 0.8812898909220918, 0.8812898909220918, 0.8812898909220918, 0.885169648507018, 0.885169648507018, 0.885169648507018, 0.7943252300909807, 0.7943252300909807, 0.7943252300909807, 0.7992832977617781, 0.7992832977617781, 0.7992832977617781, 0.806978601700252, 0.806978601700252, 0.806978601700252, 0.141836067863071, 0.141836067863071, 0.141836067863071, 0.09072257940144113, 0.09072257940144113, 0.09072257940144113, 0.11538296000510384, 0.11538296000510384, 0.11538296000510384, 0.09182634705732529, 0.09182634705732529, 0.09182634705732529, 0.10396507449566983, 0.10396507449566983, 0.10396507449566983, 0.12877403769140183, 0.12877403769140183, 0.12877403769140183, 0.9171003036492754, 0.9171003036492754, 0.9171003036492754, 0.9426071411196885, 0.9426071411196885, 0.9426071411196885, 0.947537189438548, 0.947537189438548, 0.947537189438548, 0.6001545147287968, 0.6001545147287968, 0.6001545147287968, 0.684584432385599, 0.684584432385599, 0.684584432385599, 0.5898963208656243, 0.5898963208656243, 0.5898963208656243, 0.19375146093521256, 0.19375146093521256, 0.19375146093521256, 0.8693944340969452, 0.8693944340969452, 0.8693944340969452, 0.748951913666398, 0.748951913666398, 0.748951913666398, 0.21327141745353018, 0.21327141745353018, 0.21327141745353018, 0.20118277962625464, 0.20118277962625464, 0.20118277962625464, 0.22068388192974941, 0.22068388192974941, 0.22068388192974941, 0.23075865172070587, 0.23075865172070587, 0.23075865172070587, 0.2135229554500695, 0.2135229554500695, 0.2135229554500695, 0.23668946202621444, 0.23668946202621444, 0.23668946202621444, 0.005148868860398448, 0.005148868860398448, 0.005148868860398448, 0.08177194701312396, 0.08177194701312396, 0.08177194701312396, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08208764747391684, 0.08208764747391684, 0.08208764747391684, 0.05568690635405671, 0.05568690635405671, 0.05568690635405671, 0.11343134532868715, 0.11343134532868715, 0.11343134532868715, 0.04909694094295114, 0.04909694094295114, 0.04909694094295114, 0.11383841177004017, 0.11383841177004017, 0.11383841177004017, 0.26109733429390813, 0.26109733429390813, 0.26109733429390813, 0.25317053091270736, 0.25317053091270736, 0.25317053091270736, 0.10090994703812939, 0.10090994703812939, 0.10090994703812939, 0.11422164786062972, 0.11422164786062972, 0.11422164786062972, 0.5212488269937966, 0.5212488269937966, 0.5212488269937966, 0.6092900456626009, 0.6092900456626009, 0.6092900456626009, 0.5657986694000723, 0.5657986694000723, 0.5657986694000723, 0.07625858721913681, 0.07625858721913681, 0.07625858721913681, 0.11353684310069889, 0.11353684310069889, 0.11353684310069889, 0.13349225556029598, 0.13349225556029598, 0.13349225556029598, 0.2923087655110267, 0.2923087655110267, 0.2923087655110267, 0.17058849530006337, 0.17058849530006337, 0.17058849530006337, 0.36867958361848363, 0.36867958361848363, 0.36867958361848363, 0.40865239548570576, 0.40865239548570576, 0.40865239548570576, 0.39714577174572396, 0.39714577174572396, 0.39714577174572396, 0.2695926147327291, 0.2695926147327291, 0.2695926147327291, 0.21811446266173207, 0.21811446266173207, 0.21811446266173207, 0.34268712567274884, 0.34268712567274884, 0.34268712567274884, 0.22874659868451208, 0.22874659868451208, 0.22874659868451208, 0.21928541749058428, 0.21928541749058428, 0.21928541749058428, 0.22679558567235403, 0.22679558567235403, 0.22679558567235403, 0.2801068714944557, 0.2801068714944557, 0.2801068714944557, 0.24859292531735677, 0.24859292531735677, 0.24859292531735677, 0.22841934362266458, 0.22841934362266458, 0.22841934362266458, 0.2168144089226336, 0.2168144089226336, 0.2168144089226336, 0.9271356183668746, 0.9271356183668746, 0.9271356183668746, 0.11420627305427256, 0.11420627305427256, 0.11420627305427256, 0.1366109952920993, 0.1366109952920993, 0.1366109952920993, 0.6716788495300214, 0.6716788495300214, 0.6716788495300214, 0.6525119270873981, 0.6525119270873981, 0.6525119270873981, 0.7335310158747503, 0.7335310158747503, 0.7335310158747503, 0.22509205180813374, 0.22509205180813374, 0.22509205180813374, 0.23846259715961882, 0.23846259715961882, 0.23846259715961882, 0.23026115778748257, 0.23026115778748257, 0.23026115778748257, 0.10729408229532489, 0.10729408229532489, 0.10729408229532489, 0.08707462555969336, 0.08707462555969336, 0.08707462555969336, 0.09244825892062858, 0.09244825892062858, 0.09244825892062858]}, "mutation_prompt": null}
{"id": "8d20a15a-91e5-40bb-b4c9-acb69a7956ab", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(70, 12 * dim)  # Increased particles slightly for diversity\n        self.c1 = 1.4  # Further reduced cognitive component for better balance\n        self.c2 = 2.2  # Further increased social component to leverage collective intelligence\n        self.w = 0.85  # Adjusted inertia weight to balance exploration and exploitation\n        self.decay_rate = 0.93  # Faster decay to reduce inertia over time\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.1  # Increased velocity limit for more aggressive movement\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced APSO with adaptive learning components and improved velocity dynamics for faster convergence.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.8890345554254235, 0.8890345554254235, 0.8890345554254235, 0.8812898909220918, 0.8812898909220918, 0.8812898909220918, 0.885169648507018, 0.885169648507018, 0.885169648507018, 0.7943252300909807, 0.7943252300909807, 0.7943252300909807, 0.7992832977617781, 0.7992832977617781, 0.7992832977617781, 0.806978601700252, 0.806978601700252, 0.806978601700252, 0.141836067863071, 0.141836067863071, 0.141836067863071, 0.09072257940144113, 0.09072257940144113, 0.09072257940144113, 0.11538296000510384, 0.11538296000510384, 0.11538296000510384, 0.09182634705732529, 0.09182634705732529, 0.09182634705732529, 0.10396507449566983, 0.10396507449566983, 0.10396507449566983, 0.12877403769140183, 0.12877403769140183, 0.12877403769140183, 0.9171003036492754, 0.9171003036492754, 0.9171003036492754, 0.9426071411196885, 0.9426071411196885, 0.9426071411196885, 0.947537189438548, 0.947537189438548, 0.947537189438548, 0.6001545147287968, 0.6001545147287968, 0.6001545147287968, 0.684584432385599, 0.684584432385599, 0.684584432385599, 0.5898963208656243, 0.5898963208656243, 0.5898963208656243, 0.19375146093521256, 0.19375146093521256, 0.19375146093521256, 0.8693944340969452, 0.8693944340969452, 0.8693944340969452, 0.748951913666398, 0.748951913666398, 0.748951913666398, 0.21327141745353018, 0.21327141745353018, 0.21327141745353018, 0.20118277962625464, 0.20118277962625464, 0.20118277962625464, 0.22068388192974941, 0.22068388192974941, 0.22068388192974941, 0.23075865172070587, 0.23075865172070587, 0.23075865172070587, 0.2135229554500695, 0.2135229554500695, 0.2135229554500695, 0.23668946202621444, 0.23668946202621444, 0.23668946202621444, 0.005148868860398448, 0.005148868860398448, 0.005148868860398448, 0.08177194701312396, 0.08177194701312396, 0.08177194701312396, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08208764747391684, 0.08208764747391684, 0.08208764747391684, 0.05568690635405671, 0.05568690635405671, 0.05568690635405671, 0.11343134532868715, 0.11343134532868715, 0.11343134532868715, 0.04909694094295114, 0.04909694094295114, 0.04909694094295114, 0.11383841177004017, 0.11383841177004017, 0.11383841177004017, 0.26109733429390813, 0.26109733429390813, 0.26109733429390813, 0.25317053091270736, 0.25317053091270736, 0.25317053091270736, 0.10090994703812939, 0.10090994703812939, 0.10090994703812939, 0.11422164786062972, 0.11422164786062972, 0.11422164786062972, 0.5212488269937966, 0.5212488269937966, 0.5212488269937966, 0.6092900456626009, 0.6092900456626009, 0.6092900456626009, 0.5657986694000723, 0.5657986694000723, 0.5657986694000723, 0.07625858721913681, 0.07625858721913681, 0.07625858721913681, 0.11353684310069889, 0.11353684310069889, 0.11353684310069889, 0.13349225556029598, 0.13349225556029598, 0.13349225556029598, 0.2923087655110267, 0.2923087655110267, 0.2923087655110267, 0.17058849530006337, 0.17058849530006337, 0.17058849530006337, 0.36867958361848363, 0.36867958361848363, 0.36867958361848363, 0.40865239548570576, 0.40865239548570576, 0.40865239548570576, 0.39714577174572396, 0.39714577174572396, 0.39714577174572396, 0.2695926147327291, 0.2695926147327291, 0.2695926147327291, 0.21811446266173207, 0.21811446266173207, 0.21811446266173207, 0.34268712567274884, 0.34268712567274884, 0.34268712567274884, 0.22874659868451208, 0.22874659868451208, 0.22874659868451208, 0.21928541749058428, 0.21928541749058428, 0.21928541749058428, 0.22679558567235403, 0.22679558567235403, 0.22679558567235403, 0.2801068714944557, 0.2801068714944557, 0.2801068714944557, 0.24859292531735677, 0.24859292531735677, 0.24859292531735677, 0.22841934362266458, 0.22841934362266458, 0.22841934362266458, 0.2168144089226336, 0.2168144089226336, 0.2168144089226336, 0.9271356183668746, 0.9271356183668746, 0.9271356183668746, 0.11420627305427256, 0.11420627305427256, 0.11420627305427256, 0.1366109952920993, 0.1366109952920993, 0.1366109952920993, 0.6716788495300214, 0.6716788495300214, 0.6716788495300214, 0.6525119270873981, 0.6525119270873981, 0.6525119270873981, 0.7335310158747503, 0.7335310158747503, 0.7335310158747503, 0.22509205180813374, 0.22509205180813374, 0.22509205180813374, 0.23846259715961882, 0.23846259715961882, 0.23846259715961882, 0.23026115778748257, 0.23026115778748257, 0.23026115778748257, 0.10729408229532489, 0.10729408229532489, 0.10729408229532489, 0.08707462555969336, 0.08707462555969336, 0.08707462555969336, 0.09244825892062858, 0.09244825892062858, 0.09244825892062858]}, "mutation_prompt": null}
{"id": "13578934-8d0b-4e42-aea0-1d2d82d667fa", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(60, 14 * dim)  # Adjusted number of particles for dynamic exploration\n        self.c1 = 1.5  # Adjusted cognitive component for adaptive learning\n        self.c2 = 2.0  # Slightly reduced social component to balance global influence\n        self.w = 0.9  # Increased inertia weight for initial exploration\n        self.decay_rate = 0.95  # Adjusted decay rate for more gradual change in inertia\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.12  # Adjusted velocity limit for strategic movement\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            if evaluations < self.budget * 0.5:\n                self.c1 += 0.05  # Gradually increase learning to adapt exploration\n                self.c2 -= 0.05  # Gradually decrease social influence to refine individual search\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced APSO with dynamic adaptive parameters and strategic balance between exploration and exploitation.", "configspace": "", "generation": 63, "fitness": 0.2793639926581496, "feedback": "The algorithm EnhancedAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.22.", "error": "", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.8322198297983396, 0.8322198297983396, 0.8322198297983396, 0.7749641191247978, 0.7749641191247978, 0.7749641191247978, 0.664378422025014, 0.664378422025014, 0.664378422025014, 0.14081923653650485, 0.14081923653650485, 0.14081923653650485, 0.27084930754334335, 0.27084930754334335, 0.27084930754334335, 0.2424798915669908, 0.2424798915669908, 0.2424798915669908, 0.1443670416424382, 0.1443670416424382, 0.1443670416424382, 0.09909254639351928, 0.09909254639351928, 0.09909254639351928, 0.15526921571563757, 0.15526921571563757, 0.15526921571563757, 0.1213125998520791, 0.1213125998520791, 0.1213125998520791, 0.12648165551938817, 0.12648165551938817, 0.12648165551938817, 0.10646147142170814, 0.10646147142170814, 0.10646147142170814, 0.945646313084969, 0.945646313084969, 0.945646313084969, 0.95476038640992, 0.95476038640992, 0.95476038640992, 0.9551447916054066, 0.9551447916054066, 0.9551447916054066, 0.3887012977940365, 0.3887012977940365, 0.3887012977940365, 0.4201018065301648, 0.4201018065301648, 0.4201018065301648, 0.30297917077100434, 0.30297917077100434, 0.30297917077100434, 0.2796794676686296, 0.2796794676686296, 0.2796794676686296, 0.27485417359329634, 0.27485417359329634, 0.27485417359329634, 0.24157535166506616, 0.24157535166506616, 0.24157535166506616, 0.17361547817569878, 0.17361547817569878, 0.17361547817569878, 0.1603374552556146, 0.1603374552556146, 0.1603374552556146, 0.20281275836763002, 0.20281275836763002, 0.20281275836763002, 0.13893351088228634, 0.13893351088228634, 0.13893351088228634, 0.2034773894527825, 0.2034773894527825, 0.2034773894527825, 0.18850606611672238, 0.18850606611672238, 0.18850606611672238, 0.14670081483953545, 0.14670081483953545, 0.14670081483953545, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0670992809311527, 0.0670992809311527, 0.0670992809311527, 0.11097772285414742, 0.11097772285414742, 0.11097772285414742, 0.08194791323018003, 0.08194791323018003, 0.08194791323018003, 0.11720962433804183, 0.11720962433804183, 0.11720962433804183, 0.24442070409555494, 0.24442070409555494, 0.24442070409555494, 0.10533487205505643, 0.10533487205505643, 0.10533487205505643, 0.12166420039488457, 0.12166420039488457, 0.12166420039488457, 0.18606384921622543, 0.18606384921622543, 0.18606384921622543, 0.11916678674582704, 0.11916678674582704, 0.11916678674582704, 0.15290986002986684, 0.15290986002986684, 0.15290986002986684, 0.5336430465958135, 0.5336430465958135, 0.5336430465958135, 0.51794150170204, 0.51794150170204, 0.51794150170204, 0.49909982888362525, 0.49909982888362525, 0.49909982888362525, 0.10861710660997936, 0.10861710660997936, 0.10861710660997936, 0.1326210283644801, 0.1326210283644801, 0.1326210283644801, 0.12169734326146986, 0.12169734326146986, 0.12169734326146986, 0.23884286044879588, 0.23884286044879588, 0.23884286044879588, 0.15723511893223308, 0.15723511893223308, 0.15723511893223308, 0.28426976634082257, 0.28426976634082257, 0.28426976634082257, 0.3574890566671929, 0.3574890566671929, 0.3574890566671929, 0.32895784275785067, 0.32895784275785067, 0.32895784275785067, 0.3976831448906625, 0.3976831448906625, 0.3976831448906625, 0.23490525481829072, 0.23490525481829072, 0.23490525481829072, 0.26418672681951716, 0.26418672681951716, 0.26418672681951716, 0.2596400258458629, 0.2596400258458629, 0.2596400258458629, 0.17755511975114002, 0.17755511975114002, 0.17755511975114002, 0.25377731632404066, 0.25377731632404066, 0.25377731632404066, 0.21683649753330714, 0.21683649753330714, 0.21683649753330714, 0.2490785301755366, 0.2490785301755366, 0.2490785301755366, 0.3697717428385535, 0.3697717428385535, 0.3697717428385535, 0.24995503810402941, 0.24995503810402941, 0.24995503810402941, 0.9162897298081915, 0.9162897298081915, 0.9162897298081915, 0.15794053843567668, 0.15794053843567668, 0.15794053843567668, 0.1884948872046558, 0.1884948872046558, 0.1884948872046558, 0.3459188167914793, 0.3459188167914793, 0.3459188167914793, 0.50136979276366, 0.50136979276366, 0.50136979276366, 0.21155269849740277, 0.21155269849740277, 0.21155269849740277, 0.1890714032641263, 0.1890714032641263, 0.1890714032641263, 0.1971176965908934, 0.1971176965908934, 0.1971176965908934, 0.19405820824881737, 0.19405820824881737, 0.19405820824881737, 0.10013367861855227, 0.10013367861855227, 0.10013367861855227, 0.0810812402553085, 0.0810812402553085, 0.0810812402553085, 0.11395849999930141, 0.11395849999930141, 0.11395849999930141]}, "mutation_prompt": null}
{"id": "0e5a2f1c-3c6c-4689-a0ce-78e005ed3080", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_particles = min(70, 12 * dim)\n        self.min_particles = 30  # Introduced dynamic particle adjustment\n        self.c1 = 1.5  # Slightly adjusted cognitive component for better individual learning\n        self.c2 = 2.0  # Adjusted social component to maintain global influence\n        self.w = 0.8  # Reduced inertia weight for quicker convergence\n        self.decay_rate = 0.92  # Slightly faster decay for adaptive balance\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.15  # More aggressive velocity limit\n\n    def __call__(self, func):\n        np.random.seed(42)\n        num_particles = self.initial_particles\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = num_particles\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] +\n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) +\n                          self.c2 * r2 * (global_best_position - pos[i]))\n\n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n\n                score = func(pos[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n\n            self.w *= self.decay_rate  # Decay inertia weight\n\n            # Adjust number of particles dynamically\n            if evaluations < self.budget // 2:\n                num_particles = max(self.min_particles, int(num_particles * 0.9))\n                if num_particles < len(pos):\n                    pos = pos[:num_particles]\n                    vel = vel[:num_particles]\n                    personal_best_positions = personal_best_positions[:num_particles]\n                    personal_best_scores = personal_best_scores[:num_particles]\n\n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced Adaptive PSO with dynamic population adjustment for improved convergence speed.", "configspace": "", "generation": 64, "fitness": 0.3271202245010876, "feedback": "The algorithm EnhancedAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.28.", "error": "", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.9454080413744504, 0.9454080413744504, 0.9454080413744504, 0.9331612430672942, 0.9331612430672942, 0.9331612430672942, 0.93323712726602, 0.93323712726602, 0.93323712726602, 0.8894125289325584, 0.8894125289325584, 0.8894125289325584, 0.8889933343102954, 0.8889933343102954, 0.8889933343102954, 0.8815765204062667, 0.8815765204062667, 0.8815765204062667, 0.161920821319527, 0.161920821319527, 0.161920821319527, 0.11496404100027025, 0.11496404100027025, 0.11496404100027025, 0.1884252889451814, 0.1884252889451814, 0.1884252889451814, 0.1443208273281139, 0.1443208273281139, 0.1443208273281139, 0.09977957747525712, 0.09977957747525712, 0.09977957747525712, 0.1596813095053431, 0.1596813095053431, 0.1596813095053431, 0.962594316021185, 0.962594316021185, 0.962594316021185, 0.9710443579718075, 0.9710443579718075, 0.9710443579718075, 0.9530136244099638, 0.9530136244099638, 0.9530136244099638, 0.7922260814749014, 0.7922260814749014, 0.7922260814749014, 0.6078046164084943, 0.6078046164084943, 0.6078046164084943, 0.7631724399411394, 0.7631724399411394, 0.7631724399411394, 0.17154339141090436, 0.17154339141090436, 0.17154339141090436, 0.21407806584815303, 0.21407806584815303, 0.21407806584815303, 0.21595998989816723, 0.21595998989816723, 0.21595998989816723, 0.20894534186672342, 0.20894534186672342, 0.20894534186672342, 0.13163825473819235, 0.13163825473819235, 0.13163825473819235, 0.20578881754644285, 0.20578881754644285, 0.20578881754644285, 0.23365553117079496, 0.23365553117079496, 0.23365553117079496, 0.25906814689856517, 0.25906814689856517, 0.25906814689856517, 0.22748845611585744, 0.22748845611585744, 0.22748845611585744, 0.06981895682871087, 0.06981895682871087, 0.06981895682871087, 0.08230473331113863, 0.08230473331113863, 0.08230473331113863, 0.10947329298431019, 0.10947329298431019, 0.10947329298431019, 0.031073241137252627, 0.031073241137252627, 0.031073241137252627, 0.02234456152677866, 0.02234456152677866, 0.02234456152677866, 0.10949373097091553, 0.10949373097091553, 0.10949373097091553, 0.18411973998159836, 0.18411973998159836, 0.18411973998159836, 0.08319666193724329, 0.08319666193724329, 0.08319666193724329, 0.32288690337356607, 0.32288690337356607, 0.32288690337356607, 0.12433517182234499, 0.12433517182234499, 0.12433517182234499, 0.1328042399266779, 0.1328042399266779, 0.1328042399266779, 0.2358125873066269, 0.2358125873066269, 0.2358125873066269, 0.5550209921771123, 0.5550209921771123, 0.5550209921771123, 0.5291827136188406, 0.5291827136188406, 0.5291827136188406, 0.5632775196065385, 0.5632775196065385, 0.5632775196065385, 0.10022800484460681, 0.10022800484460681, 0.10022800484460681, 0.1404210688298837, 0.1404210688298837, 0.1404210688298837, 0.0863668166817515, 0.0863668166817515, 0.0863668166817515, 0.18467064739856276, 0.18467064739856276, 0.18467064739856276, 0.16894789766726048, 0.16894789766726048, 0.16894789766726048, 0.18412816989798964, 0.18412816989798964, 0.18412816989798964, 0.3334377691351821, 0.3334377691351821, 0.3334377691351821, 0.34593592547560403, 0.34593592547560403, 0.34593592547560403, 0.43971620430039293, 0.43971620430039293, 0.43971620430039293, 0.21633704395660636, 0.21633704395660636, 0.21633704395660636, 0.24702033725662964, 0.24702033725662964, 0.24702033725662964, 0.26446782047301787, 0.26446782047301787, 0.26446782047301787, 0.24702054629844894, 0.24702054629844894, 0.24702054629844894, 0.2947075297642847, 0.2947075297642847, 0.2947075297642847, 0.22035889992551394, 0.22035889992551394, 0.22035889992551394, 0.2258316433855987, 0.2258316433855987, 0.2258316433855987, 0.1890913848158774, 0.1890913848158774, 0.1890913848158774, 0.22949098241523302, 0.22949098241523302, 0.22949098241523302, 0.9532092812811537, 0.9532092812811537, 0.9532092812811537, 0.14799450883076426, 0.14799450883076426, 0.14799450883076426, 0.13674390553655702, 0.13674390553655702, 0.13674390553655702, 0.4770380936555101, 0.4770380936555101, 0.4770380936555101, 0.21136504108379583, 0.21136504108379583, 0.21136504108379583, 0.16773914063869944, 0.16773914063869944, 0.16773914063869944, 0.20889345322950992, 0.20889345322950992, 0.20889345322950992, 0.2019311642711854, 0.2019311642711854, 0.2019311642711854, 0.22257324318926397, 0.22257324318926397, 0.22257324318926397, 0.0842485208247643, 0.0842485208247643, 0.0842485208247643, 0.09425844550629259, 0.09425844550629259, 0.09425844550629259, 0.1144355343468374, 0.1144355343468374, 0.1144355343468374]}, "mutation_prompt": null}
{"id": "8765b516-f5db-498e-a007-174b2e214327", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(70, 12 * dim)  # Increased particles slightly for diversity\n        self.c1 = 1.4  # Further reduced cognitive component for better balance\n        self.c2 = 2.2  # Further increased social component to leverage collective intelligence\n        self.w = 0.85  # Adjusted inertia weight to balance exploration and exploitation\n        self.decay_rate = 0.93  # Faster decay to reduce inertia over time\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.1  # Increased velocity limit for more aggressive movement\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced APSO with adaptive learning components and improved velocity dynamics for faster convergence.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.8890345554254235, 0.8890345554254235, 0.8890345554254235, 0.8812898909220918, 0.8812898909220918, 0.8812898909220918, 0.885169648507018, 0.885169648507018, 0.885169648507018, 0.7943252300909807, 0.7943252300909807, 0.7943252300909807, 0.7992832977617781, 0.7992832977617781, 0.7992832977617781, 0.806978601700252, 0.806978601700252, 0.806978601700252, 0.141836067863071, 0.141836067863071, 0.141836067863071, 0.09072257940144113, 0.09072257940144113, 0.09072257940144113, 0.11538296000510384, 0.11538296000510384, 0.11538296000510384, 0.09182634705732529, 0.09182634705732529, 0.09182634705732529, 0.10396507449566983, 0.10396507449566983, 0.10396507449566983, 0.12877403769140183, 0.12877403769140183, 0.12877403769140183, 0.9171003036492754, 0.9171003036492754, 0.9171003036492754, 0.9426071411196885, 0.9426071411196885, 0.9426071411196885, 0.947537189438548, 0.947537189438548, 0.947537189438548, 0.6001545147287968, 0.6001545147287968, 0.6001545147287968, 0.684584432385599, 0.684584432385599, 0.684584432385599, 0.5898963208656243, 0.5898963208656243, 0.5898963208656243, 0.19375146093521256, 0.19375146093521256, 0.19375146093521256, 0.8693944340969452, 0.8693944340969452, 0.8693944340969452, 0.748951913666398, 0.748951913666398, 0.748951913666398, 0.21327141745353018, 0.21327141745353018, 0.21327141745353018, 0.20118277962625464, 0.20118277962625464, 0.20118277962625464, 0.22068388192974941, 0.22068388192974941, 0.22068388192974941, 0.23075865172070587, 0.23075865172070587, 0.23075865172070587, 0.2135229554500695, 0.2135229554500695, 0.2135229554500695, 0.23668946202621444, 0.23668946202621444, 0.23668946202621444, 0.005148868860398448, 0.005148868860398448, 0.005148868860398448, 0.08177194701312396, 0.08177194701312396, 0.08177194701312396, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08208764747391684, 0.08208764747391684, 0.08208764747391684, 0.05568690635405671, 0.05568690635405671, 0.05568690635405671, 0.11343134532868715, 0.11343134532868715, 0.11343134532868715, 0.04909694094295114, 0.04909694094295114, 0.04909694094295114, 0.11383841177004017, 0.11383841177004017, 0.11383841177004017, 0.26109733429390813, 0.26109733429390813, 0.26109733429390813, 0.25317053091270736, 0.25317053091270736, 0.25317053091270736, 0.10090994703812939, 0.10090994703812939, 0.10090994703812939, 0.11422164786062972, 0.11422164786062972, 0.11422164786062972, 0.5212488269937966, 0.5212488269937966, 0.5212488269937966, 0.6092900456626009, 0.6092900456626009, 0.6092900456626009, 0.5657986694000723, 0.5657986694000723, 0.5657986694000723, 0.07625858721913681, 0.07625858721913681, 0.07625858721913681, 0.11353684310069889, 0.11353684310069889, 0.11353684310069889, 0.13349225556029598, 0.13349225556029598, 0.13349225556029598, 0.2923087655110267, 0.2923087655110267, 0.2923087655110267, 0.17058849530006337, 0.17058849530006337, 0.17058849530006337, 0.36867958361848363, 0.36867958361848363, 0.36867958361848363, 0.40865239548570576, 0.40865239548570576, 0.40865239548570576, 0.39714577174572396, 0.39714577174572396, 0.39714577174572396, 0.2695926147327291, 0.2695926147327291, 0.2695926147327291, 0.21811446266173207, 0.21811446266173207, 0.21811446266173207, 0.34268712567274884, 0.34268712567274884, 0.34268712567274884, 0.22874659868451208, 0.22874659868451208, 0.22874659868451208, 0.21928541749058428, 0.21928541749058428, 0.21928541749058428, 0.22679558567235403, 0.22679558567235403, 0.22679558567235403, 0.2801068714944557, 0.2801068714944557, 0.2801068714944557, 0.24859292531735677, 0.24859292531735677, 0.24859292531735677, 0.22841934362266458, 0.22841934362266458, 0.22841934362266458, 0.2168144089226336, 0.2168144089226336, 0.2168144089226336, 0.9271356183668746, 0.9271356183668746, 0.9271356183668746, 0.11420627305427256, 0.11420627305427256, 0.11420627305427256, 0.1366109952920993, 0.1366109952920993, 0.1366109952920993, 0.6716788495300214, 0.6716788495300214, 0.6716788495300214, 0.6525119270873981, 0.6525119270873981, 0.6525119270873981, 0.7335310158747503, 0.7335310158747503, 0.7335310158747503, 0.22509205180813374, 0.22509205180813374, 0.22509205180813374, 0.23846259715961882, 0.23846259715961882, 0.23846259715961882, 0.23026115778748257, 0.23026115778748257, 0.23026115778748257, 0.10729408229532489, 0.10729408229532489, 0.10729408229532489, 0.08707462555969336, 0.08707462555969336, 0.08707462555969336, 0.09244825892062858, 0.09244825892062858, 0.09244825892062858]}, "mutation_prompt": null}
{"id": "de1dd697-c488-4350-b0ee-b5ad435fa644", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(70, 12 * dim)  # Increased particles slightly for diversity\n        self.c1 = 1.4  # Further reduced cognitive component for better balance\n        self.c2 = 2.2  # Further increased social component to leverage collective intelligence\n        self.w = 0.85  # Adjusted inertia weight to balance exploration and exploitation\n        self.decay_rate = 0.93  # Faster decay to reduce inertia over time\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.1  # Increased velocity limit for more aggressive movement\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced APSO with adaptive learning components and improved velocity dynamics for faster convergence.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.8890345554254235, 0.8890345554254235, 0.8890345554254235, 0.8812898909220918, 0.8812898909220918, 0.8812898909220918, 0.885169648507018, 0.885169648507018, 0.885169648507018, 0.7943252300909807, 0.7943252300909807, 0.7943252300909807, 0.7992832977617781, 0.7992832977617781, 0.7992832977617781, 0.806978601700252, 0.806978601700252, 0.806978601700252, 0.141836067863071, 0.141836067863071, 0.141836067863071, 0.09072257940144113, 0.09072257940144113, 0.09072257940144113, 0.11538296000510384, 0.11538296000510384, 0.11538296000510384, 0.09182634705732529, 0.09182634705732529, 0.09182634705732529, 0.10396507449566983, 0.10396507449566983, 0.10396507449566983, 0.12877403769140183, 0.12877403769140183, 0.12877403769140183, 0.9171003036492754, 0.9171003036492754, 0.9171003036492754, 0.9426071411196885, 0.9426071411196885, 0.9426071411196885, 0.947537189438548, 0.947537189438548, 0.947537189438548, 0.6001545147287968, 0.6001545147287968, 0.6001545147287968, 0.684584432385599, 0.684584432385599, 0.684584432385599, 0.5898963208656243, 0.5898963208656243, 0.5898963208656243, 0.19375146093521256, 0.19375146093521256, 0.19375146093521256, 0.8693944340969452, 0.8693944340969452, 0.8693944340969452, 0.748951913666398, 0.748951913666398, 0.748951913666398, 0.21327141745353018, 0.21327141745353018, 0.21327141745353018, 0.20118277962625464, 0.20118277962625464, 0.20118277962625464, 0.22068388192974941, 0.22068388192974941, 0.22068388192974941, 0.23075865172070587, 0.23075865172070587, 0.23075865172070587, 0.2135229554500695, 0.2135229554500695, 0.2135229554500695, 0.23668946202621444, 0.23668946202621444, 0.23668946202621444, 0.005148868860398448, 0.005148868860398448, 0.005148868860398448, 0.08177194701312396, 0.08177194701312396, 0.08177194701312396, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08208764747391684, 0.08208764747391684, 0.08208764747391684, 0.05568690635405671, 0.05568690635405671, 0.05568690635405671, 0.11343134532868715, 0.11343134532868715, 0.11343134532868715, 0.04909694094295114, 0.04909694094295114, 0.04909694094295114, 0.11383841177004017, 0.11383841177004017, 0.11383841177004017, 0.26109733429390813, 0.26109733429390813, 0.26109733429390813, 0.25317053091270736, 0.25317053091270736, 0.25317053091270736, 0.10090994703812939, 0.10090994703812939, 0.10090994703812939, 0.11422164786062972, 0.11422164786062972, 0.11422164786062972, 0.5212488269937966, 0.5212488269937966, 0.5212488269937966, 0.6092900456626009, 0.6092900456626009, 0.6092900456626009, 0.5657986694000723, 0.5657986694000723, 0.5657986694000723, 0.07625858721913681, 0.07625858721913681, 0.07625858721913681, 0.11353684310069889, 0.11353684310069889, 0.11353684310069889, 0.13349225556029598, 0.13349225556029598, 0.13349225556029598, 0.2923087655110267, 0.2923087655110267, 0.2923087655110267, 0.17058849530006337, 0.17058849530006337, 0.17058849530006337, 0.36867958361848363, 0.36867958361848363, 0.36867958361848363, 0.40865239548570576, 0.40865239548570576, 0.40865239548570576, 0.39714577174572396, 0.39714577174572396, 0.39714577174572396, 0.2695926147327291, 0.2695926147327291, 0.2695926147327291, 0.21811446266173207, 0.21811446266173207, 0.21811446266173207, 0.34268712567274884, 0.34268712567274884, 0.34268712567274884, 0.22874659868451208, 0.22874659868451208, 0.22874659868451208, 0.21928541749058428, 0.21928541749058428, 0.21928541749058428, 0.22679558567235403, 0.22679558567235403, 0.22679558567235403, 0.2801068714944557, 0.2801068714944557, 0.2801068714944557, 0.24859292531735677, 0.24859292531735677, 0.24859292531735677, 0.22841934362266458, 0.22841934362266458, 0.22841934362266458, 0.2168144089226336, 0.2168144089226336, 0.2168144089226336, 0.9271356183668746, 0.9271356183668746, 0.9271356183668746, 0.11420627305427256, 0.11420627305427256, 0.11420627305427256, 0.1366109952920993, 0.1366109952920993, 0.1366109952920993, 0.6716788495300214, 0.6716788495300214, 0.6716788495300214, 0.6525119270873981, 0.6525119270873981, 0.6525119270873981, 0.7335310158747503, 0.7335310158747503, 0.7335310158747503, 0.22509205180813374, 0.22509205180813374, 0.22509205180813374, 0.23846259715961882, 0.23846259715961882, 0.23846259715961882, 0.23026115778748257, 0.23026115778748257, 0.23026115778748257, 0.10729408229532489, 0.10729408229532489, 0.10729408229532489, 0.08707462555969336, 0.08707462555969336, 0.08707462555969336, 0.09244825892062858, 0.09244825892062858, 0.09244825892062858]}, "mutation_prompt": null}
{"id": "18da3a37-9626-4245-b930-f6e68d6e056c", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(70, 12 * dim)  # Increased particles slightly for diversity\n        self.c1 = 1.4  # Further reduced cognitive component for better balance\n        self.c2 = 2.2  # Further increased social component to leverage collective intelligence\n        self.w = 0.85  # Adjusted inertia weight to balance exploration and exploitation\n        self.decay_rate = 0.93  # Faster decay to reduce inertia over time\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.1  # Increased velocity limit for more aggressive movement\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced APSO with adaptive learning components and improved velocity dynamics for faster convergence.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.8890345554254235, 0.8890345554254235, 0.8890345554254235, 0.8812898909220918, 0.8812898909220918, 0.8812898909220918, 0.885169648507018, 0.885169648507018, 0.885169648507018, 0.7943252300909807, 0.7943252300909807, 0.7943252300909807, 0.7992832977617781, 0.7992832977617781, 0.7992832977617781, 0.806978601700252, 0.806978601700252, 0.806978601700252, 0.141836067863071, 0.141836067863071, 0.141836067863071, 0.09072257940144113, 0.09072257940144113, 0.09072257940144113, 0.11538296000510384, 0.11538296000510384, 0.11538296000510384, 0.09182634705732529, 0.09182634705732529, 0.09182634705732529, 0.10396507449566983, 0.10396507449566983, 0.10396507449566983, 0.12877403769140183, 0.12877403769140183, 0.12877403769140183, 0.9171003036492754, 0.9171003036492754, 0.9171003036492754, 0.9426071411196885, 0.9426071411196885, 0.9426071411196885, 0.947537189438548, 0.947537189438548, 0.947537189438548, 0.6001545147287968, 0.6001545147287968, 0.6001545147287968, 0.684584432385599, 0.684584432385599, 0.684584432385599, 0.5898963208656243, 0.5898963208656243, 0.5898963208656243, 0.19375146093521256, 0.19375146093521256, 0.19375146093521256, 0.8693944340969452, 0.8693944340969452, 0.8693944340969452, 0.748951913666398, 0.748951913666398, 0.748951913666398, 0.21327141745353018, 0.21327141745353018, 0.21327141745353018, 0.20118277962625464, 0.20118277962625464, 0.20118277962625464, 0.22068388192974941, 0.22068388192974941, 0.22068388192974941, 0.23075865172070587, 0.23075865172070587, 0.23075865172070587, 0.2135229554500695, 0.2135229554500695, 0.2135229554500695, 0.23668946202621444, 0.23668946202621444, 0.23668946202621444, 0.005148868860398448, 0.005148868860398448, 0.005148868860398448, 0.08177194701312396, 0.08177194701312396, 0.08177194701312396, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08208764747391684, 0.08208764747391684, 0.08208764747391684, 0.05568690635405671, 0.05568690635405671, 0.05568690635405671, 0.11343134532868715, 0.11343134532868715, 0.11343134532868715, 0.04909694094295114, 0.04909694094295114, 0.04909694094295114, 0.11383841177004017, 0.11383841177004017, 0.11383841177004017, 0.26109733429390813, 0.26109733429390813, 0.26109733429390813, 0.25317053091270736, 0.25317053091270736, 0.25317053091270736, 0.10090994703812939, 0.10090994703812939, 0.10090994703812939, 0.11422164786062972, 0.11422164786062972, 0.11422164786062972, 0.5212488269937966, 0.5212488269937966, 0.5212488269937966, 0.6092900456626009, 0.6092900456626009, 0.6092900456626009, 0.5657986694000723, 0.5657986694000723, 0.5657986694000723, 0.07625858721913681, 0.07625858721913681, 0.07625858721913681, 0.11353684310069889, 0.11353684310069889, 0.11353684310069889, 0.13349225556029598, 0.13349225556029598, 0.13349225556029598, 0.2923087655110267, 0.2923087655110267, 0.2923087655110267, 0.17058849530006337, 0.17058849530006337, 0.17058849530006337, 0.36867958361848363, 0.36867958361848363, 0.36867958361848363, 0.40865239548570576, 0.40865239548570576, 0.40865239548570576, 0.39714577174572396, 0.39714577174572396, 0.39714577174572396, 0.2695926147327291, 0.2695926147327291, 0.2695926147327291, 0.21811446266173207, 0.21811446266173207, 0.21811446266173207, 0.34268712567274884, 0.34268712567274884, 0.34268712567274884, 0.22874659868451208, 0.22874659868451208, 0.22874659868451208, 0.21928541749058428, 0.21928541749058428, 0.21928541749058428, 0.22679558567235403, 0.22679558567235403, 0.22679558567235403, 0.2801068714944557, 0.2801068714944557, 0.2801068714944557, 0.24859292531735677, 0.24859292531735677, 0.24859292531735677, 0.22841934362266458, 0.22841934362266458, 0.22841934362266458, 0.2168144089226336, 0.2168144089226336, 0.2168144089226336, 0.9271356183668746, 0.9271356183668746, 0.9271356183668746, 0.11420627305427256, 0.11420627305427256, 0.11420627305427256, 0.1366109952920993, 0.1366109952920993, 0.1366109952920993, 0.6716788495300214, 0.6716788495300214, 0.6716788495300214, 0.6525119270873981, 0.6525119270873981, 0.6525119270873981, 0.7335310158747503, 0.7335310158747503, 0.7335310158747503, 0.22509205180813374, 0.22509205180813374, 0.22509205180813374, 0.23846259715961882, 0.23846259715961882, 0.23846259715961882, 0.23026115778748257, 0.23026115778748257, 0.23026115778748257, 0.10729408229532489, 0.10729408229532489, 0.10729408229532489, 0.08707462555969336, 0.08707462555969336, 0.08707462555969336, 0.09244825892062858, 0.09244825892062858, 0.09244825892062858]}, "mutation_prompt": null}
{"id": "05851473-2ef0-4ef4-a5a4-c3c4f1d87bde", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(75, 14 * dim)  # Adjusted particles for exploration\n        self.c1 = 1.3  # Reduced cognitive component for better global search\n        self.c2 = 2.4  # Increased social component for stronger collective behavior\n        self.w = 0.9  # Slightly increased inertia weight for initial exploration\n        self.decay_rate = 0.92  # Faster decay for quicker exploitation transition\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.12  # Increased velocity limit for dynamic movement\n        self.dynamic_adjustment_factor = 0.05  # Factor to adjust particles dynamically\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n            # Dynamic adjustment of particles based on convergence\n            if evaluations < self.budget * 0.5 and np.random.rand() < self.dynamic_adjustment_factor:\n                new_particle_pos = np.random.uniform(self.lower_bound, self.upper_bound, (1, self.dim))\n                pos = np.vstack((pos, new_particle_pos))\n                vel = np.vstack((vel, np.random.uniform(-1, 1, (1, self.dim))))\n                new_particle_score = func(new_particle_pos[0])\n                personal_best_positions = np.vstack((personal_best_positions, new_particle_pos))\n                personal_best_scores = np.append(personal_best_scores, new_particle_score)\n                if new_particle_score < global_best_score:\n                    global_best_score = new_particle_score\n                    global_best_position = new_particle_pos[0]\n                evaluations += 1\n                self.num_particles += 1\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced APSO with adaptive velocity scaling and dynamic particle adjustment for improved convergence.", "configspace": "", "generation": 68, "fitness": 0.31951687785537985, "feedback": "The algorithm EnhancedAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.27.", "error": "", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.8532966180103896, 0.8532966180103896, 0.8532966180103896, 0.8753098754191612, 0.8753098754191612, 0.8753098754191612, 0.8558323036035969, 0.8558323036035969, 0.8558323036035969, 0.755229743627627, 0.755229743627627, 0.755229743627627, 0.6219000085517492, 0.6219000085517492, 0.6219000085517492, 0.7297461163771863, 0.7297461163771863, 0.7297461163771863, 0.12785775582677417, 0.12785775582677417, 0.12785775582677417, 0.09496996668845603, 0.09496996668845603, 0.09496996668845603, 0.1284555523436014, 0.1284555523436014, 0.1284555523436014, 0.0835140294991592, 0.0835140294991592, 0.0835140294991592, 0.12857741013240598, 0.12857741013240598, 0.12857741013240598, 0.5317503046766999, 0.5317503046766999, 0.5317503046766999, 0.9319038764364463, 0.9319038764364463, 0.9319038764364463, 0.9457447609540854, 0.9457447609540854, 0.9457447609540854, 0.9282333764618036, 0.9282333764618036, 0.9282333764618036, 0.5135973552932247, 0.5135973552932247, 0.5135973552932247, 0.5733596427834167, 0.5733596427834167, 0.5733596427834167, 0.10934348380624215, 0.10934348380624215, 0.10934348380624215, 0.9144668197620119, 0.9144668197620119, 0.9144668197620119, 0.2557402346642341, 0.2557402346642341, 0.2557402346642341, 0.23400409840570835, 0.23400409840570835, 0.23400409840570835, 0.1959621957861939, 0.1959621957861939, 0.1959621957861939, 0.09411482647201974, 0.09411482647201974, 0.09411482647201974, 0.1874499300480229, 0.1874499300480229, 0.1874499300480229, 0.2718313900806564, 0.2718313900806564, 0.2718313900806564, 0.1901432708619436, 0.1901432708619436, 0.1901432708619436, 0.13539290351486866, 0.13539290351486866, 0.13539290351486866, 0.07858368892001677, 0.07858368892001677, 0.07858368892001677, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07603747350272638, 0.07603747350272638, 0.07603747350272638, 0.0550275405463837, 0.0550275405463837, 0.0550275405463837, 0.05804932428285514, 0.05804932428285514, 0.05804932428285514, 0.17596157769418808, 0.17596157769418808, 0.17596157769418808, 0.06261333422879345, 0.06261333422879345, 0.06261333422879345, 0.17865855485618154, 0.17865855485618154, 0.17865855485618154, 0.07166437079488608, 0.07166437079488608, 0.07166437079488608, 0.3269561627743054, 0.3269561627743054, 0.3269561627743054, 0.07388855560660923, 0.07388855560660923, 0.07388855560660923, 0.1799616801091588, 0.1799616801091588, 0.1799616801091588, 0.35002804751187755, 0.35002804751187755, 0.35002804751187755, 0.5069818840146344, 0.5069818840146344, 0.5069818840146344, 0.5879313822121042, 0.5879313822121042, 0.5879313822121042, 0.15785443029310753, 0.15785443029310753, 0.15785443029310753, 0.13747317368467216, 0.13747317368467216, 0.13747317368467216, 0.0842710182895926, 0.0842710182895926, 0.0842710182895926, 0.20063966173062653, 0.20063966173062653, 0.20063966173062653, 0.1975906081750155, 0.1975906081750155, 0.1975906081750155, 0.3633102412224032, 0.3633102412224032, 0.3633102412224032, 0.3141475054037638, 0.3141475054037638, 0.3141475054037638, 0.4222854923836573, 0.4222854923836573, 0.4222854923836573, 0.3675474059167987, 0.3675474059167987, 0.3675474059167987, 0.29295807227071424, 0.29295807227071424, 0.29295807227071424, 0.14690397756342355, 0.14690397756342355, 0.14690397756342355, 0.1342410664071143, 0.1342410664071143, 0.1342410664071143, 0.2168290592320573, 0.2168290592320573, 0.2168290592320573, 0.26918951145488945, 0.26918951145488945, 0.26918951145488945, 0.20090553947011036, 0.20090553947011036, 0.20090553947011036, 0.18222958826557, 0.18222958826557, 0.18222958826557, 0.196907773386656, 0.196907773386656, 0.196907773386656, 0.21823373287434056, 0.21823373287434056, 0.21823373287434056, 0.9011963908830771, 0.9011963908830771, 0.9011963908830771, 0.15706980276768767, 0.15706980276768767, 0.15706980276768767, 0.9016545425109909, 0.9016545425109909, 0.9016545425109909, 0.5986028615372005, 0.5986028615372005, 0.5986028615372005, 0.2104041647053766, 0.2104041647053766, 0.2104041647053766, 0.16810434794043994, 0.16810434794043994, 0.16810434794043994, 0.1903677079291144, 0.1903677079291144, 0.1903677079291144, 0.18670595201913598, 0.18670595201913598, 0.18670595201913598, 0.2504854362988521, 0.2504854362988521, 0.2504854362988521, 0.10179700342093378, 0.10179700342093378, 0.10179700342093378, 0.07658823737245113, 0.07658823737245113, 0.07658823737245113, 0.1085494730351706, 0.1085494730351706, 0.1085494730351706]}, "mutation_prompt": null}
{"id": "e2be128a-af87-463e-90fc-8ba909238444", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(70, 12 * dim)  # Increased particles slightly for diversity\n        self.c1 = 1.4  # Further reduced cognitive component for better balance\n        self.c2 = 2.2  # Further increased social component to leverage collective intelligence\n        self.w = 0.85  # Adjusted inertia weight to balance exploration and exploitation\n        self.decay_rate = 0.93  # Faster decay to reduce inertia over time\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.1  # Increased velocity limit for more aggressive movement\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced APSO with adaptive learning components and improved velocity dynamics for faster convergence.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.8890345554254235, 0.8890345554254235, 0.8890345554254235, 0.8812898909220918, 0.8812898909220918, 0.8812898909220918, 0.885169648507018, 0.885169648507018, 0.885169648507018, 0.7943252300909807, 0.7943252300909807, 0.7943252300909807, 0.7992832977617781, 0.7992832977617781, 0.7992832977617781, 0.806978601700252, 0.806978601700252, 0.806978601700252, 0.141836067863071, 0.141836067863071, 0.141836067863071, 0.09072257940144113, 0.09072257940144113, 0.09072257940144113, 0.11538296000510384, 0.11538296000510384, 0.11538296000510384, 0.09182634705732529, 0.09182634705732529, 0.09182634705732529, 0.10396507449566983, 0.10396507449566983, 0.10396507449566983, 0.12877403769140183, 0.12877403769140183, 0.12877403769140183, 0.9171003036492754, 0.9171003036492754, 0.9171003036492754, 0.9426071411196885, 0.9426071411196885, 0.9426071411196885, 0.947537189438548, 0.947537189438548, 0.947537189438548, 0.6001545147287968, 0.6001545147287968, 0.6001545147287968, 0.684584432385599, 0.684584432385599, 0.684584432385599, 0.5898963208656243, 0.5898963208656243, 0.5898963208656243, 0.19375146093521256, 0.19375146093521256, 0.19375146093521256, 0.8693944340969452, 0.8693944340969452, 0.8693944340969452, 0.748951913666398, 0.748951913666398, 0.748951913666398, 0.21327141745353018, 0.21327141745353018, 0.21327141745353018, 0.20118277962625464, 0.20118277962625464, 0.20118277962625464, 0.22068388192974941, 0.22068388192974941, 0.22068388192974941, 0.23075865172070587, 0.23075865172070587, 0.23075865172070587, 0.2135229554500695, 0.2135229554500695, 0.2135229554500695, 0.23668946202621444, 0.23668946202621444, 0.23668946202621444, 0.005148868860398448, 0.005148868860398448, 0.005148868860398448, 0.08177194701312396, 0.08177194701312396, 0.08177194701312396, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08208764747391684, 0.08208764747391684, 0.08208764747391684, 0.05568690635405671, 0.05568690635405671, 0.05568690635405671, 0.11343134532868715, 0.11343134532868715, 0.11343134532868715, 0.04909694094295114, 0.04909694094295114, 0.04909694094295114, 0.11383841177004017, 0.11383841177004017, 0.11383841177004017, 0.26109733429390813, 0.26109733429390813, 0.26109733429390813, 0.25317053091270736, 0.25317053091270736, 0.25317053091270736, 0.10090994703812939, 0.10090994703812939, 0.10090994703812939, 0.11422164786062972, 0.11422164786062972, 0.11422164786062972, 0.5212488269937966, 0.5212488269937966, 0.5212488269937966, 0.6092900456626009, 0.6092900456626009, 0.6092900456626009, 0.5657986694000723, 0.5657986694000723, 0.5657986694000723, 0.07625858721913681, 0.07625858721913681, 0.07625858721913681, 0.11353684310069889, 0.11353684310069889, 0.11353684310069889, 0.13349225556029598, 0.13349225556029598, 0.13349225556029598, 0.2923087655110267, 0.2923087655110267, 0.2923087655110267, 0.17058849530006337, 0.17058849530006337, 0.17058849530006337, 0.36867958361848363, 0.36867958361848363, 0.36867958361848363, 0.40865239548570576, 0.40865239548570576, 0.40865239548570576, 0.39714577174572396, 0.39714577174572396, 0.39714577174572396, 0.2695926147327291, 0.2695926147327291, 0.2695926147327291, 0.21811446266173207, 0.21811446266173207, 0.21811446266173207, 0.34268712567274884, 0.34268712567274884, 0.34268712567274884, 0.22874659868451208, 0.22874659868451208, 0.22874659868451208, 0.21928541749058428, 0.21928541749058428, 0.21928541749058428, 0.22679558567235403, 0.22679558567235403, 0.22679558567235403, 0.2801068714944557, 0.2801068714944557, 0.2801068714944557, 0.24859292531735677, 0.24859292531735677, 0.24859292531735677, 0.22841934362266458, 0.22841934362266458, 0.22841934362266458, 0.2168144089226336, 0.2168144089226336, 0.2168144089226336, 0.9271356183668746, 0.9271356183668746, 0.9271356183668746, 0.11420627305427256, 0.11420627305427256, 0.11420627305427256, 0.1366109952920993, 0.1366109952920993, 0.1366109952920993, 0.6716788495300214, 0.6716788495300214, 0.6716788495300214, 0.6525119270873981, 0.6525119270873981, 0.6525119270873981, 0.7335310158747503, 0.7335310158747503, 0.7335310158747503, 0.22509205180813374, 0.22509205180813374, 0.22509205180813374, 0.23846259715961882, 0.23846259715961882, 0.23846259715961882, 0.23026115778748257, 0.23026115778748257, 0.23026115778748257, 0.10729408229532489, 0.10729408229532489, 0.10729408229532489, 0.08707462555969336, 0.08707462555969336, 0.08707462555969336, 0.09244825892062858, 0.09244825892062858, 0.09244825892062858]}, "mutation_prompt": null}
{"id": "88f7f25c-3381-4033-b3ba-d2541b1fbb7f", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(70, 12 * dim)  # Increased particles slightly for diversity\n        self.c1 = 1.4  # Further reduced cognitive component for better balance\n        self.c2 = 2.2  # Further increased social component to leverage collective intelligence\n        self.w = 0.85  # Adjusted inertia weight to balance exploration and exploitation\n        self.decay_rate = 0.93  # Faster decay to reduce inertia over time\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.1  # Increased velocity limit for more aggressive movement\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced APSO with adaptive learning components and improved velocity dynamics for faster convergence.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.8890345554254235, 0.8890345554254235, 0.8890345554254235, 0.8812898909220918, 0.8812898909220918, 0.8812898909220918, 0.885169648507018, 0.885169648507018, 0.885169648507018, 0.7943252300909807, 0.7943252300909807, 0.7943252300909807, 0.7992832977617781, 0.7992832977617781, 0.7992832977617781, 0.806978601700252, 0.806978601700252, 0.806978601700252, 0.141836067863071, 0.141836067863071, 0.141836067863071, 0.09072257940144113, 0.09072257940144113, 0.09072257940144113, 0.11538296000510384, 0.11538296000510384, 0.11538296000510384, 0.09182634705732529, 0.09182634705732529, 0.09182634705732529, 0.10396507449566983, 0.10396507449566983, 0.10396507449566983, 0.12877403769140183, 0.12877403769140183, 0.12877403769140183, 0.9171003036492754, 0.9171003036492754, 0.9171003036492754, 0.9426071411196885, 0.9426071411196885, 0.9426071411196885, 0.947537189438548, 0.947537189438548, 0.947537189438548, 0.6001545147287968, 0.6001545147287968, 0.6001545147287968, 0.684584432385599, 0.684584432385599, 0.684584432385599, 0.5898963208656243, 0.5898963208656243, 0.5898963208656243, 0.19375146093521256, 0.19375146093521256, 0.19375146093521256, 0.8693944340969452, 0.8693944340969452, 0.8693944340969452, 0.748951913666398, 0.748951913666398, 0.748951913666398, 0.21327141745353018, 0.21327141745353018, 0.21327141745353018, 0.20118277962625464, 0.20118277962625464, 0.20118277962625464, 0.22068388192974941, 0.22068388192974941, 0.22068388192974941, 0.23075865172070587, 0.23075865172070587, 0.23075865172070587, 0.2135229554500695, 0.2135229554500695, 0.2135229554500695, 0.23668946202621444, 0.23668946202621444, 0.23668946202621444, 0.005148868860398448, 0.005148868860398448, 0.005148868860398448, 0.08177194701312396, 0.08177194701312396, 0.08177194701312396, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08208764747391684, 0.08208764747391684, 0.08208764747391684, 0.05568690635405671, 0.05568690635405671, 0.05568690635405671, 0.11343134532868715, 0.11343134532868715, 0.11343134532868715, 0.04909694094295114, 0.04909694094295114, 0.04909694094295114, 0.11383841177004017, 0.11383841177004017, 0.11383841177004017, 0.26109733429390813, 0.26109733429390813, 0.26109733429390813, 0.25317053091270736, 0.25317053091270736, 0.25317053091270736, 0.10090994703812939, 0.10090994703812939, 0.10090994703812939, 0.11422164786062972, 0.11422164786062972, 0.11422164786062972, 0.5212488269937966, 0.5212488269937966, 0.5212488269937966, 0.6092900456626009, 0.6092900456626009, 0.6092900456626009, 0.5657986694000723, 0.5657986694000723, 0.5657986694000723, 0.07625858721913681, 0.07625858721913681, 0.07625858721913681, 0.11353684310069889, 0.11353684310069889, 0.11353684310069889, 0.13349225556029598, 0.13349225556029598, 0.13349225556029598, 0.2923087655110267, 0.2923087655110267, 0.2923087655110267, 0.17058849530006337, 0.17058849530006337, 0.17058849530006337, 0.36867958361848363, 0.36867958361848363, 0.36867958361848363, 0.40865239548570576, 0.40865239548570576, 0.40865239548570576, 0.39714577174572396, 0.39714577174572396, 0.39714577174572396, 0.2695926147327291, 0.2695926147327291, 0.2695926147327291, 0.21811446266173207, 0.21811446266173207, 0.21811446266173207, 0.34268712567274884, 0.34268712567274884, 0.34268712567274884, 0.22874659868451208, 0.22874659868451208, 0.22874659868451208, 0.21928541749058428, 0.21928541749058428, 0.21928541749058428, 0.22679558567235403, 0.22679558567235403, 0.22679558567235403, 0.2801068714944557, 0.2801068714944557, 0.2801068714944557, 0.24859292531735677, 0.24859292531735677, 0.24859292531735677, 0.22841934362266458, 0.22841934362266458, 0.22841934362266458, 0.2168144089226336, 0.2168144089226336, 0.2168144089226336, 0.9271356183668746, 0.9271356183668746, 0.9271356183668746, 0.11420627305427256, 0.11420627305427256, 0.11420627305427256, 0.1366109952920993, 0.1366109952920993, 0.1366109952920993, 0.6716788495300214, 0.6716788495300214, 0.6716788495300214, 0.6525119270873981, 0.6525119270873981, 0.6525119270873981, 0.7335310158747503, 0.7335310158747503, 0.7335310158747503, 0.22509205180813374, 0.22509205180813374, 0.22509205180813374, 0.23846259715961882, 0.23846259715961882, 0.23846259715961882, 0.23026115778748257, 0.23026115778748257, 0.23026115778748257, 0.10729408229532489, 0.10729408229532489, 0.10729408229532489, 0.08707462555969336, 0.08707462555969336, 0.08707462555969336, 0.09244825892062858, 0.09244825892062858, 0.09244825892062858]}, "mutation_prompt": null}
{"id": "33fd6e3f-ae5b-41fd-bdf8-9a92080f6dfd", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(70, 12 * dim)  # Increased particles slightly for diversity\n        self.c1 = 1.4  # Further reduced cognitive component for better balance\n        self.c2 = 2.2  # Further increased social component to leverage collective intelligence\n        self.w = 0.85  # Adjusted inertia weight to balance exploration and exploitation\n        self.decay_rate = 0.93  # Faster decay to reduce inertia over time\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.1  # Increased velocity limit for more aggressive movement\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced APSO with adaptive learning components and improved velocity dynamics for faster convergence.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.8890345554254235, 0.8890345554254235, 0.8890345554254235, 0.8812898909220918, 0.8812898909220918, 0.8812898909220918, 0.885169648507018, 0.885169648507018, 0.885169648507018, 0.7943252300909807, 0.7943252300909807, 0.7943252300909807, 0.7992832977617781, 0.7992832977617781, 0.7992832977617781, 0.806978601700252, 0.806978601700252, 0.806978601700252, 0.141836067863071, 0.141836067863071, 0.141836067863071, 0.09072257940144113, 0.09072257940144113, 0.09072257940144113, 0.11538296000510384, 0.11538296000510384, 0.11538296000510384, 0.09182634705732529, 0.09182634705732529, 0.09182634705732529, 0.10396507449566983, 0.10396507449566983, 0.10396507449566983, 0.12877403769140183, 0.12877403769140183, 0.12877403769140183, 0.9171003036492754, 0.9171003036492754, 0.9171003036492754, 0.9426071411196885, 0.9426071411196885, 0.9426071411196885, 0.947537189438548, 0.947537189438548, 0.947537189438548, 0.6001545147287968, 0.6001545147287968, 0.6001545147287968, 0.684584432385599, 0.684584432385599, 0.684584432385599, 0.5898963208656243, 0.5898963208656243, 0.5898963208656243, 0.19375146093521256, 0.19375146093521256, 0.19375146093521256, 0.8693944340969452, 0.8693944340969452, 0.8693944340969452, 0.748951913666398, 0.748951913666398, 0.748951913666398, 0.21327141745353018, 0.21327141745353018, 0.21327141745353018, 0.20118277962625464, 0.20118277962625464, 0.20118277962625464, 0.22068388192974941, 0.22068388192974941, 0.22068388192974941, 0.23075865172070587, 0.23075865172070587, 0.23075865172070587, 0.2135229554500695, 0.2135229554500695, 0.2135229554500695, 0.23668946202621444, 0.23668946202621444, 0.23668946202621444, 0.005148868860398448, 0.005148868860398448, 0.005148868860398448, 0.08177194701312396, 0.08177194701312396, 0.08177194701312396, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08208764747391684, 0.08208764747391684, 0.08208764747391684, 0.05568690635405671, 0.05568690635405671, 0.05568690635405671, 0.11343134532868715, 0.11343134532868715, 0.11343134532868715, 0.04909694094295114, 0.04909694094295114, 0.04909694094295114, 0.11383841177004017, 0.11383841177004017, 0.11383841177004017, 0.26109733429390813, 0.26109733429390813, 0.26109733429390813, 0.25317053091270736, 0.25317053091270736, 0.25317053091270736, 0.10090994703812939, 0.10090994703812939, 0.10090994703812939, 0.11422164786062972, 0.11422164786062972, 0.11422164786062972, 0.5212488269937966, 0.5212488269937966, 0.5212488269937966, 0.6092900456626009, 0.6092900456626009, 0.6092900456626009, 0.5657986694000723, 0.5657986694000723, 0.5657986694000723, 0.07625858721913681, 0.07625858721913681, 0.07625858721913681, 0.11353684310069889, 0.11353684310069889, 0.11353684310069889, 0.13349225556029598, 0.13349225556029598, 0.13349225556029598, 0.2923087655110267, 0.2923087655110267, 0.2923087655110267, 0.17058849530006337, 0.17058849530006337, 0.17058849530006337, 0.36867958361848363, 0.36867958361848363, 0.36867958361848363, 0.40865239548570576, 0.40865239548570576, 0.40865239548570576, 0.39714577174572396, 0.39714577174572396, 0.39714577174572396, 0.2695926147327291, 0.2695926147327291, 0.2695926147327291, 0.21811446266173207, 0.21811446266173207, 0.21811446266173207, 0.34268712567274884, 0.34268712567274884, 0.34268712567274884, 0.22874659868451208, 0.22874659868451208, 0.22874659868451208, 0.21928541749058428, 0.21928541749058428, 0.21928541749058428, 0.22679558567235403, 0.22679558567235403, 0.22679558567235403, 0.2801068714944557, 0.2801068714944557, 0.2801068714944557, 0.24859292531735677, 0.24859292531735677, 0.24859292531735677, 0.22841934362266458, 0.22841934362266458, 0.22841934362266458, 0.2168144089226336, 0.2168144089226336, 0.2168144089226336, 0.9271356183668746, 0.9271356183668746, 0.9271356183668746, 0.11420627305427256, 0.11420627305427256, 0.11420627305427256, 0.1366109952920993, 0.1366109952920993, 0.1366109952920993, 0.6716788495300214, 0.6716788495300214, 0.6716788495300214, 0.6525119270873981, 0.6525119270873981, 0.6525119270873981, 0.7335310158747503, 0.7335310158747503, 0.7335310158747503, 0.22509205180813374, 0.22509205180813374, 0.22509205180813374, 0.23846259715961882, 0.23846259715961882, 0.23846259715961882, 0.23026115778748257, 0.23026115778748257, 0.23026115778748257, 0.10729408229532489, 0.10729408229532489, 0.10729408229532489, 0.08707462555969336, 0.08707462555969336, 0.08707462555969336, 0.09244825892062858, 0.09244825892062858, 0.09244825892062858]}, "mutation_prompt": null}
{"id": "aee6f769-4f1c-499a-96b9-50efcda68073", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(70, 12 * dim)\n        self.c1 = 1.3  # Slightly reduced cognitive component\n        self.c2 = 2.3  # Increased social component for enhanced collective behavior\n        self.w = 0.85\n        self.decay_rate = 0.92  # Adjusted decay rate for inertia\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.1\n        self.momentum = 0.1  # Added momentum for velocity update\n        \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Introduced momentum in velocity update\n                vel[i] = (self.momentum * vel[i] + \n                          self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n                    \n            # Dynamically adjust social and cognitive components based on progress\n            self.c1 = max(0.5, self.c1 * 0.99)\n            self.c2 = min(2.5, self.c2 * 1.01)\n            self.w *= self.decay_rate\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced APSO with momentum strategy in velocity update and dynamically adapting social-cognitive balance for faster convergence.", "configspace": "", "generation": 72, "fitness": 0.3347710604872848, "feedback": "The algorithm EnhancedAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.28.", "error": "", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.8686580856176889, 0.8686580856176889, 0.8686580856176889, 0.8729257747550514, 0.8729257747550514, 0.8729257747550514, 0.8640253578635341, 0.8640253578635341, 0.8640253578635341, 0.7440555145373164, 0.7440555145373164, 0.7440555145373164, 0.7392834051585048, 0.7392834051585048, 0.7392834051585048, 0.7527483020862988, 0.7527483020862988, 0.7527483020862988, 0.11141758750698993, 0.11141758750698993, 0.11141758750698993, 0.07587034967401474, 0.07587034967401474, 0.07587034967401474, 0.18126084178540636, 0.18126084178540636, 0.18126084178540636, 0.11063803804320504, 0.11063803804320504, 0.11063803804320504, 0.11379253482750484, 0.11379253482750484, 0.11379253482750484, 0.13908602040228524, 0.13908602040228524, 0.13908602040228524, 0.9416494759287571, 0.9416494759287571, 0.9416494759287571, 0.946130483293937, 0.946130483293937, 0.946130483293937, 0.9482242867986579, 0.9482242867986579, 0.9482242867986579, 0.6918915237056737, 0.6918915237056737, 0.6918915237056737, 0.7076963074390774, 0.7076963074390774, 0.7076963074390774, 0.735324861386175, 0.735324861386175, 0.735324861386175, 0.17032529003530816, 0.17032529003530816, 0.17032529003530816, 0.16151322979070426, 0.16151322979070426, 0.16151322979070426, 0.3750700491516381, 0.3750700491516381, 0.3750700491516381, 0.2264802928532358, 0.2264802928532358, 0.2264802928532358, 0.222748194955651, 0.222748194955651, 0.222748194955651, 0.21005269293987672, 0.21005269293987672, 0.21005269293987672, 0.23942237016563983, 0.23942237016563983, 0.23942237016563983, 0.24260183440036132, 0.24260183440036132, 0.24260183440036132, 0.26784964751735374, 0.26784964751735374, 0.26784964751735374, 0.1338117799580194, 0.1338117799580194, 0.1338117799580194, 0.08941901921155881, 0.08941901921155881, 0.08941901921155881, 0.009416200784844508, 0.009416200784844508, 0.009416200784844508, 0.07207418598134863, 0.07207418598134863, 0.07207418598134863, 0.051657778581484126, 0.051657778581484126, 0.051657778581484126, 0.10755389627771783, 0.10755389627771783, 0.10755389627771783, 0.047888149093918364, 0.047888149093918364, 0.047888149093918364, 0.11463755716051127, 0.11463755716051127, 0.11463755716051127, 0.17779357058520473, 0.17779357058520473, 0.17779357058520473, 0.188488382567229, 0.188488382567229, 0.188488382567229, 0.2070841893998807, 0.2070841893998807, 0.2070841893998807, 0.10294992500089994, 0.10294992500089994, 0.10294992500089994, 0.5471129971293083, 0.5471129971293083, 0.5471129971293083, 0.5570458843671816, 0.5570458843671816, 0.5570458843671816, 0.5802881151003177, 0.5802881151003177, 0.5802881151003177, 0.0871744909872244, 0.0871744909872244, 0.0871744909872244, 0.14328031531666985, 0.14328031531666985, 0.14328031531666985, 0.10363892641765282, 0.10363892641765282, 0.10363892641765282, 0.21618545849958037, 0.21618545849958037, 0.21618545849958037, 0.19449716383835192, 0.19449716383835192, 0.19449716383835192, 0.3155434709008613, 0.3155434709008613, 0.3155434709008613, 0.29228198163603425, 0.29228198163603425, 0.29228198163603425, 0.44910335897566833, 0.44910335897566833, 0.44910335897566833, 0.5228929765559884, 0.5228929765559884, 0.5228929765559884, 0.18966658222699662, 0.18966658222699662, 0.18966658222699662, 0.37006942969043966, 0.37006942969043966, 0.37006942969043966, 0.3152840720863449, 0.3152840720863449, 0.3152840720863449, 0.22507597924813594, 0.22507597924813594, 0.22507597924813594, 0.2518861155559906, 0.2518861155559906, 0.2518861155559906, 0.24308338368616356, 0.24308338368616356, 0.24308338368616356, 0.18960558841138786, 0.18960558841138786, 0.18960558841138786, 0.1882283043713041, 0.1882283043713041, 0.1882283043713041, 0.22429585195284085, 0.22429585195284085, 0.22429585195284085, 0.92896451190112, 0.92896451190112, 0.92896451190112, 0.11419042798311241, 0.11419042798311241, 0.11419042798311241, 0.13637356323283334, 0.13637356323283334, 0.13637356323283334, 0.866011141706805, 0.866011141706805, 0.866011141706805, 0.7699999636319813, 0.7699999636319813, 0.7699999636319813, 0.12642930517705664, 0.12642930517705664, 0.12642930517705664, 0.19173876246511834, 0.19173876246511834, 0.19173876246511834, 0.20372466525736188, 0.20372466525736188, 0.20372466525736188, 0.22792753156664247, 0.22792753156664247, 0.22792753156664247, 0.09728571759344173, 0.09728571759344173, 0.09728571759344173, 0.11126207351694228, 0.11126207351694228, 0.11126207351694228, 0.1598512568751832, 0.1598512568751832, 0.1598512568751832]}, "mutation_prompt": null}
{"id": "df38ff33-9045-4ef8-827c-b2b8054969fa", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(70, 12 * dim)  # Increased particles slightly for diversity\n        self.c1 = 1.4  # Further reduced cognitive component for better balance\n        self.c2 = 2.2  # Further increased social component to leverage collective intelligence\n        self.w = 0.85  # Adjusted inertia weight to balance exploration and exploitation\n        self.decay_rate = 0.93  # Faster decay to reduce inertia over time\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.1  # Increased velocity limit for more aggressive movement\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced APSO with adaptive learning components and improved velocity dynamics for faster convergence.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.8890345554254235, 0.8890345554254235, 0.8890345554254235, 0.8812898909220918, 0.8812898909220918, 0.8812898909220918, 0.885169648507018, 0.885169648507018, 0.885169648507018, 0.7943252300909807, 0.7943252300909807, 0.7943252300909807, 0.7992832977617781, 0.7992832977617781, 0.7992832977617781, 0.806978601700252, 0.806978601700252, 0.806978601700252, 0.141836067863071, 0.141836067863071, 0.141836067863071, 0.09072257940144113, 0.09072257940144113, 0.09072257940144113, 0.11538296000510384, 0.11538296000510384, 0.11538296000510384, 0.09182634705732529, 0.09182634705732529, 0.09182634705732529, 0.10396507449566983, 0.10396507449566983, 0.10396507449566983, 0.12877403769140183, 0.12877403769140183, 0.12877403769140183, 0.9171003036492754, 0.9171003036492754, 0.9171003036492754, 0.9426071411196885, 0.9426071411196885, 0.9426071411196885, 0.947537189438548, 0.947537189438548, 0.947537189438548, 0.6001545147287968, 0.6001545147287968, 0.6001545147287968, 0.684584432385599, 0.684584432385599, 0.684584432385599, 0.5898963208656243, 0.5898963208656243, 0.5898963208656243, 0.19375146093521256, 0.19375146093521256, 0.19375146093521256, 0.8693944340969452, 0.8693944340969452, 0.8693944340969452, 0.748951913666398, 0.748951913666398, 0.748951913666398, 0.21327141745353018, 0.21327141745353018, 0.21327141745353018, 0.20118277962625464, 0.20118277962625464, 0.20118277962625464, 0.22068388192974941, 0.22068388192974941, 0.22068388192974941, 0.23075865172070587, 0.23075865172070587, 0.23075865172070587, 0.2135229554500695, 0.2135229554500695, 0.2135229554500695, 0.23668946202621444, 0.23668946202621444, 0.23668946202621444, 0.005148868860398448, 0.005148868860398448, 0.005148868860398448, 0.08177194701312396, 0.08177194701312396, 0.08177194701312396, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08208764747391684, 0.08208764747391684, 0.08208764747391684, 0.05568690635405671, 0.05568690635405671, 0.05568690635405671, 0.11343134532868715, 0.11343134532868715, 0.11343134532868715, 0.04909694094295114, 0.04909694094295114, 0.04909694094295114, 0.11383841177004017, 0.11383841177004017, 0.11383841177004017, 0.26109733429390813, 0.26109733429390813, 0.26109733429390813, 0.25317053091270736, 0.25317053091270736, 0.25317053091270736, 0.10090994703812939, 0.10090994703812939, 0.10090994703812939, 0.11422164786062972, 0.11422164786062972, 0.11422164786062972, 0.5212488269937966, 0.5212488269937966, 0.5212488269937966, 0.6092900456626009, 0.6092900456626009, 0.6092900456626009, 0.5657986694000723, 0.5657986694000723, 0.5657986694000723, 0.07625858721913681, 0.07625858721913681, 0.07625858721913681, 0.11353684310069889, 0.11353684310069889, 0.11353684310069889, 0.13349225556029598, 0.13349225556029598, 0.13349225556029598, 0.2923087655110267, 0.2923087655110267, 0.2923087655110267, 0.17058849530006337, 0.17058849530006337, 0.17058849530006337, 0.36867958361848363, 0.36867958361848363, 0.36867958361848363, 0.40865239548570576, 0.40865239548570576, 0.40865239548570576, 0.39714577174572396, 0.39714577174572396, 0.39714577174572396, 0.2695926147327291, 0.2695926147327291, 0.2695926147327291, 0.21811446266173207, 0.21811446266173207, 0.21811446266173207, 0.34268712567274884, 0.34268712567274884, 0.34268712567274884, 0.22874659868451208, 0.22874659868451208, 0.22874659868451208, 0.21928541749058428, 0.21928541749058428, 0.21928541749058428, 0.22679558567235403, 0.22679558567235403, 0.22679558567235403, 0.2801068714944557, 0.2801068714944557, 0.2801068714944557, 0.24859292531735677, 0.24859292531735677, 0.24859292531735677, 0.22841934362266458, 0.22841934362266458, 0.22841934362266458, 0.2168144089226336, 0.2168144089226336, 0.2168144089226336, 0.9271356183668746, 0.9271356183668746, 0.9271356183668746, 0.11420627305427256, 0.11420627305427256, 0.11420627305427256, 0.1366109952920993, 0.1366109952920993, 0.1366109952920993, 0.6716788495300214, 0.6716788495300214, 0.6716788495300214, 0.6525119270873981, 0.6525119270873981, 0.6525119270873981, 0.7335310158747503, 0.7335310158747503, 0.7335310158747503, 0.22509205180813374, 0.22509205180813374, 0.22509205180813374, 0.23846259715961882, 0.23846259715961882, 0.23846259715961882, 0.23026115778748257, 0.23026115778748257, 0.23026115778748257, 0.10729408229532489, 0.10729408229532489, 0.10729408229532489, 0.08707462555969336, 0.08707462555969336, 0.08707462555969336, 0.09244825892062858, 0.09244825892062858, 0.09244825892062858]}, "mutation_prompt": null}
{"id": "6e7d18ba-9d39-481d-9f59-45f350e5bb9f", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(70, 12 * dim)  # Increased particles slightly for diversity\n        self.c1 = 1.4  # Further reduced cognitive component for better balance\n        self.c2 = 2.2  # Further increased social component to leverage collective intelligence\n        self.w = 0.85  # Adjusted inertia weight to balance exploration and exploitation\n        self.decay_rate = 0.93  # Faster decay to reduce inertia over time\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.1  # Increased velocity limit for more aggressive movement\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced APSO with adaptive learning components and improved velocity dynamics for faster convergence.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.8890345554254235, 0.8890345554254235, 0.8890345554254235, 0.8812898909220918, 0.8812898909220918, 0.8812898909220918, 0.885169648507018, 0.885169648507018, 0.885169648507018, 0.7943252300909807, 0.7943252300909807, 0.7943252300909807, 0.7992832977617781, 0.7992832977617781, 0.7992832977617781, 0.806978601700252, 0.806978601700252, 0.806978601700252, 0.141836067863071, 0.141836067863071, 0.141836067863071, 0.09072257940144113, 0.09072257940144113, 0.09072257940144113, 0.11538296000510384, 0.11538296000510384, 0.11538296000510384, 0.09182634705732529, 0.09182634705732529, 0.09182634705732529, 0.10396507449566983, 0.10396507449566983, 0.10396507449566983, 0.12877403769140183, 0.12877403769140183, 0.12877403769140183, 0.9171003036492754, 0.9171003036492754, 0.9171003036492754, 0.9426071411196885, 0.9426071411196885, 0.9426071411196885, 0.947537189438548, 0.947537189438548, 0.947537189438548, 0.6001545147287968, 0.6001545147287968, 0.6001545147287968, 0.684584432385599, 0.684584432385599, 0.684584432385599, 0.5898963208656243, 0.5898963208656243, 0.5898963208656243, 0.19375146093521256, 0.19375146093521256, 0.19375146093521256, 0.8693944340969452, 0.8693944340969452, 0.8693944340969452, 0.748951913666398, 0.748951913666398, 0.748951913666398, 0.21327141745353018, 0.21327141745353018, 0.21327141745353018, 0.20118277962625464, 0.20118277962625464, 0.20118277962625464, 0.22068388192974941, 0.22068388192974941, 0.22068388192974941, 0.23075865172070587, 0.23075865172070587, 0.23075865172070587, 0.2135229554500695, 0.2135229554500695, 0.2135229554500695, 0.23668946202621444, 0.23668946202621444, 0.23668946202621444, 0.005148868860398448, 0.005148868860398448, 0.005148868860398448, 0.08177194701312396, 0.08177194701312396, 0.08177194701312396, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08208764747391684, 0.08208764747391684, 0.08208764747391684, 0.05568690635405671, 0.05568690635405671, 0.05568690635405671, 0.11343134532868715, 0.11343134532868715, 0.11343134532868715, 0.04909694094295114, 0.04909694094295114, 0.04909694094295114, 0.11383841177004017, 0.11383841177004017, 0.11383841177004017, 0.26109733429390813, 0.26109733429390813, 0.26109733429390813, 0.25317053091270736, 0.25317053091270736, 0.25317053091270736, 0.10090994703812939, 0.10090994703812939, 0.10090994703812939, 0.11422164786062972, 0.11422164786062972, 0.11422164786062972, 0.5212488269937966, 0.5212488269937966, 0.5212488269937966, 0.6092900456626009, 0.6092900456626009, 0.6092900456626009, 0.5657986694000723, 0.5657986694000723, 0.5657986694000723, 0.07625858721913681, 0.07625858721913681, 0.07625858721913681, 0.11353684310069889, 0.11353684310069889, 0.11353684310069889, 0.13349225556029598, 0.13349225556029598, 0.13349225556029598, 0.2923087655110267, 0.2923087655110267, 0.2923087655110267, 0.17058849530006337, 0.17058849530006337, 0.17058849530006337, 0.36867958361848363, 0.36867958361848363, 0.36867958361848363, 0.40865239548570576, 0.40865239548570576, 0.40865239548570576, 0.39714577174572396, 0.39714577174572396, 0.39714577174572396, 0.2695926147327291, 0.2695926147327291, 0.2695926147327291, 0.21811446266173207, 0.21811446266173207, 0.21811446266173207, 0.34268712567274884, 0.34268712567274884, 0.34268712567274884, 0.22874659868451208, 0.22874659868451208, 0.22874659868451208, 0.21928541749058428, 0.21928541749058428, 0.21928541749058428, 0.22679558567235403, 0.22679558567235403, 0.22679558567235403, 0.2801068714944557, 0.2801068714944557, 0.2801068714944557, 0.24859292531735677, 0.24859292531735677, 0.24859292531735677, 0.22841934362266458, 0.22841934362266458, 0.22841934362266458, 0.2168144089226336, 0.2168144089226336, 0.2168144089226336, 0.9271356183668746, 0.9271356183668746, 0.9271356183668746, 0.11420627305427256, 0.11420627305427256, 0.11420627305427256, 0.1366109952920993, 0.1366109952920993, 0.1366109952920993, 0.6716788495300214, 0.6716788495300214, 0.6716788495300214, 0.6525119270873981, 0.6525119270873981, 0.6525119270873981, 0.7335310158747503, 0.7335310158747503, 0.7335310158747503, 0.22509205180813374, 0.22509205180813374, 0.22509205180813374, 0.23846259715961882, 0.23846259715961882, 0.23846259715961882, 0.23026115778748257, 0.23026115778748257, 0.23026115778748257, 0.10729408229532489, 0.10729408229532489, 0.10729408229532489, 0.08707462555969336, 0.08707462555969336, 0.08707462555969336, 0.09244825892062858, 0.09244825892062858, 0.09244825892062858]}, "mutation_prompt": null}
{"id": "ddda57ac-8944-4e6a-964a-08126442b63b", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(70, 12 * dim)  # Increased particles slightly for diversity\n        self.c1 = 1.4  # Further reduced cognitive component for better balance\n        self.c2 = 2.2  # Further increased social component to leverage collective intelligence\n        self.w = 0.85  # Adjusted inertia weight to balance exploration and exploitation\n        self.decay_rate = 0.93  # Faster decay to reduce inertia over time\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.1  # Increased velocity limit for more aggressive movement\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced APSO with adaptive learning components and improved velocity dynamics for faster convergence.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.8890345554254235, 0.8890345554254235, 0.8890345554254235, 0.8812898909220918, 0.8812898909220918, 0.8812898909220918, 0.885169648507018, 0.885169648507018, 0.885169648507018, 0.7943252300909807, 0.7943252300909807, 0.7943252300909807, 0.7992832977617781, 0.7992832977617781, 0.7992832977617781, 0.806978601700252, 0.806978601700252, 0.806978601700252, 0.141836067863071, 0.141836067863071, 0.141836067863071, 0.09072257940144113, 0.09072257940144113, 0.09072257940144113, 0.11538296000510384, 0.11538296000510384, 0.11538296000510384, 0.09182634705732529, 0.09182634705732529, 0.09182634705732529, 0.10396507449566983, 0.10396507449566983, 0.10396507449566983, 0.12877403769140183, 0.12877403769140183, 0.12877403769140183, 0.9171003036492754, 0.9171003036492754, 0.9171003036492754, 0.9426071411196885, 0.9426071411196885, 0.9426071411196885, 0.947537189438548, 0.947537189438548, 0.947537189438548, 0.6001545147287968, 0.6001545147287968, 0.6001545147287968, 0.684584432385599, 0.684584432385599, 0.684584432385599, 0.5898963208656243, 0.5898963208656243, 0.5898963208656243, 0.19375146093521256, 0.19375146093521256, 0.19375146093521256, 0.8693944340969452, 0.8693944340969452, 0.8693944340969452, 0.748951913666398, 0.748951913666398, 0.748951913666398, 0.21327141745353018, 0.21327141745353018, 0.21327141745353018, 0.20118277962625464, 0.20118277962625464, 0.20118277962625464, 0.22068388192974941, 0.22068388192974941, 0.22068388192974941, 0.23075865172070587, 0.23075865172070587, 0.23075865172070587, 0.2135229554500695, 0.2135229554500695, 0.2135229554500695, 0.23668946202621444, 0.23668946202621444, 0.23668946202621444, 0.005148868860398448, 0.005148868860398448, 0.005148868860398448, 0.08177194701312396, 0.08177194701312396, 0.08177194701312396, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08208764747391684, 0.08208764747391684, 0.08208764747391684, 0.05568690635405671, 0.05568690635405671, 0.05568690635405671, 0.11343134532868715, 0.11343134532868715, 0.11343134532868715, 0.04909694094295114, 0.04909694094295114, 0.04909694094295114, 0.11383841177004017, 0.11383841177004017, 0.11383841177004017, 0.26109733429390813, 0.26109733429390813, 0.26109733429390813, 0.25317053091270736, 0.25317053091270736, 0.25317053091270736, 0.10090994703812939, 0.10090994703812939, 0.10090994703812939, 0.11422164786062972, 0.11422164786062972, 0.11422164786062972, 0.5212488269937966, 0.5212488269937966, 0.5212488269937966, 0.6092900456626009, 0.6092900456626009, 0.6092900456626009, 0.5657986694000723, 0.5657986694000723, 0.5657986694000723, 0.07625858721913681, 0.07625858721913681, 0.07625858721913681, 0.11353684310069889, 0.11353684310069889, 0.11353684310069889, 0.13349225556029598, 0.13349225556029598, 0.13349225556029598, 0.2923087655110267, 0.2923087655110267, 0.2923087655110267, 0.17058849530006337, 0.17058849530006337, 0.17058849530006337, 0.36867958361848363, 0.36867958361848363, 0.36867958361848363, 0.40865239548570576, 0.40865239548570576, 0.40865239548570576, 0.39714577174572396, 0.39714577174572396, 0.39714577174572396, 0.2695926147327291, 0.2695926147327291, 0.2695926147327291, 0.21811446266173207, 0.21811446266173207, 0.21811446266173207, 0.34268712567274884, 0.34268712567274884, 0.34268712567274884, 0.22874659868451208, 0.22874659868451208, 0.22874659868451208, 0.21928541749058428, 0.21928541749058428, 0.21928541749058428, 0.22679558567235403, 0.22679558567235403, 0.22679558567235403, 0.2801068714944557, 0.2801068714944557, 0.2801068714944557, 0.24859292531735677, 0.24859292531735677, 0.24859292531735677, 0.22841934362266458, 0.22841934362266458, 0.22841934362266458, 0.2168144089226336, 0.2168144089226336, 0.2168144089226336, 0.9271356183668746, 0.9271356183668746, 0.9271356183668746, 0.11420627305427256, 0.11420627305427256, 0.11420627305427256, 0.1366109952920993, 0.1366109952920993, 0.1366109952920993, 0.6716788495300214, 0.6716788495300214, 0.6716788495300214, 0.6525119270873981, 0.6525119270873981, 0.6525119270873981, 0.7335310158747503, 0.7335310158747503, 0.7335310158747503, 0.22509205180813374, 0.22509205180813374, 0.22509205180813374, 0.23846259715961882, 0.23846259715961882, 0.23846259715961882, 0.23026115778748257, 0.23026115778748257, 0.23026115778748257, 0.10729408229532489, 0.10729408229532489, 0.10729408229532489, 0.08707462555969336, 0.08707462555969336, 0.08707462555969336, 0.09244825892062858, 0.09244825892062858, 0.09244825892062858]}, "mutation_prompt": null}
{"id": "182a5761-4937-4aa8-9aa4-bb2aa59ae58a", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(70, 12 * dim)  # Increased particles slightly for diversity\n        self.c1 = 1.4  # Further reduced cognitive component for better balance\n        self.c2 = 2.2  # Further increased social component to leverage collective intelligence\n        self.w = 0.85  # Adjusted inertia weight to balance exploration and exploitation\n        self.decay_rate = 0.93  # Faster decay to reduce inertia over time\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.1  # Increased velocity limit for more aggressive movement\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced APSO with adaptive learning components and improved velocity dynamics for faster convergence.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.8890345554254235, 0.8890345554254235, 0.8890345554254235, 0.8812898909220918, 0.8812898909220918, 0.8812898909220918, 0.885169648507018, 0.885169648507018, 0.885169648507018, 0.7943252300909807, 0.7943252300909807, 0.7943252300909807, 0.7992832977617781, 0.7992832977617781, 0.7992832977617781, 0.806978601700252, 0.806978601700252, 0.806978601700252, 0.141836067863071, 0.141836067863071, 0.141836067863071, 0.09072257940144113, 0.09072257940144113, 0.09072257940144113, 0.11538296000510384, 0.11538296000510384, 0.11538296000510384, 0.09182634705732529, 0.09182634705732529, 0.09182634705732529, 0.10396507449566983, 0.10396507449566983, 0.10396507449566983, 0.12877403769140183, 0.12877403769140183, 0.12877403769140183, 0.9171003036492754, 0.9171003036492754, 0.9171003036492754, 0.9426071411196885, 0.9426071411196885, 0.9426071411196885, 0.947537189438548, 0.947537189438548, 0.947537189438548, 0.6001545147287968, 0.6001545147287968, 0.6001545147287968, 0.684584432385599, 0.684584432385599, 0.684584432385599, 0.5898963208656243, 0.5898963208656243, 0.5898963208656243, 0.19375146093521256, 0.19375146093521256, 0.19375146093521256, 0.8693944340969452, 0.8693944340969452, 0.8693944340969452, 0.748951913666398, 0.748951913666398, 0.748951913666398, 0.21327141745353018, 0.21327141745353018, 0.21327141745353018, 0.20118277962625464, 0.20118277962625464, 0.20118277962625464, 0.22068388192974941, 0.22068388192974941, 0.22068388192974941, 0.23075865172070587, 0.23075865172070587, 0.23075865172070587, 0.2135229554500695, 0.2135229554500695, 0.2135229554500695, 0.23668946202621444, 0.23668946202621444, 0.23668946202621444, 0.005148868860398448, 0.005148868860398448, 0.005148868860398448, 0.08177194701312396, 0.08177194701312396, 0.08177194701312396, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08208764747391684, 0.08208764747391684, 0.08208764747391684, 0.05568690635405671, 0.05568690635405671, 0.05568690635405671, 0.11343134532868715, 0.11343134532868715, 0.11343134532868715, 0.04909694094295114, 0.04909694094295114, 0.04909694094295114, 0.11383841177004017, 0.11383841177004017, 0.11383841177004017, 0.26109733429390813, 0.26109733429390813, 0.26109733429390813, 0.25317053091270736, 0.25317053091270736, 0.25317053091270736, 0.10090994703812939, 0.10090994703812939, 0.10090994703812939, 0.11422164786062972, 0.11422164786062972, 0.11422164786062972, 0.5212488269937966, 0.5212488269937966, 0.5212488269937966, 0.6092900456626009, 0.6092900456626009, 0.6092900456626009, 0.5657986694000723, 0.5657986694000723, 0.5657986694000723, 0.07625858721913681, 0.07625858721913681, 0.07625858721913681, 0.11353684310069889, 0.11353684310069889, 0.11353684310069889, 0.13349225556029598, 0.13349225556029598, 0.13349225556029598, 0.2923087655110267, 0.2923087655110267, 0.2923087655110267, 0.17058849530006337, 0.17058849530006337, 0.17058849530006337, 0.36867958361848363, 0.36867958361848363, 0.36867958361848363, 0.40865239548570576, 0.40865239548570576, 0.40865239548570576, 0.39714577174572396, 0.39714577174572396, 0.39714577174572396, 0.2695926147327291, 0.2695926147327291, 0.2695926147327291, 0.21811446266173207, 0.21811446266173207, 0.21811446266173207, 0.34268712567274884, 0.34268712567274884, 0.34268712567274884, 0.22874659868451208, 0.22874659868451208, 0.22874659868451208, 0.21928541749058428, 0.21928541749058428, 0.21928541749058428, 0.22679558567235403, 0.22679558567235403, 0.22679558567235403, 0.2801068714944557, 0.2801068714944557, 0.2801068714944557, 0.24859292531735677, 0.24859292531735677, 0.24859292531735677, 0.22841934362266458, 0.22841934362266458, 0.22841934362266458, 0.2168144089226336, 0.2168144089226336, 0.2168144089226336, 0.9271356183668746, 0.9271356183668746, 0.9271356183668746, 0.11420627305427256, 0.11420627305427256, 0.11420627305427256, 0.1366109952920993, 0.1366109952920993, 0.1366109952920993, 0.6716788495300214, 0.6716788495300214, 0.6716788495300214, 0.6525119270873981, 0.6525119270873981, 0.6525119270873981, 0.7335310158747503, 0.7335310158747503, 0.7335310158747503, 0.22509205180813374, 0.22509205180813374, 0.22509205180813374, 0.23846259715961882, 0.23846259715961882, 0.23846259715961882, 0.23026115778748257, 0.23026115778748257, 0.23026115778748257, 0.10729408229532489, 0.10729408229532489, 0.10729408229532489, 0.08707462555969336, 0.08707462555969336, 0.08707462555969336, 0.09244825892062858, 0.09244825892062858, 0.09244825892062858]}, "mutation_prompt": null}
{"id": "3d202a69-5c3b-41c9-8116-78170e1ee810", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(80, 14 * dim)  # Increased particles for initial exploration\n        self.c1 = 1.2  # Further reduced cognitive component for enhanced social learning\n        self.c2 = 2.5  # Increased social component for stronger convergence towards global best\n        self.w = 0.9  # Adjusted inertia weight for initial rapid exploration\n        self.decay_rate = 0.91  # Faster decay to quickly switch to exploitation\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.15  # Increased velocity for initial phase\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        dynamic_threshold = int(self.budget * 0.5)  # Switch strategy halfway through the budget\n\n        while evaluations < self.budget:\n            if evaluations > dynamic_threshold:\n                self.c1, self.c2 = 0.5, 3.0  # Shift to exploitation phase with more social influence\n                self.num_particles = max(50, 10 * self.dim)  # Reduce particles for focused search\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Dual-phase Enhanced APSO with dynamic swarm adjustment for accelerated convergence.", "configspace": "", "generation": 77, "fitness": 0.33696937250760933, "feedback": "The algorithm EnhancedAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.27.", "error": "", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.8640403217781727, 0.8640403217781727, 0.8640403217781727, 0.8528811148913347, 0.8528811148913347, 0.8528811148913347, 0.8699885085257002, 0.8699885085257002, 0.8699885085257002, 0.7441701062156724, 0.7441701062156724, 0.7441701062156724, 0.7596881264076637, 0.7596881264076637, 0.7596881264076637, 0.7644859195044634, 0.7644859195044634, 0.7644859195044634, 0.14772263131292052, 0.14772263131292052, 0.14772263131292052, 0.18030065391968897, 0.18030065391968897, 0.18030065391968897, 0.17546696070876644, 0.17546696070876644, 0.17546696070876644, 0.17669117398532452, 0.17669117398532452, 0.17669117398532452, 0.12480226526680294, 0.12480226526680294, 0.12480226526680294, 0.12267459577216233, 0.12267459577216233, 0.12267459577216233, 0.9577032543474396, 0.9577032543474396, 0.9577032543474396, 0.9598080237849326, 0.9598080237849326, 0.9598080237849326, 0.9555873431412598, 0.9555873431412598, 0.9555873431412598, 0.5683825651738584, 0.5683825651738584, 0.5683825651738584, 0.597385412948543, 0.597385412948543, 0.597385412948543, 0.593007232482446, 0.593007232482446, 0.593007232482446, 0.20140896403105923, 0.20140896403105923, 0.20140896403105923, 0.27358142053004686, 0.27358142053004686, 0.27358142053004686, 0.8125825056483408, 0.8125825056483408, 0.8125825056483408, 0.13074169834275284, 0.13074169834275284, 0.13074169834275284, 0.20471356487097192, 0.20471356487097192, 0.20471356487097192, 0.1865635667547455, 0.1865635667547455, 0.1865635667547455, 0.2194629580079548, 0.2194629580079548, 0.2194629580079548, 0.24681281654388743, 0.24681281654388743, 0.24681281654388743, 0.23942606565194902, 0.23942606565194902, 0.23942606565194902, 0.00418121829372653, 0.00418121829372653, 0.00418121829372653, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011289157195834565, 0.011289157195834565, 0.011289157195834565, 0.10161672263195032, 0.10161672263195032, 0.10161672263195032, 0.05801682750060422, 0.05801682750060422, 0.05801682750060422, 0.12259612643295459, 0.12259612643295459, 0.12259612643295459, 0.0476775444349139, 0.0476775444349139, 0.0476775444349139, 0.46217337840611694, 0.46217337840611694, 0.46217337840611694, 0.27204800460905276, 0.27204800460905276, 0.27204800460905276, 0.4268822059651487, 0.4268822059651487, 0.4268822059651487, 0.21440138941437148, 0.21440138941437148, 0.21440138941437148, 0.34130118819743316, 0.34130118819743316, 0.34130118819743316, 0.4958919227378402, 0.4958919227378402, 0.4958919227378402, 0.5865354179271824, 0.5865354179271824, 0.5865354179271824, 0.5889526178807781, 0.5889526178807781, 0.5889526178807781, 0.10116264273355935, 0.10116264273355935, 0.10116264273355935, 0.10872406464934337, 0.10872406464934337, 0.10872406464934337, 0.13912643314911588, 0.13912643314911588, 0.13912643314911588, 0.22050953855527267, 0.22050953855527267, 0.22050953855527267, 0.2916880588256322, 0.2916880588256322, 0.2916880588256322, 0.22987954994546522, 0.22987954994546522, 0.22987954994546522, 0.2864862962152164, 0.2864862962152164, 0.2864862962152164, 0.4295116832866388, 0.4295116832866388, 0.4295116832866388, 0.43691085616857617, 0.43691085616857617, 0.43691085616857617, 0.33817054073053887, 0.33817054073053887, 0.33817054073053887, 0.23992133354662892, 0.23992133354662892, 0.23992133354662892, 0.1816901153815993, 0.1816901153815993, 0.1816901153815993, 0.227824576339962, 0.227824576339962, 0.227824576339962, 0.2591894266691881, 0.2591894266691881, 0.2591894266691881, 0.22416125351233174, 0.22416125351233174, 0.22416125351233174, 0.21949670491054296, 0.21949670491054296, 0.21949670491054296, 0.20672156958853793, 0.20672156958853793, 0.20672156958853793, 0.22317367291595736, 0.22317367291595736, 0.22317367291595736, 0.9021742101127421, 0.9021742101127421, 0.9021742101127421, 0.1474818997812466, 0.1474818997812466, 0.1474818997812466, 0.16092297401213873, 0.16092297401213873, 0.16092297401213873, 0.7734644565048238, 0.7734644565048238, 0.7734644565048238, 0.20926899438047242, 0.20926899438047242, 0.20926899438047242, 0.0946449643632874, 0.0946449643632874, 0.0946449643632874, 0.22715244788844147, 0.22715244788844147, 0.22715244788844147, 0.19516123350097325, 0.19516123350097325, 0.19516123350097325, 0.21571597828436562, 0.21571597828436562, 0.21571597828436562, 0.09438553239135494, 0.09438553239135494, 0.09438553239135494, 0.10241161759266904, 0.10241161759266904, 0.10241161759266904, 0.11091870243448265, 0.11091870243448265, 0.11091870243448265]}, "mutation_prompt": null}
{"id": "3715eee7-57a1-4c72-b01b-3ea96be0d2c5", "solution": "import numpy as np\n\nclass EnhancedAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(70, 12 * dim)  # Increased particles slightly for diversity\n        self.c1 = 1.4  # Further reduced cognitive component for better balance\n        self.c2 = 2.2  # Further increased social component to leverage collective intelligence\n        self.w = 0.85  # Adjusted inertia weight to balance exploration and exploitation\n        self.decay_rate = 0.93  # Faster decay to reduce inertia over time\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.1  # Increased velocity limit for more aggressive movement\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        vel = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(pos)\n        personal_best_scores = np.array([func(p) for p in pos])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                vel[i] = (self.w * vel[i] + \n                          self.c1 * r1 * (personal_best_positions[i] - pos[i]) + \n                          self.c2 * r2 * (global_best_position - pos[i]))\n                \n                vel[i] = np.clip(vel[i], -self.velocity_limit, self.velocity_limit)\n                pos[i] += vel[i]\n                pos[i] = np.clip(pos[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pos[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pos[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pos[i]\n            \n            self.w *= self.decay_rate  # Decay inertia weight\n        \n        return global_best_position, global_best_score", "name": "EnhancedAPSO", "description": "Enhanced APSO with adaptive learning components and improved velocity dynamics for faster convergence.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "af92b6ca-0dd6-4fed-a2f6-c997608a7ac7", "metadata": {"aucs": [0.8890345554254235, 0.8890345554254235, 0.8890345554254235, 0.8812898909220918, 0.8812898909220918, 0.8812898909220918, 0.885169648507018, 0.885169648507018, 0.885169648507018, 0.7943252300909807, 0.7943252300909807, 0.7943252300909807, 0.7992832977617781, 0.7992832977617781, 0.7992832977617781, 0.806978601700252, 0.806978601700252, 0.806978601700252, 0.141836067863071, 0.141836067863071, 0.141836067863071, 0.09072257940144113, 0.09072257940144113, 0.09072257940144113, 0.11538296000510384, 0.11538296000510384, 0.11538296000510384, 0.09182634705732529, 0.09182634705732529, 0.09182634705732529, 0.10396507449566983, 0.10396507449566983, 0.10396507449566983, 0.12877403769140183, 0.12877403769140183, 0.12877403769140183, 0.9171003036492754, 0.9171003036492754, 0.9171003036492754, 0.9426071411196885, 0.9426071411196885, 0.9426071411196885, 0.947537189438548, 0.947537189438548, 0.947537189438548, 0.6001545147287968, 0.6001545147287968, 0.6001545147287968, 0.684584432385599, 0.684584432385599, 0.684584432385599, 0.5898963208656243, 0.5898963208656243, 0.5898963208656243, 0.19375146093521256, 0.19375146093521256, 0.19375146093521256, 0.8693944340969452, 0.8693944340969452, 0.8693944340969452, 0.748951913666398, 0.748951913666398, 0.748951913666398, 0.21327141745353018, 0.21327141745353018, 0.21327141745353018, 0.20118277962625464, 0.20118277962625464, 0.20118277962625464, 0.22068388192974941, 0.22068388192974941, 0.22068388192974941, 0.23075865172070587, 0.23075865172070587, 0.23075865172070587, 0.2135229554500695, 0.2135229554500695, 0.2135229554500695, 0.23668946202621444, 0.23668946202621444, 0.23668946202621444, 0.005148868860398448, 0.005148868860398448, 0.005148868860398448, 0.08177194701312396, 0.08177194701312396, 0.08177194701312396, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08208764747391684, 0.08208764747391684, 0.08208764747391684, 0.05568690635405671, 0.05568690635405671, 0.05568690635405671, 0.11343134532868715, 0.11343134532868715, 0.11343134532868715, 0.04909694094295114, 0.04909694094295114, 0.04909694094295114, 0.11383841177004017, 0.11383841177004017, 0.11383841177004017, 0.26109733429390813, 0.26109733429390813, 0.26109733429390813, 0.25317053091270736, 0.25317053091270736, 0.25317053091270736, 0.10090994703812939, 0.10090994703812939, 0.10090994703812939, 0.11422164786062972, 0.11422164786062972, 0.11422164786062972, 0.5212488269937966, 0.5212488269937966, 0.5212488269937966, 0.6092900456626009, 0.6092900456626009, 0.6092900456626009, 0.5657986694000723, 0.5657986694000723, 0.5657986694000723, 0.07625858721913681, 0.07625858721913681, 0.07625858721913681, 0.11353684310069889, 0.11353684310069889, 0.11353684310069889, 0.13349225556029598, 0.13349225556029598, 0.13349225556029598, 0.2923087655110267, 0.2923087655110267, 0.2923087655110267, 0.17058849530006337, 0.17058849530006337, 0.17058849530006337, 0.36867958361848363, 0.36867958361848363, 0.36867958361848363, 0.40865239548570576, 0.40865239548570576, 0.40865239548570576, 0.39714577174572396, 0.39714577174572396, 0.39714577174572396, 0.2695926147327291, 0.2695926147327291, 0.2695926147327291, 0.21811446266173207, 0.21811446266173207, 0.21811446266173207, 0.34268712567274884, 0.34268712567274884, 0.34268712567274884, 0.22874659868451208, 0.22874659868451208, 0.22874659868451208, 0.21928541749058428, 0.21928541749058428, 0.21928541749058428, 0.22679558567235403, 0.22679558567235403, 0.22679558567235403, 0.2801068714944557, 0.2801068714944557, 0.2801068714944557, 0.24859292531735677, 0.24859292531735677, 0.24859292531735677, 0.22841934362266458, 0.22841934362266458, 0.22841934362266458, 0.2168144089226336, 0.2168144089226336, 0.2168144089226336, 0.9271356183668746, 0.9271356183668746, 0.9271356183668746, 0.11420627305427256, 0.11420627305427256, 0.11420627305427256, 0.1366109952920993, 0.1366109952920993, 0.1366109952920993, 0.6716788495300214, 0.6716788495300214, 0.6716788495300214, 0.6525119270873981, 0.6525119270873981, 0.6525119270873981, 0.7335310158747503, 0.7335310158747503, 0.7335310158747503, 0.22509205180813374, 0.22509205180813374, 0.22509205180813374, 0.23846259715961882, 0.23846259715961882, 0.23846259715961882, 0.23026115778748257, 0.23026115778748257, 0.23026115778748257, 0.10729408229532489, 0.10729408229532489, 0.10729408229532489, 0.08707462555969336, 0.08707462555969336, 0.08707462555969336, 0.09244825892062858, 0.09244825892062858, 0.09244825892062858]}, "mutation_prompt": null}

{"id": "00016c82-8530-49ce-a4cd-d0ff638928f2", "solution": "import numpy as np\n\nclass PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n\n    def __call__(self, func):\n        np.random.seed(42)\n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            # Update personal and global bests\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            # Apply Differential Evolution mutation and crossover\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "PSO_ADE_Optimizer", "description": "Hybrid Particle Swarm Optimization with Adaptive Differential Evolution (PSO-ADE) combines swarm intelligence and mutation strategies to balance exploration and exploitation for efficient search.", "configspace": "", "generation": 0, "fitness": 0.2662086944401929, "feedback": "The algorithm PSO_ADE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.23.", "error": "", "parent_id": null, "metadata": {"aucs": [0.6921163136188262, 0.6921163136188262, 0.6921163136188262, 0.6141005361866843, 0.6141005361866843, 0.6141005361866843, 0.7101297430937754, 0.7101297430937754, 0.7101297430937754, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.21222809629046424, 0.21222809629046424, 0.21222809629046424, 0.01400111651648206, 0.01400111651648206, 0.01400111651648206, 0.09027192408854134, 0.09027192408854134, 0.09027192408854134, 0.10932415872791823, 0.10932415872791823, 0.10932415872791823, 0.1341235138283826, 0.1341235138283826, 0.1341235138283826, 0.15874693251912908, 0.15874693251912908, 0.15874693251912908, 0.11845369966779984, 0.11845369966779984, 0.11845369966779984, 0.12624330260423633, 0.12624330260423633, 0.12624330260423633, 0.9750192773622189, 0.9750192773622189, 0.9750192773622189, 0.9773408907457926, 0.9773408907457926, 0.9773408907457926, 0.9764359866445449, 0.9764359866445449, 0.9764359866445449, 0.49813541922359117, 0.49813541922359117, 0.49813541922359117, 0.5066436259615181, 0.5066436259615181, 0.5066436259615181, 0.5325410217912183, 0.5325410217912183, 0.5325410217912183, 0.2180536001945066, 0.2180536001945066, 0.2180536001945066, 0.15955365086274287, 0.15955365086274287, 0.15955365086274287, 0.11669974135986194, 0.11669974135986194, 0.11669974135986194, 0.3192301653471675, 0.3192301653471675, 0.3192301653471675, 0.12047545887350408, 0.12047545887350408, 0.12047545887350408, 0.4895410527183002, 0.4895410527183002, 0.4895410527183002, 0.30983467690359756, 0.30983467690359756, 0.30983467690359756, 0.25981713931026273, 0.25981713931026273, 0.25981713931026273, 0.116775284106304, 0.116775284106304, 0.116775284106304, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11234287978186497, 0.11234287978186497, 0.11234287978186497, 0.20217911017436585, 0.20217911017436585, 0.20217911017436585, 0.26951560053030943, 0.26951560053030943, 0.26951560053030943, 0.06589815951641032, 0.06589815951641032, 0.06589815951641032, 0.19585390761318644, 0.19585390761318644, 0.19585390761318644, 0.130776515274856, 0.130776515274856, 0.130776515274856, 0.056201113150505466, 0.056201113150505466, 0.056201113150505466, 0.08474039760497687, 0.08474039760497687, 0.08474039760497687, 0.1781186427308512, 0.1781186427308512, 0.1781186427308512, 0.1651035243859651, 0.1651035243859651, 0.1651035243859651, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5306071272671027, 0.5306071272671027, 0.5306071272671027, 0.5620155147396554, 0.5620155147396554, 0.5620155147396554, 0.5674957634774221, 0.5674957634774221, 0.5674957634774221, 0.09816506173836403, 0.09816506173836403, 0.09816506173836403, 0.10662575479143965, 0.10662575479143965, 0.10662575479143965, 0.11915990157649015, 0.11915990157649015, 0.11915990157649015, 0.2480725761801056, 0.2480725761801056, 0.2480725761801056, 0.20508588272961292, 0.20508588272961292, 0.20508588272961292, 0.20186295703757473, 0.20186295703757473, 0.20186295703757473, 0.39052066099920646, 0.39052066099920646, 0.39052066099920646, 0.21340139604270136, 0.21340139604270136, 0.21340139604270136, 0.33556046609964074, 0.33556046609964074, 0.33556046609964074, 0.3079800110267952, 0.3079800110267952, 0.3079800110267952, 0.22988328261885183, 0.22988328261885183, 0.22988328261885183, 0.13934663440847161, 0.13934663440847161, 0.13934663440847161, 0.2392358162520697, 0.2392358162520697, 0.2392358162520697, 0.2353611695482163, 0.2353611695482163, 0.2353611695482163, 0.21329124322443893, 0.21329124322443893, 0.21329124322443893, 0.17623575589755058, 0.17623575589755058, 0.17623575589755058, 0.18472806386394913, 0.18472806386394913, 0.18472806386394913, 0.2332795332206743, 0.2332795332206743, 0.2332795332206743, 0.8412688632559204, 0.8412688632559204, 0.8412688632559204, 0.15738560452270445, 0.15738560452270445, 0.15738560452270445, 0.1691347649539564, 0.1691347649539564, 0.1691347649539564, 0.20971674883211822, 0.20971674883211822, 0.20971674883211822, 0.20956225564830866, 0.20956225564830866, 0.20956225564830866, 0.15187885712245497, 0.15187885712245497, 0.15187885712245497, 0.1884438209632735, 0.1884438209632735, 0.1884438209632735, 0.18092815435556575, 0.18092815435556575, 0.18092815435556575, 0.19128512249819307, 0.19128512249819307, 0.19128512249819307, 0.10496923951524872, 0.10496923951524872, 0.10496923951524872, 0.1020169549279748, 0.1020169549279748, 0.1020169549279748, 0.10565486104717525, 0.10565486104717525, 0.10565486104717525]}, "mutation_prompt": null}
{"id": "fba9d92a-38da-445c-948d-714865bad75d", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.max_mutation_factor = 0.9\n        self.min_mutation_factor = 0.5\n        self.crossover_prob = 0.9\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 2.0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            r1, r2 = np.random.rand(2)\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (eval_count / self.budget)\n            velocities = (\n                inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutation_factor = self.max_mutation_factor - (self.max_mutation_factor - self.min_mutation_factor) * (eval_count / self.budget)\n                mutated_vector = np.clip(x0 + mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced Hybrid PSO with DE: Introduce dynamic inertia and adaptive mutation to improve convergence speed.", "configspace": "", "generation": 1, "fitness": 0.1786024336349177, "feedback": "The algorithm Enhanced_PSO_ADE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.20.", "error": "", "parent_id": "00016c82-8530-49ce-a4cd-d0ff638928f2", "metadata": {"aucs": [0.39306067301678893, 0.39306067301678893, 0.39306067301678893, 0.15663924180604827, 0.15663924180604827, 0.15663924180604827, 0.3944210049919292, 0.3944210049919292, 0.3944210049919292, 0.012818223625095215, 0.012818223625095215, 0.012818223625095215, 0.021063272636071217, 0.021063272636071217, 0.021063272636071217, 0.0011121848474232587, 0.0011121848474232587, 0.0011121848474232587, 0.10913102359467652, 0.10913102359467652, 0.10913102359467652, 0.10463458066714759, 0.10463458066714759, 0.10463458066714759, 0.09079422397231829, 0.09079422397231829, 0.09079422397231829, 0.08832877833894726, 0.08832877833894726, 0.08832877833894726, 0.08027422894932912, 0.08027422894932912, 0.08027422894932912, 0.06511622152574637, 0.06511622152574637, 0.06511622152574637, 0.9853784192969735, 0.9853784192969735, 0.9853784192969735, 0.9837943244257885, 0.9837943244257885, 0.9837943244257885, 0.9776530640747174, 0.9776530640747174, 0.9776530640747174, 0.21590394430817672, 0.21590394430817672, 0.21590394430817672, 0.1397296923147553, 0.1397296923147553, 0.1397296923147553, 0.22096669077147146, 0.22096669077147146, 0.22096669077147146, 0.308443175842818, 0.308443175842818, 0.308443175842818, 0.16083240062242732, 0.16083240062242732, 0.16083240062242732, 0.33359180789955356, 0.33359180789955356, 0.33359180789955356, 0.15046675581098412, 0.15046675581098412, 0.15046675581098412, 0.12318721317908221, 0.12318721317908221, 0.12318721317908221, 0.1261178096930725, 0.1261178096930725, 0.1261178096930725, 0.10803300455320963, 0.10803300455320963, 0.10803300455320963, 0.08273287414367203, 0.08273287414367203, 0.08273287414367203, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0001420256637122419, 0.0001420256637122419, 0.0001420256637122419, 0.08221455689387747, 0.08221455689387747, 0.08221455689387747, 0.01713831521482334, 0.01713831521482334, 0.01713831521482334, 0.09319611735616706, 0.09319611735616706, 0.09319611735616706, 0.008336231271216965, 0.008336231271216965, 0.008336231271216965, 0.02135388594573273, 0.02135388594573273, 0.02135388594573273, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08493177920472861, 0.08493177920472861, 0.08493177920472861, 0.025477155287291886, 0.025477155287291886, 0.025477155287291886, 0.05287105774911871, 0.05287105774911871, 0.05287105774911871, 0.3805248978782185, 0.3805248978782185, 0.3805248978782185, 0.1670507911119734, 0.1670507911119734, 0.1670507911119734, 0.3472700225962322, 0.3472700225962322, 0.3472700225962322, 0.10629071086889075, 0.10629071086889075, 0.10629071086889075, 0.08181828264329105, 0.08181828264329105, 0.08181828264329105, 0.08818704044805692, 0.08818704044805692, 0.08818704044805692, 0.13408877859320945, 0.13408877859320945, 0.13408877859320945, 0.15562146669858845, 0.15562146669858845, 0.15562146669858845, 0.15117878945629404, 0.15117878945629404, 0.15117878945629404, 0.26193156144357854, 0.26193156144357854, 0.26193156144357854, 0.20070209916067072, 0.20070209916067072, 0.20070209916067072, 0.17833841708640452, 0.17833841708640452, 0.17833841708640452, 0.13607315998739122, 0.13607315998739122, 0.13607315998739122, 0.1570389083288023, 0.1570389083288023, 0.1570389083288023, 0.11442673588592367, 0.11442673588592367, 0.11442673588592367, 0.19910321828731736, 0.19910321828731736, 0.19910321828731736, 0.19046665308332367, 0.19046665308332367, 0.19046665308332367, 0.16766339864764723, 0.16766339864764723, 0.16766339864764723, 0.18460553656133716, 0.18460553656133716, 0.18460553656133716, 0.17667690538271819, 0.17667690538271819, 0.17667690538271819, 0.19020019800610322, 0.19020019800610322, 0.19020019800610322, 0.608066782045894, 0.608066782045894, 0.608066782045894, 0.15691941934442166, 0.15691941934442166, 0.15691941934442166, 0.1687070780479244, 0.1687070780479244, 0.1687070780479244, 0.10679385100412786, 0.10679385100412786, 0.10679385100412786, 0.2018431762791525, 0.2018431762791525, 0.2018431762791525, 0.151218696382588, 0.151218696382588, 0.151218696382588, 0.20830066266503855, 0.20830066266503855, 0.20830066266503855, 0.19161392740787386, 0.19161392740787386, 0.19161392740787386, 0.22781152150879036, 0.22781152150879036, 0.22781152150879036, 0.0838387638115341, 0.0838387638115341, 0.0838387638115341, 0.07574045391966333, 0.07574045391966333, 0.07574045391966333, 0.08897735764620118, 0.08897735764620118, 0.08897735764620118]}, "mutation_prompt": null}
{"id": "b63b0c0c-784f-41b4-bda3-f8275269ed9f", "solution": "import numpy as np\n\nclass PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n\n    def __call__(self, func):\n        np.random.seed(42)\n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            # Update personal and global bests\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            # Apply Differential Evolution mutation and crossover\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "PSO_ADE_Optimizer", "description": "Hybrid Particle Swarm Optimization with Adaptive Differential Evolution (PSO-ADE) combines swarm intelligence and mutation strategies to balance exploration and exploitation for efficient search.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "00016c82-8530-49ce-a4cd-d0ff638928f2", "metadata": {"aucs": [0.6921163136188262, 0.6921163136188262, 0.6921163136188262, 0.6141005361866843, 0.6141005361866843, 0.6141005361866843, 0.7101297430937754, 0.7101297430937754, 0.7101297430937754, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.21222809629046424, 0.21222809629046424, 0.21222809629046424, 0.01400111651648206, 0.01400111651648206, 0.01400111651648206, 0.09027192408854134, 0.09027192408854134, 0.09027192408854134, 0.10932415872791823, 0.10932415872791823, 0.10932415872791823, 0.1341235138283826, 0.1341235138283826, 0.1341235138283826, 0.15874693251912908, 0.15874693251912908, 0.15874693251912908, 0.11845369966779984, 0.11845369966779984, 0.11845369966779984, 0.12624330260423633, 0.12624330260423633, 0.12624330260423633, 0.9750192773622189, 0.9750192773622189, 0.9750192773622189, 0.9773408907457926, 0.9773408907457926, 0.9773408907457926, 0.9764359866445449, 0.9764359866445449, 0.9764359866445449, 0.49813541922359117, 0.49813541922359117, 0.49813541922359117, 0.5066436259615181, 0.5066436259615181, 0.5066436259615181, 0.5325410217912183, 0.5325410217912183, 0.5325410217912183, 0.2180536001945066, 0.2180536001945066, 0.2180536001945066, 0.15955365086274287, 0.15955365086274287, 0.15955365086274287, 0.11669974135986194, 0.11669974135986194, 0.11669974135986194, 0.3192301653471675, 0.3192301653471675, 0.3192301653471675, 0.12047545887350408, 0.12047545887350408, 0.12047545887350408, 0.4895410527183002, 0.4895410527183002, 0.4895410527183002, 0.30983467690359756, 0.30983467690359756, 0.30983467690359756, 0.25981713931026273, 0.25981713931026273, 0.25981713931026273, 0.116775284106304, 0.116775284106304, 0.116775284106304, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11234287978186497, 0.11234287978186497, 0.11234287978186497, 0.20217911017436585, 0.20217911017436585, 0.20217911017436585, 0.26951560053030943, 0.26951560053030943, 0.26951560053030943, 0.06589815951641032, 0.06589815951641032, 0.06589815951641032, 0.19585390761318644, 0.19585390761318644, 0.19585390761318644, 0.130776515274856, 0.130776515274856, 0.130776515274856, 0.056201113150505466, 0.056201113150505466, 0.056201113150505466, 0.08474039760497687, 0.08474039760497687, 0.08474039760497687, 0.1781186427308512, 0.1781186427308512, 0.1781186427308512, 0.1651035243859651, 0.1651035243859651, 0.1651035243859651, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5306071272671027, 0.5306071272671027, 0.5306071272671027, 0.5620155147396554, 0.5620155147396554, 0.5620155147396554, 0.5674957634774221, 0.5674957634774221, 0.5674957634774221, 0.09816506173836403, 0.09816506173836403, 0.09816506173836403, 0.10662575479143965, 0.10662575479143965, 0.10662575479143965, 0.11915990157649015, 0.11915990157649015, 0.11915990157649015, 0.2480725761801056, 0.2480725761801056, 0.2480725761801056, 0.20508588272961292, 0.20508588272961292, 0.20508588272961292, 0.20186295703757473, 0.20186295703757473, 0.20186295703757473, 0.39052066099920646, 0.39052066099920646, 0.39052066099920646, 0.21340139604270136, 0.21340139604270136, 0.21340139604270136, 0.33556046609964074, 0.33556046609964074, 0.33556046609964074, 0.3079800110267952, 0.3079800110267952, 0.3079800110267952, 0.22988328261885183, 0.22988328261885183, 0.22988328261885183, 0.13934663440847161, 0.13934663440847161, 0.13934663440847161, 0.2392358162520697, 0.2392358162520697, 0.2392358162520697, 0.2353611695482163, 0.2353611695482163, 0.2353611695482163, 0.21329124322443893, 0.21329124322443893, 0.21329124322443893, 0.17623575589755058, 0.17623575589755058, 0.17623575589755058, 0.18472806386394913, 0.18472806386394913, 0.18472806386394913, 0.2332795332206743, 0.2332795332206743, 0.2332795332206743, 0.8412688632559204, 0.8412688632559204, 0.8412688632559204, 0.15738560452270445, 0.15738560452270445, 0.15738560452270445, 0.1691347649539564, 0.1691347649539564, 0.1691347649539564, 0.20971674883211822, 0.20971674883211822, 0.20971674883211822, 0.20956225564830866, 0.20956225564830866, 0.20956225564830866, 0.15187885712245497, 0.15187885712245497, 0.15187885712245497, 0.1884438209632735, 0.1884438209632735, 0.1884438209632735, 0.18092815435556575, 0.18092815435556575, 0.18092815435556575, 0.19128512249819307, 0.19128512249819307, 0.19128512249819307, 0.10496923951524872, 0.10496923951524872, 0.10496923951524872, 0.1020169549279748, 0.1020169549279748, 0.1020169549279748, 0.10565486104717525, 0.10565486104717525, 0.10565486104717525]}, "mutation_prompt": null}
{"id": "4049a26a-e7d3-4f43-9b89-4490f7769b38", "solution": "import numpy as np\n\nclass PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n\n    def __call__(self, func):\n        np.random.seed(42)\n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            # Update personal and global bests\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            # Apply Differential Evolution mutation and crossover\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "PSO_ADE_Optimizer", "description": "Hybrid Particle Swarm Optimization with Adaptive Differential Evolution (PSO-ADE) combines swarm intelligence and mutation strategies to balance exploration and exploitation for efficient search.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "00016c82-8530-49ce-a4cd-d0ff638928f2", "metadata": {"aucs": [0.6921163136188262, 0.6921163136188262, 0.6921163136188262, 0.6141005361866843, 0.6141005361866843, 0.6141005361866843, 0.7101297430937754, 0.7101297430937754, 0.7101297430937754, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.21222809629046424, 0.21222809629046424, 0.21222809629046424, 0.01400111651648206, 0.01400111651648206, 0.01400111651648206, 0.09027192408854134, 0.09027192408854134, 0.09027192408854134, 0.10932415872791823, 0.10932415872791823, 0.10932415872791823, 0.1341235138283826, 0.1341235138283826, 0.1341235138283826, 0.15874693251912908, 0.15874693251912908, 0.15874693251912908, 0.11845369966779984, 0.11845369966779984, 0.11845369966779984, 0.12624330260423633, 0.12624330260423633, 0.12624330260423633, 0.9750192773622189, 0.9750192773622189, 0.9750192773622189, 0.9773408907457926, 0.9773408907457926, 0.9773408907457926, 0.9764359866445449, 0.9764359866445449, 0.9764359866445449, 0.49813541922359117, 0.49813541922359117, 0.49813541922359117, 0.5066436259615181, 0.5066436259615181, 0.5066436259615181, 0.5325410217912183, 0.5325410217912183, 0.5325410217912183, 0.2180536001945066, 0.2180536001945066, 0.2180536001945066, 0.15955365086274287, 0.15955365086274287, 0.15955365086274287, 0.11669974135986194, 0.11669974135986194, 0.11669974135986194, 0.3192301653471675, 0.3192301653471675, 0.3192301653471675, 0.12047545887350408, 0.12047545887350408, 0.12047545887350408, 0.4895410527183002, 0.4895410527183002, 0.4895410527183002, 0.30983467690359756, 0.30983467690359756, 0.30983467690359756, 0.25981713931026273, 0.25981713931026273, 0.25981713931026273, 0.116775284106304, 0.116775284106304, 0.116775284106304, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11234287978186497, 0.11234287978186497, 0.11234287978186497, 0.20217911017436585, 0.20217911017436585, 0.20217911017436585, 0.26951560053030943, 0.26951560053030943, 0.26951560053030943, 0.06589815951641032, 0.06589815951641032, 0.06589815951641032, 0.19585390761318644, 0.19585390761318644, 0.19585390761318644, 0.130776515274856, 0.130776515274856, 0.130776515274856, 0.056201113150505466, 0.056201113150505466, 0.056201113150505466, 0.08474039760497687, 0.08474039760497687, 0.08474039760497687, 0.1781186427308512, 0.1781186427308512, 0.1781186427308512, 0.1651035243859651, 0.1651035243859651, 0.1651035243859651, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5306071272671027, 0.5306071272671027, 0.5306071272671027, 0.5620155147396554, 0.5620155147396554, 0.5620155147396554, 0.5674957634774221, 0.5674957634774221, 0.5674957634774221, 0.09816506173836403, 0.09816506173836403, 0.09816506173836403, 0.10662575479143965, 0.10662575479143965, 0.10662575479143965, 0.11915990157649015, 0.11915990157649015, 0.11915990157649015, 0.2480725761801056, 0.2480725761801056, 0.2480725761801056, 0.20508588272961292, 0.20508588272961292, 0.20508588272961292, 0.20186295703757473, 0.20186295703757473, 0.20186295703757473, 0.39052066099920646, 0.39052066099920646, 0.39052066099920646, 0.21340139604270136, 0.21340139604270136, 0.21340139604270136, 0.33556046609964074, 0.33556046609964074, 0.33556046609964074, 0.3079800110267952, 0.3079800110267952, 0.3079800110267952, 0.22988328261885183, 0.22988328261885183, 0.22988328261885183, 0.13934663440847161, 0.13934663440847161, 0.13934663440847161, 0.2392358162520697, 0.2392358162520697, 0.2392358162520697, 0.2353611695482163, 0.2353611695482163, 0.2353611695482163, 0.21329124322443893, 0.21329124322443893, 0.21329124322443893, 0.17623575589755058, 0.17623575589755058, 0.17623575589755058, 0.18472806386394913, 0.18472806386394913, 0.18472806386394913, 0.2332795332206743, 0.2332795332206743, 0.2332795332206743, 0.8412688632559204, 0.8412688632559204, 0.8412688632559204, 0.15738560452270445, 0.15738560452270445, 0.15738560452270445, 0.1691347649539564, 0.1691347649539564, 0.1691347649539564, 0.20971674883211822, 0.20971674883211822, 0.20971674883211822, 0.20956225564830866, 0.20956225564830866, 0.20956225564830866, 0.15187885712245497, 0.15187885712245497, 0.15187885712245497, 0.1884438209632735, 0.1884438209632735, 0.1884438209632735, 0.18092815435556575, 0.18092815435556575, 0.18092815435556575, 0.19128512249819307, 0.19128512249819307, 0.19128512249819307, 0.10496923951524872, 0.10496923951524872, 0.10496923951524872, 0.1020169549279748, 0.1020169549279748, 0.1020169549279748, 0.10565486104717525, 0.10565486104717525, 0.10565486104717525]}, "mutation_prompt": null}
{"id": "38fdd2c3-6c73-4fdf-9f90-deebdebe8891", "solution": "import numpy as np\n\nclass PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n\n    def __call__(self, func):\n        np.random.seed(42)\n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            # Update personal and global bests\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            # Apply Differential Evolution mutation and crossover\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "PSO_ADE_Optimizer", "description": "Hybrid Particle Swarm Optimization with Adaptive Differential Evolution (PSO-ADE) combines swarm intelligence and mutation strategies to balance exploration and exploitation for efficient search.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "00016c82-8530-49ce-a4cd-d0ff638928f2", "metadata": {"aucs": [0.6921163136188262, 0.6921163136188262, 0.6921163136188262, 0.6141005361866843, 0.6141005361866843, 0.6141005361866843, 0.7101297430937754, 0.7101297430937754, 0.7101297430937754, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.21222809629046424, 0.21222809629046424, 0.21222809629046424, 0.01400111651648206, 0.01400111651648206, 0.01400111651648206, 0.09027192408854134, 0.09027192408854134, 0.09027192408854134, 0.10932415872791823, 0.10932415872791823, 0.10932415872791823, 0.1341235138283826, 0.1341235138283826, 0.1341235138283826, 0.15874693251912908, 0.15874693251912908, 0.15874693251912908, 0.11845369966779984, 0.11845369966779984, 0.11845369966779984, 0.12624330260423633, 0.12624330260423633, 0.12624330260423633, 0.9750192773622189, 0.9750192773622189, 0.9750192773622189, 0.9773408907457926, 0.9773408907457926, 0.9773408907457926, 0.9764359866445449, 0.9764359866445449, 0.9764359866445449, 0.49813541922359117, 0.49813541922359117, 0.49813541922359117, 0.5066436259615181, 0.5066436259615181, 0.5066436259615181, 0.5325410217912183, 0.5325410217912183, 0.5325410217912183, 0.2180536001945066, 0.2180536001945066, 0.2180536001945066, 0.15955365086274287, 0.15955365086274287, 0.15955365086274287, 0.11669974135986194, 0.11669974135986194, 0.11669974135986194, 0.3192301653471675, 0.3192301653471675, 0.3192301653471675, 0.12047545887350408, 0.12047545887350408, 0.12047545887350408, 0.4895410527183002, 0.4895410527183002, 0.4895410527183002, 0.30983467690359756, 0.30983467690359756, 0.30983467690359756, 0.25981713931026273, 0.25981713931026273, 0.25981713931026273, 0.116775284106304, 0.116775284106304, 0.116775284106304, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11234287978186497, 0.11234287978186497, 0.11234287978186497, 0.20217911017436585, 0.20217911017436585, 0.20217911017436585, 0.26951560053030943, 0.26951560053030943, 0.26951560053030943, 0.06589815951641032, 0.06589815951641032, 0.06589815951641032, 0.19585390761318644, 0.19585390761318644, 0.19585390761318644, 0.130776515274856, 0.130776515274856, 0.130776515274856, 0.056201113150505466, 0.056201113150505466, 0.056201113150505466, 0.08474039760497687, 0.08474039760497687, 0.08474039760497687, 0.1781186427308512, 0.1781186427308512, 0.1781186427308512, 0.1651035243859651, 0.1651035243859651, 0.1651035243859651, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5306071272671027, 0.5306071272671027, 0.5306071272671027, 0.5620155147396554, 0.5620155147396554, 0.5620155147396554, 0.5674957634774221, 0.5674957634774221, 0.5674957634774221, 0.09816506173836403, 0.09816506173836403, 0.09816506173836403, 0.10662575479143965, 0.10662575479143965, 0.10662575479143965, 0.11915990157649015, 0.11915990157649015, 0.11915990157649015, 0.2480725761801056, 0.2480725761801056, 0.2480725761801056, 0.20508588272961292, 0.20508588272961292, 0.20508588272961292, 0.20186295703757473, 0.20186295703757473, 0.20186295703757473, 0.39052066099920646, 0.39052066099920646, 0.39052066099920646, 0.21340139604270136, 0.21340139604270136, 0.21340139604270136, 0.33556046609964074, 0.33556046609964074, 0.33556046609964074, 0.3079800110267952, 0.3079800110267952, 0.3079800110267952, 0.22988328261885183, 0.22988328261885183, 0.22988328261885183, 0.13934663440847161, 0.13934663440847161, 0.13934663440847161, 0.2392358162520697, 0.2392358162520697, 0.2392358162520697, 0.2353611695482163, 0.2353611695482163, 0.2353611695482163, 0.21329124322443893, 0.21329124322443893, 0.21329124322443893, 0.17623575589755058, 0.17623575589755058, 0.17623575589755058, 0.18472806386394913, 0.18472806386394913, 0.18472806386394913, 0.2332795332206743, 0.2332795332206743, 0.2332795332206743, 0.8412688632559204, 0.8412688632559204, 0.8412688632559204, 0.15738560452270445, 0.15738560452270445, 0.15738560452270445, 0.1691347649539564, 0.1691347649539564, 0.1691347649539564, 0.20971674883211822, 0.20971674883211822, 0.20971674883211822, 0.20956225564830866, 0.20956225564830866, 0.20956225564830866, 0.15187885712245497, 0.15187885712245497, 0.15187885712245497, 0.1884438209632735, 0.1884438209632735, 0.1884438209632735, 0.18092815435556575, 0.18092815435556575, 0.18092815435556575, 0.19128512249819307, 0.19128512249819307, 0.19128512249819307, 0.10496923951524872, 0.10496923951524872, 0.10496923951524872, 0.1020169549279748, 0.1020169549279748, 0.1020169549279748, 0.10565486104717525, 0.10565486104717525, 0.10565486104717525]}, "mutation_prompt": null}
{"id": "b926a687-cdbe-4b3e-8e44-b034f0f5053f", "solution": "import numpy as np\n\nclass PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n\n    def __call__(self, func):\n        np.random.seed(42)\n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            # Update personal and global bests\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            # Apply Differential Evolution mutation and crossover\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "PSO_ADE_Optimizer", "description": "Hybrid Particle Swarm Optimization with Adaptive Differential Evolution (PSO-ADE) combines swarm intelligence and mutation strategies to balance exploration and exploitation for efficient search.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "00016c82-8530-49ce-a4cd-d0ff638928f2", "metadata": {"aucs": [0.6921163136188262, 0.6921163136188262, 0.6921163136188262, 0.6141005361866843, 0.6141005361866843, 0.6141005361866843, 0.7101297430937754, 0.7101297430937754, 0.7101297430937754, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.21222809629046424, 0.21222809629046424, 0.21222809629046424, 0.01400111651648206, 0.01400111651648206, 0.01400111651648206, 0.09027192408854134, 0.09027192408854134, 0.09027192408854134, 0.10932415872791823, 0.10932415872791823, 0.10932415872791823, 0.1341235138283826, 0.1341235138283826, 0.1341235138283826, 0.15874693251912908, 0.15874693251912908, 0.15874693251912908, 0.11845369966779984, 0.11845369966779984, 0.11845369966779984, 0.12624330260423633, 0.12624330260423633, 0.12624330260423633, 0.9750192773622189, 0.9750192773622189, 0.9750192773622189, 0.9773408907457926, 0.9773408907457926, 0.9773408907457926, 0.9764359866445449, 0.9764359866445449, 0.9764359866445449, 0.49813541922359117, 0.49813541922359117, 0.49813541922359117, 0.5066436259615181, 0.5066436259615181, 0.5066436259615181, 0.5325410217912183, 0.5325410217912183, 0.5325410217912183, 0.2180536001945066, 0.2180536001945066, 0.2180536001945066, 0.15955365086274287, 0.15955365086274287, 0.15955365086274287, 0.11669974135986194, 0.11669974135986194, 0.11669974135986194, 0.3192301653471675, 0.3192301653471675, 0.3192301653471675, 0.12047545887350408, 0.12047545887350408, 0.12047545887350408, 0.4895410527183002, 0.4895410527183002, 0.4895410527183002, 0.30983467690359756, 0.30983467690359756, 0.30983467690359756, 0.25981713931026273, 0.25981713931026273, 0.25981713931026273, 0.116775284106304, 0.116775284106304, 0.116775284106304, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11234287978186497, 0.11234287978186497, 0.11234287978186497, 0.20217911017436585, 0.20217911017436585, 0.20217911017436585, 0.26951560053030943, 0.26951560053030943, 0.26951560053030943, 0.06589815951641032, 0.06589815951641032, 0.06589815951641032, 0.19585390761318644, 0.19585390761318644, 0.19585390761318644, 0.130776515274856, 0.130776515274856, 0.130776515274856, 0.056201113150505466, 0.056201113150505466, 0.056201113150505466, 0.08474039760497687, 0.08474039760497687, 0.08474039760497687, 0.1781186427308512, 0.1781186427308512, 0.1781186427308512, 0.1651035243859651, 0.1651035243859651, 0.1651035243859651, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5306071272671027, 0.5306071272671027, 0.5306071272671027, 0.5620155147396554, 0.5620155147396554, 0.5620155147396554, 0.5674957634774221, 0.5674957634774221, 0.5674957634774221, 0.09816506173836403, 0.09816506173836403, 0.09816506173836403, 0.10662575479143965, 0.10662575479143965, 0.10662575479143965, 0.11915990157649015, 0.11915990157649015, 0.11915990157649015, 0.2480725761801056, 0.2480725761801056, 0.2480725761801056, 0.20508588272961292, 0.20508588272961292, 0.20508588272961292, 0.20186295703757473, 0.20186295703757473, 0.20186295703757473, 0.39052066099920646, 0.39052066099920646, 0.39052066099920646, 0.21340139604270136, 0.21340139604270136, 0.21340139604270136, 0.33556046609964074, 0.33556046609964074, 0.33556046609964074, 0.3079800110267952, 0.3079800110267952, 0.3079800110267952, 0.22988328261885183, 0.22988328261885183, 0.22988328261885183, 0.13934663440847161, 0.13934663440847161, 0.13934663440847161, 0.2392358162520697, 0.2392358162520697, 0.2392358162520697, 0.2353611695482163, 0.2353611695482163, 0.2353611695482163, 0.21329124322443893, 0.21329124322443893, 0.21329124322443893, 0.17623575589755058, 0.17623575589755058, 0.17623575589755058, 0.18472806386394913, 0.18472806386394913, 0.18472806386394913, 0.2332795332206743, 0.2332795332206743, 0.2332795332206743, 0.8412688632559204, 0.8412688632559204, 0.8412688632559204, 0.15738560452270445, 0.15738560452270445, 0.15738560452270445, 0.1691347649539564, 0.1691347649539564, 0.1691347649539564, 0.20971674883211822, 0.20971674883211822, 0.20971674883211822, 0.20956225564830866, 0.20956225564830866, 0.20956225564830866, 0.15187885712245497, 0.15187885712245497, 0.15187885712245497, 0.1884438209632735, 0.1884438209632735, 0.1884438209632735, 0.18092815435556575, 0.18092815435556575, 0.18092815435556575, 0.19128512249819307, 0.19128512249819307, 0.19128512249819307, 0.10496923951524872, 0.10496923951524872, 0.10496923951524872, 0.1020169549279748, 0.1020169549279748, 0.1020169549279748, 0.10565486104717525, 0.10565486104717525, 0.10565486104717525]}, "mutation_prompt": null}
{"id": "250fe2bc-f534-4d01-b49c-041f33cbdc87", "solution": "import numpy as np\n\nclass PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n\n    def __call__(self, func):\n        np.random.seed(42)\n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            # Update personal and global bests\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            # Apply Differential Evolution mutation and crossover\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "PSO_ADE_Optimizer", "description": "Hybrid Particle Swarm Optimization with Adaptive Differential Evolution (PSO-ADE) combines swarm intelligence and mutation strategies to balance exploration and exploitation for efficient search.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "00016c82-8530-49ce-a4cd-d0ff638928f2", "metadata": {"aucs": [0.6921163136188262, 0.6921163136188262, 0.6921163136188262, 0.6141005361866843, 0.6141005361866843, 0.6141005361866843, 0.7101297430937754, 0.7101297430937754, 0.7101297430937754, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.21222809629046424, 0.21222809629046424, 0.21222809629046424, 0.01400111651648206, 0.01400111651648206, 0.01400111651648206, 0.09027192408854134, 0.09027192408854134, 0.09027192408854134, 0.10932415872791823, 0.10932415872791823, 0.10932415872791823, 0.1341235138283826, 0.1341235138283826, 0.1341235138283826, 0.15874693251912908, 0.15874693251912908, 0.15874693251912908, 0.11845369966779984, 0.11845369966779984, 0.11845369966779984, 0.12624330260423633, 0.12624330260423633, 0.12624330260423633, 0.9750192773622189, 0.9750192773622189, 0.9750192773622189, 0.9773408907457926, 0.9773408907457926, 0.9773408907457926, 0.9764359866445449, 0.9764359866445449, 0.9764359866445449, 0.49813541922359117, 0.49813541922359117, 0.49813541922359117, 0.5066436259615181, 0.5066436259615181, 0.5066436259615181, 0.5325410217912183, 0.5325410217912183, 0.5325410217912183, 0.2180536001945066, 0.2180536001945066, 0.2180536001945066, 0.15955365086274287, 0.15955365086274287, 0.15955365086274287, 0.11669974135986194, 0.11669974135986194, 0.11669974135986194, 0.3192301653471675, 0.3192301653471675, 0.3192301653471675, 0.12047545887350408, 0.12047545887350408, 0.12047545887350408, 0.4895410527183002, 0.4895410527183002, 0.4895410527183002, 0.30983467690359756, 0.30983467690359756, 0.30983467690359756, 0.25981713931026273, 0.25981713931026273, 0.25981713931026273, 0.116775284106304, 0.116775284106304, 0.116775284106304, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11234287978186497, 0.11234287978186497, 0.11234287978186497, 0.20217911017436585, 0.20217911017436585, 0.20217911017436585, 0.26951560053030943, 0.26951560053030943, 0.26951560053030943, 0.06589815951641032, 0.06589815951641032, 0.06589815951641032, 0.19585390761318644, 0.19585390761318644, 0.19585390761318644, 0.130776515274856, 0.130776515274856, 0.130776515274856, 0.056201113150505466, 0.056201113150505466, 0.056201113150505466, 0.08474039760497687, 0.08474039760497687, 0.08474039760497687, 0.1781186427308512, 0.1781186427308512, 0.1781186427308512, 0.1651035243859651, 0.1651035243859651, 0.1651035243859651, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5306071272671027, 0.5306071272671027, 0.5306071272671027, 0.5620155147396554, 0.5620155147396554, 0.5620155147396554, 0.5674957634774221, 0.5674957634774221, 0.5674957634774221, 0.09816506173836403, 0.09816506173836403, 0.09816506173836403, 0.10662575479143965, 0.10662575479143965, 0.10662575479143965, 0.11915990157649015, 0.11915990157649015, 0.11915990157649015, 0.2480725761801056, 0.2480725761801056, 0.2480725761801056, 0.20508588272961292, 0.20508588272961292, 0.20508588272961292, 0.20186295703757473, 0.20186295703757473, 0.20186295703757473, 0.39052066099920646, 0.39052066099920646, 0.39052066099920646, 0.21340139604270136, 0.21340139604270136, 0.21340139604270136, 0.33556046609964074, 0.33556046609964074, 0.33556046609964074, 0.3079800110267952, 0.3079800110267952, 0.3079800110267952, 0.22988328261885183, 0.22988328261885183, 0.22988328261885183, 0.13934663440847161, 0.13934663440847161, 0.13934663440847161, 0.2392358162520697, 0.2392358162520697, 0.2392358162520697, 0.2353611695482163, 0.2353611695482163, 0.2353611695482163, 0.21329124322443893, 0.21329124322443893, 0.21329124322443893, 0.17623575589755058, 0.17623575589755058, 0.17623575589755058, 0.18472806386394913, 0.18472806386394913, 0.18472806386394913, 0.2332795332206743, 0.2332795332206743, 0.2332795332206743, 0.8412688632559204, 0.8412688632559204, 0.8412688632559204, 0.15738560452270445, 0.15738560452270445, 0.15738560452270445, 0.1691347649539564, 0.1691347649539564, 0.1691347649539564, 0.20971674883211822, 0.20971674883211822, 0.20971674883211822, 0.20956225564830866, 0.20956225564830866, 0.20956225564830866, 0.15187885712245497, 0.15187885712245497, 0.15187885712245497, 0.1884438209632735, 0.1884438209632735, 0.1884438209632735, 0.18092815435556575, 0.18092815435556575, 0.18092815435556575, 0.19128512249819307, 0.19128512249819307, 0.19128512249819307, 0.10496923951524872, 0.10496923951524872, 0.10496923951524872, 0.1020169549279748, 0.1020169549279748, 0.1020169549279748, 0.10565486104717525, 0.10565486104717525, 0.10565486104717525]}, "mutation_prompt": null}
{"id": "fc0791de-6a68-4f20-ab77-107b56a93999", "solution": "import numpy as np\n\nclass PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.85  # Slightly increased mutation factor\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.9  # Adaptive inertia weight\n        self.cognitive_coeff = 1.7  # Increased cognitive coefficient\n        self.social_coeff = 1.7  # Increased social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        inertia_decay = 0.99  # New inertia weight decay factor\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            r1, r2 = np.random.rand(2)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n            self.inertia_weight *= inertia_decay  # Apply inertia decay\n\n        return global_best_position, global_best_score", "name": "PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with dynamic parameters and adaptive inertia for improved convergence speed.", "configspace": "", "generation": 7, "fitness": 0.24372605110322992, "feedback": "The algorithm PSO_ADE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.22.", "error": "", "parent_id": "00016c82-8530-49ce-a4cd-d0ff638928f2", "metadata": {"aucs": [0.6431596860156981, 0.6431596860156981, 0.6431596860156981, 0.18090520262462428, 0.18090520262462428, 0.18090520262462428, 0.6490752527635342, 0.6490752527635342, 0.6490752527635342, 0.17791409293211913, 0.17791409293211913, 0.17791409293211913, 0.2063395524298388, 0.2063395524298388, 0.2063395524298388, 0.003457958636413072, 0.003457958636413072, 0.003457958636413072, 0.1705642542434871, 0.1705642542434871, 0.1705642542434871, 0.1052663586612731, 0.1052663586612731, 0.1052663586612731, 0.0942151312388112, 0.0942151312388112, 0.0942151312388112, 0.09204826430174307, 0.09204826430174307, 0.09204826430174307, 0.1112406980908478, 0.1112406980908478, 0.1112406980908478, 0.06204076567809769, 0.06204076567809769, 0.06204076567809769, 0.9837027805730018, 0.9837027805730018, 0.9837027805730018, 0.9836041481564826, 0.9836041481564826, 0.9836041481564826, 0.9823008527493156, 0.9823008527493156, 0.9823008527493156, 0.4046802572454383, 0.4046802572454383, 0.4046802572454383, 0.4519028260780831, 0.4519028260780831, 0.4519028260780831, 0.42870682747576094, 0.42870682747576094, 0.42870682747576094, 0.550007867095392, 0.550007867095392, 0.550007867095392, 0.16078874115546915, 0.16078874115546915, 0.16078874115546915, 0.11560553784078698, 0.11560553784078698, 0.11560553784078698, 0.23717271489123104, 0.23717271489123104, 0.23717271489123104, 0.31341913629976004, 0.31341913629976004, 0.31341913629976004, 0.17784890364032602, 0.17784890364032602, 0.17784890364032602, 0.17644744207466412, 0.17644744207466412, 0.17644744207466412, 0.32585746846519137, 0.32585746846519137, 0.32585746846519137, 0.3285747997207844, 0.3285747997207844, 0.3285747997207844, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.030049541371094723, 0.030049541371094723, 0.030049541371094723, 0.160391924678153, 0.160391924678153, 0.160391924678153, 0.18236424181095579, 0.18236424181095579, 0.18236424181095579, 0.17264372119882665, 0.17264372119882665, 0.17264372119882665, 0.12310049367266107, 0.12310049367266107, 0.12310049367266107, 0.040063525912357956, 0.040063525912357956, 0.040063525912357956, 0.0640793401530706, 0.0640793401530706, 0.0640793401530706, 0.05561103913833665, 0.05561103913833665, 0.05561103913833665, 0.18006829768053356, 0.18006829768053356, 0.18006829768053356, 0.12279433823491559, 0.12279433823491559, 0.12279433823491559, 0.06983125617730257, 0.06983125617730257, 0.06983125617730257, 0.5023553998637845, 0.5023553998637845, 0.5023553998637845, 0.18102408535214676, 0.18102408535214676, 0.18102408535214676, 0.48170588803119463, 0.48170588803119463, 0.48170588803119463, 0.1393332990560584, 0.1393332990560584, 0.1393332990560584, 0.10246116479113387, 0.10246116479113387, 0.10246116479113387, 0.12194082317517807, 0.12194082317517807, 0.12194082317517807, 0.182248282550853, 0.182248282550853, 0.182248282550853, 0.14940990623903583, 0.14940990623903583, 0.14940990623903583, 0.13327829496939214, 0.13327829496939214, 0.13327829496939214, 0.35420163264980953, 0.35420163264980953, 0.35420163264980953, 0.2860350025857492, 0.2860350025857492, 0.2860350025857492, 0.3591286136998547, 0.3591286136998547, 0.3591286136998547, 0.13379040445960022, 0.13379040445960022, 0.13379040445960022, 0.2076156396212281, 0.2076156396212281, 0.2076156396212281, 0.1524066619167057, 0.1524066619167057, 0.1524066619167057, 0.18679453801403134, 0.18679453801403134, 0.18679453801403134, 0.20841623849502766, 0.20841623849502766, 0.20841623849502766, 0.19235453542872494, 0.19235453542872494, 0.19235453542872494, 0.1890668618963025, 0.1890668618963025, 0.1890668618963025, 0.1916143568791291, 0.1916143568791291, 0.1916143568791291, 0.23975495231047272, 0.23975495231047272, 0.23975495231047272, 0.8313262563383624, 0.8313262563383624, 0.8313262563383624, 0.15599723195499715, 0.15599723195499715, 0.15599723195499715, 0.16857159467980876, 0.16857159467980876, 0.16857159467980876, 0.15241989055017324, 0.15241989055017324, 0.15241989055017324, 0.20750646251092064, 0.20750646251092064, 0.20750646251092064, 0.1551549376265413, 0.1551549376265413, 0.1551549376265413, 0.18595759561814562, 0.18595759561814562, 0.18595759561814562, 0.21489433908804945, 0.21489433908804945, 0.21489433908804945, 0.18069613914759142, 0.18069613914759142, 0.18069613914759142, 0.08550803420987363, 0.08550803420987363, 0.08550803420987363, 0.08568178803716742, 0.08568178803716742, 0.08568178803716742, 0.11167958657912802, 0.11167958657912802, 0.11167958657912802]}, "mutation_prompt": null}
{"id": "b6adbf12-9061-4478-aa31-518b2b0abc05", "solution": "import numpy as np\n\nclass PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n\n    def __call__(self, func):\n        np.random.seed(42)\n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            # Update personal and global bests\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            # Apply Differential Evolution mutation and crossover\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "PSO_ADE_Optimizer", "description": "Hybrid Particle Swarm Optimization with Adaptive Differential Evolution (PSO-ADE) combines swarm intelligence and mutation strategies to balance exploration and exploitation for efficient search.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "00016c82-8530-49ce-a4cd-d0ff638928f2", "metadata": {"aucs": [0.6921163136188262, 0.6921163136188262, 0.6921163136188262, 0.6141005361866843, 0.6141005361866843, 0.6141005361866843, 0.7101297430937754, 0.7101297430937754, 0.7101297430937754, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.21222809629046424, 0.21222809629046424, 0.21222809629046424, 0.01400111651648206, 0.01400111651648206, 0.01400111651648206, 0.09027192408854134, 0.09027192408854134, 0.09027192408854134, 0.10932415872791823, 0.10932415872791823, 0.10932415872791823, 0.1341235138283826, 0.1341235138283826, 0.1341235138283826, 0.15874693251912908, 0.15874693251912908, 0.15874693251912908, 0.11845369966779984, 0.11845369966779984, 0.11845369966779984, 0.12624330260423633, 0.12624330260423633, 0.12624330260423633, 0.9750192773622189, 0.9750192773622189, 0.9750192773622189, 0.9773408907457926, 0.9773408907457926, 0.9773408907457926, 0.9764359866445449, 0.9764359866445449, 0.9764359866445449, 0.49813541922359117, 0.49813541922359117, 0.49813541922359117, 0.5066436259615181, 0.5066436259615181, 0.5066436259615181, 0.5325410217912183, 0.5325410217912183, 0.5325410217912183, 0.2180536001945066, 0.2180536001945066, 0.2180536001945066, 0.15955365086274287, 0.15955365086274287, 0.15955365086274287, 0.11669974135986194, 0.11669974135986194, 0.11669974135986194, 0.3192301653471675, 0.3192301653471675, 0.3192301653471675, 0.12047545887350408, 0.12047545887350408, 0.12047545887350408, 0.4895410527183002, 0.4895410527183002, 0.4895410527183002, 0.30983467690359756, 0.30983467690359756, 0.30983467690359756, 0.25981713931026273, 0.25981713931026273, 0.25981713931026273, 0.116775284106304, 0.116775284106304, 0.116775284106304, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11234287978186497, 0.11234287978186497, 0.11234287978186497, 0.20217911017436585, 0.20217911017436585, 0.20217911017436585, 0.26951560053030943, 0.26951560053030943, 0.26951560053030943, 0.06589815951641032, 0.06589815951641032, 0.06589815951641032, 0.19585390761318644, 0.19585390761318644, 0.19585390761318644, 0.130776515274856, 0.130776515274856, 0.130776515274856, 0.056201113150505466, 0.056201113150505466, 0.056201113150505466, 0.08474039760497687, 0.08474039760497687, 0.08474039760497687, 0.1781186427308512, 0.1781186427308512, 0.1781186427308512, 0.1651035243859651, 0.1651035243859651, 0.1651035243859651, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5306071272671027, 0.5306071272671027, 0.5306071272671027, 0.5620155147396554, 0.5620155147396554, 0.5620155147396554, 0.5674957634774221, 0.5674957634774221, 0.5674957634774221, 0.09816506173836403, 0.09816506173836403, 0.09816506173836403, 0.10662575479143965, 0.10662575479143965, 0.10662575479143965, 0.11915990157649015, 0.11915990157649015, 0.11915990157649015, 0.2480725761801056, 0.2480725761801056, 0.2480725761801056, 0.20508588272961292, 0.20508588272961292, 0.20508588272961292, 0.20186295703757473, 0.20186295703757473, 0.20186295703757473, 0.39052066099920646, 0.39052066099920646, 0.39052066099920646, 0.21340139604270136, 0.21340139604270136, 0.21340139604270136, 0.33556046609964074, 0.33556046609964074, 0.33556046609964074, 0.3079800110267952, 0.3079800110267952, 0.3079800110267952, 0.22988328261885183, 0.22988328261885183, 0.22988328261885183, 0.13934663440847161, 0.13934663440847161, 0.13934663440847161, 0.2392358162520697, 0.2392358162520697, 0.2392358162520697, 0.2353611695482163, 0.2353611695482163, 0.2353611695482163, 0.21329124322443893, 0.21329124322443893, 0.21329124322443893, 0.17623575589755058, 0.17623575589755058, 0.17623575589755058, 0.18472806386394913, 0.18472806386394913, 0.18472806386394913, 0.2332795332206743, 0.2332795332206743, 0.2332795332206743, 0.8412688632559204, 0.8412688632559204, 0.8412688632559204, 0.15738560452270445, 0.15738560452270445, 0.15738560452270445, 0.1691347649539564, 0.1691347649539564, 0.1691347649539564, 0.20971674883211822, 0.20971674883211822, 0.20971674883211822, 0.20956225564830866, 0.20956225564830866, 0.20956225564830866, 0.15187885712245497, 0.15187885712245497, 0.15187885712245497, 0.1884438209632735, 0.1884438209632735, 0.1884438209632735, 0.18092815435556575, 0.18092815435556575, 0.18092815435556575, 0.19128512249819307, 0.19128512249819307, 0.19128512249819307, 0.10496923951524872, 0.10496923951524872, 0.10496923951524872, 0.1020169549279748, 0.1020169549279748, 0.1020169549279748, 0.10565486104717525, 0.10565486104717525, 0.10565486104717525]}, "mutation_prompt": null}
{"id": "de5f0c51-951f-40c4-a469-b9e591be69e3", "solution": "import numpy as np\n\nclass PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n\n    def __call__(self, func):\n        np.random.seed(42)\n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            # Update personal and global bests\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            # Apply Differential Evolution mutation and crossover\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "PSO_ADE_Optimizer", "description": "Hybrid Particle Swarm Optimization with Adaptive Differential Evolution (PSO-ADE) combines swarm intelligence and mutation strategies to balance exploration and exploitation for efficient search.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "00016c82-8530-49ce-a4cd-d0ff638928f2", "metadata": {"aucs": [0.6921163136188262, 0.6921163136188262, 0.6921163136188262, 0.6141005361866843, 0.6141005361866843, 0.6141005361866843, 0.7101297430937754, 0.7101297430937754, 0.7101297430937754, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.21222809629046424, 0.21222809629046424, 0.21222809629046424, 0.01400111651648206, 0.01400111651648206, 0.01400111651648206, 0.09027192408854134, 0.09027192408854134, 0.09027192408854134, 0.10932415872791823, 0.10932415872791823, 0.10932415872791823, 0.1341235138283826, 0.1341235138283826, 0.1341235138283826, 0.15874693251912908, 0.15874693251912908, 0.15874693251912908, 0.11845369966779984, 0.11845369966779984, 0.11845369966779984, 0.12624330260423633, 0.12624330260423633, 0.12624330260423633, 0.9750192773622189, 0.9750192773622189, 0.9750192773622189, 0.9773408907457926, 0.9773408907457926, 0.9773408907457926, 0.9764359866445449, 0.9764359866445449, 0.9764359866445449, 0.49813541922359117, 0.49813541922359117, 0.49813541922359117, 0.5066436259615181, 0.5066436259615181, 0.5066436259615181, 0.5325410217912183, 0.5325410217912183, 0.5325410217912183, 0.2180536001945066, 0.2180536001945066, 0.2180536001945066, 0.15955365086274287, 0.15955365086274287, 0.15955365086274287, 0.11669974135986194, 0.11669974135986194, 0.11669974135986194, 0.3192301653471675, 0.3192301653471675, 0.3192301653471675, 0.12047545887350408, 0.12047545887350408, 0.12047545887350408, 0.4895410527183002, 0.4895410527183002, 0.4895410527183002, 0.30983467690359756, 0.30983467690359756, 0.30983467690359756, 0.25981713931026273, 0.25981713931026273, 0.25981713931026273, 0.116775284106304, 0.116775284106304, 0.116775284106304, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11234287978186497, 0.11234287978186497, 0.11234287978186497, 0.20217911017436585, 0.20217911017436585, 0.20217911017436585, 0.26951560053030943, 0.26951560053030943, 0.26951560053030943, 0.06589815951641032, 0.06589815951641032, 0.06589815951641032, 0.19585390761318644, 0.19585390761318644, 0.19585390761318644, 0.130776515274856, 0.130776515274856, 0.130776515274856, 0.056201113150505466, 0.056201113150505466, 0.056201113150505466, 0.08474039760497687, 0.08474039760497687, 0.08474039760497687, 0.1781186427308512, 0.1781186427308512, 0.1781186427308512, 0.1651035243859651, 0.1651035243859651, 0.1651035243859651, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5306071272671027, 0.5306071272671027, 0.5306071272671027, 0.5620155147396554, 0.5620155147396554, 0.5620155147396554, 0.5674957634774221, 0.5674957634774221, 0.5674957634774221, 0.09816506173836403, 0.09816506173836403, 0.09816506173836403, 0.10662575479143965, 0.10662575479143965, 0.10662575479143965, 0.11915990157649015, 0.11915990157649015, 0.11915990157649015, 0.2480725761801056, 0.2480725761801056, 0.2480725761801056, 0.20508588272961292, 0.20508588272961292, 0.20508588272961292, 0.20186295703757473, 0.20186295703757473, 0.20186295703757473, 0.39052066099920646, 0.39052066099920646, 0.39052066099920646, 0.21340139604270136, 0.21340139604270136, 0.21340139604270136, 0.33556046609964074, 0.33556046609964074, 0.33556046609964074, 0.3079800110267952, 0.3079800110267952, 0.3079800110267952, 0.22988328261885183, 0.22988328261885183, 0.22988328261885183, 0.13934663440847161, 0.13934663440847161, 0.13934663440847161, 0.2392358162520697, 0.2392358162520697, 0.2392358162520697, 0.2353611695482163, 0.2353611695482163, 0.2353611695482163, 0.21329124322443893, 0.21329124322443893, 0.21329124322443893, 0.17623575589755058, 0.17623575589755058, 0.17623575589755058, 0.18472806386394913, 0.18472806386394913, 0.18472806386394913, 0.2332795332206743, 0.2332795332206743, 0.2332795332206743, 0.8412688632559204, 0.8412688632559204, 0.8412688632559204, 0.15738560452270445, 0.15738560452270445, 0.15738560452270445, 0.1691347649539564, 0.1691347649539564, 0.1691347649539564, 0.20971674883211822, 0.20971674883211822, 0.20971674883211822, 0.20956225564830866, 0.20956225564830866, 0.20956225564830866, 0.15187885712245497, 0.15187885712245497, 0.15187885712245497, 0.1884438209632735, 0.1884438209632735, 0.1884438209632735, 0.18092815435556575, 0.18092815435556575, 0.18092815435556575, 0.19128512249819307, 0.19128512249819307, 0.19128512249819307, 0.10496923951524872, 0.10496923951524872, 0.10496923951524872, 0.1020169549279748, 0.1020169549279748, 0.1020169549279748, 0.10565486104717525, 0.10565486104717525, 0.10565486104717525]}, "mutation_prompt": null}
{"id": "d636399c-b984-4291-b00e-c1caba276157", "solution": "import numpy as np\n\nclass PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n\n    def __call__(self, func):\n        np.random.seed(42)\n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            # Update personal and global bests\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            # Apply Differential Evolution mutation and crossover\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "PSO_ADE_Optimizer", "description": "Hybrid Particle Swarm Optimization with Adaptive Differential Evolution (PSO-ADE) combines swarm intelligence and mutation strategies to balance exploration and exploitation for efficient search.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "00016c82-8530-49ce-a4cd-d0ff638928f2", "metadata": {"aucs": [0.6921163136188262, 0.6921163136188262, 0.6921163136188262, 0.6141005361866843, 0.6141005361866843, 0.6141005361866843, 0.7101297430937754, 0.7101297430937754, 0.7101297430937754, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.21222809629046424, 0.21222809629046424, 0.21222809629046424, 0.01400111651648206, 0.01400111651648206, 0.01400111651648206, 0.09027192408854134, 0.09027192408854134, 0.09027192408854134, 0.10932415872791823, 0.10932415872791823, 0.10932415872791823, 0.1341235138283826, 0.1341235138283826, 0.1341235138283826, 0.15874693251912908, 0.15874693251912908, 0.15874693251912908, 0.11845369966779984, 0.11845369966779984, 0.11845369966779984, 0.12624330260423633, 0.12624330260423633, 0.12624330260423633, 0.9750192773622189, 0.9750192773622189, 0.9750192773622189, 0.9773408907457926, 0.9773408907457926, 0.9773408907457926, 0.9764359866445449, 0.9764359866445449, 0.9764359866445449, 0.49813541922359117, 0.49813541922359117, 0.49813541922359117, 0.5066436259615181, 0.5066436259615181, 0.5066436259615181, 0.5325410217912183, 0.5325410217912183, 0.5325410217912183, 0.2180536001945066, 0.2180536001945066, 0.2180536001945066, 0.15955365086274287, 0.15955365086274287, 0.15955365086274287, 0.11669974135986194, 0.11669974135986194, 0.11669974135986194, 0.3192301653471675, 0.3192301653471675, 0.3192301653471675, 0.12047545887350408, 0.12047545887350408, 0.12047545887350408, 0.4895410527183002, 0.4895410527183002, 0.4895410527183002, 0.30983467690359756, 0.30983467690359756, 0.30983467690359756, 0.25981713931026273, 0.25981713931026273, 0.25981713931026273, 0.116775284106304, 0.116775284106304, 0.116775284106304, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11234287978186497, 0.11234287978186497, 0.11234287978186497, 0.20217911017436585, 0.20217911017436585, 0.20217911017436585, 0.26951560053030943, 0.26951560053030943, 0.26951560053030943, 0.06589815951641032, 0.06589815951641032, 0.06589815951641032, 0.19585390761318644, 0.19585390761318644, 0.19585390761318644, 0.130776515274856, 0.130776515274856, 0.130776515274856, 0.056201113150505466, 0.056201113150505466, 0.056201113150505466, 0.08474039760497687, 0.08474039760497687, 0.08474039760497687, 0.1781186427308512, 0.1781186427308512, 0.1781186427308512, 0.1651035243859651, 0.1651035243859651, 0.1651035243859651, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5306071272671027, 0.5306071272671027, 0.5306071272671027, 0.5620155147396554, 0.5620155147396554, 0.5620155147396554, 0.5674957634774221, 0.5674957634774221, 0.5674957634774221, 0.09816506173836403, 0.09816506173836403, 0.09816506173836403, 0.10662575479143965, 0.10662575479143965, 0.10662575479143965, 0.11915990157649015, 0.11915990157649015, 0.11915990157649015, 0.2480725761801056, 0.2480725761801056, 0.2480725761801056, 0.20508588272961292, 0.20508588272961292, 0.20508588272961292, 0.20186295703757473, 0.20186295703757473, 0.20186295703757473, 0.39052066099920646, 0.39052066099920646, 0.39052066099920646, 0.21340139604270136, 0.21340139604270136, 0.21340139604270136, 0.33556046609964074, 0.33556046609964074, 0.33556046609964074, 0.3079800110267952, 0.3079800110267952, 0.3079800110267952, 0.22988328261885183, 0.22988328261885183, 0.22988328261885183, 0.13934663440847161, 0.13934663440847161, 0.13934663440847161, 0.2392358162520697, 0.2392358162520697, 0.2392358162520697, 0.2353611695482163, 0.2353611695482163, 0.2353611695482163, 0.21329124322443893, 0.21329124322443893, 0.21329124322443893, 0.17623575589755058, 0.17623575589755058, 0.17623575589755058, 0.18472806386394913, 0.18472806386394913, 0.18472806386394913, 0.2332795332206743, 0.2332795332206743, 0.2332795332206743, 0.8412688632559204, 0.8412688632559204, 0.8412688632559204, 0.15738560452270445, 0.15738560452270445, 0.15738560452270445, 0.1691347649539564, 0.1691347649539564, 0.1691347649539564, 0.20971674883211822, 0.20971674883211822, 0.20971674883211822, 0.20956225564830866, 0.20956225564830866, 0.20956225564830866, 0.15187885712245497, 0.15187885712245497, 0.15187885712245497, 0.1884438209632735, 0.1884438209632735, 0.1884438209632735, 0.18092815435556575, 0.18092815435556575, 0.18092815435556575, 0.19128512249819307, 0.19128512249819307, 0.19128512249819307, 0.10496923951524872, 0.10496923951524872, 0.10496923951524872, 0.1020169549279748, 0.1020169549279748, 0.1020169549279748, 0.10565486104717525, 0.10565486104717525, 0.10565486104717525]}, "mutation_prompt": null}
{"id": "fcba40e2-f6b0-4cdc-b6ee-3b1af5b2934f", "solution": "import numpy as np\n\nclass PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.85  # Slightly increased mutation factor\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n\n    def __call__(self, func):\n        np.random.seed(42)\n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            # Update personal and global bests\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            # Dynamically adjust inertia weight\n            self.inertia_weight = 0.4 + (0.5 * (self.budget - eval_count) / self.budget)\n            \n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            # Apply Differential Evolution mutation and crossover\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n                \n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "PSO_ADE_Optimizer", "description": "A refined version of PSO-ADE with dynamic inertia weight and enhanced mutation strategies for improved convergence speed.", "configspace": "", "generation": 11, "fitness": 0.23727244918473128, "feedback": "The algorithm PSO_ADE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.22.", "error": "", "parent_id": "00016c82-8530-49ce-a4cd-d0ff638928f2", "metadata": {"aucs": [0.6051673145379034, 0.6051673145379034, 0.6051673145379034, 0.6624211807672886, 0.6624211807672886, 0.6624211807672886, 0.6920207090053725, 0.6920207090053725, 0.6920207090053725, 0.19128004589974967, 0.19128004589974967, 0.19128004589974967, 0.03676543350276462, 0.03676543350276462, 0.03676543350276462, 0.007861927161099236, 0.007861927161099236, 0.007861927161099236, 0.10474335156594061, 0.10474335156594061, 0.10474335156594061, 0.12116768577685066, 0.12116768577685066, 0.12116768577685066, 0.0801680874435704, 0.0801680874435704, 0.0801680874435704, 0.09459929109962872, 0.09459929109962872, 0.09459929109962872, 0.10446520016241334, 0.10446520016241334, 0.10446520016241334, 0.10376057444841813, 0.10376057444841813, 0.10376057444841813, 0.977476328129393, 0.977476328129393, 0.977476328129393, 0.9836085507476244, 0.9836085507476244, 0.9836085507476244, 0.9767116166246341, 0.9767116166246341, 0.9767116166246341, 0.38659243749273686, 0.38659243749273686, 0.38659243749273686, 0.29988448002879264, 0.29988448002879264, 0.29988448002879264, 0.4543073852982661, 0.4543073852982661, 0.4543073852982661, 0.21659392817652368, 0.21659392817652368, 0.21659392817652368, 0.15945183339378566, 0.15945183339378566, 0.15945183339378566, 0.16180800819166397, 0.16180800819166397, 0.16180800819166397, 0.2150008857557758, 0.2150008857557758, 0.2150008857557758, 0.1700904625522075, 0.1700904625522075, 0.1700904625522075, 0.11025843597556118, 0.11025843597556118, 0.11025843597556118, 0.27926432897714093, 0.27926432897714093, 0.27926432897714093, 0.24569940064490425, 0.24569940064490425, 0.24569940064490425, 0.10797320051269421, 0.10797320051269421, 0.10797320051269421, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02702425165480049, 0.02702425165480049, 0.02702425165480049, 0.04612597166590626, 0.04612597166590626, 0.04612597166590626, 0.22604591630510873, 0.22604591630510873, 0.22604591630510873, 0.02772373960969976, 0.02772373960969976, 0.02772373960969976, 0.08169192642895362, 0.08169192642895362, 0.08169192642895362, 0.08864556035344162, 0.08864556035344162, 0.08864556035344162, 0.050883917991116356, 0.050883917991116356, 0.050883917991116356, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.16929404831739703, 0.16929404831739703, 0.16929404831739703, 0.11777390664384324, 0.11777390664384324, 0.11777390664384324, 0.06772990308476767, 0.06772990308476767, 0.06772990308476767, 0.5170489984726252, 0.5170489984726252, 0.5170489984726252, 0.46011809384322155, 0.46011809384322155, 0.46011809384322155, 0.46488154940189197, 0.46488154940189197, 0.46488154940189197, 0.10755411580655205, 0.10755411580655205, 0.10755411580655205, 0.0999480347879369, 0.0999480347879369, 0.0999480347879369, 0.09005214186058452, 0.09005214186058452, 0.09005214186058452, 0.19491196463918536, 0.19491196463918536, 0.19491196463918536, 0.2936814201918089, 0.2936814201918089, 0.2936814201918089, 0.13902506063860398, 0.13902506063860398, 0.13902506063860398, 0.32261232429292896, 0.32261232429292896, 0.32261232429292896, 0.3232796006407396, 0.3232796006407396, 0.3232796006407396, 0.31897842685573596, 0.31897842685573596, 0.31897842685573596, 0.18258714290036415, 0.18258714290036415, 0.18258714290036415, 0.19540117501391863, 0.19540117501391863, 0.19540117501391863, 0.15522605896000352, 0.15522605896000352, 0.15522605896000352, 0.23258845757936675, 0.23258845757936675, 0.23258845757936675, 0.21857257547860975, 0.21857257547860975, 0.21857257547860975, 0.208863766963316, 0.208863766963316, 0.208863766963316, 0.2010616009844025, 0.2010616009844025, 0.2010616009844025, 0.19179068692166779, 0.19179068692166779, 0.19179068692166779, 0.2028736864928965, 0.2028736864928965, 0.2028736864928965, 0.7559542081790201, 0.7559542081790201, 0.7559542081790201, 0.15482299458781856, 0.15482299458781856, 0.15482299458781856, 0.16854713623153206, 0.16854713623153206, 0.16854713623153206, 0.2021525707762154, 0.2021525707762154, 0.2021525707762154, 0.20749397740715347, 0.20749397740715347, 0.20749397740715347, 0.15866469672939054, 0.15866469672939054, 0.15866469672939054, 0.18639358506311499, 0.18639358506311499, 0.18639358506311499, 0.19213109034167508, 0.19213109034167508, 0.19213109034167508, 0.19442325410378225, 0.19442325410378225, 0.19442325410378225, 0.08352158927583353, 0.08352158927583353, 0.08352158927583353, 0.07939491534259357, 0.07939491534259357, 0.07939491534259357, 0.1267782146084232, 0.1267782146084232, 0.1267782146084232]}, "mutation_prompt": null}
{"id": "ab6c9276-2471-4b2d-9dbb-ba16db8154be", "solution": "import numpy as np\n\nclass PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n\n    def __call__(self, func):\n        np.random.seed(42)\n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            # Update personal and global bests\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            # Apply Differential Evolution mutation and crossover\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "PSO_ADE_Optimizer", "description": "Hybrid Particle Swarm Optimization with Adaptive Differential Evolution (PSO-ADE) combines swarm intelligence and mutation strategies to balance exploration and exploitation for efficient search.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "00016c82-8530-49ce-a4cd-d0ff638928f2", "metadata": {"aucs": [0.6921163136188262, 0.6921163136188262, 0.6921163136188262, 0.6141005361866843, 0.6141005361866843, 0.6141005361866843, 0.7101297430937754, 0.7101297430937754, 0.7101297430937754, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.21222809629046424, 0.21222809629046424, 0.21222809629046424, 0.01400111651648206, 0.01400111651648206, 0.01400111651648206, 0.09027192408854134, 0.09027192408854134, 0.09027192408854134, 0.10932415872791823, 0.10932415872791823, 0.10932415872791823, 0.1341235138283826, 0.1341235138283826, 0.1341235138283826, 0.15874693251912908, 0.15874693251912908, 0.15874693251912908, 0.11845369966779984, 0.11845369966779984, 0.11845369966779984, 0.12624330260423633, 0.12624330260423633, 0.12624330260423633, 0.9750192773622189, 0.9750192773622189, 0.9750192773622189, 0.9773408907457926, 0.9773408907457926, 0.9773408907457926, 0.9764359866445449, 0.9764359866445449, 0.9764359866445449, 0.49813541922359117, 0.49813541922359117, 0.49813541922359117, 0.5066436259615181, 0.5066436259615181, 0.5066436259615181, 0.5325410217912183, 0.5325410217912183, 0.5325410217912183, 0.2180536001945066, 0.2180536001945066, 0.2180536001945066, 0.15955365086274287, 0.15955365086274287, 0.15955365086274287, 0.11669974135986194, 0.11669974135986194, 0.11669974135986194, 0.3192301653471675, 0.3192301653471675, 0.3192301653471675, 0.12047545887350408, 0.12047545887350408, 0.12047545887350408, 0.4895410527183002, 0.4895410527183002, 0.4895410527183002, 0.30983467690359756, 0.30983467690359756, 0.30983467690359756, 0.25981713931026273, 0.25981713931026273, 0.25981713931026273, 0.116775284106304, 0.116775284106304, 0.116775284106304, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11234287978186497, 0.11234287978186497, 0.11234287978186497, 0.20217911017436585, 0.20217911017436585, 0.20217911017436585, 0.26951560053030943, 0.26951560053030943, 0.26951560053030943, 0.06589815951641032, 0.06589815951641032, 0.06589815951641032, 0.19585390761318644, 0.19585390761318644, 0.19585390761318644, 0.130776515274856, 0.130776515274856, 0.130776515274856, 0.056201113150505466, 0.056201113150505466, 0.056201113150505466, 0.08474039760497687, 0.08474039760497687, 0.08474039760497687, 0.1781186427308512, 0.1781186427308512, 0.1781186427308512, 0.1651035243859651, 0.1651035243859651, 0.1651035243859651, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5306071272671027, 0.5306071272671027, 0.5306071272671027, 0.5620155147396554, 0.5620155147396554, 0.5620155147396554, 0.5674957634774221, 0.5674957634774221, 0.5674957634774221, 0.09816506173836403, 0.09816506173836403, 0.09816506173836403, 0.10662575479143965, 0.10662575479143965, 0.10662575479143965, 0.11915990157649015, 0.11915990157649015, 0.11915990157649015, 0.2480725761801056, 0.2480725761801056, 0.2480725761801056, 0.20508588272961292, 0.20508588272961292, 0.20508588272961292, 0.20186295703757473, 0.20186295703757473, 0.20186295703757473, 0.39052066099920646, 0.39052066099920646, 0.39052066099920646, 0.21340139604270136, 0.21340139604270136, 0.21340139604270136, 0.33556046609964074, 0.33556046609964074, 0.33556046609964074, 0.3079800110267952, 0.3079800110267952, 0.3079800110267952, 0.22988328261885183, 0.22988328261885183, 0.22988328261885183, 0.13934663440847161, 0.13934663440847161, 0.13934663440847161, 0.2392358162520697, 0.2392358162520697, 0.2392358162520697, 0.2353611695482163, 0.2353611695482163, 0.2353611695482163, 0.21329124322443893, 0.21329124322443893, 0.21329124322443893, 0.17623575589755058, 0.17623575589755058, 0.17623575589755058, 0.18472806386394913, 0.18472806386394913, 0.18472806386394913, 0.2332795332206743, 0.2332795332206743, 0.2332795332206743, 0.8412688632559204, 0.8412688632559204, 0.8412688632559204, 0.15738560452270445, 0.15738560452270445, 0.15738560452270445, 0.1691347649539564, 0.1691347649539564, 0.1691347649539564, 0.20971674883211822, 0.20971674883211822, 0.20971674883211822, 0.20956225564830866, 0.20956225564830866, 0.20956225564830866, 0.15187885712245497, 0.15187885712245497, 0.15187885712245497, 0.1884438209632735, 0.1884438209632735, 0.1884438209632735, 0.18092815435556575, 0.18092815435556575, 0.18092815435556575, 0.19128512249819307, 0.19128512249819307, 0.19128512249819307, 0.10496923951524872, 0.10496923951524872, 0.10496923951524872, 0.1020169549279748, 0.1020169549279748, 0.1020169549279748, 0.10565486104717525, 0.10565486104717525, 0.10565486104717525]}, "mutation_prompt": null}
{"id": "9f60f2dc-d758-4509-83c8-59075f90be60", "solution": "import numpy as np\n\nclass PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n\n    def __call__(self, func):\n        np.random.seed(42)\n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            # Update personal and global bests\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            # Apply Differential Evolution mutation and crossover\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "PSO_ADE_Optimizer", "description": "Hybrid Particle Swarm Optimization with Adaptive Differential Evolution (PSO-ADE) combines swarm intelligence and mutation strategies to balance exploration and exploitation for efficient search.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "00016c82-8530-49ce-a4cd-d0ff638928f2", "metadata": {"aucs": [0.6921163136188262, 0.6921163136188262, 0.6921163136188262, 0.6141005361866843, 0.6141005361866843, 0.6141005361866843, 0.7101297430937754, 0.7101297430937754, 0.7101297430937754, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.21222809629046424, 0.21222809629046424, 0.21222809629046424, 0.01400111651648206, 0.01400111651648206, 0.01400111651648206, 0.09027192408854134, 0.09027192408854134, 0.09027192408854134, 0.10932415872791823, 0.10932415872791823, 0.10932415872791823, 0.1341235138283826, 0.1341235138283826, 0.1341235138283826, 0.15874693251912908, 0.15874693251912908, 0.15874693251912908, 0.11845369966779984, 0.11845369966779984, 0.11845369966779984, 0.12624330260423633, 0.12624330260423633, 0.12624330260423633, 0.9750192773622189, 0.9750192773622189, 0.9750192773622189, 0.9773408907457926, 0.9773408907457926, 0.9773408907457926, 0.9764359866445449, 0.9764359866445449, 0.9764359866445449, 0.49813541922359117, 0.49813541922359117, 0.49813541922359117, 0.5066436259615181, 0.5066436259615181, 0.5066436259615181, 0.5325410217912183, 0.5325410217912183, 0.5325410217912183, 0.2180536001945066, 0.2180536001945066, 0.2180536001945066, 0.15955365086274287, 0.15955365086274287, 0.15955365086274287, 0.11669974135986194, 0.11669974135986194, 0.11669974135986194, 0.3192301653471675, 0.3192301653471675, 0.3192301653471675, 0.12047545887350408, 0.12047545887350408, 0.12047545887350408, 0.4895410527183002, 0.4895410527183002, 0.4895410527183002, 0.30983467690359756, 0.30983467690359756, 0.30983467690359756, 0.25981713931026273, 0.25981713931026273, 0.25981713931026273, 0.116775284106304, 0.116775284106304, 0.116775284106304, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11234287978186497, 0.11234287978186497, 0.11234287978186497, 0.20217911017436585, 0.20217911017436585, 0.20217911017436585, 0.26951560053030943, 0.26951560053030943, 0.26951560053030943, 0.06589815951641032, 0.06589815951641032, 0.06589815951641032, 0.19585390761318644, 0.19585390761318644, 0.19585390761318644, 0.130776515274856, 0.130776515274856, 0.130776515274856, 0.056201113150505466, 0.056201113150505466, 0.056201113150505466, 0.08474039760497687, 0.08474039760497687, 0.08474039760497687, 0.1781186427308512, 0.1781186427308512, 0.1781186427308512, 0.1651035243859651, 0.1651035243859651, 0.1651035243859651, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5306071272671027, 0.5306071272671027, 0.5306071272671027, 0.5620155147396554, 0.5620155147396554, 0.5620155147396554, 0.5674957634774221, 0.5674957634774221, 0.5674957634774221, 0.09816506173836403, 0.09816506173836403, 0.09816506173836403, 0.10662575479143965, 0.10662575479143965, 0.10662575479143965, 0.11915990157649015, 0.11915990157649015, 0.11915990157649015, 0.2480725761801056, 0.2480725761801056, 0.2480725761801056, 0.20508588272961292, 0.20508588272961292, 0.20508588272961292, 0.20186295703757473, 0.20186295703757473, 0.20186295703757473, 0.39052066099920646, 0.39052066099920646, 0.39052066099920646, 0.21340139604270136, 0.21340139604270136, 0.21340139604270136, 0.33556046609964074, 0.33556046609964074, 0.33556046609964074, 0.3079800110267952, 0.3079800110267952, 0.3079800110267952, 0.22988328261885183, 0.22988328261885183, 0.22988328261885183, 0.13934663440847161, 0.13934663440847161, 0.13934663440847161, 0.2392358162520697, 0.2392358162520697, 0.2392358162520697, 0.2353611695482163, 0.2353611695482163, 0.2353611695482163, 0.21329124322443893, 0.21329124322443893, 0.21329124322443893, 0.17623575589755058, 0.17623575589755058, 0.17623575589755058, 0.18472806386394913, 0.18472806386394913, 0.18472806386394913, 0.2332795332206743, 0.2332795332206743, 0.2332795332206743, 0.8412688632559204, 0.8412688632559204, 0.8412688632559204, 0.15738560452270445, 0.15738560452270445, 0.15738560452270445, 0.1691347649539564, 0.1691347649539564, 0.1691347649539564, 0.20971674883211822, 0.20971674883211822, 0.20971674883211822, 0.20956225564830866, 0.20956225564830866, 0.20956225564830866, 0.15187885712245497, 0.15187885712245497, 0.15187885712245497, 0.1884438209632735, 0.1884438209632735, 0.1884438209632735, 0.18092815435556575, 0.18092815435556575, 0.18092815435556575, 0.19128512249819307, 0.19128512249819307, 0.19128512249819307, 0.10496923951524872, 0.10496923951524872, 0.10496923951524872, 0.1020169549279748, 0.1020169549279748, 0.1020169549279748, 0.10565486104717525, 0.10565486104717525, 0.10565486104717525]}, "mutation_prompt": null}
{"id": "e19cd5d0-ed6f-4bbf-97a4-2ae8ad7d441d", "solution": "import numpy as np\n\nclass PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.8\n        self.inertia_weight_init = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            current_inertia = (((self.budget - eval_count) / self.budget) *\n                               (self.inertia_weight_init - self.inertia_weight_final) +\n                               self.inertia_weight_final)\n            \n            r1, r2 = np.random.rand(2)\n            velocities = (\n                current_inertia * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                adaptive_crossover_prob = self.crossover_prob + ((1 - self.crossover_prob) * (scores[i] - min(scores)) / (max(scores) - min(scores) + 1e-8))\n                trial_vector = np.where(np.random.rand(self.dim) < adaptive_crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "PSO_ADE_Optimizer", "description": "Enhanced Hybrid PSO with Dynamic Inertia and Adaptive Crossover for improved convergence speed and exploration-exploitation balance.", "configspace": "", "generation": 14, "fitness": 0.21646836579755444, "feedback": "The algorithm PSO_ADE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.21.", "error": "", "parent_id": "00016c82-8530-49ce-a4cd-d0ff638928f2", "metadata": {"aucs": [0.5904849015808447, 0.5904849015808447, 0.5904849015808447, 0.18193679996241996, 0.18193679996241996, 0.18193679996241996, 0.5797480516139536, 0.5797480516139536, 0.5797480516139536, 0.02514993493330675, 0.02514993493330675, 0.02514993493330675, 0.1650007368652079, 0.1650007368652079, 0.1650007368652079, 0.08986384742327647, 0.08986384742327647, 0.08986384742327647, 0.10086444112857129, 0.10086444112857129, 0.10086444112857129, 0.1051036953613469, 0.1051036953613469, 0.1051036953613469, 0.1018966844743947, 0.1018966844743947, 0.1018966844743947, 0.09257303285889906, 0.09257303285889906, 0.09257303285889906, 0.042063664871196615, 0.042063664871196615, 0.042063664871196615, 0.07720420025910246, 0.07720420025910246, 0.07720420025910246, 0.9853368867158439, 0.9853368867158439, 0.9853368867158439, 0.9835977308712218, 0.9835977308712218, 0.9835977308712218, 0.9823530623704123, 0.9823530623704123, 0.9823530623704123, 0.3286084447206714, 0.3286084447206714, 0.3286084447206714, 0.14802152072727515, 0.14802152072727515, 0.14802152072727515, 0.3802156409680305, 0.3802156409680305, 0.3802156409680305, 0.26686100079407393, 0.26686100079407393, 0.26686100079407393, 0.160581191192396, 0.160581191192396, 0.160581191192396, 0.11454403428670756, 0.11454403428670756, 0.11454403428670756, 0.18852111141894434, 0.18852111141894434, 0.18852111141894434, 0.12051202565773944, 0.12051202565773944, 0.12051202565773944, 0.1687975381805218, 0.1687975381805218, 0.1687975381805218, 0.16961470279841784, 0.16961470279841784, 0.16961470279841784, 0.2859397086139235, 0.2859397086139235, 0.2859397086139235, 0.1722133392026708, 0.1722133392026708, 0.1722133392026708, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04058606412777244, 0.04058606412777244, 0.04058606412777244, 0.07669834575385215, 0.07669834575385215, 0.07669834575385215, 0.10829913847255279, 0.10829913847255279, 0.10829913847255279, 0.006480424625566639, 0.006480424625566639, 0.006480424625566639, 0.12634135308136496, 0.12634135308136496, 0.12634135308136496, 0.058711239655189984, 0.058711239655189984, 0.058711239655189984, 0.03981603620719054, 0.03981603620719054, 0.03981603620719054, 0.050882819493531684, 0.050882819493531684, 0.050882819493531684, 0.145732879819077, 0.145732879819077, 0.145732879819077, 0.17221316976411982, 0.17221316976411982, 0.17221316976411982, 0.0635904498367692, 0.0635904498367692, 0.0635904498367692, 0.4705073491937273, 0.4705073491937273, 0.4705073491937273, 0.1676632511980748, 0.1676632511980748, 0.1676632511980748, 0.4317491041152185, 0.4317491041152185, 0.4317491041152185, 0.10832126976159684, 0.10832126976159684, 0.10832126976159684, 0.1043128920122226, 0.1043128920122226, 0.1043128920122226, 0.12216773454361318, 0.12216773454361318, 0.12216773454361318, 0.281411995216463, 0.281411995216463, 0.281411995216463, 0.16752809602306784, 0.16752809602306784, 0.16752809602306784, 0.13350233272057888, 0.13350233272057888, 0.13350233272057888, 0.34017130081939584, 0.34017130081939584, 0.34017130081939584, 0.3276987414691104, 0.3276987414691104, 0.3276987414691104, 0.3130017037593563, 0.3130017037593563, 0.3130017037593563, 0.12612960592727918, 0.12612960592727918, 0.12612960592727918, 0.20862889236487692, 0.20862889236487692, 0.20862889236487692, 0.15433528162749555, 0.15433528162749555, 0.15433528162749555, 0.21025399961534363, 0.21025399961534363, 0.21025399961534363, 0.20384382041150462, 0.20384382041150462, 0.20384382041150462, 0.21624321920594747, 0.21624321920594747, 0.21624321920594747, 0.19426986848707384, 0.19426986848707384, 0.19426986848707384, 0.18035353518932684, 0.18035353518932684, 0.18035353518932684, 0.22400639879770134, 0.22400639879770134, 0.22400639879770134, 0.782763297241315, 0.782763297241315, 0.782763297241315, 0.1553354562736291, 0.1553354562736291, 0.1553354562736291, 0.16841676555823248, 0.16841676555823248, 0.16841676555823248, 0.11195132905714433, 0.11195132905714433, 0.11195132905714433, 0.20647034293493838, 0.20647034293493838, 0.20647034293493838, 0.1526511053050581, 0.1526511053050581, 0.1526511053050581, 0.1858054422690122, 0.1858054422690122, 0.1858054422690122, 0.1893296495703891, 0.1893296495703891, 0.1893296495703891, 0.17328260708292653, 0.17328260708292653, 0.17328260708292653, 0.09710754629509233, 0.09710754629509233, 0.09710754629509233, 0.07277270158049087, 0.07277270158049087, 0.07277270158049087, 0.10667585110835665, 0.10667585110835665, 0.10667585110835665]}, "mutation_prompt": null}
{"id": "3108c600-01df-40b8-a114-cdd5c7042e7d", "solution": "import numpy as np\n\nclass PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n\n    def __call__(self, func):\n        np.random.seed(42)\n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            # Update personal and global bests\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            # Apply Differential Evolution mutation and crossover\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "PSO_ADE_Optimizer", "description": "Hybrid Particle Swarm Optimization with Adaptive Differential Evolution (PSO-ADE) combines swarm intelligence and mutation strategies to balance exploration and exploitation for efficient search.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "00016c82-8530-49ce-a4cd-d0ff638928f2", "metadata": {"aucs": [0.6921163136188262, 0.6921163136188262, 0.6921163136188262, 0.6141005361866843, 0.6141005361866843, 0.6141005361866843, 0.7101297430937754, 0.7101297430937754, 0.7101297430937754, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.21222809629046424, 0.21222809629046424, 0.21222809629046424, 0.01400111651648206, 0.01400111651648206, 0.01400111651648206, 0.09027192408854134, 0.09027192408854134, 0.09027192408854134, 0.10932415872791823, 0.10932415872791823, 0.10932415872791823, 0.1341235138283826, 0.1341235138283826, 0.1341235138283826, 0.15874693251912908, 0.15874693251912908, 0.15874693251912908, 0.11845369966779984, 0.11845369966779984, 0.11845369966779984, 0.12624330260423633, 0.12624330260423633, 0.12624330260423633, 0.9750192773622189, 0.9750192773622189, 0.9750192773622189, 0.9773408907457926, 0.9773408907457926, 0.9773408907457926, 0.9764359866445449, 0.9764359866445449, 0.9764359866445449, 0.49813541922359117, 0.49813541922359117, 0.49813541922359117, 0.5066436259615181, 0.5066436259615181, 0.5066436259615181, 0.5325410217912183, 0.5325410217912183, 0.5325410217912183, 0.2180536001945066, 0.2180536001945066, 0.2180536001945066, 0.15955365086274287, 0.15955365086274287, 0.15955365086274287, 0.11669974135986194, 0.11669974135986194, 0.11669974135986194, 0.3192301653471675, 0.3192301653471675, 0.3192301653471675, 0.12047545887350408, 0.12047545887350408, 0.12047545887350408, 0.4895410527183002, 0.4895410527183002, 0.4895410527183002, 0.30983467690359756, 0.30983467690359756, 0.30983467690359756, 0.25981713931026273, 0.25981713931026273, 0.25981713931026273, 0.116775284106304, 0.116775284106304, 0.116775284106304, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11234287978186497, 0.11234287978186497, 0.11234287978186497, 0.20217911017436585, 0.20217911017436585, 0.20217911017436585, 0.26951560053030943, 0.26951560053030943, 0.26951560053030943, 0.06589815951641032, 0.06589815951641032, 0.06589815951641032, 0.19585390761318644, 0.19585390761318644, 0.19585390761318644, 0.130776515274856, 0.130776515274856, 0.130776515274856, 0.056201113150505466, 0.056201113150505466, 0.056201113150505466, 0.08474039760497687, 0.08474039760497687, 0.08474039760497687, 0.1781186427308512, 0.1781186427308512, 0.1781186427308512, 0.1651035243859651, 0.1651035243859651, 0.1651035243859651, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5306071272671027, 0.5306071272671027, 0.5306071272671027, 0.5620155147396554, 0.5620155147396554, 0.5620155147396554, 0.5674957634774221, 0.5674957634774221, 0.5674957634774221, 0.09816506173836403, 0.09816506173836403, 0.09816506173836403, 0.10662575479143965, 0.10662575479143965, 0.10662575479143965, 0.11915990157649015, 0.11915990157649015, 0.11915990157649015, 0.2480725761801056, 0.2480725761801056, 0.2480725761801056, 0.20508588272961292, 0.20508588272961292, 0.20508588272961292, 0.20186295703757473, 0.20186295703757473, 0.20186295703757473, 0.39052066099920646, 0.39052066099920646, 0.39052066099920646, 0.21340139604270136, 0.21340139604270136, 0.21340139604270136, 0.33556046609964074, 0.33556046609964074, 0.33556046609964074, 0.3079800110267952, 0.3079800110267952, 0.3079800110267952, 0.22988328261885183, 0.22988328261885183, 0.22988328261885183, 0.13934663440847161, 0.13934663440847161, 0.13934663440847161, 0.2392358162520697, 0.2392358162520697, 0.2392358162520697, 0.2353611695482163, 0.2353611695482163, 0.2353611695482163, 0.21329124322443893, 0.21329124322443893, 0.21329124322443893, 0.17623575589755058, 0.17623575589755058, 0.17623575589755058, 0.18472806386394913, 0.18472806386394913, 0.18472806386394913, 0.2332795332206743, 0.2332795332206743, 0.2332795332206743, 0.8412688632559204, 0.8412688632559204, 0.8412688632559204, 0.15738560452270445, 0.15738560452270445, 0.15738560452270445, 0.1691347649539564, 0.1691347649539564, 0.1691347649539564, 0.20971674883211822, 0.20971674883211822, 0.20971674883211822, 0.20956225564830866, 0.20956225564830866, 0.20956225564830866, 0.15187885712245497, 0.15187885712245497, 0.15187885712245497, 0.1884438209632735, 0.1884438209632735, 0.1884438209632735, 0.18092815435556575, 0.18092815435556575, 0.18092815435556575, 0.19128512249819307, 0.19128512249819307, 0.19128512249819307, 0.10496923951524872, 0.10496923951524872, 0.10496923951524872, 0.1020169549279748, 0.1020169549279748, 0.1020169549279748, 0.10565486104717525, 0.10565486104717525, 0.10565486104717525]}, "mutation_prompt": null}
{"id": "9330c253-32c9-46ec-9346-2f074675936e", "solution": "import numpy as np\n\nclass PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n\n    def __call__(self, func):\n        np.random.seed(42)\n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            # Update personal and global bests\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            # Apply Differential Evolution mutation and crossover\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "PSO_ADE_Optimizer", "description": "Hybrid Particle Swarm Optimization with Adaptive Differential Evolution (PSO-ADE) combines swarm intelligence and mutation strategies to balance exploration and exploitation for efficient search.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "00016c82-8530-49ce-a4cd-d0ff638928f2", "metadata": {"aucs": [0.6921163136188262, 0.6921163136188262, 0.6921163136188262, 0.6141005361866843, 0.6141005361866843, 0.6141005361866843, 0.7101297430937754, 0.7101297430937754, 0.7101297430937754, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.21222809629046424, 0.21222809629046424, 0.21222809629046424, 0.01400111651648206, 0.01400111651648206, 0.01400111651648206, 0.09027192408854134, 0.09027192408854134, 0.09027192408854134, 0.10932415872791823, 0.10932415872791823, 0.10932415872791823, 0.1341235138283826, 0.1341235138283826, 0.1341235138283826, 0.15874693251912908, 0.15874693251912908, 0.15874693251912908, 0.11845369966779984, 0.11845369966779984, 0.11845369966779984, 0.12624330260423633, 0.12624330260423633, 0.12624330260423633, 0.9750192773622189, 0.9750192773622189, 0.9750192773622189, 0.9773408907457926, 0.9773408907457926, 0.9773408907457926, 0.9764359866445449, 0.9764359866445449, 0.9764359866445449, 0.49813541922359117, 0.49813541922359117, 0.49813541922359117, 0.5066436259615181, 0.5066436259615181, 0.5066436259615181, 0.5325410217912183, 0.5325410217912183, 0.5325410217912183, 0.2180536001945066, 0.2180536001945066, 0.2180536001945066, 0.15955365086274287, 0.15955365086274287, 0.15955365086274287, 0.11669974135986194, 0.11669974135986194, 0.11669974135986194, 0.3192301653471675, 0.3192301653471675, 0.3192301653471675, 0.12047545887350408, 0.12047545887350408, 0.12047545887350408, 0.4895410527183002, 0.4895410527183002, 0.4895410527183002, 0.30983467690359756, 0.30983467690359756, 0.30983467690359756, 0.25981713931026273, 0.25981713931026273, 0.25981713931026273, 0.116775284106304, 0.116775284106304, 0.116775284106304, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11234287978186497, 0.11234287978186497, 0.11234287978186497, 0.20217911017436585, 0.20217911017436585, 0.20217911017436585, 0.26951560053030943, 0.26951560053030943, 0.26951560053030943, 0.06589815951641032, 0.06589815951641032, 0.06589815951641032, 0.19585390761318644, 0.19585390761318644, 0.19585390761318644, 0.130776515274856, 0.130776515274856, 0.130776515274856, 0.056201113150505466, 0.056201113150505466, 0.056201113150505466, 0.08474039760497687, 0.08474039760497687, 0.08474039760497687, 0.1781186427308512, 0.1781186427308512, 0.1781186427308512, 0.1651035243859651, 0.1651035243859651, 0.1651035243859651, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5306071272671027, 0.5306071272671027, 0.5306071272671027, 0.5620155147396554, 0.5620155147396554, 0.5620155147396554, 0.5674957634774221, 0.5674957634774221, 0.5674957634774221, 0.09816506173836403, 0.09816506173836403, 0.09816506173836403, 0.10662575479143965, 0.10662575479143965, 0.10662575479143965, 0.11915990157649015, 0.11915990157649015, 0.11915990157649015, 0.2480725761801056, 0.2480725761801056, 0.2480725761801056, 0.20508588272961292, 0.20508588272961292, 0.20508588272961292, 0.20186295703757473, 0.20186295703757473, 0.20186295703757473, 0.39052066099920646, 0.39052066099920646, 0.39052066099920646, 0.21340139604270136, 0.21340139604270136, 0.21340139604270136, 0.33556046609964074, 0.33556046609964074, 0.33556046609964074, 0.3079800110267952, 0.3079800110267952, 0.3079800110267952, 0.22988328261885183, 0.22988328261885183, 0.22988328261885183, 0.13934663440847161, 0.13934663440847161, 0.13934663440847161, 0.2392358162520697, 0.2392358162520697, 0.2392358162520697, 0.2353611695482163, 0.2353611695482163, 0.2353611695482163, 0.21329124322443893, 0.21329124322443893, 0.21329124322443893, 0.17623575589755058, 0.17623575589755058, 0.17623575589755058, 0.18472806386394913, 0.18472806386394913, 0.18472806386394913, 0.2332795332206743, 0.2332795332206743, 0.2332795332206743, 0.8412688632559204, 0.8412688632559204, 0.8412688632559204, 0.15738560452270445, 0.15738560452270445, 0.15738560452270445, 0.1691347649539564, 0.1691347649539564, 0.1691347649539564, 0.20971674883211822, 0.20971674883211822, 0.20971674883211822, 0.20956225564830866, 0.20956225564830866, 0.20956225564830866, 0.15187885712245497, 0.15187885712245497, 0.15187885712245497, 0.1884438209632735, 0.1884438209632735, 0.1884438209632735, 0.18092815435556575, 0.18092815435556575, 0.18092815435556575, 0.19128512249819307, 0.19128512249819307, 0.19128512249819307, 0.10496923951524872, 0.10496923951524872, 0.10496923951524872, 0.1020169549279748, 0.1020169549279748, 0.1020169549279748, 0.10565486104717525, 0.10565486104717525, 0.10565486104717525]}, "mutation_prompt": null}
{"id": "bf89bda2-0fb0-4c67-a0a0-de84aacb93eb", "solution": "import numpy as np\n\nclass PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n\n    def __call__(self, func):\n        np.random.seed(42)\n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            # Update personal and global bests\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            # Apply Differential Evolution mutation and crossover\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "PSO_ADE_Optimizer", "description": "Hybrid Particle Swarm Optimization with Adaptive Differential Evolution (PSO-ADE) combines swarm intelligence and mutation strategies to balance exploration and exploitation for efficient search.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "00016c82-8530-49ce-a4cd-d0ff638928f2", "metadata": {"aucs": [0.6921163136188262, 0.6921163136188262, 0.6921163136188262, 0.6141005361866843, 0.6141005361866843, 0.6141005361866843, 0.7101297430937754, 0.7101297430937754, 0.7101297430937754, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.21222809629046424, 0.21222809629046424, 0.21222809629046424, 0.01400111651648206, 0.01400111651648206, 0.01400111651648206, 0.09027192408854134, 0.09027192408854134, 0.09027192408854134, 0.10932415872791823, 0.10932415872791823, 0.10932415872791823, 0.1341235138283826, 0.1341235138283826, 0.1341235138283826, 0.15874693251912908, 0.15874693251912908, 0.15874693251912908, 0.11845369966779984, 0.11845369966779984, 0.11845369966779984, 0.12624330260423633, 0.12624330260423633, 0.12624330260423633, 0.9750192773622189, 0.9750192773622189, 0.9750192773622189, 0.9773408907457926, 0.9773408907457926, 0.9773408907457926, 0.9764359866445449, 0.9764359866445449, 0.9764359866445449, 0.49813541922359117, 0.49813541922359117, 0.49813541922359117, 0.5066436259615181, 0.5066436259615181, 0.5066436259615181, 0.5325410217912183, 0.5325410217912183, 0.5325410217912183, 0.2180536001945066, 0.2180536001945066, 0.2180536001945066, 0.15955365086274287, 0.15955365086274287, 0.15955365086274287, 0.11669974135986194, 0.11669974135986194, 0.11669974135986194, 0.3192301653471675, 0.3192301653471675, 0.3192301653471675, 0.12047545887350408, 0.12047545887350408, 0.12047545887350408, 0.4895410527183002, 0.4895410527183002, 0.4895410527183002, 0.30983467690359756, 0.30983467690359756, 0.30983467690359756, 0.25981713931026273, 0.25981713931026273, 0.25981713931026273, 0.116775284106304, 0.116775284106304, 0.116775284106304, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11234287978186497, 0.11234287978186497, 0.11234287978186497, 0.20217911017436585, 0.20217911017436585, 0.20217911017436585, 0.26951560053030943, 0.26951560053030943, 0.26951560053030943, 0.06589815951641032, 0.06589815951641032, 0.06589815951641032, 0.19585390761318644, 0.19585390761318644, 0.19585390761318644, 0.130776515274856, 0.130776515274856, 0.130776515274856, 0.056201113150505466, 0.056201113150505466, 0.056201113150505466, 0.08474039760497687, 0.08474039760497687, 0.08474039760497687, 0.1781186427308512, 0.1781186427308512, 0.1781186427308512, 0.1651035243859651, 0.1651035243859651, 0.1651035243859651, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5306071272671027, 0.5306071272671027, 0.5306071272671027, 0.5620155147396554, 0.5620155147396554, 0.5620155147396554, 0.5674957634774221, 0.5674957634774221, 0.5674957634774221, 0.09816506173836403, 0.09816506173836403, 0.09816506173836403, 0.10662575479143965, 0.10662575479143965, 0.10662575479143965, 0.11915990157649015, 0.11915990157649015, 0.11915990157649015, 0.2480725761801056, 0.2480725761801056, 0.2480725761801056, 0.20508588272961292, 0.20508588272961292, 0.20508588272961292, 0.20186295703757473, 0.20186295703757473, 0.20186295703757473, 0.39052066099920646, 0.39052066099920646, 0.39052066099920646, 0.21340139604270136, 0.21340139604270136, 0.21340139604270136, 0.33556046609964074, 0.33556046609964074, 0.33556046609964074, 0.3079800110267952, 0.3079800110267952, 0.3079800110267952, 0.22988328261885183, 0.22988328261885183, 0.22988328261885183, 0.13934663440847161, 0.13934663440847161, 0.13934663440847161, 0.2392358162520697, 0.2392358162520697, 0.2392358162520697, 0.2353611695482163, 0.2353611695482163, 0.2353611695482163, 0.21329124322443893, 0.21329124322443893, 0.21329124322443893, 0.17623575589755058, 0.17623575589755058, 0.17623575589755058, 0.18472806386394913, 0.18472806386394913, 0.18472806386394913, 0.2332795332206743, 0.2332795332206743, 0.2332795332206743, 0.8412688632559204, 0.8412688632559204, 0.8412688632559204, 0.15738560452270445, 0.15738560452270445, 0.15738560452270445, 0.1691347649539564, 0.1691347649539564, 0.1691347649539564, 0.20971674883211822, 0.20971674883211822, 0.20971674883211822, 0.20956225564830866, 0.20956225564830866, 0.20956225564830866, 0.15187885712245497, 0.15187885712245497, 0.15187885712245497, 0.1884438209632735, 0.1884438209632735, 0.1884438209632735, 0.18092815435556575, 0.18092815435556575, 0.18092815435556575, 0.19128512249819307, 0.19128512249819307, 0.19128512249819307, 0.10496923951524872, 0.10496923951524872, 0.10496923951524872, 0.1020169549279748, 0.1020169549279748, 0.1020169549279748, 0.10565486104717525, 0.10565486104717525, 0.10565486104717525]}, "mutation_prompt": null}
{"id": "27bbd699-d51d-4cf1-b6f1-77c86bbee0ca", "solution": "import numpy as np\n\nclass PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            r1, r2 = np.random.rand(2)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            # Dynamic crossover probability adjustment based on convergence\n            dynamic_crossover_prob = 0.5 + 0.4 * (1 - global_best_score / (np.min(personal_best_scores) + 1e-10))\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < dynamic_crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "PSO_ADE_Optimizer", "description": "PSO-ADE with Dynamic Crossover Probability adjusts crossover probability dynamically based on convergence, enhancing exploration and convergence speed.", "configspace": "", "generation": 18, "fitness": 0.24957527142441305, "feedback": "The algorithm PSO_ADE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.22.", "error": "", "parent_id": "00016c82-8530-49ce-a4cd-d0ff638928f2", "metadata": {"aucs": [0.7012044726507225, 0.7012044726507225, 0.7012044726507225, 0.18557039137151254, 0.18557039137151254, 0.18557039137151254, 0.708820230050117, 0.708820230050117, 0.708820230050117, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.311376170338038, 0.311376170338038, 0.311376170338038, 0.28357934297708176, 0.28357934297708176, 0.28357934297708176, 0.10657943607297293, 0.10657943607297293, 0.10657943607297293, 0.138677866878261, 0.138677866878261, 0.138677866878261, 0.12240800703994337, 0.12240800703994337, 0.12240800703994337, 0.11412903291181631, 0.11412903291181631, 0.11412903291181631, 0.07612872946220273, 0.07612872946220273, 0.07612872946220273, 0.09730048809756808, 0.09730048809756808, 0.09730048809756808, 0.9763322134643929, 0.9763322134643929, 0.9763322134643929, 0.9770002623123585, 0.9770002623123585, 0.9770002623123585, 0.9770968024951117, 0.9770968024951117, 0.9770968024951117, 0.4773329496145623, 0.4773329496145623, 0.4773329496145623, 0.392214072356029, 0.392214072356029, 0.392214072356029, 0.43221802992906655, 0.43221802992906655, 0.43221802992906655, 0.22161902014947166, 0.22161902014947166, 0.22161902014947166, 0.16168326443562653, 0.16168326443562653, 0.16168326443562653, 0.11706983104690372, 0.11706983104690372, 0.11706983104690372, 0.12714749165997108, 0.12714749165997108, 0.12714749165997108, 0.3545749299710279, 0.3545749299710279, 0.3545749299710279, 0.1249894230014772, 0.1249894230014772, 0.1249894230014772, 0.20480270110934362, 0.20480270110934362, 0.20480270110934362, 0.33879684979944746, 0.33879684979944746, 0.33879684979944746, 0.15293450624929117, 0.15293450624929117, 0.15293450624929117, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06740030974771694, 0.06740030974771694, 0.06740030974771694, 0.15630805617776877, 0.15630805617776877, 0.15630805617776877, 0.16056011764844458, 0.16056011764844458, 0.16056011764844458, 0.02891433265436283, 0.02891433265436283, 0.02891433265436283, 0.21877962245210492, 0.21877962245210492, 0.21877962245210492, 0.10638556646328856, 0.10638556646328856, 0.10638556646328856, 0.07466836770245733, 0.07466836770245733, 0.07466836770245733, 0.0939641586383827, 0.0939641586383827, 0.0939641586383827, 0.1318654769586154, 0.1318654769586154, 0.1318654769586154, 0.03589854670617565, 0.03589854670617565, 0.03589854670617565, 0.07425665727493602, 0.07425665727493602, 0.07425665727493602, 0.5450705632000749, 0.5450705632000749, 0.5450705632000749, 0.5190212047670263, 0.5190212047670263, 0.5190212047670263, 0.5313426732456807, 0.5313426732456807, 0.5313426732456807, 0.08893763255894394, 0.08893763255894394, 0.08893763255894394, 0.07423923183384773, 0.07423923183384773, 0.07423923183384773, 0.10158496388665716, 0.10158496388665716, 0.10158496388665716, 0.19136214756446712, 0.19136214756446712, 0.19136214756446712, 0.16430853119086364, 0.16430853119086364, 0.16430853119086364, 0.2127217860787768, 0.2127217860787768, 0.2127217860787768, 0.3722869568658904, 0.3722869568658904, 0.3722869568658904, 0.35743867252203143, 0.35743867252203143, 0.35743867252203143, 0.31578197379451145, 0.31578197379451145, 0.31578197379451145, 0.24611745406485508, 0.24611745406485508, 0.24611745406485508, 0.18956032406997947, 0.18956032406997947, 0.18956032406997947, 0.1484118073022601, 0.1484118073022601, 0.1484118073022601, 0.19416556026096576, 0.19416556026096576, 0.19416556026096576, 0.2145828528926046, 0.2145828528926046, 0.2145828528926046, 0.23666884707189306, 0.23666884707189306, 0.23666884707189306, 0.19916078785478508, 0.19916078785478508, 0.19916078785478508, 0.21731747379077537, 0.21731747379077537, 0.21731747379077537, 0.20625760543572225, 0.20625760543572225, 0.20625760543572225, 0.8231468202405215, 0.8231468202405215, 0.8231468202405215, 0.15813438082289033, 0.15813438082289033, 0.15813438082289033, 0.16943781559803794, 0.16943781559803794, 0.16943781559803794, 0.1678205333929612, 0.1678205333929612, 0.1678205333929612, 0.20998249656469137, 0.20998249656469137, 0.20998249656469137, 0.15420530129226606, 0.15420530129226606, 0.15420530129226606, 0.19886549442785773, 0.19886549442785773, 0.19886549442785773, 0.19689397250220986, 0.19689397250220986, 0.19689397250220986, 0.20398006081191744, 0.20398006081191744, 0.20398006081191744, 0.10688059911067271, 0.10688059911067271, 0.10688059911067271, 0.09161846127984685, 0.09161846127984685, 0.09161846127984685, 0.13132682839268306, 0.13132682839268306, 0.13132682839268306]}, "mutation_prompt": null}
{"id": "dbd2b374-cf4f-4d0f-bdc5-c7da6691207d", "solution": "import numpy as np\n\nclass PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n\n    def __call__(self, func):\n        np.random.seed(42)\n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            # Update personal and global bests\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            # Apply Differential Evolution mutation and crossover\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "PSO_ADE_Optimizer", "description": "Hybrid Particle Swarm Optimization with Adaptive Differential Evolution (PSO-ADE) combines swarm intelligence and mutation strategies to balance exploration and exploitation for efficient search.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "00016c82-8530-49ce-a4cd-d0ff638928f2", "metadata": {"aucs": [0.6921163136188262, 0.6921163136188262, 0.6921163136188262, 0.6141005361866843, 0.6141005361866843, 0.6141005361866843, 0.7101297430937754, 0.7101297430937754, 0.7101297430937754, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.21222809629046424, 0.21222809629046424, 0.21222809629046424, 0.01400111651648206, 0.01400111651648206, 0.01400111651648206, 0.09027192408854134, 0.09027192408854134, 0.09027192408854134, 0.10932415872791823, 0.10932415872791823, 0.10932415872791823, 0.1341235138283826, 0.1341235138283826, 0.1341235138283826, 0.15874693251912908, 0.15874693251912908, 0.15874693251912908, 0.11845369966779984, 0.11845369966779984, 0.11845369966779984, 0.12624330260423633, 0.12624330260423633, 0.12624330260423633, 0.9750192773622189, 0.9750192773622189, 0.9750192773622189, 0.9773408907457926, 0.9773408907457926, 0.9773408907457926, 0.9764359866445449, 0.9764359866445449, 0.9764359866445449, 0.49813541922359117, 0.49813541922359117, 0.49813541922359117, 0.5066436259615181, 0.5066436259615181, 0.5066436259615181, 0.5325410217912183, 0.5325410217912183, 0.5325410217912183, 0.2180536001945066, 0.2180536001945066, 0.2180536001945066, 0.15955365086274287, 0.15955365086274287, 0.15955365086274287, 0.11669974135986194, 0.11669974135986194, 0.11669974135986194, 0.3192301653471675, 0.3192301653471675, 0.3192301653471675, 0.12047545887350408, 0.12047545887350408, 0.12047545887350408, 0.4895410527183002, 0.4895410527183002, 0.4895410527183002, 0.30983467690359756, 0.30983467690359756, 0.30983467690359756, 0.25981713931026273, 0.25981713931026273, 0.25981713931026273, 0.116775284106304, 0.116775284106304, 0.116775284106304, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11234287978186497, 0.11234287978186497, 0.11234287978186497, 0.20217911017436585, 0.20217911017436585, 0.20217911017436585, 0.26951560053030943, 0.26951560053030943, 0.26951560053030943, 0.06589815951641032, 0.06589815951641032, 0.06589815951641032, 0.19585390761318644, 0.19585390761318644, 0.19585390761318644, 0.130776515274856, 0.130776515274856, 0.130776515274856, 0.056201113150505466, 0.056201113150505466, 0.056201113150505466, 0.08474039760497687, 0.08474039760497687, 0.08474039760497687, 0.1781186427308512, 0.1781186427308512, 0.1781186427308512, 0.1651035243859651, 0.1651035243859651, 0.1651035243859651, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5306071272671027, 0.5306071272671027, 0.5306071272671027, 0.5620155147396554, 0.5620155147396554, 0.5620155147396554, 0.5674957634774221, 0.5674957634774221, 0.5674957634774221, 0.09816506173836403, 0.09816506173836403, 0.09816506173836403, 0.10662575479143965, 0.10662575479143965, 0.10662575479143965, 0.11915990157649015, 0.11915990157649015, 0.11915990157649015, 0.2480725761801056, 0.2480725761801056, 0.2480725761801056, 0.20508588272961292, 0.20508588272961292, 0.20508588272961292, 0.20186295703757473, 0.20186295703757473, 0.20186295703757473, 0.39052066099920646, 0.39052066099920646, 0.39052066099920646, 0.21340139604270136, 0.21340139604270136, 0.21340139604270136, 0.33556046609964074, 0.33556046609964074, 0.33556046609964074, 0.3079800110267952, 0.3079800110267952, 0.3079800110267952, 0.22988328261885183, 0.22988328261885183, 0.22988328261885183, 0.13934663440847161, 0.13934663440847161, 0.13934663440847161, 0.2392358162520697, 0.2392358162520697, 0.2392358162520697, 0.2353611695482163, 0.2353611695482163, 0.2353611695482163, 0.21329124322443893, 0.21329124322443893, 0.21329124322443893, 0.17623575589755058, 0.17623575589755058, 0.17623575589755058, 0.18472806386394913, 0.18472806386394913, 0.18472806386394913, 0.2332795332206743, 0.2332795332206743, 0.2332795332206743, 0.8412688632559204, 0.8412688632559204, 0.8412688632559204, 0.15738560452270445, 0.15738560452270445, 0.15738560452270445, 0.1691347649539564, 0.1691347649539564, 0.1691347649539564, 0.20971674883211822, 0.20971674883211822, 0.20971674883211822, 0.20956225564830866, 0.20956225564830866, 0.20956225564830866, 0.15187885712245497, 0.15187885712245497, 0.15187885712245497, 0.1884438209632735, 0.1884438209632735, 0.1884438209632735, 0.18092815435556575, 0.18092815435556575, 0.18092815435556575, 0.19128512249819307, 0.19128512249819307, 0.19128512249819307, 0.10496923951524872, 0.10496923951524872, 0.10496923951524872, 0.1020169549279748, 0.1020169549279748, 0.1020169549279748, 0.10565486104717525, 0.10565486104717525, 0.10565486104717525]}, "mutation_prompt": null}
{"id": "09202729-ddd6-4004-b785-b92e6d16f2b0", "solution": "import numpy as np\n\nclass PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n\n    def __call__(self, func):\n        np.random.seed(42)\n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            # Update personal and global bests\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            # Apply Differential Evolution mutation and crossover\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "PSO_ADE_Optimizer", "description": "Hybrid Particle Swarm Optimization with Adaptive Differential Evolution (PSO-ADE) combines swarm intelligence and mutation strategies to balance exploration and exploitation for efficient search.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "00016c82-8530-49ce-a4cd-d0ff638928f2", "metadata": {"aucs": [0.6921163136188262, 0.6921163136188262, 0.6921163136188262, 0.6141005361866843, 0.6141005361866843, 0.6141005361866843, 0.7101297430937754, 0.7101297430937754, 0.7101297430937754, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.21222809629046424, 0.21222809629046424, 0.21222809629046424, 0.01400111651648206, 0.01400111651648206, 0.01400111651648206, 0.09027192408854134, 0.09027192408854134, 0.09027192408854134, 0.10932415872791823, 0.10932415872791823, 0.10932415872791823, 0.1341235138283826, 0.1341235138283826, 0.1341235138283826, 0.15874693251912908, 0.15874693251912908, 0.15874693251912908, 0.11845369966779984, 0.11845369966779984, 0.11845369966779984, 0.12624330260423633, 0.12624330260423633, 0.12624330260423633, 0.9750192773622189, 0.9750192773622189, 0.9750192773622189, 0.9773408907457926, 0.9773408907457926, 0.9773408907457926, 0.9764359866445449, 0.9764359866445449, 0.9764359866445449, 0.49813541922359117, 0.49813541922359117, 0.49813541922359117, 0.5066436259615181, 0.5066436259615181, 0.5066436259615181, 0.5325410217912183, 0.5325410217912183, 0.5325410217912183, 0.2180536001945066, 0.2180536001945066, 0.2180536001945066, 0.15955365086274287, 0.15955365086274287, 0.15955365086274287, 0.11669974135986194, 0.11669974135986194, 0.11669974135986194, 0.3192301653471675, 0.3192301653471675, 0.3192301653471675, 0.12047545887350408, 0.12047545887350408, 0.12047545887350408, 0.4895410527183002, 0.4895410527183002, 0.4895410527183002, 0.30983467690359756, 0.30983467690359756, 0.30983467690359756, 0.25981713931026273, 0.25981713931026273, 0.25981713931026273, 0.116775284106304, 0.116775284106304, 0.116775284106304, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11234287978186497, 0.11234287978186497, 0.11234287978186497, 0.20217911017436585, 0.20217911017436585, 0.20217911017436585, 0.26951560053030943, 0.26951560053030943, 0.26951560053030943, 0.06589815951641032, 0.06589815951641032, 0.06589815951641032, 0.19585390761318644, 0.19585390761318644, 0.19585390761318644, 0.130776515274856, 0.130776515274856, 0.130776515274856, 0.056201113150505466, 0.056201113150505466, 0.056201113150505466, 0.08474039760497687, 0.08474039760497687, 0.08474039760497687, 0.1781186427308512, 0.1781186427308512, 0.1781186427308512, 0.1651035243859651, 0.1651035243859651, 0.1651035243859651, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5306071272671027, 0.5306071272671027, 0.5306071272671027, 0.5620155147396554, 0.5620155147396554, 0.5620155147396554, 0.5674957634774221, 0.5674957634774221, 0.5674957634774221, 0.09816506173836403, 0.09816506173836403, 0.09816506173836403, 0.10662575479143965, 0.10662575479143965, 0.10662575479143965, 0.11915990157649015, 0.11915990157649015, 0.11915990157649015, 0.2480725761801056, 0.2480725761801056, 0.2480725761801056, 0.20508588272961292, 0.20508588272961292, 0.20508588272961292, 0.20186295703757473, 0.20186295703757473, 0.20186295703757473, 0.39052066099920646, 0.39052066099920646, 0.39052066099920646, 0.21340139604270136, 0.21340139604270136, 0.21340139604270136, 0.33556046609964074, 0.33556046609964074, 0.33556046609964074, 0.3079800110267952, 0.3079800110267952, 0.3079800110267952, 0.22988328261885183, 0.22988328261885183, 0.22988328261885183, 0.13934663440847161, 0.13934663440847161, 0.13934663440847161, 0.2392358162520697, 0.2392358162520697, 0.2392358162520697, 0.2353611695482163, 0.2353611695482163, 0.2353611695482163, 0.21329124322443893, 0.21329124322443893, 0.21329124322443893, 0.17623575589755058, 0.17623575589755058, 0.17623575589755058, 0.18472806386394913, 0.18472806386394913, 0.18472806386394913, 0.2332795332206743, 0.2332795332206743, 0.2332795332206743, 0.8412688632559204, 0.8412688632559204, 0.8412688632559204, 0.15738560452270445, 0.15738560452270445, 0.15738560452270445, 0.1691347649539564, 0.1691347649539564, 0.1691347649539564, 0.20971674883211822, 0.20971674883211822, 0.20971674883211822, 0.20956225564830866, 0.20956225564830866, 0.20956225564830866, 0.15187885712245497, 0.15187885712245497, 0.15187885712245497, 0.1884438209632735, 0.1884438209632735, 0.1884438209632735, 0.18092815435556575, 0.18092815435556575, 0.18092815435556575, 0.19128512249819307, 0.19128512249819307, 0.19128512249819307, 0.10496923951524872, 0.10496923951524872, 0.10496923951524872, 0.1020169549279748, 0.1020169549279748, 0.1020169549279748, 0.10565486104717525, 0.10565486104717525, 0.10565486104717525]}, "mutation_prompt": null}
{"id": "a38bff72-ab4d-4016-8bad-941a89cbfbc9", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.5  # Reduced inertia_weight for quicker convergence\n        self.cognitive_coeff = 1.7  # Increased cognitive_coeff for more exploration\n        self.social_coeff = 1.3  # Reduced social_coeff to improve diversity\n        self.dynamic_adjustment_freq = 10  # Frequency of dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0  # Initialize iteration counter\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:  # Dynamic parameter adjustment\n                self.inertia_weight *= 0.95  # Gradually reduce inertia\n                self.mutation_factor = 0.9 if iteration < self.budget // 2 else 0.7  # Adjust mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1  # Increment iteration counter\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with dynamic parameter adjustment and improved diversity mechanism for accelerated convergence.", "configspace": "", "generation": 21, "fitness": 0.3026966061364845, "feedback": "The algorithm Enhanced_PSO_ADE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.26.", "error": "", "parent_id": "00016c82-8530-49ce-a4cd-d0ff638928f2", "metadata": {"aucs": [0.8173532858943607, 0.8173532858943607, 0.8173532858943607, 0.8070665307824119, 0.8070665307824119, 0.8070665307824119, 0.8302027387283974, 0.8302027387283974, 0.8302027387283974, 0.5134322341997061, 0.5134322341997061, 0.5134322341997061, 0.624691263026809, 0.624691263026809, 0.624691263026809, 0.6002980633873294, 0.6002980633873294, 0.6002980633873294, 0.15836040046428224, 0.15836040046428224, 0.15836040046428224, 0.13123216050558661, 0.13123216050558661, 0.13123216050558661, 0.27970106171202114, 0.27970106171202114, 0.27970106171202114, 0.15124280349195118, 0.15124280349195118, 0.15124280349195118, 0.09834124134572031, 0.09834124134572031, 0.09834124134572031, 0.12989604071547778, 0.12989604071547778, 0.12989604071547778, 0.9680695927117464, 0.9680695927117464, 0.9680695927117464, 0.9768501235494804, 0.9768501235494804, 0.9768501235494804, 0.9831477879115976, 0.9831477879115976, 0.9831477879115976, 0.5971319790953125, 0.5971319790953125, 0.5971319790953125, 0.48474815956165695, 0.48474815956165695, 0.48474815956165695, 0.5830104602966175, 0.5830104602966175, 0.5830104602966175, 0.27622022111890565, 0.27622022111890565, 0.27622022111890565, 0.18779824886197094, 0.18779824886197094, 0.18779824886197094, 0.33670363500165723, 0.33670363500165723, 0.33670363500165723, 0.2952862590151156, 0.2952862590151156, 0.2952862590151156, 0.12903284797818992, 0.12903284797818992, 0.12903284797818992, 0.19498986972794174, 0.19498986972794174, 0.19498986972794174, 0.21024770382224844, 0.21024770382224844, 0.21024770382224844, 0.18127758222775825, 0.18127758222775825, 0.18127758222775825, 0.1332413227550654, 0.1332413227550654, 0.1332413227550654, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.000591596660297955, 0.000591596660297955, 0.000591596660297955, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1420256776795833, 0.1420256776795833, 0.1420256776795833, 0.020748106240395137, 0.020748106240395137, 0.020748106240395137, 0.1348851129367975, 0.1348851129367975, 0.1348851129367975, 0.04458903399180836, 0.04458903399180836, 0.04458903399180836, 0.11512893530323998, 0.11512893530323998, 0.11512893530323998, 0.08641355632800374, 0.08641355632800374, 0.08641355632800374, 0.14777383418850298, 0.14777383418850298, 0.14777383418850298, 0.07206563016569412, 0.07206563016569412, 0.07206563016569412, 0.07923642752837845, 0.07923642752837845, 0.07923642752837845, 0.5973585429735873, 0.5973585429735873, 0.5973585429735873, 0.5444614487631158, 0.5444614487631158, 0.5444614487631158, 0.5581596112472851, 0.5581596112472851, 0.5581596112472851, 0.10792836734243372, 0.10792836734243372, 0.10792836734243372, 0.16390282508876686, 0.16390282508876686, 0.16390282508876686, 0.08962551634344096, 0.08962551634344096, 0.08962551634344096, 0.19483029090259651, 0.19483029090259651, 0.19483029090259651, 0.2820278660431219, 0.2820278660431219, 0.2820278660431219, 0.26805499101487307, 0.26805499101487307, 0.26805499101487307, 0.24637636277992703, 0.24637636277992703, 0.24637636277992703, 0.3831050982404137, 0.3831050982404137, 0.3831050982404137, 0.4868095742725873, 0.4868095742725873, 0.4868095742725873, 0.16845536602753763, 0.16845536602753763, 0.16845536602753763, 0.3014920382412615, 0.3014920382412615, 0.3014920382412615, 0.36512925182854294, 0.36512925182854294, 0.36512925182854294, 0.22868397010770147, 0.22868397010770147, 0.22868397010770147, 0.22390362207286474, 0.22390362207286474, 0.22390362207286474, 0.21557387697624797, 0.21557387697624797, 0.21557387697624797, 0.19146581710468058, 0.19146581710468058, 0.19146581710468058, 0.2142825225819227, 0.2142825225819227, 0.2142825225819227, 0.23382031825464455, 0.23382031825464455, 0.23382031825464455, 0.8781972766424274, 0.8781972766424274, 0.8781972766424274, 0.16498904353322907, 0.16498904353322907, 0.16498904353322907, 0.1675048508288941, 0.1675048508288941, 0.1675048508288941, 0.1677930192856908, 0.1677930192856908, 0.1677930192856908, 0.2096363998358497, 0.2096363998358497, 0.2096363998358497, 0.7527906802205094, 0.7527906802205094, 0.7527906802205094, 0.18281873394226333, 0.18281873394226333, 0.18281873394226333, 0.18751703876694603, 0.18751703876694603, 0.18751703876694603, 0.2003195826305778, 0.2003195826305778, 0.2003195826305778, 0.09323489623740366, 0.09323489623740366, 0.09323489623740366, 0.08957474845720703, 0.08957474845720703, 0.08957474845720703, 0.11110056432631477, 0.11110056432631477, 0.11110056432631477]}, "mutation_prompt": null}
{"id": "ace083d4-351d-4e56-8b24-4f65b8eebe1d", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.5  # Reduced inertia_weight for quicker convergence\n        self.cognitive_coeff = 1.7  # Increased cognitive_coeff for more exploration\n        self.social_coeff = 1.3  # Reduced social_coeff to improve diversity\n        self.dynamic_adjustment_freq = 10  # Frequency of dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0  # Initialize iteration counter\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:  # Dynamic parameter adjustment\n                self.inertia_weight *= 0.95  # Gradually reduce inertia\n                self.mutation_factor = 0.9 if iteration < self.budget // 2 else 0.7  # Adjust mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1  # Increment iteration counter\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with dynamic parameter adjustment and improved diversity mechanism for accelerated convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a38bff72-ab4d-4016-8bad-941a89cbfbc9", "metadata": {"aucs": [0.8173532858943607, 0.8173532858943607, 0.8173532858943607, 0.8070665307824119, 0.8070665307824119, 0.8070665307824119, 0.8302027387283974, 0.8302027387283974, 0.8302027387283974, 0.5134322341997061, 0.5134322341997061, 0.5134322341997061, 0.624691263026809, 0.624691263026809, 0.624691263026809, 0.6002980633873294, 0.6002980633873294, 0.6002980633873294, 0.15836040046428224, 0.15836040046428224, 0.15836040046428224, 0.13123216050558661, 0.13123216050558661, 0.13123216050558661, 0.27970106171202114, 0.27970106171202114, 0.27970106171202114, 0.15124280349195118, 0.15124280349195118, 0.15124280349195118, 0.09834124134572031, 0.09834124134572031, 0.09834124134572031, 0.12989604071547778, 0.12989604071547778, 0.12989604071547778, 0.9680695927117464, 0.9680695927117464, 0.9680695927117464, 0.9768501235494804, 0.9768501235494804, 0.9768501235494804, 0.9831477879115976, 0.9831477879115976, 0.9831477879115976, 0.5971319790953125, 0.5971319790953125, 0.5971319790953125, 0.48474815956165695, 0.48474815956165695, 0.48474815956165695, 0.5830104602966175, 0.5830104602966175, 0.5830104602966175, 0.27622022111890565, 0.27622022111890565, 0.27622022111890565, 0.18779824886197094, 0.18779824886197094, 0.18779824886197094, 0.33670363500165723, 0.33670363500165723, 0.33670363500165723, 0.2952862590151156, 0.2952862590151156, 0.2952862590151156, 0.12903284797818992, 0.12903284797818992, 0.12903284797818992, 0.19498986972794174, 0.19498986972794174, 0.19498986972794174, 0.21024770382224844, 0.21024770382224844, 0.21024770382224844, 0.18127758222775825, 0.18127758222775825, 0.18127758222775825, 0.1332413227550654, 0.1332413227550654, 0.1332413227550654, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.000591596660297955, 0.000591596660297955, 0.000591596660297955, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1420256776795833, 0.1420256776795833, 0.1420256776795833, 0.020748106240395137, 0.020748106240395137, 0.020748106240395137, 0.1348851129367975, 0.1348851129367975, 0.1348851129367975, 0.04458903399180836, 0.04458903399180836, 0.04458903399180836, 0.11512893530323998, 0.11512893530323998, 0.11512893530323998, 0.08641355632800374, 0.08641355632800374, 0.08641355632800374, 0.14777383418850298, 0.14777383418850298, 0.14777383418850298, 0.07206563016569412, 0.07206563016569412, 0.07206563016569412, 0.07923642752837845, 0.07923642752837845, 0.07923642752837845, 0.5973585429735873, 0.5973585429735873, 0.5973585429735873, 0.5444614487631158, 0.5444614487631158, 0.5444614487631158, 0.5581596112472851, 0.5581596112472851, 0.5581596112472851, 0.10792836734243372, 0.10792836734243372, 0.10792836734243372, 0.16390282508876686, 0.16390282508876686, 0.16390282508876686, 0.08962551634344096, 0.08962551634344096, 0.08962551634344096, 0.19483029090259651, 0.19483029090259651, 0.19483029090259651, 0.2820278660431219, 0.2820278660431219, 0.2820278660431219, 0.26805499101487307, 0.26805499101487307, 0.26805499101487307, 0.24637636277992703, 0.24637636277992703, 0.24637636277992703, 0.3831050982404137, 0.3831050982404137, 0.3831050982404137, 0.4868095742725873, 0.4868095742725873, 0.4868095742725873, 0.16845536602753763, 0.16845536602753763, 0.16845536602753763, 0.3014920382412615, 0.3014920382412615, 0.3014920382412615, 0.36512925182854294, 0.36512925182854294, 0.36512925182854294, 0.22868397010770147, 0.22868397010770147, 0.22868397010770147, 0.22390362207286474, 0.22390362207286474, 0.22390362207286474, 0.21557387697624797, 0.21557387697624797, 0.21557387697624797, 0.19146581710468058, 0.19146581710468058, 0.19146581710468058, 0.2142825225819227, 0.2142825225819227, 0.2142825225819227, 0.23382031825464455, 0.23382031825464455, 0.23382031825464455, 0.8781972766424274, 0.8781972766424274, 0.8781972766424274, 0.16498904353322907, 0.16498904353322907, 0.16498904353322907, 0.1675048508288941, 0.1675048508288941, 0.1675048508288941, 0.1677930192856908, 0.1677930192856908, 0.1677930192856908, 0.2096363998358497, 0.2096363998358497, 0.2096363998358497, 0.7527906802205094, 0.7527906802205094, 0.7527906802205094, 0.18281873394226333, 0.18281873394226333, 0.18281873394226333, 0.18751703876694603, 0.18751703876694603, 0.18751703876694603, 0.2003195826305778, 0.2003195826305778, 0.2003195826305778, 0.09323489623740366, 0.09323489623740366, 0.09323489623740366, 0.08957474845720703, 0.08957474845720703, 0.08957474845720703, 0.11110056432631477, 0.11110056432631477, 0.11110056432631477]}, "mutation_prompt": null}
{"id": "de361219-75c7-492a-b119-493c42c7c3cb", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.5  # Reduced inertia_weight for quicker convergence\n        self.cognitive_coeff = 1.7  # Increased cognitive_coeff for more exploration\n        self.social_coeff = 1.3  # Reduced social_coeff to improve diversity\n        self.dynamic_adjustment_freq = 10  # Frequency of dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0  # Initialize iteration counter\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:  # Dynamic parameter adjustment\n                self.inertia_weight *= 0.95  # Gradually reduce inertia\n                self.mutation_factor = 0.9 if iteration < self.budget // 2 else 0.7  # Adjust mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1  # Increment iteration counter\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with dynamic parameter adjustment and improved diversity mechanism for accelerated convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a38bff72-ab4d-4016-8bad-941a89cbfbc9", "metadata": {"aucs": [0.8173532858943607, 0.8173532858943607, 0.8173532858943607, 0.8070665307824119, 0.8070665307824119, 0.8070665307824119, 0.8302027387283974, 0.8302027387283974, 0.8302027387283974, 0.5134322341997061, 0.5134322341997061, 0.5134322341997061, 0.624691263026809, 0.624691263026809, 0.624691263026809, 0.6002980633873294, 0.6002980633873294, 0.6002980633873294, 0.15836040046428224, 0.15836040046428224, 0.15836040046428224, 0.13123216050558661, 0.13123216050558661, 0.13123216050558661, 0.27970106171202114, 0.27970106171202114, 0.27970106171202114, 0.15124280349195118, 0.15124280349195118, 0.15124280349195118, 0.09834124134572031, 0.09834124134572031, 0.09834124134572031, 0.12989604071547778, 0.12989604071547778, 0.12989604071547778, 0.9680695927117464, 0.9680695927117464, 0.9680695927117464, 0.9768501235494804, 0.9768501235494804, 0.9768501235494804, 0.9831477879115976, 0.9831477879115976, 0.9831477879115976, 0.5971319790953125, 0.5971319790953125, 0.5971319790953125, 0.48474815956165695, 0.48474815956165695, 0.48474815956165695, 0.5830104602966175, 0.5830104602966175, 0.5830104602966175, 0.27622022111890565, 0.27622022111890565, 0.27622022111890565, 0.18779824886197094, 0.18779824886197094, 0.18779824886197094, 0.33670363500165723, 0.33670363500165723, 0.33670363500165723, 0.2952862590151156, 0.2952862590151156, 0.2952862590151156, 0.12903284797818992, 0.12903284797818992, 0.12903284797818992, 0.19498986972794174, 0.19498986972794174, 0.19498986972794174, 0.21024770382224844, 0.21024770382224844, 0.21024770382224844, 0.18127758222775825, 0.18127758222775825, 0.18127758222775825, 0.1332413227550654, 0.1332413227550654, 0.1332413227550654, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.000591596660297955, 0.000591596660297955, 0.000591596660297955, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1420256776795833, 0.1420256776795833, 0.1420256776795833, 0.020748106240395137, 0.020748106240395137, 0.020748106240395137, 0.1348851129367975, 0.1348851129367975, 0.1348851129367975, 0.04458903399180836, 0.04458903399180836, 0.04458903399180836, 0.11512893530323998, 0.11512893530323998, 0.11512893530323998, 0.08641355632800374, 0.08641355632800374, 0.08641355632800374, 0.14777383418850298, 0.14777383418850298, 0.14777383418850298, 0.07206563016569412, 0.07206563016569412, 0.07206563016569412, 0.07923642752837845, 0.07923642752837845, 0.07923642752837845, 0.5973585429735873, 0.5973585429735873, 0.5973585429735873, 0.5444614487631158, 0.5444614487631158, 0.5444614487631158, 0.5581596112472851, 0.5581596112472851, 0.5581596112472851, 0.10792836734243372, 0.10792836734243372, 0.10792836734243372, 0.16390282508876686, 0.16390282508876686, 0.16390282508876686, 0.08962551634344096, 0.08962551634344096, 0.08962551634344096, 0.19483029090259651, 0.19483029090259651, 0.19483029090259651, 0.2820278660431219, 0.2820278660431219, 0.2820278660431219, 0.26805499101487307, 0.26805499101487307, 0.26805499101487307, 0.24637636277992703, 0.24637636277992703, 0.24637636277992703, 0.3831050982404137, 0.3831050982404137, 0.3831050982404137, 0.4868095742725873, 0.4868095742725873, 0.4868095742725873, 0.16845536602753763, 0.16845536602753763, 0.16845536602753763, 0.3014920382412615, 0.3014920382412615, 0.3014920382412615, 0.36512925182854294, 0.36512925182854294, 0.36512925182854294, 0.22868397010770147, 0.22868397010770147, 0.22868397010770147, 0.22390362207286474, 0.22390362207286474, 0.22390362207286474, 0.21557387697624797, 0.21557387697624797, 0.21557387697624797, 0.19146581710468058, 0.19146581710468058, 0.19146581710468058, 0.2142825225819227, 0.2142825225819227, 0.2142825225819227, 0.23382031825464455, 0.23382031825464455, 0.23382031825464455, 0.8781972766424274, 0.8781972766424274, 0.8781972766424274, 0.16498904353322907, 0.16498904353322907, 0.16498904353322907, 0.1675048508288941, 0.1675048508288941, 0.1675048508288941, 0.1677930192856908, 0.1677930192856908, 0.1677930192856908, 0.2096363998358497, 0.2096363998358497, 0.2096363998358497, 0.7527906802205094, 0.7527906802205094, 0.7527906802205094, 0.18281873394226333, 0.18281873394226333, 0.18281873394226333, 0.18751703876694603, 0.18751703876694603, 0.18751703876694603, 0.2003195826305778, 0.2003195826305778, 0.2003195826305778, 0.09323489623740366, 0.09323489623740366, 0.09323489623740366, 0.08957474845720703, 0.08957474845720703, 0.08957474845720703, 0.11110056432631477, 0.11110056432631477, 0.11110056432631477]}, "mutation_prompt": null}
{"id": "39d8a37e-7196-4229-921f-05f3b8687df3", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.85  # Adjusted mutation factor for improved diversity\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.6  # Increased inertia_weight for better exploration\n        self.cognitive_coeff = 1.6  # Adjusted cognitive_coeff for balanced exploration\n        self.social_coeff = 1.4  # Increased social_coeff to enhance convergence\n        self.dynamic_adjustment_freq = 8  # More frequent dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.93  # Faster reduction of inertia\n                self.mutation_factor = 0.85 if iteration < self.budget // 2 else 0.65\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced exploration and convergence via adaptive learning coefficients and refined mutation strategy.", "configspace": "", "generation": 24, "fitness": 0.29141972727354315, "feedback": "The algorithm Enhanced_PSO_ADE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.25.", "error": "", "parent_id": "a38bff72-ab4d-4016-8bad-941a89cbfbc9", "metadata": {"aucs": [0.7947021477912579, 0.7947021477912579, 0.7947021477912579, 0.783232972731883, 0.783232972731883, 0.783232972731883, 0.8072234011290801, 0.8072234011290801, 0.8072234011290801, 0.5853833296662505, 0.5853833296662505, 0.5853833296662505, 0.5734852925760598, 0.5734852925760598, 0.5734852925760598, 0.5568091035602212, 0.5568091035602212, 0.5568091035602212, 0.15120236815404764, 0.15120236815404764, 0.15120236815404764, 0.1311871391576287, 0.1311871391576287, 0.1311871391576287, 0.16367554675372398, 0.16367554675372398, 0.16367554675372398, 0.10812678674325615, 0.10812678674325615, 0.10812678674325615, 0.12477704248163335, 0.12477704248163335, 0.12477704248163335, 0.13021608004603313, 0.13021608004603313, 0.13021608004603313, 0.9761060288095031, 0.9761060288095031, 0.9761060288095031, 0.9768591632204007, 0.9768591632204007, 0.9768591632204007, 0.9832368467758372, 0.9832368467758372, 0.9832368467758372, 0.5793882596613283, 0.5793882596613283, 0.5793882596613283, 0.5219445927378839, 0.5219445927378839, 0.5219445927378839, 0.5576326693307558, 0.5576326693307558, 0.5576326693307558, 0.34937799959152704, 0.34937799959152704, 0.34937799959152704, 0.27518673070065003, 0.27518673070065003, 0.27518673070065003, 0.2171228970458079, 0.2171228970458079, 0.2171228970458079, 0.17390029135423024, 0.17390029135423024, 0.17390029135423024, 0.12416293114103338, 0.12416293114103338, 0.12416293114103338, 0.19813190666557734, 0.19813190666557734, 0.19813190666557734, 0.20312623984515898, 0.20312623984515898, 0.20312623984515898, 0.20614415351673265, 0.20614415351673265, 0.20614415351673265, 0.12769325140908805, 0.12769325140908805, 0.12769325140908805, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02897292152154296, 0.02897292152154296, 0.02897292152154296, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11861740605259163, 0.11861740605259163, 0.11861740605259163, 0.04935357209174962, 0.04935357209174962, 0.04935357209174962, 0.043051060987146283, 0.043051060987146283, 0.043051060987146283, 0.0426900996967533, 0.0426900996967533, 0.0426900996967533, 0.21760550746085305, 0.21760550746085305, 0.21760550746085305, 0.11436942015343188, 0.11436942015343188, 0.11436942015343188, 0.11665807080785195, 0.11665807080785195, 0.11665807080785195, 0.03727658626403141, 0.03727658626403141, 0.03727658626403141, 0.09045778385205905, 0.09045778385205905, 0.09045778385205905, 0.5469463693619812, 0.5469463693619812, 0.5469463693619812, 0.5257731287205971, 0.5257731287205971, 0.5257731287205971, 0.5403401264535901, 0.5403401264535901, 0.5403401264535901, 0.08996423855615576, 0.08996423855615576, 0.08996423855615576, 0.16909122375640218, 0.16909122375640218, 0.16909122375640218, 0.12157323969452549, 0.12157323969452549, 0.12157323969452549, 0.21045651444290236, 0.21045651444290236, 0.21045651444290236, 0.2784915510050381, 0.2784915510050381, 0.2784915510050381, 0.3479332686208968, 0.3479332686208968, 0.3479332686208968, 0.31869766639977337, 0.31869766639977337, 0.31869766639977337, 0.4348438012855922, 0.4348438012855922, 0.4348438012855922, 0.4823466501146946, 0.4823466501146946, 0.4823466501146946, 0.2177034797819959, 0.2177034797819959, 0.2177034797819959, 0.32709832302999686, 0.32709832302999686, 0.32709832302999686, 0.25710070600689683, 0.25710070600689683, 0.25710070600689683, 0.1966501488996919, 0.1966501488996919, 0.1966501488996919, 0.20357572184467065, 0.20357572184467065, 0.20357572184467065, 0.192288491821215, 0.192288491821215, 0.192288491821215, 0.20198634722009556, 0.20198634722009556, 0.20198634722009556, 0.23677654538712156, 0.23677654538712156, 0.23677654538712156, 0.2006370022019548, 0.2006370022019548, 0.2006370022019548, 0.8636840043243474, 0.8636840043243474, 0.8636840043243474, 0.16403803121246752, 0.16403803121246752, 0.16403803121246752, 0.16834338090913903, 0.16834338090913903, 0.16834338090913903, 0.20778127271418168, 0.20778127271418168, 0.20778127271418168, 0.20828058216600887, 0.20828058216600887, 0.20828058216600887, 0.15531275752658036, 0.15531275752658036, 0.15531275752658036, 0.197821560340934, 0.197821560340934, 0.197821560340934, 0.19104853104127784, 0.19104853104127784, 0.19104853104127784, 0.19306683509486033, 0.19306683509486033, 0.19306683509486033, 0.09498618828463057, 0.09498618828463057, 0.09498618828463057, 0.0825792188352148, 0.0825792188352148, 0.0825792188352148, 0.1157158551550741, 0.1157158551550741, 0.1157158551550741]}, "mutation_prompt": null}
{"id": "b0f3f988-3c5c-49f5-b28b-82ecd3eee6ae", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 60  # Increased swarm size for more exploration\n        self.mutation_factor = 0.85  # Slightly increased mutation factor\n        self.crossover_prob = 0.95  # Increased crossover probability for exploration\n        self.inertia_weight = 0.4  # Further reduced inertia_weight for quick convergence\n        self.cognitive_coeff = 1.5  # Slightly reduced cognitive_coeff\n        self.social_coeff = 1.5  # Increased social_coeff to boost convergence speed\n        self.dynamic_adjustment_freq = 12  # Changed frequency of dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0  # Initialize iteration counter\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:  # Dynamic parameter adjustment\n                self.inertia_weight *= 0.93  # Gradually reduce inertia more aggressively\n                self.mutation_factor = 0.88 if iteration < self.budget // 3 else 0.75  # Adjust mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1  # Increment iteration counter\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "A strategically diversified PSO-ADE with adaptive exploration-exploitation balance for enhanced convergence.", "configspace": "", "generation": 25, "fitness": 0.2926875372062167, "feedback": "The algorithm Enhanced_PSO_ADE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.26.", "error": "", "parent_id": "a38bff72-ab4d-4016-8bad-941a89cbfbc9", "metadata": {"aucs": [0.8278509105905658, 0.8278509105905658, 0.8278509105905658, 0.8216545666503853, 0.8216545666503853, 0.8216545666503853, 0.8321133782810733, 0.8321133782810733, 0.8321133782810733, 0.5742512803999815, 0.5742512803999815, 0.5742512803999815, 0.601545753981156, 0.601545753981156, 0.601545753981156, 0.016970495593555124, 0.016970495593555124, 0.016970495593555124, 0.16005686356046733, 0.16005686356046733, 0.16005686356046733, 0.16104574147045747, 0.16104574147045747, 0.16104574147045747, 0.12388852383068638, 0.12388852383068638, 0.12388852383068638, 0.10589066451153684, 0.10589066451153684, 0.10589066451153684, 0.10561532640570548, 0.10561532640570548, 0.10561532640570548, 0.10602132542709275, 0.10602132542709275, 0.10602132542709275, 0.9765040124917271, 0.9765040124917271, 0.9765040124917271, 0.9686317129443139, 0.9686317129443139, 0.9686317129443139, 0.9708056960758155, 0.9708056960758155, 0.9708056960758155, 0.5904925189919303, 0.5904925189919303, 0.5904925189919303, 0.5856406132064715, 0.5856406132064715, 0.5856406132064715, 0.5912193966250805, 0.5912193966250805, 0.5912193966250805, 0.321269477896737, 0.321269477896737, 0.321269477896737, 0.2086407057878722, 0.2086407057878722, 0.2086407057878722, 0.22776606708714886, 0.22776606708714886, 0.22776606708714886, 0.20743443708994191, 0.20743443708994191, 0.20743443708994191, 0.19776869512879025, 0.19776869512879025, 0.19776869512879025, 0.18707110217553802, 0.18707110217553802, 0.18707110217553802, 0.12317578055977407, 0.12317578055977407, 0.12317578055977407, 0.2189222022234324, 0.2189222022234324, 0.2189222022234324, 0.1393100818714409, 0.1393100818714409, 0.1393100818714409, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03685209933658895, 0.03685209933658895, 0.03685209933658895, 0.01908910969728328, 0.01908910969728328, 0.01908910969728328, 0.055962524768947364, 0.055962524768947364, 0.055962524768947364, 0.08827208118247565, 0.08827208118247565, 0.08827208118247565, 0.0939337330091059, 0.0939337330091059, 0.0939337330091059, 0.04577200707359019, 0.04577200707359019, 0.04577200707359019, 0.08766009208622327, 0.08766009208622327, 0.08766009208622327, 0.12959411345530314, 0.12959411345530314, 0.12959411345530314, 0.09212904115772436, 0.09212904115772436, 0.09212904115772436, 0.14392146818853002, 0.14392146818853002, 0.14392146818853002, 0.054971776551312135, 0.054971776551312135, 0.054971776551312135, 0.542441496928777, 0.542441496928777, 0.542441496928777, 0.5358816321388193, 0.5358816321388193, 0.5358816321388193, 0.5626299752156749, 0.5626299752156749, 0.5626299752156749, 0.1105909505158783, 0.1105909505158783, 0.1105909505158783, 0.10780872654548634, 0.10780872654548634, 0.10780872654548634, 0.09305703061995207, 0.09305703061995207, 0.09305703061995207, 0.16638590502460116, 0.16638590502460116, 0.16638590502460116, 0.18105459448699202, 0.18105459448699202, 0.18105459448699202, 0.16958753462845721, 0.16958753462845721, 0.16958753462845721, 0.3690845316067618, 0.3690845316067618, 0.3690845316067618, 0.39234115274073134, 0.39234115274073134, 0.39234115274073134, 0.2716366787993919, 0.2716366787993919, 0.2716366787993919, 0.2608742079442572, 0.2608742079442572, 0.2608742079442572, 0.33522673597901753, 0.33522673597901753, 0.33522673597901753, 0.2356490826348927, 0.2356490826348927, 0.2356490826348927, 0.2016300651577384, 0.2016300651577384, 0.2016300651577384, 0.19404326003228067, 0.19404326003228067, 0.19404326003228067, 0.18288343098999016, 0.18288343098999016, 0.18288343098999016, 0.6871964694149607, 0.6871964694149607, 0.6871964694149607, 0.23858244213694602, 0.23858244213694602, 0.23858244213694602, 0.24887412285567712, 0.24887412285567712, 0.24887412285567712, 0.8666036512614166, 0.8666036512614166, 0.8666036512614166, 0.15810709408236923, 0.15810709408236923, 0.15810709408236923, 0.16878208247531312, 0.16878208247531312, 0.16878208247531312, 0.6820165548832064, 0.6820165548832064, 0.6820165548832064, 0.20700102010298016, 0.20700102010298016, 0.20700102010298016, 0.1553603846230175, 0.1553603846230175, 0.1553603846230175, 0.21965972006441947, 0.21965972006441947, 0.21965972006441947, 0.20219797549411522, 0.20219797549411522, 0.20219797549411522, 0.1965192062790294, 0.1965192062790294, 0.1965192062790294, 0.0874075932101891, 0.0874075932101891, 0.0874075932101891, 0.09951271824853614, 0.09951271824853614, 0.09951271824853614, 0.1430592743599698, 0.1430592743599698, 0.1430592743599698]}, "mutation_prompt": null}
{"id": "3fec7d4a-c7ec-4004-ae5b-2becfdcc6e94", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.5  # Reduced inertia_weight for quicker convergence\n        self.cognitive_coeff = 1.7  # Increased cognitive_coeff for more exploration\n        self.social_coeff = 1.3  # Reduced social_coeff to improve diversity\n        self.dynamic_adjustment_freq = 10  # Frequency of dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0  # Initialize iteration counter\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:  # Dynamic parameter adjustment\n                self.inertia_weight *= 0.95  # Gradually reduce inertia\n                self.mutation_factor = 0.9 if iteration < self.budget // 2 else 0.7  # Adjust mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1  # Increment iteration counter\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with dynamic parameter adjustment and improved diversity mechanism for accelerated convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a38bff72-ab4d-4016-8bad-941a89cbfbc9", "metadata": {"aucs": [0.8173532858943607, 0.8173532858943607, 0.8173532858943607, 0.8070665307824119, 0.8070665307824119, 0.8070665307824119, 0.8302027387283974, 0.8302027387283974, 0.8302027387283974, 0.5134322341997061, 0.5134322341997061, 0.5134322341997061, 0.624691263026809, 0.624691263026809, 0.624691263026809, 0.6002980633873294, 0.6002980633873294, 0.6002980633873294, 0.15836040046428224, 0.15836040046428224, 0.15836040046428224, 0.13123216050558661, 0.13123216050558661, 0.13123216050558661, 0.27970106171202114, 0.27970106171202114, 0.27970106171202114, 0.15124280349195118, 0.15124280349195118, 0.15124280349195118, 0.09834124134572031, 0.09834124134572031, 0.09834124134572031, 0.12989604071547778, 0.12989604071547778, 0.12989604071547778, 0.9680695927117464, 0.9680695927117464, 0.9680695927117464, 0.9768501235494804, 0.9768501235494804, 0.9768501235494804, 0.9831477879115976, 0.9831477879115976, 0.9831477879115976, 0.5971319790953125, 0.5971319790953125, 0.5971319790953125, 0.48474815956165695, 0.48474815956165695, 0.48474815956165695, 0.5830104602966175, 0.5830104602966175, 0.5830104602966175, 0.27622022111890565, 0.27622022111890565, 0.27622022111890565, 0.18779824886197094, 0.18779824886197094, 0.18779824886197094, 0.33670363500165723, 0.33670363500165723, 0.33670363500165723, 0.2952862590151156, 0.2952862590151156, 0.2952862590151156, 0.12903284797818992, 0.12903284797818992, 0.12903284797818992, 0.19498986972794174, 0.19498986972794174, 0.19498986972794174, 0.21024770382224844, 0.21024770382224844, 0.21024770382224844, 0.18127758222775825, 0.18127758222775825, 0.18127758222775825, 0.1332413227550654, 0.1332413227550654, 0.1332413227550654, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.000591596660297955, 0.000591596660297955, 0.000591596660297955, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1420256776795833, 0.1420256776795833, 0.1420256776795833, 0.020748106240395137, 0.020748106240395137, 0.020748106240395137, 0.1348851129367975, 0.1348851129367975, 0.1348851129367975, 0.04458903399180836, 0.04458903399180836, 0.04458903399180836, 0.11512893530323998, 0.11512893530323998, 0.11512893530323998, 0.08641355632800374, 0.08641355632800374, 0.08641355632800374, 0.14777383418850298, 0.14777383418850298, 0.14777383418850298, 0.07206563016569412, 0.07206563016569412, 0.07206563016569412, 0.07923642752837845, 0.07923642752837845, 0.07923642752837845, 0.5973585429735873, 0.5973585429735873, 0.5973585429735873, 0.5444614487631158, 0.5444614487631158, 0.5444614487631158, 0.5581596112472851, 0.5581596112472851, 0.5581596112472851, 0.10792836734243372, 0.10792836734243372, 0.10792836734243372, 0.16390282508876686, 0.16390282508876686, 0.16390282508876686, 0.08962551634344096, 0.08962551634344096, 0.08962551634344096, 0.19483029090259651, 0.19483029090259651, 0.19483029090259651, 0.2820278660431219, 0.2820278660431219, 0.2820278660431219, 0.26805499101487307, 0.26805499101487307, 0.26805499101487307, 0.24637636277992703, 0.24637636277992703, 0.24637636277992703, 0.3831050982404137, 0.3831050982404137, 0.3831050982404137, 0.4868095742725873, 0.4868095742725873, 0.4868095742725873, 0.16845536602753763, 0.16845536602753763, 0.16845536602753763, 0.3014920382412615, 0.3014920382412615, 0.3014920382412615, 0.36512925182854294, 0.36512925182854294, 0.36512925182854294, 0.22868397010770147, 0.22868397010770147, 0.22868397010770147, 0.22390362207286474, 0.22390362207286474, 0.22390362207286474, 0.21557387697624797, 0.21557387697624797, 0.21557387697624797, 0.19146581710468058, 0.19146581710468058, 0.19146581710468058, 0.2142825225819227, 0.2142825225819227, 0.2142825225819227, 0.23382031825464455, 0.23382031825464455, 0.23382031825464455, 0.8781972766424274, 0.8781972766424274, 0.8781972766424274, 0.16498904353322907, 0.16498904353322907, 0.16498904353322907, 0.1675048508288941, 0.1675048508288941, 0.1675048508288941, 0.1677930192856908, 0.1677930192856908, 0.1677930192856908, 0.2096363998358497, 0.2096363998358497, 0.2096363998358497, 0.7527906802205094, 0.7527906802205094, 0.7527906802205094, 0.18281873394226333, 0.18281873394226333, 0.18281873394226333, 0.18751703876694603, 0.18751703876694603, 0.18751703876694603, 0.2003195826305778, 0.2003195826305778, 0.2003195826305778, 0.09323489623740366, 0.09323489623740366, 0.09323489623740366, 0.08957474845720703, 0.08957474845720703, 0.08957474845720703, 0.11110056432631477, 0.11110056432631477, 0.11110056432631477]}, "mutation_prompt": null}
{"id": "9ebfa2a7-df9c-4f1f-8e94-e201f12e7161", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.5  # Reduced inertia_weight for quicker convergence\n        self.cognitive_coeff = 1.7  # Increased cognitive_coeff for more exploration\n        self.social_coeff = 1.3  # Reduced social_coeff to improve diversity\n        self.dynamic_adjustment_freq = 10  # Frequency of dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0  # Initialize iteration counter\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:  # Dynamic parameter adjustment\n                self.inertia_weight *= 0.95  # Gradually reduce inertia\n                self.mutation_factor = 0.9 if iteration < self.budget // 2 else 0.7  # Adjust mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1  # Increment iteration counter\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with dynamic parameter adjustment and improved diversity mechanism for accelerated convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a38bff72-ab4d-4016-8bad-941a89cbfbc9", "metadata": {"aucs": [0.8173532858943607, 0.8173532858943607, 0.8173532858943607, 0.8070665307824119, 0.8070665307824119, 0.8070665307824119, 0.8302027387283974, 0.8302027387283974, 0.8302027387283974, 0.5134322341997061, 0.5134322341997061, 0.5134322341997061, 0.624691263026809, 0.624691263026809, 0.624691263026809, 0.6002980633873294, 0.6002980633873294, 0.6002980633873294, 0.15836040046428224, 0.15836040046428224, 0.15836040046428224, 0.13123216050558661, 0.13123216050558661, 0.13123216050558661, 0.27970106171202114, 0.27970106171202114, 0.27970106171202114, 0.15124280349195118, 0.15124280349195118, 0.15124280349195118, 0.09834124134572031, 0.09834124134572031, 0.09834124134572031, 0.12989604071547778, 0.12989604071547778, 0.12989604071547778, 0.9680695927117464, 0.9680695927117464, 0.9680695927117464, 0.9768501235494804, 0.9768501235494804, 0.9768501235494804, 0.9831477879115976, 0.9831477879115976, 0.9831477879115976, 0.5971319790953125, 0.5971319790953125, 0.5971319790953125, 0.48474815956165695, 0.48474815956165695, 0.48474815956165695, 0.5830104602966175, 0.5830104602966175, 0.5830104602966175, 0.27622022111890565, 0.27622022111890565, 0.27622022111890565, 0.18779824886197094, 0.18779824886197094, 0.18779824886197094, 0.33670363500165723, 0.33670363500165723, 0.33670363500165723, 0.2952862590151156, 0.2952862590151156, 0.2952862590151156, 0.12903284797818992, 0.12903284797818992, 0.12903284797818992, 0.19498986972794174, 0.19498986972794174, 0.19498986972794174, 0.21024770382224844, 0.21024770382224844, 0.21024770382224844, 0.18127758222775825, 0.18127758222775825, 0.18127758222775825, 0.1332413227550654, 0.1332413227550654, 0.1332413227550654, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.000591596660297955, 0.000591596660297955, 0.000591596660297955, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1420256776795833, 0.1420256776795833, 0.1420256776795833, 0.020748106240395137, 0.020748106240395137, 0.020748106240395137, 0.1348851129367975, 0.1348851129367975, 0.1348851129367975, 0.04458903399180836, 0.04458903399180836, 0.04458903399180836, 0.11512893530323998, 0.11512893530323998, 0.11512893530323998, 0.08641355632800374, 0.08641355632800374, 0.08641355632800374, 0.14777383418850298, 0.14777383418850298, 0.14777383418850298, 0.07206563016569412, 0.07206563016569412, 0.07206563016569412, 0.07923642752837845, 0.07923642752837845, 0.07923642752837845, 0.5973585429735873, 0.5973585429735873, 0.5973585429735873, 0.5444614487631158, 0.5444614487631158, 0.5444614487631158, 0.5581596112472851, 0.5581596112472851, 0.5581596112472851, 0.10792836734243372, 0.10792836734243372, 0.10792836734243372, 0.16390282508876686, 0.16390282508876686, 0.16390282508876686, 0.08962551634344096, 0.08962551634344096, 0.08962551634344096, 0.19483029090259651, 0.19483029090259651, 0.19483029090259651, 0.2820278660431219, 0.2820278660431219, 0.2820278660431219, 0.26805499101487307, 0.26805499101487307, 0.26805499101487307, 0.24637636277992703, 0.24637636277992703, 0.24637636277992703, 0.3831050982404137, 0.3831050982404137, 0.3831050982404137, 0.4868095742725873, 0.4868095742725873, 0.4868095742725873, 0.16845536602753763, 0.16845536602753763, 0.16845536602753763, 0.3014920382412615, 0.3014920382412615, 0.3014920382412615, 0.36512925182854294, 0.36512925182854294, 0.36512925182854294, 0.22868397010770147, 0.22868397010770147, 0.22868397010770147, 0.22390362207286474, 0.22390362207286474, 0.22390362207286474, 0.21557387697624797, 0.21557387697624797, 0.21557387697624797, 0.19146581710468058, 0.19146581710468058, 0.19146581710468058, 0.2142825225819227, 0.2142825225819227, 0.2142825225819227, 0.23382031825464455, 0.23382031825464455, 0.23382031825464455, 0.8781972766424274, 0.8781972766424274, 0.8781972766424274, 0.16498904353322907, 0.16498904353322907, 0.16498904353322907, 0.1675048508288941, 0.1675048508288941, 0.1675048508288941, 0.1677930192856908, 0.1677930192856908, 0.1677930192856908, 0.2096363998358497, 0.2096363998358497, 0.2096363998358497, 0.7527906802205094, 0.7527906802205094, 0.7527906802205094, 0.18281873394226333, 0.18281873394226333, 0.18281873394226333, 0.18751703876694603, 0.18751703876694603, 0.18751703876694603, 0.2003195826305778, 0.2003195826305778, 0.2003195826305778, 0.09323489623740366, 0.09323489623740366, 0.09323489623740366, 0.08957474845720703, 0.08957474845720703, 0.08957474845720703, 0.11110056432631477, 0.11110056432631477, 0.11110056432631477]}, "mutation_prompt": null}
{"id": "49bc811e-34a6-4fbc-b134-055a83d9ba97", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.5  # Reduced inertia_weight for quicker convergence\n        self.cognitive_coeff = 1.7  # Increased cognitive_coeff for more exploration\n        self.social_coeff = 1.3  # Reduced social_coeff to improve diversity\n        self.dynamic_adjustment_freq = 10  # Frequency of dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0  # Initialize iteration counter\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:  # Dynamic parameter adjustment\n                self.inertia_weight *= 0.95  # Gradually reduce inertia\n                self.mutation_factor = 0.9 if iteration < self.budget // 2 else 0.7  # Adjust mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1  # Increment iteration counter\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with dynamic parameter adjustment and improved diversity mechanism for accelerated convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a38bff72-ab4d-4016-8bad-941a89cbfbc9", "metadata": {"aucs": [0.8173532858943607, 0.8173532858943607, 0.8173532858943607, 0.8070665307824119, 0.8070665307824119, 0.8070665307824119, 0.8302027387283974, 0.8302027387283974, 0.8302027387283974, 0.5134322341997061, 0.5134322341997061, 0.5134322341997061, 0.624691263026809, 0.624691263026809, 0.624691263026809, 0.6002980633873294, 0.6002980633873294, 0.6002980633873294, 0.15836040046428224, 0.15836040046428224, 0.15836040046428224, 0.13123216050558661, 0.13123216050558661, 0.13123216050558661, 0.27970106171202114, 0.27970106171202114, 0.27970106171202114, 0.15124280349195118, 0.15124280349195118, 0.15124280349195118, 0.09834124134572031, 0.09834124134572031, 0.09834124134572031, 0.12989604071547778, 0.12989604071547778, 0.12989604071547778, 0.9680695927117464, 0.9680695927117464, 0.9680695927117464, 0.9768501235494804, 0.9768501235494804, 0.9768501235494804, 0.9831477879115976, 0.9831477879115976, 0.9831477879115976, 0.5971319790953125, 0.5971319790953125, 0.5971319790953125, 0.48474815956165695, 0.48474815956165695, 0.48474815956165695, 0.5830104602966175, 0.5830104602966175, 0.5830104602966175, 0.27622022111890565, 0.27622022111890565, 0.27622022111890565, 0.18779824886197094, 0.18779824886197094, 0.18779824886197094, 0.33670363500165723, 0.33670363500165723, 0.33670363500165723, 0.2952862590151156, 0.2952862590151156, 0.2952862590151156, 0.12903284797818992, 0.12903284797818992, 0.12903284797818992, 0.19498986972794174, 0.19498986972794174, 0.19498986972794174, 0.21024770382224844, 0.21024770382224844, 0.21024770382224844, 0.18127758222775825, 0.18127758222775825, 0.18127758222775825, 0.1332413227550654, 0.1332413227550654, 0.1332413227550654, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.000591596660297955, 0.000591596660297955, 0.000591596660297955, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1420256776795833, 0.1420256776795833, 0.1420256776795833, 0.020748106240395137, 0.020748106240395137, 0.020748106240395137, 0.1348851129367975, 0.1348851129367975, 0.1348851129367975, 0.04458903399180836, 0.04458903399180836, 0.04458903399180836, 0.11512893530323998, 0.11512893530323998, 0.11512893530323998, 0.08641355632800374, 0.08641355632800374, 0.08641355632800374, 0.14777383418850298, 0.14777383418850298, 0.14777383418850298, 0.07206563016569412, 0.07206563016569412, 0.07206563016569412, 0.07923642752837845, 0.07923642752837845, 0.07923642752837845, 0.5973585429735873, 0.5973585429735873, 0.5973585429735873, 0.5444614487631158, 0.5444614487631158, 0.5444614487631158, 0.5581596112472851, 0.5581596112472851, 0.5581596112472851, 0.10792836734243372, 0.10792836734243372, 0.10792836734243372, 0.16390282508876686, 0.16390282508876686, 0.16390282508876686, 0.08962551634344096, 0.08962551634344096, 0.08962551634344096, 0.19483029090259651, 0.19483029090259651, 0.19483029090259651, 0.2820278660431219, 0.2820278660431219, 0.2820278660431219, 0.26805499101487307, 0.26805499101487307, 0.26805499101487307, 0.24637636277992703, 0.24637636277992703, 0.24637636277992703, 0.3831050982404137, 0.3831050982404137, 0.3831050982404137, 0.4868095742725873, 0.4868095742725873, 0.4868095742725873, 0.16845536602753763, 0.16845536602753763, 0.16845536602753763, 0.3014920382412615, 0.3014920382412615, 0.3014920382412615, 0.36512925182854294, 0.36512925182854294, 0.36512925182854294, 0.22868397010770147, 0.22868397010770147, 0.22868397010770147, 0.22390362207286474, 0.22390362207286474, 0.22390362207286474, 0.21557387697624797, 0.21557387697624797, 0.21557387697624797, 0.19146581710468058, 0.19146581710468058, 0.19146581710468058, 0.2142825225819227, 0.2142825225819227, 0.2142825225819227, 0.23382031825464455, 0.23382031825464455, 0.23382031825464455, 0.8781972766424274, 0.8781972766424274, 0.8781972766424274, 0.16498904353322907, 0.16498904353322907, 0.16498904353322907, 0.1675048508288941, 0.1675048508288941, 0.1675048508288941, 0.1677930192856908, 0.1677930192856908, 0.1677930192856908, 0.2096363998358497, 0.2096363998358497, 0.2096363998358497, 0.7527906802205094, 0.7527906802205094, 0.7527906802205094, 0.18281873394226333, 0.18281873394226333, 0.18281873394226333, 0.18751703876694603, 0.18751703876694603, 0.18751703876694603, 0.2003195826305778, 0.2003195826305778, 0.2003195826305778, 0.09323489623740366, 0.09323489623740366, 0.09323489623740366, 0.08957474845720703, 0.08957474845720703, 0.08957474845720703, 0.11110056432631477, 0.11110056432631477, 0.11110056432631477]}, "mutation_prompt": null}
{"id": "c9a6d7fe-dad6-4a85-919d-e7fbe2958076", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.5  # Reduced inertia_weight for quicker convergence\n        self.cognitive_coeff = 1.7  # Increased cognitive_coeff for more exploration\n        self.social_coeff = 1.3  # Reduced social_coeff to improve diversity\n        self.dynamic_adjustment_freq = 10  # Frequency of dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0  # Initialize iteration counter\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:  # Dynamic parameter adjustment\n                self.inertia_weight *= 0.95  # Gradually reduce inertia\n                self.mutation_factor = 0.9 if iteration < self.budget // 2 else 0.7  # Adjust mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1  # Increment iteration counter\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with dynamic parameter adjustment and improved diversity mechanism for accelerated convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a38bff72-ab4d-4016-8bad-941a89cbfbc9", "metadata": {"aucs": [0.8173532858943607, 0.8173532858943607, 0.8173532858943607, 0.8070665307824119, 0.8070665307824119, 0.8070665307824119, 0.8302027387283974, 0.8302027387283974, 0.8302027387283974, 0.5134322341997061, 0.5134322341997061, 0.5134322341997061, 0.624691263026809, 0.624691263026809, 0.624691263026809, 0.6002980633873294, 0.6002980633873294, 0.6002980633873294, 0.15836040046428224, 0.15836040046428224, 0.15836040046428224, 0.13123216050558661, 0.13123216050558661, 0.13123216050558661, 0.27970106171202114, 0.27970106171202114, 0.27970106171202114, 0.15124280349195118, 0.15124280349195118, 0.15124280349195118, 0.09834124134572031, 0.09834124134572031, 0.09834124134572031, 0.12989604071547778, 0.12989604071547778, 0.12989604071547778, 0.9680695927117464, 0.9680695927117464, 0.9680695927117464, 0.9768501235494804, 0.9768501235494804, 0.9768501235494804, 0.9831477879115976, 0.9831477879115976, 0.9831477879115976, 0.5971319790953125, 0.5971319790953125, 0.5971319790953125, 0.48474815956165695, 0.48474815956165695, 0.48474815956165695, 0.5830104602966175, 0.5830104602966175, 0.5830104602966175, 0.27622022111890565, 0.27622022111890565, 0.27622022111890565, 0.18779824886197094, 0.18779824886197094, 0.18779824886197094, 0.33670363500165723, 0.33670363500165723, 0.33670363500165723, 0.2952862590151156, 0.2952862590151156, 0.2952862590151156, 0.12903284797818992, 0.12903284797818992, 0.12903284797818992, 0.19498986972794174, 0.19498986972794174, 0.19498986972794174, 0.21024770382224844, 0.21024770382224844, 0.21024770382224844, 0.18127758222775825, 0.18127758222775825, 0.18127758222775825, 0.1332413227550654, 0.1332413227550654, 0.1332413227550654, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.000591596660297955, 0.000591596660297955, 0.000591596660297955, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1420256776795833, 0.1420256776795833, 0.1420256776795833, 0.020748106240395137, 0.020748106240395137, 0.020748106240395137, 0.1348851129367975, 0.1348851129367975, 0.1348851129367975, 0.04458903399180836, 0.04458903399180836, 0.04458903399180836, 0.11512893530323998, 0.11512893530323998, 0.11512893530323998, 0.08641355632800374, 0.08641355632800374, 0.08641355632800374, 0.14777383418850298, 0.14777383418850298, 0.14777383418850298, 0.07206563016569412, 0.07206563016569412, 0.07206563016569412, 0.07923642752837845, 0.07923642752837845, 0.07923642752837845, 0.5973585429735873, 0.5973585429735873, 0.5973585429735873, 0.5444614487631158, 0.5444614487631158, 0.5444614487631158, 0.5581596112472851, 0.5581596112472851, 0.5581596112472851, 0.10792836734243372, 0.10792836734243372, 0.10792836734243372, 0.16390282508876686, 0.16390282508876686, 0.16390282508876686, 0.08962551634344096, 0.08962551634344096, 0.08962551634344096, 0.19483029090259651, 0.19483029090259651, 0.19483029090259651, 0.2820278660431219, 0.2820278660431219, 0.2820278660431219, 0.26805499101487307, 0.26805499101487307, 0.26805499101487307, 0.24637636277992703, 0.24637636277992703, 0.24637636277992703, 0.3831050982404137, 0.3831050982404137, 0.3831050982404137, 0.4868095742725873, 0.4868095742725873, 0.4868095742725873, 0.16845536602753763, 0.16845536602753763, 0.16845536602753763, 0.3014920382412615, 0.3014920382412615, 0.3014920382412615, 0.36512925182854294, 0.36512925182854294, 0.36512925182854294, 0.22868397010770147, 0.22868397010770147, 0.22868397010770147, 0.22390362207286474, 0.22390362207286474, 0.22390362207286474, 0.21557387697624797, 0.21557387697624797, 0.21557387697624797, 0.19146581710468058, 0.19146581710468058, 0.19146581710468058, 0.2142825225819227, 0.2142825225819227, 0.2142825225819227, 0.23382031825464455, 0.23382031825464455, 0.23382031825464455, 0.8781972766424274, 0.8781972766424274, 0.8781972766424274, 0.16498904353322907, 0.16498904353322907, 0.16498904353322907, 0.1675048508288941, 0.1675048508288941, 0.1675048508288941, 0.1677930192856908, 0.1677930192856908, 0.1677930192856908, 0.2096363998358497, 0.2096363998358497, 0.2096363998358497, 0.7527906802205094, 0.7527906802205094, 0.7527906802205094, 0.18281873394226333, 0.18281873394226333, 0.18281873394226333, 0.18751703876694603, 0.18751703876694603, 0.18751703876694603, 0.2003195826305778, 0.2003195826305778, 0.2003195826305778, 0.09323489623740366, 0.09323489623740366, 0.09323489623740366, 0.08957474845720703, 0.08957474845720703, 0.08957474845720703, 0.11110056432631477, 0.11110056432631477, 0.11110056432631477]}, "mutation_prompt": null}
{"id": "7d463737-99b5-41c4-a06b-178d5e96c8d8", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.5  # Reduced inertia_weight for quicker convergence\n        self.cognitive_coeff = 1.7  # Increased cognitive_coeff for more exploration\n        self.social_coeff = 1.3  # Reduced social_coeff to improve diversity\n        self.dynamic_adjustment_freq = 10  # Frequency of dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0  # Initialize iteration counter\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:  # Dynamic parameter adjustment\n                self.inertia_weight *= 0.95  # Gradually reduce inertia\n                self.mutation_factor = 0.9 if iteration < self.budget // 2 else 0.7  # Adjust mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1  # Increment iteration counter\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with dynamic parameter adjustment and improved diversity mechanism for accelerated convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a38bff72-ab4d-4016-8bad-941a89cbfbc9", "metadata": {"aucs": [0.8173532858943607, 0.8173532858943607, 0.8173532858943607, 0.8070665307824119, 0.8070665307824119, 0.8070665307824119, 0.8302027387283974, 0.8302027387283974, 0.8302027387283974, 0.5134322341997061, 0.5134322341997061, 0.5134322341997061, 0.624691263026809, 0.624691263026809, 0.624691263026809, 0.6002980633873294, 0.6002980633873294, 0.6002980633873294, 0.15836040046428224, 0.15836040046428224, 0.15836040046428224, 0.13123216050558661, 0.13123216050558661, 0.13123216050558661, 0.27970106171202114, 0.27970106171202114, 0.27970106171202114, 0.15124280349195118, 0.15124280349195118, 0.15124280349195118, 0.09834124134572031, 0.09834124134572031, 0.09834124134572031, 0.12989604071547778, 0.12989604071547778, 0.12989604071547778, 0.9680695927117464, 0.9680695927117464, 0.9680695927117464, 0.9768501235494804, 0.9768501235494804, 0.9768501235494804, 0.9831477879115976, 0.9831477879115976, 0.9831477879115976, 0.5971319790953125, 0.5971319790953125, 0.5971319790953125, 0.48474815956165695, 0.48474815956165695, 0.48474815956165695, 0.5830104602966175, 0.5830104602966175, 0.5830104602966175, 0.27622022111890565, 0.27622022111890565, 0.27622022111890565, 0.18779824886197094, 0.18779824886197094, 0.18779824886197094, 0.33670363500165723, 0.33670363500165723, 0.33670363500165723, 0.2952862590151156, 0.2952862590151156, 0.2952862590151156, 0.12903284797818992, 0.12903284797818992, 0.12903284797818992, 0.19498986972794174, 0.19498986972794174, 0.19498986972794174, 0.21024770382224844, 0.21024770382224844, 0.21024770382224844, 0.18127758222775825, 0.18127758222775825, 0.18127758222775825, 0.1332413227550654, 0.1332413227550654, 0.1332413227550654, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.000591596660297955, 0.000591596660297955, 0.000591596660297955, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1420256776795833, 0.1420256776795833, 0.1420256776795833, 0.020748106240395137, 0.020748106240395137, 0.020748106240395137, 0.1348851129367975, 0.1348851129367975, 0.1348851129367975, 0.04458903399180836, 0.04458903399180836, 0.04458903399180836, 0.11512893530323998, 0.11512893530323998, 0.11512893530323998, 0.08641355632800374, 0.08641355632800374, 0.08641355632800374, 0.14777383418850298, 0.14777383418850298, 0.14777383418850298, 0.07206563016569412, 0.07206563016569412, 0.07206563016569412, 0.07923642752837845, 0.07923642752837845, 0.07923642752837845, 0.5973585429735873, 0.5973585429735873, 0.5973585429735873, 0.5444614487631158, 0.5444614487631158, 0.5444614487631158, 0.5581596112472851, 0.5581596112472851, 0.5581596112472851, 0.10792836734243372, 0.10792836734243372, 0.10792836734243372, 0.16390282508876686, 0.16390282508876686, 0.16390282508876686, 0.08962551634344096, 0.08962551634344096, 0.08962551634344096, 0.19483029090259651, 0.19483029090259651, 0.19483029090259651, 0.2820278660431219, 0.2820278660431219, 0.2820278660431219, 0.26805499101487307, 0.26805499101487307, 0.26805499101487307, 0.24637636277992703, 0.24637636277992703, 0.24637636277992703, 0.3831050982404137, 0.3831050982404137, 0.3831050982404137, 0.4868095742725873, 0.4868095742725873, 0.4868095742725873, 0.16845536602753763, 0.16845536602753763, 0.16845536602753763, 0.3014920382412615, 0.3014920382412615, 0.3014920382412615, 0.36512925182854294, 0.36512925182854294, 0.36512925182854294, 0.22868397010770147, 0.22868397010770147, 0.22868397010770147, 0.22390362207286474, 0.22390362207286474, 0.22390362207286474, 0.21557387697624797, 0.21557387697624797, 0.21557387697624797, 0.19146581710468058, 0.19146581710468058, 0.19146581710468058, 0.2142825225819227, 0.2142825225819227, 0.2142825225819227, 0.23382031825464455, 0.23382031825464455, 0.23382031825464455, 0.8781972766424274, 0.8781972766424274, 0.8781972766424274, 0.16498904353322907, 0.16498904353322907, 0.16498904353322907, 0.1675048508288941, 0.1675048508288941, 0.1675048508288941, 0.1677930192856908, 0.1677930192856908, 0.1677930192856908, 0.2096363998358497, 0.2096363998358497, 0.2096363998358497, 0.7527906802205094, 0.7527906802205094, 0.7527906802205094, 0.18281873394226333, 0.18281873394226333, 0.18281873394226333, 0.18751703876694603, 0.18751703876694603, 0.18751703876694603, 0.2003195826305778, 0.2003195826305778, 0.2003195826305778, 0.09323489623740366, 0.09323489623740366, 0.09323489623740366, 0.08957474845720703, 0.08957474845720703, 0.08957474845720703, 0.11110056432631477, 0.11110056432631477, 0.11110056432631477]}, "mutation_prompt": null}
{"id": "2d807236-21fe-4c4e-9ccc-5e76e158ce18", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.5  # Reduced inertia_weight for quicker convergence\n        self.cognitive_coeff = 1.7  # Increased cognitive_coeff for more exploration\n        self.social_coeff = 1.3  # Reduced social_coeff to improve diversity\n        self.dynamic_adjustment_freq = 10  # Frequency of dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0  # Initialize iteration counter\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:  # Dynamic parameter adjustment\n                self.inertia_weight *= 0.95  # Gradually reduce inertia\n                self.mutation_factor = 0.9 if iteration < self.budget // 2 else 0.7  # Adjust mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1  # Increment iteration counter\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with dynamic parameter adjustment and improved diversity mechanism for accelerated convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a38bff72-ab4d-4016-8bad-941a89cbfbc9", "metadata": {"aucs": [0.8173532858943607, 0.8173532858943607, 0.8173532858943607, 0.8070665307824119, 0.8070665307824119, 0.8070665307824119, 0.8302027387283974, 0.8302027387283974, 0.8302027387283974, 0.5134322341997061, 0.5134322341997061, 0.5134322341997061, 0.624691263026809, 0.624691263026809, 0.624691263026809, 0.6002980633873294, 0.6002980633873294, 0.6002980633873294, 0.15836040046428224, 0.15836040046428224, 0.15836040046428224, 0.13123216050558661, 0.13123216050558661, 0.13123216050558661, 0.27970106171202114, 0.27970106171202114, 0.27970106171202114, 0.15124280349195118, 0.15124280349195118, 0.15124280349195118, 0.09834124134572031, 0.09834124134572031, 0.09834124134572031, 0.12989604071547778, 0.12989604071547778, 0.12989604071547778, 0.9680695927117464, 0.9680695927117464, 0.9680695927117464, 0.9768501235494804, 0.9768501235494804, 0.9768501235494804, 0.9831477879115976, 0.9831477879115976, 0.9831477879115976, 0.5971319790953125, 0.5971319790953125, 0.5971319790953125, 0.48474815956165695, 0.48474815956165695, 0.48474815956165695, 0.5830104602966175, 0.5830104602966175, 0.5830104602966175, 0.27622022111890565, 0.27622022111890565, 0.27622022111890565, 0.18779824886197094, 0.18779824886197094, 0.18779824886197094, 0.33670363500165723, 0.33670363500165723, 0.33670363500165723, 0.2952862590151156, 0.2952862590151156, 0.2952862590151156, 0.12903284797818992, 0.12903284797818992, 0.12903284797818992, 0.19498986972794174, 0.19498986972794174, 0.19498986972794174, 0.21024770382224844, 0.21024770382224844, 0.21024770382224844, 0.18127758222775825, 0.18127758222775825, 0.18127758222775825, 0.1332413227550654, 0.1332413227550654, 0.1332413227550654, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.000591596660297955, 0.000591596660297955, 0.000591596660297955, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1420256776795833, 0.1420256776795833, 0.1420256776795833, 0.020748106240395137, 0.020748106240395137, 0.020748106240395137, 0.1348851129367975, 0.1348851129367975, 0.1348851129367975, 0.04458903399180836, 0.04458903399180836, 0.04458903399180836, 0.11512893530323998, 0.11512893530323998, 0.11512893530323998, 0.08641355632800374, 0.08641355632800374, 0.08641355632800374, 0.14777383418850298, 0.14777383418850298, 0.14777383418850298, 0.07206563016569412, 0.07206563016569412, 0.07206563016569412, 0.07923642752837845, 0.07923642752837845, 0.07923642752837845, 0.5973585429735873, 0.5973585429735873, 0.5973585429735873, 0.5444614487631158, 0.5444614487631158, 0.5444614487631158, 0.5581596112472851, 0.5581596112472851, 0.5581596112472851, 0.10792836734243372, 0.10792836734243372, 0.10792836734243372, 0.16390282508876686, 0.16390282508876686, 0.16390282508876686, 0.08962551634344096, 0.08962551634344096, 0.08962551634344096, 0.19483029090259651, 0.19483029090259651, 0.19483029090259651, 0.2820278660431219, 0.2820278660431219, 0.2820278660431219, 0.26805499101487307, 0.26805499101487307, 0.26805499101487307, 0.24637636277992703, 0.24637636277992703, 0.24637636277992703, 0.3831050982404137, 0.3831050982404137, 0.3831050982404137, 0.4868095742725873, 0.4868095742725873, 0.4868095742725873, 0.16845536602753763, 0.16845536602753763, 0.16845536602753763, 0.3014920382412615, 0.3014920382412615, 0.3014920382412615, 0.36512925182854294, 0.36512925182854294, 0.36512925182854294, 0.22868397010770147, 0.22868397010770147, 0.22868397010770147, 0.22390362207286474, 0.22390362207286474, 0.22390362207286474, 0.21557387697624797, 0.21557387697624797, 0.21557387697624797, 0.19146581710468058, 0.19146581710468058, 0.19146581710468058, 0.2142825225819227, 0.2142825225819227, 0.2142825225819227, 0.23382031825464455, 0.23382031825464455, 0.23382031825464455, 0.8781972766424274, 0.8781972766424274, 0.8781972766424274, 0.16498904353322907, 0.16498904353322907, 0.16498904353322907, 0.1675048508288941, 0.1675048508288941, 0.1675048508288941, 0.1677930192856908, 0.1677930192856908, 0.1677930192856908, 0.2096363998358497, 0.2096363998358497, 0.2096363998358497, 0.7527906802205094, 0.7527906802205094, 0.7527906802205094, 0.18281873394226333, 0.18281873394226333, 0.18281873394226333, 0.18751703876694603, 0.18751703876694603, 0.18751703876694603, 0.2003195826305778, 0.2003195826305778, 0.2003195826305778, 0.09323489623740366, 0.09323489623740366, 0.09323489623740366, 0.08957474845720703, 0.08957474845720703, 0.08957474845720703, 0.11110056432631477, 0.11110056432631477, 0.11110056432631477]}, "mutation_prompt": null}
{"id": "3428b8a7-0971-4395-9176-0eeff5510bc3", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.5  # Reduced inertia_weight for quicker convergence\n        self.cognitive_coeff = 1.7  # Increased cognitive_coeff for more exploration\n        self.social_coeff = 1.3  # Reduced social_coeff to improve diversity\n        self.dynamic_adjustment_freq = 10  # Frequency of dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0  # Initialize iteration counter\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:  # Dynamic parameter adjustment\n                self.inertia_weight *= 0.95  # Gradually reduce inertia\n                self.mutation_factor = 0.9 if iteration < self.budget // 2 else 0.7  # Adjust mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1  # Increment iteration counter\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with dynamic parameter adjustment and improved diversity mechanism for accelerated convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a38bff72-ab4d-4016-8bad-941a89cbfbc9", "metadata": {"aucs": [0.8173532858943607, 0.8173532858943607, 0.8173532858943607, 0.8070665307824119, 0.8070665307824119, 0.8070665307824119, 0.8302027387283974, 0.8302027387283974, 0.8302027387283974, 0.5134322341997061, 0.5134322341997061, 0.5134322341997061, 0.624691263026809, 0.624691263026809, 0.624691263026809, 0.6002980633873294, 0.6002980633873294, 0.6002980633873294, 0.15836040046428224, 0.15836040046428224, 0.15836040046428224, 0.13123216050558661, 0.13123216050558661, 0.13123216050558661, 0.27970106171202114, 0.27970106171202114, 0.27970106171202114, 0.15124280349195118, 0.15124280349195118, 0.15124280349195118, 0.09834124134572031, 0.09834124134572031, 0.09834124134572031, 0.12989604071547778, 0.12989604071547778, 0.12989604071547778, 0.9680695927117464, 0.9680695927117464, 0.9680695927117464, 0.9768501235494804, 0.9768501235494804, 0.9768501235494804, 0.9831477879115976, 0.9831477879115976, 0.9831477879115976, 0.5971319790953125, 0.5971319790953125, 0.5971319790953125, 0.48474815956165695, 0.48474815956165695, 0.48474815956165695, 0.5830104602966175, 0.5830104602966175, 0.5830104602966175, 0.27622022111890565, 0.27622022111890565, 0.27622022111890565, 0.18779824886197094, 0.18779824886197094, 0.18779824886197094, 0.33670363500165723, 0.33670363500165723, 0.33670363500165723, 0.2952862590151156, 0.2952862590151156, 0.2952862590151156, 0.12903284797818992, 0.12903284797818992, 0.12903284797818992, 0.19498986972794174, 0.19498986972794174, 0.19498986972794174, 0.21024770382224844, 0.21024770382224844, 0.21024770382224844, 0.18127758222775825, 0.18127758222775825, 0.18127758222775825, 0.1332413227550654, 0.1332413227550654, 0.1332413227550654, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.000591596660297955, 0.000591596660297955, 0.000591596660297955, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1420256776795833, 0.1420256776795833, 0.1420256776795833, 0.020748106240395137, 0.020748106240395137, 0.020748106240395137, 0.1348851129367975, 0.1348851129367975, 0.1348851129367975, 0.04458903399180836, 0.04458903399180836, 0.04458903399180836, 0.11512893530323998, 0.11512893530323998, 0.11512893530323998, 0.08641355632800374, 0.08641355632800374, 0.08641355632800374, 0.14777383418850298, 0.14777383418850298, 0.14777383418850298, 0.07206563016569412, 0.07206563016569412, 0.07206563016569412, 0.07923642752837845, 0.07923642752837845, 0.07923642752837845, 0.5973585429735873, 0.5973585429735873, 0.5973585429735873, 0.5444614487631158, 0.5444614487631158, 0.5444614487631158, 0.5581596112472851, 0.5581596112472851, 0.5581596112472851, 0.10792836734243372, 0.10792836734243372, 0.10792836734243372, 0.16390282508876686, 0.16390282508876686, 0.16390282508876686, 0.08962551634344096, 0.08962551634344096, 0.08962551634344096, 0.19483029090259651, 0.19483029090259651, 0.19483029090259651, 0.2820278660431219, 0.2820278660431219, 0.2820278660431219, 0.26805499101487307, 0.26805499101487307, 0.26805499101487307, 0.24637636277992703, 0.24637636277992703, 0.24637636277992703, 0.3831050982404137, 0.3831050982404137, 0.3831050982404137, 0.4868095742725873, 0.4868095742725873, 0.4868095742725873, 0.16845536602753763, 0.16845536602753763, 0.16845536602753763, 0.3014920382412615, 0.3014920382412615, 0.3014920382412615, 0.36512925182854294, 0.36512925182854294, 0.36512925182854294, 0.22868397010770147, 0.22868397010770147, 0.22868397010770147, 0.22390362207286474, 0.22390362207286474, 0.22390362207286474, 0.21557387697624797, 0.21557387697624797, 0.21557387697624797, 0.19146581710468058, 0.19146581710468058, 0.19146581710468058, 0.2142825225819227, 0.2142825225819227, 0.2142825225819227, 0.23382031825464455, 0.23382031825464455, 0.23382031825464455, 0.8781972766424274, 0.8781972766424274, 0.8781972766424274, 0.16498904353322907, 0.16498904353322907, 0.16498904353322907, 0.1675048508288941, 0.1675048508288941, 0.1675048508288941, 0.1677930192856908, 0.1677930192856908, 0.1677930192856908, 0.2096363998358497, 0.2096363998358497, 0.2096363998358497, 0.7527906802205094, 0.7527906802205094, 0.7527906802205094, 0.18281873394226333, 0.18281873394226333, 0.18281873394226333, 0.18751703876694603, 0.18751703876694603, 0.18751703876694603, 0.2003195826305778, 0.2003195826305778, 0.2003195826305778, 0.09323489623740366, 0.09323489623740366, 0.09323489623740366, 0.08957474845720703, 0.08957474845720703, 0.08957474845720703, 0.11110056432631477, 0.11110056432631477, 0.11110056432631477]}, "mutation_prompt": null}
{"id": "532a7688-2899-4a2b-a6e7-048c9bbef685", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.5  # Reduced inertia_weight for quicker convergence\n        self.cognitive_coeff = 1.7  # Increased cognitive_coeff for more exploration\n        self.social_coeff = 1.3  # Reduced social_coeff to improve diversity\n        self.dynamic_adjustment_freq = 10  # Frequency of dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0  # Initialize iteration counter\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:  # Dynamic parameter adjustment\n                self.inertia_weight *= 0.95  # Gradually reduce inertia\n                self.mutation_factor = 0.9 if iteration < self.budget // 2 else 0.7  # Adjust mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1  # Increment iteration counter\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with dynamic parameter adjustment and improved diversity mechanism for accelerated convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a38bff72-ab4d-4016-8bad-941a89cbfbc9", "metadata": {"aucs": [0.8173532858943607, 0.8173532858943607, 0.8173532858943607, 0.8070665307824119, 0.8070665307824119, 0.8070665307824119, 0.8302027387283974, 0.8302027387283974, 0.8302027387283974, 0.5134322341997061, 0.5134322341997061, 0.5134322341997061, 0.624691263026809, 0.624691263026809, 0.624691263026809, 0.6002980633873294, 0.6002980633873294, 0.6002980633873294, 0.15836040046428224, 0.15836040046428224, 0.15836040046428224, 0.13123216050558661, 0.13123216050558661, 0.13123216050558661, 0.27970106171202114, 0.27970106171202114, 0.27970106171202114, 0.15124280349195118, 0.15124280349195118, 0.15124280349195118, 0.09834124134572031, 0.09834124134572031, 0.09834124134572031, 0.12989604071547778, 0.12989604071547778, 0.12989604071547778, 0.9680695927117464, 0.9680695927117464, 0.9680695927117464, 0.9768501235494804, 0.9768501235494804, 0.9768501235494804, 0.9831477879115976, 0.9831477879115976, 0.9831477879115976, 0.5971319790953125, 0.5971319790953125, 0.5971319790953125, 0.48474815956165695, 0.48474815956165695, 0.48474815956165695, 0.5830104602966175, 0.5830104602966175, 0.5830104602966175, 0.27622022111890565, 0.27622022111890565, 0.27622022111890565, 0.18779824886197094, 0.18779824886197094, 0.18779824886197094, 0.33670363500165723, 0.33670363500165723, 0.33670363500165723, 0.2952862590151156, 0.2952862590151156, 0.2952862590151156, 0.12903284797818992, 0.12903284797818992, 0.12903284797818992, 0.19498986972794174, 0.19498986972794174, 0.19498986972794174, 0.21024770382224844, 0.21024770382224844, 0.21024770382224844, 0.18127758222775825, 0.18127758222775825, 0.18127758222775825, 0.1332413227550654, 0.1332413227550654, 0.1332413227550654, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.000591596660297955, 0.000591596660297955, 0.000591596660297955, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1420256776795833, 0.1420256776795833, 0.1420256776795833, 0.020748106240395137, 0.020748106240395137, 0.020748106240395137, 0.1348851129367975, 0.1348851129367975, 0.1348851129367975, 0.04458903399180836, 0.04458903399180836, 0.04458903399180836, 0.11512893530323998, 0.11512893530323998, 0.11512893530323998, 0.08641355632800374, 0.08641355632800374, 0.08641355632800374, 0.14777383418850298, 0.14777383418850298, 0.14777383418850298, 0.07206563016569412, 0.07206563016569412, 0.07206563016569412, 0.07923642752837845, 0.07923642752837845, 0.07923642752837845, 0.5973585429735873, 0.5973585429735873, 0.5973585429735873, 0.5444614487631158, 0.5444614487631158, 0.5444614487631158, 0.5581596112472851, 0.5581596112472851, 0.5581596112472851, 0.10792836734243372, 0.10792836734243372, 0.10792836734243372, 0.16390282508876686, 0.16390282508876686, 0.16390282508876686, 0.08962551634344096, 0.08962551634344096, 0.08962551634344096, 0.19483029090259651, 0.19483029090259651, 0.19483029090259651, 0.2820278660431219, 0.2820278660431219, 0.2820278660431219, 0.26805499101487307, 0.26805499101487307, 0.26805499101487307, 0.24637636277992703, 0.24637636277992703, 0.24637636277992703, 0.3831050982404137, 0.3831050982404137, 0.3831050982404137, 0.4868095742725873, 0.4868095742725873, 0.4868095742725873, 0.16845536602753763, 0.16845536602753763, 0.16845536602753763, 0.3014920382412615, 0.3014920382412615, 0.3014920382412615, 0.36512925182854294, 0.36512925182854294, 0.36512925182854294, 0.22868397010770147, 0.22868397010770147, 0.22868397010770147, 0.22390362207286474, 0.22390362207286474, 0.22390362207286474, 0.21557387697624797, 0.21557387697624797, 0.21557387697624797, 0.19146581710468058, 0.19146581710468058, 0.19146581710468058, 0.2142825225819227, 0.2142825225819227, 0.2142825225819227, 0.23382031825464455, 0.23382031825464455, 0.23382031825464455, 0.8781972766424274, 0.8781972766424274, 0.8781972766424274, 0.16498904353322907, 0.16498904353322907, 0.16498904353322907, 0.1675048508288941, 0.1675048508288941, 0.1675048508288941, 0.1677930192856908, 0.1677930192856908, 0.1677930192856908, 0.2096363998358497, 0.2096363998358497, 0.2096363998358497, 0.7527906802205094, 0.7527906802205094, 0.7527906802205094, 0.18281873394226333, 0.18281873394226333, 0.18281873394226333, 0.18751703876694603, 0.18751703876694603, 0.18751703876694603, 0.2003195826305778, 0.2003195826305778, 0.2003195826305778, 0.09323489623740366, 0.09323489623740366, 0.09323489623740366, 0.08957474845720703, 0.08957474845720703, 0.08957474845720703, 0.11110056432631477, 0.11110056432631477, 0.11110056432631477]}, "mutation_prompt": null}
{"id": "e89634f6-49c9-48b9-a80c-322149fdaf7f", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.5  # Reduced inertia_weight for quicker convergence\n        self.cognitive_coeff = 1.7  # Increased cognitive_coeff for more exploration\n        self.social_coeff = 1.3  # Reduced social_coeff to improve diversity\n        self.dynamic_adjustment_freq = 10  # Frequency of dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0  # Initialize iteration counter\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:  # Dynamic parameter adjustment\n                self.inertia_weight *= 0.95  # Gradually reduce inertia\n                self.mutation_factor = 0.9 if iteration < self.budget // 2 else 0.7  # Adjust mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1  # Increment iteration counter\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with dynamic parameter adjustment and improved diversity mechanism for accelerated convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a38bff72-ab4d-4016-8bad-941a89cbfbc9", "metadata": {"aucs": [0.8173532858943607, 0.8173532858943607, 0.8173532858943607, 0.8070665307824119, 0.8070665307824119, 0.8070665307824119, 0.8302027387283974, 0.8302027387283974, 0.8302027387283974, 0.5134322341997061, 0.5134322341997061, 0.5134322341997061, 0.624691263026809, 0.624691263026809, 0.624691263026809, 0.6002980633873294, 0.6002980633873294, 0.6002980633873294, 0.15836040046428224, 0.15836040046428224, 0.15836040046428224, 0.13123216050558661, 0.13123216050558661, 0.13123216050558661, 0.27970106171202114, 0.27970106171202114, 0.27970106171202114, 0.15124280349195118, 0.15124280349195118, 0.15124280349195118, 0.09834124134572031, 0.09834124134572031, 0.09834124134572031, 0.12989604071547778, 0.12989604071547778, 0.12989604071547778, 0.9680695927117464, 0.9680695927117464, 0.9680695927117464, 0.9768501235494804, 0.9768501235494804, 0.9768501235494804, 0.9831477879115976, 0.9831477879115976, 0.9831477879115976, 0.5971319790953125, 0.5971319790953125, 0.5971319790953125, 0.48474815956165695, 0.48474815956165695, 0.48474815956165695, 0.5830104602966175, 0.5830104602966175, 0.5830104602966175, 0.27622022111890565, 0.27622022111890565, 0.27622022111890565, 0.18779824886197094, 0.18779824886197094, 0.18779824886197094, 0.33670363500165723, 0.33670363500165723, 0.33670363500165723, 0.2952862590151156, 0.2952862590151156, 0.2952862590151156, 0.12903284797818992, 0.12903284797818992, 0.12903284797818992, 0.19498986972794174, 0.19498986972794174, 0.19498986972794174, 0.21024770382224844, 0.21024770382224844, 0.21024770382224844, 0.18127758222775825, 0.18127758222775825, 0.18127758222775825, 0.1332413227550654, 0.1332413227550654, 0.1332413227550654, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.000591596660297955, 0.000591596660297955, 0.000591596660297955, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1420256776795833, 0.1420256776795833, 0.1420256776795833, 0.020748106240395137, 0.020748106240395137, 0.020748106240395137, 0.1348851129367975, 0.1348851129367975, 0.1348851129367975, 0.04458903399180836, 0.04458903399180836, 0.04458903399180836, 0.11512893530323998, 0.11512893530323998, 0.11512893530323998, 0.08641355632800374, 0.08641355632800374, 0.08641355632800374, 0.14777383418850298, 0.14777383418850298, 0.14777383418850298, 0.07206563016569412, 0.07206563016569412, 0.07206563016569412, 0.07923642752837845, 0.07923642752837845, 0.07923642752837845, 0.5973585429735873, 0.5973585429735873, 0.5973585429735873, 0.5444614487631158, 0.5444614487631158, 0.5444614487631158, 0.5581596112472851, 0.5581596112472851, 0.5581596112472851, 0.10792836734243372, 0.10792836734243372, 0.10792836734243372, 0.16390282508876686, 0.16390282508876686, 0.16390282508876686, 0.08962551634344096, 0.08962551634344096, 0.08962551634344096, 0.19483029090259651, 0.19483029090259651, 0.19483029090259651, 0.2820278660431219, 0.2820278660431219, 0.2820278660431219, 0.26805499101487307, 0.26805499101487307, 0.26805499101487307, 0.24637636277992703, 0.24637636277992703, 0.24637636277992703, 0.3831050982404137, 0.3831050982404137, 0.3831050982404137, 0.4868095742725873, 0.4868095742725873, 0.4868095742725873, 0.16845536602753763, 0.16845536602753763, 0.16845536602753763, 0.3014920382412615, 0.3014920382412615, 0.3014920382412615, 0.36512925182854294, 0.36512925182854294, 0.36512925182854294, 0.22868397010770147, 0.22868397010770147, 0.22868397010770147, 0.22390362207286474, 0.22390362207286474, 0.22390362207286474, 0.21557387697624797, 0.21557387697624797, 0.21557387697624797, 0.19146581710468058, 0.19146581710468058, 0.19146581710468058, 0.2142825225819227, 0.2142825225819227, 0.2142825225819227, 0.23382031825464455, 0.23382031825464455, 0.23382031825464455, 0.8781972766424274, 0.8781972766424274, 0.8781972766424274, 0.16498904353322907, 0.16498904353322907, 0.16498904353322907, 0.1675048508288941, 0.1675048508288941, 0.1675048508288941, 0.1677930192856908, 0.1677930192856908, 0.1677930192856908, 0.2096363998358497, 0.2096363998358497, 0.2096363998358497, 0.7527906802205094, 0.7527906802205094, 0.7527906802205094, 0.18281873394226333, 0.18281873394226333, 0.18281873394226333, 0.18751703876694603, 0.18751703876694603, 0.18751703876694603, 0.2003195826305778, 0.2003195826305778, 0.2003195826305778, 0.09323489623740366, 0.09323489623740366, 0.09323489623740366, 0.08957474845720703, 0.08957474845720703, 0.08957474845720703, 0.11110056432631477, 0.11110056432631477, 0.11110056432631477]}, "mutation_prompt": null}
{"id": "114ba2d3-e6de-4fcd-97ff-118111d7376a", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.5  # Reduced inertia_weight for quicker convergence\n        self.cognitive_coeff = 1.7  # Increased cognitive_coeff for more exploration\n        self.social_coeff = 1.3  # Reduced social_coeff to improve diversity\n        self.dynamic_adjustment_freq = 10  # Frequency of dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0  # Initialize iteration counter\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:  # Dynamic parameter adjustment\n                self.inertia_weight *= 0.95  # Gradually reduce inertia\n                self.mutation_factor = 0.9 if iteration < self.budget // 2 else 0.7  # Adjust mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1  # Increment iteration counter\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with dynamic parameter adjustment and improved diversity mechanism for accelerated convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a38bff72-ab4d-4016-8bad-941a89cbfbc9", "metadata": {"aucs": [0.8173532858943607, 0.8173532858943607, 0.8173532858943607, 0.8070665307824119, 0.8070665307824119, 0.8070665307824119, 0.8302027387283974, 0.8302027387283974, 0.8302027387283974, 0.5134322341997061, 0.5134322341997061, 0.5134322341997061, 0.624691263026809, 0.624691263026809, 0.624691263026809, 0.6002980633873294, 0.6002980633873294, 0.6002980633873294, 0.15836040046428224, 0.15836040046428224, 0.15836040046428224, 0.13123216050558661, 0.13123216050558661, 0.13123216050558661, 0.27970106171202114, 0.27970106171202114, 0.27970106171202114, 0.15124280349195118, 0.15124280349195118, 0.15124280349195118, 0.09834124134572031, 0.09834124134572031, 0.09834124134572031, 0.12989604071547778, 0.12989604071547778, 0.12989604071547778, 0.9680695927117464, 0.9680695927117464, 0.9680695927117464, 0.9768501235494804, 0.9768501235494804, 0.9768501235494804, 0.9831477879115976, 0.9831477879115976, 0.9831477879115976, 0.5971319790953125, 0.5971319790953125, 0.5971319790953125, 0.48474815956165695, 0.48474815956165695, 0.48474815956165695, 0.5830104602966175, 0.5830104602966175, 0.5830104602966175, 0.27622022111890565, 0.27622022111890565, 0.27622022111890565, 0.18779824886197094, 0.18779824886197094, 0.18779824886197094, 0.33670363500165723, 0.33670363500165723, 0.33670363500165723, 0.2952862590151156, 0.2952862590151156, 0.2952862590151156, 0.12903284797818992, 0.12903284797818992, 0.12903284797818992, 0.19498986972794174, 0.19498986972794174, 0.19498986972794174, 0.21024770382224844, 0.21024770382224844, 0.21024770382224844, 0.18127758222775825, 0.18127758222775825, 0.18127758222775825, 0.1332413227550654, 0.1332413227550654, 0.1332413227550654, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.000591596660297955, 0.000591596660297955, 0.000591596660297955, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1420256776795833, 0.1420256776795833, 0.1420256776795833, 0.020748106240395137, 0.020748106240395137, 0.020748106240395137, 0.1348851129367975, 0.1348851129367975, 0.1348851129367975, 0.04458903399180836, 0.04458903399180836, 0.04458903399180836, 0.11512893530323998, 0.11512893530323998, 0.11512893530323998, 0.08641355632800374, 0.08641355632800374, 0.08641355632800374, 0.14777383418850298, 0.14777383418850298, 0.14777383418850298, 0.07206563016569412, 0.07206563016569412, 0.07206563016569412, 0.07923642752837845, 0.07923642752837845, 0.07923642752837845, 0.5973585429735873, 0.5973585429735873, 0.5973585429735873, 0.5444614487631158, 0.5444614487631158, 0.5444614487631158, 0.5581596112472851, 0.5581596112472851, 0.5581596112472851, 0.10792836734243372, 0.10792836734243372, 0.10792836734243372, 0.16390282508876686, 0.16390282508876686, 0.16390282508876686, 0.08962551634344096, 0.08962551634344096, 0.08962551634344096, 0.19483029090259651, 0.19483029090259651, 0.19483029090259651, 0.2820278660431219, 0.2820278660431219, 0.2820278660431219, 0.26805499101487307, 0.26805499101487307, 0.26805499101487307, 0.24637636277992703, 0.24637636277992703, 0.24637636277992703, 0.3831050982404137, 0.3831050982404137, 0.3831050982404137, 0.4868095742725873, 0.4868095742725873, 0.4868095742725873, 0.16845536602753763, 0.16845536602753763, 0.16845536602753763, 0.3014920382412615, 0.3014920382412615, 0.3014920382412615, 0.36512925182854294, 0.36512925182854294, 0.36512925182854294, 0.22868397010770147, 0.22868397010770147, 0.22868397010770147, 0.22390362207286474, 0.22390362207286474, 0.22390362207286474, 0.21557387697624797, 0.21557387697624797, 0.21557387697624797, 0.19146581710468058, 0.19146581710468058, 0.19146581710468058, 0.2142825225819227, 0.2142825225819227, 0.2142825225819227, 0.23382031825464455, 0.23382031825464455, 0.23382031825464455, 0.8781972766424274, 0.8781972766424274, 0.8781972766424274, 0.16498904353322907, 0.16498904353322907, 0.16498904353322907, 0.1675048508288941, 0.1675048508288941, 0.1675048508288941, 0.1677930192856908, 0.1677930192856908, 0.1677930192856908, 0.2096363998358497, 0.2096363998358497, 0.2096363998358497, 0.7527906802205094, 0.7527906802205094, 0.7527906802205094, 0.18281873394226333, 0.18281873394226333, 0.18281873394226333, 0.18751703876694603, 0.18751703876694603, 0.18751703876694603, 0.2003195826305778, 0.2003195826305778, 0.2003195826305778, 0.09323489623740366, 0.09323489623740366, 0.09323489623740366, 0.08957474845720703, 0.08957474845720703, 0.08957474845720703, 0.11110056432631477, 0.11110056432631477, 0.11110056432631477]}, "mutation_prompt": null}
{"id": "b167c0d6-b6ad-4d5c-8514-58368043043d", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.5  # Reduced inertia_weight for quicker convergence\n        self.cognitive_coeff = 1.7  # Increased cognitive_coeff for more exploration\n        self.social_coeff = 1.3  # Reduced social_coeff to improve diversity\n        self.dynamic_adjustment_freq = 10  # Frequency of dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0  # Initialize iteration counter\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:  # Dynamic parameter adjustment\n                self.inertia_weight *= 0.95  # Gradually reduce inertia\n                self.mutation_factor = 0.9 if iteration < self.budget // 2 else 0.7  # Adjust mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1  # Increment iteration counter\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with dynamic parameter adjustment and improved diversity mechanism for accelerated convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a38bff72-ab4d-4016-8bad-941a89cbfbc9", "metadata": {"aucs": [0.8173532858943607, 0.8173532858943607, 0.8173532858943607, 0.8070665307824119, 0.8070665307824119, 0.8070665307824119, 0.8302027387283974, 0.8302027387283974, 0.8302027387283974, 0.5134322341997061, 0.5134322341997061, 0.5134322341997061, 0.624691263026809, 0.624691263026809, 0.624691263026809, 0.6002980633873294, 0.6002980633873294, 0.6002980633873294, 0.15836040046428224, 0.15836040046428224, 0.15836040046428224, 0.13123216050558661, 0.13123216050558661, 0.13123216050558661, 0.27970106171202114, 0.27970106171202114, 0.27970106171202114, 0.15124280349195118, 0.15124280349195118, 0.15124280349195118, 0.09834124134572031, 0.09834124134572031, 0.09834124134572031, 0.12989604071547778, 0.12989604071547778, 0.12989604071547778, 0.9680695927117464, 0.9680695927117464, 0.9680695927117464, 0.9768501235494804, 0.9768501235494804, 0.9768501235494804, 0.9831477879115976, 0.9831477879115976, 0.9831477879115976, 0.5971319790953125, 0.5971319790953125, 0.5971319790953125, 0.48474815956165695, 0.48474815956165695, 0.48474815956165695, 0.5830104602966175, 0.5830104602966175, 0.5830104602966175, 0.27622022111890565, 0.27622022111890565, 0.27622022111890565, 0.18779824886197094, 0.18779824886197094, 0.18779824886197094, 0.33670363500165723, 0.33670363500165723, 0.33670363500165723, 0.2952862590151156, 0.2952862590151156, 0.2952862590151156, 0.12903284797818992, 0.12903284797818992, 0.12903284797818992, 0.19498986972794174, 0.19498986972794174, 0.19498986972794174, 0.21024770382224844, 0.21024770382224844, 0.21024770382224844, 0.18127758222775825, 0.18127758222775825, 0.18127758222775825, 0.1332413227550654, 0.1332413227550654, 0.1332413227550654, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.000591596660297955, 0.000591596660297955, 0.000591596660297955, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1420256776795833, 0.1420256776795833, 0.1420256776795833, 0.020748106240395137, 0.020748106240395137, 0.020748106240395137, 0.1348851129367975, 0.1348851129367975, 0.1348851129367975, 0.04458903399180836, 0.04458903399180836, 0.04458903399180836, 0.11512893530323998, 0.11512893530323998, 0.11512893530323998, 0.08641355632800374, 0.08641355632800374, 0.08641355632800374, 0.14777383418850298, 0.14777383418850298, 0.14777383418850298, 0.07206563016569412, 0.07206563016569412, 0.07206563016569412, 0.07923642752837845, 0.07923642752837845, 0.07923642752837845, 0.5973585429735873, 0.5973585429735873, 0.5973585429735873, 0.5444614487631158, 0.5444614487631158, 0.5444614487631158, 0.5581596112472851, 0.5581596112472851, 0.5581596112472851, 0.10792836734243372, 0.10792836734243372, 0.10792836734243372, 0.16390282508876686, 0.16390282508876686, 0.16390282508876686, 0.08962551634344096, 0.08962551634344096, 0.08962551634344096, 0.19483029090259651, 0.19483029090259651, 0.19483029090259651, 0.2820278660431219, 0.2820278660431219, 0.2820278660431219, 0.26805499101487307, 0.26805499101487307, 0.26805499101487307, 0.24637636277992703, 0.24637636277992703, 0.24637636277992703, 0.3831050982404137, 0.3831050982404137, 0.3831050982404137, 0.4868095742725873, 0.4868095742725873, 0.4868095742725873, 0.16845536602753763, 0.16845536602753763, 0.16845536602753763, 0.3014920382412615, 0.3014920382412615, 0.3014920382412615, 0.36512925182854294, 0.36512925182854294, 0.36512925182854294, 0.22868397010770147, 0.22868397010770147, 0.22868397010770147, 0.22390362207286474, 0.22390362207286474, 0.22390362207286474, 0.21557387697624797, 0.21557387697624797, 0.21557387697624797, 0.19146581710468058, 0.19146581710468058, 0.19146581710468058, 0.2142825225819227, 0.2142825225819227, 0.2142825225819227, 0.23382031825464455, 0.23382031825464455, 0.23382031825464455, 0.8781972766424274, 0.8781972766424274, 0.8781972766424274, 0.16498904353322907, 0.16498904353322907, 0.16498904353322907, 0.1675048508288941, 0.1675048508288941, 0.1675048508288941, 0.1677930192856908, 0.1677930192856908, 0.1677930192856908, 0.2096363998358497, 0.2096363998358497, 0.2096363998358497, 0.7527906802205094, 0.7527906802205094, 0.7527906802205094, 0.18281873394226333, 0.18281873394226333, 0.18281873394226333, 0.18751703876694603, 0.18751703876694603, 0.18751703876694603, 0.2003195826305778, 0.2003195826305778, 0.2003195826305778, 0.09323489623740366, 0.09323489623740366, 0.09323489623740366, 0.08957474845720703, 0.08957474845720703, 0.08957474845720703, 0.11110056432631477, 0.11110056432631477, 0.11110056432631477]}, "mutation_prompt": null}
{"id": "56d5ca81-3e85-4cef-b23e-caa657554242", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.5  # Reduced inertia_weight for quicker convergence\n        self.cognitive_coeff = 1.7  # Increased cognitive_coeff for more exploration\n        self.social_coeff = 1.3  # Reduced social_coeff to improve diversity\n        self.dynamic_adjustment_freq = 10  # Frequency of dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0  # Initialize iteration counter\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:  # Dynamic parameter adjustment\n                self.inertia_weight *= 0.95  # Gradually reduce inertia\n                self.mutation_factor = 0.9 if iteration < self.budget // 2 else 0.7  # Adjust mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1  # Increment iteration counter\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with dynamic parameter adjustment and improved diversity mechanism for accelerated convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a38bff72-ab4d-4016-8bad-941a89cbfbc9", "metadata": {"aucs": [0.8173532858943607, 0.8173532858943607, 0.8173532858943607, 0.8070665307824119, 0.8070665307824119, 0.8070665307824119, 0.8302027387283974, 0.8302027387283974, 0.8302027387283974, 0.5134322341997061, 0.5134322341997061, 0.5134322341997061, 0.624691263026809, 0.624691263026809, 0.624691263026809, 0.6002980633873294, 0.6002980633873294, 0.6002980633873294, 0.15836040046428224, 0.15836040046428224, 0.15836040046428224, 0.13123216050558661, 0.13123216050558661, 0.13123216050558661, 0.27970106171202114, 0.27970106171202114, 0.27970106171202114, 0.15124280349195118, 0.15124280349195118, 0.15124280349195118, 0.09834124134572031, 0.09834124134572031, 0.09834124134572031, 0.12989604071547778, 0.12989604071547778, 0.12989604071547778, 0.9680695927117464, 0.9680695927117464, 0.9680695927117464, 0.9768501235494804, 0.9768501235494804, 0.9768501235494804, 0.9831477879115976, 0.9831477879115976, 0.9831477879115976, 0.5971319790953125, 0.5971319790953125, 0.5971319790953125, 0.48474815956165695, 0.48474815956165695, 0.48474815956165695, 0.5830104602966175, 0.5830104602966175, 0.5830104602966175, 0.27622022111890565, 0.27622022111890565, 0.27622022111890565, 0.18779824886197094, 0.18779824886197094, 0.18779824886197094, 0.33670363500165723, 0.33670363500165723, 0.33670363500165723, 0.2952862590151156, 0.2952862590151156, 0.2952862590151156, 0.12903284797818992, 0.12903284797818992, 0.12903284797818992, 0.19498986972794174, 0.19498986972794174, 0.19498986972794174, 0.21024770382224844, 0.21024770382224844, 0.21024770382224844, 0.18127758222775825, 0.18127758222775825, 0.18127758222775825, 0.1332413227550654, 0.1332413227550654, 0.1332413227550654, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.000591596660297955, 0.000591596660297955, 0.000591596660297955, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1420256776795833, 0.1420256776795833, 0.1420256776795833, 0.020748106240395137, 0.020748106240395137, 0.020748106240395137, 0.1348851129367975, 0.1348851129367975, 0.1348851129367975, 0.04458903399180836, 0.04458903399180836, 0.04458903399180836, 0.11512893530323998, 0.11512893530323998, 0.11512893530323998, 0.08641355632800374, 0.08641355632800374, 0.08641355632800374, 0.14777383418850298, 0.14777383418850298, 0.14777383418850298, 0.07206563016569412, 0.07206563016569412, 0.07206563016569412, 0.07923642752837845, 0.07923642752837845, 0.07923642752837845, 0.5973585429735873, 0.5973585429735873, 0.5973585429735873, 0.5444614487631158, 0.5444614487631158, 0.5444614487631158, 0.5581596112472851, 0.5581596112472851, 0.5581596112472851, 0.10792836734243372, 0.10792836734243372, 0.10792836734243372, 0.16390282508876686, 0.16390282508876686, 0.16390282508876686, 0.08962551634344096, 0.08962551634344096, 0.08962551634344096, 0.19483029090259651, 0.19483029090259651, 0.19483029090259651, 0.2820278660431219, 0.2820278660431219, 0.2820278660431219, 0.26805499101487307, 0.26805499101487307, 0.26805499101487307, 0.24637636277992703, 0.24637636277992703, 0.24637636277992703, 0.3831050982404137, 0.3831050982404137, 0.3831050982404137, 0.4868095742725873, 0.4868095742725873, 0.4868095742725873, 0.16845536602753763, 0.16845536602753763, 0.16845536602753763, 0.3014920382412615, 0.3014920382412615, 0.3014920382412615, 0.36512925182854294, 0.36512925182854294, 0.36512925182854294, 0.22868397010770147, 0.22868397010770147, 0.22868397010770147, 0.22390362207286474, 0.22390362207286474, 0.22390362207286474, 0.21557387697624797, 0.21557387697624797, 0.21557387697624797, 0.19146581710468058, 0.19146581710468058, 0.19146581710468058, 0.2142825225819227, 0.2142825225819227, 0.2142825225819227, 0.23382031825464455, 0.23382031825464455, 0.23382031825464455, 0.8781972766424274, 0.8781972766424274, 0.8781972766424274, 0.16498904353322907, 0.16498904353322907, 0.16498904353322907, 0.1675048508288941, 0.1675048508288941, 0.1675048508288941, 0.1677930192856908, 0.1677930192856908, 0.1677930192856908, 0.2096363998358497, 0.2096363998358497, 0.2096363998358497, 0.7527906802205094, 0.7527906802205094, 0.7527906802205094, 0.18281873394226333, 0.18281873394226333, 0.18281873394226333, 0.18751703876694603, 0.18751703876694603, 0.18751703876694603, 0.2003195826305778, 0.2003195826305778, 0.2003195826305778, 0.09323489623740366, 0.09323489623740366, 0.09323489623740366, 0.08957474845720703, 0.08957474845720703, 0.08957474845720703, 0.11110056432631477, 0.11110056432631477, 0.11110056432631477]}, "mutation_prompt": null}
{"id": "5320d1e6-9ccc-4ee4-a6a1-23cefd3ff950", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.5  # Reduced inertia_weight for quicker convergence\n        self.cognitive_coeff = 1.7  # Increased cognitive_coeff for more exploration\n        self.social_coeff = 1.3  # Reduced social_coeff to improve diversity\n        self.dynamic_adjustment_freq = 10  # Frequency of dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0  # Initialize iteration counter\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:  # Dynamic parameter adjustment\n                self.inertia_weight *= 0.95  # Gradually reduce inertia\n                self.mutation_factor = 0.9 if iteration < self.budget // 2 else 0.7  # Adjust mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1  # Increment iteration counter\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with dynamic parameter adjustment and improved diversity mechanism for accelerated convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a38bff72-ab4d-4016-8bad-941a89cbfbc9", "metadata": {"aucs": [0.8173532858943607, 0.8173532858943607, 0.8173532858943607, 0.8070665307824119, 0.8070665307824119, 0.8070665307824119, 0.8302027387283974, 0.8302027387283974, 0.8302027387283974, 0.5134322341997061, 0.5134322341997061, 0.5134322341997061, 0.624691263026809, 0.624691263026809, 0.624691263026809, 0.6002980633873294, 0.6002980633873294, 0.6002980633873294, 0.15836040046428224, 0.15836040046428224, 0.15836040046428224, 0.13123216050558661, 0.13123216050558661, 0.13123216050558661, 0.27970106171202114, 0.27970106171202114, 0.27970106171202114, 0.15124280349195118, 0.15124280349195118, 0.15124280349195118, 0.09834124134572031, 0.09834124134572031, 0.09834124134572031, 0.12989604071547778, 0.12989604071547778, 0.12989604071547778, 0.9680695927117464, 0.9680695927117464, 0.9680695927117464, 0.9768501235494804, 0.9768501235494804, 0.9768501235494804, 0.9831477879115976, 0.9831477879115976, 0.9831477879115976, 0.5971319790953125, 0.5971319790953125, 0.5971319790953125, 0.48474815956165695, 0.48474815956165695, 0.48474815956165695, 0.5830104602966175, 0.5830104602966175, 0.5830104602966175, 0.27622022111890565, 0.27622022111890565, 0.27622022111890565, 0.18779824886197094, 0.18779824886197094, 0.18779824886197094, 0.33670363500165723, 0.33670363500165723, 0.33670363500165723, 0.2952862590151156, 0.2952862590151156, 0.2952862590151156, 0.12903284797818992, 0.12903284797818992, 0.12903284797818992, 0.19498986972794174, 0.19498986972794174, 0.19498986972794174, 0.21024770382224844, 0.21024770382224844, 0.21024770382224844, 0.18127758222775825, 0.18127758222775825, 0.18127758222775825, 0.1332413227550654, 0.1332413227550654, 0.1332413227550654, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.000591596660297955, 0.000591596660297955, 0.000591596660297955, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1420256776795833, 0.1420256776795833, 0.1420256776795833, 0.020748106240395137, 0.020748106240395137, 0.020748106240395137, 0.1348851129367975, 0.1348851129367975, 0.1348851129367975, 0.04458903399180836, 0.04458903399180836, 0.04458903399180836, 0.11512893530323998, 0.11512893530323998, 0.11512893530323998, 0.08641355632800374, 0.08641355632800374, 0.08641355632800374, 0.14777383418850298, 0.14777383418850298, 0.14777383418850298, 0.07206563016569412, 0.07206563016569412, 0.07206563016569412, 0.07923642752837845, 0.07923642752837845, 0.07923642752837845, 0.5973585429735873, 0.5973585429735873, 0.5973585429735873, 0.5444614487631158, 0.5444614487631158, 0.5444614487631158, 0.5581596112472851, 0.5581596112472851, 0.5581596112472851, 0.10792836734243372, 0.10792836734243372, 0.10792836734243372, 0.16390282508876686, 0.16390282508876686, 0.16390282508876686, 0.08962551634344096, 0.08962551634344096, 0.08962551634344096, 0.19483029090259651, 0.19483029090259651, 0.19483029090259651, 0.2820278660431219, 0.2820278660431219, 0.2820278660431219, 0.26805499101487307, 0.26805499101487307, 0.26805499101487307, 0.24637636277992703, 0.24637636277992703, 0.24637636277992703, 0.3831050982404137, 0.3831050982404137, 0.3831050982404137, 0.4868095742725873, 0.4868095742725873, 0.4868095742725873, 0.16845536602753763, 0.16845536602753763, 0.16845536602753763, 0.3014920382412615, 0.3014920382412615, 0.3014920382412615, 0.36512925182854294, 0.36512925182854294, 0.36512925182854294, 0.22868397010770147, 0.22868397010770147, 0.22868397010770147, 0.22390362207286474, 0.22390362207286474, 0.22390362207286474, 0.21557387697624797, 0.21557387697624797, 0.21557387697624797, 0.19146581710468058, 0.19146581710468058, 0.19146581710468058, 0.2142825225819227, 0.2142825225819227, 0.2142825225819227, 0.23382031825464455, 0.23382031825464455, 0.23382031825464455, 0.8781972766424274, 0.8781972766424274, 0.8781972766424274, 0.16498904353322907, 0.16498904353322907, 0.16498904353322907, 0.1675048508288941, 0.1675048508288941, 0.1675048508288941, 0.1677930192856908, 0.1677930192856908, 0.1677930192856908, 0.2096363998358497, 0.2096363998358497, 0.2096363998358497, 0.7527906802205094, 0.7527906802205094, 0.7527906802205094, 0.18281873394226333, 0.18281873394226333, 0.18281873394226333, 0.18751703876694603, 0.18751703876694603, 0.18751703876694603, 0.2003195826305778, 0.2003195826305778, 0.2003195826305778, 0.09323489623740366, 0.09323489623740366, 0.09323489623740366, 0.08957474845720703, 0.08957474845720703, 0.08957474845720703, 0.11110056432631477, 0.11110056432631477, 0.11110056432631477]}, "mutation_prompt": null}
{"id": "39df6573-369f-49f4-96a4-51670e49370e", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.5  # Reduced inertia_weight for quicker convergence\n        self.cognitive_coeff = 1.7  # Increased cognitive_coeff for more exploration\n        self.social_coeff = 1.3  # Reduced social_coeff to improve diversity\n        self.dynamic_adjustment_freq = 10  # Frequency of dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0  # Initialize iteration counter\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:  # Dynamic parameter adjustment\n                self.inertia_weight *= 0.95  # Gradually reduce inertia\n                self.mutation_factor = 0.9 if iteration < self.budget // 2 else 0.7  # Adjust mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1  # Increment iteration counter\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with dynamic parameter adjustment and improved diversity mechanism for accelerated convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a38bff72-ab4d-4016-8bad-941a89cbfbc9", "metadata": {"aucs": [0.8173532858943607, 0.8173532858943607, 0.8173532858943607, 0.8070665307824119, 0.8070665307824119, 0.8070665307824119, 0.8302027387283974, 0.8302027387283974, 0.8302027387283974, 0.5134322341997061, 0.5134322341997061, 0.5134322341997061, 0.624691263026809, 0.624691263026809, 0.624691263026809, 0.6002980633873294, 0.6002980633873294, 0.6002980633873294, 0.15836040046428224, 0.15836040046428224, 0.15836040046428224, 0.13123216050558661, 0.13123216050558661, 0.13123216050558661, 0.27970106171202114, 0.27970106171202114, 0.27970106171202114, 0.15124280349195118, 0.15124280349195118, 0.15124280349195118, 0.09834124134572031, 0.09834124134572031, 0.09834124134572031, 0.12989604071547778, 0.12989604071547778, 0.12989604071547778, 0.9680695927117464, 0.9680695927117464, 0.9680695927117464, 0.9768501235494804, 0.9768501235494804, 0.9768501235494804, 0.9831477879115976, 0.9831477879115976, 0.9831477879115976, 0.5971319790953125, 0.5971319790953125, 0.5971319790953125, 0.48474815956165695, 0.48474815956165695, 0.48474815956165695, 0.5830104602966175, 0.5830104602966175, 0.5830104602966175, 0.27622022111890565, 0.27622022111890565, 0.27622022111890565, 0.18779824886197094, 0.18779824886197094, 0.18779824886197094, 0.33670363500165723, 0.33670363500165723, 0.33670363500165723, 0.2952862590151156, 0.2952862590151156, 0.2952862590151156, 0.12903284797818992, 0.12903284797818992, 0.12903284797818992, 0.19498986972794174, 0.19498986972794174, 0.19498986972794174, 0.21024770382224844, 0.21024770382224844, 0.21024770382224844, 0.18127758222775825, 0.18127758222775825, 0.18127758222775825, 0.1332413227550654, 0.1332413227550654, 0.1332413227550654, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.000591596660297955, 0.000591596660297955, 0.000591596660297955, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1420256776795833, 0.1420256776795833, 0.1420256776795833, 0.020748106240395137, 0.020748106240395137, 0.020748106240395137, 0.1348851129367975, 0.1348851129367975, 0.1348851129367975, 0.04458903399180836, 0.04458903399180836, 0.04458903399180836, 0.11512893530323998, 0.11512893530323998, 0.11512893530323998, 0.08641355632800374, 0.08641355632800374, 0.08641355632800374, 0.14777383418850298, 0.14777383418850298, 0.14777383418850298, 0.07206563016569412, 0.07206563016569412, 0.07206563016569412, 0.07923642752837845, 0.07923642752837845, 0.07923642752837845, 0.5973585429735873, 0.5973585429735873, 0.5973585429735873, 0.5444614487631158, 0.5444614487631158, 0.5444614487631158, 0.5581596112472851, 0.5581596112472851, 0.5581596112472851, 0.10792836734243372, 0.10792836734243372, 0.10792836734243372, 0.16390282508876686, 0.16390282508876686, 0.16390282508876686, 0.08962551634344096, 0.08962551634344096, 0.08962551634344096, 0.19483029090259651, 0.19483029090259651, 0.19483029090259651, 0.2820278660431219, 0.2820278660431219, 0.2820278660431219, 0.26805499101487307, 0.26805499101487307, 0.26805499101487307, 0.24637636277992703, 0.24637636277992703, 0.24637636277992703, 0.3831050982404137, 0.3831050982404137, 0.3831050982404137, 0.4868095742725873, 0.4868095742725873, 0.4868095742725873, 0.16845536602753763, 0.16845536602753763, 0.16845536602753763, 0.3014920382412615, 0.3014920382412615, 0.3014920382412615, 0.36512925182854294, 0.36512925182854294, 0.36512925182854294, 0.22868397010770147, 0.22868397010770147, 0.22868397010770147, 0.22390362207286474, 0.22390362207286474, 0.22390362207286474, 0.21557387697624797, 0.21557387697624797, 0.21557387697624797, 0.19146581710468058, 0.19146581710468058, 0.19146581710468058, 0.2142825225819227, 0.2142825225819227, 0.2142825225819227, 0.23382031825464455, 0.23382031825464455, 0.23382031825464455, 0.8781972766424274, 0.8781972766424274, 0.8781972766424274, 0.16498904353322907, 0.16498904353322907, 0.16498904353322907, 0.1675048508288941, 0.1675048508288941, 0.1675048508288941, 0.1677930192856908, 0.1677930192856908, 0.1677930192856908, 0.2096363998358497, 0.2096363998358497, 0.2096363998358497, 0.7527906802205094, 0.7527906802205094, 0.7527906802205094, 0.18281873394226333, 0.18281873394226333, 0.18281873394226333, 0.18751703876694603, 0.18751703876694603, 0.18751703876694603, 0.2003195826305778, 0.2003195826305778, 0.2003195826305778, 0.09323489623740366, 0.09323489623740366, 0.09323489623740366, 0.08957474845720703, 0.08957474845720703, 0.08957474845720703, 0.11110056432631477, 0.11110056432631477, 0.11110056432631477]}, "mutation_prompt": null}
{"id": "26047c0b-b2c5-4a0b-9e10-3baebb10a8d3", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.5  # Reduced inertia_weight for quicker convergence\n        self.cognitive_coeff = 1.7  # Increased cognitive_coeff for more exploration\n        self.social_coeff = 1.3  # Reduced social_coeff to improve diversity\n        self.dynamic_adjustment_freq = 10  # Frequency of dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0  # Initialize iteration counter\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:  # Dynamic parameter adjustment\n                self.inertia_weight *= 0.95  # Gradually reduce inertia\n                self.mutation_factor = 0.9 if iteration < self.budget // 2 else 0.7  # Adjust mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1  # Increment iteration counter\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with dynamic parameter adjustment and improved diversity mechanism for accelerated convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a38bff72-ab4d-4016-8bad-941a89cbfbc9", "metadata": {"aucs": [0.8173532858943607, 0.8173532858943607, 0.8173532858943607, 0.8070665307824119, 0.8070665307824119, 0.8070665307824119, 0.8302027387283974, 0.8302027387283974, 0.8302027387283974, 0.5134322341997061, 0.5134322341997061, 0.5134322341997061, 0.624691263026809, 0.624691263026809, 0.624691263026809, 0.6002980633873294, 0.6002980633873294, 0.6002980633873294, 0.15836040046428224, 0.15836040046428224, 0.15836040046428224, 0.13123216050558661, 0.13123216050558661, 0.13123216050558661, 0.27970106171202114, 0.27970106171202114, 0.27970106171202114, 0.15124280349195118, 0.15124280349195118, 0.15124280349195118, 0.09834124134572031, 0.09834124134572031, 0.09834124134572031, 0.12989604071547778, 0.12989604071547778, 0.12989604071547778, 0.9680695927117464, 0.9680695927117464, 0.9680695927117464, 0.9768501235494804, 0.9768501235494804, 0.9768501235494804, 0.9831477879115976, 0.9831477879115976, 0.9831477879115976, 0.5971319790953125, 0.5971319790953125, 0.5971319790953125, 0.48474815956165695, 0.48474815956165695, 0.48474815956165695, 0.5830104602966175, 0.5830104602966175, 0.5830104602966175, 0.27622022111890565, 0.27622022111890565, 0.27622022111890565, 0.18779824886197094, 0.18779824886197094, 0.18779824886197094, 0.33670363500165723, 0.33670363500165723, 0.33670363500165723, 0.2952862590151156, 0.2952862590151156, 0.2952862590151156, 0.12903284797818992, 0.12903284797818992, 0.12903284797818992, 0.19498986972794174, 0.19498986972794174, 0.19498986972794174, 0.21024770382224844, 0.21024770382224844, 0.21024770382224844, 0.18127758222775825, 0.18127758222775825, 0.18127758222775825, 0.1332413227550654, 0.1332413227550654, 0.1332413227550654, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.000591596660297955, 0.000591596660297955, 0.000591596660297955, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1420256776795833, 0.1420256776795833, 0.1420256776795833, 0.020748106240395137, 0.020748106240395137, 0.020748106240395137, 0.1348851129367975, 0.1348851129367975, 0.1348851129367975, 0.04458903399180836, 0.04458903399180836, 0.04458903399180836, 0.11512893530323998, 0.11512893530323998, 0.11512893530323998, 0.08641355632800374, 0.08641355632800374, 0.08641355632800374, 0.14777383418850298, 0.14777383418850298, 0.14777383418850298, 0.07206563016569412, 0.07206563016569412, 0.07206563016569412, 0.07923642752837845, 0.07923642752837845, 0.07923642752837845, 0.5973585429735873, 0.5973585429735873, 0.5973585429735873, 0.5444614487631158, 0.5444614487631158, 0.5444614487631158, 0.5581596112472851, 0.5581596112472851, 0.5581596112472851, 0.10792836734243372, 0.10792836734243372, 0.10792836734243372, 0.16390282508876686, 0.16390282508876686, 0.16390282508876686, 0.08962551634344096, 0.08962551634344096, 0.08962551634344096, 0.19483029090259651, 0.19483029090259651, 0.19483029090259651, 0.2820278660431219, 0.2820278660431219, 0.2820278660431219, 0.26805499101487307, 0.26805499101487307, 0.26805499101487307, 0.24637636277992703, 0.24637636277992703, 0.24637636277992703, 0.3831050982404137, 0.3831050982404137, 0.3831050982404137, 0.4868095742725873, 0.4868095742725873, 0.4868095742725873, 0.16845536602753763, 0.16845536602753763, 0.16845536602753763, 0.3014920382412615, 0.3014920382412615, 0.3014920382412615, 0.36512925182854294, 0.36512925182854294, 0.36512925182854294, 0.22868397010770147, 0.22868397010770147, 0.22868397010770147, 0.22390362207286474, 0.22390362207286474, 0.22390362207286474, 0.21557387697624797, 0.21557387697624797, 0.21557387697624797, 0.19146581710468058, 0.19146581710468058, 0.19146581710468058, 0.2142825225819227, 0.2142825225819227, 0.2142825225819227, 0.23382031825464455, 0.23382031825464455, 0.23382031825464455, 0.8781972766424274, 0.8781972766424274, 0.8781972766424274, 0.16498904353322907, 0.16498904353322907, 0.16498904353322907, 0.1675048508288941, 0.1675048508288941, 0.1675048508288941, 0.1677930192856908, 0.1677930192856908, 0.1677930192856908, 0.2096363998358497, 0.2096363998358497, 0.2096363998358497, 0.7527906802205094, 0.7527906802205094, 0.7527906802205094, 0.18281873394226333, 0.18281873394226333, 0.18281873394226333, 0.18751703876694603, 0.18751703876694603, 0.18751703876694603, 0.2003195826305778, 0.2003195826305778, 0.2003195826305778, 0.09323489623740366, 0.09323489623740366, 0.09323489623740366, 0.08957474845720703, 0.08957474845720703, 0.08957474845720703, 0.11110056432631477, 0.11110056432631477, 0.11110056432631477]}, "mutation_prompt": null}
{"id": "d77d980f-ee5b-4a68-aa90-d21aa4a2144d", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.5  # Reduced inertia_weight for quicker convergence\n        self.cognitive_coeff = 1.7  # Increased cognitive_coeff for more exploration\n        self.social_coeff = 1.3  # Reduced social_coeff to improve diversity\n        self.dynamic_adjustment_freq = 10  # Frequency of dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0  # Initialize iteration counter\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:  # Dynamic parameter adjustment\n                self.inertia_weight *= 0.95  # Gradually reduce inertia\n                self.mutation_factor = 0.9 if iteration < self.budget // 2 else 0.7  # Adjust mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1  # Increment iteration counter\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with dynamic parameter adjustment and improved diversity mechanism for accelerated convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a38bff72-ab4d-4016-8bad-941a89cbfbc9", "metadata": {"aucs": [0.8173532858943607, 0.8173532858943607, 0.8173532858943607, 0.8070665307824119, 0.8070665307824119, 0.8070665307824119, 0.8302027387283974, 0.8302027387283974, 0.8302027387283974, 0.5134322341997061, 0.5134322341997061, 0.5134322341997061, 0.624691263026809, 0.624691263026809, 0.624691263026809, 0.6002980633873294, 0.6002980633873294, 0.6002980633873294, 0.15836040046428224, 0.15836040046428224, 0.15836040046428224, 0.13123216050558661, 0.13123216050558661, 0.13123216050558661, 0.27970106171202114, 0.27970106171202114, 0.27970106171202114, 0.15124280349195118, 0.15124280349195118, 0.15124280349195118, 0.09834124134572031, 0.09834124134572031, 0.09834124134572031, 0.12989604071547778, 0.12989604071547778, 0.12989604071547778, 0.9680695927117464, 0.9680695927117464, 0.9680695927117464, 0.9768501235494804, 0.9768501235494804, 0.9768501235494804, 0.9831477879115976, 0.9831477879115976, 0.9831477879115976, 0.5971319790953125, 0.5971319790953125, 0.5971319790953125, 0.48474815956165695, 0.48474815956165695, 0.48474815956165695, 0.5830104602966175, 0.5830104602966175, 0.5830104602966175, 0.27622022111890565, 0.27622022111890565, 0.27622022111890565, 0.18779824886197094, 0.18779824886197094, 0.18779824886197094, 0.33670363500165723, 0.33670363500165723, 0.33670363500165723, 0.2952862590151156, 0.2952862590151156, 0.2952862590151156, 0.12903284797818992, 0.12903284797818992, 0.12903284797818992, 0.19498986972794174, 0.19498986972794174, 0.19498986972794174, 0.21024770382224844, 0.21024770382224844, 0.21024770382224844, 0.18127758222775825, 0.18127758222775825, 0.18127758222775825, 0.1332413227550654, 0.1332413227550654, 0.1332413227550654, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.000591596660297955, 0.000591596660297955, 0.000591596660297955, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1420256776795833, 0.1420256776795833, 0.1420256776795833, 0.020748106240395137, 0.020748106240395137, 0.020748106240395137, 0.1348851129367975, 0.1348851129367975, 0.1348851129367975, 0.04458903399180836, 0.04458903399180836, 0.04458903399180836, 0.11512893530323998, 0.11512893530323998, 0.11512893530323998, 0.08641355632800374, 0.08641355632800374, 0.08641355632800374, 0.14777383418850298, 0.14777383418850298, 0.14777383418850298, 0.07206563016569412, 0.07206563016569412, 0.07206563016569412, 0.07923642752837845, 0.07923642752837845, 0.07923642752837845, 0.5973585429735873, 0.5973585429735873, 0.5973585429735873, 0.5444614487631158, 0.5444614487631158, 0.5444614487631158, 0.5581596112472851, 0.5581596112472851, 0.5581596112472851, 0.10792836734243372, 0.10792836734243372, 0.10792836734243372, 0.16390282508876686, 0.16390282508876686, 0.16390282508876686, 0.08962551634344096, 0.08962551634344096, 0.08962551634344096, 0.19483029090259651, 0.19483029090259651, 0.19483029090259651, 0.2820278660431219, 0.2820278660431219, 0.2820278660431219, 0.26805499101487307, 0.26805499101487307, 0.26805499101487307, 0.24637636277992703, 0.24637636277992703, 0.24637636277992703, 0.3831050982404137, 0.3831050982404137, 0.3831050982404137, 0.4868095742725873, 0.4868095742725873, 0.4868095742725873, 0.16845536602753763, 0.16845536602753763, 0.16845536602753763, 0.3014920382412615, 0.3014920382412615, 0.3014920382412615, 0.36512925182854294, 0.36512925182854294, 0.36512925182854294, 0.22868397010770147, 0.22868397010770147, 0.22868397010770147, 0.22390362207286474, 0.22390362207286474, 0.22390362207286474, 0.21557387697624797, 0.21557387697624797, 0.21557387697624797, 0.19146581710468058, 0.19146581710468058, 0.19146581710468058, 0.2142825225819227, 0.2142825225819227, 0.2142825225819227, 0.23382031825464455, 0.23382031825464455, 0.23382031825464455, 0.8781972766424274, 0.8781972766424274, 0.8781972766424274, 0.16498904353322907, 0.16498904353322907, 0.16498904353322907, 0.1675048508288941, 0.1675048508288941, 0.1675048508288941, 0.1677930192856908, 0.1677930192856908, 0.1677930192856908, 0.2096363998358497, 0.2096363998358497, 0.2096363998358497, 0.7527906802205094, 0.7527906802205094, 0.7527906802205094, 0.18281873394226333, 0.18281873394226333, 0.18281873394226333, 0.18751703876694603, 0.18751703876694603, 0.18751703876694603, 0.2003195826305778, 0.2003195826305778, 0.2003195826305778, 0.09323489623740366, 0.09323489623740366, 0.09323489623740366, 0.08957474845720703, 0.08957474845720703, 0.08957474845720703, 0.11110056432631477, 0.11110056432631477, 0.11110056432631477]}, "mutation_prompt": null}
{"id": "58f98ffd-025e-4af9-b9d8-183102b5c600", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer_V2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor_start = 0.85\n        self.mutation_factor_end = 0.65\n        self.crossover_prob = 0.95  # Slightly increased crossover probability\n        self.inertia_weight_start = 0.7\n        self.inertia_weight_end = 0.4\n        self.cognitive_coeff = 1.9  # Further increased for more exploration\n        self.social_coeff = 1.1  # Further reduced to enhance diversity\n        self.dynamic_adjustment_freq = 10\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (iteration / (self.budget / self.swarm_size))\n            mutation_factor = self.mutation_factor_start - (self.mutation_factor_start - self.mutation_factor_end) * (iteration / (self.budget / self.swarm_size))\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer_V2", "description": "Enhanced convergence through adaptive inertia weight, variant crossover, and increased exploration.", "configspace": "", "generation": 42, "fitness": 0.2554310920415849, "feedback": "The algorithm Enhanced_PSO_ADE_Optimizer_V2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.22.", "error": "", "parent_id": "a38bff72-ab4d-4016-8bad-941a89cbfbc9", "metadata": {"aucs": [0.6886560316554153, 0.6886560316554153, 0.6886560316554153, 0.668370427997896, 0.668370427997896, 0.668370427997896, 0.7115612375811278, 0.7115612375811278, 0.7115612375811278, 0.2672958612569811, 0.2672958612569811, 0.2672958612569811, 0.25940169472335195, 0.25940169472335195, 0.25940169472335195, 0.3148149472633338, 0.3148149472633338, 0.3148149472633338, 0.11763787833977934, 0.11763787833977934, 0.11763787833977934, 0.17727390509702468, 0.17727390509702468, 0.17727390509702468, 0.13817269517560649, 0.13817269517560649, 0.13817269517560649, 0.10960264176687073, 0.10960264176687073, 0.10960264176687073, 0.11701340916822578, 0.11701340916822578, 0.11701340916822578, 0.12017980029886444, 0.12017980029886444, 0.12017980029886444, 0.967749809560158, 0.967749809560158, 0.967749809560158, 0.9770248037732068, 0.9770248037732068, 0.9770248037732068, 0.970550485234597, 0.970550485234597, 0.970550485234597, 0.3359168384489416, 0.3359168384489416, 0.3359168384489416, 0.3297320503644182, 0.3297320503644182, 0.3297320503644182, 0.35009944607307864, 0.35009944607307864, 0.35009944607307864, 0.28475357745138674, 0.28475357745138674, 0.28475357745138674, 0.3465808521928906, 0.3465808521928906, 0.3465808521928906, 0.42168459506317235, 0.42168459506317235, 0.42168459506317235, 0.16032498723724298, 0.16032498723724298, 0.16032498723724298, 0.16468257560115163, 0.16468257560115163, 0.16468257560115163, 0.1666658466349813, 0.1666658466349813, 0.1666658466349813, 0.18351102648502893, 0.18351102648502893, 0.18351102648502893, 0.15708014063651266, 0.15708014063651266, 0.15708014063651266, 0.1841518037962998, 0.1841518037962998, 0.1841518037962998, 0.013071263066319116, 0.013071263066319116, 0.013071263066319116, 0.0368469656380539, 0.0368469656380539, 0.0368469656380539, 0.019104725695488156, 0.019104725695488156, 0.019104725695488156, 0.14802942923472096, 0.14802942923472096, 0.14802942923472096, 0.049073916520070426, 0.049073916520070426, 0.049073916520070426, 0.0380389567407623, 0.0380389567407623, 0.0380389567407623, 0.06216626985150464, 0.06216626985150464, 0.06216626985150464, 0.10890342074159975, 0.10890342074159975, 0.10890342074159975, 0.1145024040680277, 0.1145024040680277, 0.1145024040680277, 0.12671937346985818, 0.12671937346985818, 0.12671937346985818, 0.05827392884623572, 0.05827392884623572, 0.05827392884623572, 0.0742148021631236, 0.0742148021631236, 0.0742148021631236, 0.46955224810203877, 0.46955224810203877, 0.46955224810203877, 0.44544492645752176, 0.44544492645752176, 0.44544492645752176, 0.47838450279555156, 0.47838450279555156, 0.47838450279555156, 0.09648504620000098, 0.09648504620000098, 0.09648504620000098, 0.12534888712140668, 0.12534888712140668, 0.12534888712140668, 0.08638827976455266, 0.08638827976455266, 0.08638827976455266, 0.19072951978805552, 0.19072951978805552, 0.19072951978805552, 0.2067380153209034, 0.2067380153209034, 0.2067380153209034, 0.15323542833959491, 0.15323542833959491, 0.15323542833959491, 0.36597596306417945, 0.36597596306417945, 0.36597596306417945, 0.23928868099769152, 0.23928868099769152, 0.23928868099769152, 0.3874438160167497, 0.3874438160167497, 0.3874438160167497, 0.2406815940937127, 0.2406815940937127, 0.2406815940937127, 0.24884817289439465, 0.24884817289439465, 0.24884817289439465, 0.2522841908355581, 0.2522841908355581, 0.2522841908355581, 0.18991921057065908, 0.18991921057065908, 0.18991921057065908, 0.19405442024006336, 0.19405442024006336, 0.19405442024006336, 0.21250471006633864, 0.21250471006633864, 0.21250471006633864, 0.19883061131909474, 0.19883061131909474, 0.19883061131909474, 0.19848676271907684, 0.19848676271907684, 0.19848676271907684, 0.18766082417366614, 0.18766082417366614, 0.18766082417366614, 0.7986535018306722, 0.7986535018306722, 0.7986535018306722, 0.1555090083070394, 0.1555090083070394, 0.1555090083070394, 0.16606880067174046, 0.16606880067174046, 0.16606880067174046, 0.16690162606679482, 0.16690162606679482, 0.16690162606679482, 0.20949892146761695, 0.20949892146761695, 0.20949892146761695, 0.3424732306218814, 0.3424732306218814, 0.3424732306218814, 0.1757765228253847, 0.1757765228253847, 0.1757765228253847, 0.19777140078200361, 0.19777140078200361, 0.19777140078200361, 0.21351054699211347, 0.21351054699211347, 0.21351054699211347, 0.0828547037181272, 0.0828547037181272, 0.0828547037181272, 0.08057113551040762, 0.08057113551040762, 0.08057113551040762, 0.09372859240620945, 0.09372859240620945, 0.09372859240620945]}, "mutation_prompt": null}
{"id": "5699df29-11c9-4030-abd7-cb207024579b", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.5  # Reduced inertia_weight for quicker convergence\n        self.cognitive_coeff = 1.7  # Increased cognitive_coeff for more exploration\n        self.social_coeff = 1.3  # Reduced social_coeff to improve diversity\n        self.dynamic_adjustment_freq = 10  # Frequency of dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0  # Initialize iteration counter\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:  # Dynamic parameter adjustment\n                self.inertia_weight *= 0.95  # Gradually reduce inertia\n                self.mutation_factor = 0.9 if iteration < self.budget // 2 else 0.7  # Adjust mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1  # Increment iteration counter\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with dynamic parameter adjustment and improved diversity mechanism for accelerated convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a38bff72-ab4d-4016-8bad-941a89cbfbc9", "metadata": {"aucs": [0.8173532858943607, 0.8173532858943607, 0.8173532858943607, 0.8070665307824119, 0.8070665307824119, 0.8070665307824119, 0.8302027387283974, 0.8302027387283974, 0.8302027387283974, 0.5134322341997061, 0.5134322341997061, 0.5134322341997061, 0.624691263026809, 0.624691263026809, 0.624691263026809, 0.6002980633873294, 0.6002980633873294, 0.6002980633873294, 0.15836040046428224, 0.15836040046428224, 0.15836040046428224, 0.13123216050558661, 0.13123216050558661, 0.13123216050558661, 0.27970106171202114, 0.27970106171202114, 0.27970106171202114, 0.15124280349195118, 0.15124280349195118, 0.15124280349195118, 0.09834124134572031, 0.09834124134572031, 0.09834124134572031, 0.12989604071547778, 0.12989604071547778, 0.12989604071547778, 0.9680695927117464, 0.9680695927117464, 0.9680695927117464, 0.9768501235494804, 0.9768501235494804, 0.9768501235494804, 0.9831477879115976, 0.9831477879115976, 0.9831477879115976, 0.5971319790953125, 0.5971319790953125, 0.5971319790953125, 0.48474815956165695, 0.48474815956165695, 0.48474815956165695, 0.5830104602966175, 0.5830104602966175, 0.5830104602966175, 0.27622022111890565, 0.27622022111890565, 0.27622022111890565, 0.18779824886197094, 0.18779824886197094, 0.18779824886197094, 0.33670363500165723, 0.33670363500165723, 0.33670363500165723, 0.2952862590151156, 0.2952862590151156, 0.2952862590151156, 0.12903284797818992, 0.12903284797818992, 0.12903284797818992, 0.19498986972794174, 0.19498986972794174, 0.19498986972794174, 0.21024770382224844, 0.21024770382224844, 0.21024770382224844, 0.18127758222775825, 0.18127758222775825, 0.18127758222775825, 0.1332413227550654, 0.1332413227550654, 0.1332413227550654, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.000591596660297955, 0.000591596660297955, 0.000591596660297955, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1420256776795833, 0.1420256776795833, 0.1420256776795833, 0.020748106240395137, 0.020748106240395137, 0.020748106240395137, 0.1348851129367975, 0.1348851129367975, 0.1348851129367975, 0.04458903399180836, 0.04458903399180836, 0.04458903399180836, 0.11512893530323998, 0.11512893530323998, 0.11512893530323998, 0.08641355632800374, 0.08641355632800374, 0.08641355632800374, 0.14777383418850298, 0.14777383418850298, 0.14777383418850298, 0.07206563016569412, 0.07206563016569412, 0.07206563016569412, 0.07923642752837845, 0.07923642752837845, 0.07923642752837845, 0.5973585429735873, 0.5973585429735873, 0.5973585429735873, 0.5444614487631158, 0.5444614487631158, 0.5444614487631158, 0.5581596112472851, 0.5581596112472851, 0.5581596112472851, 0.10792836734243372, 0.10792836734243372, 0.10792836734243372, 0.16390282508876686, 0.16390282508876686, 0.16390282508876686, 0.08962551634344096, 0.08962551634344096, 0.08962551634344096, 0.19483029090259651, 0.19483029090259651, 0.19483029090259651, 0.2820278660431219, 0.2820278660431219, 0.2820278660431219, 0.26805499101487307, 0.26805499101487307, 0.26805499101487307, 0.24637636277992703, 0.24637636277992703, 0.24637636277992703, 0.3831050982404137, 0.3831050982404137, 0.3831050982404137, 0.4868095742725873, 0.4868095742725873, 0.4868095742725873, 0.16845536602753763, 0.16845536602753763, 0.16845536602753763, 0.3014920382412615, 0.3014920382412615, 0.3014920382412615, 0.36512925182854294, 0.36512925182854294, 0.36512925182854294, 0.22868397010770147, 0.22868397010770147, 0.22868397010770147, 0.22390362207286474, 0.22390362207286474, 0.22390362207286474, 0.21557387697624797, 0.21557387697624797, 0.21557387697624797, 0.19146581710468058, 0.19146581710468058, 0.19146581710468058, 0.2142825225819227, 0.2142825225819227, 0.2142825225819227, 0.23382031825464455, 0.23382031825464455, 0.23382031825464455, 0.8781972766424274, 0.8781972766424274, 0.8781972766424274, 0.16498904353322907, 0.16498904353322907, 0.16498904353322907, 0.1675048508288941, 0.1675048508288941, 0.1675048508288941, 0.1677930192856908, 0.1677930192856908, 0.1677930192856908, 0.2096363998358497, 0.2096363998358497, 0.2096363998358497, 0.7527906802205094, 0.7527906802205094, 0.7527906802205094, 0.18281873394226333, 0.18281873394226333, 0.18281873394226333, 0.18751703876694603, 0.18751703876694603, 0.18751703876694603, 0.2003195826305778, 0.2003195826305778, 0.2003195826305778, 0.09323489623740366, 0.09323489623740366, 0.09323489623740366, 0.08957474845720703, 0.08957474845720703, 0.08957474845720703, 0.11110056432631477, 0.11110056432631477, 0.11110056432631477]}, "mutation_prompt": null}
{"id": "2ed22c6e-c1a5-4fa4-9854-9c68b4b697cf", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.5  # Reduced inertia_weight for quicker convergence\n        self.cognitive_coeff = 1.7  # Increased cognitive_coeff for more exploration\n        self.social_coeff = 1.3  # Reduced social_coeff to improve diversity\n        self.dynamic_adjustment_freq = 10  # Frequency of dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0  # Initialize iteration counter\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:  # Dynamic parameter adjustment\n                self.inertia_weight *= 0.95  # Gradually reduce inertia\n                self.mutation_factor = 0.9 if iteration < self.budget // 2 else 0.7  # Adjust mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1  # Increment iteration counter\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with dynamic parameter adjustment and improved diversity mechanism for accelerated convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a38bff72-ab4d-4016-8bad-941a89cbfbc9", "metadata": {"aucs": [0.8173532858943607, 0.8173532858943607, 0.8173532858943607, 0.8070665307824119, 0.8070665307824119, 0.8070665307824119, 0.8302027387283974, 0.8302027387283974, 0.8302027387283974, 0.5134322341997061, 0.5134322341997061, 0.5134322341997061, 0.624691263026809, 0.624691263026809, 0.624691263026809, 0.6002980633873294, 0.6002980633873294, 0.6002980633873294, 0.15836040046428224, 0.15836040046428224, 0.15836040046428224, 0.13123216050558661, 0.13123216050558661, 0.13123216050558661, 0.27970106171202114, 0.27970106171202114, 0.27970106171202114, 0.15124280349195118, 0.15124280349195118, 0.15124280349195118, 0.09834124134572031, 0.09834124134572031, 0.09834124134572031, 0.12989604071547778, 0.12989604071547778, 0.12989604071547778, 0.9680695927117464, 0.9680695927117464, 0.9680695927117464, 0.9768501235494804, 0.9768501235494804, 0.9768501235494804, 0.9831477879115976, 0.9831477879115976, 0.9831477879115976, 0.5971319790953125, 0.5971319790953125, 0.5971319790953125, 0.48474815956165695, 0.48474815956165695, 0.48474815956165695, 0.5830104602966175, 0.5830104602966175, 0.5830104602966175, 0.27622022111890565, 0.27622022111890565, 0.27622022111890565, 0.18779824886197094, 0.18779824886197094, 0.18779824886197094, 0.33670363500165723, 0.33670363500165723, 0.33670363500165723, 0.2952862590151156, 0.2952862590151156, 0.2952862590151156, 0.12903284797818992, 0.12903284797818992, 0.12903284797818992, 0.19498986972794174, 0.19498986972794174, 0.19498986972794174, 0.21024770382224844, 0.21024770382224844, 0.21024770382224844, 0.18127758222775825, 0.18127758222775825, 0.18127758222775825, 0.1332413227550654, 0.1332413227550654, 0.1332413227550654, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.000591596660297955, 0.000591596660297955, 0.000591596660297955, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1420256776795833, 0.1420256776795833, 0.1420256776795833, 0.020748106240395137, 0.020748106240395137, 0.020748106240395137, 0.1348851129367975, 0.1348851129367975, 0.1348851129367975, 0.04458903399180836, 0.04458903399180836, 0.04458903399180836, 0.11512893530323998, 0.11512893530323998, 0.11512893530323998, 0.08641355632800374, 0.08641355632800374, 0.08641355632800374, 0.14777383418850298, 0.14777383418850298, 0.14777383418850298, 0.07206563016569412, 0.07206563016569412, 0.07206563016569412, 0.07923642752837845, 0.07923642752837845, 0.07923642752837845, 0.5973585429735873, 0.5973585429735873, 0.5973585429735873, 0.5444614487631158, 0.5444614487631158, 0.5444614487631158, 0.5581596112472851, 0.5581596112472851, 0.5581596112472851, 0.10792836734243372, 0.10792836734243372, 0.10792836734243372, 0.16390282508876686, 0.16390282508876686, 0.16390282508876686, 0.08962551634344096, 0.08962551634344096, 0.08962551634344096, 0.19483029090259651, 0.19483029090259651, 0.19483029090259651, 0.2820278660431219, 0.2820278660431219, 0.2820278660431219, 0.26805499101487307, 0.26805499101487307, 0.26805499101487307, 0.24637636277992703, 0.24637636277992703, 0.24637636277992703, 0.3831050982404137, 0.3831050982404137, 0.3831050982404137, 0.4868095742725873, 0.4868095742725873, 0.4868095742725873, 0.16845536602753763, 0.16845536602753763, 0.16845536602753763, 0.3014920382412615, 0.3014920382412615, 0.3014920382412615, 0.36512925182854294, 0.36512925182854294, 0.36512925182854294, 0.22868397010770147, 0.22868397010770147, 0.22868397010770147, 0.22390362207286474, 0.22390362207286474, 0.22390362207286474, 0.21557387697624797, 0.21557387697624797, 0.21557387697624797, 0.19146581710468058, 0.19146581710468058, 0.19146581710468058, 0.2142825225819227, 0.2142825225819227, 0.2142825225819227, 0.23382031825464455, 0.23382031825464455, 0.23382031825464455, 0.8781972766424274, 0.8781972766424274, 0.8781972766424274, 0.16498904353322907, 0.16498904353322907, 0.16498904353322907, 0.1675048508288941, 0.1675048508288941, 0.1675048508288941, 0.1677930192856908, 0.1677930192856908, 0.1677930192856908, 0.2096363998358497, 0.2096363998358497, 0.2096363998358497, 0.7527906802205094, 0.7527906802205094, 0.7527906802205094, 0.18281873394226333, 0.18281873394226333, 0.18281873394226333, 0.18751703876694603, 0.18751703876694603, 0.18751703876694603, 0.2003195826305778, 0.2003195826305778, 0.2003195826305778, 0.09323489623740366, 0.09323489623740366, 0.09323489623740366, 0.08957474845720703, 0.08957474845720703, 0.08957474845720703, 0.11110056432631477, 0.11110056432631477, 0.11110056432631477]}, "mutation_prompt": null}
{"id": "7272bd01-95ee-44f2-b382-4b23fef511ad", "solution": "import numpy as np\n\nclass Hybrid_Dual_Phase_PSO_Adaptive_Mutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.85  # Adjusted mutation factor\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.6  # Increased inertia_weight for exploration\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.4  # Slightly increased social_coeff\n        self.adaptive_mutation_phase = budget // 4  # New dual-phase approach\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            # Adjust inertia_weight dynamically\n            self.inertia_weight *= 0.97  # More gradual reduction\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                if eval_count < self.adaptive_mutation_phase:\n                    indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                    x0, x1, x2 = positions[indices]\n                    mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                else:\n                    mutated_vector = np.clip(personal_best_positions[i] + self.mutation_factor * (global_best_position - personal_best_positions[i]), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "Hybrid_Dual_Phase_PSO_Adaptive_Mutation", "description": "Hybrid Dual-Phase PSO with Adaptive Mutation for enhanced convergence through intensified exploration and exploitation.", "configspace": "", "generation": 45, "fitness": 0.2872557554591408, "feedback": "The algorithm Hybrid_Dual_Phase_PSO_Adaptive_Mutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.26.", "error": "", "parent_id": "a38bff72-ab4d-4016-8bad-941a89cbfbc9", "metadata": {"aucs": [0.8444992380392953, 0.8444992380392953, 0.8444992380392953, 0.8388074914740762, 0.8388074914740762, 0.8388074914740762, 0.843328338658988, 0.843328338658988, 0.843328338658988, 0.6630016529552987, 0.6630016529552987, 0.6630016529552987, 0.6774538761614401, 0.6774538761614401, 0.6774538761614401, 0.6857025986567604, 0.6857025986567604, 0.6857025986567604, 0.1517040529564221, 0.1517040529564221, 0.1517040529564221, 0.1721507759148424, 0.1721507759148424, 0.1721507759148424, 0.14845262108831225, 0.14845262108831225, 0.14845262108831225, 0.10941486863358418, 0.10941486863358418, 0.10941486863358418, 0.10631070099856388, 0.10631070099856388, 0.10631070099856388, 0.14297724892123242, 0.14297724892123242, 0.14297724892123242, 0.9760995472423426, 0.9760995472423426, 0.9760995472423426, 0.9768651902424917, 0.9768651902424917, 0.9768651902424917, 0.9832397066042637, 0.9832397066042637, 0.9832397066042637, 0.5965433896568388, 0.5965433896568388, 0.5965433896568388, 0.4024393346400005, 0.4024393346400005, 0.4024393346400005, 0.34348496483819857, 0.34348496483819857, 0.34348496483819857, 0.21218471556226937, 0.21218471556226937, 0.21218471556226937, 0.36679075108382664, 0.36679075108382664, 0.36679075108382664, 0.16930902001755932, 0.16930902001755932, 0.16930902001755932, 0.16546432316104787, 0.16546432316104787, 0.16546432316104787, 0.12377347239693737, 0.12377347239693737, 0.12377347239693737, 0.1633900234762654, 0.1633900234762654, 0.1633900234762654, 0.18571500679993902, 0.18571500679993902, 0.18571500679993902, 0.12617715592839418, 0.12617715592839418, 0.12617715592839418, 0.13103740636750427, 0.13103740636750427, 0.13103740636750427, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19709538972950869, 0.19709538972950869, 0.19709538972950869, 0.00697726727817749, 0.00697726727817749, 0.00697726727817749, 0.054161659534430195, 0.054161659534430195, 0.054161659534430195, 0.04579737461821021, 0.04579737461821021, 0.04579737461821021, 0.0769091695561841, 0.0769091695561841, 0.0769091695561841, 0.11345429107549243, 0.11345429107549243, 0.11345429107549243, 0.3389761283373094, 0.3389761283373094, 0.3389761283373094, 0.03749633733512214, 0.03749633733512214, 0.03749633733512214, 0.07857823116988583, 0.07857823116988583, 0.07857823116988583, 0.4998856319117717, 0.4998856319117717, 0.4998856319117717, 0.5368100649405254, 0.5368100649405254, 0.5368100649405254, 0.5213210595462897, 0.5213210595462897, 0.5213210595462897, 0.10796637625319672, 0.10796637625319672, 0.10796637625319672, 0.11202106150714952, 0.11202106150714952, 0.11202106150714952, 0.14822847897165026, 0.14822847897165026, 0.14822847897165026, 0.26982627530144987, 0.26982627530144987, 0.26982627530144987, 0.15466173768000502, 0.15466173768000502, 0.15466173768000502, 0.16158669703472228, 0.16158669703472228, 0.16158669703472228, 0.4046950981084295, 0.4046950981084295, 0.4046950981084295, 0.3847243048199681, 0.3847243048199681, 0.3847243048199681, 0.3811262370555589, 0.3811262370555589, 0.3811262370555589, 0.274104236239718, 0.274104236239718, 0.274104236239718, 0.22727529609142705, 0.22727529609142705, 0.22727529609142705, 0.1845084730998796, 0.1845084730998796, 0.1845084730998796, 0.23680828447773072, 0.23680828447773072, 0.23680828447773072, 0.22685318512850494, 0.22685318512850494, 0.22685318512850494, 0.25231088490391307, 0.25231088490391307, 0.25231088490391307, 0.24054873202356053, 0.24054873202356053, 0.24054873202356053, 0.20772837979330094, 0.20772837979330094, 0.20772837979330094, 0.24512385944301718, 0.24512385944301718, 0.24512385944301718, 0.8872685051305179, 0.8872685051305179, 0.8872685051305179, 0.16314105043412896, 0.16314105043412896, 0.16314105043412896, 0.1687395560705358, 0.1687395560705358, 0.1687395560705358, 0.1685287146938359, 0.1685287146938359, 0.1685287146938359, 0.20850596624068907, 0.20850596624068907, 0.20850596624068907, 0.1554910787674051, 0.1554910787674051, 0.1554910787674051, 0.19754670281995945, 0.19754670281995945, 0.19754670281995945, 0.1933387265756209, 0.1933387265756209, 0.1933387265756209, 0.1841224049695045, 0.1841224049695045, 0.1841224049695045, 0.10213444924472348, 0.10213444924472348, 0.10213444924472348, 0.10067086466998187, 0.10067086466998187, 0.10067086466998187, 0.11874869799844723, 0.11874869799844723, 0.11874869799844723]}, "mutation_prompt": null}
{"id": "8efc1477-e9d3-48a9-affc-41f7d93efdb4", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.5  # Reduced inertia_weight for quicker convergence\n        self.cognitive_coeff = 1.7  # Increased cognitive_coeff for more exploration\n        self.social_coeff = 1.3  # Reduced social_coeff to improve diversity\n        self.dynamic_adjustment_freq = 10  # Frequency of dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0  # Initialize iteration counter\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:  # Dynamic parameter adjustment\n                self.inertia_weight *= 0.95  # Gradually reduce inertia\n                self.mutation_factor = 0.9 if iteration < self.budget // 2 else 0.7  # Adjust mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1  # Increment iteration counter\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with dynamic parameter adjustment and improved diversity mechanism for accelerated convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a38bff72-ab4d-4016-8bad-941a89cbfbc9", "metadata": {"aucs": [0.8173532858943607, 0.8173532858943607, 0.8173532858943607, 0.8070665307824119, 0.8070665307824119, 0.8070665307824119, 0.8302027387283974, 0.8302027387283974, 0.8302027387283974, 0.5134322341997061, 0.5134322341997061, 0.5134322341997061, 0.624691263026809, 0.624691263026809, 0.624691263026809, 0.6002980633873294, 0.6002980633873294, 0.6002980633873294, 0.15836040046428224, 0.15836040046428224, 0.15836040046428224, 0.13123216050558661, 0.13123216050558661, 0.13123216050558661, 0.27970106171202114, 0.27970106171202114, 0.27970106171202114, 0.15124280349195118, 0.15124280349195118, 0.15124280349195118, 0.09834124134572031, 0.09834124134572031, 0.09834124134572031, 0.12989604071547778, 0.12989604071547778, 0.12989604071547778, 0.9680695927117464, 0.9680695927117464, 0.9680695927117464, 0.9768501235494804, 0.9768501235494804, 0.9768501235494804, 0.9831477879115976, 0.9831477879115976, 0.9831477879115976, 0.5971319790953125, 0.5971319790953125, 0.5971319790953125, 0.48474815956165695, 0.48474815956165695, 0.48474815956165695, 0.5830104602966175, 0.5830104602966175, 0.5830104602966175, 0.27622022111890565, 0.27622022111890565, 0.27622022111890565, 0.18779824886197094, 0.18779824886197094, 0.18779824886197094, 0.33670363500165723, 0.33670363500165723, 0.33670363500165723, 0.2952862590151156, 0.2952862590151156, 0.2952862590151156, 0.12903284797818992, 0.12903284797818992, 0.12903284797818992, 0.19498986972794174, 0.19498986972794174, 0.19498986972794174, 0.21024770382224844, 0.21024770382224844, 0.21024770382224844, 0.18127758222775825, 0.18127758222775825, 0.18127758222775825, 0.1332413227550654, 0.1332413227550654, 0.1332413227550654, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.000591596660297955, 0.000591596660297955, 0.000591596660297955, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1420256776795833, 0.1420256776795833, 0.1420256776795833, 0.020748106240395137, 0.020748106240395137, 0.020748106240395137, 0.1348851129367975, 0.1348851129367975, 0.1348851129367975, 0.04458903399180836, 0.04458903399180836, 0.04458903399180836, 0.11512893530323998, 0.11512893530323998, 0.11512893530323998, 0.08641355632800374, 0.08641355632800374, 0.08641355632800374, 0.14777383418850298, 0.14777383418850298, 0.14777383418850298, 0.07206563016569412, 0.07206563016569412, 0.07206563016569412, 0.07923642752837845, 0.07923642752837845, 0.07923642752837845, 0.5973585429735873, 0.5973585429735873, 0.5973585429735873, 0.5444614487631158, 0.5444614487631158, 0.5444614487631158, 0.5581596112472851, 0.5581596112472851, 0.5581596112472851, 0.10792836734243372, 0.10792836734243372, 0.10792836734243372, 0.16390282508876686, 0.16390282508876686, 0.16390282508876686, 0.08962551634344096, 0.08962551634344096, 0.08962551634344096, 0.19483029090259651, 0.19483029090259651, 0.19483029090259651, 0.2820278660431219, 0.2820278660431219, 0.2820278660431219, 0.26805499101487307, 0.26805499101487307, 0.26805499101487307, 0.24637636277992703, 0.24637636277992703, 0.24637636277992703, 0.3831050982404137, 0.3831050982404137, 0.3831050982404137, 0.4868095742725873, 0.4868095742725873, 0.4868095742725873, 0.16845536602753763, 0.16845536602753763, 0.16845536602753763, 0.3014920382412615, 0.3014920382412615, 0.3014920382412615, 0.36512925182854294, 0.36512925182854294, 0.36512925182854294, 0.22868397010770147, 0.22868397010770147, 0.22868397010770147, 0.22390362207286474, 0.22390362207286474, 0.22390362207286474, 0.21557387697624797, 0.21557387697624797, 0.21557387697624797, 0.19146581710468058, 0.19146581710468058, 0.19146581710468058, 0.2142825225819227, 0.2142825225819227, 0.2142825225819227, 0.23382031825464455, 0.23382031825464455, 0.23382031825464455, 0.8781972766424274, 0.8781972766424274, 0.8781972766424274, 0.16498904353322907, 0.16498904353322907, 0.16498904353322907, 0.1675048508288941, 0.1675048508288941, 0.1675048508288941, 0.1677930192856908, 0.1677930192856908, 0.1677930192856908, 0.2096363998358497, 0.2096363998358497, 0.2096363998358497, 0.7527906802205094, 0.7527906802205094, 0.7527906802205094, 0.18281873394226333, 0.18281873394226333, 0.18281873394226333, 0.18751703876694603, 0.18751703876694603, 0.18751703876694603, 0.2003195826305778, 0.2003195826305778, 0.2003195826305778, 0.09323489623740366, 0.09323489623740366, 0.09323489623740366, 0.08957474845720703, 0.08957474845720703, 0.08957474845720703, 0.11110056432631477, 0.11110056432631477, 0.11110056432631477]}, "mutation_prompt": null}
{"id": "4696f227-1935-4512-a75e-1ecacf2bdf79", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.5  # Reduced inertia_weight for quicker convergence\n        self.cognitive_coeff = 1.7  # Increased cognitive_coeff for more exploration\n        self.social_coeff = 1.3  # Reduced social_coeff to improve diversity\n        self.dynamic_adjustment_freq = 10  # Frequency of dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0  # Initialize iteration counter\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:  # Dynamic parameter adjustment\n                self.inertia_weight *= 0.95  # Gradually reduce inertia\n                self.mutation_factor = 0.9 if iteration < self.budget // 2 else 0.7  # Adjust mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1  # Increment iteration counter\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with dynamic parameter adjustment and improved diversity mechanism for accelerated convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a38bff72-ab4d-4016-8bad-941a89cbfbc9", "metadata": {"aucs": [0.8173532858943607, 0.8173532858943607, 0.8173532858943607, 0.8070665307824119, 0.8070665307824119, 0.8070665307824119, 0.8302027387283974, 0.8302027387283974, 0.8302027387283974, 0.5134322341997061, 0.5134322341997061, 0.5134322341997061, 0.624691263026809, 0.624691263026809, 0.624691263026809, 0.6002980633873294, 0.6002980633873294, 0.6002980633873294, 0.15836040046428224, 0.15836040046428224, 0.15836040046428224, 0.13123216050558661, 0.13123216050558661, 0.13123216050558661, 0.27970106171202114, 0.27970106171202114, 0.27970106171202114, 0.15124280349195118, 0.15124280349195118, 0.15124280349195118, 0.09834124134572031, 0.09834124134572031, 0.09834124134572031, 0.12989604071547778, 0.12989604071547778, 0.12989604071547778, 0.9680695927117464, 0.9680695927117464, 0.9680695927117464, 0.9768501235494804, 0.9768501235494804, 0.9768501235494804, 0.9831477879115976, 0.9831477879115976, 0.9831477879115976, 0.5971319790953125, 0.5971319790953125, 0.5971319790953125, 0.48474815956165695, 0.48474815956165695, 0.48474815956165695, 0.5830104602966175, 0.5830104602966175, 0.5830104602966175, 0.27622022111890565, 0.27622022111890565, 0.27622022111890565, 0.18779824886197094, 0.18779824886197094, 0.18779824886197094, 0.33670363500165723, 0.33670363500165723, 0.33670363500165723, 0.2952862590151156, 0.2952862590151156, 0.2952862590151156, 0.12903284797818992, 0.12903284797818992, 0.12903284797818992, 0.19498986972794174, 0.19498986972794174, 0.19498986972794174, 0.21024770382224844, 0.21024770382224844, 0.21024770382224844, 0.18127758222775825, 0.18127758222775825, 0.18127758222775825, 0.1332413227550654, 0.1332413227550654, 0.1332413227550654, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.000591596660297955, 0.000591596660297955, 0.000591596660297955, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1420256776795833, 0.1420256776795833, 0.1420256776795833, 0.020748106240395137, 0.020748106240395137, 0.020748106240395137, 0.1348851129367975, 0.1348851129367975, 0.1348851129367975, 0.04458903399180836, 0.04458903399180836, 0.04458903399180836, 0.11512893530323998, 0.11512893530323998, 0.11512893530323998, 0.08641355632800374, 0.08641355632800374, 0.08641355632800374, 0.14777383418850298, 0.14777383418850298, 0.14777383418850298, 0.07206563016569412, 0.07206563016569412, 0.07206563016569412, 0.07923642752837845, 0.07923642752837845, 0.07923642752837845, 0.5973585429735873, 0.5973585429735873, 0.5973585429735873, 0.5444614487631158, 0.5444614487631158, 0.5444614487631158, 0.5581596112472851, 0.5581596112472851, 0.5581596112472851, 0.10792836734243372, 0.10792836734243372, 0.10792836734243372, 0.16390282508876686, 0.16390282508876686, 0.16390282508876686, 0.08962551634344096, 0.08962551634344096, 0.08962551634344096, 0.19483029090259651, 0.19483029090259651, 0.19483029090259651, 0.2820278660431219, 0.2820278660431219, 0.2820278660431219, 0.26805499101487307, 0.26805499101487307, 0.26805499101487307, 0.24637636277992703, 0.24637636277992703, 0.24637636277992703, 0.3831050982404137, 0.3831050982404137, 0.3831050982404137, 0.4868095742725873, 0.4868095742725873, 0.4868095742725873, 0.16845536602753763, 0.16845536602753763, 0.16845536602753763, 0.3014920382412615, 0.3014920382412615, 0.3014920382412615, 0.36512925182854294, 0.36512925182854294, 0.36512925182854294, 0.22868397010770147, 0.22868397010770147, 0.22868397010770147, 0.22390362207286474, 0.22390362207286474, 0.22390362207286474, 0.21557387697624797, 0.21557387697624797, 0.21557387697624797, 0.19146581710468058, 0.19146581710468058, 0.19146581710468058, 0.2142825225819227, 0.2142825225819227, 0.2142825225819227, 0.23382031825464455, 0.23382031825464455, 0.23382031825464455, 0.8781972766424274, 0.8781972766424274, 0.8781972766424274, 0.16498904353322907, 0.16498904353322907, 0.16498904353322907, 0.1675048508288941, 0.1675048508288941, 0.1675048508288941, 0.1677930192856908, 0.1677930192856908, 0.1677930192856908, 0.2096363998358497, 0.2096363998358497, 0.2096363998358497, 0.7527906802205094, 0.7527906802205094, 0.7527906802205094, 0.18281873394226333, 0.18281873394226333, 0.18281873394226333, 0.18751703876694603, 0.18751703876694603, 0.18751703876694603, 0.2003195826305778, 0.2003195826305778, 0.2003195826305778, 0.09323489623740366, 0.09323489623740366, 0.09323489623740366, 0.08957474845720703, 0.08957474845720703, 0.08957474845720703, 0.11110056432631477, 0.11110056432631477, 0.11110056432631477]}, "mutation_prompt": null}
{"id": "f1919502-d5cc-4af3-ad65-f2c22ea608d0", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.5  # Reduced inertia_weight for quicker convergence\n        self.cognitive_coeff = 1.7  # Increased cognitive_coeff for more exploration\n        self.social_coeff = 1.3  # Reduced social_coeff to improve diversity\n        self.dynamic_adjustment_freq = 10  # Frequency of dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0  # Initialize iteration counter\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:  # Dynamic parameter adjustment\n                self.inertia_weight *= 0.95  # Gradually reduce inertia\n                self.mutation_factor = 0.9 if iteration < self.budget // 2 else 0.7  # Adjust mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1  # Increment iteration counter\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with dynamic parameter adjustment and improved diversity mechanism for accelerated convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a38bff72-ab4d-4016-8bad-941a89cbfbc9", "metadata": {"aucs": [0.8173532858943607, 0.8173532858943607, 0.8173532858943607, 0.8070665307824119, 0.8070665307824119, 0.8070665307824119, 0.8302027387283974, 0.8302027387283974, 0.8302027387283974, 0.5134322341997061, 0.5134322341997061, 0.5134322341997061, 0.624691263026809, 0.624691263026809, 0.624691263026809, 0.6002980633873294, 0.6002980633873294, 0.6002980633873294, 0.15836040046428224, 0.15836040046428224, 0.15836040046428224, 0.13123216050558661, 0.13123216050558661, 0.13123216050558661, 0.27970106171202114, 0.27970106171202114, 0.27970106171202114, 0.15124280349195118, 0.15124280349195118, 0.15124280349195118, 0.09834124134572031, 0.09834124134572031, 0.09834124134572031, 0.12989604071547778, 0.12989604071547778, 0.12989604071547778, 0.9680695927117464, 0.9680695927117464, 0.9680695927117464, 0.9768501235494804, 0.9768501235494804, 0.9768501235494804, 0.9831477879115976, 0.9831477879115976, 0.9831477879115976, 0.5971319790953125, 0.5971319790953125, 0.5971319790953125, 0.48474815956165695, 0.48474815956165695, 0.48474815956165695, 0.5830104602966175, 0.5830104602966175, 0.5830104602966175, 0.27622022111890565, 0.27622022111890565, 0.27622022111890565, 0.18779824886197094, 0.18779824886197094, 0.18779824886197094, 0.33670363500165723, 0.33670363500165723, 0.33670363500165723, 0.2952862590151156, 0.2952862590151156, 0.2952862590151156, 0.12903284797818992, 0.12903284797818992, 0.12903284797818992, 0.19498986972794174, 0.19498986972794174, 0.19498986972794174, 0.21024770382224844, 0.21024770382224844, 0.21024770382224844, 0.18127758222775825, 0.18127758222775825, 0.18127758222775825, 0.1332413227550654, 0.1332413227550654, 0.1332413227550654, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.000591596660297955, 0.000591596660297955, 0.000591596660297955, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1420256776795833, 0.1420256776795833, 0.1420256776795833, 0.020748106240395137, 0.020748106240395137, 0.020748106240395137, 0.1348851129367975, 0.1348851129367975, 0.1348851129367975, 0.04458903399180836, 0.04458903399180836, 0.04458903399180836, 0.11512893530323998, 0.11512893530323998, 0.11512893530323998, 0.08641355632800374, 0.08641355632800374, 0.08641355632800374, 0.14777383418850298, 0.14777383418850298, 0.14777383418850298, 0.07206563016569412, 0.07206563016569412, 0.07206563016569412, 0.07923642752837845, 0.07923642752837845, 0.07923642752837845, 0.5973585429735873, 0.5973585429735873, 0.5973585429735873, 0.5444614487631158, 0.5444614487631158, 0.5444614487631158, 0.5581596112472851, 0.5581596112472851, 0.5581596112472851, 0.10792836734243372, 0.10792836734243372, 0.10792836734243372, 0.16390282508876686, 0.16390282508876686, 0.16390282508876686, 0.08962551634344096, 0.08962551634344096, 0.08962551634344096, 0.19483029090259651, 0.19483029090259651, 0.19483029090259651, 0.2820278660431219, 0.2820278660431219, 0.2820278660431219, 0.26805499101487307, 0.26805499101487307, 0.26805499101487307, 0.24637636277992703, 0.24637636277992703, 0.24637636277992703, 0.3831050982404137, 0.3831050982404137, 0.3831050982404137, 0.4868095742725873, 0.4868095742725873, 0.4868095742725873, 0.16845536602753763, 0.16845536602753763, 0.16845536602753763, 0.3014920382412615, 0.3014920382412615, 0.3014920382412615, 0.36512925182854294, 0.36512925182854294, 0.36512925182854294, 0.22868397010770147, 0.22868397010770147, 0.22868397010770147, 0.22390362207286474, 0.22390362207286474, 0.22390362207286474, 0.21557387697624797, 0.21557387697624797, 0.21557387697624797, 0.19146581710468058, 0.19146581710468058, 0.19146581710468058, 0.2142825225819227, 0.2142825225819227, 0.2142825225819227, 0.23382031825464455, 0.23382031825464455, 0.23382031825464455, 0.8781972766424274, 0.8781972766424274, 0.8781972766424274, 0.16498904353322907, 0.16498904353322907, 0.16498904353322907, 0.1675048508288941, 0.1675048508288941, 0.1675048508288941, 0.1677930192856908, 0.1677930192856908, 0.1677930192856908, 0.2096363998358497, 0.2096363998358497, 0.2096363998358497, 0.7527906802205094, 0.7527906802205094, 0.7527906802205094, 0.18281873394226333, 0.18281873394226333, 0.18281873394226333, 0.18751703876694603, 0.18751703876694603, 0.18751703876694603, 0.2003195826305778, 0.2003195826305778, 0.2003195826305778, 0.09323489623740366, 0.09323489623740366, 0.09323489623740366, 0.08957474845720703, 0.08957474845720703, 0.08957474845720703, 0.11110056432631477, 0.11110056432631477, 0.11110056432631477]}, "mutation_prompt": null}
{"id": "931d7c52-670f-42e2-98a6-99061cda4e6b", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.5  # Reduced inertia_weight for quicker convergence\n        self.cognitive_coeff = 1.7  # Increased cognitive_coeff for more exploration\n        self.social_coeff = 1.3  # Reduced social_coeff to improve diversity\n        self.dynamic_adjustment_freq = 10  # Frequency of dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0  # Initialize iteration counter\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:  # Dynamic parameter adjustment\n                self.inertia_weight *= 0.95  # Gradually reduce inertia\n                self.mutation_factor = 0.9 if iteration < self.budget // 2 else 0.7  # Adjust mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1  # Increment iteration counter\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with dynamic parameter adjustment and improved diversity mechanism for accelerated convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a38bff72-ab4d-4016-8bad-941a89cbfbc9", "metadata": {"aucs": [0.8173532858943607, 0.8173532858943607, 0.8173532858943607, 0.8070665307824119, 0.8070665307824119, 0.8070665307824119, 0.8302027387283974, 0.8302027387283974, 0.8302027387283974, 0.5134322341997061, 0.5134322341997061, 0.5134322341997061, 0.624691263026809, 0.624691263026809, 0.624691263026809, 0.6002980633873294, 0.6002980633873294, 0.6002980633873294, 0.15836040046428224, 0.15836040046428224, 0.15836040046428224, 0.13123216050558661, 0.13123216050558661, 0.13123216050558661, 0.27970106171202114, 0.27970106171202114, 0.27970106171202114, 0.15124280349195118, 0.15124280349195118, 0.15124280349195118, 0.09834124134572031, 0.09834124134572031, 0.09834124134572031, 0.12989604071547778, 0.12989604071547778, 0.12989604071547778, 0.9680695927117464, 0.9680695927117464, 0.9680695927117464, 0.9768501235494804, 0.9768501235494804, 0.9768501235494804, 0.9831477879115976, 0.9831477879115976, 0.9831477879115976, 0.5971319790953125, 0.5971319790953125, 0.5971319790953125, 0.48474815956165695, 0.48474815956165695, 0.48474815956165695, 0.5830104602966175, 0.5830104602966175, 0.5830104602966175, 0.27622022111890565, 0.27622022111890565, 0.27622022111890565, 0.18779824886197094, 0.18779824886197094, 0.18779824886197094, 0.33670363500165723, 0.33670363500165723, 0.33670363500165723, 0.2952862590151156, 0.2952862590151156, 0.2952862590151156, 0.12903284797818992, 0.12903284797818992, 0.12903284797818992, 0.19498986972794174, 0.19498986972794174, 0.19498986972794174, 0.21024770382224844, 0.21024770382224844, 0.21024770382224844, 0.18127758222775825, 0.18127758222775825, 0.18127758222775825, 0.1332413227550654, 0.1332413227550654, 0.1332413227550654, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.000591596660297955, 0.000591596660297955, 0.000591596660297955, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1420256776795833, 0.1420256776795833, 0.1420256776795833, 0.020748106240395137, 0.020748106240395137, 0.020748106240395137, 0.1348851129367975, 0.1348851129367975, 0.1348851129367975, 0.04458903399180836, 0.04458903399180836, 0.04458903399180836, 0.11512893530323998, 0.11512893530323998, 0.11512893530323998, 0.08641355632800374, 0.08641355632800374, 0.08641355632800374, 0.14777383418850298, 0.14777383418850298, 0.14777383418850298, 0.07206563016569412, 0.07206563016569412, 0.07206563016569412, 0.07923642752837845, 0.07923642752837845, 0.07923642752837845, 0.5973585429735873, 0.5973585429735873, 0.5973585429735873, 0.5444614487631158, 0.5444614487631158, 0.5444614487631158, 0.5581596112472851, 0.5581596112472851, 0.5581596112472851, 0.10792836734243372, 0.10792836734243372, 0.10792836734243372, 0.16390282508876686, 0.16390282508876686, 0.16390282508876686, 0.08962551634344096, 0.08962551634344096, 0.08962551634344096, 0.19483029090259651, 0.19483029090259651, 0.19483029090259651, 0.2820278660431219, 0.2820278660431219, 0.2820278660431219, 0.26805499101487307, 0.26805499101487307, 0.26805499101487307, 0.24637636277992703, 0.24637636277992703, 0.24637636277992703, 0.3831050982404137, 0.3831050982404137, 0.3831050982404137, 0.4868095742725873, 0.4868095742725873, 0.4868095742725873, 0.16845536602753763, 0.16845536602753763, 0.16845536602753763, 0.3014920382412615, 0.3014920382412615, 0.3014920382412615, 0.36512925182854294, 0.36512925182854294, 0.36512925182854294, 0.22868397010770147, 0.22868397010770147, 0.22868397010770147, 0.22390362207286474, 0.22390362207286474, 0.22390362207286474, 0.21557387697624797, 0.21557387697624797, 0.21557387697624797, 0.19146581710468058, 0.19146581710468058, 0.19146581710468058, 0.2142825225819227, 0.2142825225819227, 0.2142825225819227, 0.23382031825464455, 0.23382031825464455, 0.23382031825464455, 0.8781972766424274, 0.8781972766424274, 0.8781972766424274, 0.16498904353322907, 0.16498904353322907, 0.16498904353322907, 0.1675048508288941, 0.1675048508288941, 0.1675048508288941, 0.1677930192856908, 0.1677930192856908, 0.1677930192856908, 0.2096363998358497, 0.2096363998358497, 0.2096363998358497, 0.7527906802205094, 0.7527906802205094, 0.7527906802205094, 0.18281873394226333, 0.18281873394226333, 0.18281873394226333, 0.18751703876694603, 0.18751703876694603, 0.18751703876694603, 0.2003195826305778, 0.2003195826305778, 0.2003195826305778, 0.09323489623740366, 0.09323489623740366, 0.09323489623740366, 0.08957474845720703, 0.08957474845720703, 0.08957474845720703, 0.11110056432631477, 0.11110056432631477, 0.11110056432631477]}, "mutation_prompt": null}
{"id": "c28960fa-e24e-4850-b4d9-73ae6773ce84", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer_V2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.85  # Slight increase in mutation factor for better exploration\n        self.crossover_prob = 0.85  # Reduced crossover probability to maintain diversity\n        self.inertia_weight = 0.6  # Increased inertia_weight for balanced exploration-exploitation\n        self.cognitive_coeff = 2.0  # Further increase cognitive_coeff for aggressive personal search\n        self.social_coeff = 1.2  # Slightly reduce social_coeff to retain swarm diversity\n        self.dynamic_adjustment_freq = 8  # More frequent dynamic parameter adjustment\n        self.local_search_threshold = 0.1  # Threshold for stochastic local search\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.93  # Faster reduction in inertia\n                self.mutation_factor = 1.0 if iteration < self.budget // 3 else 0.75  # More aggressive mutation adaptation\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            local_search_indices = np.where(np.random.rand(self.swarm_size) < self.local_search_threshold)[0]\n            for i in range(self.swarm_size):\n                if i in local_search_indices:\n                    random_search = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    if func(random_search) < personal_best_scores[i]:\n                        personal_best_positions[i], personal_best_scores[i] = random_search, func(random_search)\n                        eval_count += 2\n\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer_V2", "description": "Further enhanced PSO-ADE with refined parameter adaptation and stochastic local search strategy for improved convergence speed.", "configspace": "", "generation": 50, "fitness": 0.270413102062757, "feedback": "The algorithm Enhanced_PSO_ADE_Optimizer_V2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.24.", "error": "", "parent_id": "a38bff72-ab4d-4016-8bad-941a89cbfbc9", "metadata": {"aucs": [0.7761237217331028, 0.7761237217331028, 0.7761237217331028, 0.7827558732140997, 0.7827558732140997, 0.7827558732140997, 0.7900741409510497, 0.7900741409510497, 0.7900741409510497, 0.5872607514727548, 0.5872607514727548, 0.5872607514727548, 0.530159960529573, 0.530159960529573, 0.530159960529573, 0.5679075576631661, 0.5679075576631661, 0.5679075576631661, 0.1467488842562078, 0.1467488842562078, 0.1467488842562078, 0.12682094790698162, 0.12682094790698162, 0.12682094790698162, 0.14521618365264854, 0.14521618365264854, 0.14521618365264854, 0.12274790374773548, 0.12274790374773548, 0.12274790374773548, 0.09038709277751511, 0.09038709277751511, 0.09038709277751511, 0.13459469932505108, 0.13459469932505108, 0.13459469932505108, 0.9816835682981596, 0.9816835682981596, 0.9816835682981596, 0.9819865809538522, 0.9819865809538522, 0.9819865809538522, 0.9732247079160885, 0.9732247079160885, 0.9732247079160885, 0.44268780315529743, 0.44268780315529743, 0.44268780315529743, 0.49950869446253576, 0.49950869446253576, 0.49950869446253576, 0.49101382982363495, 0.49101382982363495, 0.49101382982363495, 0.5452763532137512, 0.5452763532137512, 0.5452763532137512, 0.15917902046362886, 0.15917902046362886, 0.15917902046362886, 0.22818063902709818, 0.22818063902709818, 0.22818063902709818, 0.18827252675756334, 0.18827252675756334, 0.18827252675756334, 0.12865654596587262, 0.12865654596587262, 0.12865654596587262, 0.18105180006268018, 0.18105180006268018, 0.18105180006268018, 0.20616817150715538, 0.20616817150715538, 0.20616817150715538, 0.15131100876495807, 0.15131100876495807, 0.15131100876495807, 0.19944821813198355, 0.19944821813198355, 0.19944821813198355, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11787452798117903, 0.11787452798117903, 0.11787452798117903, 0.07513775477779405, 0.07513775477779405, 0.07513775477779405, 0.09717827635605647, 0.09717827635605647, 0.09717827635605647, 0.040666653018612164, 0.040666653018612164, 0.040666653018612164, 0.06821199764755637, 0.06821199764755637, 0.06821199764755637, 0.05994157401787581, 0.05994157401787581, 0.05994157401787581, 0.13050626582871117, 0.13050626582871117, 0.13050626582871117, 0.05044340923435808, 0.05044340923435808, 0.05044340923435808, 0.07687812092097757, 0.07687812092097757, 0.07687812092097757, 0.5107603820249593, 0.5107603820249593, 0.5107603820249593, 0.5461323046166229, 0.5461323046166229, 0.5461323046166229, 0.5448010301149655, 0.5448010301149655, 0.5448010301149655, 0.11544012701803308, 0.11544012701803308, 0.11544012701803308, 0.10272600208254501, 0.10272600208254501, 0.10272600208254501, 0.11979088318455522, 0.11979088318455522, 0.11979088318455522, 0.19253912639116577, 0.19253912639116577, 0.19253912639116577, 0.17917167462821304, 0.17917167462821304, 0.17917167462821304, 0.20076554288897464, 0.20076554288897464, 0.20076554288897464, 0.22156678952272413, 0.22156678952272413, 0.22156678952272413, 0.29587037362315616, 0.29587037362315616, 0.29587037362315616, 0.3198668118275799, 0.3198668118275799, 0.3198668118275799, 0.21334390816300197, 0.21334390816300197, 0.21334390816300197, 0.25721898729598325, 0.25721898729598325, 0.25721898729598325, 0.253666620474446, 0.253666620474446, 0.253666620474446, 0.2160304813198688, 0.2160304813198688, 0.2160304813198688, 0.21437730025385282, 0.21437730025385282, 0.21437730025385282, 0.19989397030104283, 0.19989397030104283, 0.19989397030104283, 0.22912962441261364, 0.22912962441261364, 0.22912962441261364, 0.1839321105716758, 0.1839321105716758, 0.1839321105716758, 0.19881545627895802, 0.19881545627895802, 0.19881545627895802, 0.18730075861239204, 0.18730075861239204, 0.18730075861239204, 0.15757352657928858, 0.15757352657928858, 0.15757352657928858, 0.16778589381046882, 0.16778589381046882, 0.16778589381046882, 0.16685256489210365, 0.16685256489210365, 0.16685256489210365, 0.5780408696012262, 0.5780408696012262, 0.5780408696012262, 0.15463665724814213, 0.15463665724814213, 0.15463665724814213, 0.1974691091887083, 0.1974691091887083, 0.1974691091887083, 0.18141362495864866, 0.18141362495864866, 0.18141362495864866, 0.21316901736600735, 0.21316901736600735, 0.21316901736600735, 0.0916076114158908, 0.0916076114158908, 0.0916076114158908, 0.08962232879242349, 0.08962232879242349, 0.08962232879242349, 0.09284611354099559, 0.09284611354099559, 0.09284611354099559]}, "mutation_prompt": null}
{"id": "a932ff76-4941-4abc-9d8b-0cc23d48ff4c", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.5  # Reduced inertia_weight for quicker convergence\n        self.cognitive_coeff = 1.7  # Increased cognitive_coeff for more exploration\n        self.social_coeff = 1.3  # Reduced social_coeff to improve diversity\n        self.dynamic_adjustment_freq = 10  # Frequency of dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0  # Initialize iteration counter\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:  # Dynamic parameter adjustment\n                self.inertia_weight *= 0.95  # Gradually reduce inertia\n                self.mutation_factor = 0.9 if iteration < self.budget // 2 else 0.7  # Adjust mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1  # Increment iteration counter\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with dynamic parameter adjustment and improved diversity mechanism for accelerated convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a38bff72-ab4d-4016-8bad-941a89cbfbc9", "metadata": {"aucs": [0.8173532858943607, 0.8173532858943607, 0.8173532858943607, 0.8070665307824119, 0.8070665307824119, 0.8070665307824119, 0.8302027387283974, 0.8302027387283974, 0.8302027387283974, 0.5134322341997061, 0.5134322341997061, 0.5134322341997061, 0.624691263026809, 0.624691263026809, 0.624691263026809, 0.6002980633873294, 0.6002980633873294, 0.6002980633873294, 0.15836040046428224, 0.15836040046428224, 0.15836040046428224, 0.13123216050558661, 0.13123216050558661, 0.13123216050558661, 0.27970106171202114, 0.27970106171202114, 0.27970106171202114, 0.15124280349195118, 0.15124280349195118, 0.15124280349195118, 0.09834124134572031, 0.09834124134572031, 0.09834124134572031, 0.12989604071547778, 0.12989604071547778, 0.12989604071547778, 0.9680695927117464, 0.9680695927117464, 0.9680695927117464, 0.9768501235494804, 0.9768501235494804, 0.9768501235494804, 0.9831477879115976, 0.9831477879115976, 0.9831477879115976, 0.5971319790953125, 0.5971319790953125, 0.5971319790953125, 0.48474815956165695, 0.48474815956165695, 0.48474815956165695, 0.5830104602966175, 0.5830104602966175, 0.5830104602966175, 0.27622022111890565, 0.27622022111890565, 0.27622022111890565, 0.18779824886197094, 0.18779824886197094, 0.18779824886197094, 0.33670363500165723, 0.33670363500165723, 0.33670363500165723, 0.2952862590151156, 0.2952862590151156, 0.2952862590151156, 0.12903284797818992, 0.12903284797818992, 0.12903284797818992, 0.19498986972794174, 0.19498986972794174, 0.19498986972794174, 0.21024770382224844, 0.21024770382224844, 0.21024770382224844, 0.18127758222775825, 0.18127758222775825, 0.18127758222775825, 0.1332413227550654, 0.1332413227550654, 0.1332413227550654, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.000591596660297955, 0.000591596660297955, 0.000591596660297955, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1420256776795833, 0.1420256776795833, 0.1420256776795833, 0.020748106240395137, 0.020748106240395137, 0.020748106240395137, 0.1348851129367975, 0.1348851129367975, 0.1348851129367975, 0.04458903399180836, 0.04458903399180836, 0.04458903399180836, 0.11512893530323998, 0.11512893530323998, 0.11512893530323998, 0.08641355632800374, 0.08641355632800374, 0.08641355632800374, 0.14777383418850298, 0.14777383418850298, 0.14777383418850298, 0.07206563016569412, 0.07206563016569412, 0.07206563016569412, 0.07923642752837845, 0.07923642752837845, 0.07923642752837845, 0.5973585429735873, 0.5973585429735873, 0.5973585429735873, 0.5444614487631158, 0.5444614487631158, 0.5444614487631158, 0.5581596112472851, 0.5581596112472851, 0.5581596112472851, 0.10792836734243372, 0.10792836734243372, 0.10792836734243372, 0.16390282508876686, 0.16390282508876686, 0.16390282508876686, 0.08962551634344096, 0.08962551634344096, 0.08962551634344096, 0.19483029090259651, 0.19483029090259651, 0.19483029090259651, 0.2820278660431219, 0.2820278660431219, 0.2820278660431219, 0.26805499101487307, 0.26805499101487307, 0.26805499101487307, 0.24637636277992703, 0.24637636277992703, 0.24637636277992703, 0.3831050982404137, 0.3831050982404137, 0.3831050982404137, 0.4868095742725873, 0.4868095742725873, 0.4868095742725873, 0.16845536602753763, 0.16845536602753763, 0.16845536602753763, 0.3014920382412615, 0.3014920382412615, 0.3014920382412615, 0.36512925182854294, 0.36512925182854294, 0.36512925182854294, 0.22868397010770147, 0.22868397010770147, 0.22868397010770147, 0.22390362207286474, 0.22390362207286474, 0.22390362207286474, 0.21557387697624797, 0.21557387697624797, 0.21557387697624797, 0.19146581710468058, 0.19146581710468058, 0.19146581710468058, 0.2142825225819227, 0.2142825225819227, 0.2142825225819227, 0.23382031825464455, 0.23382031825464455, 0.23382031825464455, 0.8781972766424274, 0.8781972766424274, 0.8781972766424274, 0.16498904353322907, 0.16498904353322907, 0.16498904353322907, 0.1675048508288941, 0.1675048508288941, 0.1675048508288941, 0.1677930192856908, 0.1677930192856908, 0.1677930192856908, 0.2096363998358497, 0.2096363998358497, 0.2096363998358497, 0.7527906802205094, 0.7527906802205094, 0.7527906802205094, 0.18281873394226333, 0.18281873394226333, 0.18281873394226333, 0.18751703876694603, 0.18751703876694603, 0.18751703876694603, 0.2003195826305778, 0.2003195826305778, 0.2003195826305778, 0.09323489623740366, 0.09323489623740366, 0.09323489623740366, 0.08957474845720703, 0.08957474845720703, 0.08957474845720703, 0.11110056432631477, 0.11110056432631477, 0.11110056432631477]}, "mutation_prompt": null}
{"id": "8ff80081-90d4-4673-9ee1-4a8eb90f0de1", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.5  # Reduced inertia_weight for quicker convergence\n        self.cognitive_coeff = 1.7  # Increased cognitive_coeff for more exploration\n        self.social_coeff = 1.3  # Reduced social_coeff to improve diversity\n        self.dynamic_adjustment_freq = 10  # Frequency of dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0  # Initialize iteration counter\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:  # Dynamic parameter adjustment\n                self.inertia_weight *= 0.95  # Gradually reduce inertia\n                self.mutation_factor = 0.9 if iteration < self.budget // 2 else 0.7  # Adjust mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1  # Increment iteration counter\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with dynamic parameter adjustment and improved diversity mechanism for accelerated convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a38bff72-ab4d-4016-8bad-941a89cbfbc9", "metadata": {"aucs": [0.8173532858943607, 0.8173532858943607, 0.8173532858943607, 0.8070665307824119, 0.8070665307824119, 0.8070665307824119, 0.8302027387283974, 0.8302027387283974, 0.8302027387283974, 0.5134322341997061, 0.5134322341997061, 0.5134322341997061, 0.624691263026809, 0.624691263026809, 0.624691263026809, 0.6002980633873294, 0.6002980633873294, 0.6002980633873294, 0.15836040046428224, 0.15836040046428224, 0.15836040046428224, 0.13123216050558661, 0.13123216050558661, 0.13123216050558661, 0.27970106171202114, 0.27970106171202114, 0.27970106171202114, 0.15124280349195118, 0.15124280349195118, 0.15124280349195118, 0.09834124134572031, 0.09834124134572031, 0.09834124134572031, 0.12989604071547778, 0.12989604071547778, 0.12989604071547778, 0.9680695927117464, 0.9680695927117464, 0.9680695927117464, 0.9768501235494804, 0.9768501235494804, 0.9768501235494804, 0.9831477879115976, 0.9831477879115976, 0.9831477879115976, 0.5971319790953125, 0.5971319790953125, 0.5971319790953125, 0.48474815956165695, 0.48474815956165695, 0.48474815956165695, 0.5830104602966175, 0.5830104602966175, 0.5830104602966175, 0.27622022111890565, 0.27622022111890565, 0.27622022111890565, 0.18779824886197094, 0.18779824886197094, 0.18779824886197094, 0.33670363500165723, 0.33670363500165723, 0.33670363500165723, 0.2952862590151156, 0.2952862590151156, 0.2952862590151156, 0.12903284797818992, 0.12903284797818992, 0.12903284797818992, 0.19498986972794174, 0.19498986972794174, 0.19498986972794174, 0.21024770382224844, 0.21024770382224844, 0.21024770382224844, 0.18127758222775825, 0.18127758222775825, 0.18127758222775825, 0.1332413227550654, 0.1332413227550654, 0.1332413227550654, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.000591596660297955, 0.000591596660297955, 0.000591596660297955, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1420256776795833, 0.1420256776795833, 0.1420256776795833, 0.020748106240395137, 0.020748106240395137, 0.020748106240395137, 0.1348851129367975, 0.1348851129367975, 0.1348851129367975, 0.04458903399180836, 0.04458903399180836, 0.04458903399180836, 0.11512893530323998, 0.11512893530323998, 0.11512893530323998, 0.08641355632800374, 0.08641355632800374, 0.08641355632800374, 0.14777383418850298, 0.14777383418850298, 0.14777383418850298, 0.07206563016569412, 0.07206563016569412, 0.07206563016569412, 0.07923642752837845, 0.07923642752837845, 0.07923642752837845, 0.5973585429735873, 0.5973585429735873, 0.5973585429735873, 0.5444614487631158, 0.5444614487631158, 0.5444614487631158, 0.5581596112472851, 0.5581596112472851, 0.5581596112472851, 0.10792836734243372, 0.10792836734243372, 0.10792836734243372, 0.16390282508876686, 0.16390282508876686, 0.16390282508876686, 0.08962551634344096, 0.08962551634344096, 0.08962551634344096, 0.19483029090259651, 0.19483029090259651, 0.19483029090259651, 0.2820278660431219, 0.2820278660431219, 0.2820278660431219, 0.26805499101487307, 0.26805499101487307, 0.26805499101487307, 0.24637636277992703, 0.24637636277992703, 0.24637636277992703, 0.3831050982404137, 0.3831050982404137, 0.3831050982404137, 0.4868095742725873, 0.4868095742725873, 0.4868095742725873, 0.16845536602753763, 0.16845536602753763, 0.16845536602753763, 0.3014920382412615, 0.3014920382412615, 0.3014920382412615, 0.36512925182854294, 0.36512925182854294, 0.36512925182854294, 0.22868397010770147, 0.22868397010770147, 0.22868397010770147, 0.22390362207286474, 0.22390362207286474, 0.22390362207286474, 0.21557387697624797, 0.21557387697624797, 0.21557387697624797, 0.19146581710468058, 0.19146581710468058, 0.19146581710468058, 0.2142825225819227, 0.2142825225819227, 0.2142825225819227, 0.23382031825464455, 0.23382031825464455, 0.23382031825464455, 0.8781972766424274, 0.8781972766424274, 0.8781972766424274, 0.16498904353322907, 0.16498904353322907, 0.16498904353322907, 0.1675048508288941, 0.1675048508288941, 0.1675048508288941, 0.1677930192856908, 0.1677930192856908, 0.1677930192856908, 0.2096363998358497, 0.2096363998358497, 0.2096363998358497, 0.7527906802205094, 0.7527906802205094, 0.7527906802205094, 0.18281873394226333, 0.18281873394226333, 0.18281873394226333, 0.18751703876694603, 0.18751703876694603, 0.18751703876694603, 0.2003195826305778, 0.2003195826305778, 0.2003195826305778, 0.09323489623740366, 0.09323489623740366, 0.09323489623740366, 0.08957474845720703, 0.08957474845720703, 0.08957474845720703, 0.11110056432631477, 0.11110056432631477, 0.11110056432631477]}, "mutation_prompt": null}
{"id": "f04ae987-c6fd-4290-b8b8-24582830ee99", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_weight = 0.5  # Reduced inertia_weight for quicker convergence\n        self.cognitive_coeff = 1.7  # Increased cognitive_coeff for more exploration\n        self.social_coeff = 1.3  # Reduced social_coeff to improve diversity\n        self.dynamic_adjustment_freq = 10  # Frequency of dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0  # Initialize iteration counter\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:  # Dynamic parameter adjustment\n                self.inertia_weight *= 0.95  # Gradually reduce inertia\n                self.mutation_factor = 0.9 if iteration < self.budget // 2 else 0.7  # Adjust mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1  # Increment iteration counter\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with dynamic parameter adjustment and improved diversity mechanism for accelerated convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a38bff72-ab4d-4016-8bad-941a89cbfbc9", "metadata": {"aucs": [0.8173532858943607, 0.8173532858943607, 0.8173532858943607, 0.8070665307824119, 0.8070665307824119, 0.8070665307824119, 0.8302027387283974, 0.8302027387283974, 0.8302027387283974, 0.5134322341997061, 0.5134322341997061, 0.5134322341997061, 0.624691263026809, 0.624691263026809, 0.624691263026809, 0.6002980633873294, 0.6002980633873294, 0.6002980633873294, 0.15836040046428224, 0.15836040046428224, 0.15836040046428224, 0.13123216050558661, 0.13123216050558661, 0.13123216050558661, 0.27970106171202114, 0.27970106171202114, 0.27970106171202114, 0.15124280349195118, 0.15124280349195118, 0.15124280349195118, 0.09834124134572031, 0.09834124134572031, 0.09834124134572031, 0.12989604071547778, 0.12989604071547778, 0.12989604071547778, 0.9680695927117464, 0.9680695927117464, 0.9680695927117464, 0.9768501235494804, 0.9768501235494804, 0.9768501235494804, 0.9831477879115976, 0.9831477879115976, 0.9831477879115976, 0.5971319790953125, 0.5971319790953125, 0.5971319790953125, 0.48474815956165695, 0.48474815956165695, 0.48474815956165695, 0.5830104602966175, 0.5830104602966175, 0.5830104602966175, 0.27622022111890565, 0.27622022111890565, 0.27622022111890565, 0.18779824886197094, 0.18779824886197094, 0.18779824886197094, 0.33670363500165723, 0.33670363500165723, 0.33670363500165723, 0.2952862590151156, 0.2952862590151156, 0.2952862590151156, 0.12903284797818992, 0.12903284797818992, 0.12903284797818992, 0.19498986972794174, 0.19498986972794174, 0.19498986972794174, 0.21024770382224844, 0.21024770382224844, 0.21024770382224844, 0.18127758222775825, 0.18127758222775825, 0.18127758222775825, 0.1332413227550654, 0.1332413227550654, 0.1332413227550654, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.000591596660297955, 0.000591596660297955, 0.000591596660297955, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1420256776795833, 0.1420256776795833, 0.1420256776795833, 0.020748106240395137, 0.020748106240395137, 0.020748106240395137, 0.1348851129367975, 0.1348851129367975, 0.1348851129367975, 0.04458903399180836, 0.04458903399180836, 0.04458903399180836, 0.11512893530323998, 0.11512893530323998, 0.11512893530323998, 0.08641355632800374, 0.08641355632800374, 0.08641355632800374, 0.14777383418850298, 0.14777383418850298, 0.14777383418850298, 0.07206563016569412, 0.07206563016569412, 0.07206563016569412, 0.07923642752837845, 0.07923642752837845, 0.07923642752837845, 0.5973585429735873, 0.5973585429735873, 0.5973585429735873, 0.5444614487631158, 0.5444614487631158, 0.5444614487631158, 0.5581596112472851, 0.5581596112472851, 0.5581596112472851, 0.10792836734243372, 0.10792836734243372, 0.10792836734243372, 0.16390282508876686, 0.16390282508876686, 0.16390282508876686, 0.08962551634344096, 0.08962551634344096, 0.08962551634344096, 0.19483029090259651, 0.19483029090259651, 0.19483029090259651, 0.2820278660431219, 0.2820278660431219, 0.2820278660431219, 0.26805499101487307, 0.26805499101487307, 0.26805499101487307, 0.24637636277992703, 0.24637636277992703, 0.24637636277992703, 0.3831050982404137, 0.3831050982404137, 0.3831050982404137, 0.4868095742725873, 0.4868095742725873, 0.4868095742725873, 0.16845536602753763, 0.16845536602753763, 0.16845536602753763, 0.3014920382412615, 0.3014920382412615, 0.3014920382412615, 0.36512925182854294, 0.36512925182854294, 0.36512925182854294, 0.22868397010770147, 0.22868397010770147, 0.22868397010770147, 0.22390362207286474, 0.22390362207286474, 0.22390362207286474, 0.21557387697624797, 0.21557387697624797, 0.21557387697624797, 0.19146581710468058, 0.19146581710468058, 0.19146581710468058, 0.2142825225819227, 0.2142825225819227, 0.2142825225819227, 0.23382031825464455, 0.23382031825464455, 0.23382031825464455, 0.8781972766424274, 0.8781972766424274, 0.8781972766424274, 0.16498904353322907, 0.16498904353322907, 0.16498904353322907, 0.1675048508288941, 0.1675048508288941, 0.1675048508288941, 0.1677930192856908, 0.1677930192856908, 0.1677930192856908, 0.2096363998358497, 0.2096363998358497, 0.2096363998358497, 0.7527906802205094, 0.7527906802205094, 0.7527906802205094, 0.18281873394226333, 0.18281873394226333, 0.18281873394226333, 0.18751703876694603, 0.18751703876694603, 0.18751703876694603, 0.2003195826305778, 0.2003195826305778, 0.2003195826305778, 0.09323489623740366, 0.09323489623740366, 0.09323489623740366, 0.08957474845720703, 0.08957474845720703, 0.08957474845720703, 0.11110056432631477, 0.11110056432631477, 0.11110056432631477]}, "mutation_prompt": null}
{"id": "d62eee2b-896b-466d-87bb-32152bf3ec05", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 60  # Increased swarm size for better exploration\n        self.mutation_factor = 0.85  # Slightly increased mutation for diversity\n        self.crossover_prob = 0.8  # Adjusted crossover probability\n        self.inertia_weight = 0.55  # Adjusted inertia_weight for balance between exploration and exploitation\n        self.cognitive_coeff = 1.5  # Adjusted cognitive_coeff for slightly less personal bias\n        self.social_coeff = 1.4  # Adjusted social_coeff for enhanced global search\n        self.dynamic_adjustment_freq = 8  # More frequent dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.93  # Slightly different dynamic reduction\n                self.mutation_factor = 0.88 if iteration < self.budget // 2 else 0.75  # Adaptive mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with increased swarm size and adaptive parameter tuning for improved convergence speed.", "configspace": "", "generation": 54, "fitness": 0.3103156603368935, "feedback": "The algorithm Enhanced_PSO_ADE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.26.", "error": "", "parent_id": "a38bff72-ab4d-4016-8bad-941a89cbfbc9", "metadata": {"aucs": [0.8065029332555447, 0.8065029332555447, 0.8065029332555447, 0.7879071665328757, 0.7879071665328757, 0.7879071665328757, 0.7934045605658537, 0.7934045605658537, 0.7934045605658537, 0.5778486044918812, 0.5778486044918812, 0.5778486044918812, 0.5646336789062972, 0.5646336789062972, 0.5646336789062972, 0.5771795328509839, 0.5771795328509839, 0.5771795328509839, 0.14567817676423023, 0.14567817676423023, 0.14567817676423023, 0.14158313468323303, 0.14158313468323303, 0.14158313468323303, 0.5770269271125978, 0.5770269271125978, 0.5770269271125978, 0.10988033789413443, 0.10988033789413443, 0.10988033789413443, 0.139681313997993, 0.139681313997993, 0.139681313997993, 0.11886441780606305, 0.11886441780606305, 0.11886441780606305, 0.9748956326735576, 0.9748956326735576, 0.9748956326735576, 0.9788751324089218, 0.9788751324089218, 0.9788751324089218, 0.978872033320122, 0.978872033320122, 0.978872033320122, 0.5613211117875581, 0.5613211117875581, 0.5613211117875581, 0.5503317820573677, 0.5503317820573677, 0.5503317820573677, 0.5767195044027322, 0.5767195044027322, 0.5767195044027322, 0.22180132634763738, 0.22180132634763738, 0.22180132634763738, 0.7986618576666047, 0.7986618576666047, 0.7986618576666047, 0.1768368633291295, 0.1768368633291295, 0.1768368633291295, 0.19441291140773587, 0.19441291140773587, 0.19441291140773587, 0.23866081430005381, 0.23866081430005381, 0.23866081430005381, 0.22332167148102167, 0.22332167148102167, 0.22332167148102167, 0.19217871214864046, 0.19217871214864046, 0.19217871214864046, 0.11033361717895118, 0.11033361717895118, 0.11033361717895118, 0.1954980305228804, 0.1954980305228804, 0.1954980305228804, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00034566137854141754, 0.00034566137854141754, 0.00034566137854141754, 0.07125920339751812, 0.07125920339751812, 0.07125920339751812, 0.013217580989536293, 0.013217580989536293, 0.013217580989536293, 0.06321198533294481, 0.06321198533294481, 0.06321198533294481, 0.04577114035925678, 0.04577114035925678, 0.04577114035925678, 0.09658798328664941, 0.09658798328664941, 0.09658798328664941, 0.3060874350179851, 0.3060874350179851, 0.3060874350179851, 0.11965104258447845, 0.11965104258447845, 0.11965104258447845, 0.15715051993764828, 0.15715051993764828, 0.15715051993764828, 0.05455780613770189, 0.05455780613770189, 0.05455780613770189, 0.4989962631800221, 0.4989962631800221, 0.4989962631800221, 0.5324640573005008, 0.5324640573005008, 0.5324640573005008, 0.5089231744761383, 0.5089231744761383, 0.5089231744761383, 0.12055497961633865, 0.12055497961633865, 0.12055497961633865, 0.12131075498347332, 0.12131075498347332, 0.12131075498347332, 0.15912061654852583, 0.15912061654852583, 0.15912061654852583, 0.163519528253665, 0.163519528253665, 0.163519528253665, 0.2488630376910912, 0.2488630376910912, 0.2488630376910912, 0.23056888063354297, 0.23056888063354297, 0.23056888063354297, 0.3625324746336922, 0.3625324746336922, 0.3625324746336922, 0.4825599833120394, 0.4825599833120394, 0.4825599833120394, 0.44570137102562635, 0.44570137102562635, 0.44570137102562635, 0.1612314385004684, 0.1612314385004684, 0.1612314385004684, 0.23783887009193627, 0.23783887009193627, 0.23783887009193627, 0.16725183338394456, 0.16725183338394456, 0.16725183338394456, 0.23657817198819187, 0.23657817198819187, 0.23657817198819187, 0.23543645808806857, 0.23543645808806857, 0.23543645808806857, 0.2140369795971364, 0.2140369795971364, 0.2140369795971364, 0.21877366492012384, 0.21877366492012384, 0.21877366492012384, 0.1993422829253344, 0.1993422829253344, 0.1993422829253344, 0.20483442620804448, 0.20483442620804448, 0.20483442620804448, 0.8631868913624167, 0.8631868913624167, 0.8631868913624167, 0.15832846583405713, 0.15832846583405713, 0.15832846583405713, 0.16990480927754392, 0.16990480927754392, 0.16990480927754392, 0.6491616354155003, 0.6491616354155003, 0.6491616354155003, 0.4891365272633964, 0.4891365272633964, 0.4891365272633964, 0.15456589752638905, 0.15456589752638905, 0.15456589752638905, 0.18112036757653027, 0.18112036757653027, 0.18112036757653027, 0.1871099769076684, 0.1871099769076684, 0.1871099769076684, 0.20197314765216834, 0.20197314765216834, 0.20197314765216834, 0.0905837476483009, 0.0905837476483009, 0.0905837476483009, 0.09459420844935684, 0.09459420844935684, 0.09459420844935684, 0.11167047766823957, 0.11167047766823957, 0.11167047766823957]}, "mutation_prompt": null}
{"id": "1d72bc0a-9eb6-47ea-8eb6-802afc96debb", "solution": "import numpy as np\n\nclass Enhanced_Adaptive_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 60  \n        self.mutation_factor = 0.85  \n        self.crossover_prob = 0.85  # Slightly increased crossover probability for variation\n        self.inertia_weight = 0.55  \n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.4  \n        self.dynamic_adjustment_freq = 7  # Slightly more frequent dynamic adjustment\n        self.random_restart_prob = 0.05  # Introduce random restart probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n                    \n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.92  # Slightly faster dynamic reduction\n                self.mutation_factor = 0.87 if iteration < self.budget // 3 else 0.74  # More adaptive mutation factor\n                if np.random.rand() < self.random_restart_prob:  # Random restart for exploration\n                    positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_Adaptive_PSO_ADE_Optimizer", "description": "Enhanced Adaptive PSO-ADE with random search restart for improved global exploration and convergence.", "configspace": "", "generation": 55, "fitness": 0.2779703563115849, "feedback": "The algorithm Enhanced_Adaptive_PSO_ADE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.25.", "error": "", "parent_id": "d62eee2b-896b-466d-87bb-32152bf3ec05", "metadata": {"aucs": [0.7688666509191987, 0.7688666509191987, 0.7688666509191987, 0.74624042770237, 0.74624042770237, 0.74624042770237, 0.7514979673043782, 0.7514979673043782, 0.7514979673043782, 0.47503629897201105, 0.47503629897201105, 0.47503629897201105, 0.5340453158654263, 0.5340453158654263, 0.5340453158654263, 0.4937414307015645, 0.4937414307015645, 0.4937414307015645, 0.14631612063432053, 0.14631612063432053, 0.14631612063432053, 0.16454015867684357, 0.16454015867684357, 0.16454015867684357, 0.16295026190268147, 0.16295026190268147, 0.16295026190268147, 0.09781053964793662, 0.09781053964793662, 0.09781053964793662, 0.10069106876768896, 0.10069106876768896, 0.10069106876768896, 0.133666230757865, 0.133666230757865, 0.133666230757865, 0.983023177892079, 0.983023177892079, 0.983023177892079, 0.9714141229917835, 0.9714141229917835, 0.9714141229917835, 0.9663917730344809, 0.9663917730344809, 0.9663917730344809, 0.5297702112214677, 0.5297702112214677, 0.5297702112214677, 0.44846278052234545, 0.44846278052234545, 0.44846278052234545, 0.529605401671549, 0.529605401671549, 0.529605401671549, 0.6416867535807987, 0.6416867535807987, 0.6416867535807987, 0.18628460597824337, 0.18628460597824337, 0.18628460597824337, 0.35129156020454333, 0.35129156020454333, 0.35129156020454333, 0.18272490090176263, 0.18272490090176263, 0.18272490090176263, 0.12016726198754946, 0.12016726198754946, 0.12016726198754946, 0.12398261457692639, 0.12398261457692639, 0.12398261457692639, 0.021678811940975873, 0.021678811940975873, 0.021678811940975873, 0.2595299536886557, 0.2595299536886557, 0.2595299536886557, 0.08835945699204872, 0.08835945699204872, 0.08835945699204872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03502654402338379, 0.03502654402338379, 0.03502654402338379, 0.012080745936383419, 0.012080745936383419, 0.012080745936383419, 0.03551866905509071, 0.03551866905509071, 0.03551866905509071, 0.049695136901781733, 0.049695136901781733, 0.049695136901781733, 0.04523668627412625, 0.04523668627412625, 0.04523668627412625, 0.06247779390751074, 0.06247779390751074, 0.06247779390751074, 0.06008612553311454, 0.06008612553311454, 0.06008612553311454, 0.08528570625011167, 0.08528570625011167, 0.08528570625011167, 0.1105081966448126, 0.1105081966448126, 0.1105081966448126, 0.04566008679192546, 0.04566008679192546, 0.04566008679192546, 0.14343014781952856, 0.14343014781952856, 0.14343014781952856, 0.4736074761352447, 0.4736074761352447, 0.4736074761352447, 0.5032707887509482, 0.5032707887509482, 0.5032707887509482, 0.5225773604992041, 0.5225773604992041, 0.5225773604992041, 0.09948920001591299, 0.09948920001591299, 0.09948920001591299, 0.1146401661936618, 0.1146401661936618, 0.1146401661936618, 0.1360042366708194, 0.1360042366708194, 0.1360042366708194, 0.18511129144941718, 0.18511129144941718, 0.18511129144941718, 0.1837685017253382, 0.1837685017253382, 0.1837685017253382, 0.21671699165228897, 0.21671699165228897, 0.21671699165228897, 0.3701374243115254, 0.3701374243115254, 0.3701374243115254, 0.3647585393862617, 0.3647585393862617, 0.3647585393862617, 0.2855106662563337, 0.2855106662563337, 0.2855106662563337, 0.18544446441001672, 0.18544446441001672, 0.18544446441001672, 0.19890981895806892, 0.19890981895806892, 0.19890981895806892, 0.24131894025902278, 0.24131894025902278, 0.24131894025902278, 0.20421489976064744, 0.20421489976064744, 0.20421489976064744, 0.20818509904152593, 0.20818509904152593, 0.20818509904152593, 0.20062636023877145, 0.20062636023877145, 0.20062636023877145, 0.23965321627066294, 0.23965321627066294, 0.23965321627066294, 0.21635415023217786, 0.21635415023217786, 0.21635415023217786, 0.2323075593973486, 0.2323075593973486, 0.2323075593973486, 0.8236405349589812, 0.8236405349589812, 0.8236405349589812, 0.15710167658786212, 0.15710167658786212, 0.15710167658786212, 0.16862760217653217, 0.16862760217653217, 0.16862760217653217, 0.5951655412793009, 0.5951655412793009, 0.5951655412793009, 0.20591711440525562, 0.20591711440525562, 0.20591711440525562, 0.15532422081705355, 0.15532422081705355, 0.15532422081705355, 0.18316469332919538, 0.18316469332919538, 0.18316469332919538, 0.1905617769763991, 0.1905617769763991, 0.1905617769763991, 0.18434863643884614, 0.18434863643884614, 0.18434863643884614, 0.10096187283899871, 0.10096187283899871, 0.10096187283899871, 0.0887753013875957, 0.0887753013875957, 0.0887753013875957, 0.11278783344763144, 0.11278783344763144, 0.11278783344763144]}, "mutation_prompt": null}
{"id": "750a5cf5-b553-46f2-b8a0-6d3db80680a5", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 58  # Slightly reduced swarm size for faster iteration\n        self.mutation_factor = 0.90  # Increased mutation for diversity\n        self.crossover_prob = 0.85  # Increased crossover probability for variety in exploration\n        self.inertia_weight = 0.50  # Tweaked inertia weight for better inertia control\n        self.cognitive_coeff = 1.55  # Slightly increased cognitive coefficient\n        self.social_coeff = 1.35  # Adjusted for more controlled global influence\n        self.dynamic_adjustment_freq = 7  # More frequent dynamic parameter adjustment\n        self.diversity_control_factor = 0.1  # New attribute to maintain diversity\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.92  # More aggressive inertia reduction\n                self.mutation_factor = 0.92 if iteration < self.budget // 3 else 0.78  # Adaptive mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            diversity_adjustment = self.diversity_control_factor * (positions - global_best_position)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions) +\n                diversity_adjustment\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with focused diversity control and balanced exploration-exploitation for improved convergence.", "configspace": "", "generation": 56, "fitness": 0.29964908372438265, "feedback": "The algorithm Enhanced_PSO_ADE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.26.", "error": "", "parent_id": "d62eee2b-896b-466d-87bb-32152bf3ec05", "metadata": {"aucs": [0.8113948107992559, 0.8113948107992559, 0.8113948107992559, 0.8074116673028542, 0.8074116673028542, 0.8074116673028542, 0.8270432333718613, 0.8270432333718613, 0.8270432333718613, 0.5929569944851738, 0.5929569944851738, 0.5929569944851738, 0.6253762760953393, 0.6253762760953393, 0.6253762760953393, 0.4056825426354901, 0.4056825426354901, 0.4056825426354901, 0.10587527322238621, 0.10587527322238621, 0.10587527322238621, 0.10940657827070666, 0.10940657827070666, 0.10940657827070666, 0.4361297551397513, 0.4361297551397513, 0.4361297551397513, 0.1206765250377857, 0.1206765250377857, 0.1206765250377857, 0.11210591061907726, 0.11210591061907726, 0.11210591061907726, 0.14675679272715825, 0.14675679272715825, 0.14675679272715825, 0.9740806046288399, 0.9740806046288399, 0.9740806046288399, 0.9730902939581713, 0.9730902939581713, 0.9730902939581713, 0.9700035683250343, 0.9700035683250343, 0.9700035683250343, 0.5382114100284536, 0.5382114100284536, 0.5382114100284536, 0.1495823703151189, 0.1495823703151189, 0.1495823703151189, 0.5095952638278354, 0.5095952638278354, 0.5095952638278354, 0.22418487935818343, 0.22418487935818343, 0.22418487935818343, 0.16037847615802658, 0.16037847615802658, 0.16037847615802658, 0.22145782896103305, 0.22145782896103305, 0.22145782896103305, 0.29056634480223087, 0.29056634480223087, 0.29056634480223087, 0.12919495422692273, 0.12919495422692273, 0.12919495422692273, 0.1272031827058332, 0.1272031827058332, 0.1272031827058332, 0.15696238445137, 0.15696238445137, 0.15696238445137, 0.1556377646521565, 0.1556377646521565, 0.1556377646521565, 0.18126177302819158, 0.18126177302819158, 0.18126177302819158, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05173562472244342, 0.05173562472244342, 0.05173562472244342, 0.024958055631614795, 0.024958055631614795, 0.024958055631614795, 0.13543665839342067, 0.13543665839342067, 0.13543665839342067, 0.0812078240397004, 0.0812078240397004, 0.0812078240397004, 0.08404846210848194, 0.08404846210848194, 0.08404846210848194, 0.1283504021535844, 0.1283504021535844, 0.1283504021535844, 0.2512245991080745, 0.2512245991080745, 0.2512245991080745, 0.05267985205853898, 0.05267985205853898, 0.05267985205853898, 0.07919646441842321, 0.07919646441842321, 0.07919646441842321, 0.5642133657174635, 0.5642133657174635, 0.5642133657174635, 0.5922061115684008, 0.5922061115684008, 0.5922061115684008, 0.5510026355774447, 0.5510026355774447, 0.5510026355774447, 0.16906750432748008, 0.16906750432748008, 0.16906750432748008, 0.11839313951937724, 0.11839313951937724, 0.11839313951937724, 0.14487935606523605, 0.14487935606523605, 0.14487935606523605, 0.20487030076092072, 0.20487030076092072, 0.20487030076092072, 0.345974746474245, 0.345974746474245, 0.345974746474245, 0.18444703017107866, 0.18444703017107866, 0.18444703017107866, 0.2883794298548865, 0.2883794298548865, 0.2883794298548865, 0.4200967287009798, 0.4200967287009798, 0.4200967287009798, 0.4380267994227953, 0.4380267994227953, 0.4380267994227953, 0.20764473099253422, 0.20764473099253422, 0.20764473099253422, 0.16802377314577277, 0.16802377314577277, 0.16802377314577277, 0.3217434939877105, 0.3217434939877105, 0.3217434939877105, 0.18839115405360762, 0.18839115405360762, 0.18839115405360762, 0.2332075473954277, 0.2332075473954277, 0.2332075473954277, 0.22244957080673267, 0.22244957080673267, 0.22244957080673267, 0.19185195525668142, 0.19185195525668142, 0.19185195525668142, 0.2193896918978424, 0.2193896918978424, 0.2193896918978424, 0.7111700510587382, 0.7111700510587382, 0.7111700510587382, 0.8620143071807294, 0.8620143071807294, 0.8620143071807294, 0.15730988465217322, 0.15730988465217322, 0.15730988465217322, 0.16913218371556482, 0.16913218371556482, 0.16913218371556482, 0.4011278928421028, 0.4011278928421028, 0.4011278928421028, 0.20766859661453452, 0.20766859661453452, 0.20766859661453452, 0.6381328445468271, 0.6381328445468271, 0.6381328445468271, 0.21398396841247902, 0.21398396841247902, 0.21398396841247902, 0.19576027452631928, 0.19576027452631928, 0.19576027452631928, 0.2062882564694326, 0.2062882564694326, 0.2062882564694326, 0.08183193464799765, 0.08183193464799765, 0.08183193464799765, 0.08647295422814805, 0.08647295422814805, 0.08647295422814805, 0.11821641179536713, 0.11821641179536713, 0.11821641179536713]}, "mutation_prompt": null}
{"id": "1a4210aa-cd00-4eea-9279-5ae668e47a2f", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 60  # Increased swarm size for better exploration\n        self.mutation_factor = 0.85  # Slightly increased mutation for diversity\n        self.crossover_prob = 0.8  # Adjusted crossover probability\n        self.inertia_weight = 0.55  # Adjusted inertia_weight for balance between exploration and exploitation\n        self.cognitive_coeff = 1.5  # Adjusted cognitive_coeff for slightly less personal bias\n        self.social_coeff = 1.4  # Adjusted social_coeff for enhanced global search\n        self.dynamic_adjustment_freq = 8  # More frequent dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.93  # Slightly different dynamic reduction\n                self.mutation_factor = 0.88 if iteration < self.budget // 2 else 0.75  # Adaptive mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with increased swarm size and adaptive parameter tuning for improved convergence speed.", "configspace": "", "generation": 55, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d62eee2b-896b-466d-87bb-32152bf3ec05", "metadata": {"aucs": [0.8065029332555447, 0.8065029332555447, 0.8065029332555447, 0.7879071665328757, 0.7879071665328757, 0.7879071665328757, 0.7934045605658537, 0.7934045605658537, 0.7934045605658537, 0.5778486044918812, 0.5778486044918812, 0.5778486044918812, 0.5646336789062972, 0.5646336789062972, 0.5646336789062972, 0.5771795328509839, 0.5771795328509839, 0.5771795328509839, 0.14567817676423023, 0.14567817676423023, 0.14567817676423023, 0.14158313468323303, 0.14158313468323303, 0.14158313468323303, 0.5770269271125978, 0.5770269271125978, 0.5770269271125978, 0.10988033789413443, 0.10988033789413443, 0.10988033789413443, 0.139681313997993, 0.139681313997993, 0.139681313997993, 0.11886441780606305, 0.11886441780606305, 0.11886441780606305, 0.9748956326735576, 0.9748956326735576, 0.9748956326735576, 0.9788751324089218, 0.9788751324089218, 0.9788751324089218, 0.978872033320122, 0.978872033320122, 0.978872033320122, 0.5613211117875581, 0.5613211117875581, 0.5613211117875581, 0.5503317820573677, 0.5503317820573677, 0.5503317820573677, 0.5767195044027322, 0.5767195044027322, 0.5767195044027322, 0.22180132634763738, 0.22180132634763738, 0.22180132634763738, 0.7986618576666047, 0.7986618576666047, 0.7986618576666047, 0.1768368633291295, 0.1768368633291295, 0.1768368633291295, 0.19441291140773587, 0.19441291140773587, 0.19441291140773587, 0.23866081430005381, 0.23866081430005381, 0.23866081430005381, 0.22332167148102167, 0.22332167148102167, 0.22332167148102167, 0.19217871214864046, 0.19217871214864046, 0.19217871214864046, 0.11033361717895118, 0.11033361717895118, 0.11033361717895118, 0.1954980305228804, 0.1954980305228804, 0.1954980305228804, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00034566137854141754, 0.00034566137854141754, 0.00034566137854141754, 0.07125920339751812, 0.07125920339751812, 0.07125920339751812, 0.013217580989536293, 0.013217580989536293, 0.013217580989536293, 0.06321198533294481, 0.06321198533294481, 0.06321198533294481, 0.04577114035925678, 0.04577114035925678, 0.04577114035925678, 0.09658798328664941, 0.09658798328664941, 0.09658798328664941, 0.3060874350179851, 0.3060874350179851, 0.3060874350179851, 0.11965104258447845, 0.11965104258447845, 0.11965104258447845, 0.15715051993764828, 0.15715051993764828, 0.15715051993764828, 0.05455780613770189, 0.05455780613770189, 0.05455780613770189, 0.4989962631800221, 0.4989962631800221, 0.4989962631800221, 0.5324640573005008, 0.5324640573005008, 0.5324640573005008, 0.5089231744761383, 0.5089231744761383, 0.5089231744761383, 0.12055497961633865, 0.12055497961633865, 0.12055497961633865, 0.12131075498347332, 0.12131075498347332, 0.12131075498347332, 0.15912061654852583, 0.15912061654852583, 0.15912061654852583, 0.163519528253665, 0.163519528253665, 0.163519528253665, 0.2488630376910912, 0.2488630376910912, 0.2488630376910912, 0.23056888063354297, 0.23056888063354297, 0.23056888063354297, 0.3625324746336922, 0.3625324746336922, 0.3625324746336922, 0.4825599833120394, 0.4825599833120394, 0.4825599833120394, 0.44570137102562635, 0.44570137102562635, 0.44570137102562635, 0.1612314385004684, 0.1612314385004684, 0.1612314385004684, 0.23783887009193627, 0.23783887009193627, 0.23783887009193627, 0.16725183338394456, 0.16725183338394456, 0.16725183338394456, 0.23657817198819187, 0.23657817198819187, 0.23657817198819187, 0.23543645808806857, 0.23543645808806857, 0.23543645808806857, 0.2140369795971364, 0.2140369795971364, 0.2140369795971364, 0.21877366492012384, 0.21877366492012384, 0.21877366492012384, 0.1993422829253344, 0.1993422829253344, 0.1993422829253344, 0.20483442620804448, 0.20483442620804448, 0.20483442620804448, 0.8631868913624167, 0.8631868913624167, 0.8631868913624167, 0.15832846583405713, 0.15832846583405713, 0.15832846583405713, 0.16990480927754392, 0.16990480927754392, 0.16990480927754392, 0.6491616354155003, 0.6491616354155003, 0.6491616354155003, 0.4891365272633964, 0.4891365272633964, 0.4891365272633964, 0.15456589752638905, 0.15456589752638905, 0.15456589752638905, 0.18112036757653027, 0.18112036757653027, 0.18112036757653027, 0.1871099769076684, 0.1871099769076684, 0.1871099769076684, 0.20197314765216834, 0.20197314765216834, 0.20197314765216834, 0.0905837476483009, 0.0905837476483009, 0.0905837476483009, 0.09459420844935684, 0.09459420844935684, 0.09459420844935684, 0.11167047766823957, 0.11167047766823957, 0.11167047766823957]}, "mutation_prompt": null}
{"id": "00e56654-12b7-43b0-af75-6ff031af4486", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 60  # Increased swarm size for better exploration\n        self.mutation_factor = 0.85  # Slightly increased mutation for diversity\n        self.crossover_prob = 0.8  # Adjusted crossover probability\n        self.inertia_weight = 0.55  # Adjusted inertia_weight for balance between exploration and exploitation\n        self.cognitive_coeff = 1.5  # Adjusted cognitive_coeff for slightly less personal bias\n        self.social_coeff = 1.4  # Adjusted social_coeff for enhanced global search\n        self.dynamic_adjustment_freq = 8  # More frequent dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.93  # Slightly different dynamic reduction\n                self.mutation_factor = 0.88 if iteration < self.budget // 2 else 0.75  # Adaptive mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with increased swarm size and adaptive parameter tuning for improved convergence speed.", "configspace": "", "generation": 55, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d62eee2b-896b-466d-87bb-32152bf3ec05", "metadata": {"aucs": [0.8065029332555447, 0.8065029332555447, 0.8065029332555447, 0.7879071665328757, 0.7879071665328757, 0.7879071665328757, 0.7934045605658537, 0.7934045605658537, 0.7934045605658537, 0.5778486044918812, 0.5778486044918812, 0.5778486044918812, 0.5646336789062972, 0.5646336789062972, 0.5646336789062972, 0.5771795328509839, 0.5771795328509839, 0.5771795328509839, 0.14567817676423023, 0.14567817676423023, 0.14567817676423023, 0.14158313468323303, 0.14158313468323303, 0.14158313468323303, 0.5770269271125978, 0.5770269271125978, 0.5770269271125978, 0.10988033789413443, 0.10988033789413443, 0.10988033789413443, 0.139681313997993, 0.139681313997993, 0.139681313997993, 0.11886441780606305, 0.11886441780606305, 0.11886441780606305, 0.9748956326735576, 0.9748956326735576, 0.9748956326735576, 0.9788751324089218, 0.9788751324089218, 0.9788751324089218, 0.978872033320122, 0.978872033320122, 0.978872033320122, 0.5613211117875581, 0.5613211117875581, 0.5613211117875581, 0.5503317820573677, 0.5503317820573677, 0.5503317820573677, 0.5767195044027322, 0.5767195044027322, 0.5767195044027322, 0.22180132634763738, 0.22180132634763738, 0.22180132634763738, 0.7986618576666047, 0.7986618576666047, 0.7986618576666047, 0.1768368633291295, 0.1768368633291295, 0.1768368633291295, 0.19441291140773587, 0.19441291140773587, 0.19441291140773587, 0.23866081430005381, 0.23866081430005381, 0.23866081430005381, 0.22332167148102167, 0.22332167148102167, 0.22332167148102167, 0.19217871214864046, 0.19217871214864046, 0.19217871214864046, 0.11033361717895118, 0.11033361717895118, 0.11033361717895118, 0.1954980305228804, 0.1954980305228804, 0.1954980305228804, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00034566137854141754, 0.00034566137854141754, 0.00034566137854141754, 0.07125920339751812, 0.07125920339751812, 0.07125920339751812, 0.013217580989536293, 0.013217580989536293, 0.013217580989536293, 0.06321198533294481, 0.06321198533294481, 0.06321198533294481, 0.04577114035925678, 0.04577114035925678, 0.04577114035925678, 0.09658798328664941, 0.09658798328664941, 0.09658798328664941, 0.3060874350179851, 0.3060874350179851, 0.3060874350179851, 0.11965104258447845, 0.11965104258447845, 0.11965104258447845, 0.15715051993764828, 0.15715051993764828, 0.15715051993764828, 0.05455780613770189, 0.05455780613770189, 0.05455780613770189, 0.4989962631800221, 0.4989962631800221, 0.4989962631800221, 0.5324640573005008, 0.5324640573005008, 0.5324640573005008, 0.5089231744761383, 0.5089231744761383, 0.5089231744761383, 0.12055497961633865, 0.12055497961633865, 0.12055497961633865, 0.12131075498347332, 0.12131075498347332, 0.12131075498347332, 0.15912061654852583, 0.15912061654852583, 0.15912061654852583, 0.163519528253665, 0.163519528253665, 0.163519528253665, 0.2488630376910912, 0.2488630376910912, 0.2488630376910912, 0.23056888063354297, 0.23056888063354297, 0.23056888063354297, 0.3625324746336922, 0.3625324746336922, 0.3625324746336922, 0.4825599833120394, 0.4825599833120394, 0.4825599833120394, 0.44570137102562635, 0.44570137102562635, 0.44570137102562635, 0.1612314385004684, 0.1612314385004684, 0.1612314385004684, 0.23783887009193627, 0.23783887009193627, 0.23783887009193627, 0.16725183338394456, 0.16725183338394456, 0.16725183338394456, 0.23657817198819187, 0.23657817198819187, 0.23657817198819187, 0.23543645808806857, 0.23543645808806857, 0.23543645808806857, 0.2140369795971364, 0.2140369795971364, 0.2140369795971364, 0.21877366492012384, 0.21877366492012384, 0.21877366492012384, 0.1993422829253344, 0.1993422829253344, 0.1993422829253344, 0.20483442620804448, 0.20483442620804448, 0.20483442620804448, 0.8631868913624167, 0.8631868913624167, 0.8631868913624167, 0.15832846583405713, 0.15832846583405713, 0.15832846583405713, 0.16990480927754392, 0.16990480927754392, 0.16990480927754392, 0.6491616354155003, 0.6491616354155003, 0.6491616354155003, 0.4891365272633964, 0.4891365272633964, 0.4891365272633964, 0.15456589752638905, 0.15456589752638905, 0.15456589752638905, 0.18112036757653027, 0.18112036757653027, 0.18112036757653027, 0.1871099769076684, 0.1871099769076684, 0.1871099769076684, 0.20197314765216834, 0.20197314765216834, 0.20197314765216834, 0.0905837476483009, 0.0905837476483009, 0.0905837476483009, 0.09459420844935684, 0.09459420844935684, 0.09459420844935684, 0.11167047766823957, 0.11167047766823957, 0.11167047766823957]}, "mutation_prompt": null}
{"id": "57e99625-9a52-4d46-bfac-22dd3f6cd58e", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 62  # Increased swarm size slightly for more diversity\n        self.mutation_factor = 0.88  # Slightly increased mutation for better exploration\n        self.crossover_prob = 0.85  # Adjusted crossover probability for more combination\n        self.inertia_weight = 0.6  # Slightly higher inertia for better momentum\n        self.cognitive_coeff = 1.3  # Reduced cognitive coefficient for less local bias\n        self.social_coeff = 1.6  # Increased social coefficient for stronger global search\n        self.dynamic_adjustment_freq = 7  # More frequent dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.9  # Faster dynamic reduction\n                self.crossover_prob = 0.9 if iteration < self.budget // 3 else 0.7  # Adaptive crossover probability\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with dynamic inertia and adaptive crossover for improved exploration and speed.", "configspace": "", "generation": 59, "fitness": 0.2687364475514573, "feedback": "The algorithm Enhanced_PSO_ADE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.26.", "error": "", "parent_id": "d62eee2b-896b-466d-87bb-32152bf3ec05", "metadata": {"aucs": [0.7847474013728675, 0.7847474013728675, 0.7847474013728675, 0.754962264334502, 0.754962264334502, 0.754962264334502, 0.7799054545668174, 0.7799054545668174, 0.7799054545668174, 0.03794347246170415, 0.03794347246170415, 0.03794347246170415, 0.43135611205801616, 0.43135611205801616, 0.43135611205801616, 0.46597246212974597, 0.46597246212974597, 0.46597246212974597, 0.14047925307443443, 0.14047925307443443, 0.14047925307443443, 0.11079841102254251, 0.11079841102254251, 0.11079841102254251, 0.13291080023502888, 0.13291080023502888, 0.13291080023502888, 0.15191904693247582, 0.15191904693247582, 0.15191904693247582, 0.12965984294397825, 0.12965984294397825, 0.12965984294397825, 0.10628224093631411, 0.10628224093631411, 0.10628224093631411, 0.9808234957922224, 0.9808234957922224, 0.9808234957922224, 0.9717863531462594, 0.9717863531462594, 0.9717863531462594, 0.980954045146583, 0.980954045146583, 0.980954045146583, 0.5811938150782338, 0.5811938150782338, 0.5811938150782338, 0.1493971889925586, 0.1493971889925586, 0.1493971889925586, 0.5434079555688661, 0.5434079555688661, 0.5434079555688661, 0.213500901540852, 0.213500901540852, 0.213500901540852, 0.15955076296088377, 0.15955076296088377, 0.15955076296088377, 0.11635253203698126, 0.11635253203698126, 0.11635253203698126, 0.19168473411221454, 0.19168473411221454, 0.19168473411221454, 0.18740364676506838, 0.18740364676506838, 0.18740364676506838, 0.1830454196406467, 0.1830454196406467, 0.1830454196406467, 0.05162415996484471, 0.05162415996484471, 0.05162415996484471, 0.13212178567901123, 0.13212178567901123, 0.13212178567901123, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00024237832722062702, 0.00024237832722062702, 0.00024237832722062702, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09922913816068957, 0.09922913816068957, 0.09922913816068957, 0.036037539132731, 0.036037539132731, 0.036037539132731, 0.056829429789429176, 0.056829429789429176, 0.056829429789429176, 0.04256376879358437, 0.04256376879358437, 0.04256376879358437, 0.0640042324176262, 0.0640042324176262, 0.0640042324176262, 0.08279874969417855, 0.08279874969417855, 0.08279874969417855, 0.11946319821049534, 0.11946319821049534, 0.11946319821049534, 0.03604476205445939, 0.03604476205445939, 0.03604476205445939, 0.04720876189023149, 0.04720876189023149, 0.04720876189023149, 0.49584277644577657, 0.49584277644577657, 0.49584277644577657, 0.4833439872860468, 0.4833439872860468, 0.4833439872860468, 0.527795154830669, 0.527795154830669, 0.527795154830669, 0.11437958013987248, 0.11437958013987248, 0.11437958013987248, 0.11724296927799893, 0.11724296927799893, 0.11724296927799893, 0.11894754664917928, 0.11894754664917928, 0.11894754664917928, 0.20102625914646555, 0.20102625914646555, 0.20102625914646555, 0.18110553930450046, 0.18110553930450046, 0.18110553930450046, 0.19212880360101858, 0.19212880360101858, 0.19212880360101858, 0.45726805098704904, 0.45726805098704904, 0.45726805098704904, 0.43498128168148953, 0.43498128168148953, 0.43498128168148953, 0.33182339039441733, 0.33182339039441733, 0.33182339039441733, 0.19869199191143527, 0.19869199191143527, 0.19869199191143527, 0.2373069306600134, 0.2373069306600134, 0.2373069306600134, 0.18655403253034641, 0.18655403253034641, 0.18655403253034641, 0.22369046216777277, 0.22369046216777277, 0.22369046216777277, 0.22347274283929586, 0.22347274283929586, 0.22347274283929586, 0.2287604515514733, 0.2287604515514733, 0.2287604515514733, 0.19803195227028036, 0.19803195227028036, 0.19803195227028036, 0.23436967748449944, 0.23436967748449944, 0.23436967748449944, 0.22428608418347507, 0.22428608418347507, 0.22428608418347507, 0.8652242872909088, 0.8652242872909088, 0.8652242872909088, 0.15515701961011652, 0.15515701961011652, 0.15515701961011652, 0.7872932137721508, 0.7872932137721508, 0.7872932137721508, 0.6262662972982935, 0.6262662972982935, 0.6262662972982935, 0.20644218082501042, 0.20644218082501042, 0.20644218082501042, 0.1546383807226721, 0.1546383807226721, 0.1546383807226721, 0.20299672978299477, 0.20299672978299477, 0.20299672978299477, 0.18395806458534536, 0.18395806458534536, 0.18395806458534536, 0.19783896883008678, 0.19783896883008678, 0.19783896883008678, 0.0791989861715412, 0.0791989861715412, 0.0791989861715412, 0.10114214696262591, 0.10114214696262591, 0.10114214696262591, 0.1233127655458065, 0.1233127655458065, 0.1233127655458065]}, "mutation_prompt": null}
{"id": "fc2b8484-b524-4b5f-b9fe-9e6fb4bf3220", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 60\n        self.mutation_factor = 0.85\n        self.crossover_prob = 0.8\n        self.inertia_weight = 0.55\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.4\n        self.dynamic_adjustment_freq = 7  # Slightly more frequent adjustments\n        self.local_search_prob = 0.1  # Introduced local search probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.92  # Slightly faster reduction\n                self.mutation_factor = 0.87 if iteration < self.budget // 2 else 0.76  # Adaptive mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                if np.random.rand() < self.local_search_prob:  # Local search phase\n                    indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 2, replace=False)\n                    x0, x1 = positions[indices]\n                    local_search_vector = np.clip(x0 + 0.5 * (x1 - positions[i]), self.lower_bound, self.upper_bound)\n                    trial_score = func(local_search_vector)\n                else:\n                    indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                    x0, x1, x2 = positions[indices]\n                    mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                    trial_score = func(trial_vector)\n                \n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = local_search_vector if np.random.rand() < self.local_search_prob else trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = local_search_vector if np.random.rand() < self.local_search_prob else trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer_Improved", "description": "Enhanced convergence speed by introducing local search phases and adaptive velocity scaling within the PSO-ADE hybrid framework.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'local_search_vector' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'local_search_vector' referenced before assignment\")", "parent_id": "d62eee2b-896b-466d-87bb-32152bf3ec05", "metadata": {}, "mutation_prompt": null}
{"id": "05039177-aca2-401f-b37d-836469dfb776", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 60  # Increased swarm size for better exploration\n        self.mutation_factor = 0.85  # Slightly increased mutation for diversity\n        self.crossover_prob = 0.8  # Adjusted crossover probability\n        self.inertia_weight = 0.55  # Adjusted inertia_weight for balance between exploration and exploitation\n        self.cognitive_coeff = 1.5  # Adjusted cognitive_coeff for slightly less personal bias\n        self.social_coeff = 1.4  # Adjusted social_coeff for enhanced global search\n        self.dynamic_adjustment_freq = 8  # More frequent dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.93  # Slightly different dynamic reduction\n                self.mutation_factor = 0.88 if iteration < self.budget // 2 else 0.75  # Adaptive mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with increased swarm size and adaptive parameter tuning for improved convergence speed.", "configspace": "", "generation": 55, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d62eee2b-896b-466d-87bb-32152bf3ec05", "metadata": {"aucs": [0.8065029332555447, 0.8065029332555447, 0.8065029332555447, 0.7879071665328757, 0.7879071665328757, 0.7879071665328757, 0.7934045605658537, 0.7934045605658537, 0.7934045605658537, 0.5778486044918812, 0.5778486044918812, 0.5778486044918812, 0.5646336789062972, 0.5646336789062972, 0.5646336789062972, 0.5771795328509839, 0.5771795328509839, 0.5771795328509839, 0.14567817676423023, 0.14567817676423023, 0.14567817676423023, 0.14158313468323303, 0.14158313468323303, 0.14158313468323303, 0.5770269271125978, 0.5770269271125978, 0.5770269271125978, 0.10988033789413443, 0.10988033789413443, 0.10988033789413443, 0.139681313997993, 0.139681313997993, 0.139681313997993, 0.11886441780606305, 0.11886441780606305, 0.11886441780606305, 0.9748956326735576, 0.9748956326735576, 0.9748956326735576, 0.9788751324089218, 0.9788751324089218, 0.9788751324089218, 0.978872033320122, 0.978872033320122, 0.978872033320122, 0.5613211117875581, 0.5613211117875581, 0.5613211117875581, 0.5503317820573677, 0.5503317820573677, 0.5503317820573677, 0.5767195044027322, 0.5767195044027322, 0.5767195044027322, 0.22180132634763738, 0.22180132634763738, 0.22180132634763738, 0.7986618576666047, 0.7986618576666047, 0.7986618576666047, 0.1768368633291295, 0.1768368633291295, 0.1768368633291295, 0.19441291140773587, 0.19441291140773587, 0.19441291140773587, 0.23866081430005381, 0.23866081430005381, 0.23866081430005381, 0.22332167148102167, 0.22332167148102167, 0.22332167148102167, 0.19217871214864046, 0.19217871214864046, 0.19217871214864046, 0.11033361717895118, 0.11033361717895118, 0.11033361717895118, 0.1954980305228804, 0.1954980305228804, 0.1954980305228804, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00034566137854141754, 0.00034566137854141754, 0.00034566137854141754, 0.07125920339751812, 0.07125920339751812, 0.07125920339751812, 0.013217580989536293, 0.013217580989536293, 0.013217580989536293, 0.06321198533294481, 0.06321198533294481, 0.06321198533294481, 0.04577114035925678, 0.04577114035925678, 0.04577114035925678, 0.09658798328664941, 0.09658798328664941, 0.09658798328664941, 0.3060874350179851, 0.3060874350179851, 0.3060874350179851, 0.11965104258447845, 0.11965104258447845, 0.11965104258447845, 0.15715051993764828, 0.15715051993764828, 0.15715051993764828, 0.05455780613770189, 0.05455780613770189, 0.05455780613770189, 0.4989962631800221, 0.4989962631800221, 0.4989962631800221, 0.5324640573005008, 0.5324640573005008, 0.5324640573005008, 0.5089231744761383, 0.5089231744761383, 0.5089231744761383, 0.12055497961633865, 0.12055497961633865, 0.12055497961633865, 0.12131075498347332, 0.12131075498347332, 0.12131075498347332, 0.15912061654852583, 0.15912061654852583, 0.15912061654852583, 0.163519528253665, 0.163519528253665, 0.163519528253665, 0.2488630376910912, 0.2488630376910912, 0.2488630376910912, 0.23056888063354297, 0.23056888063354297, 0.23056888063354297, 0.3625324746336922, 0.3625324746336922, 0.3625324746336922, 0.4825599833120394, 0.4825599833120394, 0.4825599833120394, 0.44570137102562635, 0.44570137102562635, 0.44570137102562635, 0.1612314385004684, 0.1612314385004684, 0.1612314385004684, 0.23783887009193627, 0.23783887009193627, 0.23783887009193627, 0.16725183338394456, 0.16725183338394456, 0.16725183338394456, 0.23657817198819187, 0.23657817198819187, 0.23657817198819187, 0.23543645808806857, 0.23543645808806857, 0.23543645808806857, 0.2140369795971364, 0.2140369795971364, 0.2140369795971364, 0.21877366492012384, 0.21877366492012384, 0.21877366492012384, 0.1993422829253344, 0.1993422829253344, 0.1993422829253344, 0.20483442620804448, 0.20483442620804448, 0.20483442620804448, 0.8631868913624167, 0.8631868913624167, 0.8631868913624167, 0.15832846583405713, 0.15832846583405713, 0.15832846583405713, 0.16990480927754392, 0.16990480927754392, 0.16990480927754392, 0.6491616354155003, 0.6491616354155003, 0.6491616354155003, 0.4891365272633964, 0.4891365272633964, 0.4891365272633964, 0.15456589752638905, 0.15456589752638905, 0.15456589752638905, 0.18112036757653027, 0.18112036757653027, 0.18112036757653027, 0.1871099769076684, 0.1871099769076684, 0.1871099769076684, 0.20197314765216834, 0.20197314765216834, 0.20197314765216834, 0.0905837476483009, 0.0905837476483009, 0.0905837476483009, 0.09459420844935684, 0.09459420844935684, 0.09459420844935684, 0.11167047766823957, 0.11167047766823957, 0.11167047766823957]}, "mutation_prompt": null}
{"id": "04bfd5df-19b9-4a31-a5c2-91c5c9783ffd", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 60  # Increased swarm size for better exploration\n        self.mutation_factor = 0.85  # Slightly increased mutation for diversity\n        self.crossover_prob = 0.8  # Adjusted crossover probability\n        self.inertia_weight = 0.55  # Adjusted inertia_weight for balance between exploration and exploitation\n        self.cognitive_coeff = 1.5  # Adjusted cognitive_coeff for slightly less personal bias\n        self.social_coeff = 1.4  # Adjusted social_coeff for enhanced global search\n        self.dynamic_adjustment_freq = 8  # More frequent dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.93  # Slightly different dynamic reduction\n                self.mutation_factor = 0.88 if iteration < self.budget // 2 else 0.75  # Adaptive mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with increased swarm size and adaptive parameter tuning for improved convergence speed.", "configspace": "", "generation": 55, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d62eee2b-896b-466d-87bb-32152bf3ec05", "metadata": {"aucs": [0.8065029332555447, 0.8065029332555447, 0.8065029332555447, 0.7879071665328757, 0.7879071665328757, 0.7879071665328757, 0.7934045605658537, 0.7934045605658537, 0.7934045605658537, 0.5778486044918812, 0.5778486044918812, 0.5778486044918812, 0.5646336789062972, 0.5646336789062972, 0.5646336789062972, 0.5771795328509839, 0.5771795328509839, 0.5771795328509839, 0.14567817676423023, 0.14567817676423023, 0.14567817676423023, 0.14158313468323303, 0.14158313468323303, 0.14158313468323303, 0.5770269271125978, 0.5770269271125978, 0.5770269271125978, 0.10988033789413443, 0.10988033789413443, 0.10988033789413443, 0.139681313997993, 0.139681313997993, 0.139681313997993, 0.11886441780606305, 0.11886441780606305, 0.11886441780606305, 0.9748956326735576, 0.9748956326735576, 0.9748956326735576, 0.9788751324089218, 0.9788751324089218, 0.9788751324089218, 0.978872033320122, 0.978872033320122, 0.978872033320122, 0.5613211117875581, 0.5613211117875581, 0.5613211117875581, 0.5503317820573677, 0.5503317820573677, 0.5503317820573677, 0.5767195044027322, 0.5767195044027322, 0.5767195044027322, 0.22180132634763738, 0.22180132634763738, 0.22180132634763738, 0.7986618576666047, 0.7986618576666047, 0.7986618576666047, 0.1768368633291295, 0.1768368633291295, 0.1768368633291295, 0.19441291140773587, 0.19441291140773587, 0.19441291140773587, 0.23866081430005381, 0.23866081430005381, 0.23866081430005381, 0.22332167148102167, 0.22332167148102167, 0.22332167148102167, 0.19217871214864046, 0.19217871214864046, 0.19217871214864046, 0.11033361717895118, 0.11033361717895118, 0.11033361717895118, 0.1954980305228804, 0.1954980305228804, 0.1954980305228804, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00034566137854141754, 0.00034566137854141754, 0.00034566137854141754, 0.07125920339751812, 0.07125920339751812, 0.07125920339751812, 0.013217580989536293, 0.013217580989536293, 0.013217580989536293, 0.06321198533294481, 0.06321198533294481, 0.06321198533294481, 0.04577114035925678, 0.04577114035925678, 0.04577114035925678, 0.09658798328664941, 0.09658798328664941, 0.09658798328664941, 0.3060874350179851, 0.3060874350179851, 0.3060874350179851, 0.11965104258447845, 0.11965104258447845, 0.11965104258447845, 0.15715051993764828, 0.15715051993764828, 0.15715051993764828, 0.05455780613770189, 0.05455780613770189, 0.05455780613770189, 0.4989962631800221, 0.4989962631800221, 0.4989962631800221, 0.5324640573005008, 0.5324640573005008, 0.5324640573005008, 0.5089231744761383, 0.5089231744761383, 0.5089231744761383, 0.12055497961633865, 0.12055497961633865, 0.12055497961633865, 0.12131075498347332, 0.12131075498347332, 0.12131075498347332, 0.15912061654852583, 0.15912061654852583, 0.15912061654852583, 0.163519528253665, 0.163519528253665, 0.163519528253665, 0.2488630376910912, 0.2488630376910912, 0.2488630376910912, 0.23056888063354297, 0.23056888063354297, 0.23056888063354297, 0.3625324746336922, 0.3625324746336922, 0.3625324746336922, 0.4825599833120394, 0.4825599833120394, 0.4825599833120394, 0.44570137102562635, 0.44570137102562635, 0.44570137102562635, 0.1612314385004684, 0.1612314385004684, 0.1612314385004684, 0.23783887009193627, 0.23783887009193627, 0.23783887009193627, 0.16725183338394456, 0.16725183338394456, 0.16725183338394456, 0.23657817198819187, 0.23657817198819187, 0.23657817198819187, 0.23543645808806857, 0.23543645808806857, 0.23543645808806857, 0.2140369795971364, 0.2140369795971364, 0.2140369795971364, 0.21877366492012384, 0.21877366492012384, 0.21877366492012384, 0.1993422829253344, 0.1993422829253344, 0.1993422829253344, 0.20483442620804448, 0.20483442620804448, 0.20483442620804448, 0.8631868913624167, 0.8631868913624167, 0.8631868913624167, 0.15832846583405713, 0.15832846583405713, 0.15832846583405713, 0.16990480927754392, 0.16990480927754392, 0.16990480927754392, 0.6491616354155003, 0.6491616354155003, 0.6491616354155003, 0.4891365272633964, 0.4891365272633964, 0.4891365272633964, 0.15456589752638905, 0.15456589752638905, 0.15456589752638905, 0.18112036757653027, 0.18112036757653027, 0.18112036757653027, 0.1871099769076684, 0.1871099769076684, 0.1871099769076684, 0.20197314765216834, 0.20197314765216834, 0.20197314765216834, 0.0905837476483009, 0.0905837476483009, 0.0905837476483009, 0.09459420844935684, 0.09459420844935684, 0.09459420844935684, 0.11167047766823957, 0.11167047766823957, 0.11167047766823957]}, "mutation_prompt": null}
{"id": "b7251722-b588-4ed9-a930-e4a1904daa5e", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 60  # Increased swarm size for better exploration\n        self.mutation_factor = 0.85  # Slightly increased mutation for diversity\n        self.crossover_prob = 0.8  # Adjusted crossover probability\n        self.inertia_weight = 0.55  # Adjusted inertia_weight for balance between exploration and exploitation\n        self.cognitive_coeff = 1.5  # Adjusted cognitive_coeff for slightly less personal bias\n        self.social_coeff = 1.4  # Adjusted social_coeff for enhanced global search\n        self.dynamic_adjustment_freq = 8  # More frequent dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.93  # Slightly different dynamic reduction\n                self.mutation_factor = 0.88 if iteration < self.budget // 2 else 0.75  # Adaptive mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with increased swarm size and adaptive parameter tuning for improved convergence speed.", "configspace": "", "generation": 55, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d62eee2b-896b-466d-87bb-32152bf3ec05", "metadata": {"aucs": [0.8065029332555447, 0.8065029332555447, 0.8065029332555447, 0.7879071665328757, 0.7879071665328757, 0.7879071665328757, 0.7934045605658537, 0.7934045605658537, 0.7934045605658537, 0.5778486044918812, 0.5778486044918812, 0.5778486044918812, 0.5646336789062972, 0.5646336789062972, 0.5646336789062972, 0.5771795328509839, 0.5771795328509839, 0.5771795328509839, 0.14567817676423023, 0.14567817676423023, 0.14567817676423023, 0.14158313468323303, 0.14158313468323303, 0.14158313468323303, 0.5770269271125978, 0.5770269271125978, 0.5770269271125978, 0.10988033789413443, 0.10988033789413443, 0.10988033789413443, 0.139681313997993, 0.139681313997993, 0.139681313997993, 0.11886441780606305, 0.11886441780606305, 0.11886441780606305, 0.9748956326735576, 0.9748956326735576, 0.9748956326735576, 0.9788751324089218, 0.9788751324089218, 0.9788751324089218, 0.978872033320122, 0.978872033320122, 0.978872033320122, 0.5613211117875581, 0.5613211117875581, 0.5613211117875581, 0.5503317820573677, 0.5503317820573677, 0.5503317820573677, 0.5767195044027322, 0.5767195044027322, 0.5767195044027322, 0.22180132634763738, 0.22180132634763738, 0.22180132634763738, 0.7986618576666047, 0.7986618576666047, 0.7986618576666047, 0.1768368633291295, 0.1768368633291295, 0.1768368633291295, 0.19441291140773587, 0.19441291140773587, 0.19441291140773587, 0.23866081430005381, 0.23866081430005381, 0.23866081430005381, 0.22332167148102167, 0.22332167148102167, 0.22332167148102167, 0.19217871214864046, 0.19217871214864046, 0.19217871214864046, 0.11033361717895118, 0.11033361717895118, 0.11033361717895118, 0.1954980305228804, 0.1954980305228804, 0.1954980305228804, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00034566137854141754, 0.00034566137854141754, 0.00034566137854141754, 0.07125920339751812, 0.07125920339751812, 0.07125920339751812, 0.013217580989536293, 0.013217580989536293, 0.013217580989536293, 0.06321198533294481, 0.06321198533294481, 0.06321198533294481, 0.04577114035925678, 0.04577114035925678, 0.04577114035925678, 0.09658798328664941, 0.09658798328664941, 0.09658798328664941, 0.3060874350179851, 0.3060874350179851, 0.3060874350179851, 0.11965104258447845, 0.11965104258447845, 0.11965104258447845, 0.15715051993764828, 0.15715051993764828, 0.15715051993764828, 0.05455780613770189, 0.05455780613770189, 0.05455780613770189, 0.4989962631800221, 0.4989962631800221, 0.4989962631800221, 0.5324640573005008, 0.5324640573005008, 0.5324640573005008, 0.5089231744761383, 0.5089231744761383, 0.5089231744761383, 0.12055497961633865, 0.12055497961633865, 0.12055497961633865, 0.12131075498347332, 0.12131075498347332, 0.12131075498347332, 0.15912061654852583, 0.15912061654852583, 0.15912061654852583, 0.163519528253665, 0.163519528253665, 0.163519528253665, 0.2488630376910912, 0.2488630376910912, 0.2488630376910912, 0.23056888063354297, 0.23056888063354297, 0.23056888063354297, 0.3625324746336922, 0.3625324746336922, 0.3625324746336922, 0.4825599833120394, 0.4825599833120394, 0.4825599833120394, 0.44570137102562635, 0.44570137102562635, 0.44570137102562635, 0.1612314385004684, 0.1612314385004684, 0.1612314385004684, 0.23783887009193627, 0.23783887009193627, 0.23783887009193627, 0.16725183338394456, 0.16725183338394456, 0.16725183338394456, 0.23657817198819187, 0.23657817198819187, 0.23657817198819187, 0.23543645808806857, 0.23543645808806857, 0.23543645808806857, 0.2140369795971364, 0.2140369795971364, 0.2140369795971364, 0.21877366492012384, 0.21877366492012384, 0.21877366492012384, 0.1993422829253344, 0.1993422829253344, 0.1993422829253344, 0.20483442620804448, 0.20483442620804448, 0.20483442620804448, 0.8631868913624167, 0.8631868913624167, 0.8631868913624167, 0.15832846583405713, 0.15832846583405713, 0.15832846583405713, 0.16990480927754392, 0.16990480927754392, 0.16990480927754392, 0.6491616354155003, 0.6491616354155003, 0.6491616354155003, 0.4891365272633964, 0.4891365272633964, 0.4891365272633964, 0.15456589752638905, 0.15456589752638905, 0.15456589752638905, 0.18112036757653027, 0.18112036757653027, 0.18112036757653027, 0.1871099769076684, 0.1871099769076684, 0.1871099769076684, 0.20197314765216834, 0.20197314765216834, 0.20197314765216834, 0.0905837476483009, 0.0905837476483009, 0.0905837476483009, 0.09459420844935684, 0.09459420844935684, 0.09459420844935684, 0.11167047766823957, 0.11167047766823957, 0.11167047766823957]}, "mutation_prompt": null}
{"id": "fdb7f21c-6646-4086-ad51-5ef580830f95", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 60  # Increased swarm size for better exploration\n        self.mutation_factor = 0.85  # Slightly increased mutation for diversity\n        self.crossover_prob = 0.8  # Adjusted crossover probability\n        self.inertia_weight = 0.55  # Adjusted inertia_weight for balance between exploration and exploitation\n        self.cognitive_coeff = 1.5  # Adjusted cognitive_coeff for slightly less personal bias\n        self.social_coeff = 1.4  # Adjusted social_coeff for enhanced global search\n        self.dynamic_adjustment_freq = 8  # More frequent dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.93  # Slightly different dynamic reduction\n                self.mutation_factor = 0.88 if iteration < self.budget // 2 else 0.75  # Adaptive mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with increased swarm size and adaptive parameter tuning for improved convergence speed.", "configspace": "", "generation": 55, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d62eee2b-896b-466d-87bb-32152bf3ec05", "metadata": {"aucs": [0.8065029332555447, 0.8065029332555447, 0.8065029332555447, 0.7879071665328757, 0.7879071665328757, 0.7879071665328757, 0.7934045605658537, 0.7934045605658537, 0.7934045605658537, 0.5778486044918812, 0.5778486044918812, 0.5778486044918812, 0.5646336789062972, 0.5646336789062972, 0.5646336789062972, 0.5771795328509839, 0.5771795328509839, 0.5771795328509839, 0.14567817676423023, 0.14567817676423023, 0.14567817676423023, 0.14158313468323303, 0.14158313468323303, 0.14158313468323303, 0.5770269271125978, 0.5770269271125978, 0.5770269271125978, 0.10988033789413443, 0.10988033789413443, 0.10988033789413443, 0.139681313997993, 0.139681313997993, 0.139681313997993, 0.11886441780606305, 0.11886441780606305, 0.11886441780606305, 0.9748956326735576, 0.9748956326735576, 0.9748956326735576, 0.9788751324089218, 0.9788751324089218, 0.9788751324089218, 0.978872033320122, 0.978872033320122, 0.978872033320122, 0.5613211117875581, 0.5613211117875581, 0.5613211117875581, 0.5503317820573677, 0.5503317820573677, 0.5503317820573677, 0.5767195044027322, 0.5767195044027322, 0.5767195044027322, 0.22180132634763738, 0.22180132634763738, 0.22180132634763738, 0.7986618576666047, 0.7986618576666047, 0.7986618576666047, 0.1768368633291295, 0.1768368633291295, 0.1768368633291295, 0.19441291140773587, 0.19441291140773587, 0.19441291140773587, 0.23866081430005381, 0.23866081430005381, 0.23866081430005381, 0.22332167148102167, 0.22332167148102167, 0.22332167148102167, 0.19217871214864046, 0.19217871214864046, 0.19217871214864046, 0.11033361717895118, 0.11033361717895118, 0.11033361717895118, 0.1954980305228804, 0.1954980305228804, 0.1954980305228804, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00034566137854141754, 0.00034566137854141754, 0.00034566137854141754, 0.07125920339751812, 0.07125920339751812, 0.07125920339751812, 0.013217580989536293, 0.013217580989536293, 0.013217580989536293, 0.06321198533294481, 0.06321198533294481, 0.06321198533294481, 0.04577114035925678, 0.04577114035925678, 0.04577114035925678, 0.09658798328664941, 0.09658798328664941, 0.09658798328664941, 0.3060874350179851, 0.3060874350179851, 0.3060874350179851, 0.11965104258447845, 0.11965104258447845, 0.11965104258447845, 0.15715051993764828, 0.15715051993764828, 0.15715051993764828, 0.05455780613770189, 0.05455780613770189, 0.05455780613770189, 0.4989962631800221, 0.4989962631800221, 0.4989962631800221, 0.5324640573005008, 0.5324640573005008, 0.5324640573005008, 0.5089231744761383, 0.5089231744761383, 0.5089231744761383, 0.12055497961633865, 0.12055497961633865, 0.12055497961633865, 0.12131075498347332, 0.12131075498347332, 0.12131075498347332, 0.15912061654852583, 0.15912061654852583, 0.15912061654852583, 0.163519528253665, 0.163519528253665, 0.163519528253665, 0.2488630376910912, 0.2488630376910912, 0.2488630376910912, 0.23056888063354297, 0.23056888063354297, 0.23056888063354297, 0.3625324746336922, 0.3625324746336922, 0.3625324746336922, 0.4825599833120394, 0.4825599833120394, 0.4825599833120394, 0.44570137102562635, 0.44570137102562635, 0.44570137102562635, 0.1612314385004684, 0.1612314385004684, 0.1612314385004684, 0.23783887009193627, 0.23783887009193627, 0.23783887009193627, 0.16725183338394456, 0.16725183338394456, 0.16725183338394456, 0.23657817198819187, 0.23657817198819187, 0.23657817198819187, 0.23543645808806857, 0.23543645808806857, 0.23543645808806857, 0.2140369795971364, 0.2140369795971364, 0.2140369795971364, 0.21877366492012384, 0.21877366492012384, 0.21877366492012384, 0.1993422829253344, 0.1993422829253344, 0.1993422829253344, 0.20483442620804448, 0.20483442620804448, 0.20483442620804448, 0.8631868913624167, 0.8631868913624167, 0.8631868913624167, 0.15832846583405713, 0.15832846583405713, 0.15832846583405713, 0.16990480927754392, 0.16990480927754392, 0.16990480927754392, 0.6491616354155003, 0.6491616354155003, 0.6491616354155003, 0.4891365272633964, 0.4891365272633964, 0.4891365272633964, 0.15456589752638905, 0.15456589752638905, 0.15456589752638905, 0.18112036757653027, 0.18112036757653027, 0.18112036757653027, 0.1871099769076684, 0.1871099769076684, 0.1871099769076684, 0.20197314765216834, 0.20197314765216834, 0.20197314765216834, 0.0905837476483009, 0.0905837476483009, 0.0905837476483009, 0.09459420844935684, 0.09459420844935684, 0.09459420844935684, 0.11167047766823957, 0.11167047766823957, 0.11167047766823957]}, "mutation_prompt": null}
{"id": "6d764691-87da-4cd1-9d60-85039ab70ce4", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 60  # Retain swarm size for exploration\n        self.mutation_factor = 0.85  # Balanced mutation for diversity\n        self.crossover_prob = 0.85  # Increased crossover probability for exploration\n        self.inertia_weight = 0.5  # Adjusted inertia for better dynamic adjustment\n        self.cognitive_coeff = 1.4  # Reduced cognitive bias\n        self.social_coeff = 1.5  # Enhanced global search\n        self.dynamic_adjustment_freq = 7  # More frequent adjustments\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.92  # Slightly different dynamic reduction\n                if iteration > self.budget // 3:  # Earlier mutation adaptation\n                    self.mutation_factor = 0.80 if iteration < self.budget // 2 else 0.7\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            if iteration % (self.budget // 10) == 0:  # Stochastic restart\n                restart_indices = np.random.choice(self.swarm_size, size=int(0.1 * self.swarm_size), replace=False)\n                positions[restart_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(restart_indices), self.dim))\n\n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with adaptive local-global balance and stochastic restarts for improved robustness and convergence speed.", "configspace": "", "generation": 65, "fitness": 0.3038906507553342, "feedback": "The algorithm Enhanced_PSO_ADE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.26.", "error": "", "parent_id": "d62eee2b-896b-466d-87bb-32152bf3ec05", "metadata": {"aucs": [0.7995796496834641, 0.7995796496834641, 0.7995796496834641, 0.8150291641800724, 0.8150291641800724, 0.8150291641800724, 0.8104807919153069, 0.8104807919153069, 0.8104807919153069, 0.386273143375067, 0.386273143375067, 0.386273143375067, 0.603478443987336, 0.603478443987336, 0.603478443987336, 0.5729871548911354, 0.5729871548911354, 0.5729871548911354, 0.1011978520679071, 0.1011978520679071, 0.1011978520679071, 0.47593518819226, 0.47593518819226, 0.47593518819226, 0.44279678531104605, 0.44279678531104605, 0.44279678531104605, 0.11683903205377133, 0.11683903205377133, 0.11683903205377133, 0.12207799570216482, 0.12207799570216482, 0.12207799570216482, 0.11688872944244066, 0.11688872944244066, 0.11688872944244066, 0.9839197986443611, 0.9839197986443611, 0.9839197986443611, 0.9706613145794798, 0.9706613145794798, 0.9706613145794798, 0.9727552634245967, 0.9727552634245967, 0.9727552634245967, 0.5525341524761302, 0.5525341524761302, 0.5525341524761302, 0.5590123981947646, 0.5590123981947646, 0.5590123981947646, 0.5624732930064815, 0.5624732930064815, 0.5624732930064815, 0.7452149907067944, 0.7452149907067944, 0.7452149907067944, 0.34965494684293885, 0.34965494684293885, 0.34965494684293885, 0.14712363734594658, 0.14712363734594658, 0.14712363734594658, 0.192656200693202, 0.192656200693202, 0.192656200693202, 0.12871467276769633, 0.12871467276769633, 0.12871467276769633, 0.12927406592764634, 0.12927406592764634, 0.12927406592764634, 0.11816325664554805, 0.11816325664554805, 0.11816325664554805, 0.13949177843478078, 0.13949177843478078, 0.13949177843478078, 0.22655335322988546, 0.22655335322988546, 0.22655335322988546, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011598175429965885, 0.011598175429965885, 0.011598175429965885, 0.10408323429704214, 0.10408323429704214, 0.10408323429704214, 0.029894165116264748, 0.029894165116264748, 0.029894165116264748, 0.006828856830095487, 0.006828856830095487, 0.006828856830095487, 0.05260703981431469, 0.05260703981431469, 0.05260703981431469, 0.042612843695043034, 0.042612843695043034, 0.042612843695043034, 0.08253807997109941, 0.08253807997109941, 0.08253807997109941, 0.11435231042576666, 0.11435231042576666, 0.11435231042576666, 0.1025533972318714, 0.1025533972318714, 0.1025533972318714, 0.08629789638748897, 0.08629789638748897, 0.08629789638748897, 0.1609918718190274, 0.1609918718190274, 0.1609918718190274, 0.5262674641770531, 0.5262674641770531, 0.5262674641770531, 0.5162451516482369, 0.5162451516482369, 0.5162451516482369, 0.5458313129875686, 0.5458313129875686, 0.5458313129875686, 0.1145249319264714, 0.1145249319264714, 0.1145249319264714, 0.14667474829012794, 0.14667474829012794, 0.14667474829012794, 0.09800769674003607, 0.09800769674003607, 0.09800769674003607, 0.15736985676646398, 0.15736985676646398, 0.15736985676646398, 0.1852809516559838, 0.1852809516559838, 0.1852809516559838, 0.24030496631191034, 0.24030496631191034, 0.24030496631191034, 0.3162366794329252, 0.3162366794329252, 0.3162366794329252, 0.2564298330714748, 0.2564298330714748, 0.2564298330714748, 0.33798723038486833, 0.33798723038486833, 0.33798723038486833, 0.2876320578206789, 0.2876320578206789, 0.2876320578206789, 0.24222925057631306, 0.24222925057631306, 0.24222925057631306, 0.19869887395853625, 0.19869887395853625, 0.19869887395853625, 0.20599408270987218, 0.20599408270987218, 0.20599408270987218, 0.2191343491203548, 0.2191343491203548, 0.2191343491203548, 0.22165501034616053, 0.22165501034616053, 0.22165501034616053, 0.21140037551055435, 0.21140037551055435, 0.21140037551055435, 0.21139581912806882, 0.21139581912806882, 0.21139581912806882, 0.22002691804609997, 0.22002691804609997, 0.22002691804609997, 0.8750052426064311, 0.8750052426064311, 0.8750052426064311, 0.15788468673054923, 0.15788468673054923, 0.15788468673054923, 0.16945071403299594, 0.16945071403299594, 0.16945071403299594, 0.5049930157257395, 0.5049930157257395, 0.5049930157257395, 0.20552207017495305, 0.20552207017495305, 0.20552207017495305, 0.6584935049416616, 0.6584935049416616, 0.6584935049416616, 0.19711093697434812, 0.19711093697434812, 0.19711093697434812, 0.19190119650493398, 0.19190119650493398, 0.19190119650493398, 0.19913564936523465, 0.19913564936523465, 0.19913564936523465, 0.0800683235439772, 0.0800683235439772, 0.0800683235439772, 0.09230231885441786, 0.09230231885441786, 0.09230231885441786, 0.1527067095788578, 0.1527067095788578, 0.1527067095788578]}, "mutation_prompt": null}
{"id": "7229fae8-99dd-4677-a804-6dd6b6e0d8d8", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 60  # Increased swarm size for better exploration\n        self.mutation_factor = 0.85  # Slightly increased mutation for diversity\n        self.crossover_prob = 0.8  # Adjusted crossover probability\n        self.inertia_weight = 0.55  # Adjusted inertia_weight for balance between exploration and exploitation\n        self.cognitive_coeff = 1.5  # Adjusted cognitive_coeff for slightly less personal bias\n        self.social_coeff = 1.4  # Adjusted social_coeff for enhanced global search\n        self.dynamic_adjustment_freq = 8  # More frequent dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.93  # Slightly different dynamic reduction\n                self.mutation_factor = 0.88 if iteration < self.budget // 2 else 0.75  # Adaptive mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with increased swarm size and adaptive parameter tuning for improved convergence speed.", "configspace": "", "generation": 55, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d62eee2b-896b-466d-87bb-32152bf3ec05", "metadata": {"aucs": [0.8065029332555447, 0.8065029332555447, 0.8065029332555447, 0.7879071665328757, 0.7879071665328757, 0.7879071665328757, 0.7934045605658537, 0.7934045605658537, 0.7934045605658537, 0.5778486044918812, 0.5778486044918812, 0.5778486044918812, 0.5646336789062972, 0.5646336789062972, 0.5646336789062972, 0.5771795328509839, 0.5771795328509839, 0.5771795328509839, 0.14567817676423023, 0.14567817676423023, 0.14567817676423023, 0.14158313468323303, 0.14158313468323303, 0.14158313468323303, 0.5770269271125978, 0.5770269271125978, 0.5770269271125978, 0.10988033789413443, 0.10988033789413443, 0.10988033789413443, 0.139681313997993, 0.139681313997993, 0.139681313997993, 0.11886441780606305, 0.11886441780606305, 0.11886441780606305, 0.9748956326735576, 0.9748956326735576, 0.9748956326735576, 0.9788751324089218, 0.9788751324089218, 0.9788751324089218, 0.978872033320122, 0.978872033320122, 0.978872033320122, 0.5613211117875581, 0.5613211117875581, 0.5613211117875581, 0.5503317820573677, 0.5503317820573677, 0.5503317820573677, 0.5767195044027322, 0.5767195044027322, 0.5767195044027322, 0.22180132634763738, 0.22180132634763738, 0.22180132634763738, 0.7986618576666047, 0.7986618576666047, 0.7986618576666047, 0.1768368633291295, 0.1768368633291295, 0.1768368633291295, 0.19441291140773587, 0.19441291140773587, 0.19441291140773587, 0.23866081430005381, 0.23866081430005381, 0.23866081430005381, 0.22332167148102167, 0.22332167148102167, 0.22332167148102167, 0.19217871214864046, 0.19217871214864046, 0.19217871214864046, 0.11033361717895118, 0.11033361717895118, 0.11033361717895118, 0.1954980305228804, 0.1954980305228804, 0.1954980305228804, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00034566137854141754, 0.00034566137854141754, 0.00034566137854141754, 0.07125920339751812, 0.07125920339751812, 0.07125920339751812, 0.013217580989536293, 0.013217580989536293, 0.013217580989536293, 0.06321198533294481, 0.06321198533294481, 0.06321198533294481, 0.04577114035925678, 0.04577114035925678, 0.04577114035925678, 0.09658798328664941, 0.09658798328664941, 0.09658798328664941, 0.3060874350179851, 0.3060874350179851, 0.3060874350179851, 0.11965104258447845, 0.11965104258447845, 0.11965104258447845, 0.15715051993764828, 0.15715051993764828, 0.15715051993764828, 0.05455780613770189, 0.05455780613770189, 0.05455780613770189, 0.4989962631800221, 0.4989962631800221, 0.4989962631800221, 0.5324640573005008, 0.5324640573005008, 0.5324640573005008, 0.5089231744761383, 0.5089231744761383, 0.5089231744761383, 0.12055497961633865, 0.12055497961633865, 0.12055497961633865, 0.12131075498347332, 0.12131075498347332, 0.12131075498347332, 0.15912061654852583, 0.15912061654852583, 0.15912061654852583, 0.163519528253665, 0.163519528253665, 0.163519528253665, 0.2488630376910912, 0.2488630376910912, 0.2488630376910912, 0.23056888063354297, 0.23056888063354297, 0.23056888063354297, 0.3625324746336922, 0.3625324746336922, 0.3625324746336922, 0.4825599833120394, 0.4825599833120394, 0.4825599833120394, 0.44570137102562635, 0.44570137102562635, 0.44570137102562635, 0.1612314385004684, 0.1612314385004684, 0.1612314385004684, 0.23783887009193627, 0.23783887009193627, 0.23783887009193627, 0.16725183338394456, 0.16725183338394456, 0.16725183338394456, 0.23657817198819187, 0.23657817198819187, 0.23657817198819187, 0.23543645808806857, 0.23543645808806857, 0.23543645808806857, 0.2140369795971364, 0.2140369795971364, 0.2140369795971364, 0.21877366492012384, 0.21877366492012384, 0.21877366492012384, 0.1993422829253344, 0.1993422829253344, 0.1993422829253344, 0.20483442620804448, 0.20483442620804448, 0.20483442620804448, 0.8631868913624167, 0.8631868913624167, 0.8631868913624167, 0.15832846583405713, 0.15832846583405713, 0.15832846583405713, 0.16990480927754392, 0.16990480927754392, 0.16990480927754392, 0.6491616354155003, 0.6491616354155003, 0.6491616354155003, 0.4891365272633964, 0.4891365272633964, 0.4891365272633964, 0.15456589752638905, 0.15456589752638905, 0.15456589752638905, 0.18112036757653027, 0.18112036757653027, 0.18112036757653027, 0.1871099769076684, 0.1871099769076684, 0.1871099769076684, 0.20197314765216834, 0.20197314765216834, 0.20197314765216834, 0.0905837476483009, 0.0905837476483009, 0.0905837476483009, 0.09459420844935684, 0.09459420844935684, 0.09459420844935684, 0.11167047766823957, 0.11167047766823957, 0.11167047766823957]}, "mutation_prompt": null}
{"id": "aeef5ad7-ecde-4cfb-b525-69ee3b378990", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 60  # Increased swarm size for better exploration\n        self.mutation_factor = 0.85  # Slightly increased mutation for diversity\n        self.crossover_prob = 0.8  # Adjusted crossover probability\n        self.inertia_weight = 0.55  # Adjusted inertia_weight for balance between exploration and exploitation\n        self.cognitive_coeff = 1.5  # Adjusted cognitive_coeff for slightly less personal bias\n        self.social_coeff = 1.4  # Adjusted social_coeff for enhanced global search\n        self.dynamic_adjustment_freq = 8  # More frequent dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.93  # Slightly different dynamic reduction\n                self.mutation_factor = 0.88 if iteration < self.budget // 2 else 0.75  # Adaptive mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with increased swarm size and adaptive parameter tuning for improved convergence speed.", "configspace": "", "generation": 55, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d62eee2b-896b-466d-87bb-32152bf3ec05", "metadata": {"aucs": [0.8065029332555447, 0.8065029332555447, 0.8065029332555447, 0.7879071665328757, 0.7879071665328757, 0.7879071665328757, 0.7934045605658537, 0.7934045605658537, 0.7934045605658537, 0.5778486044918812, 0.5778486044918812, 0.5778486044918812, 0.5646336789062972, 0.5646336789062972, 0.5646336789062972, 0.5771795328509839, 0.5771795328509839, 0.5771795328509839, 0.14567817676423023, 0.14567817676423023, 0.14567817676423023, 0.14158313468323303, 0.14158313468323303, 0.14158313468323303, 0.5770269271125978, 0.5770269271125978, 0.5770269271125978, 0.10988033789413443, 0.10988033789413443, 0.10988033789413443, 0.139681313997993, 0.139681313997993, 0.139681313997993, 0.11886441780606305, 0.11886441780606305, 0.11886441780606305, 0.9748956326735576, 0.9748956326735576, 0.9748956326735576, 0.9788751324089218, 0.9788751324089218, 0.9788751324089218, 0.978872033320122, 0.978872033320122, 0.978872033320122, 0.5613211117875581, 0.5613211117875581, 0.5613211117875581, 0.5503317820573677, 0.5503317820573677, 0.5503317820573677, 0.5767195044027322, 0.5767195044027322, 0.5767195044027322, 0.22180132634763738, 0.22180132634763738, 0.22180132634763738, 0.7986618576666047, 0.7986618576666047, 0.7986618576666047, 0.1768368633291295, 0.1768368633291295, 0.1768368633291295, 0.19441291140773587, 0.19441291140773587, 0.19441291140773587, 0.23866081430005381, 0.23866081430005381, 0.23866081430005381, 0.22332167148102167, 0.22332167148102167, 0.22332167148102167, 0.19217871214864046, 0.19217871214864046, 0.19217871214864046, 0.11033361717895118, 0.11033361717895118, 0.11033361717895118, 0.1954980305228804, 0.1954980305228804, 0.1954980305228804, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00034566137854141754, 0.00034566137854141754, 0.00034566137854141754, 0.07125920339751812, 0.07125920339751812, 0.07125920339751812, 0.013217580989536293, 0.013217580989536293, 0.013217580989536293, 0.06321198533294481, 0.06321198533294481, 0.06321198533294481, 0.04577114035925678, 0.04577114035925678, 0.04577114035925678, 0.09658798328664941, 0.09658798328664941, 0.09658798328664941, 0.3060874350179851, 0.3060874350179851, 0.3060874350179851, 0.11965104258447845, 0.11965104258447845, 0.11965104258447845, 0.15715051993764828, 0.15715051993764828, 0.15715051993764828, 0.05455780613770189, 0.05455780613770189, 0.05455780613770189, 0.4989962631800221, 0.4989962631800221, 0.4989962631800221, 0.5324640573005008, 0.5324640573005008, 0.5324640573005008, 0.5089231744761383, 0.5089231744761383, 0.5089231744761383, 0.12055497961633865, 0.12055497961633865, 0.12055497961633865, 0.12131075498347332, 0.12131075498347332, 0.12131075498347332, 0.15912061654852583, 0.15912061654852583, 0.15912061654852583, 0.163519528253665, 0.163519528253665, 0.163519528253665, 0.2488630376910912, 0.2488630376910912, 0.2488630376910912, 0.23056888063354297, 0.23056888063354297, 0.23056888063354297, 0.3625324746336922, 0.3625324746336922, 0.3625324746336922, 0.4825599833120394, 0.4825599833120394, 0.4825599833120394, 0.44570137102562635, 0.44570137102562635, 0.44570137102562635, 0.1612314385004684, 0.1612314385004684, 0.1612314385004684, 0.23783887009193627, 0.23783887009193627, 0.23783887009193627, 0.16725183338394456, 0.16725183338394456, 0.16725183338394456, 0.23657817198819187, 0.23657817198819187, 0.23657817198819187, 0.23543645808806857, 0.23543645808806857, 0.23543645808806857, 0.2140369795971364, 0.2140369795971364, 0.2140369795971364, 0.21877366492012384, 0.21877366492012384, 0.21877366492012384, 0.1993422829253344, 0.1993422829253344, 0.1993422829253344, 0.20483442620804448, 0.20483442620804448, 0.20483442620804448, 0.8631868913624167, 0.8631868913624167, 0.8631868913624167, 0.15832846583405713, 0.15832846583405713, 0.15832846583405713, 0.16990480927754392, 0.16990480927754392, 0.16990480927754392, 0.6491616354155003, 0.6491616354155003, 0.6491616354155003, 0.4891365272633964, 0.4891365272633964, 0.4891365272633964, 0.15456589752638905, 0.15456589752638905, 0.15456589752638905, 0.18112036757653027, 0.18112036757653027, 0.18112036757653027, 0.1871099769076684, 0.1871099769076684, 0.1871099769076684, 0.20197314765216834, 0.20197314765216834, 0.20197314765216834, 0.0905837476483009, 0.0905837476483009, 0.0905837476483009, 0.09459420844935684, 0.09459420844935684, 0.09459420844935684, 0.11167047766823957, 0.11167047766823957, 0.11167047766823957]}, "mutation_prompt": null}
{"id": "02950a21-3312-4529-ba3e-671e5584ae29", "solution": "import numpy as np\nfrom scipy.stats import qmc\n\nclass Chaotic_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 60\n        self.mutation_factor = 0.85\n        self.crossover_prob = 0.8\n        self.inertia_weight = 0.55\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.4\n        self.dynamic_adjustment_freq = 8\n        self.chaos_map = qmc.Halton(d=1, scramble=True).random\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.92  # Slightly different dynamic reduction\n                chaos_value = self.chaos_map(1)[0][0]\n                self.mutation_factor = 0.88 if chaos_value < 0.5 else 0.75\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Chaotic_PSO_ADE_Optimizer", "description": "Integration of chaotic maps for parameter control enhances convergence speed and solution diversity.", "configspace": "", "generation": 68, "fitness": 0.3071557010804196, "feedback": "The algorithm Chaotic_PSO_ADE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.26.", "error": "", "parent_id": "d62eee2b-896b-466d-87bb-32152bf3ec05", "metadata": {"aucs": [0.8013068318487454, 0.7991250745976901, 0.7991274598686258, 0.772827193243434, 0.7736610584787698, 0.779939453276135, 0.8010461466935587, 0.799334695959117, 0.8178761789353071, 0.4605470427194539, 0.5425897553473025, 0.46574287828221894, 0.5876518336944242, 0.5895441482434842, 0.5651570819591994, 0.5598020264941721, 0.5286758376335323, 0.5410567334182343, 0.13436046709741734, 0.1093216278800423, 0.1622300348854453, 0.1605185822394789, 0.16053798953886522, 0.16024820258320505, 0.5270293838902571, 0.48642217273194166, 0.5270293838902571, 0.11680362689262258, 0.11462128956598883, 0.1168100851678997, 0.12956360451829096, 0.1285682678128678, 0.11451087792799353, 0.1073104943855171, 0.13212646560641328, 0.1321264356666546, 0.9748868570670661, 0.9748868570670661, 0.9741613652177166, 0.9789184767005592, 0.9789184767005592, 0.9788772451764101, 0.9788698320736253, 0.9788698320736253, 0.9788698320736253, 0.5871251416708465, 0.5543102073627243, 0.586148978293943, 0.14727070500159467, 0.14922464816418102, 0.24415601173500434, 0.5763746252966633, 0.5765220860521092, 0.6086639098809792, 0.3490033006733749, 0.3489724833851501, 0.6897363093945837, 0.739721137249394, 0.3658508605783807, 0.7704304568428598, 0.7080535624091533, 0.1740052134769816, 0.1740052134769816, 0.2071247158299545, 0.20453938142426042, 0.18480393199362155, 0.1909605004835424, 0.18503709524556033, 0.1908919342061316, 0.2128129432414403, 0.21176243083267832, 0.2108654529390488, 0.10264192202415012, 0.10266608718201364, 0.10275081934225849, 0.10896220907861498, 0.10899080929728788, 0.19504422535144728, 0.1904119619230109, 0.20817583969240894, 0.16042996155493094, 0.0002929392923524121, 0.0011796593531778754, 0.01308323245152787, 0.006875967893216539, 0.012806960273867518, 0.014507877503813549, 9.999999999998899e-05, 0.00013895439006905708, 9.999999999998899e-05, 0.07204292306137872, 0.07796076313256362, 0.07131252900098783, 0.03806424867093483, 0.03833871192939242, 0.03463903491472686, 0.049169284924832746, 0.0744249967541959, 0.05034707909135627, 0.04189992115693075, 0.042030404371047214, 0.04203151764689117, 0.17767789758918806, 0.17764580042824496, 0.08765248793511216, 0.06333557753694663, 0.06368044475396473, 0.07262348673696961, 0.22851055921585428, 0.3401399029821994, 0.2294961214274004, 0.19187446672035013, 0.09898600158740523, 0.09898604733744654, 0.04620929269948015, 0.047097208554755854, 0.047096963605073316, 0.5311157304093848, 0.5470412150244466, 0.6157772871656523, 0.5487141951770669, 0.5496089186718862, 0.5455274856100079, 0.5711765296748905, 0.5681332923277699, 0.5677743497883487, 0.1499192933305583, 0.13543896653404974, 0.13550438628192063, 0.1465726952433184, 0.14657592567468258, 0.5066634856460516, 0.10290791781455377, 0.14399817149155336, 0.10774265932976723, 0.23559385220262052, 0.18588272238305759, 0.24023964256047414, 0.20421184868235265, 0.18471080016832853, 0.17099926112446484, 0.18564296818036596, 0.1850835052595493, 0.18508400767510813, 0.3752088667445328, 0.343857133959375, 0.45650804664242883, 0.30791159649022837, 0.3124462521932464, 0.30812617310677504, 0.4777311458967358, 0.46480049452251937, 0.530586514475547, 0.288264449325332, 0.17950711608167036, 0.18012732450495916, 0.2437721677206368, 0.26890035204539386, 0.2717192071607528, 0.2209519928363246, 0.2011955185479224, 0.2549591415578012, 0.2132582626269971, 0.18873871002567566, 0.18623222781253124, 0.19409741083024, 0.21393573878938288, 0.22930476170263292, 0.21742102804091845, 0.22110846051262434, 0.21600823328266638, 0.18963596351765932, 0.238524339190464, 0.23594967333987404, 0.22907779436499376, 0.19851346397683356, 0.1900883166625178, 0.2205594034787991, 0.20419996428558151, 0.20416456072394806, 0.884764726865638, 0.884764726865638, 0.8695601551667241, 0.15833484291169153, 0.1583601053669882, 0.15833488783464877, 0.16989645305608114, 0.16990364378905976, 0.16990352048733803, 0.6829911810477387, 0.6214406699140073, 0.5930626160148176, 0.7382028705523382, 0.20787575007691572, 0.5529763217259855, 0.15471859170431745, 0.1547179066887756, 0.15460107010088797, 0.17850370052498254, 0.19038001346567257, 0.19530443722282043, 0.18527206146057584, 0.20819845330087794, 0.18289988350202246, 0.1776798277243885, 0.18211360865761095, 0.18128659319454066, 0.0961184216376576, 0.10643606734568478, 0.09180414388874492, 0.09203624187600146, 0.09121719583660726, 0.09241744310956035, 0.1258130671907407, 0.11061163893707016, 0.11488013928099428]}, "mutation_prompt": null}
{"id": "854bb62e-4059-4fff-9cd1-6cd99f8ac1bb", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 60  # Increased swarm size for better exploration\n        self.mutation_factor = 0.85  # Slightly increased mutation for diversity\n        self.crossover_prob = 0.8  # Adjusted crossover probability\n        self.inertia_weight = 0.55  # Adjusted inertia_weight for balance between exploration and exploitation\n        self.cognitive_coeff = 1.5  # Adjusted cognitive_coeff for slightly less personal bias\n        self.social_coeff = 1.4  # Adjusted social_coeff for enhanced global search\n        self.dynamic_adjustment_freq = 8  # More frequent dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.93  # Slightly different dynamic reduction\n                self.mutation_factor = 0.88 if iteration < self.budget // 2 else 0.75  # Adaptive mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with increased swarm size and adaptive parameter tuning for improved convergence speed.", "configspace": "", "generation": 55, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d62eee2b-896b-466d-87bb-32152bf3ec05", "metadata": {"aucs": [0.8065029332555447, 0.8065029332555447, 0.8065029332555447, 0.7879071665328757, 0.7879071665328757, 0.7879071665328757, 0.7934045605658537, 0.7934045605658537, 0.7934045605658537, 0.5778486044918812, 0.5778486044918812, 0.5778486044918812, 0.5646336789062972, 0.5646336789062972, 0.5646336789062972, 0.5771795328509839, 0.5771795328509839, 0.5771795328509839, 0.14567817676423023, 0.14567817676423023, 0.14567817676423023, 0.14158313468323303, 0.14158313468323303, 0.14158313468323303, 0.5770269271125978, 0.5770269271125978, 0.5770269271125978, 0.10988033789413443, 0.10988033789413443, 0.10988033789413443, 0.139681313997993, 0.139681313997993, 0.139681313997993, 0.11886441780606305, 0.11886441780606305, 0.11886441780606305, 0.9748956326735576, 0.9748956326735576, 0.9748956326735576, 0.9788751324089218, 0.9788751324089218, 0.9788751324089218, 0.978872033320122, 0.978872033320122, 0.978872033320122, 0.5613211117875581, 0.5613211117875581, 0.5613211117875581, 0.5503317820573677, 0.5503317820573677, 0.5503317820573677, 0.5767195044027322, 0.5767195044027322, 0.5767195044027322, 0.22180132634763738, 0.22180132634763738, 0.22180132634763738, 0.7986618576666047, 0.7986618576666047, 0.7986618576666047, 0.1768368633291295, 0.1768368633291295, 0.1768368633291295, 0.19441291140773587, 0.19441291140773587, 0.19441291140773587, 0.23866081430005381, 0.23866081430005381, 0.23866081430005381, 0.22332167148102167, 0.22332167148102167, 0.22332167148102167, 0.19217871214864046, 0.19217871214864046, 0.19217871214864046, 0.11033361717895118, 0.11033361717895118, 0.11033361717895118, 0.1954980305228804, 0.1954980305228804, 0.1954980305228804, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00034566137854141754, 0.00034566137854141754, 0.00034566137854141754, 0.07125920339751812, 0.07125920339751812, 0.07125920339751812, 0.013217580989536293, 0.013217580989536293, 0.013217580989536293, 0.06321198533294481, 0.06321198533294481, 0.06321198533294481, 0.04577114035925678, 0.04577114035925678, 0.04577114035925678, 0.09658798328664941, 0.09658798328664941, 0.09658798328664941, 0.3060874350179851, 0.3060874350179851, 0.3060874350179851, 0.11965104258447845, 0.11965104258447845, 0.11965104258447845, 0.15715051993764828, 0.15715051993764828, 0.15715051993764828, 0.05455780613770189, 0.05455780613770189, 0.05455780613770189, 0.4989962631800221, 0.4989962631800221, 0.4989962631800221, 0.5324640573005008, 0.5324640573005008, 0.5324640573005008, 0.5089231744761383, 0.5089231744761383, 0.5089231744761383, 0.12055497961633865, 0.12055497961633865, 0.12055497961633865, 0.12131075498347332, 0.12131075498347332, 0.12131075498347332, 0.15912061654852583, 0.15912061654852583, 0.15912061654852583, 0.163519528253665, 0.163519528253665, 0.163519528253665, 0.2488630376910912, 0.2488630376910912, 0.2488630376910912, 0.23056888063354297, 0.23056888063354297, 0.23056888063354297, 0.3625324746336922, 0.3625324746336922, 0.3625324746336922, 0.4825599833120394, 0.4825599833120394, 0.4825599833120394, 0.44570137102562635, 0.44570137102562635, 0.44570137102562635, 0.1612314385004684, 0.1612314385004684, 0.1612314385004684, 0.23783887009193627, 0.23783887009193627, 0.23783887009193627, 0.16725183338394456, 0.16725183338394456, 0.16725183338394456, 0.23657817198819187, 0.23657817198819187, 0.23657817198819187, 0.23543645808806857, 0.23543645808806857, 0.23543645808806857, 0.2140369795971364, 0.2140369795971364, 0.2140369795971364, 0.21877366492012384, 0.21877366492012384, 0.21877366492012384, 0.1993422829253344, 0.1993422829253344, 0.1993422829253344, 0.20483442620804448, 0.20483442620804448, 0.20483442620804448, 0.8631868913624167, 0.8631868913624167, 0.8631868913624167, 0.15832846583405713, 0.15832846583405713, 0.15832846583405713, 0.16990480927754392, 0.16990480927754392, 0.16990480927754392, 0.6491616354155003, 0.6491616354155003, 0.6491616354155003, 0.4891365272633964, 0.4891365272633964, 0.4891365272633964, 0.15456589752638905, 0.15456589752638905, 0.15456589752638905, 0.18112036757653027, 0.18112036757653027, 0.18112036757653027, 0.1871099769076684, 0.1871099769076684, 0.1871099769076684, 0.20197314765216834, 0.20197314765216834, 0.20197314765216834, 0.0905837476483009, 0.0905837476483009, 0.0905837476483009, 0.09459420844935684, 0.09459420844935684, 0.09459420844935684, 0.11167047766823957, 0.11167047766823957, 0.11167047766823957]}, "mutation_prompt": null}
{"id": "0aa5f59d-3599-4f6b-b47e-5fba120b7c42", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 60  # Increased swarm size for better exploration\n        self.mutation_factor = 0.85  # Slightly increased mutation for diversity\n        self.crossover_prob = 0.8  # Adjusted crossover probability\n        self.inertia_weight = 0.55  # Adjusted inertia_weight for balance between exploration and exploitation\n        self.cognitive_coeff = 1.5  # Adjusted cognitive_coeff for slightly less personal bias\n        self.social_coeff = 1.4  # Adjusted social_coeff for enhanced global search\n        self.dynamic_adjustment_freq = 8  # More frequent dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.93  # Slightly different dynamic reduction\n                self.mutation_factor = 0.88 if iteration < self.budget // 2 else 0.75  # Adaptive mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with increased swarm size and adaptive parameter tuning for improved convergence speed.", "configspace": "", "generation": 55, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d62eee2b-896b-466d-87bb-32152bf3ec05", "metadata": {"aucs": [0.8065029332555447, 0.8065029332555447, 0.8065029332555447, 0.7879071665328757, 0.7879071665328757, 0.7879071665328757, 0.7934045605658537, 0.7934045605658537, 0.7934045605658537, 0.5778486044918812, 0.5778486044918812, 0.5778486044918812, 0.5646336789062972, 0.5646336789062972, 0.5646336789062972, 0.5771795328509839, 0.5771795328509839, 0.5771795328509839, 0.14567817676423023, 0.14567817676423023, 0.14567817676423023, 0.14158313468323303, 0.14158313468323303, 0.14158313468323303, 0.5770269271125978, 0.5770269271125978, 0.5770269271125978, 0.10988033789413443, 0.10988033789413443, 0.10988033789413443, 0.139681313997993, 0.139681313997993, 0.139681313997993, 0.11886441780606305, 0.11886441780606305, 0.11886441780606305, 0.9748956326735576, 0.9748956326735576, 0.9748956326735576, 0.9788751324089218, 0.9788751324089218, 0.9788751324089218, 0.978872033320122, 0.978872033320122, 0.978872033320122, 0.5613211117875581, 0.5613211117875581, 0.5613211117875581, 0.5503317820573677, 0.5503317820573677, 0.5503317820573677, 0.5767195044027322, 0.5767195044027322, 0.5767195044027322, 0.22180132634763738, 0.22180132634763738, 0.22180132634763738, 0.7986618576666047, 0.7986618576666047, 0.7986618576666047, 0.1768368633291295, 0.1768368633291295, 0.1768368633291295, 0.19441291140773587, 0.19441291140773587, 0.19441291140773587, 0.23866081430005381, 0.23866081430005381, 0.23866081430005381, 0.22332167148102167, 0.22332167148102167, 0.22332167148102167, 0.19217871214864046, 0.19217871214864046, 0.19217871214864046, 0.11033361717895118, 0.11033361717895118, 0.11033361717895118, 0.1954980305228804, 0.1954980305228804, 0.1954980305228804, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00034566137854141754, 0.00034566137854141754, 0.00034566137854141754, 0.07125920339751812, 0.07125920339751812, 0.07125920339751812, 0.013217580989536293, 0.013217580989536293, 0.013217580989536293, 0.06321198533294481, 0.06321198533294481, 0.06321198533294481, 0.04577114035925678, 0.04577114035925678, 0.04577114035925678, 0.09658798328664941, 0.09658798328664941, 0.09658798328664941, 0.3060874350179851, 0.3060874350179851, 0.3060874350179851, 0.11965104258447845, 0.11965104258447845, 0.11965104258447845, 0.15715051993764828, 0.15715051993764828, 0.15715051993764828, 0.05455780613770189, 0.05455780613770189, 0.05455780613770189, 0.4989962631800221, 0.4989962631800221, 0.4989962631800221, 0.5324640573005008, 0.5324640573005008, 0.5324640573005008, 0.5089231744761383, 0.5089231744761383, 0.5089231744761383, 0.12055497961633865, 0.12055497961633865, 0.12055497961633865, 0.12131075498347332, 0.12131075498347332, 0.12131075498347332, 0.15912061654852583, 0.15912061654852583, 0.15912061654852583, 0.163519528253665, 0.163519528253665, 0.163519528253665, 0.2488630376910912, 0.2488630376910912, 0.2488630376910912, 0.23056888063354297, 0.23056888063354297, 0.23056888063354297, 0.3625324746336922, 0.3625324746336922, 0.3625324746336922, 0.4825599833120394, 0.4825599833120394, 0.4825599833120394, 0.44570137102562635, 0.44570137102562635, 0.44570137102562635, 0.1612314385004684, 0.1612314385004684, 0.1612314385004684, 0.23783887009193627, 0.23783887009193627, 0.23783887009193627, 0.16725183338394456, 0.16725183338394456, 0.16725183338394456, 0.23657817198819187, 0.23657817198819187, 0.23657817198819187, 0.23543645808806857, 0.23543645808806857, 0.23543645808806857, 0.2140369795971364, 0.2140369795971364, 0.2140369795971364, 0.21877366492012384, 0.21877366492012384, 0.21877366492012384, 0.1993422829253344, 0.1993422829253344, 0.1993422829253344, 0.20483442620804448, 0.20483442620804448, 0.20483442620804448, 0.8631868913624167, 0.8631868913624167, 0.8631868913624167, 0.15832846583405713, 0.15832846583405713, 0.15832846583405713, 0.16990480927754392, 0.16990480927754392, 0.16990480927754392, 0.6491616354155003, 0.6491616354155003, 0.6491616354155003, 0.4891365272633964, 0.4891365272633964, 0.4891365272633964, 0.15456589752638905, 0.15456589752638905, 0.15456589752638905, 0.18112036757653027, 0.18112036757653027, 0.18112036757653027, 0.1871099769076684, 0.1871099769076684, 0.1871099769076684, 0.20197314765216834, 0.20197314765216834, 0.20197314765216834, 0.0905837476483009, 0.0905837476483009, 0.0905837476483009, 0.09459420844935684, 0.09459420844935684, 0.09459420844935684, 0.11167047766823957, 0.11167047766823957, 0.11167047766823957]}, "mutation_prompt": null}
{"id": "2a3c5a45-6c1e-4bcd-98d3-388be0f6627e", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 60  # Increased swarm size for better exploration\n        self.mutation_factor = 0.85  # Slightly increased mutation for diversity\n        self.crossover_prob = 0.8  # Adjusted crossover probability\n        self.inertia_weight = 0.55  # Adjusted inertia_weight for balance between exploration and exploitation\n        self.cognitive_coeff = 1.5  # Adjusted cognitive_coeff for slightly less personal bias\n        self.social_coeff = 1.4  # Adjusted social_coeff for enhanced global search\n        self.dynamic_adjustment_freq = 8  # More frequent dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.93  # Slightly different dynamic reduction\n                self.mutation_factor = 0.88 if iteration < self.budget // 2 else 0.75  # Adaptive mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with increased swarm size and adaptive parameter tuning for improved convergence speed.", "configspace": "", "generation": 55, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d62eee2b-896b-466d-87bb-32152bf3ec05", "metadata": {"aucs": [0.8065029332555447, 0.8065029332555447, 0.8065029332555447, 0.7879071665328757, 0.7879071665328757, 0.7879071665328757, 0.7934045605658537, 0.7934045605658537, 0.7934045605658537, 0.5778486044918812, 0.5778486044918812, 0.5778486044918812, 0.5646336789062972, 0.5646336789062972, 0.5646336789062972, 0.5771795328509839, 0.5771795328509839, 0.5771795328509839, 0.14567817676423023, 0.14567817676423023, 0.14567817676423023, 0.14158313468323303, 0.14158313468323303, 0.14158313468323303, 0.5770269271125978, 0.5770269271125978, 0.5770269271125978, 0.10988033789413443, 0.10988033789413443, 0.10988033789413443, 0.139681313997993, 0.139681313997993, 0.139681313997993, 0.11886441780606305, 0.11886441780606305, 0.11886441780606305, 0.9748956326735576, 0.9748956326735576, 0.9748956326735576, 0.9788751324089218, 0.9788751324089218, 0.9788751324089218, 0.978872033320122, 0.978872033320122, 0.978872033320122, 0.5613211117875581, 0.5613211117875581, 0.5613211117875581, 0.5503317820573677, 0.5503317820573677, 0.5503317820573677, 0.5767195044027322, 0.5767195044027322, 0.5767195044027322, 0.22180132634763738, 0.22180132634763738, 0.22180132634763738, 0.7986618576666047, 0.7986618576666047, 0.7986618576666047, 0.1768368633291295, 0.1768368633291295, 0.1768368633291295, 0.19441291140773587, 0.19441291140773587, 0.19441291140773587, 0.23866081430005381, 0.23866081430005381, 0.23866081430005381, 0.22332167148102167, 0.22332167148102167, 0.22332167148102167, 0.19217871214864046, 0.19217871214864046, 0.19217871214864046, 0.11033361717895118, 0.11033361717895118, 0.11033361717895118, 0.1954980305228804, 0.1954980305228804, 0.1954980305228804, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00034566137854141754, 0.00034566137854141754, 0.00034566137854141754, 0.07125920339751812, 0.07125920339751812, 0.07125920339751812, 0.013217580989536293, 0.013217580989536293, 0.013217580989536293, 0.06321198533294481, 0.06321198533294481, 0.06321198533294481, 0.04577114035925678, 0.04577114035925678, 0.04577114035925678, 0.09658798328664941, 0.09658798328664941, 0.09658798328664941, 0.3060874350179851, 0.3060874350179851, 0.3060874350179851, 0.11965104258447845, 0.11965104258447845, 0.11965104258447845, 0.15715051993764828, 0.15715051993764828, 0.15715051993764828, 0.05455780613770189, 0.05455780613770189, 0.05455780613770189, 0.4989962631800221, 0.4989962631800221, 0.4989962631800221, 0.5324640573005008, 0.5324640573005008, 0.5324640573005008, 0.5089231744761383, 0.5089231744761383, 0.5089231744761383, 0.12055497961633865, 0.12055497961633865, 0.12055497961633865, 0.12131075498347332, 0.12131075498347332, 0.12131075498347332, 0.15912061654852583, 0.15912061654852583, 0.15912061654852583, 0.163519528253665, 0.163519528253665, 0.163519528253665, 0.2488630376910912, 0.2488630376910912, 0.2488630376910912, 0.23056888063354297, 0.23056888063354297, 0.23056888063354297, 0.3625324746336922, 0.3625324746336922, 0.3625324746336922, 0.4825599833120394, 0.4825599833120394, 0.4825599833120394, 0.44570137102562635, 0.44570137102562635, 0.44570137102562635, 0.1612314385004684, 0.1612314385004684, 0.1612314385004684, 0.23783887009193627, 0.23783887009193627, 0.23783887009193627, 0.16725183338394456, 0.16725183338394456, 0.16725183338394456, 0.23657817198819187, 0.23657817198819187, 0.23657817198819187, 0.23543645808806857, 0.23543645808806857, 0.23543645808806857, 0.2140369795971364, 0.2140369795971364, 0.2140369795971364, 0.21877366492012384, 0.21877366492012384, 0.21877366492012384, 0.1993422829253344, 0.1993422829253344, 0.1993422829253344, 0.20483442620804448, 0.20483442620804448, 0.20483442620804448, 0.8631868913624167, 0.8631868913624167, 0.8631868913624167, 0.15832846583405713, 0.15832846583405713, 0.15832846583405713, 0.16990480927754392, 0.16990480927754392, 0.16990480927754392, 0.6491616354155003, 0.6491616354155003, 0.6491616354155003, 0.4891365272633964, 0.4891365272633964, 0.4891365272633964, 0.15456589752638905, 0.15456589752638905, 0.15456589752638905, 0.18112036757653027, 0.18112036757653027, 0.18112036757653027, 0.1871099769076684, 0.1871099769076684, 0.1871099769076684, 0.20197314765216834, 0.20197314765216834, 0.20197314765216834, 0.0905837476483009, 0.0905837476483009, 0.0905837476483009, 0.09459420844935684, 0.09459420844935684, 0.09459420844935684, 0.11167047766823957, 0.11167047766823957, 0.11167047766823957]}, "mutation_prompt": null}
{"id": "1de82207-16db-463a-af97-c9e0346997a2", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 60  # Increased swarm size for better exploration\n        self.mutation_factor = 0.9  # Slightly increased mutation for diversity\n        self.crossover_prob = 0.85  # Adjusted crossover probability\n        self.inertia_weight = 0.6  # Adjusted inertia_weight for balance between exploration and exploitation\n        self.cognitive_coeff = 1.6  # Adjusted cognitive_coeff for slightly less personal bias\n        self.social_coeff = 1.5  # Adjusted social_coeff for enhanced global search\n        self.dynamic_adjustment_freq = 7  # More frequent dynamic parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.91  # Slightly different dynamic reduction\n                self.mutation_factor = 0.87 if iteration < self.budget // 2 else 0.77  # Adaptive mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with improved adaptive inertia and increased cognitive diversity for faster convergence.", "configspace": "", "generation": 72, "fitness": 0.2948242393653749, "feedback": "The algorithm Enhanced_PSO_ADE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.25.", "error": "", "parent_id": "d62eee2b-896b-466d-87bb-32152bf3ec05", "metadata": {"aucs": [0.7713301696538077, 0.7713301696538077, 0.7713301696538077, 0.7644815639559176, 0.7644815639559176, 0.7644815639559176, 0.7783543716829586, 0.7783543716829586, 0.7783543716829586, 0.5459700026024874, 0.5459700026024874, 0.5459700026024874, 0.5306135755696417, 0.5306135755696417, 0.5306135755696417, 0.5256681376017214, 0.5256681376017214, 0.5256681376017214, 0.15943044297292708, 0.15943044297292708, 0.15943044297292708, 0.15786026199380143, 0.15786026199380143, 0.15786026199380143, 0.1460183086954323, 0.1460183086954323, 0.1460183086954323, 0.1123575243988616, 0.1123575243988616, 0.1123575243988616, 0.10598699063251571, 0.10598699063251571, 0.10598699063251571, 0.12846599091861755, 0.12846599091861755, 0.12846599091861755, 0.9769545728926405, 0.9769545728926405, 0.9769545728926405, 0.9636574971950914, 0.9636574971950914, 0.9636574971950914, 0.9728124339331957, 0.9728124339331957, 0.9728124339331957, 0.48533971498596207, 0.48533971498596207, 0.48533971498596207, 0.48724794361915924, 0.48724794361915924, 0.48724794361915924, 0.47564376942294795, 0.47564376942294795, 0.47564376942294795, 0.6483612390744693, 0.6483612390744693, 0.6483612390744693, 0.7158175752740505, 0.7158175752740505, 0.7158175752740505, 0.21464497954309414, 0.21464497954309414, 0.21464497954309414, 0.19392686432727146, 0.19392686432727146, 0.19392686432727146, 0.180369784207407, 0.180369784207407, 0.180369784207407, 0.19087389308438207, 0.19087389308438207, 0.19087389308438207, 0.021844067680444113, 0.021844067680444113, 0.021844067680444113, 0.18793895686365003, 0.18793895686365003, 0.18793895686365003, 0.17366320250544998, 0.17366320250544998, 0.17366320250544998, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.004237927717762213, 0.004237927717762213, 0.004237927717762213, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03671720267498879, 0.03671720267498879, 0.03671720267498879, 0.03933596936404715, 0.03933596936404715, 0.03933596936404715, 0.040068741570644106, 0.040068741570644106, 0.040068741570644106, 0.04234884129120742, 0.04234884129120742, 0.04234884129120742, 0.18958487688778913, 0.18958487688778913, 0.18958487688778913, 0.16253475818365093, 0.16253475818365093, 0.16253475818365093, 0.183877262651303, 0.183877262651303, 0.183877262651303, 0.10831893085701161, 0.10831893085701161, 0.10831893085701161, 0.062140200698076464, 0.062140200698076464, 0.062140200698076464, 0.4948619616218147, 0.4948619616218147, 0.4948619616218147, 0.5496516927395431, 0.5496516927395431, 0.5496516927395431, 0.5234118411678137, 0.5234118411678137, 0.5234118411678137, 0.12256639228845434, 0.12256639228845434, 0.12256639228845434, 0.13044783019019401, 0.13044783019019401, 0.13044783019019401, 0.08118907959087596, 0.08118907959087596, 0.08118907959087596, 0.2796281429983981, 0.2796281429983981, 0.2796281429983981, 0.14460055611284317, 0.14460055611284317, 0.14460055611284317, 0.2101457107271988, 0.2101457107271988, 0.2101457107271988, 0.39089021556528447, 0.39089021556528447, 0.39089021556528447, 0.38572215735243154, 0.38572215735243154, 0.38572215735243154, 0.32100818074980775, 0.32100818074980775, 0.32100818074980775, 0.19455817774285233, 0.19455817774285233, 0.19455817774285233, 0.2099781069222728, 0.2099781069222728, 0.2099781069222728, 0.14285680173828064, 0.14285680173828064, 0.14285680173828064, 0.18896084829741577, 0.18896084829741577, 0.18896084829741577, 0.19714346399909155, 0.19714346399909155, 0.19714346399909155, 0.2159593405852689, 0.2159593405852689, 0.2159593405852689, 0.2375956708244753, 0.2375956708244753, 0.2375956708244753, 0.24022556829177588, 0.24022556829177588, 0.24022556829177588, 0.7063213734563301, 0.7063213734563301, 0.7063213734563301, 0.8261754125717304, 0.8261754125717304, 0.8261754125717304, 0.1572893801192502, 0.1572893801192502, 0.1572893801192502, 0.1694194625798615, 0.1694194625798615, 0.1694194625798615, 0.38783481499360484, 0.38783481499360484, 0.38783481499360484, 0.20584644247617578, 0.20584644247617578, 0.20584644247617578, 0.15491057783093132, 0.15491057783093132, 0.15491057783093132, 0.1964285898199979, 0.1964285898199979, 0.1964285898199979, 0.19249988524592954, 0.19249988524592954, 0.19249988524592954, 0.18895069151507493, 0.18895069151507493, 0.18895069151507493, 0.08784519444380279, 0.08784519444380279, 0.08784519444380279, 0.09471672346464843, 0.09471672346464843, 0.09471672346464843, 0.11270639909917568, 0.11270639909917568, 0.11270639909917568]}, "mutation_prompt": null}
{"id": "eb54d35b-e19e-4af0-8843-8cead5d59837", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 60\n        self.mutation_factor = 0.85\n        self.crossover_prob = 0.8\n        self.inertia_weight = 0.6  # Modified for improved balance\n        self.cognitive_coeff = 1.7  # Increased for better local search\n        self.social_coeff = 1.6  # Increased for enhanced global search\n        self.dynamic_adjustment_freq = 6  # More frequent adjustments\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.92  # Adjusted dynamic reduction\n                self.mutation_factor = 0.87 if iteration < self.budget // 2 else 0.72  # Adaptive mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * 0.9 * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            velocities = np.clip(velocities, -0.5, 0.5)  # Newly added velocity clipping for stability\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced exploration and exploitation via adaptive cognition and dynamic velocity scaling.", "configspace": "", "generation": 73, "fitness": 0.315052166295587, "feedback": "The algorithm Enhanced_PSO_ADE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.25.", "error": "", "parent_id": "d62eee2b-896b-466d-87bb-32152bf3ec05", "metadata": {"aucs": [0.7806037005125466, 0.7806037005125466, 0.7806037005125466, 0.7505816119826985, 0.7505816119826985, 0.7505816119826985, 0.7633378872054232, 0.7633378872054232, 0.7633378872054232, 0.5370080800385593, 0.5370080800385593, 0.5370080800385593, 0.5189513171681039, 0.5189513171681039, 0.5189513171681039, 0.5506998852525102, 0.5506998852525102, 0.5506998852525102, 0.16982295226058708, 0.16982295226058708, 0.16982295226058708, 0.1457130346119313, 0.1457130346119313, 0.1457130346119313, 0.1392880860995307, 0.1392880860995307, 0.1392880860995307, 0.10877902911458825, 0.10877902911458825, 0.10877902911458825, 0.08674440365567793, 0.08674440365567793, 0.08674440365567793, 0.1297659010011063, 0.1297659010011063, 0.1297659010011063, 0.8372124200650422, 0.8372124200650422, 0.8372124200650422, 0.9055680448791295, 0.9055680448791295, 0.9055680448791295, 0.8666026145978315, 0.8666026145978315, 0.8666026145978315, 0.5331841708951058, 0.5331841708951058, 0.5331841708951058, 0.5461679303813038, 0.5461679303813038, 0.5461679303813038, 0.5195536457095576, 0.5195536457095576, 0.5195536457095576, 0.2184733291829407, 0.2184733291829407, 0.2184733291829407, 0.20824866348361226, 0.20824866348361226, 0.20824866348361226, 0.2309053429801856, 0.2309053429801856, 0.2309053429801856, 0.1251653318752205, 0.1251653318752205, 0.1251653318752205, 0.22704900909967007, 0.22704900909967007, 0.22704900909967007, 0.11781433976503652, 0.11781433976503652, 0.11781433976503652, 0.21100068538103955, 0.21100068538103955, 0.21100068538103955, 0.21261363695091207, 0.21261363695091207, 0.21261363695091207, 0.23101571584830094, 0.23101571584830094, 0.23101571584830094, 0.09284748077203475, 0.09284748077203475, 0.09284748077203475, 0.027021783539842414, 0.027021783539842414, 0.027021783539842414, 0.005395024241547586, 0.005395024241547586, 0.005395024241547586, 0.11067385860183876, 0.11067385860183876, 0.11067385860183876, 0.048197261334110175, 0.048197261334110175, 0.048197261334110175, 0.14582204613146788, 0.14582204613146788, 0.14582204613146788, 0.08681982563736879, 0.08681982563736879, 0.08681982563736879, 0.06573853126052631, 0.06573853126052631, 0.06573853126052631, 0.07771026958936311, 0.07771026958936311, 0.07771026958936311, 0.11788309766652949, 0.11788309766652949, 0.11788309766652949, 0.23737054271200275, 0.23737054271200275, 0.23737054271200275, 0.13902252726356634, 0.13902252726356634, 0.13902252726356634, 0.5312071216638617, 0.5312071216638617, 0.5312071216638617, 0.5466775494176652, 0.5466775494176652, 0.5466775494176652, 0.5020228579681516, 0.5020228579681516, 0.5020228579681516, 0.07998833451464638, 0.07998833451464638, 0.07998833451464638, 0.07814783831944261, 0.07814783831944261, 0.07814783831944261, 0.12711716378292748, 0.12711716378292748, 0.12711716378292748, 0.26580221473739907, 0.26580221473739907, 0.26580221473739907, 0.17574831510837374, 0.17574831510837374, 0.17574831510837374, 0.23657326216880126, 0.23657326216880126, 0.23657326216880126, 0.36594406459018913, 0.36594406459018913, 0.36594406459018913, 0.38442990249231057, 0.38442990249231057, 0.38442990249231057, 0.27064689790163243, 0.27064689790163243, 0.27064689790163243, 0.23227149116217927, 0.23227149116217927, 0.23227149116217927, 0.1888083001177321, 0.1888083001177321, 0.1888083001177321, 0.20784974757845986, 0.20784974757845986, 0.20784974757845986, 0.21848875931255418, 0.21848875931255418, 0.21848875931255418, 0.23707707899836483, 0.23707707899836483, 0.23707707899836483, 0.23557838487715488, 0.23557838487715488, 0.23557838487715488, 0.24720867371385435, 0.24720867371385435, 0.24720867371385435, 0.17563130094899448, 0.17563130094899448, 0.17563130094899448, 0.6353349189826808, 0.6353349189826808, 0.6353349189826808, 0.8350026493746141, 0.8350026493746141, 0.8350026493746141, 0.8427870366563281, 0.8427870366563281, 0.8427870366563281, 0.7898416604262448, 0.7898416604262448, 0.7898416604262448, 0.720680269507624, 0.720680269507624, 0.720680269507624, 0.20728025891266333, 0.20728025891266333, 0.20728025891266333, 0.6229117097113855, 0.6229117097113855, 0.6229117097113855, 0.20341001586372098, 0.20341001586372098, 0.20341001586372098, 0.2059064029568164, 0.2059064029568164, 0.2059064029568164, 0.18088667542278347, 0.18088667542278347, 0.18088667542278347, 0.09112421688121453, 0.09112421688121453, 0.09112421688121453, 0.11284339359557016, 0.11284339359557016, 0.11284339359557016, 0.10215448686757123, 0.10215448686757123, 0.10215448686757123]}, "mutation_prompt": null}
{"id": "224a5482-2fa4-4960-a595-965783a72d10", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer_V2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 65  # Increased swarm size for diversity\n        self.mutation_factor = 0.9  # Slightly increased for exploration\n        self.crossover_prob = 0.85  # Increased to encourage exploration\n        self.inertia_weight = 0.5  # Reduced weight for faster convergence\n        self.cognitive_coeff = 1.8  # Adjusted for adaptive learning\n        self.social_coeff = 1.5  # Slightly decreased for controlled exploration\n        self.dynamic_adjustment_freq = 5  # More frequent adaptation\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.9  # Slightly faster reduction\n                self.mutation_factor = 0.9 if iteration < self.budget // 3 else 0.75  # Modified adaptability\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            velocities = np.clip(velocities, -0.6, 0.6)  # Adjusted clipping\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer_V2", "description": "Optimize convergence through enhanced diversity and adaptive learning rates.", "configspace": "", "generation": 74, "fitness": 0.30259556860959436, "feedback": "The algorithm Enhanced_PSO_ADE_Optimizer_V2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.24.", "error": "", "parent_id": "eb54d35b-e19e-4af0-8843-8cead5d59837", "metadata": {"aucs": [0.7947727931756008, 0.7947727931756008, 0.7947727931756008, 0.7578293191479948, 0.7578293191479948, 0.7578293191479948, 0.7825765628864824, 0.7825765628864824, 0.7825765628864824, 0.5737262766506727, 0.5737262766506727, 0.5737262766506727, 0.5769274684547898, 0.5769274684547898, 0.5769274684547898, 0.5672364737248448, 0.5672364737248448, 0.5672364737248448, 0.16219999269780783, 0.16219999269780783, 0.16219999269780783, 0.1353642246007295, 0.1353642246007295, 0.1353642246007295, 0.1494522254406625, 0.1494522254406625, 0.1494522254406625, 0.12907951651801308, 0.12907951651801308, 0.12907951651801308, 0.11321462152262063, 0.11321462152262063, 0.11321462152262063, 0.13725159162962264, 0.13725159162962264, 0.13725159162962264, 0.8372579964194808, 0.8372579964194808, 0.8372579964194808, 0.8012210961093713, 0.8012210961093713, 0.8012210961093713, 0.8117520017146413, 0.8117520017146413, 0.8117520017146413, 0.5019398001330808, 0.5019398001330808, 0.5019398001330808, 0.5136545351033233, 0.5136545351033233, 0.5136545351033233, 0.550663179701135, 0.550663179701135, 0.550663179701135, 0.8194158089128232, 0.8194158089128232, 0.8194158089128232, 0.20354685423715702, 0.20354685423715702, 0.20354685423715702, 0.2193243340978862, 0.2193243340978862, 0.2193243340978862, 0.12841587191499837, 0.12841587191499837, 0.12841587191499837, 0.12901811635447136, 0.12901811635447136, 0.12901811635447136, 0.1816541122253419, 0.1816541122253419, 0.1816541122253419, 0.1911316377911939, 0.1911316377911939, 0.1911316377911939, 0.11810756313409221, 0.11810756313409221, 0.11810756313409221, 0.1845944688670016, 0.1845944688670016, 0.1845944688670016, 0.1698237031327341, 0.1698237031327341, 0.1698237031327341, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.041902110450913965, 0.041902110450913965, 0.041902110450913965, 0.1167295919612481, 0.1167295919612481, 0.1167295919612481, 0.05634347239202364, 0.05634347239202364, 0.05634347239202364, 0.14121955549205578, 0.14121955549205578, 0.14121955549205578, 0.09402246289816796, 0.09402246289816796, 0.09402246289816796, 0.07855213738458533, 0.07855213738458533, 0.07855213738458533, 0.0660389324268621, 0.0660389324268621, 0.0660389324268621, 0.1421910130858265, 0.1421910130858265, 0.1421910130858265, 0.09688447381838616, 0.09688447381838616, 0.09688447381838616, 0.20643589083575076, 0.20643589083575076, 0.20643589083575076, 0.4940338028509549, 0.4940338028509549, 0.4940338028509549, 0.5232077142904996, 0.5232077142904996, 0.5232077142904996, 0.5537058103668829, 0.5537058103668829, 0.5537058103668829, 0.09916096721420686, 0.09916096721420686, 0.09916096721420686, 0.1302143131012048, 0.1302143131012048, 0.1302143131012048, 0.10593525732947551, 0.10593525732947551, 0.10593525732947551, 0.16382250097315465, 0.16382250097315465, 0.16382250097315465, 0.17416609519110138, 0.17416609519110138, 0.17416609519110138, 0.1467537637804056, 0.1467537637804056, 0.1467537637804056, 0.3448272022758029, 0.3448272022758029, 0.3448272022758029, 0.4524803809067339, 0.4524803809067339, 0.4524803809067339, 0.2521447312958349, 0.2521447312958349, 0.2521447312958349, 0.2778825771897089, 0.2778825771897089, 0.2778825771897089, 0.2523619458438586, 0.2523619458438586, 0.2523619458438586, 0.1944249102685529, 0.1944249102685529, 0.1944249102685529, 0.2134659809881171, 0.2134659809881171, 0.2134659809881171, 0.23548846319723793, 0.23548846319723793, 0.23548846319723793, 0.22524167554775354, 0.22524167554775354, 0.22524167554775354, 0.20222361243905407, 0.20222361243905407, 0.20222361243905407, 0.1765424375788307, 0.1765424375788307, 0.1765424375788307, 0.22678028172808873, 0.22678028172808873, 0.22678028172808873, 0.8476428857466436, 0.8476428857466436, 0.8476428857466436, 0.1966411973893475, 0.1966411973893475, 0.1966411973893475, 0.8239824295902675, 0.8239824295902675, 0.8239824295902675, 0.6124156235706969, 0.6124156235706969, 0.6124156235706969, 0.16883905323489057, 0.16883905323489057, 0.16883905323489057, 0.5491679185212048, 0.5491679185212048, 0.5491679185212048, 0.19050951570224084, 0.19050951570224084, 0.19050951570224084, 0.18774625562799874, 0.18774625562799874, 0.18774625562799874, 0.18219520628368868, 0.18219520628368868, 0.18219520628368868, 0.08166349142875373, 0.08166349142875373, 0.08166349142875373, 0.08761121019472629, 0.08761121019472629, 0.08761121019472629, 0.13202994119848077, 0.13202994119848077, 0.13202994119848077]}, "mutation_prompt": null}
{"id": "fc426c6c-bfe2-4ff3-b6be-80693d1152c3", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 60\n        self.mutation_factor = 0.85\n        self.crossover_prob = 0.8\n        self.inertia_weight = 0.6  # Modified for improved balance\n        self.cognitive_coeff = 1.7  # Increased for better local search\n        self.social_coeff = 1.6  # Increased for enhanced global search\n        self.dynamic_adjustment_freq = 6  # More frequent adjustments\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.92  # Adjusted dynamic reduction\n                self.mutation_factor = 0.87 if iteration < self.budget // 2 else 0.72  # Adaptive mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * 0.9 * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            velocities = np.clip(velocities, -0.5, 0.5)  # Newly added velocity clipping for stability\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced exploration and exploitation via adaptive cognition and dynamic velocity scaling.", "configspace": "", "generation": 74, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "eb54d35b-e19e-4af0-8843-8cead5d59837", "metadata": {"aucs": [0.7806037005125466, 0.7806037005125466, 0.7806037005125466, 0.7505816119826985, 0.7505816119826985, 0.7505816119826985, 0.7633378872054232, 0.7633378872054232, 0.7633378872054232, 0.5370080800385593, 0.5370080800385593, 0.5370080800385593, 0.5189513171681039, 0.5189513171681039, 0.5189513171681039, 0.5506998852525102, 0.5506998852525102, 0.5506998852525102, 0.16982295226058708, 0.16982295226058708, 0.16982295226058708, 0.1457130346119313, 0.1457130346119313, 0.1457130346119313, 0.1392880860995307, 0.1392880860995307, 0.1392880860995307, 0.10877902911458825, 0.10877902911458825, 0.10877902911458825, 0.08674440365567793, 0.08674440365567793, 0.08674440365567793, 0.1297659010011063, 0.1297659010011063, 0.1297659010011063, 0.8372124200650422, 0.8372124200650422, 0.8372124200650422, 0.9055680448791295, 0.9055680448791295, 0.9055680448791295, 0.8666026145978315, 0.8666026145978315, 0.8666026145978315, 0.5331841708951058, 0.5331841708951058, 0.5331841708951058, 0.5461679303813038, 0.5461679303813038, 0.5461679303813038, 0.5195536457095576, 0.5195536457095576, 0.5195536457095576, 0.2184733291829407, 0.2184733291829407, 0.2184733291829407, 0.20824866348361226, 0.20824866348361226, 0.20824866348361226, 0.2309053429801856, 0.2309053429801856, 0.2309053429801856, 0.1251653318752205, 0.1251653318752205, 0.1251653318752205, 0.22704900909967007, 0.22704900909967007, 0.22704900909967007, 0.11781433976503652, 0.11781433976503652, 0.11781433976503652, 0.21100068538103955, 0.21100068538103955, 0.21100068538103955, 0.21261363695091207, 0.21261363695091207, 0.21261363695091207, 0.23101571584830094, 0.23101571584830094, 0.23101571584830094, 0.09284748077203475, 0.09284748077203475, 0.09284748077203475, 0.027021783539842414, 0.027021783539842414, 0.027021783539842414, 0.005395024241547586, 0.005395024241547586, 0.005395024241547586, 0.11067385860183876, 0.11067385860183876, 0.11067385860183876, 0.048197261334110175, 0.048197261334110175, 0.048197261334110175, 0.14582204613146788, 0.14582204613146788, 0.14582204613146788, 0.08681982563736879, 0.08681982563736879, 0.08681982563736879, 0.06573853126052631, 0.06573853126052631, 0.06573853126052631, 0.07771026958936311, 0.07771026958936311, 0.07771026958936311, 0.11788309766652949, 0.11788309766652949, 0.11788309766652949, 0.23737054271200275, 0.23737054271200275, 0.23737054271200275, 0.13902252726356634, 0.13902252726356634, 0.13902252726356634, 0.5312071216638617, 0.5312071216638617, 0.5312071216638617, 0.5466775494176652, 0.5466775494176652, 0.5466775494176652, 0.5020228579681516, 0.5020228579681516, 0.5020228579681516, 0.07998833451464638, 0.07998833451464638, 0.07998833451464638, 0.07814783831944261, 0.07814783831944261, 0.07814783831944261, 0.12711716378292748, 0.12711716378292748, 0.12711716378292748, 0.26580221473739907, 0.26580221473739907, 0.26580221473739907, 0.17574831510837374, 0.17574831510837374, 0.17574831510837374, 0.23657326216880126, 0.23657326216880126, 0.23657326216880126, 0.36594406459018913, 0.36594406459018913, 0.36594406459018913, 0.38442990249231057, 0.38442990249231057, 0.38442990249231057, 0.27064689790163243, 0.27064689790163243, 0.27064689790163243, 0.23227149116217927, 0.23227149116217927, 0.23227149116217927, 0.1888083001177321, 0.1888083001177321, 0.1888083001177321, 0.20784974757845986, 0.20784974757845986, 0.20784974757845986, 0.21848875931255418, 0.21848875931255418, 0.21848875931255418, 0.23707707899836483, 0.23707707899836483, 0.23707707899836483, 0.23557838487715488, 0.23557838487715488, 0.23557838487715488, 0.24720867371385435, 0.24720867371385435, 0.24720867371385435, 0.17563130094899448, 0.17563130094899448, 0.17563130094899448, 0.6353349189826808, 0.6353349189826808, 0.6353349189826808, 0.8350026493746141, 0.8350026493746141, 0.8350026493746141, 0.8427870366563281, 0.8427870366563281, 0.8427870366563281, 0.7898416604262448, 0.7898416604262448, 0.7898416604262448, 0.720680269507624, 0.720680269507624, 0.720680269507624, 0.20728025891266333, 0.20728025891266333, 0.20728025891266333, 0.6229117097113855, 0.6229117097113855, 0.6229117097113855, 0.20341001586372098, 0.20341001586372098, 0.20341001586372098, 0.2059064029568164, 0.2059064029568164, 0.2059064029568164, 0.18088667542278347, 0.18088667542278347, 0.18088667542278347, 0.09112421688121453, 0.09112421688121453, 0.09112421688121453, 0.11284339359557016, 0.11284339359557016, 0.11284339359557016, 0.10215448686757123, 0.10215448686757123, 0.10215448686757123]}, "mutation_prompt": null}
{"id": "e5d0b8e1-fbfd-4b69-be0c-a733c890dd28", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 60\n        self.mutation_factor = 0.85\n        self.crossover_prob = 0.8\n        self.inertia_weight = 0.6  # Modified for improved balance\n        self.cognitive_coeff = 1.7  # Increased for better local search\n        self.social_coeff = 1.6  # Increased for enhanced global search\n        self.dynamic_adjustment_freq = 6  # More frequent adjustments\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.92  # Adjusted dynamic reduction\n                self.mutation_factor = 0.87 if iteration < self.budget // 2 else 0.72  # Adaptive mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * 0.9 * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            velocities = np.clip(velocities, -0.5, 0.5)  # Newly added velocity clipping for stability\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced exploration and exploitation via adaptive cognition and dynamic velocity scaling.", "configspace": "", "generation": 74, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "eb54d35b-e19e-4af0-8843-8cead5d59837", "metadata": {"aucs": [0.7806037005125466, 0.7806037005125466, 0.7806037005125466, 0.7505816119826985, 0.7505816119826985, 0.7505816119826985, 0.7633378872054232, 0.7633378872054232, 0.7633378872054232, 0.5370080800385593, 0.5370080800385593, 0.5370080800385593, 0.5189513171681039, 0.5189513171681039, 0.5189513171681039, 0.5506998852525102, 0.5506998852525102, 0.5506998852525102, 0.16982295226058708, 0.16982295226058708, 0.16982295226058708, 0.1457130346119313, 0.1457130346119313, 0.1457130346119313, 0.1392880860995307, 0.1392880860995307, 0.1392880860995307, 0.10877902911458825, 0.10877902911458825, 0.10877902911458825, 0.08674440365567793, 0.08674440365567793, 0.08674440365567793, 0.1297659010011063, 0.1297659010011063, 0.1297659010011063, 0.8372124200650422, 0.8372124200650422, 0.8372124200650422, 0.9055680448791295, 0.9055680448791295, 0.9055680448791295, 0.8666026145978315, 0.8666026145978315, 0.8666026145978315, 0.5331841708951058, 0.5331841708951058, 0.5331841708951058, 0.5461679303813038, 0.5461679303813038, 0.5461679303813038, 0.5195536457095576, 0.5195536457095576, 0.5195536457095576, 0.2184733291829407, 0.2184733291829407, 0.2184733291829407, 0.20824866348361226, 0.20824866348361226, 0.20824866348361226, 0.2309053429801856, 0.2309053429801856, 0.2309053429801856, 0.1251653318752205, 0.1251653318752205, 0.1251653318752205, 0.22704900909967007, 0.22704900909967007, 0.22704900909967007, 0.11781433976503652, 0.11781433976503652, 0.11781433976503652, 0.21100068538103955, 0.21100068538103955, 0.21100068538103955, 0.21261363695091207, 0.21261363695091207, 0.21261363695091207, 0.23101571584830094, 0.23101571584830094, 0.23101571584830094, 0.09284748077203475, 0.09284748077203475, 0.09284748077203475, 0.027021783539842414, 0.027021783539842414, 0.027021783539842414, 0.005395024241547586, 0.005395024241547586, 0.005395024241547586, 0.11067385860183876, 0.11067385860183876, 0.11067385860183876, 0.048197261334110175, 0.048197261334110175, 0.048197261334110175, 0.14582204613146788, 0.14582204613146788, 0.14582204613146788, 0.08681982563736879, 0.08681982563736879, 0.08681982563736879, 0.06573853126052631, 0.06573853126052631, 0.06573853126052631, 0.07771026958936311, 0.07771026958936311, 0.07771026958936311, 0.11788309766652949, 0.11788309766652949, 0.11788309766652949, 0.23737054271200275, 0.23737054271200275, 0.23737054271200275, 0.13902252726356634, 0.13902252726356634, 0.13902252726356634, 0.5312071216638617, 0.5312071216638617, 0.5312071216638617, 0.5466775494176652, 0.5466775494176652, 0.5466775494176652, 0.5020228579681516, 0.5020228579681516, 0.5020228579681516, 0.07998833451464638, 0.07998833451464638, 0.07998833451464638, 0.07814783831944261, 0.07814783831944261, 0.07814783831944261, 0.12711716378292748, 0.12711716378292748, 0.12711716378292748, 0.26580221473739907, 0.26580221473739907, 0.26580221473739907, 0.17574831510837374, 0.17574831510837374, 0.17574831510837374, 0.23657326216880126, 0.23657326216880126, 0.23657326216880126, 0.36594406459018913, 0.36594406459018913, 0.36594406459018913, 0.38442990249231057, 0.38442990249231057, 0.38442990249231057, 0.27064689790163243, 0.27064689790163243, 0.27064689790163243, 0.23227149116217927, 0.23227149116217927, 0.23227149116217927, 0.1888083001177321, 0.1888083001177321, 0.1888083001177321, 0.20784974757845986, 0.20784974757845986, 0.20784974757845986, 0.21848875931255418, 0.21848875931255418, 0.21848875931255418, 0.23707707899836483, 0.23707707899836483, 0.23707707899836483, 0.23557838487715488, 0.23557838487715488, 0.23557838487715488, 0.24720867371385435, 0.24720867371385435, 0.24720867371385435, 0.17563130094899448, 0.17563130094899448, 0.17563130094899448, 0.6353349189826808, 0.6353349189826808, 0.6353349189826808, 0.8350026493746141, 0.8350026493746141, 0.8350026493746141, 0.8427870366563281, 0.8427870366563281, 0.8427870366563281, 0.7898416604262448, 0.7898416604262448, 0.7898416604262448, 0.720680269507624, 0.720680269507624, 0.720680269507624, 0.20728025891266333, 0.20728025891266333, 0.20728025891266333, 0.6229117097113855, 0.6229117097113855, 0.6229117097113855, 0.20341001586372098, 0.20341001586372098, 0.20341001586372098, 0.2059064029568164, 0.2059064029568164, 0.2059064029568164, 0.18088667542278347, 0.18088667542278347, 0.18088667542278347, 0.09112421688121453, 0.09112421688121453, 0.09112421688121453, 0.11284339359557016, 0.11284339359557016, 0.11284339359557016, 0.10215448686757123, 0.10215448686757123, 0.10215448686757123]}, "mutation_prompt": null}
{"id": "f3d42f66-153b-4403-8721-e06426099a4e", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 60\n        self.mutation_factor = 0.85\n        self.crossover_prob = 0.8\n        self.inertia_weight = 0.6  # Modified for improved balance\n        self.cognitive_coeff = 1.7  # Increased for better local search\n        self.social_coeff = 1.6  # Increased for enhanced global search\n        self.dynamic_adjustment_freq = 6  # More frequent adjustments\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.92  # Adjusted dynamic reduction\n                self.mutation_factor = 0.87 if iteration < self.budget // 2 else 0.72  # Adaptive mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * 0.9 * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            velocities = np.clip(velocities, -0.5, 0.5)  # Newly added velocity clipping for stability\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced exploration and exploitation via adaptive cognition and dynamic velocity scaling.", "configspace": "", "generation": 74, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "eb54d35b-e19e-4af0-8843-8cead5d59837", "metadata": {"aucs": [0.7806037005125466, 0.7806037005125466, 0.7806037005125466, 0.7505816119826985, 0.7505816119826985, 0.7505816119826985, 0.7633378872054232, 0.7633378872054232, 0.7633378872054232, 0.5370080800385593, 0.5370080800385593, 0.5370080800385593, 0.5189513171681039, 0.5189513171681039, 0.5189513171681039, 0.5506998852525102, 0.5506998852525102, 0.5506998852525102, 0.16982295226058708, 0.16982295226058708, 0.16982295226058708, 0.1457130346119313, 0.1457130346119313, 0.1457130346119313, 0.1392880860995307, 0.1392880860995307, 0.1392880860995307, 0.10877902911458825, 0.10877902911458825, 0.10877902911458825, 0.08674440365567793, 0.08674440365567793, 0.08674440365567793, 0.1297659010011063, 0.1297659010011063, 0.1297659010011063, 0.8372124200650422, 0.8372124200650422, 0.8372124200650422, 0.9055680448791295, 0.9055680448791295, 0.9055680448791295, 0.8666026145978315, 0.8666026145978315, 0.8666026145978315, 0.5331841708951058, 0.5331841708951058, 0.5331841708951058, 0.5461679303813038, 0.5461679303813038, 0.5461679303813038, 0.5195536457095576, 0.5195536457095576, 0.5195536457095576, 0.2184733291829407, 0.2184733291829407, 0.2184733291829407, 0.20824866348361226, 0.20824866348361226, 0.20824866348361226, 0.2309053429801856, 0.2309053429801856, 0.2309053429801856, 0.1251653318752205, 0.1251653318752205, 0.1251653318752205, 0.22704900909967007, 0.22704900909967007, 0.22704900909967007, 0.11781433976503652, 0.11781433976503652, 0.11781433976503652, 0.21100068538103955, 0.21100068538103955, 0.21100068538103955, 0.21261363695091207, 0.21261363695091207, 0.21261363695091207, 0.23101571584830094, 0.23101571584830094, 0.23101571584830094, 0.09284748077203475, 0.09284748077203475, 0.09284748077203475, 0.027021783539842414, 0.027021783539842414, 0.027021783539842414, 0.005395024241547586, 0.005395024241547586, 0.005395024241547586, 0.11067385860183876, 0.11067385860183876, 0.11067385860183876, 0.048197261334110175, 0.048197261334110175, 0.048197261334110175, 0.14582204613146788, 0.14582204613146788, 0.14582204613146788, 0.08681982563736879, 0.08681982563736879, 0.08681982563736879, 0.06573853126052631, 0.06573853126052631, 0.06573853126052631, 0.07771026958936311, 0.07771026958936311, 0.07771026958936311, 0.11788309766652949, 0.11788309766652949, 0.11788309766652949, 0.23737054271200275, 0.23737054271200275, 0.23737054271200275, 0.13902252726356634, 0.13902252726356634, 0.13902252726356634, 0.5312071216638617, 0.5312071216638617, 0.5312071216638617, 0.5466775494176652, 0.5466775494176652, 0.5466775494176652, 0.5020228579681516, 0.5020228579681516, 0.5020228579681516, 0.07998833451464638, 0.07998833451464638, 0.07998833451464638, 0.07814783831944261, 0.07814783831944261, 0.07814783831944261, 0.12711716378292748, 0.12711716378292748, 0.12711716378292748, 0.26580221473739907, 0.26580221473739907, 0.26580221473739907, 0.17574831510837374, 0.17574831510837374, 0.17574831510837374, 0.23657326216880126, 0.23657326216880126, 0.23657326216880126, 0.36594406459018913, 0.36594406459018913, 0.36594406459018913, 0.38442990249231057, 0.38442990249231057, 0.38442990249231057, 0.27064689790163243, 0.27064689790163243, 0.27064689790163243, 0.23227149116217927, 0.23227149116217927, 0.23227149116217927, 0.1888083001177321, 0.1888083001177321, 0.1888083001177321, 0.20784974757845986, 0.20784974757845986, 0.20784974757845986, 0.21848875931255418, 0.21848875931255418, 0.21848875931255418, 0.23707707899836483, 0.23707707899836483, 0.23707707899836483, 0.23557838487715488, 0.23557838487715488, 0.23557838487715488, 0.24720867371385435, 0.24720867371385435, 0.24720867371385435, 0.17563130094899448, 0.17563130094899448, 0.17563130094899448, 0.6353349189826808, 0.6353349189826808, 0.6353349189826808, 0.8350026493746141, 0.8350026493746141, 0.8350026493746141, 0.8427870366563281, 0.8427870366563281, 0.8427870366563281, 0.7898416604262448, 0.7898416604262448, 0.7898416604262448, 0.720680269507624, 0.720680269507624, 0.720680269507624, 0.20728025891266333, 0.20728025891266333, 0.20728025891266333, 0.6229117097113855, 0.6229117097113855, 0.6229117097113855, 0.20341001586372098, 0.20341001586372098, 0.20341001586372098, 0.2059064029568164, 0.2059064029568164, 0.2059064029568164, 0.18088667542278347, 0.18088667542278347, 0.18088667542278347, 0.09112421688121453, 0.09112421688121453, 0.09112421688121453, 0.11284339359557016, 0.11284339359557016, 0.11284339359557016, 0.10215448686757123, 0.10215448686757123, 0.10215448686757123]}, "mutation_prompt": null}
{"id": "fa35801e-9baf-470d-a6b9-5851b73c1db0", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 60\n        self.mutation_factor = 0.85\n        self.crossover_prob = 0.8\n        self.inertia_weight = 0.6  # Modified for improved balance\n        self.cognitive_coeff = 1.7  # Increased for better local search\n        self.social_coeff = 1.6  # Increased for enhanced global search\n        self.dynamic_adjustment_freq = 6  # More frequent adjustments\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.92  # Adjusted dynamic reduction\n                self.mutation_factor = 0.87 if iteration < self.budget // 2 else 0.72  # Adaptive mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * 0.9 * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            velocities = np.clip(velocities, -0.5, 0.5)  # Newly added velocity clipping for stability\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced exploration and exploitation via adaptive cognition and dynamic velocity scaling.", "configspace": "", "generation": 74, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "eb54d35b-e19e-4af0-8843-8cead5d59837", "metadata": {"aucs": [0.7806037005125466, 0.7806037005125466, 0.7806037005125466, 0.7505816119826985, 0.7505816119826985, 0.7505816119826985, 0.7633378872054232, 0.7633378872054232, 0.7633378872054232, 0.5370080800385593, 0.5370080800385593, 0.5370080800385593, 0.5189513171681039, 0.5189513171681039, 0.5189513171681039, 0.5506998852525102, 0.5506998852525102, 0.5506998852525102, 0.16982295226058708, 0.16982295226058708, 0.16982295226058708, 0.1457130346119313, 0.1457130346119313, 0.1457130346119313, 0.1392880860995307, 0.1392880860995307, 0.1392880860995307, 0.10877902911458825, 0.10877902911458825, 0.10877902911458825, 0.08674440365567793, 0.08674440365567793, 0.08674440365567793, 0.1297659010011063, 0.1297659010011063, 0.1297659010011063, 0.8372124200650422, 0.8372124200650422, 0.8372124200650422, 0.9055680448791295, 0.9055680448791295, 0.9055680448791295, 0.8666026145978315, 0.8666026145978315, 0.8666026145978315, 0.5331841708951058, 0.5331841708951058, 0.5331841708951058, 0.5461679303813038, 0.5461679303813038, 0.5461679303813038, 0.5195536457095576, 0.5195536457095576, 0.5195536457095576, 0.2184733291829407, 0.2184733291829407, 0.2184733291829407, 0.20824866348361226, 0.20824866348361226, 0.20824866348361226, 0.2309053429801856, 0.2309053429801856, 0.2309053429801856, 0.1251653318752205, 0.1251653318752205, 0.1251653318752205, 0.22704900909967007, 0.22704900909967007, 0.22704900909967007, 0.11781433976503652, 0.11781433976503652, 0.11781433976503652, 0.21100068538103955, 0.21100068538103955, 0.21100068538103955, 0.21261363695091207, 0.21261363695091207, 0.21261363695091207, 0.23101571584830094, 0.23101571584830094, 0.23101571584830094, 0.09284748077203475, 0.09284748077203475, 0.09284748077203475, 0.027021783539842414, 0.027021783539842414, 0.027021783539842414, 0.005395024241547586, 0.005395024241547586, 0.005395024241547586, 0.11067385860183876, 0.11067385860183876, 0.11067385860183876, 0.048197261334110175, 0.048197261334110175, 0.048197261334110175, 0.14582204613146788, 0.14582204613146788, 0.14582204613146788, 0.08681982563736879, 0.08681982563736879, 0.08681982563736879, 0.06573853126052631, 0.06573853126052631, 0.06573853126052631, 0.07771026958936311, 0.07771026958936311, 0.07771026958936311, 0.11788309766652949, 0.11788309766652949, 0.11788309766652949, 0.23737054271200275, 0.23737054271200275, 0.23737054271200275, 0.13902252726356634, 0.13902252726356634, 0.13902252726356634, 0.5312071216638617, 0.5312071216638617, 0.5312071216638617, 0.5466775494176652, 0.5466775494176652, 0.5466775494176652, 0.5020228579681516, 0.5020228579681516, 0.5020228579681516, 0.07998833451464638, 0.07998833451464638, 0.07998833451464638, 0.07814783831944261, 0.07814783831944261, 0.07814783831944261, 0.12711716378292748, 0.12711716378292748, 0.12711716378292748, 0.26580221473739907, 0.26580221473739907, 0.26580221473739907, 0.17574831510837374, 0.17574831510837374, 0.17574831510837374, 0.23657326216880126, 0.23657326216880126, 0.23657326216880126, 0.36594406459018913, 0.36594406459018913, 0.36594406459018913, 0.38442990249231057, 0.38442990249231057, 0.38442990249231057, 0.27064689790163243, 0.27064689790163243, 0.27064689790163243, 0.23227149116217927, 0.23227149116217927, 0.23227149116217927, 0.1888083001177321, 0.1888083001177321, 0.1888083001177321, 0.20784974757845986, 0.20784974757845986, 0.20784974757845986, 0.21848875931255418, 0.21848875931255418, 0.21848875931255418, 0.23707707899836483, 0.23707707899836483, 0.23707707899836483, 0.23557838487715488, 0.23557838487715488, 0.23557838487715488, 0.24720867371385435, 0.24720867371385435, 0.24720867371385435, 0.17563130094899448, 0.17563130094899448, 0.17563130094899448, 0.6353349189826808, 0.6353349189826808, 0.6353349189826808, 0.8350026493746141, 0.8350026493746141, 0.8350026493746141, 0.8427870366563281, 0.8427870366563281, 0.8427870366563281, 0.7898416604262448, 0.7898416604262448, 0.7898416604262448, 0.720680269507624, 0.720680269507624, 0.720680269507624, 0.20728025891266333, 0.20728025891266333, 0.20728025891266333, 0.6229117097113855, 0.6229117097113855, 0.6229117097113855, 0.20341001586372098, 0.20341001586372098, 0.20341001586372098, 0.2059064029568164, 0.2059064029568164, 0.2059064029568164, 0.18088667542278347, 0.18088667542278347, 0.18088667542278347, 0.09112421688121453, 0.09112421688121453, 0.09112421688121453, 0.11284339359557016, 0.11284339359557016, 0.11284339359557016, 0.10215448686757123, 0.10215448686757123, 0.10215448686757123]}, "mutation_prompt": null}
{"id": "f17bcdc9-c2a1-46e4-bc19-35fa44b0d8ed", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 60\n        self.mutation_factor = 0.9  # Slightly increased for more diversity\n        self.crossover_prob = 0.75  # Slightly decreased to promote exploration\n        self.inertia_weight = 0.7  # Increased for better exploration\n        self.cognitive_coeff = 1.5  # Decreased for broader search\n        self.social_coeff = 1.8  # Increased for stronger convergence\n        self.dynamic_adjustment_freq = 5  # Frequent adjustments\n        self.adaptive_lr = 0.95  # New adaptive learning rate factor\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= self.adaptive_lr\n                self.mutation_factor = 0.9 if iteration < self.budget // 3 else 0.75\n                if iteration % (self.dynamic_adjustment_freq * 2) == 0:\n                    # Periodically reseed positions for missed global optima\n                    positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            velocities = np.clip(velocities, -0.5, 0.5)\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced convergence through adaptive learning rates and periodic swarm reseeding.", "configspace": "", "generation": 79, "fitness": 0.1909023326046855, "feedback": "The algorithm Enhanced_PSO_ADE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.16.", "error": "", "parent_id": "eb54d35b-e19e-4af0-8843-8cead5d59837", "metadata": {"aucs": [0.40961691249421883, 0.40961691249421883, 0.40961691249421883, 0.31872609384394646, 0.31872609384394646, 0.31872609384394646, 0.3932455890477391, 0.3932455890477391, 0.3932455890477391, 0.025810232727296323, 0.025810232727296323, 0.025810232727296323, 0.0010302476284741457, 0.0010302476284741457, 0.0010302476284741457, 0.02149642574119992, 0.02149642574119992, 0.02149642574119992, 0.09201277895510407, 0.09201277895510407, 0.09201277895510407, 0.09250185771294928, 0.09250185771294928, 0.09250185771294928, 0.09868037025093546, 0.09868037025093546, 0.09868037025093546, 0.0975662640133953, 0.0975662640133953, 0.0975662640133953, 0.10110719975582438, 0.10110719975582438, 0.10110719975582438, 0.07445941982108506, 0.07445941982108506, 0.07445941982108506, 0.32535241399333625, 0.32535241399333625, 0.32535241399333625, 0.7944202335201674, 0.7944202335201674, 0.7944202335201674, 0.8035998627942441, 0.8035998627942441, 0.8035998627942441, 0.21481331744726206, 0.21481331744726206, 0.21481331744726206, 0.22578785718737593, 0.22578785718737593, 0.22578785718737593, 0.21093463952456892, 0.21093463952456892, 0.21093463952456892, 0.19922832444501481, 0.19922832444501481, 0.19922832444501481, 0.2530965638988194, 0.2530965638988194, 0.2530965638988194, 0.17290746959920977, 0.17290746959920977, 0.17290746959920977, 0.16403377327098045, 0.16403377327098045, 0.16403377327098045, 0.14538126369997095, 0.14538126369997095, 0.14538126369997095, 0.1253765458775511, 0.1253765458775511, 0.1253765458775511, 0.14106837734232647, 0.14106837734232647, 0.14106837734232647, 0.15982226096662322, 0.15982226096662322, 0.15982226096662322, 0.16295312882691926, 0.16295312882691926, 0.16295312882691926, 0.0003427162445477361, 0.0003427162445477361, 0.0003427162445477361, 0.0065913536668591455, 0.0065913536668591455, 0.0065913536668591455, 0.05108593107290693, 0.05108593107290693, 0.05108593107290693, 0.0905521105919006, 0.0905521105919006, 0.0905521105919006, 0.06852092843729951, 0.06852092843729951, 0.06852092843729951, 0.08806523293197788, 0.08806523293197788, 0.08806523293197788, 0.0002632726718886369, 0.0002632726718886369, 0.0002632726718886369, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06305740000356685, 0.06305740000356685, 0.06305740000356685, 0.06990381015391445, 0.06990381015391445, 0.06990381015391445, 0.06971358503047798, 0.06971358503047798, 0.06971358503047798, 0.3897293025726817, 0.3897293025726817, 0.3897293025726817, 0.35391508857867016, 0.35391508857867016, 0.35391508857867016, 0.38199799986231087, 0.38199799986231087, 0.38199799986231087, 0.08160026164505507, 0.08160026164505507, 0.08160026164505507, 0.08342911124790531, 0.08342911124790531, 0.08342911124790531, 0.07975950135090681, 0.07975950135090681, 0.07975950135090681, 0.14833828221649292, 0.14833828221649292, 0.14833828221649292, 0.148681146950163, 0.148681146950163, 0.148681146950163, 0.13393066549089727, 0.13393066549089727, 0.13393066549089727, 0.25577299315850466, 0.25577299315850466, 0.25577299315850466, 0.27312096030922817, 0.27312096030922817, 0.27312096030922817, 0.2153647930779734, 0.2153647930779734, 0.2153647930779734, 0.17295725592735212, 0.17295725592735212, 0.17295725592735212, 0.17819006556478179, 0.17819006556478179, 0.17819006556478179, 0.16891950661802635, 0.16891950661802635, 0.16891950661802635, 0.20199796484021715, 0.20199796484021715, 0.20199796484021715, 0.2043074080701225, 0.2043074080701225, 0.2043074080701225, 0.2401182971533169, 0.2401182971533169, 0.2401182971533169, 0.1829091589222448, 0.1829091589222448, 0.1829091589222448, 0.1882700433131398, 0.1882700433131398, 0.1882700433131398, 0.18325453291896232, 0.18325453291896232, 0.18325453291896232, 0.6100977331507837, 0.6100977331507837, 0.6100977331507837, 0.17807425899577978, 0.17807425899577978, 0.17807425899577978, 0.559524751902527, 0.559524751902527, 0.559524751902527, 0.3528444932869742, 0.3528444932869742, 0.3528444932869742, 0.20529802670489794, 0.20529802670489794, 0.20529802670489794, 0.41677151222157804, 0.41677151222157804, 0.41677151222157804, 0.1914181967648918, 0.1914181967648918, 0.1914181967648918, 0.19218487457643163, 0.19218487457643163, 0.19218487457643163, 0.18653596491589852, 0.18653596491589852, 0.18653596491589852, 0.07779301938724603, 0.07779301938724603, 0.07779301938724603, 0.0744047385349027, 0.0744047385349027, 0.0744047385349027, 0.10013027211461556, 0.10013027211461556, 0.10013027211461556]}, "mutation_prompt": null}
{"id": "e73045e9-fb84-481c-a19d-060794d1c5e6", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 60\n        self.mutation_factor = 0.85\n        self.crossover_prob = 0.8\n        self.inertia_weight = 0.6  # Modified for improved balance\n        self.cognitive_coeff = 1.7  # Increased for better local search\n        self.social_coeff = 1.6  # Increased for enhanced global search\n        self.dynamic_adjustment_freq = 6  # More frequent adjustments\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.92  # Adjusted dynamic reduction\n                self.mutation_factor = 0.87 if iteration < self.budget // 2 else 0.72  # Adaptive mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * 0.9 * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            velocities = np.clip(velocities, -0.5, 0.5)  # Newly added velocity clipping for stability\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced exploration and exploitation via adaptive cognition and dynamic velocity scaling.", "configspace": "", "generation": 74, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "eb54d35b-e19e-4af0-8843-8cead5d59837", "metadata": {"aucs": [0.7806037005125466, 0.7806037005125466, 0.7806037005125466, 0.7505816119826985, 0.7505816119826985, 0.7505816119826985, 0.7633378872054232, 0.7633378872054232, 0.7633378872054232, 0.5370080800385593, 0.5370080800385593, 0.5370080800385593, 0.5189513171681039, 0.5189513171681039, 0.5189513171681039, 0.5506998852525102, 0.5506998852525102, 0.5506998852525102, 0.16982295226058708, 0.16982295226058708, 0.16982295226058708, 0.1457130346119313, 0.1457130346119313, 0.1457130346119313, 0.1392880860995307, 0.1392880860995307, 0.1392880860995307, 0.10877902911458825, 0.10877902911458825, 0.10877902911458825, 0.08674440365567793, 0.08674440365567793, 0.08674440365567793, 0.1297659010011063, 0.1297659010011063, 0.1297659010011063, 0.8372124200650422, 0.8372124200650422, 0.8372124200650422, 0.9055680448791295, 0.9055680448791295, 0.9055680448791295, 0.8666026145978315, 0.8666026145978315, 0.8666026145978315, 0.5331841708951058, 0.5331841708951058, 0.5331841708951058, 0.5461679303813038, 0.5461679303813038, 0.5461679303813038, 0.5195536457095576, 0.5195536457095576, 0.5195536457095576, 0.2184733291829407, 0.2184733291829407, 0.2184733291829407, 0.20824866348361226, 0.20824866348361226, 0.20824866348361226, 0.2309053429801856, 0.2309053429801856, 0.2309053429801856, 0.1251653318752205, 0.1251653318752205, 0.1251653318752205, 0.22704900909967007, 0.22704900909967007, 0.22704900909967007, 0.11781433976503652, 0.11781433976503652, 0.11781433976503652, 0.21100068538103955, 0.21100068538103955, 0.21100068538103955, 0.21261363695091207, 0.21261363695091207, 0.21261363695091207, 0.23101571584830094, 0.23101571584830094, 0.23101571584830094, 0.09284748077203475, 0.09284748077203475, 0.09284748077203475, 0.027021783539842414, 0.027021783539842414, 0.027021783539842414, 0.005395024241547586, 0.005395024241547586, 0.005395024241547586, 0.11067385860183876, 0.11067385860183876, 0.11067385860183876, 0.048197261334110175, 0.048197261334110175, 0.048197261334110175, 0.14582204613146788, 0.14582204613146788, 0.14582204613146788, 0.08681982563736879, 0.08681982563736879, 0.08681982563736879, 0.06573853126052631, 0.06573853126052631, 0.06573853126052631, 0.07771026958936311, 0.07771026958936311, 0.07771026958936311, 0.11788309766652949, 0.11788309766652949, 0.11788309766652949, 0.23737054271200275, 0.23737054271200275, 0.23737054271200275, 0.13902252726356634, 0.13902252726356634, 0.13902252726356634, 0.5312071216638617, 0.5312071216638617, 0.5312071216638617, 0.5466775494176652, 0.5466775494176652, 0.5466775494176652, 0.5020228579681516, 0.5020228579681516, 0.5020228579681516, 0.07998833451464638, 0.07998833451464638, 0.07998833451464638, 0.07814783831944261, 0.07814783831944261, 0.07814783831944261, 0.12711716378292748, 0.12711716378292748, 0.12711716378292748, 0.26580221473739907, 0.26580221473739907, 0.26580221473739907, 0.17574831510837374, 0.17574831510837374, 0.17574831510837374, 0.23657326216880126, 0.23657326216880126, 0.23657326216880126, 0.36594406459018913, 0.36594406459018913, 0.36594406459018913, 0.38442990249231057, 0.38442990249231057, 0.38442990249231057, 0.27064689790163243, 0.27064689790163243, 0.27064689790163243, 0.23227149116217927, 0.23227149116217927, 0.23227149116217927, 0.1888083001177321, 0.1888083001177321, 0.1888083001177321, 0.20784974757845986, 0.20784974757845986, 0.20784974757845986, 0.21848875931255418, 0.21848875931255418, 0.21848875931255418, 0.23707707899836483, 0.23707707899836483, 0.23707707899836483, 0.23557838487715488, 0.23557838487715488, 0.23557838487715488, 0.24720867371385435, 0.24720867371385435, 0.24720867371385435, 0.17563130094899448, 0.17563130094899448, 0.17563130094899448, 0.6353349189826808, 0.6353349189826808, 0.6353349189826808, 0.8350026493746141, 0.8350026493746141, 0.8350026493746141, 0.8427870366563281, 0.8427870366563281, 0.8427870366563281, 0.7898416604262448, 0.7898416604262448, 0.7898416604262448, 0.720680269507624, 0.720680269507624, 0.720680269507624, 0.20728025891266333, 0.20728025891266333, 0.20728025891266333, 0.6229117097113855, 0.6229117097113855, 0.6229117097113855, 0.20341001586372098, 0.20341001586372098, 0.20341001586372098, 0.2059064029568164, 0.2059064029568164, 0.2059064029568164, 0.18088667542278347, 0.18088667542278347, 0.18088667542278347, 0.09112421688121453, 0.09112421688121453, 0.09112421688121453, 0.11284339359557016, 0.11284339359557016, 0.11284339359557016, 0.10215448686757123, 0.10215448686757123, 0.10215448686757123]}, "mutation_prompt": null}
{"id": "0819ae9b-ace8-4693-9082-54ccc5f517f4", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 60\n        self.mutation_factor = 0.85\n        self.crossover_prob = 0.8\n        self.inertia_weight = 0.6  # Modified for improved balance\n        self.cognitive_coeff = 1.7  # Increased for better local search\n        self.social_coeff = 1.6  # Increased for enhanced global search\n        self.dynamic_adjustment_freq = 6  # More frequent adjustments\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.92  # Adjusted dynamic reduction\n                self.mutation_factor = 0.87 if iteration < self.budget // 2 else 0.72  # Adaptive mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * 0.9 * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            velocities = np.clip(velocities, -0.5, 0.5)  # Newly added velocity clipping for stability\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced exploration and exploitation via adaptive cognition and dynamic velocity scaling.", "configspace": "", "generation": 74, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "eb54d35b-e19e-4af0-8843-8cead5d59837", "metadata": {"aucs": [0.7806037005125466, 0.7806037005125466, 0.7806037005125466, 0.7505816119826985, 0.7505816119826985, 0.7505816119826985, 0.7633378872054232, 0.7633378872054232, 0.7633378872054232, 0.5370080800385593, 0.5370080800385593, 0.5370080800385593, 0.5189513171681039, 0.5189513171681039, 0.5189513171681039, 0.5506998852525102, 0.5506998852525102, 0.5506998852525102, 0.16982295226058708, 0.16982295226058708, 0.16982295226058708, 0.1457130346119313, 0.1457130346119313, 0.1457130346119313, 0.1392880860995307, 0.1392880860995307, 0.1392880860995307, 0.10877902911458825, 0.10877902911458825, 0.10877902911458825, 0.08674440365567793, 0.08674440365567793, 0.08674440365567793, 0.1297659010011063, 0.1297659010011063, 0.1297659010011063, 0.8372124200650422, 0.8372124200650422, 0.8372124200650422, 0.9055680448791295, 0.9055680448791295, 0.9055680448791295, 0.8666026145978315, 0.8666026145978315, 0.8666026145978315, 0.5331841708951058, 0.5331841708951058, 0.5331841708951058, 0.5461679303813038, 0.5461679303813038, 0.5461679303813038, 0.5195536457095576, 0.5195536457095576, 0.5195536457095576, 0.2184733291829407, 0.2184733291829407, 0.2184733291829407, 0.20824866348361226, 0.20824866348361226, 0.20824866348361226, 0.2309053429801856, 0.2309053429801856, 0.2309053429801856, 0.1251653318752205, 0.1251653318752205, 0.1251653318752205, 0.22704900909967007, 0.22704900909967007, 0.22704900909967007, 0.11781433976503652, 0.11781433976503652, 0.11781433976503652, 0.21100068538103955, 0.21100068538103955, 0.21100068538103955, 0.21261363695091207, 0.21261363695091207, 0.21261363695091207, 0.23101571584830094, 0.23101571584830094, 0.23101571584830094, 0.09284748077203475, 0.09284748077203475, 0.09284748077203475, 0.027021783539842414, 0.027021783539842414, 0.027021783539842414, 0.005395024241547586, 0.005395024241547586, 0.005395024241547586, 0.11067385860183876, 0.11067385860183876, 0.11067385860183876, 0.048197261334110175, 0.048197261334110175, 0.048197261334110175, 0.14582204613146788, 0.14582204613146788, 0.14582204613146788, 0.08681982563736879, 0.08681982563736879, 0.08681982563736879, 0.06573853126052631, 0.06573853126052631, 0.06573853126052631, 0.07771026958936311, 0.07771026958936311, 0.07771026958936311, 0.11788309766652949, 0.11788309766652949, 0.11788309766652949, 0.23737054271200275, 0.23737054271200275, 0.23737054271200275, 0.13902252726356634, 0.13902252726356634, 0.13902252726356634, 0.5312071216638617, 0.5312071216638617, 0.5312071216638617, 0.5466775494176652, 0.5466775494176652, 0.5466775494176652, 0.5020228579681516, 0.5020228579681516, 0.5020228579681516, 0.07998833451464638, 0.07998833451464638, 0.07998833451464638, 0.07814783831944261, 0.07814783831944261, 0.07814783831944261, 0.12711716378292748, 0.12711716378292748, 0.12711716378292748, 0.26580221473739907, 0.26580221473739907, 0.26580221473739907, 0.17574831510837374, 0.17574831510837374, 0.17574831510837374, 0.23657326216880126, 0.23657326216880126, 0.23657326216880126, 0.36594406459018913, 0.36594406459018913, 0.36594406459018913, 0.38442990249231057, 0.38442990249231057, 0.38442990249231057, 0.27064689790163243, 0.27064689790163243, 0.27064689790163243, 0.23227149116217927, 0.23227149116217927, 0.23227149116217927, 0.1888083001177321, 0.1888083001177321, 0.1888083001177321, 0.20784974757845986, 0.20784974757845986, 0.20784974757845986, 0.21848875931255418, 0.21848875931255418, 0.21848875931255418, 0.23707707899836483, 0.23707707899836483, 0.23707707899836483, 0.23557838487715488, 0.23557838487715488, 0.23557838487715488, 0.24720867371385435, 0.24720867371385435, 0.24720867371385435, 0.17563130094899448, 0.17563130094899448, 0.17563130094899448, 0.6353349189826808, 0.6353349189826808, 0.6353349189826808, 0.8350026493746141, 0.8350026493746141, 0.8350026493746141, 0.8427870366563281, 0.8427870366563281, 0.8427870366563281, 0.7898416604262448, 0.7898416604262448, 0.7898416604262448, 0.720680269507624, 0.720680269507624, 0.720680269507624, 0.20728025891266333, 0.20728025891266333, 0.20728025891266333, 0.6229117097113855, 0.6229117097113855, 0.6229117097113855, 0.20341001586372098, 0.20341001586372098, 0.20341001586372098, 0.2059064029568164, 0.2059064029568164, 0.2059064029568164, 0.18088667542278347, 0.18088667542278347, 0.18088667542278347, 0.09112421688121453, 0.09112421688121453, 0.09112421688121453, 0.11284339359557016, 0.11284339359557016, 0.11284339359557016, 0.10215448686757123, 0.10215448686757123, 0.10215448686757123]}, "mutation_prompt": null}
{"id": "22fdea63-9a98-4a50-b760-7d19ebd11e48", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_swarm_size = 60\n        self.swarm_size = self.initial_swarm_size\n        self.mutation_factor = 0.85\n        self.crossover_prob = 0.8\n        self.inertia_weight = 0.6\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.6\n        self.dynamic_adjustment_freq = 5  # More frequent adjustments \n        self.velocity_init_factor = 0.2  # Enhanced velocity scaling\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-self.velocity_init_factor, self.velocity_init_factor, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.92\n                self.mutation_factor = 0.87 if iteration < self.budget // 2 else 0.72\n                if iteration % 10 == 0 and self.swarm_size > 30:\n                    self.swarm_size -= 5  # Adaptive swarm resizing\n                \n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            velocities = np.clip(velocities, -0.5, 0.5)\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Introduced adaptive population resizing and enhanced velocity initialization for improved convergence speed.", "configspace": "", "generation": 82, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (55,5) (60,5) ').", "error": "ValueError('operands could not be broadcast together with shapes (55,5) (60,5) ')", "parent_id": "eb54d35b-e19e-4af0-8843-8cead5d59837", "metadata": {}, "mutation_prompt": null}
{"id": "fcac7ff5-ca7c-455b-b4c0-bf18f125f402", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer_v2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 60\n        self.mutation_factor = 0.9  # Increased slightly for exploration\n        self.crossover_prob = 0.85  # Enhanced crossover probability\n        self.inertia_weight = 0.65  # Slightly increased for better exploration\n        self.cognitive_coeff = 1.8  # Further increased for better local search\n        self.social_coeff = 1.5  # Slightly decreased for diversity\n        self.dynamic_adjustment_freq = 5  # More frequent adjustments\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))  # Narrowed velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.93  # Slightly adjusted dynamic reduction\n                self.mutation_factor = 0.88 if iteration < self.budget // 2 else 0.74  # Adaptive mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * 0.95 * r2 * (global_best_position - positions)\n            )\n            velocities = np.clip(velocities, -0.4, 0.4)  # Adjusted velocity clipping for stability\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer_v2", "description": "Improved convergence by refining velocity update rules and enhancing mutation strategy.", "configspace": "", "generation": 83, "fitness": 0.2881398380856241, "feedback": "The algorithm Enhanced_PSO_ADE_Optimizer_v2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.23.", "error": "", "parent_id": "eb54d35b-e19e-4af0-8843-8cead5d59837", "metadata": {"aucs": [0.7388668538136978, 0.7388668538136978, 0.7388668538136978, 0.7277579060032026, 0.7277579060032026, 0.7277579060032026, 0.749263336126075, 0.749263336126075, 0.749263336126075, 0.48338333125053845, 0.48338333125053845, 0.48338333125053845, 0.48216181780707523, 0.48216181780707523, 0.48216181780707523, 0.4882416330277095, 0.4882416330277095, 0.4882416330277095, 0.14017686815609542, 0.14017686815609542, 0.14017686815609542, 0.10882027943878003, 0.10882027943878003, 0.10882027943878003, 0.16278208788071058, 0.16278208788071058, 0.16278208788071058, 0.11673709206816407, 0.11673709206816407, 0.11673709206816407, 0.08808303969017595, 0.08808303969017595, 0.08808303969017595, 0.11770296654664458, 0.11770296654664458, 0.11770296654664458, 0.810662871662293, 0.810662871662293, 0.810662871662293, 0.8304056202101231, 0.8304056202101231, 0.8304056202101231, 0.8056625633889671, 0.8056625633889671, 0.8056625633889671, 0.43625126917785817, 0.43625126917785817, 0.43625126917785817, 0.5254523729885545, 0.5254523729885545, 0.5254523729885545, 0.4966175744301681, 0.4966175744301681, 0.4966175744301681, 0.2164637336355365, 0.2164637336355365, 0.2164637336355365, 0.20779063536395115, 0.20779063536395115, 0.20779063536395115, 0.21410300035930419, 0.21410300035930419, 0.21410300035930419, 0.21961047803861333, 0.21961047803861333, 0.21961047803861333, 0.18168683266842323, 0.18168683266842323, 0.18168683266842323, 0.185912628032181, 0.185912628032181, 0.185912628032181, 0.21178056845848203, 0.21178056845848203, 0.21178056845848203, 0.19283234722935627, 0.19283234722935627, 0.19283234722935627, 0.21548426476657445, 0.21548426476657445, 0.21548426476657445, 0.03765866388699801, 0.03765866388699801, 0.03765866388699801, 0.04925977215588495, 0.04925977215588495, 0.04925977215588495, 0.00010038684104807238, 0.00010038684104807238, 0.00010038684104807238, 0.09116115200720631, 0.09116115200720631, 0.09116115200720631, 0.09707961111040442, 0.09707961111040442, 0.09707961111040442, 0.17008083837427934, 0.17008083837427934, 0.17008083837427934, 0.05804919554126742, 0.05804919554126742, 0.05804919554126742, 0.10610596375437276, 0.10610596375437276, 0.10610596375437276, 0.07521602680748785, 0.07521602680748785, 0.07521602680748785, 0.07816919081525431, 0.07816919081525431, 0.07816919081525431, 0.06310925502071008, 0.06310925502071008, 0.06310925502071008, 0.07677944506371182, 0.07677944506371182, 0.07677944506371182, 0.5130892984180258, 0.5130892984180258, 0.5130892984180258, 0.47978714363652364, 0.47978714363652364, 0.47978714363652364, 0.5128643760885068, 0.5128643760885068, 0.5128643760885068, 0.11087648455085675, 0.11087648455085675, 0.11087648455085675, 0.1309722559907326, 0.1309722559907326, 0.1309722559907326, 0.16009377448087325, 0.16009377448087325, 0.16009377448087325, 0.1743395986031635, 0.1743395986031635, 0.1743395986031635, 0.18402097065233336, 0.18402097065233336, 0.18402097065233336, 0.22582785627789703, 0.22582785627789703, 0.22582785627789703, 0.420119028847709, 0.420119028847709, 0.420119028847709, 0.4337196499727808, 0.4337196499727808, 0.4337196499727808, 0.25800637735346477, 0.25800637735346477, 0.25800637735346477, 0.22727320114460015, 0.22727320114460015, 0.22727320114460015, 0.24041740126029076, 0.24041740126029076, 0.24041740126029076, 0.20460369474833562, 0.20460369474833562, 0.20460369474833562, 0.2201735789015371, 0.2201735789015371, 0.2201735789015371, 0.2260131652580789, 0.2260131652580789, 0.2260131652580789, 0.2503772204663115, 0.2503772204663115, 0.2503772204663115, 0.2410439996919238, 0.2410439996919238, 0.2410439996919238, 0.19514905012857586, 0.19514905012857586, 0.19514905012857586, 0.23792020526183766, 0.23792020526183766, 0.23792020526183766, 0.8281253206173105, 0.8281253206173105, 0.8281253206173105, 0.16078313656403131, 0.16078313656403131, 0.16078313656403131, 0.7372476261307939, 0.7372476261307939, 0.7372476261307939, 0.684114999925971, 0.684114999925971, 0.684114999925971, 0.20708229721310956, 0.20708229721310956, 0.20708229721310956, 0.526019617090858, 0.526019617090858, 0.526019617090858, 0.1959257290351909, 0.1959257290351909, 0.1959257290351909, 0.1813470952322056, 0.1813470952322056, 0.1813470952322056, 0.1960093333206011, 0.1960093333206011, 0.1960093333206011, 0.08589943035879821, 0.08589943035879821, 0.08589943035879821, 0.09846362760018279, 0.09846362760018279, 0.09846362760018279, 0.1408983237436472, 0.1408983237436472, 0.1408983237436472]}, "mutation_prompt": null}
{"id": "8accb25c-966e-4cc3-80ed-f5c862ab4848", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 60\n        self.mutation_factor = 0.9  # Slightly increased to enhance diversity\n        self.crossover_prob = 0.85  # Increased to promote exploration\n        self.inertia_weight = 0.7  # Increased initial inertia weight\n        self.cognitive_coeff = 1.6  # Slightly decreased\n        self.social_coeff = 1.7  # Slightly increased for enhanced global search\n        self.dynamic_adjustment_freq = 5  # More frequent adjustments\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.93  # Fine-tuned decay for inertia weight\n                self.mutation_factor = 0.9 if iteration < self.budget // 2 else 0.75  # Adaptive mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * 0.95 * r2 * (global_best_position - positions)  # Adjusted influence\n            )\n            velocities = np.clip(velocities, -0.6, 0.6)  # Adjusted velocity clipping\n            positions = np.clip(positions + velocities + np.random.uniform(-0.1, 0.1, (self.swarm_size, self.dim)), self.lower_bound, self.upper_bound)  # Added randomness to enhance exploration\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced convergence through adaptive inertia decay, dynamic position update, and more aggressive exploration-exploitation balance.", "configspace": "", "generation": 84, "fitness": 0.2317910496984167, "feedback": "The algorithm Enhanced_PSO_ADE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.19.", "error": "", "parent_id": "eb54d35b-e19e-4af0-8843-8cead5d59837", "metadata": {"aucs": [0.43399191071925347, 0.43399191071925347, 0.43399191071925347, 0.4243575865946616, 0.4243575865946616, 0.4243575865946616, 0.4476404471473129, 0.4476404471473129, 0.4476404471473129, 0.05464752264535233, 0.05464752264535233, 0.05464752264535233, 0.021652066980615392, 0.021652066980615392, 0.021652066980615392, 0.030195644763939655, 0.030195644763939655, 0.030195644763939655, 0.15726850007218196, 0.15726850007218196, 0.15726850007218196, 0.09284444600329478, 0.09284444600329478, 0.09284444600329478, 0.11666490294066212, 0.11666490294066212, 0.11666490294066212, 0.09750424086651965, 0.09750424086651965, 0.09750424086651965, 0.09901296752299427, 0.09901296752299427, 0.09901296752299427, 0.1023742703780115, 0.1023742703780115, 0.1023742703780115, 0.8829749474752089, 0.8829749474752089, 0.8829749474752089, 0.7871911468046349, 0.7871911468046349, 0.7871911468046349, 0.7898964840211037, 0.7898964840211037, 0.7898964840211037, 0.31652329504086163, 0.31652329504086163, 0.31652329504086163, 0.28836657968685764, 0.28836657968685764, 0.28836657968685764, 0.2927523751951576, 0.2927523751951576, 0.2927523751951576, 0.3398834245006169, 0.3398834245006169, 0.3398834245006169, 0.2631350704473818, 0.2631350704473818, 0.2631350704473818, 0.42080666075353645, 0.42080666075353645, 0.42080666075353645, 0.11634130347849136, 0.11634130347849136, 0.11634130347849136, 0.17050790449270115, 0.17050790449270115, 0.17050790449270115, 0.1471957514278971, 0.1471957514278971, 0.1471957514278971, 0.2211512155443972, 0.2211512155443972, 0.2211512155443972, 0.1600398903776873, 0.1600398903776873, 0.1600398903776873, 0.18483274451858822, 0.18483274451858822, 0.18483274451858822, 0.0514402783173622, 0.0514402783173622, 0.0514402783173622, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.046870064232055086, 0.046870064232055086, 0.046870064232055086, 0.0894860242568779, 0.0894860242568779, 0.0894860242568779, 0.03814539859149013, 0.03814539859149013, 0.03814539859149013, 0.1420045081195458, 0.1420045081195458, 0.1420045081195458, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0013723122094639884, 0.0013723122094639884, 0.0013723122094639884, 0.1235569956408521, 0.1235569956408521, 0.1235569956408521, 0.09251123648160797, 0.09251123648160797, 0.09251123648160797, 0.11908781122352485, 0.11908781122352485, 0.11908781122352485, 0.41382518146888503, 0.41382518146888503, 0.41382518146888503, 0.4084097172794535, 0.4084097172794535, 0.4084097172794535, 0.39693308181461495, 0.39693308181461495, 0.39693308181461495, 0.08811348382030915, 0.08811348382030915, 0.08811348382030915, 0.07083469118866437, 0.07083469118866437, 0.07083469118866437, 0.12087036312432942, 0.12087036312432942, 0.12087036312432942, 0.16466122408990358, 0.16466122408990358, 0.16466122408990358, 0.22312257975468242, 0.22312257975468242, 0.22312257975468242, 0.21986153821975873, 0.21986153821975873, 0.21986153821975873, 0.2817863559461984, 0.2817863559461984, 0.2817863559461984, 0.2890960789155185, 0.2890960789155185, 0.2890960789155185, 0.2897498130868952, 0.2897498130868952, 0.2897498130868952, 0.1684774644936522, 0.1684774644936522, 0.1684774644936522, 0.22013600296614333, 0.22013600296614333, 0.22013600296614333, 0.18647269638788821, 0.18647269638788821, 0.18647269638788821, 0.20753347250218757, 0.20753347250218757, 0.20753347250218757, 0.2301282347753708, 0.2301282347753708, 0.2301282347753708, 0.20593837898665546, 0.20593837898665546, 0.20593837898665546, 0.19726131948190662, 0.19726131948190662, 0.19726131948190662, 0.20949117839254283, 0.20949117839254283, 0.20949117839254283, 0.21436287970310863, 0.21436287970310863, 0.21436287970310863, 0.691497107245159, 0.691497107245159, 0.691497107245159, 0.5866922150652514, 0.5866922150652514, 0.5866922150652514, 0.6613825359732892, 0.6613825359732892, 0.6613825359732892, 0.552812226262654, 0.552812226262654, 0.552812226262654, 0.20797851911802734, 0.20797851911802734, 0.20797851911802734, 0.16312151613973125, 0.16312151613973125, 0.16312151613973125, 0.19074151398566075, 0.19074151398566075, 0.19074151398566075, 0.18277252884412032, 0.18277252884412032, 0.18277252884412032, 0.18241768292474236, 0.18241768292474236, 0.18241768292474236, 0.09177596403411903, 0.09177596403411903, 0.09177596403411903, 0.08529117392711627, 0.08529117392711627, 0.08529117392711627, 0.12087892889476115, 0.12087892889476115, 0.12087892889476115]}, "mutation_prompt": null}
{"id": "88029524-3c9e-40ab-80ad-57534faf67a0", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 60\n        self.mutation_factor = 0.85\n        self.crossover_prob = 0.8\n        self.inertia_weight = 0.6  # Modified for improved balance\n        self.cognitive_coeff = 1.7  # Increased for better local search\n        self.social_coeff = 1.6  # Increased for enhanced global search\n        self.dynamic_adjustment_freq = 6  # More frequent adjustments\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.92  # Adjusted dynamic reduction\n                self.mutation_factor = 0.87 if iteration < self.budget // 2 else 0.72  # Adaptive mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * 0.9 * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            velocities = np.clip(velocities, -0.5, 0.5)  # Newly added velocity clipping for stability\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced exploration and exploitation via adaptive cognition and dynamic velocity scaling.", "configspace": "", "generation": 74, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "eb54d35b-e19e-4af0-8843-8cead5d59837", "metadata": {"aucs": [0.7806037005125466, 0.7806037005125466, 0.7806037005125466, 0.7505816119826985, 0.7505816119826985, 0.7505816119826985, 0.7633378872054232, 0.7633378872054232, 0.7633378872054232, 0.5370080800385593, 0.5370080800385593, 0.5370080800385593, 0.5189513171681039, 0.5189513171681039, 0.5189513171681039, 0.5506998852525102, 0.5506998852525102, 0.5506998852525102, 0.16982295226058708, 0.16982295226058708, 0.16982295226058708, 0.1457130346119313, 0.1457130346119313, 0.1457130346119313, 0.1392880860995307, 0.1392880860995307, 0.1392880860995307, 0.10877902911458825, 0.10877902911458825, 0.10877902911458825, 0.08674440365567793, 0.08674440365567793, 0.08674440365567793, 0.1297659010011063, 0.1297659010011063, 0.1297659010011063, 0.8372124200650422, 0.8372124200650422, 0.8372124200650422, 0.9055680448791295, 0.9055680448791295, 0.9055680448791295, 0.8666026145978315, 0.8666026145978315, 0.8666026145978315, 0.5331841708951058, 0.5331841708951058, 0.5331841708951058, 0.5461679303813038, 0.5461679303813038, 0.5461679303813038, 0.5195536457095576, 0.5195536457095576, 0.5195536457095576, 0.2184733291829407, 0.2184733291829407, 0.2184733291829407, 0.20824866348361226, 0.20824866348361226, 0.20824866348361226, 0.2309053429801856, 0.2309053429801856, 0.2309053429801856, 0.1251653318752205, 0.1251653318752205, 0.1251653318752205, 0.22704900909967007, 0.22704900909967007, 0.22704900909967007, 0.11781433976503652, 0.11781433976503652, 0.11781433976503652, 0.21100068538103955, 0.21100068538103955, 0.21100068538103955, 0.21261363695091207, 0.21261363695091207, 0.21261363695091207, 0.23101571584830094, 0.23101571584830094, 0.23101571584830094, 0.09284748077203475, 0.09284748077203475, 0.09284748077203475, 0.027021783539842414, 0.027021783539842414, 0.027021783539842414, 0.005395024241547586, 0.005395024241547586, 0.005395024241547586, 0.11067385860183876, 0.11067385860183876, 0.11067385860183876, 0.048197261334110175, 0.048197261334110175, 0.048197261334110175, 0.14582204613146788, 0.14582204613146788, 0.14582204613146788, 0.08681982563736879, 0.08681982563736879, 0.08681982563736879, 0.06573853126052631, 0.06573853126052631, 0.06573853126052631, 0.07771026958936311, 0.07771026958936311, 0.07771026958936311, 0.11788309766652949, 0.11788309766652949, 0.11788309766652949, 0.23737054271200275, 0.23737054271200275, 0.23737054271200275, 0.13902252726356634, 0.13902252726356634, 0.13902252726356634, 0.5312071216638617, 0.5312071216638617, 0.5312071216638617, 0.5466775494176652, 0.5466775494176652, 0.5466775494176652, 0.5020228579681516, 0.5020228579681516, 0.5020228579681516, 0.07998833451464638, 0.07998833451464638, 0.07998833451464638, 0.07814783831944261, 0.07814783831944261, 0.07814783831944261, 0.12711716378292748, 0.12711716378292748, 0.12711716378292748, 0.26580221473739907, 0.26580221473739907, 0.26580221473739907, 0.17574831510837374, 0.17574831510837374, 0.17574831510837374, 0.23657326216880126, 0.23657326216880126, 0.23657326216880126, 0.36594406459018913, 0.36594406459018913, 0.36594406459018913, 0.38442990249231057, 0.38442990249231057, 0.38442990249231057, 0.27064689790163243, 0.27064689790163243, 0.27064689790163243, 0.23227149116217927, 0.23227149116217927, 0.23227149116217927, 0.1888083001177321, 0.1888083001177321, 0.1888083001177321, 0.20784974757845986, 0.20784974757845986, 0.20784974757845986, 0.21848875931255418, 0.21848875931255418, 0.21848875931255418, 0.23707707899836483, 0.23707707899836483, 0.23707707899836483, 0.23557838487715488, 0.23557838487715488, 0.23557838487715488, 0.24720867371385435, 0.24720867371385435, 0.24720867371385435, 0.17563130094899448, 0.17563130094899448, 0.17563130094899448, 0.6353349189826808, 0.6353349189826808, 0.6353349189826808, 0.8350026493746141, 0.8350026493746141, 0.8350026493746141, 0.8427870366563281, 0.8427870366563281, 0.8427870366563281, 0.7898416604262448, 0.7898416604262448, 0.7898416604262448, 0.720680269507624, 0.720680269507624, 0.720680269507624, 0.20728025891266333, 0.20728025891266333, 0.20728025891266333, 0.6229117097113855, 0.6229117097113855, 0.6229117097113855, 0.20341001586372098, 0.20341001586372098, 0.20341001586372098, 0.2059064029568164, 0.2059064029568164, 0.2059064029568164, 0.18088667542278347, 0.18088667542278347, 0.18088667542278347, 0.09112421688121453, 0.09112421688121453, 0.09112421688121453, 0.11284339359557016, 0.11284339359557016, 0.11284339359557016, 0.10215448686757123, 0.10215448686757123, 0.10215448686757123]}, "mutation_prompt": null}
{"id": "432ef35a-909a-469f-9211-03d26d0403e5", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 60\n        self.mutation_factor = 0.85\n        self.crossover_prob = 0.8\n        self.inertia_weight = 0.6  # Modified for improved balance\n        self.cognitive_coeff = 1.7  # Increased for better local search\n        self.social_coeff = 1.6  # Increased for enhanced global search\n        self.dynamic_adjustment_freq = 6  # More frequent adjustments\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.92  # Adjusted dynamic reduction\n                self.mutation_factor = 0.87 if iteration < self.budget // 2 else 0.72  # Adaptive mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * 0.9 * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            velocities = np.clip(velocities, -0.5, 0.5)  # Newly added velocity clipping for stability\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced exploration and exploitation via adaptive cognition and dynamic velocity scaling.", "configspace": "", "generation": 74, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "eb54d35b-e19e-4af0-8843-8cead5d59837", "metadata": {"aucs": [0.7806037005125466, 0.7806037005125466, 0.7806037005125466, 0.7505816119826985, 0.7505816119826985, 0.7505816119826985, 0.7633378872054232, 0.7633378872054232, 0.7633378872054232, 0.5370080800385593, 0.5370080800385593, 0.5370080800385593, 0.5189513171681039, 0.5189513171681039, 0.5189513171681039, 0.5506998852525102, 0.5506998852525102, 0.5506998852525102, 0.16982295226058708, 0.16982295226058708, 0.16982295226058708, 0.1457130346119313, 0.1457130346119313, 0.1457130346119313, 0.1392880860995307, 0.1392880860995307, 0.1392880860995307, 0.10877902911458825, 0.10877902911458825, 0.10877902911458825, 0.08674440365567793, 0.08674440365567793, 0.08674440365567793, 0.1297659010011063, 0.1297659010011063, 0.1297659010011063, 0.8372124200650422, 0.8372124200650422, 0.8372124200650422, 0.9055680448791295, 0.9055680448791295, 0.9055680448791295, 0.8666026145978315, 0.8666026145978315, 0.8666026145978315, 0.5331841708951058, 0.5331841708951058, 0.5331841708951058, 0.5461679303813038, 0.5461679303813038, 0.5461679303813038, 0.5195536457095576, 0.5195536457095576, 0.5195536457095576, 0.2184733291829407, 0.2184733291829407, 0.2184733291829407, 0.20824866348361226, 0.20824866348361226, 0.20824866348361226, 0.2309053429801856, 0.2309053429801856, 0.2309053429801856, 0.1251653318752205, 0.1251653318752205, 0.1251653318752205, 0.22704900909967007, 0.22704900909967007, 0.22704900909967007, 0.11781433976503652, 0.11781433976503652, 0.11781433976503652, 0.21100068538103955, 0.21100068538103955, 0.21100068538103955, 0.21261363695091207, 0.21261363695091207, 0.21261363695091207, 0.23101571584830094, 0.23101571584830094, 0.23101571584830094, 0.09284748077203475, 0.09284748077203475, 0.09284748077203475, 0.027021783539842414, 0.027021783539842414, 0.027021783539842414, 0.005395024241547586, 0.005395024241547586, 0.005395024241547586, 0.11067385860183876, 0.11067385860183876, 0.11067385860183876, 0.048197261334110175, 0.048197261334110175, 0.048197261334110175, 0.14582204613146788, 0.14582204613146788, 0.14582204613146788, 0.08681982563736879, 0.08681982563736879, 0.08681982563736879, 0.06573853126052631, 0.06573853126052631, 0.06573853126052631, 0.07771026958936311, 0.07771026958936311, 0.07771026958936311, 0.11788309766652949, 0.11788309766652949, 0.11788309766652949, 0.23737054271200275, 0.23737054271200275, 0.23737054271200275, 0.13902252726356634, 0.13902252726356634, 0.13902252726356634, 0.5312071216638617, 0.5312071216638617, 0.5312071216638617, 0.5466775494176652, 0.5466775494176652, 0.5466775494176652, 0.5020228579681516, 0.5020228579681516, 0.5020228579681516, 0.07998833451464638, 0.07998833451464638, 0.07998833451464638, 0.07814783831944261, 0.07814783831944261, 0.07814783831944261, 0.12711716378292748, 0.12711716378292748, 0.12711716378292748, 0.26580221473739907, 0.26580221473739907, 0.26580221473739907, 0.17574831510837374, 0.17574831510837374, 0.17574831510837374, 0.23657326216880126, 0.23657326216880126, 0.23657326216880126, 0.36594406459018913, 0.36594406459018913, 0.36594406459018913, 0.38442990249231057, 0.38442990249231057, 0.38442990249231057, 0.27064689790163243, 0.27064689790163243, 0.27064689790163243, 0.23227149116217927, 0.23227149116217927, 0.23227149116217927, 0.1888083001177321, 0.1888083001177321, 0.1888083001177321, 0.20784974757845986, 0.20784974757845986, 0.20784974757845986, 0.21848875931255418, 0.21848875931255418, 0.21848875931255418, 0.23707707899836483, 0.23707707899836483, 0.23707707899836483, 0.23557838487715488, 0.23557838487715488, 0.23557838487715488, 0.24720867371385435, 0.24720867371385435, 0.24720867371385435, 0.17563130094899448, 0.17563130094899448, 0.17563130094899448, 0.6353349189826808, 0.6353349189826808, 0.6353349189826808, 0.8350026493746141, 0.8350026493746141, 0.8350026493746141, 0.8427870366563281, 0.8427870366563281, 0.8427870366563281, 0.7898416604262448, 0.7898416604262448, 0.7898416604262448, 0.720680269507624, 0.720680269507624, 0.720680269507624, 0.20728025891266333, 0.20728025891266333, 0.20728025891266333, 0.6229117097113855, 0.6229117097113855, 0.6229117097113855, 0.20341001586372098, 0.20341001586372098, 0.20341001586372098, 0.2059064029568164, 0.2059064029568164, 0.2059064029568164, 0.18088667542278347, 0.18088667542278347, 0.18088667542278347, 0.09112421688121453, 0.09112421688121453, 0.09112421688121453, 0.11284339359557016, 0.11284339359557016, 0.11284339359557016, 0.10215448686757123, 0.10215448686757123, 0.10215448686757123]}, "mutation_prompt": null}
{"id": "07596bc0-70a9-47b0-9b9d-4c554a132695", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 60\n        self.mutation_factor = 0.9  # Slightly increased for diversity\n        self.crossover_prob = 0.85  # Increased to encourage exploration\n        self.inertia_weight = 0.65  # Slightly increased for exploration\n        self.cognitive_coeff = 1.8  # Slightly increased for better local attraction\n        self.social_coeff = 1.65  # Slightly increased for stronger global influence\n        self.dynamic_adjustment_freq = 5  # More frequent adjustments\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))  # Adjusted initial velocities\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.9  # Adjusted dynamic reduction for more agility\n                self.mutation_factor = 0.89 if iteration < self.budget // 2 else 0.75  # Adaptive mutation adjusted\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * 0.95 * r1 * (personal_best_positions - positions) +\n                self.social_coeff * 1.05 * r2 * (global_best_position - positions)\n            )\n            velocities = np.clip(velocities, -0.6, 0.6)  # Enhanced stability through velocity clipping\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced PSO-ADE with improved velocity control and adaptive mutation for faster convergence.", "configspace": "", "generation": 87, "fitness": 0.30870381085566767, "feedback": "The algorithm Enhanced_PSO_ADE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.25.", "error": "", "parent_id": "eb54d35b-e19e-4af0-8843-8cead5d59837", "metadata": {"aucs": [0.7782722266754922, 0.7782722266754922, 0.7782722266754922, 0.765805077066154, 0.765805077066154, 0.765805077066154, 0.7613166993794465, 0.7613166993794465, 0.7613166993794465, 0.5279518991657404, 0.5279518991657404, 0.5279518991657404, 0.46729550600755265, 0.46729550600755265, 0.46729550600755265, 0.5466427737738533, 0.5466427737738533, 0.5466427737738533, 0.13479861932682746, 0.13479861932682746, 0.13479861932682746, 0.12475094370558237, 0.12475094370558237, 0.12475094370558237, 0.14709478216819516, 0.14709478216819516, 0.14709478216819516, 0.16756057582980155, 0.16756057582980155, 0.16756057582980155, 0.11019364334493909, 0.11019364334493909, 0.11019364334493909, 0.09973027349247132, 0.09973027349247132, 0.09973027349247132, 0.8572468408225937, 0.8572468408225937, 0.8572468408225937, 0.8692921410484352, 0.8692921410484352, 0.8692921410484352, 0.8755222567275842, 0.8755222567275842, 0.8755222567275842, 0.49172981665660676, 0.49172981665660676, 0.49172981665660676, 0.504355876158344, 0.504355876158344, 0.504355876158344, 0.44959194499989685, 0.44959194499989685, 0.44959194499989685, 0.1665736228992426, 0.1665736228992426, 0.1665736228992426, 0.18790941960333718, 0.18790941960333718, 0.18790941960333718, 0.6834070744320857, 0.6834070744320857, 0.6834070744320857, 0.21019084369932484, 0.21019084369932484, 0.21019084369932484, 0.12701102408487952, 0.12701102408487952, 0.12701102408487952, 0.19796232899708965, 0.19796232899708965, 0.19796232899708965, 0.24351457499258855, 0.24351457499258855, 0.24351457499258855, 0.16968809892187142, 0.16968809892187142, 0.16968809892187142, 0.20611507342880486, 0.20611507342880486, 0.20611507342880486, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07003637881667091, 0.07003637881667091, 0.07003637881667091, 0.0001833547947331926, 0.0001833547947331926, 0.0001833547947331926, 0.1117758675812831, 0.1117758675812831, 0.1117758675812831, 0.07970988476234431, 0.07970988476234431, 0.07970988476234431, 0.21193166782398654, 0.21193166782398654, 0.21193166782398654, 0.0703795689680301, 0.0703795689680301, 0.0703795689680301, 0.06827871543515973, 0.06827871543515973, 0.06827871543515973, 0.10482385609783451, 0.10482385609783451, 0.10482385609783451, 0.10968227681576159, 0.10968227681576159, 0.10968227681576159, 0.12229589741635205, 0.12229589741635205, 0.12229589741635205, 0.09214636128114906, 0.09214636128114906, 0.09214636128114906, 0.5156552599508903, 0.5156552599508903, 0.5156552599508903, 0.5104723925794237, 0.5104723925794237, 0.5104723925794237, 0.5177560031017501, 0.5177560031017501, 0.5177560031017501, 0.11438735760935181, 0.11438735760935181, 0.11438735760935181, 0.08920499708746699, 0.08920499708746699, 0.08920499708746699, 0.1285160517598275, 0.1285160517598275, 0.1285160517598275, 0.22389629679828915, 0.22389629679828915, 0.22389629679828915, 0.2242771283289302, 0.2242771283289302, 0.2242771283289302, 0.25899113560933107, 0.25899113560933107, 0.25899113560933107, 0.3882815745338799, 0.3882815745338799, 0.3882815745338799, 0.3535737812369728, 0.3535737812369728, 0.3535737812369728, 0.26187159815947647, 0.26187159815947647, 0.26187159815947647, 0.24968136393132911, 0.24968136393132911, 0.24968136393132911, 0.24921269863202156, 0.24921269863202156, 0.24921269863202156, 0.13572529133435418, 0.13572529133435418, 0.13572529133435418, 0.2209578247540529, 0.2209578247540529, 0.2209578247540529, 0.20250683608033448, 0.20250683608033448, 0.20250683608033448, 0.20856429408952504, 0.20856429408952504, 0.20856429408952504, 0.21292937645664678, 0.21292937645664678, 0.21292937645664678, 0.1986579978119275, 0.1986579978119275, 0.1986579978119275, 0.6898759024373855, 0.6898759024373855, 0.6898759024373855, 0.8528265085936381, 0.8528265085936381, 0.8528265085936381, 0.1559373063312791, 0.1559373063312791, 0.1559373063312791, 0.8262251476294077, 0.8262251476294077, 0.8262251476294077, 0.7355157818517598, 0.7355157818517598, 0.7355157818517598, 0.20754295327657546, 0.20754295327657546, 0.20754295327657546, 0.6980327896684602, 0.6980327896684602, 0.6980327896684602, 0.19151344092398837, 0.19151344092398837, 0.19151344092398837, 0.19453869331022688, 0.19453869331022688, 0.19453869331022688, 0.19874821884588978, 0.19874821884588978, 0.19874821884588978, 0.09082958348808046, 0.09082958348808046, 0.09082958348808046, 0.08845900538235785, 0.08845900538235785, 0.08845900538235785, 0.11864200282119486, 0.11864200282119486, 0.11864200282119486]}, "mutation_prompt": null}
{"id": "478e286a-f20f-453c-9650-9f3940f82623", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 60\n        self.mutation_factor = 0.85\n        self.crossover_prob = 0.8\n        self.inertia_weight = 0.6  # Modified for improved balance\n        self.cognitive_coeff = 1.7  # Increased for better local search\n        self.social_coeff = 1.6  # Increased for enhanced global search\n        self.dynamic_adjustment_freq = 6  # More frequent adjustments\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.92  # Adjusted dynamic reduction\n                self.mutation_factor = 0.87 if iteration < self.budget // 2 else 0.72  # Adaptive mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * 0.9 * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            velocities = np.clip(velocities, -0.5, 0.5)  # Newly added velocity clipping for stability\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced exploration and exploitation via adaptive cognition and dynamic velocity scaling.", "configspace": "", "generation": 74, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "eb54d35b-e19e-4af0-8843-8cead5d59837", "metadata": {"aucs": [0.7806037005125466, 0.7806037005125466, 0.7806037005125466, 0.7505816119826985, 0.7505816119826985, 0.7505816119826985, 0.7633378872054232, 0.7633378872054232, 0.7633378872054232, 0.5370080800385593, 0.5370080800385593, 0.5370080800385593, 0.5189513171681039, 0.5189513171681039, 0.5189513171681039, 0.5506998852525102, 0.5506998852525102, 0.5506998852525102, 0.16982295226058708, 0.16982295226058708, 0.16982295226058708, 0.1457130346119313, 0.1457130346119313, 0.1457130346119313, 0.1392880860995307, 0.1392880860995307, 0.1392880860995307, 0.10877902911458825, 0.10877902911458825, 0.10877902911458825, 0.08674440365567793, 0.08674440365567793, 0.08674440365567793, 0.1297659010011063, 0.1297659010011063, 0.1297659010011063, 0.8372124200650422, 0.8372124200650422, 0.8372124200650422, 0.9055680448791295, 0.9055680448791295, 0.9055680448791295, 0.8666026145978315, 0.8666026145978315, 0.8666026145978315, 0.5331841708951058, 0.5331841708951058, 0.5331841708951058, 0.5461679303813038, 0.5461679303813038, 0.5461679303813038, 0.5195536457095576, 0.5195536457095576, 0.5195536457095576, 0.2184733291829407, 0.2184733291829407, 0.2184733291829407, 0.20824866348361226, 0.20824866348361226, 0.20824866348361226, 0.2309053429801856, 0.2309053429801856, 0.2309053429801856, 0.1251653318752205, 0.1251653318752205, 0.1251653318752205, 0.22704900909967007, 0.22704900909967007, 0.22704900909967007, 0.11781433976503652, 0.11781433976503652, 0.11781433976503652, 0.21100068538103955, 0.21100068538103955, 0.21100068538103955, 0.21261363695091207, 0.21261363695091207, 0.21261363695091207, 0.23101571584830094, 0.23101571584830094, 0.23101571584830094, 0.09284748077203475, 0.09284748077203475, 0.09284748077203475, 0.027021783539842414, 0.027021783539842414, 0.027021783539842414, 0.005395024241547586, 0.005395024241547586, 0.005395024241547586, 0.11067385860183876, 0.11067385860183876, 0.11067385860183876, 0.048197261334110175, 0.048197261334110175, 0.048197261334110175, 0.14582204613146788, 0.14582204613146788, 0.14582204613146788, 0.08681982563736879, 0.08681982563736879, 0.08681982563736879, 0.06573853126052631, 0.06573853126052631, 0.06573853126052631, 0.07771026958936311, 0.07771026958936311, 0.07771026958936311, 0.11788309766652949, 0.11788309766652949, 0.11788309766652949, 0.23737054271200275, 0.23737054271200275, 0.23737054271200275, 0.13902252726356634, 0.13902252726356634, 0.13902252726356634, 0.5312071216638617, 0.5312071216638617, 0.5312071216638617, 0.5466775494176652, 0.5466775494176652, 0.5466775494176652, 0.5020228579681516, 0.5020228579681516, 0.5020228579681516, 0.07998833451464638, 0.07998833451464638, 0.07998833451464638, 0.07814783831944261, 0.07814783831944261, 0.07814783831944261, 0.12711716378292748, 0.12711716378292748, 0.12711716378292748, 0.26580221473739907, 0.26580221473739907, 0.26580221473739907, 0.17574831510837374, 0.17574831510837374, 0.17574831510837374, 0.23657326216880126, 0.23657326216880126, 0.23657326216880126, 0.36594406459018913, 0.36594406459018913, 0.36594406459018913, 0.38442990249231057, 0.38442990249231057, 0.38442990249231057, 0.27064689790163243, 0.27064689790163243, 0.27064689790163243, 0.23227149116217927, 0.23227149116217927, 0.23227149116217927, 0.1888083001177321, 0.1888083001177321, 0.1888083001177321, 0.20784974757845986, 0.20784974757845986, 0.20784974757845986, 0.21848875931255418, 0.21848875931255418, 0.21848875931255418, 0.23707707899836483, 0.23707707899836483, 0.23707707899836483, 0.23557838487715488, 0.23557838487715488, 0.23557838487715488, 0.24720867371385435, 0.24720867371385435, 0.24720867371385435, 0.17563130094899448, 0.17563130094899448, 0.17563130094899448, 0.6353349189826808, 0.6353349189826808, 0.6353349189826808, 0.8350026493746141, 0.8350026493746141, 0.8350026493746141, 0.8427870366563281, 0.8427870366563281, 0.8427870366563281, 0.7898416604262448, 0.7898416604262448, 0.7898416604262448, 0.720680269507624, 0.720680269507624, 0.720680269507624, 0.20728025891266333, 0.20728025891266333, 0.20728025891266333, 0.6229117097113855, 0.6229117097113855, 0.6229117097113855, 0.20341001586372098, 0.20341001586372098, 0.20341001586372098, 0.2059064029568164, 0.2059064029568164, 0.2059064029568164, 0.18088667542278347, 0.18088667542278347, 0.18088667542278347, 0.09112421688121453, 0.09112421688121453, 0.09112421688121453, 0.11284339359557016, 0.11284339359557016, 0.11284339359557016, 0.10215448686757123, 0.10215448686757123, 0.10215448686757123]}, "mutation_prompt": null}
{"id": "497f96e4-9bd9-4c3f-be2d-6986eea73f0c", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 60\n        self.mutation_factor = 0.85\n        self.crossover_prob = 0.8\n        self.inertia_weight = 0.6  # Modified for improved balance\n        self.cognitive_coeff = 1.7  # Increased for better local search\n        self.social_coeff = 1.6  # Increased for enhanced global search\n        self.dynamic_adjustment_freq = 6  # More frequent adjustments\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.92  # Adjusted dynamic reduction\n                self.mutation_factor = 0.87 if iteration < self.budget // 2 else 0.72  # Adaptive mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * 0.9 * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            velocities = np.clip(velocities, -0.5, 0.5)  # Newly added velocity clipping for stability\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer", "description": "Enhanced exploration and exploitation via adaptive cognition and dynamic velocity scaling.", "configspace": "", "generation": 74, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "eb54d35b-e19e-4af0-8843-8cead5d59837", "metadata": {"aucs": [0.7806037005125466, 0.7806037005125466, 0.7806037005125466, 0.7505816119826985, 0.7505816119826985, 0.7505816119826985, 0.7633378872054232, 0.7633378872054232, 0.7633378872054232, 0.5370080800385593, 0.5370080800385593, 0.5370080800385593, 0.5189513171681039, 0.5189513171681039, 0.5189513171681039, 0.5506998852525102, 0.5506998852525102, 0.5506998852525102, 0.16982295226058708, 0.16982295226058708, 0.16982295226058708, 0.1457130346119313, 0.1457130346119313, 0.1457130346119313, 0.1392880860995307, 0.1392880860995307, 0.1392880860995307, 0.10877902911458825, 0.10877902911458825, 0.10877902911458825, 0.08674440365567793, 0.08674440365567793, 0.08674440365567793, 0.1297659010011063, 0.1297659010011063, 0.1297659010011063, 0.8372124200650422, 0.8372124200650422, 0.8372124200650422, 0.9055680448791295, 0.9055680448791295, 0.9055680448791295, 0.8666026145978315, 0.8666026145978315, 0.8666026145978315, 0.5331841708951058, 0.5331841708951058, 0.5331841708951058, 0.5461679303813038, 0.5461679303813038, 0.5461679303813038, 0.5195536457095576, 0.5195536457095576, 0.5195536457095576, 0.2184733291829407, 0.2184733291829407, 0.2184733291829407, 0.20824866348361226, 0.20824866348361226, 0.20824866348361226, 0.2309053429801856, 0.2309053429801856, 0.2309053429801856, 0.1251653318752205, 0.1251653318752205, 0.1251653318752205, 0.22704900909967007, 0.22704900909967007, 0.22704900909967007, 0.11781433976503652, 0.11781433976503652, 0.11781433976503652, 0.21100068538103955, 0.21100068538103955, 0.21100068538103955, 0.21261363695091207, 0.21261363695091207, 0.21261363695091207, 0.23101571584830094, 0.23101571584830094, 0.23101571584830094, 0.09284748077203475, 0.09284748077203475, 0.09284748077203475, 0.027021783539842414, 0.027021783539842414, 0.027021783539842414, 0.005395024241547586, 0.005395024241547586, 0.005395024241547586, 0.11067385860183876, 0.11067385860183876, 0.11067385860183876, 0.048197261334110175, 0.048197261334110175, 0.048197261334110175, 0.14582204613146788, 0.14582204613146788, 0.14582204613146788, 0.08681982563736879, 0.08681982563736879, 0.08681982563736879, 0.06573853126052631, 0.06573853126052631, 0.06573853126052631, 0.07771026958936311, 0.07771026958936311, 0.07771026958936311, 0.11788309766652949, 0.11788309766652949, 0.11788309766652949, 0.23737054271200275, 0.23737054271200275, 0.23737054271200275, 0.13902252726356634, 0.13902252726356634, 0.13902252726356634, 0.5312071216638617, 0.5312071216638617, 0.5312071216638617, 0.5466775494176652, 0.5466775494176652, 0.5466775494176652, 0.5020228579681516, 0.5020228579681516, 0.5020228579681516, 0.07998833451464638, 0.07998833451464638, 0.07998833451464638, 0.07814783831944261, 0.07814783831944261, 0.07814783831944261, 0.12711716378292748, 0.12711716378292748, 0.12711716378292748, 0.26580221473739907, 0.26580221473739907, 0.26580221473739907, 0.17574831510837374, 0.17574831510837374, 0.17574831510837374, 0.23657326216880126, 0.23657326216880126, 0.23657326216880126, 0.36594406459018913, 0.36594406459018913, 0.36594406459018913, 0.38442990249231057, 0.38442990249231057, 0.38442990249231057, 0.27064689790163243, 0.27064689790163243, 0.27064689790163243, 0.23227149116217927, 0.23227149116217927, 0.23227149116217927, 0.1888083001177321, 0.1888083001177321, 0.1888083001177321, 0.20784974757845986, 0.20784974757845986, 0.20784974757845986, 0.21848875931255418, 0.21848875931255418, 0.21848875931255418, 0.23707707899836483, 0.23707707899836483, 0.23707707899836483, 0.23557838487715488, 0.23557838487715488, 0.23557838487715488, 0.24720867371385435, 0.24720867371385435, 0.24720867371385435, 0.17563130094899448, 0.17563130094899448, 0.17563130094899448, 0.6353349189826808, 0.6353349189826808, 0.6353349189826808, 0.8350026493746141, 0.8350026493746141, 0.8350026493746141, 0.8427870366563281, 0.8427870366563281, 0.8427870366563281, 0.7898416604262448, 0.7898416604262448, 0.7898416604262448, 0.720680269507624, 0.720680269507624, 0.720680269507624, 0.20728025891266333, 0.20728025891266333, 0.20728025891266333, 0.6229117097113855, 0.6229117097113855, 0.6229117097113855, 0.20341001586372098, 0.20341001586372098, 0.20341001586372098, 0.2059064029568164, 0.2059064029568164, 0.2059064029568164, 0.18088667542278347, 0.18088667542278347, 0.18088667542278347, 0.09112421688121453, 0.09112421688121453, 0.09112421688121453, 0.11284339359557016, 0.11284339359557016, 0.11284339359557016, 0.10215448686757123, 0.10215448686757123, 0.10215448686757123]}, "mutation_prompt": null}
{"id": "850e303a-9b38-47cc-a32b-d6efdf1acdab", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer_V2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50  # Reduced size for faster convergence\n        self.mutation_factor = 0.9  # Increased to enhance diversity\n        self.crossover_prob = 0.85  # Slightly increased for better exploration\n        self.inertia_weight = 0.5  # Adjusted for faster convergence\n        self.cognitive_coeff = 1.8  # Tweaked for more localized search\n        self.social_coeff = 1.5  # Reduced to balance global influence\n        self.dynamic_adjustment_freq = 5  # More frequent adjustments\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.90  # Faster reduction for inertia\n                self.mutation_factor = 0.88 if iteration < self.budget // 2 else 0.75  # Adaptive mutation enhancement\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            velocities = np.clip(velocities, -0.7, 0.7)  # Adjusted velocity limits to promote exploration\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer_V2", "description": "Improved dynamic adjustment and exploitation with adaptive learning rate and enhanced diversity.", "configspace": "", "generation": 90, "fitness": 0.34225555274753966, "feedback": "The algorithm Enhanced_PSO_ADE_Optimizer_V2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.27.", "error": "", "parent_id": "eb54d35b-e19e-4af0-8843-8cead5d59837", "metadata": {"aucs": [0.8396044719036575, 0.8396044719036575, 0.8396044719036575, 0.8198586127047862, 0.8198586127047862, 0.8198586127047862, 0.8368415781417637, 0.8368415781417637, 0.8368415781417637, 0.6891100940471951, 0.6891100940471951, 0.6891100940471951, 0.6705281974203544, 0.6705281974203544, 0.6705281974203544, 0.6506388267389893, 0.6506388267389893, 0.6506388267389893, 0.13724355661302512, 0.13724355661302512, 0.13724355661302512, 0.5490019155261059, 0.5490019155261059, 0.5490019155261059, 0.13461988883189258, 0.13461988883189258, 0.13461988883189258, 0.10234499528814955, 0.10234499528814955, 0.10234499528814955, 0.11271235651904721, 0.11271235651904721, 0.11271235651904721, 0.11728844415504025, 0.11728844415504025, 0.11728844415504025, 0.9087334982994018, 0.9087334982994018, 0.9087334982994018, 0.8939270954135277, 0.8939270954135277, 0.8939270954135277, 0.8891830816878267, 0.8891830816878267, 0.8891830816878267, 0.6251575910018332, 0.6251575910018332, 0.6251575910018332, 0.5937865277153052, 0.5937865277153052, 0.5937865277153052, 0.599934457373321, 0.599934457373321, 0.599934457373321, 0.6708362262017533, 0.6708362262017533, 0.6708362262017533, 0.8467058153458593, 0.8467058153458593, 0.8467058153458593, 0.22914760842275328, 0.22914760842275328, 0.22914760842275328, 0.18889045298701534, 0.18889045298701534, 0.18889045298701534, 0.19881957741658962, 0.19881957741658962, 0.19881957741658962, 0.3914827549041269, 0.3914827549041269, 0.3914827549041269, 0.2222416991056998, 0.2222416991056998, 0.2222416991056998, 0.2051044619404888, 0.2051044619404888, 0.2051044619404888, 0.20064106699402184, 0.20064106699402184, 0.20064106699402184, 0.04142762923291998, 0.04142762923291998, 0.04142762923291998, 0.060148210548633285, 0.060148210548633285, 0.060148210548633285, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.15381373907129914, 0.15381373907129914, 0.15381373907129914, 0.09289561537631374, 0.09289561537631374, 0.09289561537631374, 0.17281492526298914, 0.17281492526298914, 0.17281492526298914, 0.07847885967241852, 0.07847885967241852, 0.07847885967241852, 0.07746487350068543, 0.07746487350068543, 0.07746487350068543, 0.1121195270696238, 0.1121195270696238, 0.1121195270696238, 0.1215284646730086, 0.1215284646730086, 0.1215284646730086, 0.0887051187616833, 0.0887051187616833, 0.0887051187616833, 0.07815744015654813, 0.07815744015654813, 0.07815744015654813, 0.5221091906932726, 0.5221091906932726, 0.5221091906932726, 0.5282806887159686, 0.5282806887159686, 0.5282806887159686, 0.5389227789221347, 0.5389227789221347, 0.5389227789221347, 0.0783573744311361, 0.0783573744311361, 0.0783573744311361, 0.14781218071869096, 0.14781218071869096, 0.14781218071869096, 0.1049205968943594, 0.1049205968943594, 0.1049205968943594, 0.2220581768034796, 0.2220581768034796, 0.2220581768034796, 0.17391417519321128, 0.17391417519321128, 0.17391417519321128, 0.2128241683018719, 0.2128241683018719, 0.2128241683018719, 0.2699827487500739, 0.2699827487500739, 0.2699827487500739, 0.36220118633434484, 0.36220118633434484, 0.36220118633434484, 0.44120584649788275, 0.44120584649788275, 0.44120584649788275, 0.2328894961038569, 0.2328894961038569, 0.2328894961038569, 0.2585203061741802, 0.2585203061741802, 0.2585203061741802, 0.23387965611305628, 0.23387965611305628, 0.23387965611305628, 0.23092139879740547, 0.23092139879740547, 0.23092139879740547, 0.24876409485733864, 0.24876409485733864, 0.24876409485733864, 0.2500442967333115, 0.2500442967333115, 0.2500442967333115, 0.2174260166976424, 0.2174260166976424, 0.2174260166976424, 0.21748770605187218, 0.21748770605187218, 0.21748770605187218, 0.22169851466969004, 0.22169851466969004, 0.22169851466969004, 0.8943106534698957, 0.8943106534698957, 0.8943106534698957, 0.8469362433168687, 0.8469362433168687, 0.8469362433168687, 0.8409411394632338, 0.8409411394632338, 0.8409411394632338, 0.15388447509826852, 0.15388447509826852, 0.15388447509826852, 0.20831507884829148, 0.20831507884829148, 0.20831507884829148, 0.7049388305277102, 0.7049388305277102, 0.7049388305277102, 0.20394142836437112, 0.20394142836437112, 0.20394142836437112, 0.1933799584959648, 0.1933799584959648, 0.1933799584959648, 0.19662842650221257, 0.19662842650221257, 0.19662842650221257, 0.09983014341114471, 0.09983014341114471, 0.09983014341114471, 0.10137548395111262, 0.10137548395111262, 0.10137548395111262, 0.08165808189334911, 0.08165808189334911, 0.08165808189334911]}, "mutation_prompt": null}
{"id": "19496d8e-063f-46ca-8b16-0facb3984d13", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer_V2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50  # Reduced size for faster convergence\n        self.mutation_factor = 0.9  # Increased to enhance diversity\n        self.crossover_prob = 0.85  # Slightly increased for better exploration\n        self.inertia_weight = 0.5  # Adjusted for faster convergence\n        self.cognitive_coeff = 1.8  # Tweaked for more localized search\n        self.social_coeff = 1.5  # Reduced to balance global influence\n        self.dynamic_adjustment_freq = 5  # More frequent adjustments\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.90  # Faster reduction for inertia\n                self.mutation_factor = 0.88 if iteration < self.budget // 2 else 0.75  # Adaptive mutation enhancement\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            velocities = np.clip(velocities, -0.7, 0.7)  # Adjusted velocity limits to promote exploration\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer_V2", "description": "Improved dynamic adjustment and exploitation with adaptive learning rate and enhanced diversity.", "configspace": "", "generation": 91, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "850e303a-9b38-47cc-a32b-d6efdf1acdab", "metadata": {"aucs": [0.8396044719036575, 0.8396044719036575, 0.8396044719036575, 0.8198586127047862, 0.8198586127047862, 0.8198586127047862, 0.8368415781417637, 0.8368415781417637, 0.8368415781417637, 0.6891100940471951, 0.6891100940471951, 0.6891100940471951, 0.6705281974203544, 0.6705281974203544, 0.6705281974203544, 0.6506388267389893, 0.6506388267389893, 0.6506388267389893, 0.13724355661302512, 0.13724355661302512, 0.13724355661302512, 0.5490019155261059, 0.5490019155261059, 0.5490019155261059, 0.13461988883189258, 0.13461988883189258, 0.13461988883189258, 0.10234499528814955, 0.10234499528814955, 0.10234499528814955, 0.11271235651904721, 0.11271235651904721, 0.11271235651904721, 0.11728844415504025, 0.11728844415504025, 0.11728844415504025, 0.9087334982994018, 0.9087334982994018, 0.9087334982994018, 0.8939270954135277, 0.8939270954135277, 0.8939270954135277, 0.8891830816878267, 0.8891830816878267, 0.8891830816878267, 0.6251575910018332, 0.6251575910018332, 0.6251575910018332, 0.5937865277153052, 0.5937865277153052, 0.5937865277153052, 0.599934457373321, 0.599934457373321, 0.599934457373321, 0.6708362262017533, 0.6708362262017533, 0.6708362262017533, 0.8467058153458593, 0.8467058153458593, 0.8467058153458593, 0.22914760842275328, 0.22914760842275328, 0.22914760842275328, 0.18889045298701534, 0.18889045298701534, 0.18889045298701534, 0.19881957741658962, 0.19881957741658962, 0.19881957741658962, 0.3914827549041269, 0.3914827549041269, 0.3914827549041269, 0.2222416991056998, 0.2222416991056998, 0.2222416991056998, 0.2051044619404888, 0.2051044619404888, 0.2051044619404888, 0.20064106699402184, 0.20064106699402184, 0.20064106699402184, 0.04142762923291998, 0.04142762923291998, 0.04142762923291998, 0.060148210548633285, 0.060148210548633285, 0.060148210548633285, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.15381373907129914, 0.15381373907129914, 0.15381373907129914, 0.09289561537631374, 0.09289561537631374, 0.09289561537631374, 0.17281492526298914, 0.17281492526298914, 0.17281492526298914, 0.07847885967241852, 0.07847885967241852, 0.07847885967241852, 0.07746487350068543, 0.07746487350068543, 0.07746487350068543, 0.1121195270696238, 0.1121195270696238, 0.1121195270696238, 0.1215284646730086, 0.1215284646730086, 0.1215284646730086, 0.0887051187616833, 0.0887051187616833, 0.0887051187616833, 0.07815744015654813, 0.07815744015654813, 0.07815744015654813, 0.5221091906932726, 0.5221091906932726, 0.5221091906932726, 0.5282806887159686, 0.5282806887159686, 0.5282806887159686, 0.5389227789221347, 0.5389227789221347, 0.5389227789221347, 0.0783573744311361, 0.0783573744311361, 0.0783573744311361, 0.14781218071869096, 0.14781218071869096, 0.14781218071869096, 0.1049205968943594, 0.1049205968943594, 0.1049205968943594, 0.2220581768034796, 0.2220581768034796, 0.2220581768034796, 0.17391417519321128, 0.17391417519321128, 0.17391417519321128, 0.2128241683018719, 0.2128241683018719, 0.2128241683018719, 0.2699827487500739, 0.2699827487500739, 0.2699827487500739, 0.36220118633434484, 0.36220118633434484, 0.36220118633434484, 0.44120584649788275, 0.44120584649788275, 0.44120584649788275, 0.2328894961038569, 0.2328894961038569, 0.2328894961038569, 0.2585203061741802, 0.2585203061741802, 0.2585203061741802, 0.23387965611305628, 0.23387965611305628, 0.23387965611305628, 0.23092139879740547, 0.23092139879740547, 0.23092139879740547, 0.24876409485733864, 0.24876409485733864, 0.24876409485733864, 0.2500442967333115, 0.2500442967333115, 0.2500442967333115, 0.2174260166976424, 0.2174260166976424, 0.2174260166976424, 0.21748770605187218, 0.21748770605187218, 0.21748770605187218, 0.22169851466969004, 0.22169851466969004, 0.22169851466969004, 0.8943106534698957, 0.8943106534698957, 0.8943106534698957, 0.8469362433168687, 0.8469362433168687, 0.8469362433168687, 0.8409411394632338, 0.8409411394632338, 0.8409411394632338, 0.15388447509826852, 0.15388447509826852, 0.15388447509826852, 0.20831507884829148, 0.20831507884829148, 0.20831507884829148, 0.7049388305277102, 0.7049388305277102, 0.7049388305277102, 0.20394142836437112, 0.20394142836437112, 0.20394142836437112, 0.1933799584959648, 0.1933799584959648, 0.1933799584959648, 0.19662842650221257, 0.19662842650221257, 0.19662842650221257, 0.09983014341114471, 0.09983014341114471, 0.09983014341114471, 0.10137548395111262, 0.10137548395111262, 0.10137548395111262, 0.08165808189334911, 0.08165808189334911, 0.08165808189334911]}, "mutation_prompt": null}
{"id": "97ad4bb7-1ec8-4be2-a895-2b958e4bebfa", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer_V2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50  # Reduced size for faster convergence\n        self.mutation_factor = 0.9  # Increased to enhance diversity\n        self.crossover_prob = 0.85  # Slightly increased for better exploration\n        self.inertia_weight = 0.5  # Adjusted for faster convergence\n        self.cognitive_coeff = 1.8  # Tweaked for more localized search\n        self.social_coeff = 1.5  # Reduced to balance global influence\n        self.dynamic_adjustment_freq = 5  # More frequent adjustments\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.90  # Faster reduction for inertia\n                self.mutation_factor = 0.88 if iteration < self.budget // 2 else 0.75  # Adaptive mutation enhancement\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            velocities = np.clip(velocities, -0.7, 0.7)  # Adjusted velocity limits to promote exploration\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer_V2", "description": "Improved dynamic adjustment and exploitation with adaptive learning rate and enhanced diversity.", "configspace": "", "generation": 91, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "850e303a-9b38-47cc-a32b-d6efdf1acdab", "metadata": {"aucs": [0.8396044719036575, 0.8396044719036575, 0.8396044719036575, 0.8198586127047862, 0.8198586127047862, 0.8198586127047862, 0.8368415781417637, 0.8368415781417637, 0.8368415781417637, 0.6891100940471951, 0.6891100940471951, 0.6891100940471951, 0.6705281974203544, 0.6705281974203544, 0.6705281974203544, 0.6506388267389893, 0.6506388267389893, 0.6506388267389893, 0.13724355661302512, 0.13724355661302512, 0.13724355661302512, 0.5490019155261059, 0.5490019155261059, 0.5490019155261059, 0.13461988883189258, 0.13461988883189258, 0.13461988883189258, 0.10234499528814955, 0.10234499528814955, 0.10234499528814955, 0.11271235651904721, 0.11271235651904721, 0.11271235651904721, 0.11728844415504025, 0.11728844415504025, 0.11728844415504025, 0.9087334982994018, 0.9087334982994018, 0.9087334982994018, 0.8939270954135277, 0.8939270954135277, 0.8939270954135277, 0.8891830816878267, 0.8891830816878267, 0.8891830816878267, 0.6251575910018332, 0.6251575910018332, 0.6251575910018332, 0.5937865277153052, 0.5937865277153052, 0.5937865277153052, 0.599934457373321, 0.599934457373321, 0.599934457373321, 0.6708362262017533, 0.6708362262017533, 0.6708362262017533, 0.8467058153458593, 0.8467058153458593, 0.8467058153458593, 0.22914760842275328, 0.22914760842275328, 0.22914760842275328, 0.18889045298701534, 0.18889045298701534, 0.18889045298701534, 0.19881957741658962, 0.19881957741658962, 0.19881957741658962, 0.3914827549041269, 0.3914827549041269, 0.3914827549041269, 0.2222416991056998, 0.2222416991056998, 0.2222416991056998, 0.2051044619404888, 0.2051044619404888, 0.2051044619404888, 0.20064106699402184, 0.20064106699402184, 0.20064106699402184, 0.04142762923291998, 0.04142762923291998, 0.04142762923291998, 0.060148210548633285, 0.060148210548633285, 0.060148210548633285, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.15381373907129914, 0.15381373907129914, 0.15381373907129914, 0.09289561537631374, 0.09289561537631374, 0.09289561537631374, 0.17281492526298914, 0.17281492526298914, 0.17281492526298914, 0.07847885967241852, 0.07847885967241852, 0.07847885967241852, 0.07746487350068543, 0.07746487350068543, 0.07746487350068543, 0.1121195270696238, 0.1121195270696238, 0.1121195270696238, 0.1215284646730086, 0.1215284646730086, 0.1215284646730086, 0.0887051187616833, 0.0887051187616833, 0.0887051187616833, 0.07815744015654813, 0.07815744015654813, 0.07815744015654813, 0.5221091906932726, 0.5221091906932726, 0.5221091906932726, 0.5282806887159686, 0.5282806887159686, 0.5282806887159686, 0.5389227789221347, 0.5389227789221347, 0.5389227789221347, 0.0783573744311361, 0.0783573744311361, 0.0783573744311361, 0.14781218071869096, 0.14781218071869096, 0.14781218071869096, 0.1049205968943594, 0.1049205968943594, 0.1049205968943594, 0.2220581768034796, 0.2220581768034796, 0.2220581768034796, 0.17391417519321128, 0.17391417519321128, 0.17391417519321128, 0.2128241683018719, 0.2128241683018719, 0.2128241683018719, 0.2699827487500739, 0.2699827487500739, 0.2699827487500739, 0.36220118633434484, 0.36220118633434484, 0.36220118633434484, 0.44120584649788275, 0.44120584649788275, 0.44120584649788275, 0.2328894961038569, 0.2328894961038569, 0.2328894961038569, 0.2585203061741802, 0.2585203061741802, 0.2585203061741802, 0.23387965611305628, 0.23387965611305628, 0.23387965611305628, 0.23092139879740547, 0.23092139879740547, 0.23092139879740547, 0.24876409485733864, 0.24876409485733864, 0.24876409485733864, 0.2500442967333115, 0.2500442967333115, 0.2500442967333115, 0.2174260166976424, 0.2174260166976424, 0.2174260166976424, 0.21748770605187218, 0.21748770605187218, 0.21748770605187218, 0.22169851466969004, 0.22169851466969004, 0.22169851466969004, 0.8943106534698957, 0.8943106534698957, 0.8943106534698957, 0.8469362433168687, 0.8469362433168687, 0.8469362433168687, 0.8409411394632338, 0.8409411394632338, 0.8409411394632338, 0.15388447509826852, 0.15388447509826852, 0.15388447509826852, 0.20831507884829148, 0.20831507884829148, 0.20831507884829148, 0.7049388305277102, 0.7049388305277102, 0.7049388305277102, 0.20394142836437112, 0.20394142836437112, 0.20394142836437112, 0.1933799584959648, 0.1933799584959648, 0.1933799584959648, 0.19662842650221257, 0.19662842650221257, 0.19662842650221257, 0.09983014341114471, 0.09983014341114471, 0.09983014341114471, 0.10137548395111262, 0.10137548395111262, 0.10137548395111262, 0.08165808189334911, 0.08165808189334911, 0.08165808189334911]}, "mutation_prompt": null}
{"id": "fc30d68d-0b64-43d1-8b7c-83dce4ecc8d4", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer_V3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 60  # Increased size for better diversity\n        self.mutation_factor = 0.85  # Slightly adjusted for balanced exploration\n        self.crossover_prob = 0.80  # Reduced for more selective exploration\n        self.inertia_weight = 0.4  # Lowered for quicker convergence\n        self.cognitive_coeff = 2.0  # Increased for more aggressive local search\n        self.social_coeff = 1.6  # Slightly increased for better global search\n        self.dynamic_adjustment_freq = 4  # More frequent adjustments for faster learning\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.85  # Accelerate inertia weight decay\n                self.mutation_factor = 0.82 if iteration < self.budget // 2 else 0.70  # More adaptive mutation factor\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            velocities = np.clip(velocities, -0.6, 0.6)  # Fine-tuned velocity limits\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer_V3", "description": "Enhanced convergence speed via fine-tuned particle velocity dynamics and adaptive mutation strategies.", "configspace": "", "generation": 93, "fitness": 0.3090685409413463, "feedback": "The algorithm Enhanced_PSO_ADE_Optimizer_V3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.25.", "error": "", "parent_id": "850e303a-9b38-47cc-a32b-d6efdf1acdab", "metadata": {"aucs": [0.8406542329147927, 0.8406542329147927, 0.8406542329147927, 0.811186571932867, 0.811186571932867, 0.811186571932867, 0.8245099685646052, 0.8245099685646052, 0.8245099685646052, 0.6214266511349111, 0.6214266511349111, 0.6214266511349111, 0.578396484243334, 0.578396484243334, 0.578396484243334, 0.6220077605101517, 0.6220077605101517, 0.6220077605101517, 0.17727850492049024, 0.17727850492049024, 0.17727850492049024, 0.13508624291526916, 0.13508624291526916, 0.13508624291526916, 0.1743278559101682, 0.1743278559101682, 0.1743278559101682, 0.10377061423835987, 0.10377061423835987, 0.10377061423835987, 0.09164730109607677, 0.09164730109607677, 0.09164730109607677, 0.1426845207110049, 0.1426845207110049, 0.1426845207110049, 0.8394893036317131, 0.8394893036317131, 0.8394893036317131, 0.9050320430160138, 0.9050320430160138, 0.9050320430160138, 0.8257596030986957, 0.8257596030986957, 0.8257596030986957, 0.5432806076541092, 0.5432806076541092, 0.5432806076541092, 0.5180855849458038, 0.5180855849458038, 0.5180855849458038, 0.47556808265174233, 0.47556808265174233, 0.47556808265174233, 0.3562281617595303, 0.3562281617595303, 0.3562281617595303, 0.1904070287388001, 0.1904070287388001, 0.1904070287388001, 0.21957690337039293, 0.21957690337039293, 0.21957690337039293, 0.12319410570590295, 0.12319410570590295, 0.12319410570590295, 0.12676011362150297, 0.12676011362150297, 0.12676011362150297, 0.19173557433308674, 0.19173557433308674, 0.19173557433308674, 0.12661185372742656, 0.12661185372742656, 0.12661185372742656, 0.18057762773832453, 0.18057762773832453, 0.18057762773832453, 0.12320981487595217, 0.12320981487595217, 0.12320981487595217, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07181748092987306, 0.07181748092987306, 0.07181748092987306, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13197736791869175, 0.13197736791869175, 0.13197736791869175, 0.08533121865405224, 0.08533121865405224, 0.08533121865405224, 0.19276671446205662, 0.19276671446205662, 0.19276671446205662, 0.050693507066835064, 0.050693507066835064, 0.050693507066835064, 0.09290257786474798, 0.09290257786474798, 0.09290257786474798, 0.09191604256760455, 0.09191604256760455, 0.09191604256760455, 0.1581655168509828, 0.1581655168509828, 0.1581655168509828, 0.2527462246062804, 0.2527462246062804, 0.2527462246062804, 0.16967238793222805, 0.16967238793222805, 0.16967238793222805, 0.481405223988674, 0.481405223988674, 0.481405223988674, 0.5049523704924486, 0.5049523704924486, 0.5049523704924486, 0.5327218932157378, 0.5327218932157378, 0.5327218932157378, 0.1104346182832352, 0.1104346182832352, 0.1104346182832352, 0.11219570094268205, 0.11219570094268205, 0.11219570094268205, 0.11770518443175393, 0.11770518443175393, 0.11770518443175393, 0.21256030739752163, 0.21256030739752163, 0.21256030739752163, 0.2071569656942277, 0.2071569656942277, 0.2071569656942277, 0.24753727415708626, 0.24753727415708626, 0.24753727415708626, 0.2952099837474217, 0.2952099837474217, 0.2952099837474217, 0.2995149209949226, 0.2995149209949226, 0.2995149209949226, 0.24276307590194113, 0.24276307590194113, 0.24276307590194113, 0.19121301424032222, 0.19121301424032222, 0.19121301424032222, 0.39946819442594783, 0.39946819442594783, 0.39946819442594783, 0.2246651266802674, 0.2246651266802674, 0.2246651266802674, 0.2542238815824418, 0.2542238815824418, 0.2542238815824418, 0.21309331963536182, 0.21309331963536182, 0.21309331963536182, 0.24389161422538408, 0.24389161422538408, 0.24389161422538408, 0.2228758392891742, 0.2228758392891742, 0.2228758392891742, 0.18104711057107847, 0.18104711057107847, 0.18104711057107847, 0.21726839654512276, 0.21726839654512276, 0.21726839654512276, 0.8594507085632304, 0.8594507085632304, 0.8594507085632304, 0.7267879025138007, 0.7267879025138007, 0.7267879025138007, 0.8148409501121792, 0.8148409501121792, 0.8148409501121792, 0.4898652786968749, 0.4898652786968749, 0.4898652786968749, 0.20722524202947257, 0.20722524202947257, 0.20722524202947257, 0.6238403996744857, 0.6238403996744857, 0.6238403996744857, 0.1918783958498027, 0.1918783958498027, 0.1918783958498027, 0.18689021091610758, 0.18689021091610758, 0.18689021091610758, 0.20445573809793494, 0.20445573809793494, 0.20445573809793494, 0.09182928468238494, 0.09182928468238494, 0.09182928468238494, 0.09745908361824296, 0.09745908361824296, 0.09745908361824296, 0.07982557976527882, 0.07982557976527882, 0.07982557976527882]}, "mutation_prompt": null}
{"id": "d73449f7-249f-4b92-a1a8-fcdf90d87068", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer_V2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50  # Reduced size for faster convergence\n        self.mutation_factor = 0.9  # Increased to enhance diversity\n        self.crossover_prob = 0.85  # Slightly increased for better exploration\n        self.inertia_weight = 0.5  # Adjusted for faster convergence\n        self.cognitive_coeff = 1.8  # Tweaked for more localized search\n        self.social_coeff = 1.5  # Reduced to balance global influence\n        self.dynamic_adjustment_freq = 5  # More frequent adjustments\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.90  # Faster reduction for inertia\n                self.mutation_factor = 0.88 if iteration < self.budget // 2 else 0.75  # Adaptive mutation enhancement\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            velocities = np.clip(velocities, -0.7, 0.7)  # Adjusted velocity limits to promote exploration\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer_V2", "description": "Improved dynamic adjustment and exploitation with adaptive learning rate and enhanced diversity.", "configspace": "", "generation": 91, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "850e303a-9b38-47cc-a32b-d6efdf1acdab", "metadata": {"aucs": [0.8396044719036575, 0.8396044719036575, 0.8396044719036575, 0.8198586127047862, 0.8198586127047862, 0.8198586127047862, 0.8368415781417637, 0.8368415781417637, 0.8368415781417637, 0.6891100940471951, 0.6891100940471951, 0.6891100940471951, 0.6705281974203544, 0.6705281974203544, 0.6705281974203544, 0.6506388267389893, 0.6506388267389893, 0.6506388267389893, 0.13724355661302512, 0.13724355661302512, 0.13724355661302512, 0.5490019155261059, 0.5490019155261059, 0.5490019155261059, 0.13461988883189258, 0.13461988883189258, 0.13461988883189258, 0.10234499528814955, 0.10234499528814955, 0.10234499528814955, 0.11271235651904721, 0.11271235651904721, 0.11271235651904721, 0.11728844415504025, 0.11728844415504025, 0.11728844415504025, 0.9087334982994018, 0.9087334982994018, 0.9087334982994018, 0.8939270954135277, 0.8939270954135277, 0.8939270954135277, 0.8891830816878267, 0.8891830816878267, 0.8891830816878267, 0.6251575910018332, 0.6251575910018332, 0.6251575910018332, 0.5937865277153052, 0.5937865277153052, 0.5937865277153052, 0.599934457373321, 0.599934457373321, 0.599934457373321, 0.6708362262017533, 0.6708362262017533, 0.6708362262017533, 0.8467058153458593, 0.8467058153458593, 0.8467058153458593, 0.22914760842275328, 0.22914760842275328, 0.22914760842275328, 0.18889045298701534, 0.18889045298701534, 0.18889045298701534, 0.19881957741658962, 0.19881957741658962, 0.19881957741658962, 0.3914827549041269, 0.3914827549041269, 0.3914827549041269, 0.2222416991056998, 0.2222416991056998, 0.2222416991056998, 0.2051044619404888, 0.2051044619404888, 0.2051044619404888, 0.20064106699402184, 0.20064106699402184, 0.20064106699402184, 0.04142762923291998, 0.04142762923291998, 0.04142762923291998, 0.060148210548633285, 0.060148210548633285, 0.060148210548633285, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.15381373907129914, 0.15381373907129914, 0.15381373907129914, 0.09289561537631374, 0.09289561537631374, 0.09289561537631374, 0.17281492526298914, 0.17281492526298914, 0.17281492526298914, 0.07847885967241852, 0.07847885967241852, 0.07847885967241852, 0.07746487350068543, 0.07746487350068543, 0.07746487350068543, 0.1121195270696238, 0.1121195270696238, 0.1121195270696238, 0.1215284646730086, 0.1215284646730086, 0.1215284646730086, 0.0887051187616833, 0.0887051187616833, 0.0887051187616833, 0.07815744015654813, 0.07815744015654813, 0.07815744015654813, 0.5221091906932726, 0.5221091906932726, 0.5221091906932726, 0.5282806887159686, 0.5282806887159686, 0.5282806887159686, 0.5389227789221347, 0.5389227789221347, 0.5389227789221347, 0.0783573744311361, 0.0783573744311361, 0.0783573744311361, 0.14781218071869096, 0.14781218071869096, 0.14781218071869096, 0.1049205968943594, 0.1049205968943594, 0.1049205968943594, 0.2220581768034796, 0.2220581768034796, 0.2220581768034796, 0.17391417519321128, 0.17391417519321128, 0.17391417519321128, 0.2128241683018719, 0.2128241683018719, 0.2128241683018719, 0.2699827487500739, 0.2699827487500739, 0.2699827487500739, 0.36220118633434484, 0.36220118633434484, 0.36220118633434484, 0.44120584649788275, 0.44120584649788275, 0.44120584649788275, 0.2328894961038569, 0.2328894961038569, 0.2328894961038569, 0.2585203061741802, 0.2585203061741802, 0.2585203061741802, 0.23387965611305628, 0.23387965611305628, 0.23387965611305628, 0.23092139879740547, 0.23092139879740547, 0.23092139879740547, 0.24876409485733864, 0.24876409485733864, 0.24876409485733864, 0.2500442967333115, 0.2500442967333115, 0.2500442967333115, 0.2174260166976424, 0.2174260166976424, 0.2174260166976424, 0.21748770605187218, 0.21748770605187218, 0.21748770605187218, 0.22169851466969004, 0.22169851466969004, 0.22169851466969004, 0.8943106534698957, 0.8943106534698957, 0.8943106534698957, 0.8469362433168687, 0.8469362433168687, 0.8469362433168687, 0.8409411394632338, 0.8409411394632338, 0.8409411394632338, 0.15388447509826852, 0.15388447509826852, 0.15388447509826852, 0.20831507884829148, 0.20831507884829148, 0.20831507884829148, 0.7049388305277102, 0.7049388305277102, 0.7049388305277102, 0.20394142836437112, 0.20394142836437112, 0.20394142836437112, 0.1933799584959648, 0.1933799584959648, 0.1933799584959648, 0.19662842650221257, 0.19662842650221257, 0.19662842650221257, 0.09983014341114471, 0.09983014341114471, 0.09983014341114471, 0.10137548395111262, 0.10137548395111262, 0.10137548395111262, 0.08165808189334911, 0.08165808189334911, 0.08165808189334911]}, "mutation_prompt": null}
{"id": "a57ff031-102d-426e-8b0a-053d8cb3cc0b", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer_V2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50  # Reduced size for faster convergence\n        self.mutation_factor = 0.9  # Increased to enhance diversity\n        self.crossover_prob = 0.85  # Slightly increased for better exploration\n        self.inertia_weight = 0.5  # Adjusted for faster convergence\n        self.cognitive_coeff = 1.8  # Tweaked for more localized search\n        self.social_coeff = 1.5  # Reduced to balance global influence\n        self.dynamic_adjustment_freq = 5  # More frequent adjustments\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.90  # Faster reduction for inertia\n                self.mutation_factor = 0.88 if iteration < self.budget // 2 else 0.75  # Adaptive mutation enhancement\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            velocities = np.clip(velocities, -0.7, 0.7)  # Adjusted velocity limits to promote exploration\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer_V2", "description": "Improved dynamic adjustment and exploitation with adaptive learning rate and enhanced diversity.", "configspace": "", "generation": 91, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "850e303a-9b38-47cc-a32b-d6efdf1acdab", "metadata": {"aucs": [0.8396044719036575, 0.8396044719036575, 0.8396044719036575, 0.8198586127047862, 0.8198586127047862, 0.8198586127047862, 0.8368415781417637, 0.8368415781417637, 0.8368415781417637, 0.6891100940471951, 0.6891100940471951, 0.6891100940471951, 0.6705281974203544, 0.6705281974203544, 0.6705281974203544, 0.6506388267389893, 0.6506388267389893, 0.6506388267389893, 0.13724355661302512, 0.13724355661302512, 0.13724355661302512, 0.5490019155261059, 0.5490019155261059, 0.5490019155261059, 0.13461988883189258, 0.13461988883189258, 0.13461988883189258, 0.10234499528814955, 0.10234499528814955, 0.10234499528814955, 0.11271235651904721, 0.11271235651904721, 0.11271235651904721, 0.11728844415504025, 0.11728844415504025, 0.11728844415504025, 0.9087334982994018, 0.9087334982994018, 0.9087334982994018, 0.8939270954135277, 0.8939270954135277, 0.8939270954135277, 0.8891830816878267, 0.8891830816878267, 0.8891830816878267, 0.6251575910018332, 0.6251575910018332, 0.6251575910018332, 0.5937865277153052, 0.5937865277153052, 0.5937865277153052, 0.599934457373321, 0.599934457373321, 0.599934457373321, 0.6708362262017533, 0.6708362262017533, 0.6708362262017533, 0.8467058153458593, 0.8467058153458593, 0.8467058153458593, 0.22914760842275328, 0.22914760842275328, 0.22914760842275328, 0.18889045298701534, 0.18889045298701534, 0.18889045298701534, 0.19881957741658962, 0.19881957741658962, 0.19881957741658962, 0.3914827549041269, 0.3914827549041269, 0.3914827549041269, 0.2222416991056998, 0.2222416991056998, 0.2222416991056998, 0.2051044619404888, 0.2051044619404888, 0.2051044619404888, 0.20064106699402184, 0.20064106699402184, 0.20064106699402184, 0.04142762923291998, 0.04142762923291998, 0.04142762923291998, 0.060148210548633285, 0.060148210548633285, 0.060148210548633285, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.15381373907129914, 0.15381373907129914, 0.15381373907129914, 0.09289561537631374, 0.09289561537631374, 0.09289561537631374, 0.17281492526298914, 0.17281492526298914, 0.17281492526298914, 0.07847885967241852, 0.07847885967241852, 0.07847885967241852, 0.07746487350068543, 0.07746487350068543, 0.07746487350068543, 0.1121195270696238, 0.1121195270696238, 0.1121195270696238, 0.1215284646730086, 0.1215284646730086, 0.1215284646730086, 0.0887051187616833, 0.0887051187616833, 0.0887051187616833, 0.07815744015654813, 0.07815744015654813, 0.07815744015654813, 0.5221091906932726, 0.5221091906932726, 0.5221091906932726, 0.5282806887159686, 0.5282806887159686, 0.5282806887159686, 0.5389227789221347, 0.5389227789221347, 0.5389227789221347, 0.0783573744311361, 0.0783573744311361, 0.0783573744311361, 0.14781218071869096, 0.14781218071869096, 0.14781218071869096, 0.1049205968943594, 0.1049205968943594, 0.1049205968943594, 0.2220581768034796, 0.2220581768034796, 0.2220581768034796, 0.17391417519321128, 0.17391417519321128, 0.17391417519321128, 0.2128241683018719, 0.2128241683018719, 0.2128241683018719, 0.2699827487500739, 0.2699827487500739, 0.2699827487500739, 0.36220118633434484, 0.36220118633434484, 0.36220118633434484, 0.44120584649788275, 0.44120584649788275, 0.44120584649788275, 0.2328894961038569, 0.2328894961038569, 0.2328894961038569, 0.2585203061741802, 0.2585203061741802, 0.2585203061741802, 0.23387965611305628, 0.23387965611305628, 0.23387965611305628, 0.23092139879740547, 0.23092139879740547, 0.23092139879740547, 0.24876409485733864, 0.24876409485733864, 0.24876409485733864, 0.2500442967333115, 0.2500442967333115, 0.2500442967333115, 0.2174260166976424, 0.2174260166976424, 0.2174260166976424, 0.21748770605187218, 0.21748770605187218, 0.21748770605187218, 0.22169851466969004, 0.22169851466969004, 0.22169851466969004, 0.8943106534698957, 0.8943106534698957, 0.8943106534698957, 0.8469362433168687, 0.8469362433168687, 0.8469362433168687, 0.8409411394632338, 0.8409411394632338, 0.8409411394632338, 0.15388447509826852, 0.15388447509826852, 0.15388447509826852, 0.20831507884829148, 0.20831507884829148, 0.20831507884829148, 0.7049388305277102, 0.7049388305277102, 0.7049388305277102, 0.20394142836437112, 0.20394142836437112, 0.20394142836437112, 0.1933799584959648, 0.1933799584959648, 0.1933799584959648, 0.19662842650221257, 0.19662842650221257, 0.19662842650221257, 0.09983014341114471, 0.09983014341114471, 0.09983014341114471, 0.10137548395111262, 0.10137548395111262, 0.10137548395111262, 0.08165808189334911, 0.08165808189334911, 0.08165808189334911]}, "mutation_prompt": null}
{"id": "d58f94dc-d82c-43ec-b713-2b03662c563f", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer_V2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50  # Reduced size for faster convergence\n        self.mutation_factor = 0.9  # Increased to enhance diversity\n        self.crossover_prob = 0.85  # Slightly increased for better exploration\n        self.inertia_weight = 0.5  # Adjusted for faster convergence\n        self.cognitive_coeff = 1.8  # Tweaked for more localized search\n        self.social_coeff = 1.5  # Reduced to balance global influence\n        self.dynamic_adjustment_freq = 5  # More frequent adjustments\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.90  # Faster reduction for inertia\n                self.mutation_factor = 0.88 if iteration < self.budget // 2 else 0.75  # Adaptive mutation enhancement\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            velocities = np.clip(velocities, -0.7, 0.7)  # Adjusted velocity limits to promote exploration\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer_V2", "description": "Improved dynamic adjustment and exploitation with adaptive learning rate and enhanced diversity.", "configspace": "", "generation": 91, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "850e303a-9b38-47cc-a32b-d6efdf1acdab", "metadata": {"aucs": [0.8396044719036575, 0.8396044719036575, 0.8396044719036575, 0.8198586127047862, 0.8198586127047862, 0.8198586127047862, 0.8368415781417637, 0.8368415781417637, 0.8368415781417637, 0.6891100940471951, 0.6891100940471951, 0.6891100940471951, 0.6705281974203544, 0.6705281974203544, 0.6705281974203544, 0.6506388267389893, 0.6506388267389893, 0.6506388267389893, 0.13724355661302512, 0.13724355661302512, 0.13724355661302512, 0.5490019155261059, 0.5490019155261059, 0.5490019155261059, 0.13461988883189258, 0.13461988883189258, 0.13461988883189258, 0.10234499528814955, 0.10234499528814955, 0.10234499528814955, 0.11271235651904721, 0.11271235651904721, 0.11271235651904721, 0.11728844415504025, 0.11728844415504025, 0.11728844415504025, 0.9087334982994018, 0.9087334982994018, 0.9087334982994018, 0.8939270954135277, 0.8939270954135277, 0.8939270954135277, 0.8891830816878267, 0.8891830816878267, 0.8891830816878267, 0.6251575910018332, 0.6251575910018332, 0.6251575910018332, 0.5937865277153052, 0.5937865277153052, 0.5937865277153052, 0.599934457373321, 0.599934457373321, 0.599934457373321, 0.6708362262017533, 0.6708362262017533, 0.6708362262017533, 0.8467058153458593, 0.8467058153458593, 0.8467058153458593, 0.22914760842275328, 0.22914760842275328, 0.22914760842275328, 0.18889045298701534, 0.18889045298701534, 0.18889045298701534, 0.19881957741658962, 0.19881957741658962, 0.19881957741658962, 0.3914827549041269, 0.3914827549041269, 0.3914827549041269, 0.2222416991056998, 0.2222416991056998, 0.2222416991056998, 0.2051044619404888, 0.2051044619404888, 0.2051044619404888, 0.20064106699402184, 0.20064106699402184, 0.20064106699402184, 0.04142762923291998, 0.04142762923291998, 0.04142762923291998, 0.060148210548633285, 0.060148210548633285, 0.060148210548633285, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.15381373907129914, 0.15381373907129914, 0.15381373907129914, 0.09289561537631374, 0.09289561537631374, 0.09289561537631374, 0.17281492526298914, 0.17281492526298914, 0.17281492526298914, 0.07847885967241852, 0.07847885967241852, 0.07847885967241852, 0.07746487350068543, 0.07746487350068543, 0.07746487350068543, 0.1121195270696238, 0.1121195270696238, 0.1121195270696238, 0.1215284646730086, 0.1215284646730086, 0.1215284646730086, 0.0887051187616833, 0.0887051187616833, 0.0887051187616833, 0.07815744015654813, 0.07815744015654813, 0.07815744015654813, 0.5221091906932726, 0.5221091906932726, 0.5221091906932726, 0.5282806887159686, 0.5282806887159686, 0.5282806887159686, 0.5389227789221347, 0.5389227789221347, 0.5389227789221347, 0.0783573744311361, 0.0783573744311361, 0.0783573744311361, 0.14781218071869096, 0.14781218071869096, 0.14781218071869096, 0.1049205968943594, 0.1049205968943594, 0.1049205968943594, 0.2220581768034796, 0.2220581768034796, 0.2220581768034796, 0.17391417519321128, 0.17391417519321128, 0.17391417519321128, 0.2128241683018719, 0.2128241683018719, 0.2128241683018719, 0.2699827487500739, 0.2699827487500739, 0.2699827487500739, 0.36220118633434484, 0.36220118633434484, 0.36220118633434484, 0.44120584649788275, 0.44120584649788275, 0.44120584649788275, 0.2328894961038569, 0.2328894961038569, 0.2328894961038569, 0.2585203061741802, 0.2585203061741802, 0.2585203061741802, 0.23387965611305628, 0.23387965611305628, 0.23387965611305628, 0.23092139879740547, 0.23092139879740547, 0.23092139879740547, 0.24876409485733864, 0.24876409485733864, 0.24876409485733864, 0.2500442967333115, 0.2500442967333115, 0.2500442967333115, 0.2174260166976424, 0.2174260166976424, 0.2174260166976424, 0.21748770605187218, 0.21748770605187218, 0.21748770605187218, 0.22169851466969004, 0.22169851466969004, 0.22169851466969004, 0.8943106534698957, 0.8943106534698957, 0.8943106534698957, 0.8469362433168687, 0.8469362433168687, 0.8469362433168687, 0.8409411394632338, 0.8409411394632338, 0.8409411394632338, 0.15388447509826852, 0.15388447509826852, 0.15388447509826852, 0.20831507884829148, 0.20831507884829148, 0.20831507884829148, 0.7049388305277102, 0.7049388305277102, 0.7049388305277102, 0.20394142836437112, 0.20394142836437112, 0.20394142836437112, 0.1933799584959648, 0.1933799584959648, 0.1933799584959648, 0.19662842650221257, 0.19662842650221257, 0.19662842650221257, 0.09983014341114471, 0.09983014341114471, 0.09983014341114471, 0.10137548395111262, 0.10137548395111262, 0.10137548395111262, 0.08165808189334911, 0.08165808189334911, 0.08165808189334911]}, "mutation_prompt": null}
{"id": "fbaea451-8eeb-4227-8b80-147552a3f061", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer_V2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50  # Reduced size for faster convergence\n        self.mutation_factor = 0.9  # Increased to enhance diversity\n        self.crossover_prob = 0.85  # Slightly increased for better exploration\n        self.inertia_weight = 0.5  # Adjusted for faster convergence\n        self.cognitive_coeff = 1.8  # Tweaked for more localized search\n        self.social_coeff = 1.5  # Reduced to balance global influence\n        self.dynamic_adjustment_freq = 5  # More frequent adjustments\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.90  # Faster reduction for inertia\n                self.mutation_factor = 0.88 if iteration < self.budget // 2 else 0.75  # Adaptive mutation enhancement\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            velocities = np.clip(velocities, -0.7, 0.7)  # Adjusted velocity limits to promote exploration\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer_V2", "description": "Improved dynamic adjustment and exploitation with adaptive learning rate and enhanced diversity.", "configspace": "", "generation": 91, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "850e303a-9b38-47cc-a32b-d6efdf1acdab", "metadata": {"aucs": [0.8396044719036575, 0.8396044719036575, 0.8396044719036575, 0.8198586127047862, 0.8198586127047862, 0.8198586127047862, 0.8368415781417637, 0.8368415781417637, 0.8368415781417637, 0.6891100940471951, 0.6891100940471951, 0.6891100940471951, 0.6705281974203544, 0.6705281974203544, 0.6705281974203544, 0.6506388267389893, 0.6506388267389893, 0.6506388267389893, 0.13724355661302512, 0.13724355661302512, 0.13724355661302512, 0.5490019155261059, 0.5490019155261059, 0.5490019155261059, 0.13461988883189258, 0.13461988883189258, 0.13461988883189258, 0.10234499528814955, 0.10234499528814955, 0.10234499528814955, 0.11271235651904721, 0.11271235651904721, 0.11271235651904721, 0.11728844415504025, 0.11728844415504025, 0.11728844415504025, 0.9087334982994018, 0.9087334982994018, 0.9087334982994018, 0.8939270954135277, 0.8939270954135277, 0.8939270954135277, 0.8891830816878267, 0.8891830816878267, 0.8891830816878267, 0.6251575910018332, 0.6251575910018332, 0.6251575910018332, 0.5937865277153052, 0.5937865277153052, 0.5937865277153052, 0.599934457373321, 0.599934457373321, 0.599934457373321, 0.6708362262017533, 0.6708362262017533, 0.6708362262017533, 0.8467058153458593, 0.8467058153458593, 0.8467058153458593, 0.22914760842275328, 0.22914760842275328, 0.22914760842275328, 0.18889045298701534, 0.18889045298701534, 0.18889045298701534, 0.19881957741658962, 0.19881957741658962, 0.19881957741658962, 0.3914827549041269, 0.3914827549041269, 0.3914827549041269, 0.2222416991056998, 0.2222416991056998, 0.2222416991056998, 0.2051044619404888, 0.2051044619404888, 0.2051044619404888, 0.20064106699402184, 0.20064106699402184, 0.20064106699402184, 0.04142762923291998, 0.04142762923291998, 0.04142762923291998, 0.060148210548633285, 0.060148210548633285, 0.060148210548633285, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.15381373907129914, 0.15381373907129914, 0.15381373907129914, 0.09289561537631374, 0.09289561537631374, 0.09289561537631374, 0.17281492526298914, 0.17281492526298914, 0.17281492526298914, 0.07847885967241852, 0.07847885967241852, 0.07847885967241852, 0.07746487350068543, 0.07746487350068543, 0.07746487350068543, 0.1121195270696238, 0.1121195270696238, 0.1121195270696238, 0.1215284646730086, 0.1215284646730086, 0.1215284646730086, 0.0887051187616833, 0.0887051187616833, 0.0887051187616833, 0.07815744015654813, 0.07815744015654813, 0.07815744015654813, 0.5221091906932726, 0.5221091906932726, 0.5221091906932726, 0.5282806887159686, 0.5282806887159686, 0.5282806887159686, 0.5389227789221347, 0.5389227789221347, 0.5389227789221347, 0.0783573744311361, 0.0783573744311361, 0.0783573744311361, 0.14781218071869096, 0.14781218071869096, 0.14781218071869096, 0.1049205968943594, 0.1049205968943594, 0.1049205968943594, 0.2220581768034796, 0.2220581768034796, 0.2220581768034796, 0.17391417519321128, 0.17391417519321128, 0.17391417519321128, 0.2128241683018719, 0.2128241683018719, 0.2128241683018719, 0.2699827487500739, 0.2699827487500739, 0.2699827487500739, 0.36220118633434484, 0.36220118633434484, 0.36220118633434484, 0.44120584649788275, 0.44120584649788275, 0.44120584649788275, 0.2328894961038569, 0.2328894961038569, 0.2328894961038569, 0.2585203061741802, 0.2585203061741802, 0.2585203061741802, 0.23387965611305628, 0.23387965611305628, 0.23387965611305628, 0.23092139879740547, 0.23092139879740547, 0.23092139879740547, 0.24876409485733864, 0.24876409485733864, 0.24876409485733864, 0.2500442967333115, 0.2500442967333115, 0.2500442967333115, 0.2174260166976424, 0.2174260166976424, 0.2174260166976424, 0.21748770605187218, 0.21748770605187218, 0.21748770605187218, 0.22169851466969004, 0.22169851466969004, 0.22169851466969004, 0.8943106534698957, 0.8943106534698957, 0.8943106534698957, 0.8469362433168687, 0.8469362433168687, 0.8469362433168687, 0.8409411394632338, 0.8409411394632338, 0.8409411394632338, 0.15388447509826852, 0.15388447509826852, 0.15388447509826852, 0.20831507884829148, 0.20831507884829148, 0.20831507884829148, 0.7049388305277102, 0.7049388305277102, 0.7049388305277102, 0.20394142836437112, 0.20394142836437112, 0.20394142836437112, 0.1933799584959648, 0.1933799584959648, 0.1933799584959648, 0.19662842650221257, 0.19662842650221257, 0.19662842650221257, 0.09983014341114471, 0.09983014341114471, 0.09983014341114471, 0.10137548395111262, 0.10137548395111262, 0.10137548395111262, 0.08165808189334911, 0.08165808189334911, 0.08165808189334911]}, "mutation_prompt": null}
{"id": "a411ae71-d5de-42f1-89a9-bfc469a0ebed", "solution": "import numpy as np\n\nclass Enhanced_PSO_ADE_Optimizer_V2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 50  # Reduced size for faster convergence\n        self.mutation_factor = 0.9  # Increased to enhance diversity\n        self.crossover_prob = 0.85  # Slightly increased for better exploration\n        self.inertia_weight = 0.5  # Adjusted for faster convergence\n        self.cognitive_coeff = 1.8  # Tweaked for more localized search\n        self.social_coeff = 1.5  # Reduced to balance global influence\n        self.dynamic_adjustment_freq = 5  # More frequent adjustments\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.90  # Faster reduction for inertia\n                self.mutation_factor = 0.88 if iteration < self.budget // 2 else 0.75  # Adaptive mutation enhancement\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            velocities = np.clip(velocities, -0.7, 0.7)  # Adjusted velocity limits to promote exploration\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_PSO_ADE_Optimizer_V2", "description": "Improved dynamic adjustment and exploitation with adaptive learning rate and enhanced diversity.", "configspace": "", "generation": 91, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "850e303a-9b38-47cc-a32b-d6efdf1acdab", "metadata": {"aucs": [0.8396044719036575, 0.8396044719036575, 0.8396044719036575, 0.8198586127047862, 0.8198586127047862, 0.8198586127047862, 0.8368415781417637, 0.8368415781417637, 0.8368415781417637, 0.6891100940471951, 0.6891100940471951, 0.6891100940471951, 0.6705281974203544, 0.6705281974203544, 0.6705281974203544, 0.6506388267389893, 0.6506388267389893, 0.6506388267389893, 0.13724355661302512, 0.13724355661302512, 0.13724355661302512, 0.5490019155261059, 0.5490019155261059, 0.5490019155261059, 0.13461988883189258, 0.13461988883189258, 0.13461988883189258, 0.10234499528814955, 0.10234499528814955, 0.10234499528814955, 0.11271235651904721, 0.11271235651904721, 0.11271235651904721, 0.11728844415504025, 0.11728844415504025, 0.11728844415504025, 0.9087334982994018, 0.9087334982994018, 0.9087334982994018, 0.8939270954135277, 0.8939270954135277, 0.8939270954135277, 0.8891830816878267, 0.8891830816878267, 0.8891830816878267, 0.6251575910018332, 0.6251575910018332, 0.6251575910018332, 0.5937865277153052, 0.5937865277153052, 0.5937865277153052, 0.599934457373321, 0.599934457373321, 0.599934457373321, 0.6708362262017533, 0.6708362262017533, 0.6708362262017533, 0.8467058153458593, 0.8467058153458593, 0.8467058153458593, 0.22914760842275328, 0.22914760842275328, 0.22914760842275328, 0.18889045298701534, 0.18889045298701534, 0.18889045298701534, 0.19881957741658962, 0.19881957741658962, 0.19881957741658962, 0.3914827549041269, 0.3914827549041269, 0.3914827549041269, 0.2222416991056998, 0.2222416991056998, 0.2222416991056998, 0.2051044619404888, 0.2051044619404888, 0.2051044619404888, 0.20064106699402184, 0.20064106699402184, 0.20064106699402184, 0.04142762923291998, 0.04142762923291998, 0.04142762923291998, 0.060148210548633285, 0.060148210548633285, 0.060148210548633285, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.15381373907129914, 0.15381373907129914, 0.15381373907129914, 0.09289561537631374, 0.09289561537631374, 0.09289561537631374, 0.17281492526298914, 0.17281492526298914, 0.17281492526298914, 0.07847885967241852, 0.07847885967241852, 0.07847885967241852, 0.07746487350068543, 0.07746487350068543, 0.07746487350068543, 0.1121195270696238, 0.1121195270696238, 0.1121195270696238, 0.1215284646730086, 0.1215284646730086, 0.1215284646730086, 0.0887051187616833, 0.0887051187616833, 0.0887051187616833, 0.07815744015654813, 0.07815744015654813, 0.07815744015654813, 0.5221091906932726, 0.5221091906932726, 0.5221091906932726, 0.5282806887159686, 0.5282806887159686, 0.5282806887159686, 0.5389227789221347, 0.5389227789221347, 0.5389227789221347, 0.0783573744311361, 0.0783573744311361, 0.0783573744311361, 0.14781218071869096, 0.14781218071869096, 0.14781218071869096, 0.1049205968943594, 0.1049205968943594, 0.1049205968943594, 0.2220581768034796, 0.2220581768034796, 0.2220581768034796, 0.17391417519321128, 0.17391417519321128, 0.17391417519321128, 0.2128241683018719, 0.2128241683018719, 0.2128241683018719, 0.2699827487500739, 0.2699827487500739, 0.2699827487500739, 0.36220118633434484, 0.36220118633434484, 0.36220118633434484, 0.44120584649788275, 0.44120584649788275, 0.44120584649788275, 0.2328894961038569, 0.2328894961038569, 0.2328894961038569, 0.2585203061741802, 0.2585203061741802, 0.2585203061741802, 0.23387965611305628, 0.23387965611305628, 0.23387965611305628, 0.23092139879740547, 0.23092139879740547, 0.23092139879740547, 0.24876409485733864, 0.24876409485733864, 0.24876409485733864, 0.2500442967333115, 0.2500442967333115, 0.2500442967333115, 0.2174260166976424, 0.2174260166976424, 0.2174260166976424, 0.21748770605187218, 0.21748770605187218, 0.21748770605187218, 0.22169851466969004, 0.22169851466969004, 0.22169851466969004, 0.8943106534698957, 0.8943106534698957, 0.8943106534698957, 0.8469362433168687, 0.8469362433168687, 0.8469362433168687, 0.8409411394632338, 0.8409411394632338, 0.8409411394632338, 0.15388447509826852, 0.15388447509826852, 0.15388447509826852, 0.20831507884829148, 0.20831507884829148, 0.20831507884829148, 0.7049388305277102, 0.7049388305277102, 0.7049388305277102, 0.20394142836437112, 0.20394142836437112, 0.20394142836437112, 0.1933799584959648, 0.1933799584959648, 0.1933799584959648, 0.19662842650221257, 0.19662842650221257, 0.19662842650221257, 0.09983014341114471, 0.09983014341114471, 0.09983014341114471, 0.10137548395111262, 0.10137548395111262, 0.10137548395111262, 0.08165808189334911, 0.08165808189334911, 0.08165808189334911]}, "mutation_prompt": null}
{"id": "3c62a76d-659c-423f-9158-ad77c516e60c", "solution": "import numpy as np\n\nclass Enhanced_MultiSwarm_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = 60  # Increased for more diverse solutions\n        self.mutation_factor = 0.85  # Adaptive mutation based on iterations\n        self.crossover_prob = 0.9  # Increased to improve exploration\n        self.inertia_weight = 0.6  # Enhanced inertia for improved balance\n        self.cognitive_coeff = 2.0  # Boosted for better exploitation\n        self.social_coeff = 1.3  # Slightly reduced for balanced search\n        self.dynamic_adjustment_freq = 4  # More frequent adjustments for agility\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, positions)\n            eval_count += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = positions[i]\n\n            if iteration % self.dynamic_adjustment_freq == 0:\n                self.inertia_weight *= 0.92  # Slightly faster reduction\n                self.mutation_factor = 0.82 if iteration < self.budget // 2 else 0.78  # Adaptive mutation adjustment\n\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            velocities = (\n                self.inertia_weight * velocities +\n                self.cognitive_coeff * r1 * (personal_best_positions - positions) +\n                self.social_coeff * r2 * (global_best_position - positions)\n            )\n            velocities = np.clip(velocities, -0.8, 0.8)  # Expanded velocity limits for exploration\n            positions = np.clip(positions + velocities, self.lower_bound, self.upper_bound)\n\n            for i in range(self.swarm_size):\n                indices = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                x0, x1, x2 = positions[indices]\n                mutated_vector = np.clip(x0 + self.mutation_factor * (x1 - x2), self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutated_vector, positions[i])\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n\n        return global_best_position, global_best_score", "name": "Enhanced_MultiSwarm_ADE_Optimizer", "description": "Enhanced multi-swarm dynamics with adaptive parameter tuning for faster convergence.", "configspace": "", "generation": 99, "fitness": 0.3270176321442413, "feedback": "The algorithm Enhanced_MultiSwarm_ADE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.26.", "error": "", "parent_id": "850e303a-9b38-47cc-a32b-d6efdf1acdab", "metadata": {"aucs": [0.8072323588409136, 0.8072323588409136, 0.8072323588409136, 0.7875209845538833, 0.7875209845538833, 0.7875209845538833, 0.7894024586364823, 0.7894024586364823, 0.7894024586364823, 0.6201975684815237, 0.6201975684815237, 0.6201975684815237, 0.5549933515243479, 0.5549933515243479, 0.5549933515243479, 0.5828530334176274, 0.5828530334176274, 0.5828530334176274, 0.4247996065077515, 0.4247996065077515, 0.4247996065077515, 0.16165827261886212, 0.16165827261886212, 0.16165827261886212, 0.14857603439703926, 0.14857603439703926, 0.14857603439703926, 0.1102299731512254, 0.1102299731512254, 0.1102299731512254, 0.11622356779200149, 0.11622356779200149, 0.11622356779200149, 0.10982270809341277, 0.10982270809341277, 0.10982270809341277, 0.8982256163953993, 0.8982256163953993, 0.8982256163953993, 0.8768537413387621, 0.8768537413387621, 0.8768537413387621, 0.8496374051608333, 0.8496374051608333, 0.8496374051608333, 0.547216367264963, 0.547216367264963, 0.547216367264963, 0.4882116713740441, 0.4882116713740441, 0.4882116713740441, 0.4971777688931275, 0.4971777688931275, 0.4971777688931275, 0.22076256802514937, 0.22076256802514937, 0.22076256802514937, 0.20547212449128716, 0.20547212449128716, 0.20547212449128716, 0.7505837643463698, 0.7505837643463698, 0.7505837643463698, 0.22096587313470717, 0.22096587313470717, 0.22096587313470717, 0.18118585430120737, 0.18118585430120737, 0.18118585430120737, 0.17124166535570307, 0.17124166535570307, 0.17124166535570307, 0.21042558368945252, 0.21042558368945252, 0.21042558368945252, 0.219067640050843, 0.219067640050843, 0.219067640050843, 0.20061029041089518, 0.20061029041089518, 0.20061029041089518, 0.03534938072083316, 0.03534938072083316, 0.03534938072083316, 0.03180102772326954, 0.03180102772326954, 0.03180102772326954, 0.042895389956824514, 0.042895389956824514, 0.042895389956824514, 0.07942364028529625, 0.07942364028529625, 0.07942364028529625, 0.05656408129199919, 0.05656408129199919, 0.05656408129199919, 0.14400307067392004, 0.14400307067392004, 0.14400307067392004, 0.09802820482855801, 0.09802820482855801, 0.09802820482855801, 0.07051146244699102, 0.07051146244699102, 0.07051146244699102, 0.11795680952206966, 0.11795680952206966, 0.11795680952206966, 0.13421094239942954, 0.13421094239942954, 0.13421094239942954, 0.11585543776227436, 0.11585543776227436, 0.11585543776227436, 0.0867984829768107, 0.0867984829768107, 0.0867984829768107, 0.5077210600099962, 0.5077210600099962, 0.5077210600099962, 0.5395260296125403, 0.5395260296125403, 0.5395260296125403, 0.5151766857352761, 0.5151766857352761, 0.5151766857352761, 0.11093894729591502, 0.11093894729591502, 0.11093894729591502, 0.11190953922532865, 0.11190953922532865, 0.11190953922532865, 0.16366632686563698, 0.16366632686563698, 0.16366632686563698, 0.18662418169332717, 0.18662418169332717, 0.18662418169332717, 0.261262394750547, 0.261262394750547, 0.261262394750547, 0.18115886648650492, 0.18115886648650492, 0.18115886648650492, 0.3546833301647817, 0.3546833301647817, 0.3546833301647817, 0.5061411547760478, 0.5061411547760478, 0.5061411547760478, 0.295780570386054, 0.295780570386054, 0.295780570386054, 0.18644972164677842, 0.18644972164677842, 0.18644972164677842, 0.2993727243759533, 0.2993727243759533, 0.2993727243759533, 0.2523982542441707, 0.2523982542441707, 0.2523982542441707, 0.23351268866720365, 0.23351268866720365, 0.23351268866720365, 0.2341035257749079, 0.2341035257749079, 0.2341035257749079, 0.22443534009931132, 0.22443534009931132, 0.22443534009931132, 0.2422055600745433, 0.2422055600745433, 0.2422055600745433, 0.21569591073604033, 0.21569591073604033, 0.21569591073604033, 0.2482107306678396, 0.2482107306678396, 0.2482107306678396, 0.8639035714701887, 0.8639035714701887, 0.8639035714701887, 0.7910070766745494, 0.7910070766745494, 0.7910070766745494, 0.8666142890252536, 0.8666142890252536, 0.8666142890252536, 0.6439632634089739, 0.6439632634089739, 0.6439632634089739, 0.20978123970079832, 0.20978123970079832, 0.20978123970079832, 0.664031610029483, 0.664031610029483, 0.664031610029483, 0.17783909839407586, 0.17783909839407586, 0.17783909839407586, 0.18708841586751201, 0.18708841586751201, 0.18708841586751201, 0.1951970854596351, 0.1951970854596351, 0.1951970854596351, 0.1020858757401083, 0.1020858757401083, 0.1020858757401083, 0.10245769975582075, 0.10245769975582075, 0.10245769975582075, 0.10578096273417781, 0.10578096273417781, 0.10578096273417781]}, "mutation_prompt": null}

{"id": "d46e36e5-0a1d-4a2c-bc43-a815e8742e74", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, initial_temp, final_temp, max_iter):\n            # Simulated Annealing implementation\n            pass\n        \n        # Combined PSO-SA optimization\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, self.final_temp, 100)\n        \n        return best_solution", "name": "PSO_SA_Optimizer", "description": "Novel optimization algorithm combining Particle Swarm Optimization (PSO) with Simulated Annealing (SA) for efficient exploration and exploitation in black box optimization problems.", "configspace": "", "generation": 0, "fitness": 0.0, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00 with standard deviation 0.00.", "error": "", "parent_id": null, "metadata": {"aucs": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "mutation_prompt": null}
{"id": "ebf11c61-4296-468c-8f7a-f12c008b3c3a", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, initial_temp, final_temp, max_iter):\n            # Simulated Annealing implementation\n            pass\n        \n        # Combined PSO-SA optimization\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, self.final_temp, 100)\n        \n        return best_solution", "name": "PSO_SA_Optimizer", "description": "Novel optimization algorithm combining Particle Swarm Optimization (PSO) with Simulated Annealing (SA) for efficient exploration and exploitation in black box optimization problems.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d46e36e5-0a1d-4a2c-bc43-a815e8742e74", "metadata": {"aucs": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "mutation_prompt": null}
{"id": "9703d08e-e59b-41dc-b906-02519874d10f", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, initial_temp, final_temp, max_iter):\n            # Simulated Annealing implementation\n            pass\n        \n        # Combined PSO-SA optimization\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, self.final_temp, 100)\n        \n        return best_solution", "name": "PSO_SA_Optimizer", "description": "Novel optimization algorithm combining Particle Swarm Optimization (PSO) with Simulated Annealing (SA) for efficient exploration and exploitation in black box optimization problems.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d46e36e5-0a1d-4a2c-bc43-a815e8742e74", "metadata": {"aucs": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "mutation_prompt": null}
{"id": "8436dc75-7e22-4ad4-8b27-1298afee7116", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, initial_temp, final_temp, max_iter):\n            # Simulated Annealing implementation\n            pass\n        \n        # Combined PSO-SA optimization\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, self.final_temp, 100)\n        \n        return best_solution", "name": "PSO_SA_Optimizer", "description": "Novel optimization algorithm combining Particle Swarm Optimization (PSO) with Simulated Annealing (SA) for efficient exploration and exploitation in black box optimization problems.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d46e36e5-0a1d-4a2c-bc43-a815e8742e74", "metadata": {"aucs": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "mutation_prompt": null}
{"id": "1e56a5bf-3a18-46a5-b96f-19d47c1f5397", "solution": "import numpy as np\n\nclass Improved_PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, initial_temp, final_temp, max_iter):\n            # Simulated Annealing implementation\n            pass\n        \n        # Combined PSO-SA optimization with dynamic exploration-exploitation adjustment\n        best_solution = None\n        for _ in range(self.budget):\n            exploration_ratio = 1.0 - _ / self.budget  # Dynamic adjustment\n            if np.random.rand() < exploration_ratio:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, self.final_temp, 100)\n        \n        return best_solution", "name": "Improved_PSO_SA_Optimizer", "description": "Improved PSO-SA Optimizer by dynamically adjusting exploration-exploitation ratio for faster convergence.", "configspace": "", "generation": 4, "fitness": 0.0, "feedback": "The algorithm Improved_PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00 with standard deviation 0.00.", "error": "", "parent_id": "d46e36e5-0a1d-4a2c-bc43-a815e8742e74", "metadata": {"aucs": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "mutation_prompt": null}
{"id": "e4fbab5f-3448-4923-8c53-91f3c2b07bd4", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, initial_temp, final_temp, max_iter):\n            # Simulated Annealing implementation\n            pass\n        \n        # Combined PSO-SA optimization\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, self.final_temp, 100)\n        \n        return best_solution", "name": "PSO_SA_Optimizer", "description": "Novel optimization algorithm combining Particle Swarm Optimization (PSO) with Simulated Annealing (SA) for efficient exploration and exploitation in black box optimization problems.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d46e36e5-0a1d-4a2c-bc43-a815e8742e74", "metadata": {"aucs": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "mutation_prompt": null}
{"id": "a0e07276-a957-43cb-b86d-0d7a343d2619", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, initial_temp, final_temp, max_iter):\n            # Simulated Annealing implementation\n            pass\n        \n        # Combined PSO-SA optimization\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, self.final_temp, 100)\n        \n        return best_solution", "name": "PSO_SA_Optimizer", "description": "Novel optimization algorithm combining Particle Swarm Optimization (PSO) with Simulated Annealing (SA) for efficient exploration and exploitation in black box optimization problems.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d46e36e5-0a1d-4a2c-bc43-a815e8742e74", "metadata": {"aucs": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "mutation_prompt": null}
{"id": "bd78833b-ac7d-45b5-92a4-133585edadb0", "solution": "import numpy as np\n\nclass Enhanced_PSO_SA_Optimizer(PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, mutation_prob=0.2):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp)\n        self.mutation_prob = mutation_prob\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter, mutation_prob):\n            # Enhanced Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, initial_temp, final_temp, max_iter, mutation_prob):\n            # Enhanced Simulated Annealing implementation\n            pass\n        \n        # Combined Enhanced PSO-SA optimization with adaptive mutation\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < self.mutation_prob:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100, self.mutation_prob)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, self.final_temp, 100, self.mutation_prob)\n        \n        return best_solution", "name": "Enhanced_PSO_SA_Optimizer", "description": "Enhanced PSO-SA Optimizer with adaptive mutation probability to dynamically adjust the exploration-exploitation balance, boosting convergence speed while maintaining the core hybrid PSO-SA framework.", "configspace": "", "generation": 7, "fitness": 0.0, "feedback": "The algorithm Enhanced_PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00 with standard deviation 0.00.", "error": "", "parent_id": "d46e36e5-0a1d-4a2c-bc43-a815e8742e74", "metadata": {"aucs": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "mutation_prompt": null}
{"id": "432a5602-be3e-443c-a98d-c33f0df36bd7", "solution": "import numpy as np\n\nclass Improved_PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Dynamically adjust max_iter based on performance feedback\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, initial_temp, final_temp, max_iter):\n            # Dynamically adjust max_iter based on performance feedback\n            pass\n        \n        # Combined PSO-SA optimization with dynamic iteration adjustment\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)  # Adjusted max_iter\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, self.final_temp, 100)  # Adjusted max_iter\n        \n        return best_solution", "name": "Improved_PSO_SA_Optimizer", "description": "Improved PSO_SA_Optimizer by dynamically adjusting the number of iterations for each optimization method based on performance feedback.", "configspace": "", "generation": 8, "fitness": 0.0, "feedback": "The algorithm Improved_PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00 with standard deviation 0.00.", "error": "", "parent_id": "d46e36e5-0a1d-4a2c-bc43-a815e8742e74", "metadata": {"aucs": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "mutation_prompt": null}
{"id": "173ef690-7522-4f08-ac42-f47abed49b4d", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, initial_temp, final_temp, max_iter):\n            # Simulated Annealing implementation\n            pass\n        \n        # Combined PSO-SA optimization\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, self.final_temp, 100)\n        \n        return best_solution", "name": "PSO_SA_Optimizer", "description": "Novel optimization algorithm combining Particle Swarm Optimization (PSO) with Simulated Annealing (SA) for efficient exploration and exploitation in black box optimization problems.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d46e36e5-0a1d-4a2c-bc43-a815e8742e74", "metadata": {"aucs": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "mutation_prompt": null}
{"id": "8b99a292-9161-4c9e-af9e-bc20efeb143a", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, initial_temp, final_temp, max_iter):\n            # Simulated Annealing implementation\n            pass\n        \n        # Combined PSO-SA optimization\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, self.final_temp, 100)\n        \n        return best_solution", "name": "PSO_SA_Optimizer", "description": "Novel optimization algorithm combining Particle Swarm Optimization (PSO) with Simulated Annealing (SA) for efficient exploration and exploitation in black box optimization problems.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d46e36e5-0a1d-4a2c-bc43-a815e8742e74", "metadata": {"aucs": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "mutation_prompt": null}
{"id": "6df51326-819b-42b0-9bab-8f90b543d910", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, initial_temp, final_temp, max_iter):\n            # Simulated Annealing implementation\n            pass\n        \n        # Combined PSO-SA optimization\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, self.final_temp, 100)\n        \n        return best_solution", "name": "PSO_SA_Optimizer", "description": "Novel optimization algorithm combining Particle Swarm Optimization (PSO) with Simulated Annealing (SA) for efficient exploration and exploitation in black box optimization problems.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d46e36e5-0a1d-4a2c-bc43-a815e8742e74", "metadata": {"aucs": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "mutation_prompt": null}
{"id": "f0b13d6d-6032-4ff9-add8-d1d00f187b17", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, initial_temp, final_temp, max_iter):\n            # Simulated Annealing implementation\n            pass\n        \n        # Combined PSO-SA optimization\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, self.final_temp, 100)\n        \n        return best_solution", "name": "PSO_SA_Optimizer", "description": "Novel optimization algorithm combining Particle Swarm Optimization (PSO) with Simulated Annealing (SA) for efficient exploration and exploitation in black box optimization problems.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d46e36e5-0a1d-4a2c-bc43-a815e8742e74", "metadata": {"aucs": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "mutation_prompt": null}
{"id": "51c34e13-bd41-4972-8df6-5ccc0c830080", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, initial_temp, final_temp, max_iter):\n            # Simulated Annealing implementation\n            pass\n        \n        # Combined PSO-SA optimization\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, self.final_temp, 100)\n        \n        return best_solution", "name": "PSO_SA_Optimizer", "description": "Novel optimization algorithm combining Particle Swarm Optimization (PSO) with Simulated Annealing (SA) for efficient exploration and exploitation in black box optimization problems.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d46e36e5-0a1d-4a2c-bc43-a815e8742e74", "metadata": {"aucs": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "mutation_prompt": null}
{"id": "afe64a1e-98c7-4807-86cb-9a42a1e9a8c8", "solution": "import numpy as np\n\nclass Improved_PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, initial_temp, final_temp, max_iter):\n            # Improved Simulated Annealing with dynamically adjusting temperature schedule\n            temp = self.initial_temp\n            for _ in range(max_iter):\n                acceptance_probability = np.exp((obj_func(final_temp) - obj_func(initial_temp)) / temp)\n                if acceptance_probability > np.random.rand():\n                    current_temp = temp\n            pass\n        \n        # Combined PSO-SA optimization with improved SA\n        best_solution = None\n        for i in range(self.budget):\n            if i / self.budget < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, self.final_temp, 100)\n        \n        return best_solution", "name": "Improved_PSO_SA_Optimizer", "description": "Improved convergence speed by dynamically adjusting the temperature schedule in Simulated Annealing based on the budget percentage to explore the search space more efficiently.", "configspace": "", "generation": 14, "fitness": -Infinity, "feedback": "An exception occurred: TypeError('__call__(): incompatible function arguments. The following argument types are supported:\\n    1. (self: ioh.iohcpp.problem.RealSingleObjective, arg0: List[float]) -> float\\n    2. (self: ioh.iohcpp.problem.RealSingleObjective, arg0: List[List[float]]) -> List[float]\\n\\nInvoked with: <RealSingleObjectiveProblem 1. Sphere (iid=1 dim=5)>, 0.1').", "error": "TypeError('__call__(): incompatible function arguments. The following argument types are supported:\\n    1. (self: ioh.iohcpp.problem.RealSingleObjective, arg0: List[float]) -> float\\n    2. (self: ioh.iohcpp.problem.RealSingleObjective, arg0: List[List[float]]) -> List[float]\\n\\nInvoked with: <RealSingleObjectiveProblem 1. Sphere (iid=1 dim=5)>, 0.1')", "parent_id": "d46e36e5-0a1d-4a2c-bc43-a815e8742e74", "metadata": {}, "mutation_prompt": null}
{"id": "8fc6ba2f-1b70-4ec1-aa40-9ab8abf5b07c", "solution": "import numpy as np\n\nclass DynamicPopSize_PSO_SA_Optimizer:\n    def __init__(self, budget, dim, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation with adaptive population size\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, initial_temp, final_temp, max_iter):\n            # Simulated Annealing implementation\n            pass\n        \n        # Combined PSO-SA optimization with dynamic population sizing\n        population_sizes = np.linspace(10, 50, self.budget)  # Dynamic population size based on function evaluations\n        best_solution = None\n        for num_particles in population_sizes:\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, int(num_particles), 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, self.final_temp, 100)\n        \n        return best_solution", "name": "DynamicPopSize_PSO_SA_Optimizer", "description": "Enhanced PSO_SA_Optimizer by dynamically adjusting the population size based on function evaluations to improve convergence speed.", "configspace": "", "generation": 15, "fitness": 0.0, "feedback": "The algorithm DynamicPopSize_PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00 with standard deviation 0.00.", "error": "", "parent_id": "d46e36e5-0a1d-4a2c-bc43-a815e8742e74", "metadata": {"aucs": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "mutation_prompt": null}
{"id": "5765ae7d-5635-401e-bfd7-ed7e3e39e34f", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, initial_temp, final_temp, max_iter):\n            # Simulated Annealing implementation\n            pass\n        \n        # Combined PSO-SA optimization\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, self.final_temp, 100)\n        \n        return best_solution", "name": "PSO_SA_Optimizer", "description": "Novel optimization algorithm combining Particle Swarm Optimization (PSO) with Simulated Annealing (SA) for efficient exploration and exploitation in black box optimization problems.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d46e36e5-0a1d-4a2c-bc43-a815e8742e74", "metadata": {"aucs": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "mutation_prompt": null}
{"id": "98e4c766-500a-4454-8843-cc6a9744ca6f", "solution": "import numpy as np\n\nclass Enhanced_PSO_SA_Optimizer:\n    def __init__(self, budget, dim, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, initial_temp, final_temp, max_iter):\n            # Simulated Annealing implementation\n            pass\n        \n        # Combined PSO-SA optimization with dynamic particle adjustment\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                num_particles = 30 if func.__name__ == \"griewank\" else 50\n                best_solution = pso_optimize(func, -5.0, 5.0, num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, self.final_temp, 100)\n        \n        return best_solution", "name": "Enhanced_PSO_SA_Optimizer", "description": "Enhanced PSO_SA_Optimizer algorithm by dynamically adjusting the number of particles based on function landscape to improve convergence speed.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"'ioh.iohcpp.problem.Sphere' object has no attribute '__name__'\").", "error": "AttributeError(\"'ioh.iohcpp.problem.Sphere' object has no attribute '__name__'\")", "parent_id": "d46e36e5-0a1d-4a2c-bc43-a815e8742e74", "metadata": {}, "mutation_prompt": null}
{"id": "ce3f8e12-c8f8-433e-a9a9-4b959ae002cd", "solution": "import numpy as np\n\nclass Enhanced_PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Enhanced Particle Swarm Optimization with adaptive parameters\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, initial_temp, final_temp, max_iter):\n            # Enhanced Simulated Annealing with adaptive parameters\n            pass\n        \n        # Combined PSO-SA optimization with improved convergence speed\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 50)  # Faster convergence by decreasing max_iter\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, self.final_temp, 50)  # Faster convergence by decreasing max_iter\n        \n        return best_solution", "name": "Enhanced_PSO_SA_Optimizer", "description": "Enhanced PSO-SA hybrid optimizer with adaptive control parameters to improve convergence speed while maintaining exploration and exploitation balance.", "configspace": "", "generation": 18, "fitness": 0.0, "feedback": "The algorithm Enhanced_PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00 with standard deviation 0.00.", "error": "", "parent_id": "d46e36e5-0a1d-4a2c-bc43-a815e8742e74", "metadata": {"aucs": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "mutation_prompt": null}
{"id": "eb2b9ec1-436b-4872-93d0-af05fb06f174", "solution": "import numpy as np\n\nclass Dynamic_PSOSA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, initial_temp, final_temp, max_iter):\n            # Simulated Annealing implementation\n            pass\n        \n        # Combined PSO-SA optimization with dynamic ratio adjustment\n        best_solution = None\n        exploration_rate = 0.5\n        for _ in range(self.budget):\n            if np.random.rand() < exploration_rate:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, self.final_temp, 100)\n            # Adjust the exploration rate based on remaining budget\n            exploration_rate = max(0.1, 0.5 - 0.4 * _ / self.budget)\n        \n        return best_solution", "name": "Dynamic_PSOSA_Optimizer", "description": "Improved convergence speed by dynamically adjusting the exploration-exploitation ratio based on function evaluations.", "configspace": "", "generation": 19, "fitness": 0.0, "feedback": "The algorithm Dynamic_PSOSA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00 with standard deviation 0.00.", "error": "", "parent_id": "d46e36e5-0a1d-4a2c-bc43-a815e8742e74", "metadata": {"aucs": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "mutation_prompt": null}
{"id": "35777dbb-a28d-49af-9314-305f343917f1", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, initial_temp, final_temp, max_iter):\n            # Simulated Annealing implementation\n            pass\n        \n        # Combined PSO-SA optimization\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, self.final_temp, 100)\n        \n        return best_solution", "name": "PSO_SA_Optimizer", "description": "Novel optimization algorithm combining Particle Swarm Optimization (PSO) with Simulated Annealing (SA) for efficient exploration and exploitation in black box optimization problems.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d46e36e5-0a1d-4a2c-bc43-a815e8742e74", "metadata": {"aucs": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "mutation_prompt": null}
{"id": "a313a52f-95e1-4846-b6c1-8708420c308b", "solution": "import numpy as np\n\nclass Improved_PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, mutation_prob=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n        self.mutation_prob = mutation_prob\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, initial_temp, final_temp, max_iter):\n            # Simulated Annealing implementation\n            pass\n        \n        # Combined PSO-SA optimization with dynamic mutation probability\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < self.mutation_prob:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, self.final_temp, 100)\n            # Adjust mutation probability based on algorithm progress\n            self.mutation_prob = 0.5 * (1 - _ / self.budget)  # Linearly decrease mutation probability\n        \n        return best_solution", "name": "Improved_PSO_SA_Optimizer", "description": "Improved PSO_SA_Optimizer by dynamically adjusting the mutation probability based on the algorithm's progress.", "configspace": "", "generation": 21, "fitness": 0.0, "feedback": "The algorithm Improved_PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00 with standard deviation 0.00.", "error": "", "parent_id": "d46e36e5-0a1d-4a2c-bc43-a815e8742e74", "metadata": {"aucs": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "mutation_prompt": null}
{"id": "bc8909ff-b41c-4669-ab8e-2f0e2eb39f55", "solution": "import numpy as np\n\nclass Improved_PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Enhanced Particle Swarm Optimization implementation with dynamic behavior\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, initial_temp, final_temp, max_iter):\n            # Enhanced Simulated Annealing implementation with dynamic behavior\n            pass\n        \n        # Combined PSO-SA optimization with dynamic behavior adjustment\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:  # Adjusted selection based on fitness feedback\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, self.final_temp, 100)\n        \n        return best_solution", "name": "Improved_PSO_SA_Optimizer", "description": "Enhancing PSO-SA optimization by dynamically adjusting search behavior based on fitness feedback to accelerate convergence.", "configspace": "", "generation": 22, "fitness": 0.0, "feedback": "The algorithm Improved_PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00 with standard deviation 0.00.", "error": "", "parent_id": "d46e36e5-0a1d-4a2c-bc43-a815e8742e74", "metadata": {"aucs": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "mutation_prompt": null}
{"id": "92854b71-fdba-451d-a2da-f2690a8e7312", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, initial_temp, final_temp, max_iter):\n            # Simulated Annealing implementation\n            pass\n        \n        # Combined PSO-SA optimization\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, self.final_temp, 100)\n        \n        return best_solution", "name": "PSO_SA_Optimizer", "description": "Novel optimization algorithm combining Particle Swarm Optimization (PSO) with Simulated Annealing (SA) for efficient exploration and exploitation in black box optimization problems.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d46e36e5-0a1d-4a2c-bc43-a815e8742e74", "metadata": {"aucs": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "mutation_prompt": null}
{"id": "09547903-fbc5-43ff-8289-d0d1ff0bccc8", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, initial_temp, final_temp, max_iter):\n            # Simulated Annealing implementation\n            pass\n        \n        # Combined PSO-SA optimization\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, self.final_temp, 100)\n        \n        return best_solution", "name": "PSO_SA_Optimizer", "description": "Novel optimization algorithm combining Particle Swarm Optimization (PSO) with Simulated Annealing (SA) for efficient exploration and exploitation in black box optimization problems.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d46e36e5-0a1d-4a2c-bc43-a815e8742e74", "metadata": {"aucs": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "mutation_prompt": null}
{"id": "b7922068-24c3-4c91-ae91-679424d96ec4", "solution": "import numpy as np\n\nclass Enhanced_PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            inertia_weight = 0.9 + 0.4 * (1 - _ / max_iter)  # Dynamic inertia weight\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, initial_temp, final_temp, max_iter):\n            temp = initial_temp * (final_temp / initial_temp) ** (_ / max_iter)  # Dynamic temperature\n            # Simulated Annealing implementation\n            pass\n        \n        # Combined PSO-SA optimization with enhanced convergence speed\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, self.final_temp, 100)\n        \n        return best_solution", "name": "Enhanced_PSO_SA_Optimizer", "description": "Enhanced PSO_SA_Optimizer algorithm by dynamically adjusting temperature and inertia weight for Simulated Annealing and Particle Swarm Optimization to improve convergence speed.", "configspace": "", "generation": 25, "fitness": 0.0, "feedback": "The algorithm Enhanced_PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00 with standard deviation 0.00.", "error": "", "parent_id": "d46e36e5-0a1d-4a2c-bc43-a815e8742e74", "metadata": {"aucs": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "mutation_prompt": null}
{"id": "1706c310-5e72-482a-bb55-45f7a7a95acb", "solution": "import numpy as np\n\nclass Enhanced_PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, mutation_prob_pso=0.7, mutation_prob_sa=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n        self.mutation_prob_pso = mutation_prob_pso\n        self.mutation_prob_sa = mutation_prob_sa\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter, mutation_prob):\n            # Adaptive Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, initial_temp, final_temp, max_iter, mutation_prob):\n            # Adaptive Simulated Annealing implementation\n            pass\n        \n        # Combined PSO-SA optimization with adaptive mutation probabilities\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100, self.mutation_prob_pso)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, self.final_temp, 100, self.mutation_prob_sa)\n        \n        return best_solution", "name": "Enhanced_PSO_SA_Optimizer", "description": "Enhanced PSO_SA_Optimizer with adaptive mutation probabilities to balance exploration and exploitation for improved convergence speed.", "configspace": "", "generation": 26, "fitness": 0.0, "feedback": "The algorithm Enhanced_PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00 with standard deviation 0.00.", "error": "", "parent_id": "d46e36e5-0a1d-4a2c-bc43-a815e8742e74", "metadata": {"aucs": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "mutation_prompt": null}
{"id": "8dc22bfd-337e-464e-8a72-479ddbb2644a", "solution": "import numpy as np\n\nclass Faster_PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, initial_temp, final_temp, max_iter):\n            # Simulated Annealing implementation\n            pass\n        \n        # Combined PSO-SA optimization with adaptive selection probability\n        best_solution = None\n        pso_prob = 0.5\n        for _ in range(self.budget):\n            if np.random.rand() < pso_prob:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n                pso_prob *= 0.95  # Adjust selection probability\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, self.final_temp, 100)\n                pso_prob = min(pso_prob + 0.05, 1.0)  # Adjust selection probability\n            \n        return best_solution", "name": "Faster_PSO_SA_Optimizer", "description": "Improved convergence speed by adaptively adjusting the selection probability between PSO and SA based on the algorithm's progress.", "configspace": "", "generation": 27, "fitness": 0.0, "feedback": "The algorithm Faster_PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00 with standard deviation 0.00.", "error": "", "parent_id": "d46e36e5-0a1d-4a2c-bc43-a815e8742e74", "metadata": {"aucs": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "mutation_prompt": null}
{"id": "c57550b8-8852-4e21-b9f2-692033c185b5", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, initial_temp, final_temp, max_iter):\n            # Simulated Annealing implementation\n            pass\n        \n        # Combined PSO-SA optimization\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, self.final_temp, 100)\n        \n        return best_solution", "name": "PSO_SA_Optimizer", "description": "Novel optimization algorithm combining Particle Swarm Optimization (PSO) with Simulated Annealing (SA) for efficient exploration and exploitation in black box optimization problems.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d46e36e5-0a1d-4a2c-bc43-a815e8742e74", "metadata": {"aucs": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "mutation_prompt": null}
{"id": "ce8197fd-48dd-4fb7-b62c-06fe80670129", "solution": "import numpy as np\n\nclass DynamicPSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, pso_weight=0.5, sa_weight=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n        self.pso_weight = pso_weight\n        self.sa_weight = sa_weight\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, initial_temp, final_temp, max_iter):\n            # Simulated Annealing implementation\n            pass\n        \n        # Dynamic selection between PSO and SA based on performance\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < self.pso_weight:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, self.final_temp, 100)\n        \n        return best_solution", "name": "DynamicPSO_SA_Optimizer", "description": "Enhancing the exploration-exploitation balance by dynamically adjusting the selection probability between PSO and SA based on their performance.", "configspace": "", "generation": 29, "fitness": 0.0, "feedback": "The algorithm DynamicPSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00 with standard deviation 0.00.", "error": "", "parent_id": "d46e36e5-0a1d-4a2c-bc43-a815e8742e74", "metadata": {"aucs": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "mutation_prompt": null}
{"id": "9817d7b1-6621-442d-8560-ce8c28d9c12f", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, initial_temp, final_temp, max_iter):\n            # Simulated Annealing implementation\n            pass\n        \n        # Combined PSO-SA optimization\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, self.final_temp, 100)\n        \n        return best_solution", "name": "PSO_SA_Optimizer", "description": "Novel optimization algorithm combining Particle Swarm Optimization (PSO) with Simulated Annealing (SA) for efficient exploration and exploitation in black box optimization problems.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d46e36e5-0a1d-4a2c-bc43-a815e8742e74", "metadata": {"aucs": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "mutation_prompt": null}
{"id": "5e24b8d0-a447-468b-92a2-7750fde03917", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, initial_temp, final_temp, max_iter):\n            # Simulated Annealing implementation\n            pass\n        \n        # Combined PSO-SA optimization\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, self.final_temp, 100)\n        \n        return best_solution", "name": "PSO_SA_Optimizer", "description": "Novel optimization algorithm combining Particle Swarm Optimization (PSO) with Simulated Annealing (SA) for efficient exploration and exploitation in black box optimization problems.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d46e36e5-0a1d-4a2c-bc43-a815e8742e74", "metadata": {"aucs": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "mutation_prompt": null}
{"id": "80e79062-f7f1-4aee-91e9-a7ecbcbc598e", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, initial_temp, final_temp, max_iter):\n            # Simulated Annealing implementation\n            pass\n        \n        # Combined PSO-SA optimization\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, self.final_temp, 100)\n        \n        return best_solution", "name": "PSO_SA_Optimizer", "description": "Novel optimization algorithm combining Particle Swarm Optimization (PSO) with Simulated Annealing (SA) for efficient exploration and exploitation in black box optimization problems.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d46e36e5-0a1d-4a2c-bc43-a815e8742e74", "metadata": {"aucs": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "mutation_prompt": null}
{"id": "e3fe4d95-96d2-4067-8641-d2bdf0a81189", "solution": "import numpy as np\n\nclass Improved_PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n        self.temp_decay = temp_decay\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter):\n            # Simulated Annealing implementation with dynamic temperature control\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                candidate_state = current_state + np.random.normal(0, temp, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                if np.random.rand() < np.exp((best_fitness - candidate_fitness) / temp):\n                    current_state = candidate_state\n            return best_state\n        \n        # Combined PSO-SA optimization with improved SA\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100)\n                self.initial_temp *= self.temp_decay  # Adjust temperature dynamically\n        \n        return best_solution", "name": "Improved_PSO_SA_Optimizer", "description": "Improved PSO_SA_Optimizer by adding dynamic control of temperature in Simulated Annealing to enhance exploration and exploitation, leading to faster convergence.", "configspace": "", "generation": 33, "fitness": 0.08552861712555614, "feedback": "The algorithm Improved_PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.20.", "error": "", "parent_id": "d46e36e5-0a1d-4a2c-bc43-a815e8742e74", "metadata": {"aucs": [0.08263869391262813, 0.10536137587980099, 0.11183264138871984, 0.10217547660675641, 0.08925525995768835, 0.08991387867329537, 0.07695199978489187, 0.10044734006518696, 0.06315194412015557, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.030393022979896323, 0.009960077267040512, 0.0023786334281409305, 0.005433529532655523, 0.018028844407162792, 0.011730387608653636, 0.012012685079445862, 0.010022063847275775, 0.013698516630642144, 0.008019277389376134, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003807569159453683, 9.999999999998899e-05, 0.0159885002800485, 0.024401771308367293, 0.9835318602685958, 0.9996067851848265, 0.99863, 0.9992039200685581, 0.9974704728708431, 0.9990389807695648, 0.9987528193537036, 0.9999009861871812, 0.9957944555612087, 0.05583072738656303, 9.999999999998899e-05, 0.01273904911974022, 0.018670407000398126, 0.046145304615846205, 0.006237793089872823, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04417980164014701, 0.028062814586127804, 0.029065908287157827, 0.011283719280897775, 0.06143454706523954, 0.03702887079949213, 0.040290009716108965, 0.022893320038877563, 0.027064932767697614, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09924398698311365, 0.12676243710872992, 0.13396379771160427, 0.13134521120787757, 0.2063460927970323, 0.1000536500901058, 0.13403165533076677, 0.12377046786888934, 0.1540841810278869, 0.009110899613546053, 0.016622362336781937, 0.017751217721911017, 0.002141427384738881, 0.012566562176546947, 0.007568777574919139, 0.0038364187196014976, 0.013397101886610141, 0.012385243396762946, 0.09868750031505713, 0.09345224932479546, 0.09869592805895522, 0.1084076251417706, 0.09910977957578959, 0.08921589371096939, 0.09663947052164856, 0.10793912550789175, 0.10358139167766256, 0.11784649393943814, 0.10299074459407331, 0.11861156349839308, 0.1353027737227942, 0.11816977067880474, 0.11826450200959593, 0.11275107913502858, 0.11112261435746862, 0.11945044554831274, 0.0706325670646678, 0.053164873214458175, 0.062375763069205115, 0.07778343714459901, 0.046291190484533784, 0.05833243779278341, 0.08215751511458724, 0.0465072265609644, 0.0640650206579263, 0.11659799102838131, 0.1044969283226046, 0.107198033997574, 0.1467513978382522, 0.10033900642658333, 0.11154409313970115, 0.10908327457344769, 0.0898759503133344, 0.10721316335913778, 0.12329843157964737, 0.03504018387167307, 9.999999999998899e-05, 0.0016411522568472448, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07934234869062673, 0.08240100916451865, 0.09729502929116329, 0.08585228512026155, 0.09903062891899117, 0.10215815362488556, 0.09507642808210925, 0.10825936078737708, 0.08358359502469326, 0.05868369031173115, 0.1065230064646957, 0.03976211977740296, 0.05936027996745907, 0.07903952876914833, 0.04372926671451005, 0.06504498899856204, 0.05736177795129338, 0.10068533246764078, 0.16378598952020695, 0.16229528731764675, 0.15478412667831654, 0.15029884663980664, 0.15893522766244095, 0.15834857543714387, 0.15153427002762387, 0.15394147920385182, 0.15230841776965154, 0.029745749059496118, 0.026769411719862024, 0.01658011895142575, 0.02491303665596223, 0.02750731750058477, 0.017278347041896458, 0.057303757127379895, 0.03208283295949155, 0.014708622687554795]}, "mutation_prompt": null}
{"id": "2c3f2920-1cf8-4baa-9bd5-e0c523c99e89", "solution": "import numpy as np\n\nclass Adaptive_Mutation_PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n        self.temp_decay = temp_decay\n        self.mutation_scale = mutation_scale\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale):\n            # Simulated Annealing implementation with adaptive mutation\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                candidate_state = current_state + np.random.normal(0, temp * mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                if np.random.rand() < np.exp((best_fitness - candidate_fitness) / temp):\n                    current_state = candidate_state\n            return best_state\n        \n        # Combined PSO-SA optimization with improved SA\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale)\n                self.initial_temp *= self.temp_decay  # Adjust temperature dynamically\n                \n        return best_solution", "name": "Adaptive_Mutation_PSO_SA_Optimizer", "description": "Improved PSO_SA_Optimizer with an adaptive mutation mechanism that adjusts the mutation scale based on the fitness landscape to enhance exploration and exploitation, leading to faster convergence.", "configspace": "", "generation": 34, "fitness": 0.0887602618277948, "feedback": "The algorithm Adaptive_Mutation_PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.20.", "error": "", "parent_id": "e3fe4d95-96d2-4067-8641-d2bdf0a81189", "metadata": {"aucs": [0.08263869391262813, 0.10537552756018831, 0.11183264138871984, 0.10749137665278452, 0.10516904424578355, 0.10955039229510044, 0.07988536128700385, 0.10044734006518696, 0.06528732344447019, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.030393022979896323, 0.009960077267040512, 0.0023786334281409305, 0.005433529532655523, 0.018028844407162792, 0.011730387608653636, 0.012151523198922431, 0.010022063847275775, 0.013698516630642144, 0.008019277389376134, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003807569159453683, 9.999999999998899e-05, 0.0159885002800485, 0.024401771308367293, 0.983573303231345, 0.9996067851848265, 0.9985668562540724, 0.9992039200685581, 0.9974704728708431, 0.9990335717372488, 0.9950801522397211, 0.9999009861871812, 0.9957872447220172, 0.05583072738656303, 0.004960841488374723, 0.01273904911974022, 0.018670407000398126, 0.046145304615846205, 0.006237793089872823, 0.004892371971547571, 9.999999999998899e-05, 0.009146916424722429, 0.044207056426254554, 0.028062814586127804, 0.029233708580172824, 0.028550939119874386, 0.06143454706523954, 0.037052823643021315, 0.04453605447772879, 0.05351678172994312, 0.03336764697030847, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009516805429056197, 0.001640932429432751, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005215070945354783, 9.999999999998899e-05, 0.009679656014563776, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003220007829734972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10221308498308224, 0.13060952151620153, 0.13568509999360845, 0.13134521120787757, 0.20636803535946002, 0.10115610418211507, 0.13403165533076677, 0.12447967737168619, 0.1540841810278869, 0.009275489493793643, 0.016622362336781937, 0.01962180193522145, 0.002141427384738881, 0.012566562176546947, 0.007568777574919139, 0.0038364187196014976, 0.013397101886610141, 0.012385243396762946, 0.12981471691519186, 0.12467204850535107, 0.10124919758472117, 0.10660591973885825, 0.10151600803284178, 0.12076845912634382, 0.1310650333020762, 0.13293303719846516, 0.10572741526342977, 0.11807452435922261, 0.10912062118196042, 0.12054430306801389, 0.1353027737227942, 0.11823296270511219, 0.11826510974792437, 0.11334305106515363, 0.11358427737371535, 0.12342607786561854, 0.07075253584230268, 0.05454639322706645, 0.06320523084774099, 0.07778343714459901, 0.0582502637534702, 0.06330509043814869, 0.08215751511458724, 0.04859653661796126, 0.06646402342864699, 0.11659799102838131, 0.1065248547413905, 0.107198033997574, 0.1467513978382522, 0.10215151150616752, 0.11207788923810036, 0.10908327457344769, 0.08988151294579982, 0.10721316335913778, 0.12329843157964737, 0.03504018387167307, 9.999999999998899e-05, 0.0016411522568472448, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1008054165240212, 0.09385916232950708, 0.11688967857044541, 0.08979182778577233, 0.09925440843834421, 0.10978333068347035, 0.09572224287684206, 0.08088681953953603, 0.08439668588585825, 0.08297537859208914, 0.11995996621966132, 0.050316359881892425, 0.05936027996745907, 0.07903952876914833, 0.043814776697189695, 0.10206027788072425, 0.09499430529102226, 0.10365203709473647, 0.1754453913836882, 0.18549583588932206, 0.16176317004842278, 0.1842408906299987, 0.1816479166300069, 0.17085410189156536, 0.17506260816767794, 0.17284681934687762, 0.169437373957383, 0.029745749059496118, 0.026769411719862024, 0.01658011895142575, 0.02491303665596223, 0.02750731750058477, 0.017322434454664082, 0.057303757127379895, 0.03208283295949155, 0.014708622687554795]}, "mutation_prompt": null}
{"id": "e0142a7d-a5b3-49d5-a7fc-5b740689f834", "solution": "import numpy as np\n\nclass Adaptive_Mutation_PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n        self.temp_decay = temp_decay\n        self.mutation_scale = mutation_scale\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale):\n            # Simulated Annealing implementation with adaptive mutation\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                candidate_state = current_state + np.random.normal(0, temp * mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                if np.random.rand() < np.exp((best_fitness - candidate_fitness) / temp):\n                    current_state = candidate_state\n            return best_state\n        \n        # Combined PSO-SA optimization with improved SA\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale)\n                self.initial_temp *= self.temp_decay  # Adjust temperature dynamically\n                \n        return best_solution", "name": "Adaptive_Mutation_PSO_SA_Optimizer", "description": "Improved PSO_SA_Optimizer with an adaptive mutation mechanism that adjusts the mutation scale based on the fitness landscape to enhance exploration and exploitation, leading to faster convergence.", "configspace": "", "generation": 35, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "2c3f2920-1cf8-4baa-9bd5-e0c523c99e89", "metadata": {"aucs": [0.08263869391262813, 0.10537552756018831, 0.11183264138871984, 0.10749137665278452, 0.10516904424578355, 0.10955039229510044, 0.07988536128700385, 0.10044734006518696, 0.06528732344447019, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.030393022979896323, 0.009960077267040512, 0.0023786334281409305, 0.005433529532655523, 0.018028844407162792, 0.011730387608653636, 0.012151523198922431, 0.010022063847275775, 0.013698516630642144, 0.008019277389376134, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003807569159453683, 9.999999999998899e-05, 0.0159885002800485, 0.024401771308367293, 0.983573303231345, 0.9996067851848265, 0.9985668562540724, 0.9992039200685581, 0.9974704728708431, 0.9990335717372488, 0.9950801522397211, 0.9999009861871812, 0.9957872447220172, 0.05583072738656303, 0.004960841488374723, 0.01273904911974022, 0.018670407000398126, 0.046145304615846205, 0.006237793089872823, 0.004892371971547571, 9.999999999998899e-05, 0.009146916424722429, 0.044207056426254554, 0.028062814586127804, 0.029233708580172824, 0.028550939119874386, 0.06143454706523954, 0.037052823643021315, 0.04453605447772879, 0.05351678172994312, 0.03336764697030847, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009516805429056197, 0.001640932429432751, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005215070945354783, 9.999999999998899e-05, 0.009679656014563776, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003220007829734972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10221308498308224, 0.13060952151620153, 0.13568509999360845, 0.13134521120787757, 0.20636803535946002, 0.10115610418211507, 0.13403165533076677, 0.12447967737168619, 0.1540841810278869, 0.009275489493793643, 0.016622362336781937, 0.01962180193522145, 0.002141427384738881, 0.012566562176546947, 0.007568777574919139, 0.0038364187196014976, 0.013397101886610141, 0.012385243396762946, 0.12981471691519186, 0.12467204850535107, 0.10124919758472117, 0.10660591973885825, 0.10151600803284178, 0.12076845912634382, 0.1310650333020762, 0.13293303719846516, 0.10572741526342977, 0.11807452435922261, 0.10912062118196042, 0.12054430306801389, 0.1353027737227942, 0.11823296270511219, 0.11826510974792437, 0.11334305106515363, 0.11358427737371535, 0.12342607786561854, 0.07075253584230268, 0.05454639322706645, 0.06320523084774099, 0.07778343714459901, 0.0582502637534702, 0.06330509043814869, 0.08215751511458724, 0.04859653661796126, 0.06646402342864699, 0.11659799102838131, 0.1065248547413905, 0.107198033997574, 0.1467513978382522, 0.10215151150616752, 0.11207788923810036, 0.10908327457344769, 0.08988151294579982, 0.10721316335913778, 0.12329843157964737, 0.03504018387167307, 9.999999999998899e-05, 0.0016411522568472448, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1008054165240212, 0.09385916232950708, 0.11688967857044541, 0.08979182778577233, 0.09925440843834421, 0.10978333068347035, 0.09572224287684206, 0.08088681953953603, 0.08439668588585825, 0.08297537859208914, 0.11995996621966132, 0.050316359881892425, 0.05936027996745907, 0.07903952876914833, 0.043814776697189695, 0.10206027788072425, 0.09499430529102226, 0.10365203709473647, 0.1754453913836882, 0.18549583588932206, 0.16176317004842278, 0.1842408906299987, 0.1816479166300069, 0.17085410189156536, 0.17506260816767794, 0.17284681934687762, 0.169437373957383, 0.029745749059496118, 0.026769411719862024, 0.01658011895142575, 0.02491303665596223, 0.02750731750058477, 0.017322434454664082, 0.057303757127379895, 0.03208283295949155, 0.014708622687554795]}, "mutation_prompt": null}
{"id": "8b9f425b-3df8-49e5-bc42-733adec21642", "solution": "import numpy as np\n\nclass Adaptive_Mutation_PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n        self.temp_decay = temp_decay\n        self.mutation_scale = mutation_scale\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale):\n            # Simulated Annealing implementation with adaptive mutation\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                candidate_state = current_state + np.random.normal(0, temp * mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                if np.random.rand() < np.exp((best_fitness - candidate_fitness) / temp):\n                    current_state = candidate_state\n            return best_state\n        \n        # Combined PSO-SA optimization with improved SA\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale)\n                self.initial_temp *= self.temp_decay  # Adjust temperature dynamically\n                \n        return best_solution", "name": "Adaptive_Mutation_PSO_SA_Optimizer", "description": "Improved PSO_SA_Optimizer with an adaptive mutation mechanism that adjusts the mutation scale based on the fitness landscape to enhance exploration and exploitation, leading to faster convergence.", "configspace": "", "generation": 35, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "2c3f2920-1cf8-4baa-9bd5-e0c523c99e89", "metadata": {"aucs": [0.08263869391262813, 0.10537552756018831, 0.11183264138871984, 0.10749137665278452, 0.10516904424578355, 0.10955039229510044, 0.07988536128700385, 0.10044734006518696, 0.06528732344447019, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.030393022979896323, 0.009960077267040512, 0.0023786334281409305, 0.005433529532655523, 0.018028844407162792, 0.011730387608653636, 0.012151523198922431, 0.010022063847275775, 0.013698516630642144, 0.008019277389376134, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003807569159453683, 9.999999999998899e-05, 0.0159885002800485, 0.024401771308367293, 0.983573303231345, 0.9996067851848265, 0.9985668562540724, 0.9992039200685581, 0.9974704728708431, 0.9990335717372488, 0.9950801522397211, 0.9999009861871812, 0.9957872447220172, 0.05583072738656303, 0.004960841488374723, 0.01273904911974022, 0.018670407000398126, 0.046145304615846205, 0.006237793089872823, 0.004892371971547571, 9.999999999998899e-05, 0.009146916424722429, 0.044207056426254554, 0.028062814586127804, 0.029233708580172824, 0.028550939119874386, 0.06143454706523954, 0.037052823643021315, 0.04453605447772879, 0.05351678172994312, 0.03336764697030847, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009516805429056197, 0.001640932429432751, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005215070945354783, 9.999999999998899e-05, 0.009679656014563776, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003220007829734972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10221308498308224, 0.13060952151620153, 0.13568509999360845, 0.13134521120787757, 0.20636803535946002, 0.10115610418211507, 0.13403165533076677, 0.12447967737168619, 0.1540841810278869, 0.009275489493793643, 0.016622362336781937, 0.01962180193522145, 0.002141427384738881, 0.012566562176546947, 0.007568777574919139, 0.0038364187196014976, 0.013397101886610141, 0.012385243396762946, 0.12981471691519186, 0.12467204850535107, 0.10124919758472117, 0.10660591973885825, 0.10151600803284178, 0.12076845912634382, 0.1310650333020762, 0.13293303719846516, 0.10572741526342977, 0.11807452435922261, 0.10912062118196042, 0.12054430306801389, 0.1353027737227942, 0.11823296270511219, 0.11826510974792437, 0.11334305106515363, 0.11358427737371535, 0.12342607786561854, 0.07075253584230268, 0.05454639322706645, 0.06320523084774099, 0.07778343714459901, 0.0582502637534702, 0.06330509043814869, 0.08215751511458724, 0.04859653661796126, 0.06646402342864699, 0.11659799102838131, 0.1065248547413905, 0.107198033997574, 0.1467513978382522, 0.10215151150616752, 0.11207788923810036, 0.10908327457344769, 0.08988151294579982, 0.10721316335913778, 0.12329843157964737, 0.03504018387167307, 9.999999999998899e-05, 0.0016411522568472448, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1008054165240212, 0.09385916232950708, 0.11688967857044541, 0.08979182778577233, 0.09925440843834421, 0.10978333068347035, 0.09572224287684206, 0.08088681953953603, 0.08439668588585825, 0.08297537859208914, 0.11995996621966132, 0.050316359881892425, 0.05936027996745907, 0.07903952876914833, 0.043814776697189695, 0.10206027788072425, 0.09499430529102226, 0.10365203709473647, 0.1754453913836882, 0.18549583588932206, 0.16176317004842278, 0.1842408906299987, 0.1816479166300069, 0.17085410189156536, 0.17506260816767794, 0.17284681934687762, 0.169437373957383, 0.029745749059496118, 0.026769411719862024, 0.01658011895142575, 0.02491303665596223, 0.02750731750058477, 0.017322434454664082, 0.057303757127379895, 0.03208283295949155, 0.014708622687554795]}, "mutation_prompt": null}
{"id": "efe06c1e-6165-4785-82e3-1d910489d170", "solution": "import numpy as np\n\nclass Adaptive_Mutation_PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n        self.temp_decay = temp_decay\n        self.mutation_scale = mutation_scale\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale):\n            # Simulated Annealing implementation with adaptive mutation\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                candidate_state = current_state + np.random.normal(0, temp * mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                if np.random.rand() < np.exp((best_fitness - candidate_fitness) / temp):\n                    current_state = candidate_state\n            return best_state\n        \n        # Combined PSO-SA optimization with improved SA\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale)\n                self.initial_temp *= self.temp_decay  # Adjust temperature dynamically\n                \n        return best_solution", "name": "Adaptive_Mutation_PSO_SA_Optimizer", "description": "Improved PSO_SA_Optimizer with an adaptive mutation mechanism that adjusts the mutation scale based on the fitness landscape to enhance exploration and exploitation, leading to faster convergence.", "configspace": "", "generation": 35, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "2c3f2920-1cf8-4baa-9bd5-e0c523c99e89", "metadata": {"aucs": [0.08263869391262813, 0.10537552756018831, 0.11183264138871984, 0.10749137665278452, 0.10516904424578355, 0.10955039229510044, 0.07988536128700385, 0.10044734006518696, 0.06528732344447019, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.030393022979896323, 0.009960077267040512, 0.0023786334281409305, 0.005433529532655523, 0.018028844407162792, 0.011730387608653636, 0.012151523198922431, 0.010022063847275775, 0.013698516630642144, 0.008019277389376134, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003807569159453683, 9.999999999998899e-05, 0.0159885002800485, 0.024401771308367293, 0.983573303231345, 0.9996067851848265, 0.9985668562540724, 0.9992039200685581, 0.9974704728708431, 0.9990335717372488, 0.9950801522397211, 0.9999009861871812, 0.9957872447220172, 0.05583072738656303, 0.004960841488374723, 0.01273904911974022, 0.018670407000398126, 0.046145304615846205, 0.006237793089872823, 0.004892371971547571, 9.999999999998899e-05, 0.009146916424722429, 0.044207056426254554, 0.028062814586127804, 0.029233708580172824, 0.028550939119874386, 0.06143454706523954, 0.037052823643021315, 0.04453605447772879, 0.05351678172994312, 0.03336764697030847, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009516805429056197, 0.001640932429432751, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005215070945354783, 9.999999999998899e-05, 0.009679656014563776, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003220007829734972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10221308498308224, 0.13060952151620153, 0.13568509999360845, 0.13134521120787757, 0.20636803535946002, 0.10115610418211507, 0.13403165533076677, 0.12447967737168619, 0.1540841810278869, 0.009275489493793643, 0.016622362336781937, 0.01962180193522145, 0.002141427384738881, 0.012566562176546947, 0.007568777574919139, 0.0038364187196014976, 0.013397101886610141, 0.012385243396762946, 0.12981471691519186, 0.12467204850535107, 0.10124919758472117, 0.10660591973885825, 0.10151600803284178, 0.12076845912634382, 0.1310650333020762, 0.13293303719846516, 0.10572741526342977, 0.11807452435922261, 0.10912062118196042, 0.12054430306801389, 0.1353027737227942, 0.11823296270511219, 0.11826510974792437, 0.11334305106515363, 0.11358427737371535, 0.12342607786561854, 0.07075253584230268, 0.05454639322706645, 0.06320523084774099, 0.07778343714459901, 0.0582502637534702, 0.06330509043814869, 0.08215751511458724, 0.04859653661796126, 0.06646402342864699, 0.11659799102838131, 0.1065248547413905, 0.107198033997574, 0.1467513978382522, 0.10215151150616752, 0.11207788923810036, 0.10908327457344769, 0.08988151294579982, 0.10721316335913778, 0.12329843157964737, 0.03504018387167307, 9.999999999998899e-05, 0.0016411522568472448, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1008054165240212, 0.09385916232950708, 0.11688967857044541, 0.08979182778577233, 0.09925440843834421, 0.10978333068347035, 0.09572224287684206, 0.08088681953953603, 0.08439668588585825, 0.08297537859208914, 0.11995996621966132, 0.050316359881892425, 0.05936027996745907, 0.07903952876914833, 0.043814776697189695, 0.10206027788072425, 0.09499430529102226, 0.10365203709473647, 0.1754453913836882, 0.18549583588932206, 0.16176317004842278, 0.1842408906299987, 0.1816479166300069, 0.17085410189156536, 0.17506260816767794, 0.17284681934687762, 0.169437373957383, 0.029745749059496118, 0.026769411719862024, 0.01658011895142575, 0.02491303665596223, 0.02750731750058477, 0.017322434454664082, 0.057303757127379895, 0.03208283295949155, 0.014708622687554795]}, "mutation_prompt": null}
{"id": "23b26c42-f7a9-4b31-bf7b-18b9dad8f823", "solution": "import numpy as np\n\nclass Adaptive_Mutation_PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n        self.temp_decay = temp_decay\n        self.mutation_scale = mutation_scale\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale):\n            # Simulated Annealing implementation with adaptive mutation\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                candidate_state = current_state + np.random.normal(0, temp * mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                if np.random.rand() < np.exp((best_fitness - candidate_fitness) / temp):\n                    current_state = candidate_state\n            return best_state\n        \n        # Combined PSO-SA optimization with improved SA\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale)\n                self.initial_temp *= self.temp_decay  # Adjust temperature dynamically\n                \n        return best_solution", "name": "Adaptive_Mutation_PSO_SA_Optimizer", "description": "Improved PSO_SA_Optimizer with an adaptive mutation mechanism that adjusts the mutation scale based on the fitness landscape to enhance exploration and exploitation, leading to faster convergence.", "configspace": "", "generation": 35, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "2c3f2920-1cf8-4baa-9bd5-e0c523c99e89", "metadata": {"aucs": [0.08263869391262813, 0.10537552756018831, 0.11183264138871984, 0.10749137665278452, 0.10516904424578355, 0.10955039229510044, 0.07988536128700385, 0.10044734006518696, 0.06528732344447019, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.030393022979896323, 0.009960077267040512, 0.0023786334281409305, 0.005433529532655523, 0.018028844407162792, 0.011730387608653636, 0.012151523198922431, 0.010022063847275775, 0.013698516630642144, 0.008019277389376134, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003807569159453683, 9.999999999998899e-05, 0.0159885002800485, 0.024401771308367293, 0.983573303231345, 0.9996067851848265, 0.9985668562540724, 0.9992039200685581, 0.9974704728708431, 0.9990335717372488, 0.9950801522397211, 0.9999009861871812, 0.9957872447220172, 0.05583072738656303, 0.004960841488374723, 0.01273904911974022, 0.018670407000398126, 0.046145304615846205, 0.006237793089872823, 0.004892371971547571, 9.999999999998899e-05, 0.009146916424722429, 0.044207056426254554, 0.028062814586127804, 0.029233708580172824, 0.028550939119874386, 0.06143454706523954, 0.037052823643021315, 0.04453605447772879, 0.05351678172994312, 0.03336764697030847, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009516805429056197, 0.001640932429432751, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005215070945354783, 9.999999999998899e-05, 0.009679656014563776, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003220007829734972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10221308498308224, 0.13060952151620153, 0.13568509999360845, 0.13134521120787757, 0.20636803535946002, 0.10115610418211507, 0.13403165533076677, 0.12447967737168619, 0.1540841810278869, 0.009275489493793643, 0.016622362336781937, 0.01962180193522145, 0.002141427384738881, 0.012566562176546947, 0.007568777574919139, 0.0038364187196014976, 0.013397101886610141, 0.012385243396762946, 0.12981471691519186, 0.12467204850535107, 0.10124919758472117, 0.10660591973885825, 0.10151600803284178, 0.12076845912634382, 0.1310650333020762, 0.13293303719846516, 0.10572741526342977, 0.11807452435922261, 0.10912062118196042, 0.12054430306801389, 0.1353027737227942, 0.11823296270511219, 0.11826510974792437, 0.11334305106515363, 0.11358427737371535, 0.12342607786561854, 0.07075253584230268, 0.05454639322706645, 0.06320523084774099, 0.07778343714459901, 0.0582502637534702, 0.06330509043814869, 0.08215751511458724, 0.04859653661796126, 0.06646402342864699, 0.11659799102838131, 0.1065248547413905, 0.107198033997574, 0.1467513978382522, 0.10215151150616752, 0.11207788923810036, 0.10908327457344769, 0.08988151294579982, 0.10721316335913778, 0.12329843157964737, 0.03504018387167307, 9.999999999998899e-05, 0.0016411522568472448, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1008054165240212, 0.09385916232950708, 0.11688967857044541, 0.08979182778577233, 0.09925440843834421, 0.10978333068347035, 0.09572224287684206, 0.08088681953953603, 0.08439668588585825, 0.08297537859208914, 0.11995996621966132, 0.050316359881892425, 0.05936027996745907, 0.07903952876914833, 0.043814776697189695, 0.10206027788072425, 0.09499430529102226, 0.10365203709473647, 0.1754453913836882, 0.18549583588932206, 0.16176317004842278, 0.1842408906299987, 0.1816479166300069, 0.17085410189156536, 0.17506260816767794, 0.17284681934687762, 0.169437373957383, 0.029745749059496118, 0.026769411719862024, 0.01658011895142575, 0.02491303665596223, 0.02750731750058477, 0.017322434454664082, 0.057303757127379895, 0.03208283295949155, 0.014708622687554795]}, "mutation_prompt": null}
{"id": "4d8c6fe3-0d2f-4193-9690-17f5cb9fcd1a", "solution": "import numpy as np\n\nclass Adaptive_Mutation_PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n        self.temp_decay = temp_decay\n        self.mutation_scale = mutation_scale\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale):\n            # Simulated Annealing implementation with adaptive mutation\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                candidate_state = current_state + np.random.normal(0, temp * mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                if np.random.rand() < np.exp((best_fitness - candidate_fitness) / temp):\n                    current_state = candidate_state\n            return best_state\n        \n        # Combined PSO-SA optimization with improved SA\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale)\n                self.initial_temp *= self.temp_decay  # Adjust temperature dynamically\n                \n        return best_solution", "name": "Adaptive_Mutation_PSO_SA_Optimizer", "description": "Improved PSO_SA_Optimizer with an adaptive mutation mechanism that adjusts the mutation scale based on the fitness landscape to enhance exploration and exploitation, leading to faster convergence.", "configspace": "", "generation": 35, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "2c3f2920-1cf8-4baa-9bd5-e0c523c99e89", "metadata": {"aucs": [0.08263869391262813, 0.10537552756018831, 0.11183264138871984, 0.10749137665278452, 0.10516904424578355, 0.10955039229510044, 0.07988536128700385, 0.10044734006518696, 0.06528732344447019, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.030393022979896323, 0.009960077267040512, 0.0023786334281409305, 0.005433529532655523, 0.018028844407162792, 0.011730387608653636, 0.012151523198922431, 0.010022063847275775, 0.013698516630642144, 0.008019277389376134, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003807569159453683, 9.999999999998899e-05, 0.0159885002800485, 0.024401771308367293, 0.983573303231345, 0.9996067851848265, 0.9985668562540724, 0.9992039200685581, 0.9974704728708431, 0.9990335717372488, 0.9950801522397211, 0.9999009861871812, 0.9957872447220172, 0.05583072738656303, 0.004960841488374723, 0.01273904911974022, 0.018670407000398126, 0.046145304615846205, 0.006237793089872823, 0.004892371971547571, 9.999999999998899e-05, 0.009146916424722429, 0.044207056426254554, 0.028062814586127804, 0.029233708580172824, 0.028550939119874386, 0.06143454706523954, 0.037052823643021315, 0.04453605447772879, 0.05351678172994312, 0.03336764697030847, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009516805429056197, 0.001640932429432751, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005215070945354783, 9.999999999998899e-05, 0.009679656014563776, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003220007829734972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10221308498308224, 0.13060952151620153, 0.13568509999360845, 0.13134521120787757, 0.20636803535946002, 0.10115610418211507, 0.13403165533076677, 0.12447967737168619, 0.1540841810278869, 0.009275489493793643, 0.016622362336781937, 0.01962180193522145, 0.002141427384738881, 0.012566562176546947, 0.007568777574919139, 0.0038364187196014976, 0.013397101886610141, 0.012385243396762946, 0.12981471691519186, 0.12467204850535107, 0.10124919758472117, 0.10660591973885825, 0.10151600803284178, 0.12076845912634382, 0.1310650333020762, 0.13293303719846516, 0.10572741526342977, 0.11807452435922261, 0.10912062118196042, 0.12054430306801389, 0.1353027737227942, 0.11823296270511219, 0.11826510974792437, 0.11334305106515363, 0.11358427737371535, 0.12342607786561854, 0.07075253584230268, 0.05454639322706645, 0.06320523084774099, 0.07778343714459901, 0.0582502637534702, 0.06330509043814869, 0.08215751511458724, 0.04859653661796126, 0.06646402342864699, 0.11659799102838131, 0.1065248547413905, 0.107198033997574, 0.1467513978382522, 0.10215151150616752, 0.11207788923810036, 0.10908327457344769, 0.08988151294579982, 0.10721316335913778, 0.12329843157964737, 0.03504018387167307, 9.999999999998899e-05, 0.0016411522568472448, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1008054165240212, 0.09385916232950708, 0.11688967857044541, 0.08979182778577233, 0.09925440843834421, 0.10978333068347035, 0.09572224287684206, 0.08088681953953603, 0.08439668588585825, 0.08297537859208914, 0.11995996621966132, 0.050316359881892425, 0.05936027996745907, 0.07903952876914833, 0.043814776697189695, 0.10206027788072425, 0.09499430529102226, 0.10365203709473647, 0.1754453913836882, 0.18549583588932206, 0.16176317004842278, 0.1842408906299987, 0.1816479166300069, 0.17085410189156536, 0.17506260816767794, 0.17284681934687762, 0.169437373957383, 0.029745749059496118, 0.026769411719862024, 0.01658011895142575, 0.02491303665596223, 0.02750731750058477, 0.017322434454664082, 0.057303757127379895, 0.03208283295949155, 0.014708622687554795]}, "mutation_prompt": null}
{"id": "3211ff83-4f5c-4d33-9ba6-cd7431ff0c28", "solution": "import numpy as np\n\nclass Adaptive_Mutation_PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n        self.temp_decay = temp_decay\n        self.mutation_scale = mutation_scale\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale):\n            # Simulated Annealing implementation with adaptive mutation\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                candidate_state = current_state + np.random.normal(0, temp * mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                if np.random.rand() < np.exp((best_fitness - candidate_fitness) / temp):\n                    current_state = candidate_state\n            return best_state\n        \n        # Combined PSO-SA optimization with improved SA\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale)\n                self.initial_temp *= self.temp_decay  # Adjust temperature dynamically\n                \n        return best_solution", "name": "Adaptive_Mutation_PSO_SA_Optimizer", "description": "Improved PSO_SA_Optimizer with an adaptive mutation mechanism that adjusts the mutation scale based on the fitness landscape to enhance exploration and exploitation, leading to faster convergence.", "configspace": "", "generation": 35, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "2c3f2920-1cf8-4baa-9bd5-e0c523c99e89", "metadata": {"aucs": [0.08263869391262813, 0.10537552756018831, 0.11183264138871984, 0.10749137665278452, 0.10516904424578355, 0.10955039229510044, 0.07988536128700385, 0.10044734006518696, 0.06528732344447019, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.030393022979896323, 0.009960077267040512, 0.0023786334281409305, 0.005433529532655523, 0.018028844407162792, 0.011730387608653636, 0.012151523198922431, 0.010022063847275775, 0.013698516630642144, 0.008019277389376134, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003807569159453683, 9.999999999998899e-05, 0.0159885002800485, 0.024401771308367293, 0.983573303231345, 0.9996067851848265, 0.9985668562540724, 0.9992039200685581, 0.9974704728708431, 0.9990335717372488, 0.9950801522397211, 0.9999009861871812, 0.9957872447220172, 0.05583072738656303, 0.004960841488374723, 0.01273904911974022, 0.018670407000398126, 0.046145304615846205, 0.006237793089872823, 0.004892371971547571, 9.999999999998899e-05, 0.009146916424722429, 0.044207056426254554, 0.028062814586127804, 0.029233708580172824, 0.028550939119874386, 0.06143454706523954, 0.037052823643021315, 0.04453605447772879, 0.05351678172994312, 0.03336764697030847, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009516805429056197, 0.001640932429432751, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005215070945354783, 9.999999999998899e-05, 0.009679656014563776, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003220007829734972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10221308498308224, 0.13060952151620153, 0.13568509999360845, 0.13134521120787757, 0.20636803535946002, 0.10115610418211507, 0.13403165533076677, 0.12447967737168619, 0.1540841810278869, 0.009275489493793643, 0.016622362336781937, 0.01962180193522145, 0.002141427384738881, 0.012566562176546947, 0.007568777574919139, 0.0038364187196014976, 0.013397101886610141, 0.012385243396762946, 0.12981471691519186, 0.12467204850535107, 0.10124919758472117, 0.10660591973885825, 0.10151600803284178, 0.12076845912634382, 0.1310650333020762, 0.13293303719846516, 0.10572741526342977, 0.11807452435922261, 0.10912062118196042, 0.12054430306801389, 0.1353027737227942, 0.11823296270511219, 0.11826510974792437, 0.11334305106515363, 0.11358427737371535, 0.12342607786561854, 0.07075253584230268, 0.05454639322706645, 0.06320523084774099, 0.07778343714459901, 0.0582502637534702, 0.06330509043814869, 0.08215751511458724, 0.04859653661796126, 0.06646402342864699, 0.11659799102838131, 0.1065248547413905, 0.107198033997574, 0.1467513978382522, 0.10215151150616752, 0.11207788923810036, 0.10908327457344769, 0.08988151294579982, 0.10721316335913778, 0.12329843157964737, 0.03504018387167307, 9.999999999998899e-05, 0.0016411522568472448, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1008054165240212, 0.09385916232950708, 0.11688967857044541, 0.08979182778577233, 0.09925440843834421, 0.10978333068347035, 0.09572224287684206, 0.08088681953953603, 0.08439668588585825, 0.08297537859208914, 0.11995996621966132, 0.050316359881892425, 0.05936027996745907, 0.07903952876914833, 0.043814776697189695, 0.10206027788072425, 0.09499430529102226, 0.10365203709473647, 0.1754453913836882, 0.18549583588932206, 0.16176317004842278, 0.1842408906299987, 0.1816479166300069, 0.17085410189156536, 0.17506260816767794, 0.17284681934687762, 0.169437373957383, 0.029745749059496118, 0.026769411719862024, 0.01658011895142575, 0.02491303665596223, 0.02750731750058477, 0.017322434454664082, 0.057303757127379895, 0.03208283295949155, 0.014708622687554795]}, "mutation_prompt": null}
{"id": "38b2d5e4-9ae9-41f7-b2b1-387519c0e21b", "solution": "import numpy as np\n\nclass Improved_Adaptive_Mutation_PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n        self.temp_decay = temp_decay\n        self.mutation_scale = mutation_scale\n        self.dynamic_scale_factor = dynamic_scale_factor\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale):\n            # Simulated Annealing implementation with adaptive mutation\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                if np.random.rand() < np.exp((best_fitness - candidate_fitness) / temp):\n                    current_state = candidate_state\n            return best_state\n        \n        # Combined PSO-SA optimization with improved SA\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale)\n                self.initial_temp *= self.temp_decay  # Adjust temperature dynamically\n                \n        return best_solution", "name": "Improved_Adaptive_Mutation_PSO_SA_Optimizer", "description": "To improve convergence speed, we introduce a dynamic mutation scaling strategy that adapts based on the fitness landscape's volatility to enhance exploration and exploitation effectively.", "configspace": "", "generation": 41, "fitness": 0.08901266851498955, "feedback": "The algorithm Improved_Adaptive_Mutation_PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.20.", "error": "", "parent_id": "2c3f2920-1cf8-4baa-9bd5-e0c523c99e89", "metadata": {"aucs": [0.08263869391262813, 0.10537189348558273, 0.11183264138871984, 0.10894249815120727, 0.10936846053851224, 0.11402129538355965, 0.08151715298801832, 0.10044734006518696, 0.06631653485717359, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.030393022979896323, 0.009960077267040512, 0.0023786334281409305, 0.005433529532655523, 0.018028844407162792, 0.011730387608653636, 0.012983558442637322, 0.010022063847275775, 0.013698516630642144, 0.008019277389376134, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003807569159453683, 9.999999999998899e-05, 0.0159885002800485, 0.024401771308367293, 0.9835626763622813, 0.9996067851848265, 0.9985665821016864, 0.9992039200685581, 0.9974704728708431, 0.9990335723676586, 0.995089706718323, 0.9999009861871812, 0.9957872451255732, 0.05583072738656303, 0.0017991593129148553, 0.01273904911974022, 0.018670407000398126, 0.046145304615846205, 0.006237793089872823, 0.00645164354549288, 0.009050540832098664, 0.008097509281582482, 0.047578189159767525, 0.0281137083258014, 0.029084656532247788, 0.03423736565859048, 0.06208269127504373, 0.03702887079949213, 0.04538980237517665, 0.05054527425192501, 0.03342855964570712, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005882720522139007, 0.008023836049127042, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007003158133999432, 9.999999999998899e-05, 0.012750558946003965, 9.999999999998899e-05, 0.0015038685551522768, 9.999999999998899e-05, 9.999999999998899e-05, 0.004708269760549388, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1017047563684117, 0.13072094483509533, 0.1361334485359299, 0.13134521120787757, 0.2063639642724886, 0.10072638391379951, 0.13403165533076677, 0.12462459316889818, 0.1540841810278869, 0.012370525923469766, 0.01666745141057968, 0.02007166558511675, 0.002141427384738881, 0.012566562176546947, 0.011425500037940739, 0.006501002148295965, 0.013397101886610141, 0.012385243396762946, 0.10180582813300953, 0.14236723547190655, 0.11174545721697926, 0.12412875640391519, 0.1269336658845368, 0.11441467657107729, 0.13614782136413195, 0.11402380363444986, 0.11717402752794348, 0.11804672173450859, 0.10446200375227688, 0.12117655506752545, 0.1353027737227942, 0.11816977067880474, 0.11836315165160427, 0.11625043456264961, 0.11214424313277982, 0.12187573606286095, 0.07065920384940183, 0.057685985509240756, 0.06323479274836041, 0.07778343714459901, 0.05857321267870752, 0.05833243779278341, 0.0822670726201844, 0.05232853836161844, 0.06743554120929474, 0.11905643261245857, 0.10459451462601554, 0.11078486565497658, 0.1467513978382522, 0.10602789521233957, 0.11159352760066665, 0.10908327457344769, 0.0898759503133344, 0.10721316335913778, 0.12329843157964737, 0.03504018387167307, 9.999999999998899e-05, 0.0016411522568472448, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09962493294305241, 0.09146720592259261, 0.11793244567814565, 0.08951284150752836, 0.09920591757201314, 0.10793403587252981, 0.0962900992119492, 0.08328494213253512, 0.08925049345954428, 0.09289154609054129, 0.12020256937724993, 0.0520697642653315, 0.05936027996745907, 0.07903952876914833, 0.043745890666191056, 0.10317606202338081, 0.10726034544049634, 0.0980731438877841, 0.17897218515750868, 0.17606470788325246, 0.1730830247854921, 0.1622885273756739, 0.16646298649818314, 0.17514662062807151, 0.15169868276492382, 0.16598261684134463, 0.17535692655667245, 0.029745749059496118, 0.026769411719862024, 0.01658011895142575, 0.02491303665596223, 0.02750731750058477, 0.017278510955255677, 0.057303757127379895, 0.03208283295949155, 0.014708622687554795]}, "mutation_prompt": null}
{"id": "d21dca69-9e60-4665-b43a-0945067af29a", "solution": "import numpy as np\n\nclass Improved_Adaptive_Mutation_PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n        self.temp_decay = temp_decay\n        self.mutation_scale = mutation_scale\n        self.dynamic_scale_factor = dynamic_scale_factor\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale):\n            # Simulated Annealing implementation with adaptive mutation\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                if np.random.rand() < np.exp((best_fitness - candidate_fitness) / temp):\n                    current_state = candidate_state\n            return best_state\n        \n        # Combined PSO-SA optimization with improved SA\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale)\n                self.initial_temp *= self.temp_decay  # Adjust temperature dynamically\n                \n        return best_solution", "name": "Improved_Adaptive_Mutation_PSO_SA_Optimizer", "description": "To improve convergence speed, we introduce a dynamic mutation scaling strategy that adapts based on the fitness landscape's volatility to enhance exploration and exploitation effectively.", "configspace": "", "generation": 42, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "38b2d5e4-9ae9-41f7-b2b1-387519c0e21b", "metadata": {"aucs": [0.08263869391262813, 0.10537189348558273, 0.11183264138871984, 0.10894249815120727, 0.10936846053851224, 0.11402129538355965, 0.08151715298801832, 0.10044734006518696, 0.06631653485717359, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.030393022979896323, 0.009960077267040512, 0.0023786334281409305, 0.005433529532655523, 0.018028844407162792, 0.011730387608653636, 0.012983558442637322, 0.010022063847275775, 0.013698516630642144, 0.008019277389376134, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003807569159453683, 9.999999999998899e-05, 0.0159885002800485, 0.024401771308367293, 0.9835626763622813, 0.9996067851848265, 0.9985665821016864, 0.9992039200685581, 0.9974704728708431, 0.9990335723676586, 0.995089706718323, 0.9999009861871812, 0.9957872451255732, 0.05583072738656303, 0.0017991593129148553, 0.01273904911974022, 0.018670407000398126, 0.046145304615846205, 0.006237793089872823, 0.00645164354549288, 0.009050540832098664, 0.008097509281582482, 0.047578189159767525, 0.0281137083258014, 0.029084656532247788, 0.03423736565859048, 0.06208269127504373, 0.03702887079949213, 0.04538980237517665, 0.05054527425192501, 0.03342855964570712, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005882720522139007, 0.008023836049127042, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007003158133999432, 9.999999999998899e-05, 0.012750558946003965, 9.999999999998899e-05, 0.0015038685551522768, 9.999999999998899e-05, 9.999999999998899e-05, 0.004708269760549388, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1017047563684117, 0.13072094483509533, 0.1361334485359299, 0.13134521120787757, 0.2063639642724886, 0.10072638391379951, 0.13403165533076677, 0.12462459316889818, 0.1540841810278869, 0.012370525923469766, 0.01666745141057968, 0.02007166558511675, 0.002141427384738881, 0.012566562176546947, 0.011425500037940739, 0.006501002148295965, 0.013397101886610141, 0.012385243396762946, 0.10180582813300953, 0.14236723547190655, 0.11174545721697926, 0.12412875640391519, 0.1269336658845368, 0.11441467657107729, 0.13614782136413195, 0.11402380363444986, 0.11717402752794348, 0.11804672173450859, 0.10446200375227688, 0.12117655506752545, 0.1353027737227942, 0.11816977067880474, 0.11836315165160427, 0.11625043456264961, 0.11214424313277982, 0.12187573606286095, 0.07065920384940183, 0.057685985509240756, 0.06323479274836041, 0.07778343714459901, 0.05857321267870752, 0.05833243779278341, 0.0822670726201844, 0.05232853836161844, 0.06743554120929474, 0.11905643261245857, 0.10459451462601554, 0.11078486565497658, 0.1467513978382522, 0.10602789521233957, 0.11159352760066665, 0.10908327457344769, 0.0898759503133344, 0.10721316335913778, 0.12329843157964737, 0.03504018387167307, 9.999999999998899e-05, 0.0016411522568472448, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09962493294305241, 0.09146720592259261, 0.11793244567814565, 0.08951284150752836, 0.09920591757201314, 0.10793403587252981, 0.0962900992119492, 0.08328494213253512, 0.08925049345954428, 0.09289154609054129, 0.12020256937724993, 0.0520697642653315, 0.05936027996745907, 0.07903952876914833, 0.043745890666191056, 0.10317606202338081, 0.10726034544049634, 0.0980731438877841, 0.17897218515750868, 0.17606470788325246, 0.1730830247854921, 0.1622885273756739, 0.16646298649818314, 0.17514662062807151, 0.15169868276492382, 0.16598261684134463, 0.17535692655667245, 0.029745749059496118, 0.026769411719862024, 0.01658011895142575, 0.02491303665596223, 0.02750731750058477, 0.017278510955255677, 0.057303757127379895, 0.03208283295949155, 0.014708622687554795]}, "mutation_prompt": null}
{"id": "a63cfef4-19af-4c13-ae0f-cf50d74759f4", "solution": "import numpy as np\n\nclass Enhanced_Adaptive_Mutation_PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n        self.temp_decay = temp_decay\n        self.mutation_scale = mutation_scale\n        self.dynamic_scale_factor = dynamic_scale_factor\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale):\n            # Simulated Annealing implementation with adaptive mutation and dynamic temperature adjustment\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * acceptance_prob  # Adjust temperature dynamically based on acceptance probability\n            return best_state\n        \n        # Combined PSO-SA optimization with improved SA incorporating dynamic temperature adjustment\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale)\n                self.initial_temp *= self.temp_decay  # Adjust initial temperature dynamically\n                \n        return best_solution", "name": "Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Enhanced Adaptive Mutation PSO-SA Optimizer with Dynamic Temperature Adjustment for Improved Convergence Speed", "configspace": "", "generation": 43, "fitness": 0.09397174575181542, "feedback": "The algorithm Enhanced_Adaptive_Mutation_PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.19.", "error": "", "parent_id": "38b2d5e4-9ae9-41f7-b2b1-387519c0e21b", "metadata": {"aucs": [0.10426715074306392, 0.10540615423554589, 0.11183264138871984, 0.1525540958840753, 0.11427363127525747, 0.11145383390263575, 0.1289549398450932, 0.1156452720028377, 0.13204328106145768, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.030393022979896323, 0.010055002594768658, 0.018190080380336093, 0.014327539797945099, 0.020101164011769423, 0.011730387608653636, 0.012012696582957672, 0.010942018552778765, 0.013698516630642144, 0.009766250132295706, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0020749756143720877, 0.0038124192307356086, 9.999999999998899e-05, 0.0159885002800485, 0.024401771308367293, 0.9098911974002528, 0.9996067851848265, 0.9985665472895754, 0.9992039200685581, 0.981360472870843, 0.9990335734718359, 0.9724728193537036, 0.9999009861871812, 0.9634772457328525, 0.05773277783784192, 0.00760740115961267, 0.014499070012796822, 0.018966622848715864, 0.047788774723150906, 0.01048358639339697, 0.005147291670799858, 9.999999999998899e-05, 0.030024381710137105, 0.05847788640743912, 0.030366625297762906, 0.043733148425520785, 0.026762153321836513, 0.06182081664876227, 0.03704506124568874, 0.03150684559879424, 0.03430466556072076, 0.06657267635800468, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0380076195087129, 0.04629851823043174, 0.05655226046295081, 0.007890314173900737, 0.02125032751571576, 0.028692205473987986, 0.04050125089067225, 0.041739688984755774, 0.027624650133185047, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10679609478156071, 0.12695410795940332, 0.13961972532342715, 0.13461542764147783, 0.2158231306600742, 0.10106559355299327, 0.13403165533076677, 0.12930672702822998, 0.1540841810278869, 0.012480395607710304, 0.01747947918128645, 0.020642363971088318, 0.011727695347679923, 0.012566608887133457, 0.025473498417645013, 0.005742694872400311, 0.016971586649568993, 0.012385387938900427, 0.10754749190561885, 0.11608741960969327, 0.11235756246834594, 0.11727645226351724, 0.10753259740959165, 0.10162607372686105, 0.11284246683062793, 0.12509610992770903, 0.1032684049150826, 0.15455591107168254, 0.12910715810807416, 0.12242721246469446, 0.1353027737227942, 0.12550391495718327, 0.12570943636081866, 0.1183992205017328, 0.1331339737605982, 0.1267412673935494, 0.07088470252721746, 0.0595147563321603, 0.06368717677575042, 0.07794678396961463, 0.04981371569066173, 0.07009162734751384, 0.08541815947087161, 0.054960912498627335, 0.06497674199457582, 0.14047549473203125, 0.10553263838366089, 0.11026088192928307, 0.14766865892593328, 0.12474495818519316, 0.1125825258590688, 0.11241527180175725, 0.11171461742675493, 0.10849098562813908, 0.12329843157964737, 0.03713055931292131, 9.999999999998899e-05, 0.0016411522568472448, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10489337439646129, 0.09257198183157112, 0.10943338317617124, 0.09302518570389329, 0.10051081329376943, 0.12638756449154076, 0.1004831412827687, 0.08036640277513829, 0.12609858769351723, 0.08885743409290203, 0.12838494529608746, 0.15260314146648213, 0.09754155583178692, 0.18847736793050862, 0.10862633025530088, 0.16114936957791326, 0.10500613802161096, 0.10568861451184308, 0.1833197375039194, 0.17544105423024903, 0.1699717025618004, 0.17806182777018675, 0.16261988578167075, 0.17132633190410906, 0.19940731951461754, 0.16413811950916757, 0.16358489866494041, 0.0328075745387052, 0.027278351548905122, 0.0217104111485954, 0.02491303665596223, 0.028331130849877817, 0.02728633038185746, 0.057303757127379895, 0.03208283295949155, 0.027339379706612044]}, "mutation_prompt": null}
{"id": "97f5ba67-60d9-40bd-80df-f4eaa41bb96b", "solution": "import numpy as np\n\nclass Enhanced_Adaptive_Mutation_PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n        self.temp_decay = temp_decay\n        self.mutation_scale = mutation_scale\n        self.dynamic_scale_factor = dynamic_scale_factor\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale):\n            # Simulated Annealing implementation with adaptive mutation and dynamic temperature adjustment\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * acceptance_prob  # Adjust temperature dynamically based on acceptance probability\n            return best_state\n        \n        # Combined PSO-SA optimization with improved SA incorporating dynamic temperature adjustment\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale)\n                self.initial_temp *= self.temp_decay  # Adjust initial temperature dynamically\n                \n        return best_solution", "name": "Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Enhanced Adaptive Mutation PSO-SA Optimizer with Dynamic Temperature Adjustment for Improved Convergence Speed", "configspace": "", "generation": 44, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a63cfef4-19af-4c13-ae0f-cf50d74759f4", "metadata": {"aucs": [0.10426715074306392, 0.10540615423554589, 0.11183264138871984, 0.1525540958840753, 0.11427363127525747, 0.11145383390263575, 0.1289549398450932, 0.1156452720028377, 0.13204328106145768, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.030393022979896323, 0.010055002594768658, 0.018190080380336093, 0.014327539797945099, 0.020101164011769423, 0.011730387608653636, 0.012012696582957672, 0.010942018552778765, 0.013698516630642144, 0.009766250132295706, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0020749756143720877, 0.0038124192307356086, 9.999999999998899e-05, 0.0159885002800485, 0.024401771308367293, 0.9098911974002528, 0.9996067851848265, 0.9985665472895754, 0.9992039200685581, 0.981360472870843, 0.9990335734718359, 0.9724728193537036, 0.9999009861871812, 0.9634772457328525, 0.05773277783784192, 0.00760740115961267, 0.014499070012796822, 0.018966622848715864, 0.047788774723150906, 0.01048358639339697, 0.005147291670799858, 9.999999999998899e-05, 0.030024381710137105, 0.05847788640743912, 0.030366625297762906, 0.043733148425520785, 0.026762153321836513, 0.06182081664876227, 0.03704506124568874, 0.03150684559879424, 0.03430466556072076, 0.06657267635800468, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0380076195087129, 0.04629851823043174, 0.05655226046295081, 0.007890314173900737, 0.02125032751571576, 0.028692205473987986, 0.04050125089067225, 0.041739688984755774, 0.027624650133185047, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10679609478156071, 0.12695410795940332, 0.13961972532342715, 0.13461542764147783, 0.2158231306600742, 0.10106559355299327, 0.13403165533076677, 0.12930672702822998, 0.1540841810278869, 0.012480395607710304, 0.01747947918128645, 0.020642363971088318, 0.011727695347679923, 0.012566608887133457, 0.025473498417645013, 0.005742694872400311, 0.016971586649568993, 0.012385387938900427, 0.10754749190561885, 0.11608741960969327, 0.11235756246834594, 0.11727645226351724, 0.10753259740959165, 0.10162607372686105, 0.11284246683062793, 0.12509610992770903, 0.1032684049150826, 0.15455591107168254, 0.12910715810807416, 0.12242721246469446, 0.1353027737227942, 0.12550391495718327, 0.12570943636081866, 0.1183992205017328, 0.1331339737605982, 0.1267412673935494, 0.07088470252721746, 0.0595147563321603, 0.06368717677575042, 0.07794678396961463, 0.04981371569066173, 0.07009162734751384, 0.08541815947087161, 0.054960912498627335, 0.06497674199457582, 0.14047549473203125, 0.10553263838366089, 0.11026088192928307, 0.14766865892593328, 0.12474495818519316, 0.1125825258590688, 0.11241527180175725, 0.11171461742675493, 0.10849098562813908, 0.12329843157964737, 0.03713055931292131, 9.999999999998899e-05, 0.0016411522568472448, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10489337439646129, 0.09257198183157112, 0.10943338317617124, 0.09302518570389329, 0.10051081329376943, 0.12638756449154076, 0.1004831412827687, 0.08036640277513829, 0.12609858769351723, 0.08885743409290203, 0.12838494529608746, 0.15260314146648213, 0.09754155583178692, 0.18847736793050862, 0.10862633025530088, 0.16114936957791326, 0.10500613802161096, 0.10568861451184308, 0.1833197375039194, 0.17544105423024903, 0.1699717025618004, 0.17806182777018675, 0.16261988578167075, 0.17132633190410906, 0.19940731951461754, 0.16413811950916757, 0.16358489866494041, 0.0328075745387052, 0.027278351548905122, 0.0217104111485954, 0.02491303665596223, 0.028331130849877817, 0.02728633038185746, 0.057303757127379895, 0.03208283295949155, 0.027339379706612044]}, "mutation_prompt": null}
{"id": "e8e56d53-e8ac-456c-a4f2-46cea9ba77bb", "solution": "import numpy as np\n\nclass Enhanced_Adaptive_Mutation_PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n        self.temp_decay = temp_decay\n        self.mutation_scale = mutation_scale\n        self.dynamic_scale_factor = dynamic_scale_factor\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale):\n            # Simulated Annealing implementation with adaptive mutation and dynamic temperature adjustment\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * acceptance_prob  # Adjust temperature dynamically based on acceptance probability\n            return best_state\n        \n        # Combined PSO-SA optimization with improved SA incorporating dynamic temperature adjustment\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale)\n                self.initial_temp *= self.temp_decay  # Adjust initial temperature dynamically\n                \n        return best_solution", "name": "Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Enhanced Adaptive Mutation PSO-SA Optimizer with Dynamic Temperature Adjustment for Improved Convergence Speed", "configspace": "", "generation": 44, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a63cfef4-19af-4c13-ae0f-cf50d74759f4", "metadata": {"aucs": [0.10426715074306392, 0.10540615423554589, 0.11183264138871984, 0.1525540958840753, 0.11427363127525747, 0.11145383390263575, 0.1289549398450932, 0.1156452720028377, 0.13204328106145768, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.030393022979896323, 0.010055002594768658, 0.018190080380336093, 0.014327539797945099, 0.020101164011769423, 0.011730387608653636, 0.012012696582957672, 0.010942018552778765, 0.013698516630642144, 0.009766250132295706, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0020749756143720877, 0.0038124192307356086, 9.999999999998899e-05, 0.0159885002800485, 0.024401771308367293, 0.9098911974002528, 0.9996067851848265, 0.9985665472895754, 0.9992039200685581, 0.981360472870843, 0.9990335734718359, 0.9724728193537036, 0.9999009861871812, 0.9634772457328525, 0.05773277783784192, 0.00760740115961267, 0.014499070012796822, 0.018966622848715864, 0.047788774723150906, 0.01048358639339697, 0.005147291670799858, 9.999999999998899e-05, 0.030024381710137105, 0.05847788640743912, 0.030366625297762906, 0.043733148425520785, 0.026762153321836513, 0.06182081664876227, 0.03704506124568874, 0.03150684559879424, 0.03430466556072076, 0.06657267635800468, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0380076195087129, 0.04629851823043174, 0.05655226046295081, 0.007890314173900737, 0.02125032751571576, 0.028692205473987986, 0.04050125089067225, 0.041739688984755774, 0.027624650133185047, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10679609478156071, 0.12695410795940332, 0.13961972532342715, 0.13461542764147783, 0.2158231306600742, 0.10106559355299327, 0.13403165533076677, 0.12930672702822998, 0.1540841810278869, 0.012480395607710304, 0.01747947918128645, 0.020642363971088318, 0.011727695347679923, 0.012566608887133457, 0.025473498417645013, 0.005742694872400311, 0.016971586649568993, 0.012385387938900427, 0.10754749190561885, 0.11608741960969327, 0.11235756246834594, 0.11727645226351724, 0.10753259740959165, 0.10162607372686105, 0.11284246683062793, 0.12509610992770903, 0.1032684049150826, 0.15455591107168254, 0.12910715810807416, 0.12242721246469446, 0.1353027737227942, 0.12550391495718327, 0.12570943636081866, 0.1183992205017328, 0.1331339737605982, 0.1267412673935494, 0.07088470252721746, 0.0595147563321603, 0.06368717677575042, 0.07794678396961463, 0.04981371569066173, 0.07009162734751384, 0.08541815947087161, 0.054960912498627335, 0.06497674199457582, 0.14047549473203125, 0.10553263838366089, 0.11026088192928307, 0.14766865892593328, 0.12474495818519316, 0.1125825258590688, 0.11241527180175725, 0.11171461742675493, 0.10849098562813908, 0.12329843157964737, 0.03713055931292131, 9.999999999998899e-05, 0.0016411522568472448, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10489337439646129, 0.09257198183157112, 0.10943338317617124, 0.09302518570389329, 0.10051081329376943, 0.12638756449154076, 0.1004831412827687, 0.08036640277513829, 0.12609858769351723, 0.08885743409290203, 0.12838494529608746, 0.15260314146648213, 0.09754155583178692, 0.18847736793050862, 0.10862633025530088, 0.16114936957791326, 0.10500613802161096, 0.10568861451184308, 0.1833197375039194, 0.17544105423024903, 0.1699717025618004, 0.17806182777018675, 0.16261988578167075, 0.17132633190410906, 0.19940731951461754, 0.16413811950916757, 0.16358489866494041, 0.0328075745387052, 0.027278351548905122, 0.0217104111485954, 0.02491303665596223, 0.028331130849877817, 0.02728633038185746, 0.057303757127379895, 0.03208283295949155, 0.027339379706612044]}, "mutation_prompt": null}
{"id": "7b9bca48-7f17-42eb-a241-853df1edb7dc", "solution": "import numpy as np\n\nclass Enhanced_Adaptive_Mutation_PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1, num_starts=5):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n        self.temp_decay = temp_decay\n        self.mutation_scale = mutation_scale\n        self.dynamic_scale_factor = dynamic_scale_factor\n        self.num_starts = num_starts\n\n    def __call__(self, func):\n        def sa_optimize_multi_start(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, num_starts):\n            best_state = None\n            best_fitness = float('inf')\n            for _ in range(num_starts):\n                current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n                for _ in range(max_iter):\n                    dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                    candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                    candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                    candidate_fitness = obj_func(candidate_state)\n                    if candidate_fitness < best_fitness:\n                        best_state = candidate_state\n                        best_fitness = candidate_fitness\n                    acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                    if np.random.rand() < acceptance_prob:\n                        current_state = candidate_state\n                    temp *= self.temp_decay * acceptance_prob  # Adjust temperature dynamically based on acceptance probability\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize_multi_start(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, self.num_starts)\n                self.initial_temp *= self.temp_decay  # Adjust initial temperature dynamically\n\n        return best_solution", "name": "Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Enhancing the SA optimization by introducing a multi-start strategy for initialization to escape local optima more effectively.", "configspace": "", "generation": 46, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'pso_optimize' is not defined\").", "error": "NameError(\"name 'pso_optimize' is not defined\")", "parent_id": "a63cfef4-19af-4c13-ae0f-cf50d74759f4", "metadata": {}, "mutation_prompt": null}
{"id": "bb748b42-86e6-46cb-aa6a-7a9595ca4ff4", "solution": "import numpy as np\n\nclass Enhanced_Adaptive_Mutation_PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n        self.temp_decay = temp_decay\n        self.mutation_scale = mutation_scale\n        self.dynamic_scale_factor = dynamic_scale_factor\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * acceptance_prob ** 0.9  # Adjust temperature dynamically based on acceptance probability with improved convergence\n            return best_state\n        \n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale)\n                self.initial_temp *= self.temp_decay ** 1.1  # Adjust initial temperature dynamically with improved speed\n                \n        return best_solution", "name": "Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Improved convergence speed by dynamically adjusting mutation scale and temperature decay factors in the Simulated Annealing component.", "configspace": "", "generation": 47, "fitness": 0.09423629852269627, "feedback": "The algorithm Enhanced_Adaptive_Mutation_PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.19.", "error": "", "parent_id": "a63cfef4-19af-4c13-ae0f-cf50d74759f4", "metadata": {"aucs": [0.10511094629662854, 0.10598103396598235, 0.11394362718371998, 0.18753983105847882, 0.10777770951206544, 0.11692258983559423, 0.11876588132134402, 0.1122109982590922, 0.13037370659203174, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.030393022979896323, 0.02223559941559683, 0.0023786334281409305, 0.011661677686274352, 0.01985900741408153, 0.011730387608653636, 0.012012805228970858, 0.011725845589511286, 0.013892782971292261, 0.01842981144031275, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0019525254438927941, 0.0038927501611891735, 9.999999999998899e-05, 0.0159885002800485, 0.024401771308367293, 0.9102016467142718, 0.9996067851848265, 0.9985665473043793, 0.9992039200685581, 0.9814780624015382, 0.9990335733908732, 0.9738624147046544, 0.9999009861871812, 0.9634772456912056, 0.05773277783784192, 0.00683204346662003, 0.014664576564666798, 0.01992414207036075, 0.047788774723150906, 0.010589464422342876, 0.008361233654255562, 0.0036619892823347433, 0.030024381710137105, 0.06871156341121165, 0.03856616274512181, 0.04078938659325049, 0.020303749130074933, 0.06500282808283153, 0.037103346851996344, 0.034693681792709485, 0.04412764461089136, 0.07692626450934548, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013129873888785393, 0.04821228054700899, 0.0460970753070733, 0.04376994635579323, 0.00882428332573304, 0.03082122149357769, 0.034530154860579976, 0.044578862563989796, 0.03328892359721025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14783902449788766, 0.13132170263480292, 0.13910194455755487, 0.13508240540892946, 0.2085141774227931, 0.11682569229534567, 0.13403165533076677, 0.12970941519202495, 0.1540841810278869, 0.01584634426376652, 0.017850780624616536, 0.02567365379473996, 0.01143863859884986, 0.017734115471411904, 0.01399380467267497, 0.01429700812337198, 0.045913241627991375, 0.019044921542443638, 0.13204007090518877, 0.13286263262979336, 0.1180310313218057, 0.09391909524201769, 0.09127668220920948, 0.09325548879741696, 0.10855962364140048, 0.11327548659979403, 0.10578852426127139, 0.11800151046569751, 0.1338837776877153, 0.12463309372952314, 0.13545748591336304, 0.12348295693861577, 0.14528993428291304, 0.15933389172334023, 0.12251956789634277, 0.13314987948464863, 0.07334184824568424, 0.08940980033945778, 0.06248408827691987, 0.07782197591448636, 0.056980652022920575, 0.06514401028237293, 0.08255995068984012, 0.06567451057598628, 0.08120935896086845, 0.11739412330900356, 0.12149075901735285, 0.10904565887061857, 0.1467513978382522, 0.10124178264050465, 0.11597591960458087, 0.11072940309006352, 0.09952162324712732, 0.12860476007539967, 0.12329843157964737, 0.03713055931292131, 9.999999999998899e-05, 0.0016411522568472448, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10515169389271939, 0.0937637640820903, 0.1017431974206271, 0.08888365966837797, 0.11673247978311141, 0.13432120758919242, 0.09937357626920207, 0.13799159702843666, 0.09467200755748961, 0.08415945288642401, 0.13323269795572268, 0.09087440372809164, 0.11349053291702604, 0.08149802404360706, 0.06324192642309523, 0.121259022491776, 0.10361718609926229, 0.10981804407644358, 0.17057201024288882, 0.17128509464328834, 0.17108638058393877, 0.18265726998998155, 0.1758763362970741, 0.19544407718377388, 0.17685054095396624, 0.19091768965663047, 0.17414776646495522, 0.03806571778385259, 0.03382935634879336, 0.01861924300482065, 0.025576050799674843, 0.028655426354917246, 0.01914753066401953, 0.057303757127379895, 0.038223399636208355, 0.02247389225721841]}, "mutation_prompt": null}
{"id": "6d6e19ac-4225-4ce6-bc3a-438e253adfbb", "solution": "import numpy as np\n\nclass Enhanced_Adaptive_Mutation_PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n        self.temp_decay = temp_decay\n        self.mutation_scale = mutation_scale\n        self.dynamic_scale_factor = dynamic_scale_factor\n\n    def __call__(self, func):\n        def pso_optimize(obj_func, lower_bound, upper_bound, num_particles, max_iter):\n            # Particle Swarm Optimization implementation\n            pass\n        \n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * acceptance_prob ** 0.9  # Adjust temperature dynamically based on acceptance probability with improved convergence\n            return best_state\n        \n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = pso_optimize(func, -5.0, 5.0, self.num_particles, 100)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale)\n                self.initial_temp *= self.temp_decay ** 1.1  # Adjust initial temperature dynamically with improved speed\n                \n        return best_solution", "name": "Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Improved convergence speed by dynamically adjusting mutation scale and temperature decay factors in the Simulated Annealing component.", "configspace": "", "generation": 48, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "bb748b42-86e6-46cb-aa6a-7a9595ca4ff4", "metadata": {"aucs": [0.10511094629662854, 0.10598103396598235, 0.11394362718371998, 0.18753983105847882, 0.10777770951206544, 0.11692258983559423, 0.11876588132134402, 0.1122109982590922, 0.13037370659203174, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.030393022979896323, 0.02223559941559683, 0.0023786334281409305, 0.011661677686274352, 0.01985900741408153, 0.011730387608653636, 0.012012805228970858, 0.011725845589511286, 0.013892782971292261, 0.01842981144031275, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0019525254438927941, 0.0038927501611891735, 9.999999999998899e-05, 0.0159885002800485, 0.024401771308367293, 0.9102016467142718, 0.9996067851848265, 0.9985665473043793, 0.9992039200685581, 0.9814780624015382, 0.9990335733908732, 0.9738624147046544, 0.9999009861871812, 0.9634772456912056, 0.05773277783784192, 0.00683204346662003, 0.014664576564666798, 0.01992414207036075, 0.047788774723150906, 0.010589464422342876, 0.008361233654255562, 0.0036619892823347433, 0.030024381710137105, 0.06871156341121165, 0.03856616274512181, 0.04078938659325049, 0.020303749130074933, 0.06500282808283153, 0.037103346851996344, 0.034693681792709485, 0.04412764461089136, 0.07692626450934548, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013129873888785393, 0.04821228054700899, 0.0460970753070733, 0.04376994635579323, 0.00882428332573304, 0.03082122149357769, 0.034530154860579976, 0.044578862563989796, 0.03328892359721025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14783902449788766, 0.13132170263480292, 0.13910194455755487, 0.13508240540892946, 0.2085141774227931, 0.11682569229534567, 0.13403165533076677, 0.12970941519202495, 0.1540841810278869, 0.01584634426376652, 0.017850780624616536, 0.02567365379473996, 0.01143863859884986, 0.017734115471411904, 0.01399380467267497, 0.01429700812337198, 0.045913241627991375, 0.019044921542443638, 0.13204007090518877, 0.13286263262979336, 0.1180310313218057, 0.09391909524201769, 0.09127668220920948, 0.09325548879741696, 0.10855962364140048, 0.11327548659979403, 0.10578852426127139, 0.11800151046569751, 0.1338837776877153, 0.12463309372952314, 0.13545748591336304, 0.12348295693861577, 0.14528993428291304, 0.15933389172334023, 0.12251956789634277, 0.13314987948464863, 0.07334184824568424, 0.08940980033945778, 0.06248408827691987, 0.07782197591448636, 0.056980652022920575, 0.06514401028237293, 0.08255995068984012, 0.06567451057598628, 0.08120935896086845, 0.11739412330900356, 0.12149075901735285, 0.10904565887061857, 0.1467513978382522, 0.10124178264050465, 0.11597591960458087, 0.11072940309006352, 0.09952162324712732, 0.12860476007539967, 0.12329843157964737, 0.03713055931292131, 9.999999999998899e-05, 0.0016411522568472448, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10515169389271939, 0.0937637640820903, 0.1017431974206271, 0.08888365966837797, 0.11673247978311141, 0.13432120758919242, 0.09937357626920207, 0.13799159702843666, 0.09467200755748961, 0.08415945288642401, 0.13323269795572268, 0.09087440372809164, 0.11349053291702604, 0.08149802404360706, 0.06324192642309523, 0.121259022491776, 0.10361718609926229, 0.10981804407644358, 0.17057201024288882, 0.17128509464328834, 0.17108638058393877, 0.18265726998998155, 0.1758763362970741, 0.19544407718377388, 0.17685054095396624, 0.19091768965663047, 0.17414776646495522, 0.03806571778385259, 0.03382935634879336, 0.01861924300482065, 0.025576050799674843, 0.028655426354917246, 0.01914753066401953, 0.057303757127379895, 0.038223399636208355, 0.02247389225721841]}, "mutation_prompt": null}
{"id": "3e21e470-36b3-42c6-87aa-79b4b9634493", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * acceptance_prob ** 0.9  # Adjust temperature dynamically based on acceptance probability with improved convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale)\n                self.initial_temp *= self.temp_decay ** 1.2  # Enhanced initial temperature update for faster convergence\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Improved convergence speed by dynamically adjusting mutation scale and temperature decay factors in the Simulated Annealing component and enhancing the initial temperature update strategy.", "configspace": "", "generation": 49, "fitness": 0.09457920372203557, "feedback": "The algorithm Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.19.", "error": "", "parent_id": "bb748b42-86e6-46cb-aa6a-7a9595ca4ff4", "metadata": {"aucs": [0.12644462934353873, 0.10625882034600109, 0.14786962706378237, 0.17192770707458693, 0.13591662658817716, 0.12218449866921333, 0.16612699626396077, 0.10578808884499669, 0.2041096869657829, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.018925327909581346, 0.017692810144695037, 0.01784261910231888, 0.025422525550461206, 0.00787634258048675, 0.0008125728014259925, 0.055914092473776655, 0.00328224615810635, 0.00030031289556775587, 0.019482730176248908, 0.0047645476180976365, 9.999999999998899e-05, 0.0005669668984510379, 0.00607969941567621, 0.00830469849906601, 0.0006374668586464072, 0.010703409256426544, 0.0004747874614924319, 0.9529965555505899, 0.9896756390042035, 0.9752034896896307, 0.9992039200685581, 0.9822084440861111, 0.9990337641372856, 0.9907428193537036, 0.9651026691853302, 0.9818205934813851, 0.015694651097046375, 0.03710876269560104, 0.01606976885694933, 0.005981809858896847, 0.023215655439351, 0.022267409794023973, 9.999999999998899e-05, 9.999999999998899e-05, 0.004504444749834913, 0.04885910378775393, 0.05407294047254385, 0.03646119959779681, 0.06641604831493442, 0.0556873991718807, 0.0423053120159429, 0.08067590261790392, 0.03539176027049884, 0.05180060964921196, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.025499587941569146, 0.03830377708506716, 0.045774103332550165, 0.04533652556293777, 0.02433275321749173, 0.03658051067774848, 0.018348500776445675, 0.005441009887053538, 0.030530374812332783, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12106799063781959, 0.142694507335147, 0.13147586224830443, 0.10588865142833581, 0.13685139461847395, 0.12071129501429056, 0.14232996139931997, 0.12658123578461422, 0.1463217299190066, 0.009695498159739913, 0.006611317334819455, 0.00994214687115269, 0.024281874795266445, 0.017637376333730415, 0.012708280234767555, 0.00804370243891639, 0.002764995644277457, 0.03657050249063809, 0.11301678640936952, 0.09919397271301711, 0.1276125180010469, 0.09758323879828368, 0.1031962390502571, 0.10016401004779785, 0.11378358533788235, 0.11737390568044992, 0.1001211760402404, 0.12546171792165484, 0.122855684993179, 0.12857130124372795, 0.13544962478278244, 0.12545752419912237, 0.139896407384834, 0.1293010219445414, 0.12716040844742071, 0.13005555503881006, 0.0522122186998919, 0.10236131096819157, 0.06989630258940105, 0.08086963891774013, 0.08643230853582173, 0.09450975968081021, 0.06739778890822146, 0.05667215572481887, 0.06645779195027846, 0.10568588279753188, 0.12560128401956516, 0.11020160522769351, 0.11774984395029553, 0.10747790640719579, 0.12201764333697651, 0.1245480610637294, 0.10695072526711391, 0.13204439913603905, 0.12460611692168255, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08222467972100345, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10109926106165457, 0.09091242382697351, 0.10277024931131107, 0.09722497335821334, 0.15751541164671656, 0.11889881663932389, 0.09714859605404214, 0.11854225305852306, 0.10430483963980897, 0.1026656348271785, 0.09975810799901663, 0.1360168024041506, 0.09063206619031194, 0.07869348776371776, 0.08169990781397374, 0.11963137723846518, 0.24755556147636082, 0.10902285059489747, 0.16592855568672804, 0.17156622498319174, 0.17401005210889942, 0.19039598648151534, 0.1580736562406193, 0.17071432728924796, 0.17151711778476297, 0.1760569060190431, 0.1737333775149562, 0.026338008818217906, 0.02049085448305754, 0.03755234531829044, 0.0200295456521995, 0.021210647089677348, 0.03201884768997065, 0.057303757127379895, 0.01916418305328005, 0.019802911966241066]}, "mutation_prompt": null}
{"id": "2e996ed6-43f3-449e-9306-ab9fe9f44085", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * acceptance_prob ** 0.9  # Adjust temperature dynamically based on acceptance probability with improved convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale)\n                self.initial_temp *= self.temp_decay ** 1.2  # Enhanced initial temperature update for faster convergence\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Improved convergence speed by dynamically adjusting mutation scale and temperature decay factors in the Simulated Annealing component and enhancing the initial temperature update strategy.", "configspace": "", "generation": 50, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "3e21e470-36b3-42c6-87aa-79b4b9634493", "metadata": {"aucs": [0.12644462934353873, 0.10625882034600109, 0.14786962706378237, 0.17192770707458693, 0.13591662658817716, 0.12218449866921333, 0.16612699626396077, 0.10578808884499669, 0.2041096869657829, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.018925327909581346, 0.017692810144695037, 0.01784261910231888, 0.025422525550461206, 0.00787634258048675, 0.0008125728014259925, 0.055914092473776655, 0.00328224615810635, 0.00030031289556775587, 0.019482730176248908, 0.0047645476180976365, 9.999999999998899e-05, 0.0005669668984510379, 0.00607969941567621, 0.00830469849906601, 0.0006374668586464072, 0.010703409256426544, 0.0004747874614924319, 0.9529965555505899, 0.9896756390042035, 0.9752034896896307, 0.9992039200685581, 0.9822084440861111, 0.9990337641372856, 0.9907428193537036, 0.9651026691853302, 0.9818205934813851, 0.015694651097046375, 0.03710876269560104, 0.01606976885694933, 0.005981809858896847, 0.023215655439351, 0.022267409794023973, 9.999999999998899e-05, 9.999999999998899e-05, 0.004504444749834913, 0.04885910378775393, 0.05407294047254385, 0.03646119959779681, 0.06641604831493442, 0.0556873991718807, 0.0423053120159429, 0.08067590261790392, 0.03539176027049884, 0.05180060964921196, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.025499587941569146, 0.03830377708506716, 0.045774103332550165, 0.04533652556293777, 0.02433275321749173, 0.03658051067774848, 0.018348500776445675, 0.005441009887053538, 0.030530374812332783, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12106799063781959, 0.142694507335147, 0.13147586224830443, 0.10588865142833581, 0.13685139461847395, 0.12071129501429056, 0.14232996139931997, 0.12658123578461422, 0.1463217299190066, 0.009695498159739913, 0.006611317334819455, 0.00994214687115269, 0.024281874795266445, 0.017637376333730415, 0.012708280234767555, 0.00804370243891639, 0.002764995644277457, 0.03657050249063809, 0.11301678640936952, 0.09919397271301711, 0.1276125180010469, 0.09758323879828368, 0.1031962390502571, 0.10016401004779785, 0.11378358533788235, 0.11737390568044992, 0.1001211760402404, 0.12546171792165484, 0.122855684993179, 0.12857130124372795, 0.13544962478278244, 0.12545752419912237, 0.139896407384834, 0.1293010219445414, 0.12716040844742071, 0.13005555503881006, 0.0522122186998919, 0.10236131096819157, 0.06989630258940105, 0.08086963891774013, 0.08643230853582173, 0.09450975968081021, 0.06739778890822146, 0.05667215572481887, 0.06645779195027846, 0.10568588279753188, 0.12560128401956516, 0.11020160522769351, 0.11774984395029553, 0.10747790640719579, 0.12201764333697651, 0.1245480610637294, 0.10695072526711391, 0.13204439913603905, 0.12460611692168255, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08222467972100345, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10109926106165457, 0.09091242382697351, 0.10277024931131107, 0.09722497335821334, 0.15751541164671656, 0.11889881663932389, 0.09714859605404214, 0.11854225305852306, 0.10430483963980897, 0.1026656348271785, 0.09975810799901663, 0.1360168024041506, 0.09063206619031194, 0.07869348776371776, 0.08169990781397374, 0.11963137723846518, 0.24755556147636082, 0.10902285059489747, 0.16592855568672804, 0.17156622498319174, 0.17401005210889942, 0.19039598648151534, 0.1580736562406193, 0.17071432728924796, 0.17151711778476297, 0.1760569060190431, 0.1737333775149562, 0.026338008818217906, 0.02049085448305754, 0.03755234531829044, 0.0200295456521995, 0.021210647089677348, 0.03201884768997065, 0.057303757127379895, 0.01916418305328005, 0.019802911966241066]}, "mutation_prompt": null}
{"id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Enhanced convergence speed by dynamically adjusting mutation scale and temperature decay factors with an adaptive mechanism based on historical acceptance probabilities.", "configspace": "", "generation": 51, "fitness": 0.10558296337227657, "feedback": "The algorithm Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11 with standard deviation 0.19.", "error": "", "parent_id": "3e21e470-36b3-42c6-87aa-79b4b9634493", "metadata": {"aucs": [0.12260295445140168, 0.11947685247797968, 0.1712205642752055, 0.12008761924512712, 0.18199544217734143, 0.1386268714454887, 0.17504467177553362, 0.12714558139702692, 0.20742175956360176, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04835415276942312, 0.022206927706640234, 0.03613709616761285, 0.018858583105297422, 0.02168475029126804, 0.015410207560193845, 0.05286053545021163, 0.03399007068136739, 0.01849310919291891, 0.01246382039880356, 0.0049489030419821445, 0.0006156842861095857, 0.0014424854728846137, 0.0072218570142533745, 0.01397848081933839, 0.0007534951458901817, 0.010698710116858856, 0.0009000424767853232, 0.9621546504895162, 0.9896757919514211, 0.9909559015337105, 0.9992039200685581, 0.9821743252930901, 0.9990337642319617, 0.9907428193537036, 0.9727041376700166, 0.9894891872392355, 0.043845061899681625, 0.08079043765465543, 0.020275817139078223, 0.00515055803683695, 0.05449380861911013, 0.022221385998442034, 0.00043515885738176774, 0.02615612493870545, 0.009231525090477422, 0.06808074746214865, 0.07154023331345993, 0.05355923047622235, 0.07723502547861938, 0.058164962103124385, 0.04918156957825637, 0.04515113942454885, 0.0682503653625689, 0.10535460552058906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.054542055665274036, 0.061066144799690525, 0.025618495427218835, 0.04737920306491794, 9.999999999998899e-05, 0.0003500330713901434, 0.03319877754448275, 0.03828397007689577, 0.024709618817116308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005608166234629675, 0.15437031771245624, 0.14098749370205566, 0.13746611904423767, 0.12565557642278835, 0.19220883654293475, 0.14982800426269938, 0.13937227729915935, 0.14071287288949275, 0.18393561552773052, 0.01913485645967672, 0.0323906851824135, 0.0317375939635447, 0.02906234698697896, 0.0332760377811655, 0.028853181580578924, 0.021030495235029645, 0.038314355212751394, 0.03823455409746834, 0.14471801260110695, 0.16336160564911228, 0.14435396803855072, 0.16123521435224697, 0.16986300977936186, 0.13663292517543035, 0.13410992939214417, 0.17202668963208156, 0.12467683647522321, 0.12773223689868518, 0.15241279711607458, 0.13329841251619434, 0.14104990982507193, 0.1399896969848805, 0.14595032201804647, 0.14684919724094847, 0.1434501524251811, 0.16679839159934695, 0.07412927925901791, 0.06817785650301467, 0.08966959971294308, 0.07807769700873612, 0.08230504418663909, 0.09735147839171732, 0.09055932238645115, 0.0755673690094667, 0.08449720412666162, 0.11646813376341647, 0.1439951795517661, 0.13215472325379163, 0.1306435058207257, 0.16541065603673322, 0.15222302713084368, 0.12609190406798754, 0.10590868147103993, 0.15945396274544887, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 0.001627199979735039, 9.999999999998899e-05, 9.999999999998899e-05, 0.1175556582095294, 0.1536529960543871, 0.11932827186152661, 0.17588017650267251, 0.16045650807769252, 0.17933225313104761, 0.13434904038957662, 0.14762956385481174, 0.13647071101641217, 0.13306146110709016, 0.13090067373980363, 0.13418678751562552, 0.16062228087036579, 0.12385802544278102, 0.15488825278214258, 0.14275401908604668, 0.14678328341790403, 0.1579310142416236, 0.1778596617435494, 0.1755930809686852, 0.1848768936095213, 0.18915721919526463, 0.18433888073864924, 0.18758530785712835, 0.17970616860733335, 0.18020899566339355, 0.18337711261363543, 0.042147645728826455, 0.0415530752211456, 0.03776526912769351, 0.03394360267638019, 0.05249175375060933, 0.042612102269229624, 0.057303757127379895, 0.02927366547243382, 0.047913905901639575]}, "mutation_prompt": null}
{"id": "bd2d22af-9401-4919-b09c-905c8be9c33d", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Enhanced convergence speed by dynamically adjusting mutation scale and temperature decay factors with an adaptive mechanism based on historical acceptance probabilities.", "configspace": "", "generation": 52, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.12260295445140168, 0.11947685247797968, 0.1712205642752055, 0.12008761924512712, 0.18199544217734143, 0.1386268714454887, 0.17504467177553362, 0.12714558139702692, 0.20742175956360176, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04835415276942312, 0.022206927706640234, 0.03613709616761285, 0.018858583105297422, 0.02168475029126804, 0.015410207560193845, 0.05286053545021163, 0.03399007068136739, 0.01849310919291891, 0.01246382039880356, 0.0049489030419821445, 0.0006156842861095857, 0.0014424854728846137, 0.0072218570142533745, 0.01397848081933839, 0.0007534951458901817, 0.010698710116858856, 0.0009000424767853232, 0.9621546504895162, 0.9896757919514211, 0.9909559015337105, 0.9992039200685581, 0.9821743252930901, 0.9990337642319617, 0.9907428193537036, 0.9727041376700166, 0.9894891872392355, 0.043845061899681625, 0.08079043765465543, 0.020275817139078223, 0.00515055803683695, 0.05449380861911013, 0.022221385998442034, 0.00043515885738176774, 0.02615612493870545, 0.009231525090477422, 0.06808074746214865, 0.07154023331345993, 0.05355923047622235, 0.07723502547861938, 0.058164962103124385, 0.04918156957825637, 0.04515113942454885, 0.0682503653625689, 0.10535460552058906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.054542055665274036, 0.061066144799690525, 0.025618495427218835, 0.04737920306491794, 9.999999999998899e-05, 0.0003500330713901434, 0.03319877754448275, 0.03828397007689577, 0.024709618817116308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005608166234629675, 0.15437031771245624, 0.14098749370205566, 0.13746611904423767, 0.12565557642278835, 0.19220883654293475, 0.14982800426269938, 0.13937227729915935, 0.14071287288949275, 0.18393561552773052, 0.01913485645967672, 0.0323906851824135, 0.0317375939635447, 0.02906234698697896, 0.0332760377811655, 0.028853181580578924, 0.021030495235029645, 0.038314355212751394, 0.03823455409746834, 0.14471801260110695, 0.16336160564911228, 0.14435396803855072, 0.16123521435224697, 0.16986300977936186, 0.13663292517543035, 0.13410992939214417, 0.17202668963208156, 0.12467683647522321, 0.12773223689868518, 0.15241279711607458, 0.13329841251619434, 0.14104990982507193, 0.1399896969848805, 0.14595032201804647, 0.14684919724094847, 0.1434501524251811, 0.16679839159934695, 0.07412927925901791, 0.06817785650301467, 0.08966959971294308, 0.07807769700873612, 0.08230504418663909, 0.09735147839171732, 0.09055932238645115, 0.0755673690094667, 0.08449720412666162, 0.11646813376341647, 0.1439951795517661, 0.13215472325379163, 0.1306435058207257, 0.16541065603673322, 0.15222302713084368, 0.12609190406798754, 0.10590868147103993, 0.15945396274544887, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 0.001627199979735039, 9.999999999998899e-05, 9.999999999998899e-05, 0.1175556582095294, 0.1536529960543871, 0.11932827186152661, 0.17588017650267251, 0.16045650807769252, 0.17933225313104761, 0.13434904038957662, 0.14762956385481174, 0.13647071101641217, 0.13306146110709016, 0.13090067373980363, 0.13418678751562552, 0.16062228087036579, 0.12385802544278102, 0.15488825278214258, 0.14275401908604668, 0.14678328341790403, 0.1579310142416236, 0.1778596617435494, 0.1755930809686852, 0.1848768936095213, 0.18915721919526463, 0.18433888073864924, 0.18758530785712835, 0.17970616860733335, 0.18020899566339355, 0.18337711261363543, 0.042147645728826455, 0.0415530752211456, 0.03776526912769351, 0.03394360267638019, 0.05249175375060933, 0.042612102269229624, 0.057303757127379895, 0.02927366547243382, 0.047913905901639575]}, "mutation_prompt": null}
{"id": "b7790caa-2303-4a91-9bc5-a7efd7b8cc39", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Enhanced convergence speed by dynamically adjusting mutation scale and temperature decay factors with an adaptive mechanism based on historical acceptance probabilities.", "configspace": "", "generation": 52, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.12260295445140168, 0.11947685247797968, 0.1712205642752055, 0.12008761924512712, 0.18199544217734143, 0.1386268714454887, 0.17504467177553362, 0.12714558139702692, 0.20742175956360176, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04835415276942312, 0.022206927706640234, 0.03613709616761285, 0.018858583105297422, 0.02168475029126804, 0.015410207560193845, 0.05286053545021163, 0.03399007068136739, 0.01849310919291891, 0.01246382039880356, 0.0049489030419821445, 0.0006156842861095857, 0.0014424854728846137, 0.0072218570142533745, 0.01397848081933839, 0.0007534951458901817, 0.010698710116858856, 0.0009000424767853232, 0.9621546504895162, 0.9896757919514211, 0.9909559015337105, 0.9992039200685581, 0.9821743252930901, 0.9990337642319617, 0.9907428193537036, 0.9727041376700166, 0.9894891872392355, 0.043845061899681625, 0.08079043765465543, 0.020275817139078223, 0.00515055803683695, 0.05449380861911013, 0.022221385998442034, 0.00043515885738176774, 0.02615612493870545, 0.009231525090477422, 0.06808074746214865, 0.07154023331345993, 0.05355923047622235, 0.07723502547861938, 0.058164962103124385, 0.04918156957825637, 0.04515113942454885, 0.0682503653625689, 0.10535460552058906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.054542055665274036, 0.061066144799690525, 0.025618495427218835, 0.04737920306491794, 9.999999999998899e-05, 0.0003500330713901434, 0.03319877754448275, 0.03828397007689577, 0.024709618817116308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005608166234629675, 0.15437031771245624, 0.14098749370205566, 0.13746611904423767, 0.12565557642278835, 0.19220883654293475, 0.14982800426269938, 0.13937227729915935, 0.14071287288949275, 0.18393561552773052, 0.01913485645967672, 0.0323906851824135, 0.0317375939635447, 0.02906234698697896, 0.0332760377811655, 0.028853181580578924, 0.021030495235029645, 0.038314355212751394, 0.03823455409746834, 0.14471801260110695, 0.16336160564911228, 0.14435396803855072, 0.16123521435224697, 0.16986300977936186, 0.13663292517543035, 0.13410992939214417, 0.17202668963208156, 0.12467683647522321, 0.12773223689868518, 0.15241279711607458, 0.13329841251619434, 0.14104990982507193, 0.1399896969848805, 0.14595032201804647, 0.14684919724094847, 0.1434501524251811, 0.16679839159934695, 0.07412927925901791, 0.06817785650301467, 0.08966959971294308, 0.07807769700873612, 0.08230504418663909, 0.09735147839171732, 0.09055932238645115, 0.0755673690094667, 0.08449720412666162, 0.11646813376341647, 0.1439951795517661, 0.13215472325379163, 0.1306435058207257, 0.16541065603673322, 0.15222302713084368, 0.12609190406798754, 0.10590868147103993, 0.15945396274544887, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 0.001627199979735039, 9.999999999998899e-05, 9.999999999998899e-05, 0.1175556582095294, 0.1536529960543871, 0.11932827186152661, 0.17588017650267251, 0.16045650807769252, 0.17933225313104761, 0.13434904038957662, 0.14762956385481174, 0.13647071101641217, 0.13306146110709016, 0.13090067373980363, 0.13418678751562552, 0.16062228087036579, 0.12385802544278102, 0.15488825278214258, 0.14275401908604668, 0.14678328341790403, 0.1579310142416236, 0.1778596617435494, 0.1755930809686852, 0.1848768936095213, 0.18915721919526463, 0.18433888073864924, 0.18758530785712835, 0.17970616860733335, 0.18020899566339355, 0.18337711261363543, 0.042147645728826455, 0.0415530752211456, 0.03776526912769351, 0.03394360267638019, 0.05249175375060933, 0.042612102269229624, 0.057303757127379895, 0.02927366547243382, 0.047913905901639575]}, "mutation_prompt": null}
{"id": "fbf7ee98-9f2b-4967-990c-532517800cc7", "solution": "import numpy as np\n\nclass Enhanced_Faster_Adaptive_Mutation_PSO_SA_Optimizer(Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                    mutation_scale = mutation_scale * 1.05  # Adjust mutation scale based on individual particle performance\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Enhanced_Faster_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Improving convergence speed by dynamically adjusting the mutation scale based on individual particle performance rather than a global scale factor.", "configspace": "", "generation": 54, "fitness": 0.10513045022391083, "feedback": "The algorithm Enhanced_Faster_Adaptive_Mutation_PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11 with standard deviation 0.19.", "error": "", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.1398086616701505, 0.1317455807455612, 0.12803427661759492, 0.12560955743254543, 0.162828922677955, 0.13713047556520164, 0.13668386851482306, 0.21392347479734197, 0.2053609141280851, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04399514174892816, 0.03494752426929759, 0.03889460762129493, 0.017972802801590526, 0.019427903169524696, 0.010880681152564464, 0.0529416229851698, 0.029352893551643833, 0.02710076542710882, 0.01255342533024284, 0.004949248606584522, 0.0007355255022833962, 0.0014475224556854682, 0.007232964963752031, 0.014194590117390882, 0.0007900325740032299, 0.010698740880865643, 0.0008792211967464381, 0.9622150336863943, 0.9896752108733141, 0.9985650006775206, 0.9992039200685581, 0.9818027855238531, 0.9990337629746939, 0.9912621970437044, 0.9734284391156696, 0.9894891864931026, 0.030124887987530435, 0.07813698032491068, 0.013178608831011851, 0.00515055803683695, 0.05488555885252444, 0.022221385998442034, 0.0005352702958077993, 0.006991276533887536, 0.009155977157341288, 0.06817676865023681, 0.07522445486203, 0.056765190460777326, 0.12230651910569068, 0.053222956853846926, 0.05153866683231112, 0.03945259907794385, 0.07440056097300185, 0.10807756153815262, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03784395440515742, 0.04284301699891435, 0.04691505089880865, 0.03273266169963718, 0.0460384059315726, 0.009539904606949645, 0.022826284327740698, 0.021000699293162728, 0.027769538463184418, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1420416482742115, 0.14117524212805732, 0.17175490090445766, 0.1286233070797167, 0.14911179559460108, 0.13764279015918712, 0.15305675053057843, 0.15603342060214231, 0.16736220386316403, 0.02887458854336311, 0.030374338250262922, 0.03605059288906909, 0.029866201018658334, 0.03228885539570858, 0.024266292251139743, 0.01840468237334225, 0.03300829351044143, 0.046117883062386844, 0.16762976112639294, 0.1365415339884083, 0.15211927617658516, 0.15747339139095407, 0.1279008286823895, 0.14540599460806225, 0.16112207035033588, 0.14547443771261404, 0.14491664705323115, 0.13817500126347204, 0.13763774498982362, 0.1570988696805603, 0.1489084272084541, 0.1491584985506793, 0.1656403317346079, 0.14743511985086621, 0.13325099092137438, 0.16817700405214941, 0.07490384570051478, 0.0713616591034677, 0.08239809686219635, 0.09453871998034247, 0.08711948242118928, 0.09312423916674617, 0.0748308787949592, 0.09004807489424205, 0.06778372339420968, 0.11461885755417822, 0.12534631652984463, 0.12932582425316996, 0.13736012932315567, 0.14432307423801372, 0.14075047272407715, 0.11805357356228363, 0.13496420594927927, 0.13248996849076577, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 0.08070797594904566, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1383626226157223, 0.13937176267666596, 0.17593529759884674, 0.14728147291417848, 0.15468022290010797, 0.13825557372303088, 0.13505057152406574, 0.14532868787851383, 0.2161937038565488, 0.13754458991154328, 0.10978184367685484, 0.12352224391569888, 0.14502864284358508, 0.09589059669326383, 0.09945319359780092, 0.13186503325129473, 0.15965422160683607, 0.15173961319601914, 0.16200031974802187, 0.17345485774498104, 0.17076669675565426, 0.16477548211413073, 0.16318035629841965, 0.18509271522758608, 0.16447587591854862, 0.16737342632980567, 0.16269730355116785, 0.03835515054513039, 0.04208115587934791, 0.05144020185182485, 0.02807223053111718, 0.03258900503314055, 0.052228166352211725, 0.057303757127379895, 0.04156023734797476, 0.04619373657932557]}, "mutation_prompt": null}
{"id": "fac7c732-060c-4fc1-b525-0bad6c15898d", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                    mutation_scale *= 0.95  # Adjust mutation scale dynamically based on fitness improvement for faster convergence\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Enhancing convergence speed by introducing a dynamic mutation scale adjustment based on the fitness improvement of candidate solutions.", "configspace": "", "generation": 55, "fitness": 0.10458595781005547, "feedback": "The algorithm Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.19.", "error": "", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.13779133699341906, 0.12183898804692295, 0.14324330023671483, 0.13083378289784664, 0.1559974552491642, 0.14477040918997952, 0.15307411819052197, 0.12504963495785126, 0.2041096869657829, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.058753533106460254, 0.025515916921300952, 0.02240281506897468, 0.02014950787299863, 0.025046652572266792, 0.01962402727232615, 0.05278246729249836, 0.029860464916916518, 0.026593054358475587, 0.012453257892611092, 0.0049485669812660005, 0.0006221355457149969, 0.0018050533659236256, 0.007210865529230559, 0.013669524213755335, 0.0006365967887853596, 0.010698680311583497, 0.0009113459909630972, 0.9537193381840723, 0.9896758811093848, 0.9756880801109866, 0.9992039200685581, 0.9822517371848999, 0.9990337644606955, 0.9907428193537036, 0.9727041376700166, 0.989489187374975, 0.045265144235256405, 0.036351227254495244, 0.015181504073751073, 0.00515055803683695, 0.0064659894533423135, 0.022221385998442034, 0.00030161311388565704, 0.02749400983103789, 0.013226032586835412, 0.07320799908220521, 0.07054685337836109, 0.05334740088282963, 0.07714970058899595, 0.08206939736481034, 0.05474828029269807, 0.03717569820052935, 0.0431282524296841, 0.10260853545241388, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.049887800355170486, 0.08534681015846912, 0.02390164669629702, 0.03273266169963718, 0.006683534281238246, 0.03202180972108781, 0.031825244684909326, 0.05984153432021344, 0.02615414050327869, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.21308522198506463, 0.14098749370205566, 0.12603150957021958, 0.14283428775287776, 0.16409460760236994, 0.14540442780996565, 0.13858538209695648, 0.14891166050811921, 0.1642638835162772, 0.023419292844583994, 0.025447187926951664, 0.04718882431272142, 0.027243602651775056, 0.02862228627413843, 0.023098107399327272, 0.021736732453829788, 0.030091664582676425, 0.022264679600664916, 0.12274891709974833, 0.13593136413486662, 0.17449212126716973, 0.15230661022571512, 0.15294627996203347, 0.13881241417034362, 0.13424373266909095, 0.14416828445294327, 0.13759129628307676, 0.13477163640217316, 0.14366445480843792, 0.13738465314494785, 0.14281049891957287, 0.15825773978416857, 0.1483329735499327, 0.1384739777785451, 0.12968154801962195, 0.15986241816357816, 0.08298621373488235, 0.07422014841035107, 0.08309345559869397, 0.08141879489251513, 0.0811419070403484, 0.09693296486361691, 0.07378900955480527, 0.07398337293472323, 0.08455588234783351, 0.13267674400726537, 0.13812198683649912, 0.13931066360621502, 0.12935967395144476, 0.1334101815366987, 0.1328991906089193, 0.1173279911973546, 0.10746122119289281, 0.1606572390136275, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12549511674322655, 0.144740964440785, 0.12099668442428135, 0.12342972425031296, 0.15678863878759786, 0.1578759939256219, 0.12034441803926899, 0.151585483613911, 0.1295249984435417, 0.14760885802555002, 0.1393074679938443, 0.2024109843534706, 0.13126593483402138, 0.15107036151188347, 0.12638525708808024, 0.12041707721906203, 0.16828495915571617, 0.16753260287897842, 0.18844851200067003, 0.1876929477354925, 0.17922057641133216, 0.17775971033513582, 0.1802723067958938, 0.18126374431693004, 0.18472551411286253, 0.20167692878895216, 0.18948892470577516, 0.037251032258070915, 0.05118047540076076, 0.04962822413659873, 0.0291487532127096, 0.02783510854492599, 0.037874785646576536, 0.057303757127379895, 0.03493572074196816, 0.04604305286420207]}, "mutation_prompt": null}
{"id": "d9526cd1-f4d4-42a3-acfb-a8af658f88fb", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                    mutation_scale *= acceptance_prob  # Adaptive mutation scaling\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Implement adaptive mutation scaling based on the acceptance probability to enhance convergence speed dynamically.", "configspace": "", "generation": 56, "fitness": 0.0992012944307606, "feedback": "The algorithm Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.19.", "error": "", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.11264368627199506, 0.09034126602474701, 0.12362581093881109, 0.11617220359503411, 0.11598208985495584, 0.12455093738969081, 0.1981220046912654, 0.11021780124600067, 0.2041096869657829, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.047194196152634094, 0.02440118992611351, 0.017040705422921354, 0.017965041208807264, 0.022363507679968864, 0.011933861178677008, 0.05286053545021163, 0.029959537115423207, 0.0032010692967753274, 0.012463820397922376, 0.004948903041545938, 0.00060356757749358, 0.0014424854728846137, 0.007221853480269935, 0.01397848081933839, 0.0007424009038330404, 0.010698710116858856, 0.000900041702202925, 0.9528170741052832, 0.915565710704461, 0.9724788134563916, 0.9992039200685581, 0.9827888130409351, 0.999033765229746, 0.9907428193537036, 0.9640067730484014, 0.9812991879428513, 0.04150768578302266, 0.07953085910627145, 0.020261774338620087, 0.00515055803683695, 0.05344314373308012, 0.022221385998442034, 0.00043298730278695796, 0.02615612493870545, 0.009231525090477422, 0.0681597810966954, 0.0708329899563025, 0.053349191137046725, 0.07062994687405078, 0.057347772568726585, 0.10832302198954258, 0.03442767279960157, 0.05639359718969372, 0.1017721033713378, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.054542055665274036, 0.061066144799690525, 0.025618495427218835, 0.04737920306491794, 9.999999999998899e-05, 0.0003500330713901434, 0.033198777518513634, 0.03828270659870847, 0.024709618817116308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0017611911753645515, 0.13710078057330388, 0.14479585865482514, 0.1500308188659757, 0.16178250856392729, 0.15182627244026914, 0.12364410377732837, 0.14070000152401718, 0.14049652330450824, 0.15959072835696098, 0.02046442733402143, 0.032877127547630836, 0.032592084383817554, 0.02906234698697896, 0.03238582466982076, 0.02586196028625587, 0.013166703424338455, 0.038314355212751394, 0.02577273418360959, 0.11110739081848786, 0.14906062921178764, 0.12759185155133546, 0.11204746652119024, 0.14633787921908148, 0.12371772527201241, 0.12700747712431604, 0.12800682754617088, 0.13490335509078355, 0.1413919520152387, 0.13142219997918525, 0.14767079865792165, 0.13687928049464482, 0.12884942902345686, 0.14803745458174544, 0.13405675759862967, 0.15143558134597457, 0.1345073046713483, 0.07173984025608238, 0.07109729892654637, 0.07709750010558059, 0.08680857120666241, 0.07928863103192674, 0.09168433524931585, 0.08424454073938159, 0.08970391341780415, 0.0772214830345942, 0.11768624403493899, 0.1133643590116784, 0.1475398310773004, 0.1306271765158593, 0.1148505653939561, 0.13162799613490317, 0.1169453174811268, 0.12141030803537756, 0.12768612375354804, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 0.001627199979735039, 9.999999999998899e-05, 9.999999999998899e-05, 0.10428569387028364, 0.10179735638535936, 0.10699779084062988, 0.14888211222624703, 0.10194784620511343, 0.17270132048926956, 0.1134661709539192, 0.12939588341853014, 0.13192465243080875, 0.09805752855661232, 0.10085201103169461, 0.08304114345910907, 0.11930277625873875, 0.08539452704313821, 0.10061448403212903, 0.10348656975723769, 0.10309984276890882, 0.10602858599814102, 0.16663021923961574, 0.18972090775873762, 0.1847868996647759, 0.205132255213324, 0.2042375497334753, 0.17073054849658087, 0.1896645210238107, 0.18493253398069087, 0.17144771371573297, 0.02787213162789759, 0.03858997011303, 0.04633073246023034, 0.03386686670916683, 0.02567653491630173, 0.030946811805165675, 0.057303757127379895, 0.024997632186410046, 0.033309278597089875]}, "mutation_prompt": null}
{"id": "2894c302-7bd3-4cf3-8972-c6ec58960521", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Enhanced convergence speed by dynamically adjusting mutation scale and temperature decay factors with an adaptive mechanism based on historical acceptance probabilities.", "configspace": "", "generation": 52, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.12260295445140168, 0.11947685247797968, 0.1712205642752055, 0.12008761924512712, 0.18199544217734143, 0.1386268714454887, 0.17504467177553362, 0.12714558139702692, 0.20742175956360176, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04835415276942312, 0.022206927706640234, 0.03613709616761285, 0.018858583105297422, 0.02168475029126804, 0.015410207560193845, 0.05286053545021163, 0.03399007068136739, 0.01849310919291891, 0.01246382039880356, 0.0049489030419821445, 0.0006156842861095857, 0.0014424854728846137, 0.0072218570142533745, 0.01397848081933839, 0.0007534951458901817, 0.010698710116858856, 0.0009000424767853232, 0.9621546504895162, 0.9896757919514211, 0.9909559015337105, 0.9992039200685581, 0.9821743252930901, 0.9990337642319617, 0.9907428193537036, 0.9727041376700166, 0.9894891872392355, 0.043845061899681625, 0.08079043765465543, 0.020275817139078223, 0.00515055803683695, 0.05449380861911013, 0.022221385998442034, 0.00043515885738176774, 0.02615612493870545, 0.009231525090477422, 0.06808074746214865, 0.07154023331345993, 0.05355923047622235, 0.07723502547861938, 0.058164962103124385, 0.04918156957825637, 0.04515113942454885, 0.0682503653625689, 0.10535460552058906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.054542055665274036, 0.061066144799690525, 0.025618495427218835, 0.04737920306491794, 9.999999999998899e-05, 0.0003500330713901434, 0.03319877754448275, 0.03828397007689577, 0.024709618817116308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005608166234629675, 0.15437031771245624, 0.14098749370205566, 0.13746611904423767, 0.12565557642278835, 0.19220883654293475, 0.14982800426269938, 0.13937227729915935, 0.14071287288949275, 0.18393561552773052, 0.01913485645967672, 0.0323906851824135, 0.0317375939635447, 0.02906234698697896, 0.0332760377811655, 0.028853181580578924, 0.021030495235029645, 0.038314355212751394, 0.03823455409746834, 0.14471801260110695, 0.16336160564911228, 0.14435396803855072, 0.16123521435224697, 0.16986300977936186, 0.13663292517543035, 0.13410992939214417, 0.17202668963208156, 0.12467683647522321, 0.12773223689868518, 0.15241279711607458, 0.13329841251619434, 0.14104990982507193, 0.1399896969848805, 0.14595032201804647, 0.14684919724094847, 0.1434501524251811, 0.16679839159934695, 0.07412927925901791, 0.06817785650301467, 0.08966959971294308, 0.07807769700873612, 0.08230504418663909, 0.09735147839171732, 0.09055932238645115, 0.0755673690094667, 0.08449720412666162, 0.11646813376341647, 0.1439951795517661, 0.13215472325379163, 0.1306435058207257, 0.16541065603673322, 0.15222302713084368, 0.12609190406798754, 0.10590868147103993, 0.15945396274544887, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 0.001627199979735039, 9.999999999998899e-05, 9.999999999998899e-05, 0.1175556582095294, 0.1536529960543871, 0.11932827186152661, 0.17588017650267251, 0.16045650807769252, 0.17933225313104761, 0.13434904038957662, 0.14762956385481174, 0.13647071101641217, 0.13306146110709016, 0.13090067373980363, 0.13418678751562552, 0.16062228087036579, 0.12385802544278102, 0.15488825278214258, 0.14275401908604668, 0.14678328341790403, 0.1579310142416236, 0.1778596617435494, 0.1755930809686852, 0.1848768936095213, 0.18915721919526463, 0.18433888073864924, 0.18758530785712835, 0.17970616860733335, 0.18020899566339355, 0.18337711261363543, 0.042147645728826455, 0.0415530752211456, 0.03776526912769351, 0.03394360267638019, 0.05249175375060933, 0.042612102269229624, 0.057303757127379895, 0.02927366547243382, 0.047913905901639575]}, "mutation_prompt": null}
{"id": "dd7bff18-5e25-4ee2-85c0-733737e8b9eb", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Enhanced convergence speed by dynamically adjusting mutation scale and temperature decay factors with an adaptive mechanism based on historical acceptance probabilities.", "configspace": "", "generation": 52, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.12260295445140168, 0.11947685247797968, 0.1712205642752055, 0.12008761924512712, 0.18199544217734143, 0.1386268714454887, 0.17504467177553362, 0.12714558139702692, 0.20742175956360176, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04835415276942312, 0.022206927706640234, 0.03613709616761285, 0.018858583105297422, 0.02168475029126804, 0.015410207560193845, 0.05286053545021163, 0.03399007068136739, 0.01849310919291891, 0.01246382039880356, 0.0049489030419821445, 0.0006156842861095857, 0.0014424854728846137, 0.0072218570142533745, 0.01397848081933839, 0.0007534951458901817, 0.010698710116858856, 0.0009000424767853232, 0.9621546504895162, 0.9896757919514211, 0.9909559015337105, 0.9992039200685581, 0.9821743252930901, 0.9990337642319617, 0.9907428193537036, 0.9727041376700166, 0.9894891872392355, 0.043845061899681625, 0.08079043765465543, 0.020275817139078223, 0.00515055803683695, 0.05449380861911013, 0.022221385998442034, 0.00043515885738176774, 0.02615612493870545, 0.009231525090477422, 0.06808074746214865, 0.07154023331345993, 0.05355923047622235, 0.07723502547861938, 0.058164962103124385, 0.04918156957825637, 0.04515113942454885, 0.0682503653625689, 0.10535460552058906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.054542055665274036, 0.061066144799690525, 0.025618495427218835, 0.04737920306491794, 9.999999999998899e-05, 0.0003500330713901434, 0.03319877754448275, 0.03828397007689577, 0.024709618817116308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005608166234629675, 0.15437031771245624, 0.14098749370205566, 0.13746611904423767, 0.12565557642278835, 0.19220883654293475, 0.14982800426269938, 0.13937227729915935, 0.14071287288949275, 0.18393561552773052, 0.01913485645967672, 0.0323906851824135, 0.0317375939635447, 0.02906234698697896, 0.0332760377811655, 0.028853181580578924, 0.021030495235029645, 0.038314355212751394, 0.03823455409746834, 0.14471801260110695, 0.16336160564911228, 0.14435396803855072, 0.16123521435224697, 0.16986300977936186, 0.13663292517543035, 0.13410992939214417, 0.17202668963208156, 0.12467683647522321, 0.12773223689868518, 0.15241279711607458, 0.13329841251619434, 0.14104990982507193, 0.1399896969848805, 0.14595032201804647, 0.14684919724094847, 0.1434501524251811, 0.16679839159934695, 0.07412927925901791, 0.06817785650301467, 0.08966959971294308, 0.07807769700873612, 0.08230504418663909, 0.09735147839171732, 0.09055932238645115, 0.0755673690094667, 0.08449720412666162, 0.11646813376341647, 0.1439951795517661, 0.13215472325379163, 0.1306435058207257, 0.16541065603673322, 0.15222302713084368, 0.12609190406798754, 0.10590868147103993, 0.15945396274544887, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 0.001627199979735039, 9.999999999998899e-05, 9.999999999998899e-05, 0.1175556582095294, 0.1536529960543871, 0.11932827186152661, 0.17588017650267251, 0.16045650807769252, 0.17933225313104761, 0.13434904038957662, 0.14762956385481174, 0.13647071101641217, 0.13306146110709016, 0.13090067373980363, 0.13418678751562552, 0.16062228087036579, 0.12385802544278102, 0.15488825278214258, 0.14275401908604668, 0.14678328341790403, 0.1579310142416236, 0.1778596617435494, 0.1755930809686852, 0.1848768936095213, 0.18915721919526463, 0.18433888073864924, 0.18758530785712835, 0.17970616860733335, 0.18020899566339355, 0.18337711261363543, 0.042147645728826455, 0.0415530752211456, 0.03776526912769351, 0.03394360267638019, 0.05249175375060933, 0.042612102269229624, 0.057303757127379895, 0.02927366547243382, 0.047913905901639575]}, "mutation_prompt": null}
{"id": "ae3f5d60-efda-4681-91fa-3688bbffcd12", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Enhanced convergence speed by dynamically adjusting mutation scale and temperature decay factors with an adaptive mechanism based on historical acceptance probabilities.", "configspace": "", "generation": 52, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.12260295445140168, 0.11947685247797968, 0.1712205642752055, 0.12008761924512712, 0.18199544217734143, 0.1386268714454887, 0.17504467177553362, 0.12714558139702692, 0.20742175956360176, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04835415276942312, 0.022206927706640234, 0.03613709616761285, 0.018858583105297422, 0.02168475029126804, 0.015410207560193845, 0.05286053545021163, 0.03399007068136739, 0.01849310919291891, 0.01246382039880356, 0.0049489030419821445, 0.0006156842861095857, 0.0014424854728846137, 0.0072218570142533745, 0.01397848081933839, 0.0007534951458901817, 0.010698710116858856, 0.0009000424767853232, 0.9621546504895162, 0.9896757919514211, 0.9909559015337105, 0.9992039200685581, 0.9821743252930901, 0.9990337642319617, 0.9907428193537036, 0.9727041376700166, 0.9894891872392355, 0.043845061899681625, 0.08079043765465543, 0.020275817139078223, 0.00515055803683695, 0.05449380861911013, 0.022221385998442034, 0.00043515885738176774, 0.02615612493870545, 0.009231525090477422, 0.06808074746214865, 0.07154023331345993, 0.05355923047622235, 0.07723502547861938, 0.058164962103124385, 0.04918156957825637, 0.04515113942454885, 0.0682503653625689, 0.10535460552058906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.054542055665274036, 0.061066144799690525, 0.025618495427218835, 0.04737920306491794, 9.999999999998899e-05, 0.0003500330713901434, 0.03319877754448275, 0.03828397007689577, 0.024709618817116308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005608166234629675, 0.15437031771245624, 0.14098749370205566, 0.13746611904423767, 0.12565557642278835, 0.19220883654293475, 0.14982800426269938, 0.13937227729915935, 0.14071287288949275, 0.18393561552773052, 0.01913485645967672, 0.0323906851824135, 0.0317375939635447, 0.02906234698697896, 0.0332760377811655, 0.028853181580578924, 0.021030495235029645, 0.038314355212751394, 0.03823455409746834, 0.14471801260110695, 0.16336160564911228, 0.14435396803855072, 0.16123521435224697, 0.16986300977936186, 0.13663292517543035, 0.13410992939214417, 0.17202668963208156, 0.12467683647522321, 0.12773223689868518, 0.15241279711607458, 0.13329841251619434, 0.14104990982507193, 0.1399896969848805, 0.14595032201804647, 0.14684919724094847, 0.1434501524251811, 0.16679839159934695, 0.07412927925901791, 0.06817785650301467, 0.08966959971294308, 0.07807769700873612, 0.08230504418663909, 0.09735147839171732, 0.09055932238645115, 0.0755673690094667, 0.08449720412666162, 0.11646813376341647, 0.1439951795517661, 0.13215472325379163, 0.1306435058207257, 0.16541065603673322, 0.15222302713084368, 0.12609190406798754, 0.10590868147103993, 0.15945396274544887, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 0.001627199979735039, 9.999999999998899e-05, 9.999999999998899e-05, 0.1175556582095294, 0.1536529960543871, 0.11932827186152661, 0.17588017650267251, 0.16045650807769252, 0.17933225313104761, 0.13434904038957662, 0.14762956385481174, 0.13647071101641217, 0.13306146110709016, 0.13090067373980363, 0.13418678751562552, 0.16062228087036579, 0.12385802544278102, 0.15488825278214258, 0.14275401908604668, 0.14678328341790403, 0.1579310142416236, 0.1778596617435494, 0.1755930809686852, 0.1848768936095213, 0.18915721919526463, 0.18433888073864924, 0.18758530785712835, 0.17970616860733335, 0.18020899566339355, 0.18337711261363543, 0.042147645728826455, 0.0415530752211456, 0.03776526912769351, 0.03394360267638019, 0.05249175375060933, 0.042612102269229624, 0.057303757127379895, 0.02927366547243382, 0.047913905901639575]}, "mutation_prompt": null}
{"id": "c369facd-86c4-4fac-89d6-32bdb3b1fd4c", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n                mutation_scale *= 1.05  # Dynamically adjust the mutation scale for efficient exploration-exploitation balance\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Improved convergence speed by introducing a dynamic adjustment of mutation scale based on the acceptance probability history to enhance the exploration-exploitation balance efficiently.", "configspace": "", "generation": 60, "fitness": 0.10460944957054161, "feedback": "The algorithm Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.20.", "error": "", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.1364737242037094, 0.13341839218054463, 0.1419275079556488, 0.1336949571535231, 0.15601198923779247, 0.15718640988946442, 0.19129168752704218, 0.15224499962119842, 0.20523109143662954, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01909653837501124, 0.02798874994685685, 0.0291861757969194, 0.02019308322033886, 0.03014204509306162, 0.008065289736166825, 0.053163994679037985, 0.024686239512995756, 0.016229248798382834, 0.01269240082186096, 0.004997995453708826, 0.0004671735720251924, 0.0005531745052210768, 0.007075818388811994, 0.014646590048269847, 0.0008208135344835998, 0.010698615982809634, 0.004906843068654632, 0.9623643602685961, 0.9896752108733141, 0.9985650006775206, 0.9992039200685581, 0.9818027855238531, 0.9990337629746939, 0.9911557734628758, 0.9734284391156696, 0.9894891864931026, 0.021706769012434735, 0.07781578516703325, 0.005383608202644052, 0.008184931267299356, 0.0033366500635861884, 0.022221385998442034, 0.002238360935914563, 0.0054657496022780805, 0.010037763257152443, 0.0730943229329154, 0.075089567593695, 0.0455227873529106, 0.14124535634726743, 0.051314509398008745, 0.05105802233891077, 0.040979916230467484, 0.07117791382454319, 0.10214708297679032, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05207709243000569, 0.028204978206657128, 0.021780531282106108, 0.036524032114916505, 0.016742630555325544, 0.05925770427627053, 0.018430502298671825, 0.05539935739993229, 0.012520040242782082, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.014307220326351344, 0.13772294315049272, 0.14306964539100586, 0.1398741244818702, 0.1465463995018883, 0.14694257110102116, 0.15761203359643317, 0.15916959558061594, 0.1370173342708868, 0.16379267876670345, 0.03858802946486917, 0.025965975236335592, 0.037724138952959785, 0.02580806643992506, 0.023589734203635082, 0.01711265354174263, 0.021913151344927773, 0.024217603341399663, 0.035211551592182366, 0.13958760772305945, 0.1348194452737158, 0.14806124400591436, 0.13481839584742306, 0.12890739743697122, 0.1597736521511548, 0.13816028880994435, 0.15527051337888553, 0.15447847028092765, 0.13913786794816807, 0.14234284633827687, 0.1473954025273848, 0.14902200214021177, 0.1373658647478887, 0.16046222540487598, 0.20306269366395058, 0.14091832187894948, 0.16692028228342148, 0.10202412819838214, 0.06869748680903542, 0.08832201406219065, 0.07001349301233528, 0.1029431660554605, 0.11957311968391804, 0.07285694400514608, 0.09424267920573215, 0.08038269486833471, 0.12982269334434082, 0.13058430286097022, 0.13867378990173207, 0.1246277322181264, 0.14130573957188486, 0.14789663501918837, 0.11739764808196962, 0.13913270703863723, 0.12935635582564808, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13180683932321902, 0.1630390686829014, 0.16551966838588672, 0.14468622199682069, 0.15672797222703938, 0.1470630261807464, 0.13877887891577578, 0.14628830638046308, 0.1417821493875968, 0.11881260786719616, 0.11977730689968125, 0.12151324394467233, 0.1011815643898184, 0.09212205828610442, 0.09738219562960226, 0.20675310539488878, 0.15632790436210053, 0.1657389907065837, 0.1789738547309937, 0.16739905631737984, 0.16600217732063915, 0.16224550701056673, 0.16869735210783077, 0.15708813610409178, 0.18212810648193167, 0.15956774895918624, 0.16620518530940775, 0.041668782982408836, 0.031893506010181594, 0.03772922829005132, 0.0264894220873928, 0.03751343856858114, 0.06079825372980918, 0.057303757127379895, 0.05530711659439691, 0.05844266371983864]}, "mutation_prompt": null}
{"id": "bb1b9d61-2987-42be-b526-b7566764545c", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Enhanced convergence speed by dynamically adjusting mutation scale and temperature decay factors with an adaptive mechanism based on historical acceptance probabilities.", "configspace": "", "generation": 52, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.12260295445140168, 0.11947685247797968, 0.1712205642752055, 0.12008761924512712, 0.18199544217734143, 0.1386268714454887, 0.17504467177553362, 0.12714558139702692, 0.20742175956360176, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04835415276942312, 0.022206927706640234, 0.03613709616761285, 0.018858583105297422, 0.02168475029126804, 0.015410207560193845, 0.05286053545021163, 0.03399007068136739, 0.01849310919291891, 0.01246382039880356, 0.0049489030419821445, 0.0006156842861095857, 0.0014424854728846137, 0.0072218570142533745, 0.01397848081933839, 0.0007534951458901817, 0.010698710116858856, 0.0009000424767853232, 0.9621546504895162, 0.9896757919514211, 0.9909559015337105, 0.9992039200685581, 0.9821743252930901, 0.9990337642319617, 0.9907428193537036, 0.9727041376700166, 0.9894891872392355, 0.043845061899681625, 0.08079043765465543, 0.020275817139078223, 0.00515055803683695, 0.05449380861911013, 0.022221385998442034, 0.00043515885738176774, 0.02615612493870545, 0.009231525090477422, 0.06808074746214865, 0.07154023331345993, 0.05355923047622235, 0.07723502547861938, 0.058164962103124385, 0.04918156957825637, 0.04515113942454885, 0.0682503653625689, 0.10535460552058906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.054542055665274036, 0.061066144799690525, 0.025618495427218835, 0.04737920306491794, 9.999999999998899e-05, 0.0003500330713901434, 0.03319877754448275, 0.03828397007689577, 0.024709618817116308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005608166234629675, 0.15437031771245624, 0.14098749370205566, 0.13746611904423767, 0.12565557642278835, 0.19220883654293475, 0.14982800426269938, 0.13937227729915935, 0.14071287288949275, 0.18393561552773052, 0.01913485645967672, 0.0323906851824135, 0.0317375939635447, 0.02906234698697896, 0.0332760377811655, 0.028853181580578924, 0.021030495235029645, 0.038314355212751394, 0.03823455409746834, 0.14471801260110695, 0.16336160564911228, 0.14435396803855072, 0.16123521435224697, 0.16986300977936186, 0.13663292517543035, 0.13410992939214417, 0.17202668963208156, 0.12467683647522321, 0.12773223689868518, 0.15241279711607458, 0.13329841251619434, 0.14104990982507193, 0.1399896969848805, 0.14595032201804647, 0.14684919724094847, 0.1434501524251811, 0.16679839159934695, 0.07412927925901791, 0.06817785650301467, 0.08966959971294308, 0.07807769700873612, 0.08230504418663909, 0.09735147839171732, 0.09055932238645115, 0.0755673690094667, 0.08449720412666162, 0.11646813376341647, 0.1439951795517661, 0.13215472325379163, 0.1306435058207257, 0.16541065603673322, 0.15222302713084368, 0.12609190406798754, 0.10590868147103993, 0.15945396274544887, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 0.001627199979735039, 9.999999999998899e-05, 9.999999999998899e-05, 0.1175556582095294, 0.1536529960543871, 0.11932827186152661, 0.17588017650267251, 0.16045650807769252, 0.17933225313104761, 0.13434904038957662, 0.14762956385481174, 0.13647071101641217, 0.13306146110709016, 0.13090067373980363, 0.13418678751562552, 0.16062228087036579, 0.12385802544278102, 0.15488825278214258, 0.14275401908604668, 0.14678328341790403, 0.1579310142416236, 0.1778596617435494, 0.1755930809686852, 0.1848768936095213, 0.18915721919526463, 0.18433888073864924, 0.18758530785712835, 0.17970616860733335, 0.18020899566339355, 0.18337711261363543, 0.042147645728826455, 0.0415530752211456, 0.03776526912769351, 0.03394360267638019, 0.05249175375060933, 0.042612102269229624, 0.057303757127379895, 0.02927366547243382, 0.047913905901639575]}, "mutation_prompt": null}
{"id": "5e85c5e2-f619-4e85-9dee-e6c26bef48c4", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Enhanced convergence speed by dynamically adjusting mutation scale and temperature decay factors with an adaptive mechanism based on historical acceptance probabilities.", "configspace": "", "generation": 52, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.12260295445140168, 0.11947685247797968, 0.1712205642752055, 0.12008761924512712, 0.18199544217734143, 0.1386268714454887, 0.17504467177553362, 0.12714558139702692, 0.20742175956360176, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04835415276942312, 0.022206927706640234, 0.03613709616761285, 0.018858583105297422, 0.02168475029126804, 0.015410207560193845, 0.05286053545021163, 0.03399007068136739, 0.01849310919291891, 0.01246382039880356, 0.0049489030419821445, 0.0006156842861095857, 0.0014424854728846137, 0.0072218570142533745, 0.01397848081933839, 0.0007534951458901817, 0.010698710116858856, 0.0009000424767853232, 0.9621546504895162, 0.9896757919514211, 0.9909559015337105, 0.9992039200685581, 0.9821743252930901, 0.9990337642319617, 0.9907428193537036, 0.9727041376700166, 0.9894891872392355, 0.043845061899681625, 0.08079043765465543, 0.020275817139078223, 0.00515055803683695, 0.05449380861911013, 0.022221385998442034, 0.00043515885738176774, 0.02615612493870545, 0.009231525090477422, 0.06808074746214865, 0.07154023331345993, 0.05355923047622235, 0.07723502547861938, 0.058164962103124385, 0.04918156957825637, 0.04515113942454885, 0.0682503653625689, 0.10535460552058906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.054542055665274036, 0.061066144799690525, 0.025618495427218835, 0.04737920306491794, 9.999999999998899e-05, 0.0003500330713901434, 0.03319877754448275, 0.03828397007689577, 0.024709618817116308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005608166234629675, 0.15437031771245624, 0.14098749370205566, 0.13746611904423767, 0.12565557642278835, 0.19220883654293475, 0.14982800426269938, 0.13937227729915935, 0.14071287288949275, 0.18393561552773052, 0.01913485645967672, 0.0323906851824135, 0.0317375939635447, 0.02906234698697896, 0.0332760377811655, 0.028853181580578924, 0.021030495235029645, 0.038314355212751394, 0.03823455409746834, 0.14471801260110695, 0.16336160564911228, 0.14435396803855072, 0.16123521435224697, 0.16986300977936186, 0.13663292517543035, 0.13410992939214417, 0.17202668963208156, 0.12467683647522321, 0.12773223689868518, 0.15241279711607458, 0.13329841251619434, 0.14104990982507193, 0.1399896969848805, 0.14595032201804647, 0.14684919724094847, 0.1434501524251811, 0.16679839159934695, 0.07412927925901791, 0.06817785650301467, 0.08966959971294308, 0.07807769700873612, 0.08230504418663909, 0.09735147839171732, 0.09055932238645115, 0.0755673690094667, 0.08449720412666162, 0.11646813376341647, 0.1439951795517661, 0.13215472325379163, 0.1306435058207257, 0.16541065603673322, 0.15222302713084368, 0.12609190406798754, 0.10590868147103993, 0.15945396274544887, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 0.001627199979735039, 9.999999999998899e-05, 9.999999999998899e-05, 0.1175556582095294, 0.1536529960543871, 0.11932827186152661, 0.17588017650267251, 0.16045650807769252, 0.17933225313104761, 0.13434904038957662, 0.14762956385481174, 0.13647071101641217, 0.13306146110709016, 0.13090067373980363, 0.13418678751562552, 0.16062228087036579, 0.12385802544278102, 0.15488825278214258, 0.14275401908604668, 0.14678328341790403, 0.1579310142416236, 0.1778596617435494, 0.1755930809686852, 0.1848768936095213, 0.18915721919526463, 0.18433888073864924, 0.18758530785712835, 0.17970616860733335, 0.18020899566339355, 0.18337711261363543, 0.042147645728826455, 0.0415530752211456, 0.03776526912769351, 0.03394360267638019, 0.05249175375060933, 0.042612102269229624, 0.057303757127379895, 0.02927366547243382, 0.047913905901639575]}, "mutation_prompt": null}
{"id": "7eb9aa6e-2f74-4c01-8e30-1d53a833459c", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Enhanced convergence speed by dynamically adjusting mutation scale and temperature decay factors with an adaptive mechanism based on historical acceptance probabilities.", "configspace": "", "generation": 52, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.12260295445140168, 0.11947685247797968, 0.1712205642752055, 0.12008761924512712, 0.18199544217734143, 0.1386268714454887, 0.17504467177553362, 0.12714558139702692, 0.20742175956360176, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04835415276942312, 0.022206927706640234, 0.03613709616761285, 0.018858583105297422, 0.02168475029126804, 0.015410207560193845, 0.05286053545021163, 0.03399007068136739, 0.01849310919291891, 0.01246382039880356, 0.0049489030419821445, 0.0006156842861095857, 0.0014424854728846137, 0.0072218570142533745, 0.01397848081933839, 0.0007534951458901817, 0.010698710116858856, 0.0009000424767853232, 0.9621546504895162, 0.9896757919514211, 0.9909559015337105, 0.9992039200685581, 0.9821743252930901, 0.9990337642319617, 0.9907428193537036, 0.9727041376700166, 0.9894891872392355, 0.043845061899681625, 0.08079043765465543, 0.020275817139078223, 0.00515055803683695, 0.05449380861911013, 0.022221385998442034, 0.00043515885738176774, 0.02615612493870545, 0.009231525090477422, 0.06808074746214865, 0.07154023331345993, 0.05355923047622235, 0.07723502547861938, 0.058164962103124385, 0.04918156957825637, 0.04515113942454885, 0.0682503653625689, 0.10535460552058906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.054542055665274036, 0.061066144799690525, 0.025618495427218835, 0.04737920306491794, 9.999999999998899e-05, 0.0003500330713901434, 0.03319877754448275, 0.03828397007689577, 0.024709618817116308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005608166234629675, 0.15437031771245624, 0.14098749370205566, 0.13746611904423767, 0.12565557642278835, 0.19220883654293475, 0.14982800426269938, 0.13937227729915935, 0.14071287288949275, 0.18393561552773052, 0.01913485645967672, 0.0323906851824135, 0.0317375939635447, 0.02906234698697896, 0.0332760377811655, 0.028853181580578924, 0.021030495235029645, 0.038314355212751394, 0.03823455409746834, 0.14471801260110695, 0.16336160564911228, 0.14435396803855072, 0.16123521435224697, 0.16986300977936186, 0.13663292517543035, 0.13410992939214417, 0.17202668963208156, 0.12467683647522321, 0.12773223689868518, 0.15241279711607458, 0.13329841251619434, 0.14104990982507193, 0.1399896969848805, 0.14595032201804647, 0.14684919724094847, 0.1434501524251811, 0.16679839159934695, 0.07412927925901791, 0.06817785650301467, 0.08966959971294308, 0.07807769700873612, 0.08230504418663909, 0.09735147839171732, 0.09055932238645115, 0.0755673690094667, 0.08449720412666162, 0.11646813376341647, 0.1439951795517661, 0.13215472325379163, 0.1306435058207257, 0.16541065603673322, 0.15222302713084368, 0.12609190406798754, 0.10590868147103993, 0.15945396274544887, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 0.001627199979735039, 9.999999999998899e-05, 9.999999999998899e-05, 0.1175556582095294, 0.1536529960543871, 0.11932827186152661, 0.17588017650267251, 0.16045650807769252, 0.17933225313104761, 0.13434904038957662, 0.14762956385481174, 0.13647071101641217, 0.13306146110709016, 0.13090067373980363, 0.13418678751562552, 0.16062228087036579, 0.12385802544278102, 0.15488825278214258, 0.14275401908604668, 0.14678328341790403, 0.1579310142416236, 0.1778596617435494, 0.1755930809686852, 0.1848768936095213, 0.18915721919526463, 0.18433888073864924, 0.18758530785712835, 0.17970616860733335, 0.18020899566339355, 0.18337711261363543, 0.042147645728826455, 0.0415530752211456, 0.03776526912769351, 0.03394360267638019, 0.05249175375060933, 0.042612102269229624, 0.057303757127379895, 0.02927366547243382, 0.047913905901639575]}, "mutation_prompt": null}
{"id": "a53265e0-7eac-47c5-9445-68986c7304bb", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Enhanced convergence speed by dynamically adjusting mutation scale and temperature decay factors with an adaptive mechanism based on historical acceptance probabilities.", "configspace": "", "generation": 52, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.12260295445140168, 0.11947685247797968, 0.1712205642752055, 0.12008761924512712, 0.18199544217734143, 0.1386268714454887, 0.17504467177553362, 0.12714558139702692, 0.20742175956360176, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04835415276942312, 0.022206927706640234, 0.03613709616761285, 0.018858583105297422, 0.02168475029126804, 0.015410207560193845, 0.05286053545021163, 0.03399007068136739, 0.01849310919291891, 0.01246382039880356, 0.0049489030419821445, 0.0006156842861095857, 0.0014424854728846137, 0.0072218570142533745, 0.01397848081933839, 0.0007534951458901817, 0.010698710116858856, 0.0009000424767853232, 0.9621546504895162, 0.9896757919514211, 0.9909559015337105, 0.9992039200685581, 0.9821743252930901, 0.9990337642319617, 0.9907428193537036, 0.9727041376700166, 0.9894891872392355, 0.043845061899681625, 0.08079043765465543, 0.020275817139078223, 0.00515055803683695, 0.05449380861911013, 0.022221385998442034, 0.00043515885738176774, 0.02615612493870545, 0.009231525090477422, 0.06808074746214865, 0.07154023331345993, 0.05355923047622235, 0.07723502547861938, 0.058164962103124385, 0.04918156957825637, 0.04515113942454885, 0.0682503653625689, 0.10535460552058906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.054542055665274036, 0.061066144799690525, 0.025618495427218835, 0.04737920306491794, 9.999999999998899e-05, 0.0003500330713901434, 0.03319877754448275, 0.03828397007689577, 0.024709618817116308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005608166234629675, 0.15437031771245624, 0.14098749370205566, 0.13746611904423767, 0.12565557642278835, 0.19220883654293475, 0.14982800426269938, 0.13937227729915935, 0.14071287288949275, 0.18393561552773052, 0.01913485645967672, 0.0323906851824135, 0.0317375939635447, 0.02906234698697896, 0.0332760377811655, 0.028853181580578924, 0.021030495235029645, 0.038314355212751394, 0.03823455409746834, 0.14471801260110695, 0.16336160564911228, 0.14435396803855072, 0.16123521435224697, 0.16986300977936186, 0.13663292517543035, 0.13410992939214417, 0.17202668963208156, 0.12467683647522321, 0.12773223689868518, 0.15241279711607458, 0.13329841251619434, 0.14104990982507193, 0.1399896969848805, 0.14595032201804647, 0.14684919724094847, 0.1434501524251811, 0.16679839159934695, 0.07412927925901791, 0.06817785650301467, 0.08966959971294308, 0.07807769700873612, 0.08230504418663909, 0.09735147839171732, 0.09055932238645115, 0.0755673690094667, 0.08449720412666162, 0.11646813376341647, 0.1439951795517661, 0.13215472325379163, 0.1306435058207257, 0.16541065603673322, 0.15222302713084368, 0.12609190406798754, 0.10590868147103993, 0.15945396274544887, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 0.001627199979735039, 9.999999999998899e-05, 9.999999999998899e-05, 0.1175556582095294, 0.1536529960543871, 0.11932827186152661, 0.17588017650267251, 0.16045650807769252, 0.17933225313104761, 0.13434904038957662, 0.14762956385481174, 0.13647071101641217, 0.13306146110709016, 0.13090067373980363, 0.13418678751562552, 0.16062228087036579, 0.12385802544278102, 0.15488825278214258, 0.14275401908604668, 0.14678328341790403, 0.1579310142416236, 0.1778596617435494, 0.1755930809686852, 0.1848768936095213, 0.18915721919526463, 0.18433888073864924, 0.18758530785712835, 0.17970616860733335, 0.18020899566339355, 0.18337711261363543, 0.042147645728826455, 0.0415530752211456, 0.03776526912769351, 0.03394360267638019, 0.05249175375060933, 0.042612102269229624, 0.057303757127379895, 0.02927366547243382, 0.047913905901639575]}, "mutation_prompt": null}
{"id": "b79e2b3f-642d-4b9b-9da6-36ff66c6165c", "solution": "import numpy as np\nfrom scipy.optimize import differential_evolution\n\nclass Faster_Enhanced_Adaptive_DE_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def de_optimize(obj_func, lower_bound, upper_bound):\n            bounds = [(lower_bound, upper_bound)] * self.dim\n            result = differential_evolution(obj_func, bounds, maxiter=10)\n            return result.x\n\n        best_solution = None\n        for _ in range(self.budget):\n            if np.random.rand() < 0.5:\n                best_solution = de_optimize(func, -5.0, 5.0)\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, [])\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_DE_SA_Optimizer", "description": "Improved convergence speed by incorporating a differential evolution component for global exploration alongside simulated annealing for local exploitation, leading to faster optimization.", "configspace": "", "generation": 65, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'sa_optimize' is not defined\").", "error": "NameError(\"name 'sa_optimize' is not defined\")", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {}, "mutation_prompt": null}
{"id": "c255b5ba-fece-47fd-b97d-843d69730ce5", "solution": "import numpy as np\n\nclass Enhanced_Fast_Adaptive_Mutation_PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n        self.temp_decay = temp_decay\n        self.mutation_scale = mutation_scale\n        self.dynamic_scale_factor = dynamic_scale_factor\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history) * np.mean(np.abs(candidate_state - best_state))  # Adjust temperature dynamically based on historical acceptance probabilities and fitness landscape\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Enhanced_Fast_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Improved convergence speed by dynamically adapting the mutation scale and temperature decay factors based on both historical acceptance probabilities and the fitness landscape of the objective function.", "configspace": "", "generation": 66, "fitness": 0.10486445551652916, "feedback": "The algorithm Enhanced_Fast_Adaptive_Mutation_PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.19.", "error": "", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.10760027754604962, 0.09767858352347181, 0.08880273142774842, 0.13405665944198497, 0.10602995426670203, 0.12018429479327786, 0.12122100016132531, 0.11042103827677852, 0.21287378574745464, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021894152720197235, 0.01827034682296158, 0.00796278389342131, 0.02708712771807964, 0.025471740980685387, 0.02323585523149463, 0.04953358124047558, 0.039840127749003806, 0.023889840834912635, 0.034798324936405334, 0.02045060813456434, 0.02229026634043496, 0.016830573554103334, 0.02312620477439209, 0.027239571195022072, 0.023714607479399796, 0.029871972781157607, 0.01609172263474412, 0.994080483460216, 0.9942051384241939, 0.9983763334747495, 0.9950308572752956, 0.9890678774372019, 0.9911041079329862, 0.9996016574696955, 0.9995065439384648, 0.9930219409629849, 0.08014271060847955, 0.07746461140381122, 0.062767828550504, 0.05800485764968455, 0.10201700761559274, 0.07617869749000894, 0.07266469769453943, 0.06802391310571454, 0.04135563762897254, 0.054457068241499984, 0.08153523326260059, 0.07243006983807732, 0.09708927133026246, 0.07002400810709897, 0.08989442208438281, 0.07799383119710257, 0.07205272026384135, 0.07178106884671431, 0.044902810237023916, 9.999999999998899e-05, 9.999999999998899e-05, 0.007890918462098662, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.002407916892267159, 0.014257209592713704, 9.999999999998899e-05, 9.999999999998899e-05, 0.037031924259497084, 9.999999999998899e-05, 9.999999999998899e-05, 0.08856587179961373, 0.013163025077840618, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.026893912466590564, 0.0341917357179069, 0.05119992610228841, 0.05637496450961843, 0.033008129083403004, 0.04029117927816683, 0.02900001266508867, 0.010307459649413264, 0.04319867638596675, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13177362950762617, 0.15214318187628073, 0.15760641562265032, 0.11460845877481585, 0.1534934083525319, 0.1300811748352415, 0.16545562287129256, 0.13193137213933492, 0.1496810386721521, 0.024282080209454437, 0.029139208166831354, 0.03664989042597555, 0.028042681549960813, 0.022841707781696696, 0.024191351368557434, 0.018503568091712386, 0.007980197465079386, 0.021274224120748975, 0.16097860414663046, 0.10307438262923496, 0.11482660421358526, 0.12857044131955442, 0.1203447666399392, 0.11770723211150147, 0.12339057866407643, 0.14110724735355218, 0.12048983416148717, 0.12982434772286433, 0.1337246354613224, 0.14292698750129862, 0.14317047765181345, 0.13256418704970807, 0.1476830801603224, 0.15503112503922056, 0.12937292101947873, 0.14032508208324257, 0.06302544703461976, 0.08291101900231457, 0.09287760549235102, 0.08393925124548385, 0.11309541834261361, 0.09947031438809373, 0.10589013202903697, 0.06823127534526918, 0.07317708920925148, 0.10887083568873912, 0.09586228465648239, 0.11731105850766221, 0.11695382273861266, 0.10997104434812244, 0.10804931837492693, 0.11894249294628678, 0.10834900312056472, 0.11549606728439743, 0.17098234664289558, 0.13951916008442078, 0.13439238448790125, 0.12921186548030583, 0.13514566754437507, 0.1207534681996516, 0.11993033112494123, 0.11380606396510196, 0.12391525610489718, 0.10617121072841496, 0.10569889634435325, 0.10878836260259428, 0.11668388007106933, 0.09388915358465744, 0.0927969385213111, 0.1146831003212937, 0.07792459596984391, 0.09893973149468216, 0.10454931622764019, 0.06729961795790607, 0.08170536661933425, 0.10137121942396277, 0.07175248834214776, 0.06983869919141616, 0.0653476310833383, 0.06738004422978361, 0.08251639139379163, 0.17850900149122806, 0.16587682617186383, 0.17202760425194152, 0.16784998544026353, 0.1645864129356276, 0.16771368674676468, 0.1789622889805802, 0.18306276814428213, 0.17444912210041652, 0.028119095841464326, 0.012772907135502054, 0.03801145933542682, 0.020309567353947955, 0.022331370481989854, 0.029233262252896353, 0.057303757127379895, 0.021481287780336755, 0.018187572060328283]}, "mutation_prompt": null}
{"id": "aeeee92d-dbef-48b5-8927-cb4ae843cdbe", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Enhanced convergence speed by dynamically adjusting mutation scale and temperature decay factors with an adaptive mechanism based on historical acceptance probabilities.", "configspace": "", "generation": 52, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.12260295445140168, 0.11947685247797968, 0.1712205642752055, 0.12008761924512712, 0.18199544217734143, 0.1386268714454887, 0.17504467177553362, 0.12714558139702692, 0.20742175956360176, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04835415276942312, 0.022206927706640234, 0.03613709616761285, 0.018858583105297422, 0.02168475029126804, 0.015410207560193845, 0.05286053545021163, 0.03399007068136739, 0.01849310919291891, 0.01246382039880356, 0.0049489030419821445, 0.0006156842861095857, 0.0014424854728846137, 0.0072218570142533745, 0.01397848081933839, 0.0007534951458901817, 0.010698710116858856, 0.0009000424767853232, 0.9621546504895162, 0.9896757919514211, 0.9909559015337105, 0.9992039200685581, 0.9821743252930901, 0.9990337642319617, 0.9907428193537036, 0.9727041376700166, 0.9894891872392355, 0.043845061899681625, 0.08079043765465543, 0.020275817139078223, 0.00515055803683695, 0.05449380861911013, 0.022221385998442034, 0.00043515885738176774, 0.02615612493870545, 0.009231525090477422, 0.06808074746214865, 0.07154023331345993, 0.05355923047622235, 0.07723502547861938, 0.058164962103124385, 0.04918156957825637, 0.04515113942454885, 0.0682503653625689, 0.10535460552058906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.054542055665274036, 0.061066144799690525, 0.025618495427218835, 0.04737920306491794, 9.999999999998899e-05, 0.0003500330713901434, 0.03319877754448275, 0.03828397007689577, 0.024709618817116308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005608166234629675, 0.15437031771245624, 0.14098749370205566, 0.13746611904423767, 0.12565557642278835, 0.19220883654293475, 0.14982800426269938, 0.13937227729915935, 0.14071287288949275, 0.18393561552773052, 0.01913485645967672, 0.0323906851824135, 0.0317375939635447, 0.02906234698697896, 0.0332760377811655, 0.028853181580578924, 0.021030495235029645, 0.038314355212751394, 0.03823455409746834, 0.14471801260110695, 0.16336160564911228, 0.14435396803855072, 0.16123521435224697, 0.16986300977936186, 0.13663292517543035, 0.13410992939214417, 0.17202668963208156, 0.12467683647522321, 0.12773223689868518, 0.15241279711607458, 0.13329841251619434, 0.14104990982507193, 0.1399896969848805, 0.14595032201804647, 0.14684919724094847, 0.1434501524251811, 0.16679839159934695, 0.07412927925901791, 0.06817785650301467, 0.08966959971294308, 0.07807769700873612, 0.08230504418663909, 0.09735147839171732, 0.09055932238645115, 0.0755673690094667, 0.08449720412666162, 0.11646813376341647, 0.1439951795517661, 0.13215472325379163, 0.1306435058207257, 0.16541065603673322, 0.15222302713084368, 0.12609190406798754, 0.10590868147103993, 0.15945396274544887, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 0.001627199979735039, 9.999999999998899e-05, 9.999999999998899e-05, 0.1175556582095294, 0.1536529960543871, 0.11932827186152661, 0.17588017650267251, 0.16045650807769252, 0.17933225313104761, 0.13434904038957662, 0.14762956385481174, 0.13647071101641217, 0.13306146110709016, 0.13090067373980363, 0.13418678751562552, 0.16062228087036579, 0.12385802544278102, 0.15488825278214258, 0.14275401908604668, 0.14678328341790403, 0.1579310142416236, 0.1778596617435494, 0.1755930809686852, 0.1848768936095213, 0.18915721919526463, 0.18433888073864924, 0.18758530785712835, 0.17970616860733335, 0.18020899566339355, 0.18337711261363543, 0.042147645728826455, 0.0415530752211456, 0.03776526912769351, 0.03394360267638019, 0.05249175375060933, 0.042612102269229624, 0.057303757127379895, 0.02927366547243382, 0.047913905901639575]}, "mutation_prompt": null}
{"id": "5e669692-b1c6-4979-b89d-2f2572bb7392", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = np.copy(current_state)\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                local_information = np.abs(current_state - best_state)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale * local_information, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = np.copy(candidate_state)\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = np.copy(candidate_state)\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Improve convergence speed by dynamically adjusting mutation scale based on local information of current and best states to guide the search.", "configspace": "", "generation": 68, "fitness": 0.04288557812470053, "feedback": "The algorithm Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.05.", "error": "", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.10623421029443159, 0.08871311229773948, 0.08842522814832754, 0.11455977729951228, 0.08506071893585199, 0.10801952844605622, 0.09198226442049295, 0.09033985115369159, 0.2041096869657829, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.012358551275867269, 0.01769281014462576, 0.004461091780131432, 0.01563334337031974, 0.00787634258048675, 0.0008125728014259925, 0.04810278385139932, 9.999999999998899e-05, 9.999999999998899e-05, 0.010912825385777203, 0.0004704776952112466, 9.999999999998899e-05, 0.0005061275059582426, 0.004167014296911131, 0.00806053971563614, 0.0006364474525842878, 0.010697844373597998, 0.00038461303466719166, 0.033957151583904666, 0.06185097134719364, 0.04410786384842047, 0.036943014611880653, 0.03075451425180431, 0.04192603060410327, 0.042971283450527364, 0.027035925630446433, 0.04850845562221784, 0.012019096890639958, 0.035964568539764374, 9.999999999998899e-05, 0.0037247235229315168, 0.0011686235425392155, 0.022221385998442034, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04885910378775393, 0.050889517451604305, 0.029818745549782366, 0.06160225790083218, 0.028494461998032627, 0.033097846772143336, 0.01416214647943037, 0.028330320217226257, 0.04375559358368142, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005345121163061406, 9.999999999998899e-05, 0.026657598836599017, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11763736995233287, 0.13976670719697926, 0.11813930458832089, 0.09582789855127649, 0.13395561682447865, 0.0917842073982601, 0.13858538209695648, 0.12602517500623067, 0.1463217299190066, 0.0003545501978083898, 0.0017935466330296634, 0.00033105523269916226, 0.024281874795266445, 0.004037460380864055, 0.01270828002254254, 0.005263565955110572, 0.0018840887269052642, 0.017011726239508196, 0.07339304164589777, 0.07643655227886081, 0.08817328509738032, 0.06715131493567572, 0.0637818811334604, 0.08256078796653687, 0.07892871193117534, 0.09065112263108455, 0.08922761864724127, 0.11107965904746575, 0.11682688965428156, 0.12573272414680303, 0.1333874712841645, 0.11338666190559665, 0.13686492954251994, 0.11704104606041332, 0.11582180649815421, 0.12740105252950285, 0.0520031068640332, 0.052621974592053644, 0.05945321415004945, 0.06695739661329392, 0.07040314368895428, 0.07799371831396817, 0.06422220369394449, 0.052534373767271214, 0.049275618870289195, 0.1055241851573594, 0.09044521582302623, 0.10674610453960542, 0.11695382273861266, 0.10270175261945447, 0.10523259178165878, 0.11653647058673411, 0.10490992383237896, 0.10780030180513711, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07498273501437436, 0.0820843533109672, 0.08923291727805394, 0.09002265075358884, 0.0741444106894884, 0.09195793595702362, 0.08389131295175889, 0.07100459188054242, 0.0966357088771802, 0.0530181581769531, 0.0570050717311269, 0.05605087794246577, 0.07604158100852532, 0.05682783941793201, 0.04569491615345744, 0.04479739352551004, 0.05705156017935098, 0.05031590863523039, 0.12869154810550132, 0.12124709836054348, 0.14014922643568895, 0.12276137735635495, 0.13389219818102593, 0.12251133663920977, 0.12736629891597073, 0.12738340171833695, 0.13651613324598344, 0.026338008818217906, 0.009522573371089083, 0.03741476858790571, 0.0200295456521995, 0.02059603069475502, 0.02349699493848223, 0.057303757127379895, 0.018477093798564992, 0.013496194574407094]}, "mutation_prompt": null}
{"id": "cf236ce9-087d-4b79-8d2b-4849b23cb849", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Enhanced convergence speed by dynamically adjusting mutation scale and temperature decay factors with an adaptive mechanism based on historical acceptance probabilities.", "configspace": "", "generation": 52, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.12260295445140168, 0.11947685247797968, 0.1712205642752055, 0.12008761924512712, 0.18199544217734143, 0.1386268714454887, 0.17504467177553362, 0.12714558139702692, 0.20742175956360176, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04835415276942312, 0.022206927706640234, 0.03613709616761285, 0.018858583105297422, 0.02168475029126804, 0.015410207560193845, 0.05286053545021163, 0.03399007068136739, 0.01849310919291891, 0.01246382039880356, 0.0049489030419821445, 0.0006156842861095857, 0.0014424854728846137, 0.0072218570142533745, 0.01397848081933839, 0.0007534951458901817, 0.010698710116858856, 0.0009000424767853232, 0.9621546504895162, 0.9896757919514211, 0.9909559015337105, 0.9992039200685581, 0.9821743252930901, 0.9990337642319617, 0.9907428193537036, 0.9727041376700166, 0.9894891872392355, 0.043845061899681625, 0.08079043765465543, 0.020275817139078223, 0.00515055803683695, 0.05449380861911013, 0.022221385998442034, 0.00043515885738176774, 0.02615612493870545, 0.009231525090477422, 0.06808074746214865, 0.07154023331345993, 0.05355923047622235, 0.07723502547861938, 0.058164962103124385, 0.04918156957825637, 0.04515113942454885, 0.0682503653625689, 0.10535460552058906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.054542055665274036, 0.061066144799690525, 0.025618495427218835, 0.04737920306491794, 9.999999999998899e-05, 0.0003500330713901434, 0.03319877754448275, 0.03828397007689577, 0.024709618817116308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005608166234629675, 0.15437031771245624, 0.14098749370205566, 0.13746611904423767, 0.12565557642278835, 0.19220883654293475, 0.14982800426269938, 0.13937227729915935, 0.14071287288949275, 0.18393561552773052, 0.01913485645967672, 0.0323906851824135, 0.0317375939635447, 0.02906234698697896, 0.0332760377811655, 0.028853181580578924, 0.021030495235029645, 0.038314355212751394, 0.03823455409746834, 0.14471801260110695, 0.16336160564911228, 0.14435396803855072, 0.16123521435224697, 0.16986300977936186, 0.13663292517543035, 0.13410992939214417, 0.17202668963208156, 0.12467683647522321, 0.12773223689868518, 0.15241279711607458, 0.13329841251619434, 0.14104990982507193, 0.1399896969848805, 0.14595032201804647, 0.14684919724094847, 0.1434501524251811, 0.16679839159934695, 0.07412927925901791, 0.06817785650301467, 0.08966959971294308, 0.07807769700873612, 0.08230504418663909, 0.09735147839171732, 0.09055932238645115, 0.0755673690094667, 0.08449720412666162, 0.11646813376341647, 0.1439951795517661, 0.13215472325379163, 0.1306435058207257, 0.16541065603673322, 0.15222302713084368, 0.12609190406798754, 0.10590868147103993, 0.15945396274544887, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 0.001627199979735039, 9.999999999998899e-05, 9.999999999998899e-05, 0.1175556582095294, 0.1536529960543871, 0.11932827186152661, 0.17588017650267251, 0.16045650807769252, 0.17933225313104761, 0.13434904038957662, 0.14762956385481174, 0.13647071101641217, 0.13306146110709016, 0.13090067373980363, 0.13418678751562552, 0.16062228087036579, 0.12385802544278102, 0.15488825278214258, 0.14275401908604668, 0.14678328341790403, 0.1579310142416236, 0.1778596617435494, 0.1755930809686852, 0.1848768936095213, 0.18915721919526463, 0.18433888073864924, 0.18758530785712835, 0.17970616860733335, 0.18020899566339355, 0.18337711261363543, 0.042147645728826455, 0.0415530752211456, 0.03776526912769351, 0.03394360267638019, 0.05249175375060933, 0.042612102269229624, 0.057303757127379895, 0.02927366547243382, 0.047913905901639575]}, "mutation_prompt": null}
{"id": "f5515c5c-0371-4f9d-8bf1-593442700547", "solution": "# import numpy as np\n\nclass Dynamic_Adaptive_Mutation_PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n        self.temp_decay = temp_decay\n        self.mutation_scale = mutation_scale\n        self.dynamic_scale_factor = dynamic_scale_factor\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n                self.dynamic_scale_factor += 0.05  # Introduce dynamic adaptation of mutation scale factor\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Dynamic_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Improved convergence speed by incorporating a dynamic adjustment of mutation scale and temperature decay factors based on both global and local information.", "configspace": "", "generation": 70, "fitness": 0.10548720206626541, "feedback": "The algorithm Dynamic_Adaptive_Mutation_PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11 with standard deviation 0.19.", "error": "", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.1221410282163532, 0.12065925830898416, 0.11282175887265788, 0.14458534856300742, 0.156298529423048, 0.1360607854014817, 0.15421819568461959, 0.11473612640253505, 0.20459905710755066, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.044841360650050954, 0.027500215638506798, 0.032391324038998914, 0.027535292023638802, 0.02529384200169893, 0.015793452540565522, 0.05243571872970365, 0.034588266189045314, 0.04431299929263499, 0.01258853254726322, 0.004576908424330228, 9.999999999998899e-05, 0.0005061275059582426, 0.005543225458612633, 0.00911859521579228, 0.0008546881843066734, 0.010700206307952098, 0.0070940151381396754, 0.9539031175096193, 0.9896757919514211, 0.9778229746078997, 0.9992039200685581, 0.9821927092165538, 0.9990337642319617, 0.9907428193537036, 0.9727041376700166, 0.9894891872392355, 0.035661590983869784, 0.05174583403123889, 0.017451210880464862, 0.01791605405309815, 0.0225572159755002, 0.05072321621075904, 0.029089341591809204, 0.02884157507339402, 0.02365585637620493, 0.08378073742341863, 0.08265662057753997, 0.05151077641291557, 0.07320451307145026, 0.05212486353594048, 0.10106969734321392, 0.04949790255556252, 0.06164167430578982, 0.08565401965110742, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.054776455375859956, 0.03871940436000876, 0.046531561104444674, 0.03601772544390136, 0.010313815657327141, 0.06740812265856255, 0.038978582592921196, 0.030387337084567867, 0.05532660702093761, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0006226964611547592, 9.999999999998899e-05, 0.0016593098530108819, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1537033938922583, 0.14156781209113212, 0.12078670838076944, 0.11967150268275362, 0.16757158468786182, 0.20831205918583173, 0.14880605174058614, 0.15667438193271033, 0.1521226448245181, 0.016887234578156107, 0.03543091121284869, 0.04449095295869432, 0.024281874795266445, 0.03206822023287459, 0.015017108240850008, 0.033422064584421984, 0.03242735672548702, 0.024770961007222314, 0.13018247871806854, 0.1591814928459394, 0.1206406941176903, 0.18220292916337544, 0.13960068588237773, 0.14857483142275218, 0.14889313317857833, 0.13040515548113873, 0.14424586321791244, 0.15284296961500043, 0.13712360581355532, 0.14442514758730363, 0.140171566926659, 0.12074602050763483, 0.1453289347148773, 0.14200108246844334, 0.13928028257611347, 0.15514299848865598, 0.08391945115024724, 0.07302507161620708, 0.0937619100815642, 0.0745928101338581, 0.07574334839082841, 0.08756367596302372, 0.08960596898241546, 0.08316159347219887, 0.08520024544563254, 0.12056053311484227, 0.12747322990874432, 0.13123758822877973, 0.13312326194534874, 0.13521224410137989, 0.14208128854546376, 0.14011367379453, 0.13480327748705645, 0.12333660827087167, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14584637548149026, 0.14071990360668807, 0.15530019671692585, 0.12206463036935766, 0.1514055838814884, 0.12279272280947495, 0.11915418596651417, 0.1466436857249167, 0.13693591555537699, 0.1431344864914338, 0.16559191576518517, 0.12468436164627816, 0.21161231004325487, 0.1226998231947215, 0.15112967358671447, 0.12413638630020829, 0.15784540761806853, 0.14716895864486157, 0.18092978626035738, 0.17428582238908452, 0.18459035074686725, 0.1763552445611586, 0.20895732531973787, 0.17722403572920464, 0.18542784969976145, 0.20307426417750274, 0.18069113858965014, 0.03945451643419218, 0.03196299049602125, 0.07774176238326014, 0.025307270493752143, 0.042835337031516096, 0.03575833852627397, 0.057303757127379895, 0.04560556074847466, 0.04568163527337854]}, "mutation_prompt": null}
{"id": "bc654885-c284-4c03-aac8-7193a56527ff", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on current acceptance probabilities for improved convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.4  # Adjust temperature decay factor for faster convergence\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Improved convergence speed by dynamically adjusting mutation scale and temperature decay factors with an adaptive mechanism based on the current acceptance probabilities.", "configspace": "", "generation": 71, "fitness": 0.10549268294775083, "feedback": "The algorithm Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11 with standard deviation 0.19.", "error": "", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.12893215478198383, 0.13332782356323647, 0.19937514808832335, 0.1152039472577504, 0.18328822577013204, 0.15470849919917962, 0.17257731331528958, 0.14072271573048734, 0.2041096869657829, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0425308439881501, 0.021331015492597416, 0.03404864643677907, 0.02102156295845148, 0.008805906785288808, 0.014970262623128283, 0.052684886540200426, 0.037547069433847224, 0.010515382502660042, 0.01246341008817986, 0.004097302469827757, 0.00163739363825266, 0.0005061275059582426, 0.006298396764688019, 0.012097374274659844, 0.0032473215914916587, 0.010698667195466971, 0.0009231499018549361, 0.9621546504895162, 0.9896757919514211, 0.9909559015337105, 0.9992039200685581, 0.982175717150468, 0.9990337642319617, 0.9907428193537036, 0.9727041376700166, 0.9894891872392355, 0.04649759216997695, 0.08115378383501481, 0.01710317001972339, 0.005245613671097438, 0.05310845103515471, 0.022221385998442034, 0.007019620302002649, 0.029099318406041075, 0.01782437680185811, 0.07378437751406397, 0.061453844738558305, 0.039040400425924604, 0.07567419676188214, 0.07681265291010664, 0.05170168203709835, 0.03792280064328446, 0.048075974197478, 0.10161586188773453, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.054616265282230736, 0.06047029425079853, 0.038376762190539204, 0.04151086657941416, 0.018467782841076086, 0.02694077900175329, 0.04296905029774112, 0.018890891450513703, 0.009138530230284214, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0004659167390982377, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19010411630227508, 0.14098749370205566, 0.13896374223123242, 0.12531156126817566, 0.16925415885100226, 0.15432832518083106, 0.13950910736878797, 0.14814385044036804, 0.15252248950503056, 0.033634789029028056, 0.03305824538341473, 0.05328030334451195, 0.024281874795266445, 0.030303584103097414, 0.028714130625347556, 0.013060575938071861, 0.03522444424623572, 0.03390240453313709, 0.15976347275271796, 0.12637653072770916, 0.16072090681425566, 0.15004348495661857, 0.15849665669600121, 0.17669546263220015, 0.14263828721639094, 0.12827661192235296, 0.12108678711540866, 0.13642060829372882, 0.13604824797581094, 0.14171882756983434, 0.14329325106193558, 0.1306029323285458, 0.14284826846369902, 0.15734573583947387, 0.1478442030396312, 0.14763544091084313, 0.08654005351610228, 0.07349385878497783, 0.0798947675613263, 0.09003064105745218, 0.09046701011568858, 0.09168005244773281, 0.09228314409835292, 0.08622960518159273, 0.0957720606032737, 0.12003908344054126, 0.14593724345027004, 0.13133992233441205, 0.12251176905852368, 0.1289728096881816, 0.12236041605398573, 0.12644192128149967, 0.11663230846280148, 0.13038250252710604, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14016494421714543, 0.16539444410728044, 0.12508213281330338, 0.11790195382862345, 0.12879022307350274, 0.13735828881320544, 0.1357103538921376, 0.15203093441329296, 0.15272225055669664, 0.14323960744139808, 0.201582618336416, 0.11387417242133291, 0.11773561861548443, 0.19254098954491006, 0.11532104579280489, 0.15472924352188622, 0.1628021129013778, 0.1573945954631295, 0.18449853753680368, 0.16919847191183834, 0.17277047018237268, 0.18617450823317772, 0.1751799107037063, 0.1822743449229458, 0.18918389507046462, 0.17460115908192841, 0.1880164681161014, 0.0364720506656564, 0.041813979379402344, 0.052665988286496934, 0.041445543365137616, 0.05279172134426857, 0.04163691906910494, 0.057303757127379895, 0.03471583891461838, 0.04326591102176769]}, "mutation_prompt": null}
{"id": "f676978a-def4-4aa0-b751-a44b049557e3", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Enhanced convergence speed by dynamically adjusting mutation scale and temperature decay factors with an adaptive mechanism based on historical acceptance probabilities.", "configspace": "", "generation": 52, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.12260295445140168, 0.11947685247797968, 0.1712205642752055, 0.12008761924512712, 0.18199544217734143, 0.1386268714454887, 0.17504467177553362, 0.12714558139702692, 0.20742175956360176, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04835415276942312, 0.022206927706640234, 0.03613709616761285, 0.018858583105297422, 0.02168475029126804, 0.015410207560193845, 0.05286053545021163, 0.03399007068136739, 0.01849310919291891, 0.01246382039880356, 0.0049489030419821445, 0.0006156842861095857, 0.0014424854728846137, 0.0072218570142533745, 0.01397848081933839, 0.0007534951458901817, 0.010698710116858856, 0.0009000424767853232, 0.9621546504895162, 0.9896757919514211, 0.9909559015337105, 0.9992039200685581, 0.9821743252930901, 0.9990337642319617, 0.9907428193537036, 0.9727041376700166, 0.9894891872392355, 0.043845061899681625, 0.08079043765465543, 0.020275817139078223, 0.00515055803683695, 0.05449380861911013, 0.022221385998442034, 0.00043515885738176774, 0.02615612493870545, 0.009231525090477422, 0.06808074746214865, 0.07154023331345993, 0.05355923047622235, 0.07723502547861938, 0.058164962103124385, 0.04918156957825637, 0.04515113942454885, 0.0682503653625689, 0.10535460552058906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.054542055665274036, 0.061066144799690525, 0.025618495427218835, 0.04737920306491794, 9.999999999998899e-05, 0.0003500330713901434, 0.03319877754448275, 0.03828397007689577, 0.024709618817116308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005608166234629675, 0.15437031771245624, 0.14098749370205566, 0.13746611904423767, 0.12565557642278835, 0.19220883654293475, 0.14982800426269938, 0.13937227729915935, 0.14071287288949275, 0.18393561552773052, 0.01913485645967672, 0.0323906851824135, 0.0317375939635447, 0.02906234698697896, 0.0332760377811655, 0.028853181580578924, 0.021030495235029645, 0.038314355212751394, 0.03823455409746834, 0.14471801260110695, 0.16336160564911228, 0.14435396803855072, 0.16123521435224697, 0.16986300977936186, 0.13663292517543035, 0.13410992939214417, 0.17202668963208156, 0.12467683647522321, 0.12773223689868518, 0.15241279711607458, 0.13329841251619434, 0.14104990982507193, 0.1399896969848805, 0.14595032201804647, 0.14684919724094847, 0.1434501524251811, 0.16679839159934695, 0.07412927925901791, 0.06817785650301467, 0.08966959971294308, 0.07807769700873612, 0.08230504418663909, 0.09735147839171732, 0.09055932238645115, 0.0755673690094667, 0.08449720412666162, 0.11646813376341647, 0.1439951795517661, 0.13215472325379163, 0.1306435058207257, 0.16541065603673322, 0.15222302713084368, 0.12609190406798754, 0.10590868147103993, 0.15945396274544887, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 0.001627199979735039, 9.999999999998899e-05, 9.999999999998899e-05, 0.1175556582095294, 0.1536529960543871, 0.11932827186152661, 0.17588017650267251, 0.16045650807769252, 0.17933225313104761, 0.13434904038957662, 0.14762956385481174, 0.13647071101641217, 0.13306146110709016, 0.13090067373980363, 0.13418678751562552, 0.16062228087036579, 0.12385802544278102, 0.15488825278214258, 0.14275401908604668, 0.14678328341790403, 0.1579310142416236, 0.1778596617435494, 0.1755930809686852, 0.1848768936095213, 0.18915721919526463, 0.18433888073864924, 0.18758530785712835, 0.17970616860733335, 0.18020899566339355, 0.18337711261363543, 0.042147645728826455, 0.0415530752211456, 0.03776526912769351, 0.03394360267638019, 0.05249175375060933, 0.042612102269229624, 0.057303757127379895, 0.02927366547243382, 0.047913905901639575]}, "mutation_prompt": null}
{"id": "04ae1bcb-4322-4d35-b9e2-e755de19d777", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Enhanced convergence speed by dynamically adjusting mutation scale and temperature decay factors with an adaptive mechanism based on historical acceptance probabilities.", "configspace": "", "generation": 52, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.12260295445140168, 0.11947685247797968, 0.1712205642752055, 0.12008761924512712, 0.18199544217734143, 0.1386268714454887, 0.17504467177553362, 0.12714558139702692, 0.20742175956360176, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04835415276942312, 0.022206927706640234, 0.03613709616761285, 0.018858583105297422, 0.02168475029126804, 0.015410207560193845, 0.05286053545021163, 0.03399007068136739, 0.01849310919291891, 0.01246382039880356, 0.0049489030419821445, 0.0006156842861095857, 0.0014424854728846137, 0.0072218570142533745, 0.01397848081933839, 0.0007534951458901817, 0.010698710116858856, 0.0009000424767853232, 0.9621546504895162, 0.9896757919514211, 0.9909559015337105, 0.9992039200685581, 0.9821743252930901, 0.9990337642319617, 0.9907428193537036, 0.9727041376700166, 0.9894891872392355, 0.043845061899681625, 0.08079043765465543, 0.020275817139078223, 0.00515055803683695, 0.05449380861911013, 0.022221385998442034, 0.00043515885738176774, 0.02615612493870545, 0.009231525090477422, 0.06808074746214865, 0.07154023331345993, 0.05355923047622235, 0.07723502547861938, 0.058164962103124385, 0.04918156957825637, 0.04515113942454885, 0.0682503653625689, 0.10535460552058906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.054542055665274036, 0.061066144799690525, 0.025618495427218835, 0.04737920306491794, 9.999999999998899e-05, 0.0003500330713901434, 0.03319877754448275, 0.03828397007689577, 0.024709618817116308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005608166234629675, 0.15437031771245624, 0.14098749370205566, 0.13746611904423767, 0.12565557642278835, 0.19220883654293475, 0.14982800426269938, 0.13937227729915935, 0.14071287288949275, 0.18393561552773052, 0.01913485645967672, 0.0323906851824135, 0.0317375939635447, 0.02906234698697896, 0.0332760377811655, 0.028853181580578924, 0.021030495235029645, 0.038314355212751394, 0.03823455409746834, 0.14471801260110695, 0.16336160564911228, 0.14435396803855072, 0.16123521435224697, 0.16986300977936186, 0.13663292517543035, 0.13410992939214417, 0.17202668963208156, 0.12467683647522321, 0.12773223689868518, 0.15241279711607458, 0.13329841251619434, 0.14104990982507193, 0.1399896969848805, 0.14595032201804647, 0.14684919724094847, 0.1434501524251811, 0.16679839159934695, 0.07412927925901791, 0.06817785650301467, 0.08966959971294308, 0.07807769700873612, 0.08230504418663909, 0.09735147839171732, 0.09055932238645115, 0.0755673690094667, 0.08449720412666162, 0.11646813376341647, 0.1439951795517661, 0.13215472325379163, 0.1306435058207257, 0.16541065603673322, 0.15222302713084368, 0.12609190406798754, 0.10590868147103993, 0.15945396274544887, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 0.001627199979735039, 9.999999999998899e-05, 9.999999999998899e-05, 0.1175556582095294, 0.1536529960543871, 0.11932827186152661, 0.17588017650267251, 0.16045650807769252, 0.17933225313104761, 0.13434904038957662, 0.14762956385481174, 0.13647071101641217, 0.13306146110709016, 0.13090067373980363, 0.13418678751562552, 0.16062228087036579, 0.12385802544278102, 0.15488825278214258, 0.14275401908604668, 0.14678328341790403, 0.1579310142416236, 0.1778596617435494, 0.1755930809686852, 0.1848768936095213, 0.18915721919526463, 0.18433888073864924, 0.18758530785712835, 0.17970616860733335, 0.18020899566339355, 0.18337711261363543, 0.042147645728826455, 0.0415530752211456, 0.03776526912769351, 0.03394360267638019, 0.05249175375060933, 0.042612102269229624, 0.057303757127379895, 0.02927366547243382, 0.047913905901639575]}, "mutation_prompt": null}
{"id": "94dfdfc6-6c7d-48b8-9d7a-fb1d3eb03182", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Enhanced convergence speed by dynamically adjusting mutation scale and temperature decay factors with an adaptive mechanism based on historical acceptance probabilities.", "configspace": "", "generation": 52, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.12260295445140168, 0.11947685247797968, 0.1712205642752055, 0.12008761924512712, 0.18199544217734143, 0.1386268714454887, 0.17504467177553362, 0.12714558139702692, 0.20742175956360176, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04835415276942312, 0.022206927706640234, 0.03613709616761285, 0.018858583105297422, 0.02168475029126804, 0.015410207560193845, 0.05286053545021163, 0.03399007068136739, 0.01849310919291891, 0.01246382039880356, 0.0049489030419821445, 0.0006156842861095857, 0.0014424854728846137, 0.0072218570142533745, 0.01397848081933839, 0.0007534951458901817, 0.010698710116858856, 0.0009000424767853232, 0.9621546504895162, 0.9896757919514211, 0.9909559015337105, 0.9992039200685581, 0.9821743252930901, 0.9990337642319617, 0.9907428193537036, 0.9727041376700166, 0.9894891872392355, 0.043845061899681625, 0.08079043765465543, 0.020275817139078223, 0.00515055803683695, 0.05449380861911013, 0.022221385998442034, 0.00043515885738176774, 0.02615612493870545, 0.009231525090477422, 0.06808074746214865, 0.07154023331345993, 0.05355923047622235, 0.07723502547861938, 0.058164962103124385, 0.04918156957825637, 0.04515113942454885, 0.0682503653625689, 0.10535460552058906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.054542055665274036, 0.061066144799690525, 0.025618495427218835, 0.04737920306491794, 9.999999999998899e-05, 0.0003500330713901434, 0.03319877754448275, 0.03828397007689577, 0.024709618817116308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005608166234629675, 0.15437031771245624, 0.14098749370205566, 0.13746611904423767, 0.12565557642278835, 0.19220883654293475, 0.14982800426269938, 0.13937227729915935, 0.14071287288949275, 0.18393561552773052, 0.01913485645967672, 0.0323906851824135, 0.0317375939635447, 0.02906234698697896, 0.0332760377811655, 0.028853181580578924, 0.021030495235029645, 0.038314355212751394, 0.03823455409746834, 0.14471801260110695, 0.16336160564911228, 0.14435396803855072, 0.16123521435224697, 0.16986300977936186, 0.13663292517543035, 0.13410992939214417, 0.17202668963208156, 0.12467683647522321, 0.12773223689868518, 0.15241279711607458, 0.13329841251619434, 0.14104990982507193, 0.1399896969848805, 0.14595032201804647, 0.14684919724094847, 0.1434501524251811, 0.16679839159934695, 0.07412927925901791, 0.06817785650301467, 0.08966959971294308, 0.07807769700873612, 0.08230504418663909, 0.09735147839171732, 0.09055932238645115, 0.0755673690094667, 0.08449720412666162, 0.11646813376341647, 0.1439951795517661, 0.13215472325379163, 0.1306435058207257, 0.16541065603673322, 0.15222302713084368, 0.12609190406798754, 0.10590868147103993, 0.15945396274544887, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 0.001627199979735039, 9.999999999998899e-05, 9.999999999998899e-05, 0.1175556582095294, 0.1536529960543871, 0.11932827186152661, 0.17588017650267251, 0.16045650807769252, 0.17933225313104761, 0.13434904038957662, 0.14762956385481174, 0.13647071101641217, 0.13306146110709016, 0.13090067373980363, 0.13418678751562552, 0.16062228087036579, 0.12385802544278102, 0.15488825278214258, 0.14275401908604668, 0.14678328341790403, 0.1579310142416236, 0.1778596617435494, 0.1755930809686852, 0.1848768936095213, 0.18915721919526463, 0.18433888073864924, 0.18758530785712835, 0.17970616860733335, 0.18020899566339355, 0.18337711261363543, 0.042147645728826455, 0.0415530752211456, 0.03776526912769351, 0.03394360267638019, 0.05249175375060933, 0.042612102269229624, 0.057303757127379895, 0.02927366547243382, 0.047913905901639575]}, "mutation_prompt": null}
{"id": "28e04694-789d-4b53-acaa-1e50ab0a14fe", "solution": "# import numpy as np\n\nclass Hybrid_SA_DE_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1, de_scale_factor=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n        self.temp_decay = temp_decay\n        self.mutation_scale = mutation_scale\n        self.dynamic_scale_factor = dynamic_scale_factor\n        self.de_scale_factor = de_scale_factor\n\n    def __call__(self, func):\n        def de_mutate(current_state, scale):\n            candidates = [current_state]\n            for _ in range(self.dim):\n                candidate = current_state + np.random.uniform(-scale, scale, size=self.dim)\n                candidates.append(np.clip(candidate, -5.0, 5.0))\n            return candidates\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            current_state = np.random.uniform(low=-5.0, high=5.0, size=self.dim)\n            best_state = current_state\n            best_fitness = func(best_state)\n\n            for _ in range(100):\n                dynamic_mutation_scale = self.mutation_scale * np.exp(-self.dynamic_scale_factor)\n                de_candidates = de_mutate(current_state, dynamic_mutation_scale * self.de_scale_factor)\n                for candidate_state in de_candidates:\n                    candidate_fitness = func(candidate_state)\n                    if candidate_fitness < best_fitness:\n                        best_state = candidate_state\n                        best_fitness = candidate_fitness\n                current_state = best_state\n\n            best_solution = best_state\n\n        return best_solution", "name": "Hybrid_SA_DE_Optimizer", "description": "Enhanced convergence speed by incorporating a hybrid optimization approach that combines Simulated Annealing with Differential Evolution for more efficient exploration-exploitation balance.", "configspace": "", "generation": 75, "fitness": 0.07745091507834845, "feedback": "The algorithm Hybrid_SA_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.08.", "error": "", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.19940156532335207, 0.19685657645888466, 0.21455711761777507, 0.08599675881805835, 0.1705633646200858, 0.07871415203611887, 0.1018746113129313, 0.2382522845277314, 0.0812515906960638, 9.999999999998899e-05, 0.02209732519365548, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007950799058617841, 9.999999999998899e-05, 9.999999999998899e-05, 0.002315169391077898, 0.025982384673749803, 0.003606409848410652, 0.003303367764608822, 9.999999999998899e-05, 0.013979897906999939, 0.021388240139249004, 0.003962606954543979, 0.01966846258123367, 0.013642126348399342, 0.0031772032003920536, 9.999999999998899e-05, 9.999999999998899e-05, 0.026681638190264256, 0.0026351484876843134, 0.004106228394299305, 0.04244728966852929, 0.016104735345142562, 0.04461691538112644, 0.03759728196925771, 0.0610877248811077, 0.04104294654821439, 0.04840556783947758, 0.036091234873636635, 0.041037894509586836, 0.04757601727457972, 0.032198773161026706, 0.08215643178249499, 0.02505445137052631, 0.11294716778986891, 0.0881425621203723, 0.05784302941515396, 0.0025491059284274975, 0.02209238868132457, 0.013396089442830439, 0.05207146159438836, 0.032420390398068766, 0.013792464965872164, 9.999999999998899e-05, 9.999999999998899e-05, 0.003908781001953354, 0.03237314719415185, 0.03145857829981702, 9.999999999998899e-05, 0.00413840754457373, 0.023611333278877322, 0.05446030024333759, 0.0020094850695883126, 9.999999999998899e-05, 0.03944794500573845, 9.999999999998899e-05, 0.0008435992969904049, 0.0683206141338496, 9.999999999998899e-05, 0.176948042391735, 0.021425069544108388, 9.999999999998899e-05, 0.1644167309199176, 0.07676143451454098, 9.999999999998899e-05, 0.2214912582827273, 0.06592051727929105, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.057377135575484184, 0.09212992248569352, 0.14479989277645222, 0.0780339939368696, 0.04797002697551511, 0.053337185083739636, 0.13929108827769154, 0.07685717653172419, 0.0740738230429373, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03528684355668099, 0.023685287890755302, 9.999999999998899e-05, 9.999999999998899e-05, 0.0032399509576894747, 0.007631913445461214, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14987394621054084, 0.33610824037307496, 0.18112843653095012, 0.22565694997502628, 0.3158688130749412, 0.15912577286606577, 0.1860696247034882, 0.18972453983160764, 0.15309539405139272, 0.0005857614631479269, 0.004290142990047596, 0.029652458258073833, 0.007291301216104884, 0.011435324108114542, 9.999999999998899e-05, 9.999999999998899e-05, 0.00846678045822169, 9.999999999998899e-05, 0.10681798240198148, 0.10087867134007278, 0.15994788689882955, 0.20906522860240662, 0.08244494296178018, 0.17562762666347376, 0.16788879489885655, 0.09003616355811206, 0.10742913007332733, 0.12069241428109034, 0.1134189841412212, 0.13611761524129085, 0.14626268489534255, 0.1454443461141478, 0.1309474291367746, 0.13876187150437325, 0.11916086104268031, 0.11787626088185443, 0.056925827889815483, 0.0500136377323428, 0.06535697994338274, 0.08199535306785566, 0.06847472890034256, 0.08378588206289628, 0.07034194014819417, 0.061718740219022794, 0.060354662846003326, 0.16875293022847748, 0.09934233786998015, 0.10056271955735097, 0.17384811306911596, 0.10023120102765237, 0.078775822084866, 0.1820932028853286, 0.13000594066685556, 0.1008707574717379, 0.14805769599544982, 0.09568639660985212, 0.018612454541794388, 0.1563658033395774, 0.15099318984078458, 0.16102528062352084, 0.1562555262959766, 0.1495071081821998, 0.13465566496717385, 0.13241595696470354, 0.2867419587883352, 0.1434843548990914, 0.17653931580124227, 0.08907870025993847, 0.3560353544360658, 0.13993727468828132, 0.1586142149132318, 0.13575613182120483, 0.1386098972175378, 0.27108883069096856, 0.23471063662741143, 0.1372235006215251, 0.1903523727580414, 0.11575701158311624, 0.0890879940324727, 0.13623562482117468, 0.1214930174072626, 0.21782480629894663, 0.18834301934611553, 0.2034469637201698, 0.19309360340217474, 0.20088615527179676, 0.18798541146948167, 0.18949802878353716, 0.2054669703775137, 0.21306681828927287, 0.03928687571076972, 0.034163166563834446, 0.03330701762806909, 0.03296423645254165, 0.04452261153083781, 0.015191486090879502, 0.04342694741041231, 0.04852306326824496, 0.0350496091380037]}, "mutation_prompt": null}
{"id": "3048eb39-2e18-4334-a1dc-1736e183d853", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Enhanced convergence speed by dynamically adjusting mutation scale and temperature decay factors with an adaptive mechanism based on historical acceptance probabilities.", "configspace": "", "generation": 52, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.12260295445140168, 0.11947685247797968, 0.1712205642752055, 0.12008761924512712, 0.18199544217734143, 0.1386268714454887, 0.17504467177553362, 0.12714558139702692, 0.20742175956360176, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04835415276942312, 0.022206927706640234, 0.03613709616761285, 0.018858583105297422, 0.02168475029126804, 0.015410207560193845, 0.05286053545021163, 0.03399007068136739, 0.01849310919291891, 0.01246382039880356, 0.0049489030419821445, 0.0006156842861095857, 0.0014424854728846137, 0.0072218570142533745, 0.01397848081933839, 0.0007534951458901817, 0.010698710116858856, 0.0009000424767853232, 0.9621546504895162, 0.9896757919514211, 0.9909559015337105, 0.9992039200685581, 0.9821743252930901, 0.9990337642319617, 0.9907428193537036, 0.9727041376700166, 0.9894891872392355, 0.043845061899681625, 0.08079043765465543, 0.020275817139078223, 0.00515055803683695, 0.05449380861911013, 0.022221385998442034, 0.00043515885738176774, 0.02615612493870545, 0.009231525090477422, 0.06808074746214865, 0.07154023331345993, 0.05355923047622235, 0.07723502547861938, 0.058164962103124385, 0.04918156957825637, 0.04515113942454885, 0.0682503653625689, 0.10535460552058906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.054542055665274036, 0.061066144799690525, 0.025618495427218835, 0.04737920306491794, 9.999999999998899e-05, 0.0003500330713901434, 0.03319877754448275, 0.03828397007689577, 0.024709618817116308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005608166234629675, 0.15437031771245624, 0.14098749370205566, 0.13746611904423767, 0.12565557642278835, 0.19220883654293475, 0.14982800426269938, 0.13937227729915935, 0.14071287288949275, 0.18393561552773052, 0.01913485645967672, 0.0323906851824135, 0.0317375939635447, 0.02906234698697896, 0.0332760377811655, 0.028853181580578924, 0.021030495235029645, 0.038314355212751394, 0.03823455409746834, 0.14471801260110695, 0.16336160564911228, 0.14435396803855072, 0.16123521435224697, 0.16986300977936186, 0.13663292517543035, 0.13410992939214417, 0.17202668963208156, 0.12467683647522321, 0.12773223689868518, 0.15241279711607458, 0.13329841251619434, 0.14104990982507193, 0.1399896969848805, 0.14595032201804647, 0.14684919724094847, 0.1434501524251811, 0.16679839159934695, 0.07412927925901791, 0.06817785650301467, 0.08966959971294308, 0.07807769700873612, 0.08230504418663909, 0.09735147839171732, 0.09055932238645115, 0.0755673690094667, 0.08449720412666162, 0.11646813376341647, 0.1439951795517661, 0.13215472325379163, 0.1306435058207257, 0.16541065603673322, 0.15222302713084368, 0.12609190406798754, 0.10590868147103993, 0.15945396274544887, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 0.001627199979735039, 9.999999999998899e-05, 9.999999999998899e-05, 0.1175556582095294, 0.1536529960543871, 0.11932827186152661, 0.17588017650267251, 0.16045650807769252, 0.17933225313104761, 0.13434904038957662, 0.14762956385481174, 0.13647071101641217, 0.13306146110709016, 0.13090067373980363, 0.13418678751562552, 0.16062228087036579, 0.12385802544278102, 0.15488825278214258, 0.14275401908604668, 0.14678328341790403, 0.1579310142416236, 0.1778596617435494, 0.1755930809686852, 0.1848768936095213, 0.18915721919526463, 0.18433888073864924, 0.18758530785712835, 0.17970616860733335, 0.18020899566339355, 0.18337711261363543, 0.042147645728826455, 0.0415530752211456, 0.03776526912769351, 0.03394360267638019, 0.05249175375060933, 0.042612102269229624, 0.057303757127379895, 0.02927366547243382, 0.047913905901639575]}, "mutation_prompt": null}
{"id": "6987f0ff-3501-4819-b483-8665e8221de9", "solution": "import numpy as np\n\nclass Enhanced_Adaptive_Mutation_PSO_SA_Dynamic_Local_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n        self.temp_decay = temp_decay\n        self.mutation_scale = mutation_scale\n        self.dynamic_scale_factor = dynamic_scale_factor\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Enhanced_Adaptive_Mutation_PSO_SA_Dynamic_Local_Optimizer", "description": "Improve convergence speed by incorporating a dynamic adaptive mutation strategy based on both historical acceptance probabilities and local information to enhance exploration-exploitation trade-off.", "configspace": "", "generation": 77, "fitness": 0.10558296337227657, "feedback": "The algorithm Enhanced_Adaptive_Mutation_PSO_SA_Dynamic_Local_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11 with standard deviation 0.19.", "error": "", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.12260295445140168, 0.11947685247797968, 0.1712205642752055, 0.12008761924512712, 0.18199544217734143, 0.1386268714454887, 0.17504467177553362, 0.12714558139702692, 0.20742175956360176, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04835415276942312, 0.022206927706640234, 0.03613709616761285, 0.018858583105297422, 0.02168475029126804, 0.015410207560193845, 0.05286053545021163, 0.03399007068136739, 0.01849310919291891, 0.01246382039880356, 0.0049489030419821445, 0.0006156842861095857, 0.0014424854728846137, 0.0072218570142533745, 0.01397848081933839, 0.0007534951458901817, 0.010698710116858856, 0.0009000424767853232, 0.9621546504895162, 0.9896757919514211, 0.9909559015337105, 0.9992039200685581, 0.9821743252930901, 0.9990337642319617, 0.9907428193537036, 0.9727041376700166, 0.9894891872392355, 0.043845061899681625, 0.08079043765465543, 0.020275817139078223, 0.00515055803683695, 0.05449380861911013, 0.022221385998442034, 0.00043515885738176774, 0.02615612493870545, 0.009231525090477422, 0.06808074746214865, 0.07154023331345993, 0.05355923047622235, 0.07723502547861938, 0.058164962103124385, 0.04918156957825637, 0.04515113942454885, 0.0682503653625689, 0.10535460552058906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.054542055665274036, 0.061066144799690525, 0.025618495427218835, 0.04737920306491794, 9.999999999998899e-05, 0.0003500330713901434, 0.03319877754448275, 0.03828397007689577, 0.024709618817116308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005608166234629675, 0.15437031771245624, 0.14098749370205566, 0.13746611904423767, 0.12565557642278835, 0.19220883654293475, 0.14982800426269938, 0.13937227729915935, 0.14071287288949275, 0.18393561552773052, 0.01913485645967672, 0.0323906851824135, 0.0317375939635447, 0.02906234698697896, 0.0332760377811655, 0.028853181580578924, 0.021030495235029645, 0.038314355212751394, 0.03823455409746834, 0.14471801260110695, 0.16336160564911228, 0.14435396803855072, 0.16123521435224697, 0.16986300977936186, 0.13663292517543035, 0.13410992939214417, 0.17202668963208156, 0.12467683647522321, 0.12773223689868518, 0.15241279711607458, 0.13329841251619434, 0.14104990982507193, 0.1399896969848805, 0.14595032201804647, 0.14684919724094847, 0.1434501524251811, 0.16679839159934695, 0.07412927925901791, 0.06817785650301467, 0.08966959971294308, 0.07807769700873612, 0.08230504418663909, 0.09735147839171732, 0.09055932238645115, 0.0755673690094667, 0.08449720412666162, 0.11646813376341647, 0.1439951795517661, 0.13215472325379163, 0.1306435058207257, 0.16541065603673322, 0.15222302713084368, 0.12609190406798754, 0.10590868147103993, 0.15945396274544887, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 0.001627199979735039, 9.999999999998899e-05, 9.999999999998899e-05, 0.1175556582095294, 0.1536529960543871, 0.11932827186152661, 0.17588017650267251, 0.16045650807769252, 0.17933225313104761, 0.13434904038957662, 0.14762956385481174, 0.13647071101641217, 0.13306146110709016, 0.13090067373980363, 0.13418678751562552, 0.16062228087036579, 0.12385802544278102, 0.15488825278214258, 0.14275401908604668, 0.14678328341790403, 0.1579310142416236, 0.1778596617435494, 0.1755930809686852, 0.1848768936095213, 0.18915721919526463, 0.18433888073864924, 0.18758530785712835, 0.17970616860733335, 0.18020899566339355, 0.18337711261363543, 0.042147645728826455, 0.0415530752211456, 0.03776526912769351, 0.03394360267638019, 0.05249175375060933, 0.042612102269229624, 0.057303757127379895, 0.02927366547243382, 0.047913905901639575]}, "mutation_prompt": null}
{"id": "cf0c3f33-704d-4f1d-b07e-0ed911aee62d", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1, mutation_scale_decay=0.95):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n        self.mutation_scale_decay = mutation_scale_decay\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n                mutation_scale *= self.mutation_scale_decay  # Adapt mutation scale based on acceptance probability and fitness landscape gradient\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Improved convergence speed by adapting the mutation scale dynamically based on the acceptance probability and fitness landscape gradient.", "configspace": "", "generation": 78, "fitness": 0.10302171326787692, "feedback": "The algorithm Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.19.", "error": "", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.11116539607329701, 0.10441102074437236, 0.1015194713170744, 0.15167896952530968, 0.22332211963091975, 0.1293537183106097, 0.11308344485391697, 0.1169344451603469, 0.2056198800779312, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03777362769964365, 0.026261272509437772, 0.009147727167527986, 0.018300465350108097, 0.014588341958965079, 0.0315607986988653, 0.052563814590422586, 0.024251131923304303, 0.007413153170246156, 0.01234147287395404, 0.004866900316666034, 0.001141344758120999, 0.0017659514227158501, 0.007928152863662219, 0.013276130260799768, 0.0010390490299981847, 0.010698859144926076, 0.0010062255516751772, 0.9531400895249492, 0.9895769393453889, 0.9733853213058398, 0.9992038764246176, 0.9825673455218732, 0.9990337652588874, 0.9907428392758667, 0.9653780142964831, 0.981615844739046, 0.048611194505807864, 0.04750768926849491, 0.016171241141964443, 0.00515055803683695, 0.025384052324323836, 0.022221385998442034, 9.999999999998899e-05, 0.030437263037379814, 0.012597982266517649, 0.07757021065097347, 0.07139259396588915, 0.041690936141524415, 0.09333846351422925, 0.05237914445839287, 0.057629724195262355, 0.052076819860318535, 0.05673716803140927, 0.07118294425679172, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0359198936777404, 0.03114490669912462, 0.027966512620381634, 0.0439102647523707, 0.0435294321109031, 0.04532586917340564, 0.02628318776620364, 0.0770509947139324, 0.060418305740628564, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.004417833573690633, 0.16124051987882426, 0.14000811728798312, 0.1294565920321804, 0.15094646198004957, 0.1448135313077673, 0.1924109053513242, 0.14011869549247769, 0.14454822291270597, 0.150901376904525, 0.03708560149675155, 0.04282165109523395, 0.03899934520144144, 0.024333698568303364, 0.03081308799028515, 0.023689572172773454, 0.014956355554368583, 0.014215417358744653, 0.020956790931215052, 0.15713197433953885, 0.12432037320242184, 0.15531928599763156, 0.10781428400061555, 0.16363597728121426, 0.1320738911310525, 0.12312457719110448, 0.12602278046716675, 0.13548262399122646, 0.1395353987066572, 0.13009098316303247, 0.13182960127968202, 0.1455512089002905, 0.13261968710637206, 0.14919678534329361, 0.1420676701630741, 0.14479613042925799, 0.14269254076199978, 0.07671948710164067, 0.07685474436109396, 0.09102067511845013, 0.07842766631166198, 0.08119267946024233, 0.10286644594861172, 0.10723046476438503, 0.10550673801625854, 0.0932792888555336, 0.11798423220835175, 0.12943815690626925, 0.1376250794910544, 0.12062179469182122, 0.1216979723829048, 0.11617604760258204, 0.11700115522884902, 0.15008855944309563, 0.15403708508939185, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11192315340680559, 0.15315492577397805, 0.1442018484621047, 0.13298271363018754, 0.11338378708385444, 0.11558068388562737, 0.1395371715743038, 0.13265600191854532, 0.16458198965707738, 0.1322955068798376, 0.10385857595514825, 0.1051115175067453, 0.10345436132533103, 0.12106119599499421, 0.11073049575835825, 0.12395026290175304, 0.13878074805076734, 0.1336024732221851, 0.1139192135037278, 0.17768898654218268, 0.18238386287648534, 0.18447389321540875, 0.1759617920614206, 0.1799491330693338, 0.1911492234690324, 0.19457118812905294, 0.17454292471840127, 0.18423284529088257, 0.04193501653049514, 0.04184723021156311, 0.03761712880083701, 0.045912403948119795, 0.03533539246373307, 0.0356326000619942, 0.057303757127379895, 0.06446870150627804, 0.04024781380488496]}, "mutation_prompt": null}
{"id": "9c76e002-b7e3-4ba6-9547-b8d7054b144b", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Enhanced convergence speed by dynamically adjusting mutation scale and temperature decay factors with an adaptive mechanism based on historical acceptance probabilities.", "configspace": "", "generation": 52, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.12260295445140168, 0.11947685247797968, 0.1712205642752055, 0.12008761924512712, 0.18199544217734143, 0.1386268714454887, 0.17504467177553362, 0.12714558139702692, 0.20742175956360176, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04835415276942312, 0.022206927706640234, 0.03613709616761285, 0.018858583105297422, 0.02168475029126804, 0.015410207560193845, 0.05286053545021163, 0.03399007068136739, 0.01849310919291891, 0.01246382039880356, 0.0049489030419821445, 0.0006156842861095857, 0.0014424854728846137, 0.0072218570142533745, 0.01397848081933839, 0.0007534951458901817, 0.010698710116858856, 0.0009000424767853232, 0.9621546504895162, 0.9896757919514211, 0.9909559015337105, 0.9992039200685581, 0.9821743252930901, 0.9990337642319617, 0.9907428193537036, 0.9727041376700166, 0.9894891872392355, 0.043845061899681625, 0.08079043765465543, 0.020275817139078223, 0.00515055803683695, 0.05449380861911013, 0.022221385998442034, 0.00043515885738176774, 0.02615612493870545, 0.009231525090477422, 0.06808074746214865, 0.07154023331345993, 0.05355923047622235, 0.07723502547861938, 0.058164962103124385, 0.04918156957825637, 0.04515113942454885, 0.0682503653625689, 0.10535460552058906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.054542055665274036, 0.061066144799690525, 0.025618495427218835, 0.04737920306491794, 9.999999999998899e-05, 0.0003500330713901434, 0.03319877754448275, 0.03828397007689577, 0.024709618817116308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005608166234629675, 0.15437031771245624, 0.14098749370205566, 0.13746611904423767, 0.12565557642278835, 0.19220883654293475, 0.14982800426269938, 0.13937227729915935, 0.14071287288949275, 0.18393561552773052, 0.01913485645967672, 0.0323906851824135, 0.0317375939635447, 0.02906234698697896, 0.0332760377811655, 0.028853181580578924, 0.021030495235029645, 0.038314355212751394, 0.03823455409746834, 0.14471801260110695, 0.16336160564911228, 0.14435396803855072, 0.16123521435224697, 0.16986300977936186, 0.13663292517543035, 0.13410992939214417, 0.17202668963208156, 0.12467683647522321, 0.12773223689868518, 0.15241279711607458, 0.13329841251619434, 0.14104990982507193, 0.1399896969848805, 0.14595032201804647, 0.14684919724094847, 0.1434501524251811, 0.16679839159934695, 0.07412927925901791, 0.06817785650301467, 0.08966959971294308, 0.07807769700873612, 0.08230504418663909, 0.09735147839171732, 0.09055932238645115, 0.0755673690094667, 0.08449720412666162, 0.11646813376341647, 0.1439951795517661, 0.13215472325379163, 0.1306435058207257, 0.16541065603673322, 0.15222302713084368, 0.12609190406798754, 0.10590868147103993, 0.15945396274544887, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 0.001627199979735039, 9.999999999998899e-05, 9.999999999998899e-05, 0.1175556582095294, 0.1536529960543871, 0.11932827186152661, 0.17588017650267251, 0.16045650807769252, 0.17933225313104761, 0.13434904038957662, 0.14762956385481174, 0.13647071101641217, 0.13306146110709016, 0.13090067373980363, 0.13418678751562552, 0.16062228087036579, 0.12385802544278102, 0.15488825278214258, 0.14275401908604668, 0.14678328341790403, 0.1579310142416236, 0.1778596617435494, 0.1755930809686852, 0.1848768936095213, 0.18915721919526463, 0.18433888073864924, 0.18758530785712835, 0.17970616860733335, 0.18020899566339355, 0.18337711261363543, 0.042147645728826455, 0.0415530752211456, 0.03776526912769351, 0.03394360267638019, 0.05249175375060933, 0.042612102269229624, 0.057303757127379895, 0.02927366547243382, 0.047913905901639575]}, "mutation_prompt": null}
{"id": "d9037294-35e6-4580-aa97-d18e431f5c17", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                    mutation_scale *= 1.05  # Adjust mutation scale dynamically based on fitness improvement rate\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Improved convergence speed by incorporating a dynamic mutation update strategy based on the fitness improvement rate of the candidate solutions.", "configspace": "", "generation": 80, "fitness": 0.10541226981429846, "feedback": "The algorithm Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11 with standard deviation 0.19.", "error": "", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.1235725410042845, 0.12786331608304047, 0.17403949430278465, 0.14530845202087062, 0.17231699806939582, 0.15184210604126058, 0.14172572559255858, 0.14361504144234205, 0.2041096869657829, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03677018241555141, 0.0277344778202101, 0.0490994313626989, 0.018177124158917257, 0.01684905710182616, 0.020147554496534714, 0.0529416229851698, 0.033347352672689845, 0.02643644665792455, 0.0125534253302374, 0.004949248606584522, 0.0007320680985459793, 0.0014475224556854682, 0.0072329610520739385, 0.014194590117280304, 0.0006366041369570974, 0.010698740880865643, 0.0008792211966487384, 0.9621543602685961, 0.9896757045870553, 0.998565000528849, 0.9992039200685581, 0.9821009609557637, 0.9990337640029747, 0.9907428193537036, 0.9727041376700166, 0.9894891871033449, 0.03685334907879245, 0.07813698032491068, 0.013141291229285312, 0.00515055803683695, 0.04611032187239239, 0.022221385998442034, 0.0005346289551462213, 0.006989275165972142, 0.009155977157341288, 0.0681717375211911, 0.07529257864461614, 0.05682007581113191, 0.07957111884022883, 0.07481732430508925, 0.04771282439841962, 0.03804050362316702, 0.0743609485859088, 0.10789536103566932, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.059737873110551454, 0.03843157394812102, 0.04692373868089961, 0.03273266169963718, 0.0460384059315726, 0.009539904606949645, 0.022826284327740698, 0.02081754699460092, 0.02780339302059931, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1543195842357551, 0.14098749370205566, 0.14023974116313298, 0.12590370482447466, 0.15892765816496812, 0.1516079889088494, 0.1413603642726612, 0.1504940860536773, 0.15204596703190143, 0.027334012505673466, 0.03261365414332762, 0.023552974742088062, 0.024281874795266445, 0.03194167478347176, 0.02782554341406762, 0.026603598326182865, 0.033008293425305424, 0.03130726120334326, 0.13214423774863115, 0.13243439326825024, 0.11893324254236182, 0.14506350398639445, 0.15050590139723785, 0.14537817615782456, 0.12539290739042463, 0.17100112677562773, 0.1241811345882683, 0.13507013267369783, 0.14042810803823724, 0.13090976662682718, 0.1395385736881941, 0.148556478282854, 0.14661239677402393, 0.13598618157341313, 0.13589726335977026, 0.1558884815163809, 0.07076950769843593, 0.06298133372130177, 0.09426121624988049, 0.08231081627672299, 0.08470196902706573, 0.09743146775196965, 0.09578502046070347, 0.08546936335419997, 0.08337771181371956, 0.12309169120446373, 0.1252664716537567, 0.12080787296762063, 0.12341920158418485, 0.12456695773431525, 0.16180318319217424, 0.12454389971201585, 0.14353214416249116, 0.14556854035760425, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 0.08070797594904566, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11733064774844282, 0.2571972991074706, 0.13151714411392745, 0.16168857273213566, 0.1532249946430091, 0.18589910729431436, 0.1372668607429679, 0.15870308943937528, 0.16082173715300174, 0.1421532663956212, 0.13817326750439063, 0.10957425840977886, 0.15384376082768025, 0.13853900211256698, 0.1069346326031746, 0.1107365832229833, 0.1520586705346446, 0.17799030297533425, 0.17776122609569267, 0.17813019516187656, 0.18210557782987258, 0.17503838015943474, 0.172435685249139, 0.18525547041731638, 0.1849957933438705, 0.1866589144424905, 0.17535785058919406, 0.03471903536063603, 0.044448442087483664, 0.041750120258191914, 0.036631241048542096, 0.04724332620338356, 0.04569571807464401, 0.05731146101268936, 0.03786438876624665, 0.04102589633075315]}, "mutation_prompt": null}
{"id": "0a456373-dd0c-4bda-872d-5dcb7e5026ad", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Enhanced convergence speed by dynamically adjusting mutation scale and temperature decay factors with an adaptive mechanism based on historical acceptance probabilities.", "configspace": "", "generation": 52, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.12260295445140168, 0.11947685247797968, 0.1712205642752055, 0.12008761924512712, 0.18199544217734143, 0.1386268714454887, 0.17504467177553362, 0.12714558139702692, 0.20742175956360176, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04835415276942312, 0.022206927706640234, 0.03613709616761285, 0.018858583105297422, 0.02168475029126804, 0.015410207560193845, 0.05286053545021163, 0.03399007068136739, 0.01849310919291891, 0.01246382039880356, 0.0049489030419821445, 0.0006156842861095857, 0.0014424854728846137, 0.0072218570142533745, 0.01397848081933839, 0.0007534951458901817, 0.010698710116858856, 0.0009000424767853232, 0.9621546504895162, 0.9896757919514211, 0.9909559015337105, 0.9992039200685581, 0.9821743252930901, 0.9990337642319617, 0.9907428193537036, 0.9727041376700166, 0.9894891872392355, 0.043845061899681625, 0.08079043765465543, 0.020275817139078223, 0.00515055803683695, 0.05449380861911013, 0.022221385998442034, 0.00043515885738176774, 0.02615612493870545, 0.009231525090477422, 0.06808074746214865, 0.07154023331345993, 0.05355923047622235, 0.07723502547861938, 0.058164962103124385, 0.04918156957825637, 0.04515113942454885, 0.0682503653625689, 0.10535460552058906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.054542055665274036, 0.061066144799690525, 0.025618495427218835, 0.04737920306491794, 9.999999999998899e-05, 0.0003500330713901434, 0.03319877754448275, 0.03828397007689577, 0.024709618817116308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005608166234629675, 0.15437031771245624, 0.14098749370205566, 0.13746611904423767, 0.12565557642278835, 0.19220883654293475, 0.14982800426269938, 0.13937227729915935, 0.14071287288949275, 0.18393561552773052, 0.01913485645967672, 0.0323906851824135, 0.0317375939635447, 0.02906234698697896, 0.0332760377811655, 0.028853181580578924, 0.021030495235029645, 0.038314355212751394, 0.03823455409746834, 0.14471801260110695, 0.16336160564911228, 0.14435396803855072, 0.16123521435224697, 0.16986300977936186, 0.13663292517543035, 0.13410992939214417, 0.17202668963208156, 0.12467683647522321, 0.12773223689868518, 0.15241279711607458, 0.13329841251619434, 0.14104990982507193, 0.1399896969848805, 0.14595032201804647, 0.14684919724094847, 0.1434501524251811, 0.16679839159934695, 0.07412927925901791, 0.06817785650301467, 0.08966959971294308, 0.07807769700873612, 0.08230504418663909, 0.09735147839171732, 0.09055932238645115, 0.0755673690094667, 0.08449720412666162, 0.11646813376341647, 0.1439951795517661, 0.13215472325379163, 0.1306435058207257, 0.16541065603673322, 0.15222302713084368, 0.12609190406798754, 0.10590868147103993, 0.15945396274544887, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 0.001627199979735039, 9.999999999998899e-05, 9.999999999998899e-05, 0.1175556582095294, 0.1536529960543871, 0.11932827186152661, 0.17588017650267251, 0.16045650807769252, 0.17933225313104761, 0.13434904038957662, 0.14762956385481174, 0.13647071101641217, 0.13306146110709016, 0.13090067373980363, 0.13418678751562552, 0.16062228087036579, 0.12385802544278102, 0.15488825278214258, 0.14275401908604668, 0.14678328341790403, 0.1579310142416236, 0.1778596617435494, 0.1755930809686852, 0.1848768936095213, 0.18915721919526463, 0.18433888073864924, 0.18758530785712835, 0.17970616860733335, 0.18020899566339355, 0.18337711261363543, 0.042147645728826455, 0.0415530752211456, 0.03776526912769351, 0.03394360267638019, 0.05249175375060933, 0.042612102269229624, 0.057303757127379895, 0.02927366547243382, 0.047913905901639575]}, "mutation_prompt": null}
{"id": "654d51a5-c955-4fda-ac41-3e7d3836338a", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-(best_fitness - obj_func(current_state)))\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Improved convergence speed by dynamically adjusting mutation scale based on the difference between candidate and current fitness values to enhance exploration-exploitation balance.", "configspace": "", "generation": 82, "fitness": 0.08867113128255746, "feedback": "The algorithm Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.20.", "error": "", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.09780356416797076, 0.07458596511108295, 0.11249832875705867, 0.11446226886572552, 0.12047572775260706, 0.12260432989994352, 0.0856323710432878, 0.09425668397333542, 0.19193732754678916, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01878687138136137, 0.003075596970499861, 0.02903698693104706, 0.00682546911054871, 9.999999999998899e-05, 0.05166986490928627, 0.013339815576732361, 0.019841790783394986, 0.010197423869056754, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0025731483757849283, 0.008917986834857894, 9.999999999998899e-05, 0.009519385592062446, 0.00039003096561152084, 0.9761537205371917, 0.9794408172753982, 0.9988, 0.998407840137116, 0.9873157548744039, 0.9980436620015062, 0.9975056387074073, 0.9990130878769298, 0.9915617220630858, 0.026160331151817484, 0.07022188602940937, 0.011344431580908143, 9.999999999998899e-05, 9.999999999998899e-05, 0.021769790897930408, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06009263475058091, 0.05170706789791257, 0.040172699278364976, 0.040870007905489336, 0.018086540028356857, 0.036874847683522005, 0.034404466117295085, 0.026615200558030128, 0.06687147231361612, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05071326549327826, 0.006143553357512266, 0.04866008560689461, 0.00058805230198411, 9.999999999998899e-05, 9.999999999998899e-05, 0.05663698373400072, 0.006122622499888486, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11985742536673483, 0.12725928077174153, 0.12484860385154717, 0.08476241159297915, 0.1269902575542965, 0.09175743690340732, 0.1365064206778327, 0.13932249054907786, 0.15557043135148085, 0.019706577661007585, 0.016409876414517188, 0.04506409895645824, 0.023059396340050053, 0.01818704221092171, 0.012904257515365503, 0.006151290516884345, 0.026738394515024466, 0.01865418118214679, 0.13252192716119038, 0.13248076029475142, 0.1329658203337949, 0.09536352237304468, 0.09583741932764311, 0.11727237905756394, 0.10190127501312707, 0.0942344345036974, 0.15961764147221802, 0.11241045458269616, 0.11850556628618181, 0.1192222797147966, 0.12364249272176508, 0.10855343494890946, 0.12682767446568544, 0.11860849298245357, 0.11352693992730911, 0.13015144965440972, 0.04869211965372411, 0.051682334112420514, 0.0487722616577817, 0.06935880101806291, 0.055231821783323753, 0.07940535549351202, 0.058772830135664256, 0.06381425372442351, 0.053369787779826816, 0.10665484607012243, 0.08937896186593353, 0.11200027422681047, 0.11695382273861266, 0.09861010259845537, 0.11118083407615398, 0.11119313740360581, 0.10172317868043323, 0.09847000328821598, 0.12329843157964737, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.010410083999652486, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11804550266380942, 0.11114112469158444, 0.1331732878459959, 0.14780410567437774, 0.1032464922277988, 0.16609410869811947, 0.09761090310623854, 0.09317387895715679, 0.1023561639557038, 0.08672288410470408, 0.0472027121427373, 0.07257755049352821, 0.05872506239532371, 0.040219959614818945, 0.04293106150666137, 0.13605634552313728, 0.06481006793770427, 0.09909198609435155, 0.13069353941400552, 0.1343232743919709, 0.1648134068101168, 0.1531453552083356, 0.15317949633047956, 0.17172016357171072, 0.16079565155987363, 0.1493057330903519, 0.15100451537293558, 0.021774560529568388, 0.009951475290383316, 0.03556241200913168, 0.01720487208970567, 0.01601137709617273, 0.02591043966467388, 0.057303757127379895, 0.0331850919626937, 0.013499836162205847]}, "mutation_prompt": null}
{"id": "17c30cd2-b5c4-47b7-a6df-43d4ebf302ec", "solution": "# import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n                mutation_scale *= np.exp(-np.mean(acceptance_prob_history))  # Adapt mutation scale based on acceptance history for accelerated convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Accelerated convergence by introducing adaptive self-adjustment of mutation scale and temperature decay based on real-time acceptance statistics to dynamically fine-tune the exploration-exploitation balance.", "configspace": "", "generation": 83, "fitness": 0.08779547337329197, "feedback": "The algorithm Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.18.", "error": "", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.10623421029443159, 0.09193457834055496, 0.1277854107458274, 0.11481993010642533, 0.08780075166317325, 0.11844330460319819, 0.09571862003433929, 0.09761584408375734, 0.2041096869657829, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0239906886032919, 0.02357247471536117, 0.008025380318958941, 0.017901867450844433, 0.013331192023448568, 0.008445641979415663, 0.052292806040428186, 0.005934067648467711, 0.004341549595101579, 0.012375387849651087, 0.004942916194285885, 0.0009755544770306823, 0.0005345701972286898, 0.006229716084929393, 0.011909460742759226, 0.0038118391400532303, 0.010698542328982152, 0.000944744135549791, 0.9422894226602369, 0.8937110265533731, 0.9700920095307605, 0.8017344854482334, 0.9226965551196871, 0.7638473409012779, 0.9898016574696955, 0.9239044926893677, 0.8284684966138905, 0.019567535298530836, 0.036351227254495244, 0.0380701718671691, 0.00515055803683695, 0.0033366500635861884, 0.022221385998442034, 9.999999999998899e-05, 0.05236104555750065, 9.999999999998899e-05, 0.06276459234031806, 0.06866358063314415, 0.045496103911650265, 0.07359077068349085, 0.04385091431638777, 0.040657692624667674, 0.05154014420587627, 0.03970574698900797, 0.05089866733571469, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.024353557734630327, 0.03878400161433382, 0.0283864176070574, 0.03273266169963718, 0.003949431622261357, 0.035872419966129554, 0.03478850439169889, 0.019385732038993964, 0.0082640838701169, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12037427153577396, 0.14452624529871883, 0.122109539753119, 0.09826789447374051, 0.13395561682447865, 0.12908445828675252, 0.13858538209695648, 0.13241025192854727, 0.1463217299190066, 0.013207625351366215, 0.022149893366306017, 0.011025959071559788, 0.034773304203435274, 0.018606431514242794, 0.026133109995695514, 0.03429823781786978, 0.011364658328894661, 0.017972770137810068, 0.09398644323382632, 0.10441893521505574, 0.12125295385556634, 0.09365136124245221, 0.13203765304807624, 0.13743426807850578, 0.09607625324484126, 0.10558783481527168, 0.09614657432064089, 0.11669797059055653, 0.11982168142158667, 0.12723051888038794, 0.1333874712841645, 0.12025118149016312, 0.14305770259158979, 0.13057371691628428, 0.11964192970819876, 0.12743766289569636, 0.05325953047394183, 0.06541340644032279, 0.06323263686736968, 0.07639557032670818, 0.07558772483891207, 0.09912534997873534, 0.0686196062928317, 0.09181182133406873, 0.05488833562834439, 0.10570129829480301, 0.10284545707181225, 0.10772005322650224, 0.11695382273861266, 0.11080547644387806, 0.1122623458358778, 0.11731451941080251, 0.1063805568766154, 0.11089792019723432, 0.12418272955839271, 0.05094236326737156, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11456692953967818, 0.08927402217079905, 0.14308925662797933, 0.12575635411433927, 0.08263141672080998, 0.09514812882472412, 0.08939553709173087, 0.10877079535007594, 0.09794990103149648, 0.08759070274219971, 0.10168637366240296, 0.07477114597549495, 0.07838534948511411, 0.09140685386245351, 0.08746056240208522, 0.06256443739341433, 0.08992385196764785, 0.06018591058837952, 0.18908051533736203, 0.16274336437547643, 0.15813152590677604, 0.15763194759189714, 0.1697768612340127, 0.15874801198479616, 0.163211262383975, 0.1674399720920715, 0.16024454320724635, 0.02668141766410248, 0.022342714541385478, 0.03741476858790571, 0.020087826981161738, 0.021910215158467916, 0.029044442052065467, 0.057303757127379895, 0.01875276015715166, 0.022915640976539198]}, "mutation_prompt": null}
{"id": "cecbd8bb-40b4-44fa-bd75-201a10fac7f1", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Enhanced convergence speed by dynamically adjusting mutation scale and temperature decay factors with an adaptive mechanism based on historical acceptance probabilities.", "configspace": "", "generation": 52, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.12260295445140168, 0.11947685247797968, 0.1712205642752055, 0.12008761924512712, 0.18199544217734143, 0.1386268714454887, 0.17504467177553362, 0.12714558139702692, 0.20742175956360176, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04835415276942312, 0.022206927706640234, 0.03613709616761285, 0.018858583105297422, 0.02168475029126804, 0.015410207560193845, 0.05286053545021163, 0.03399007068136739, 0.01849310919291891, 0.01246382039880356, 0.0049489030419821445, 0.0006156842861095857, 0.0014424854728846137, 0.0072218570142533745, 0.01397848081933839, 0.0007534951458901817, 0.010698710116858856, 0.0009000424767853232, 0.9621546504895162, 0.9896757919514211, 0.9909559015337105, 0.9992039200685581, 0.9821743252930901, 0.9990337642319617, 0.9907428193537036, 0.9727041376700166, 0.9894891872392355, 0.043845061899681625, 0.08079043765465543, 0.020275817139078223, 0.00515055803683695, 0.05449380861911013, 0.022221385998442034, 0.00043515885738176774, 0.02615612493870545, 0.009231525090477422, 0.06808074746214865, 0.07154023331345993, 0.05355923047622235, 0.07723502547861938, 0.058164962103124385, 0.04918156957825637, 0.04515113942454885, 0.0682503653625689, 0.10535460552058906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.054542055665274036, 0.061066144799690525, 0.025618495427218835, 0.04737920306491794, 9.999999999998899e-05, 0.0003500330713901434, 0.03319877754448275, 0.03828397007689577, 0.024709618817116308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005608166234629675, 0.15437031771245624, 0.14098749370205566, 0.13746611904423767, 0.12565557642278835, 0.19220883654293475, 0.14982800426269938, 0.13937227729915935, 0.14071287288949275, 0.18393561552773052, 0.01913485645967672, 0.0323906851824135, 0.0317375939635447, 0.02906234698697896, 0.0332760377811655, 0.028853181580578924, 0.021030495235029645, 0.038314355212751394, 0.03823455409746834, 0.14471801260110695, 0.16336160564911228, 0.14435396803855072, 0.16123521435224697, 0.16986300977936186, 0.13663292517543035, 0.13410992939214417, 0.17202668963208156, 0.12467683647522321, 0.12773223689868518, 0.15241279711607458, 0.13329841251619434, 0.14104990982507193, 0.1399896969848805, 0.14595032201804647, 0.14684919724094847, 0.1434501524251811, 0.16679839159934695, 0.07412927925901791, 0.06817785650301467, 0.08966959971294308, 0.07807769700873612, 0.08230504418663909, 0.09735147839171732, 0.09055932238645115, 0.0755673690094667, 0.08449720412666162, 0.11646813376341647, 0.1439951795517661, 0.13215472325379163, 0.1306435058207257, 0.16541065603673322, 0.15222302713084368, 0.12609190406798754, 0.10590868147103993, 0.15945396274544887, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 0.001627199979735039, 9.999999999998899e-05, 9.999999999998899e-05, 0.1175556582095294, 0.1536529960543871, 0.11932827186152661, 0.17588017650267251, 0.16045650807769252, 0.17933225313104761, 0.13434904038957662, 0.14762956385481174, 0.13647071101641217, 0.13306146110709016, 0.13090067373980363, 0.13418678751562552, 0.16062228087036579, 0.12385802544278102, 0.15488825278214258, 0.14275401908604668, 0.14678328341790403, 0.1579310142416236, 0.1778596617435494, 0.1755930809686852, 0.1848768936095213, 0.18915721919526463, 0.18433888073864924, 0.18758530785712835, 0.17970616860733335, 0.18020899566339355, 0.18337711261363543, 0.042147645728826455, 0.0415530752211456, 0.03776526912769351, 0.03394360267638019, 0.05249175375060933, 0.042612102269229624, 0.057303757127379895, 0.02927366547243382, 0.047913905901639575]}, "mutation_prompt": null}
{"id": "5c787b81-e29b-4e53-8fb0-7d95855c8aab", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Enhanced convergence speed by dynamically adjusting mutation scale and temperature decay factors with an adaptive mechanism based on historical acceptance probabilities.", "configspace": "", "generation": 52, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.12260295445140168, 0.11947685247797968, 0.1712205642752055, 0.12008761924512712, 0.18199544217734143, 0.1386268714454887, 0.17504467177553362, 0.12714558139702692, 0.20742175956360176, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04835415276942312, 0.022206927706640234, 0.03613709616761285, 0.018858583105297422, 0.02168475029126804, 0.015410207560193845, 0.05286053545021163, 0.03399007068136739, 0.01849310919291891, 0.01246382039880356, 0.0049489030419821445, 0.0006156842861095857, 0.0014424854728846137, 0.0072218570142533745, 0.01397848081933839, 0.0007534951458901817, 0.010698710116858856, 0.0009000424767853232, 0.9621546504895162, 0.9896757919514211, 0.9909559015337105, 0.9992039200685581, 0.9821743252930901, 0.9990337642319617, 0.9907428193537036, 0.9727041376700166, 0.9894891872392355, 0.043845061899681625, 0.08079043765465543, 0.020275817139078223, 0.00515055803683695, 0.05449380861911013, 0.022221385998442034, 0.00043515885738176774, 0.02615612493870545, 0.009231525090477422, 0.06808074746214865, 0.07154023331345993, 0.05355923047622235, 0.07723502547861938, 0.058164962103124385, 0.04918156957825637, 0.04515113942454885, 0.0682503653625689, 0.10535460552058906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.054542055665274036, 0.061066144799690525, 0.025618495427218835, 0.04737920306491794, 9.999999999998899e-05, 0.0003500330713901434, 0.03319877754448275, 0.03828397007689577, 0.024709618817116308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005608166234629675, 0.15437031771245624, 0.14098749370205566, 0.13746611904423767, 0.12565557642278835, 0.19220883654293475, 0.14982800426269938, 0.13937227729915935, 0.14071287288949275, 0.18393561552773052, 0.01913485645967672, 0.0323906851824135, 0.0317375939635447, 0.02906234698697896, 0.0332760377811655, 0.028853181580578924, 0.021030495235029645, 0.038314355212751394, 0.03823455409746834, 0.14471801260110695, 0.16336160564911228, 0.14435396803855072, 0.16123521435224697, 0.16986300977936186, 0.13663292517543035, 0.13410992939214417, 0.17202668963208156, 0.12467683647522321, 0.12773223689868518, 0.15241279711607458, 0.13329841251619434, 0.14104990982507193, 0.1399896969848805, 0.14595032201804647, 0.14684919724094847, 0.1434501524251811, 0.16679839159934695, 0.07412927925901791, 0.06817785650301467, 0.08966959971294308, 0.07807769700873612, 0.08230504418663909, 0.09735147839171732, 0.09055932238645115, 0.0755673690094667, 0.08449720412666162, 0.11646813376341647, 0.1439951795517661, 0.13215472325379163, 0.1306435058207257, 0.16541065603673322, 0.15222302713084368, 0.12609190406798754, 0.10590868147103993, 0.15945396274544887, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 0.001627199979735039, 9.999999999998899e-05, 9.999999999998899e-05, 0.1175556582095294, 0.1536529960543871, 0.11932827186152661, 0.17588017650267251, 0.16045650807769252, 0.17933225313104761, 0.13434904038957662, 0.14762956385481174, 0.13647071101641217, 0.13306146110709016, 0.13090067373980363, 0.13418678751562552, 0.16062228087036579, 0.12385802544278102, 0.15488825278214258, 0.14275401908604668, 0.14678328341790403, 0.1579310142416236, 0.1778596617435494, 0.1755930809686852, 0.1848768936095213, 0.18915721919526463, 0.18433888073864924, 0.18758530785712835, 0.17970616860733335, 0.18020899566339355, 0.18337711261363543, 0.042147645728826455, 0.0415530752211456, 0.03776526912769351, 0.03394360267638019, 0.05249175375060933, 0.042612102269229624, 0.057303757127379895, 0.02927366547243382, 0.047913905901639575]}, "mutation_prompt": null}
{"id": "83a3f12a-f1db-48c0-8af8-3c609eee785f", "solution": "import numpy as np\n\nclass Enhanced_Faster_Adaptive_Mutation_PSO_SA_Optimizer(Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __call__(self, func):\n        def sa_optimize_adaptive_mut(obj_func, lower_bound, upper_bound, temp, max_iter, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                mutation_scale = np.clip(np.abs(np.random.normal(0, 1, size=self.dim)) * self.mutation_scale, 0.01, 0.5)\n                candidate_state = current_state + np.random.normal(0, temp * mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize_adaptive_mut(func, -5.0, 5.0, self.initial_temp, 100, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize_adaptive_mut(func, -5.0, 5.0, self.initial_temp, 100, acceptance_prob_history)\n\n        return best_solution", "name": "Enhanced_Faster_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Improved convergence speed by incorporating a novel adaptive mutation strategy that dynamically adjusts the mutation scale and temperature based on the fitness landscape to enhance exploration and exploitation capabilities.", "configspace": "", "generation": 86, "fitness": 0.10385363432394724, "feedback": "The algorithm Enhanced_Faster_Adaptive_Mutation_PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.19.", "error": "", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.14894940335004614, 0.1287660761826921, 0.133871218190304, 0.16301328876392585, 0.15828551721226902, 0.12034279667911219, 0.1479289460687987, 0.13807633195302493, 0.1522543706644336, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01318190240493311, 0.01569705467457372, 0.036118080547576925, 0.019173616459137177, 0.028302816483859128, 0.01851363289184793, 0.02544781909197469, 0.015615054917706539, 0.03344562129768436, 0.01799800063843182, 0.0038413562975052606, 0.010927566669024946, 0.00010346189919641091, 9.999999999998899e-05, 0.011883783390828628, 0.008988996000923732, 0.005577240736798883, 0.0050449505198877365, 0.8798964429320766, 0.9450128417103154, 0.9989968759933385, 0.9911138348085019, 0.936257202661305, 0.9809070053321223, 0.9626532582479136, 0.9185646050512564, 0.9351589671546818, 0.0066238740723778555, 0.02202979243976455, 0.0375787111985868, 0.007693266276955324, 0.020061778585496404, 0.026320016017309378, 9.999999999998899e-05, 0.008087636722237224, 0.06258304519759372, 0.08980647045854273, 0.07173931921507082, 0.09413740717023988, 0.0816568461769488, 0.06062321636938772, 0.0885022385191987, 0.07612180835624127, 0.07471753684691229, 0.07811775246462715, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0034914996714739965, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06007993756007313, 0.03536100019255117, 0.022612996108163697, 0.04216662835416196, 0.05693983711917805, 0.05411841545410501, 0.01986750847552743, 0.02105263728852047, 0.019693112347227593, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14102972753312792, 0.1295887888823618, 0.1469221541207829, 0.157508967379539, 0.13455705001339102, 0.1880493807717336, 0.1385659634408577, 0.13780831762986623, 0.17434248924609164, 0.032284679744051914, 0.03899569433298422, 0.03934210764172841, 0.021757466012949922, 0.018830013099099596, 0.033828707503652966, 0.014093941748043126, 0.01820873026543901, 0.009999568233393763, 0.14245001434361915, 0.12456299313979124, 0.16323099589304912, 0.13098418973620263, 0.17308854624978887, 0.13403931339135655, 0.1387388750127977, 0.15881817045166624, 0.1239982433330662, 0.14793636545330136, 0.16487750262866152, 0.13692980049471337, 0.1505729146794056, 0.1463126257635753, 0.1348581076609413, 0.16044494385244867, 0.14034476943228802, 0.12890841938327702, 0.07602299496799514, 0.07447696059872921, 0.09511531153287811, 0.0772088233874978, 0.09212641561418111, 0.08037719669308896, 0.08798612125273264, 0.07532070955586345, 0.08991639274895935, 0.1221309587534184, 0.12343405022793374, 0.1522170130816568, 0.1530269269824881, 0.13784328007506097, 0.11656856020269057, 0.12877070464110552, 0.11456687067103433, 0.11725187099541579, 0.12329843157964737, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10517176879389445, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11394015873165608, 0.14855947829309357, 0.13721270264692498, 0.1395169950230989, 0.16574510122973374, 0.16289516491553968, 0.12398700124343176, 0.13994264367572118, 0.13947675913425195, 0.1307111451659786, 0.1398296722170882, 0.14350067834045144, 0.19373376337637893, 0.08190408954895156, 0.1069597357837394, 0.15502787035593102, 0.16480247855457364, 0.13467182161394775, 0.14930333768625115, 0.21988382758310798, 0.1974911374561782, 0.18083347086521817, 0.18357582516067528, 0.20399365231276156, 0.20327782077229073, 0.1739279287349047, 0.18471462866817234, 0.18135718968342018, 0.029487813231846682, 0.03399324114468549, 0.035566169562507244, 0.033516094469503654, 0.031436708280856096, 0.035117791895291295, 0.057303757127379895, 0.06252251076038884, 0.03522872133487731]}, "mutation_prompt": null}
{"id": "06ab076c-02ed-4ffb-9147-4c58408b586c", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Enhanced convergence speed by dynamically adjusting mutation scale and temperature decay factors with an adaptive mechanism based on historical acceptance probabilities.", "configspace": "", "generation": 52, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.12260295445140168, 0.11947685247797968, 0.1712205642752055, 0.12008761924512712, 0.18199544217734143, 0.1386268714454887, 0.17504467177553362, 0.12714558139702692, 0.20742175956360176, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04835415276942312, 0.022206927706640234, 0.03613709616761285, 0.018858583105297422, 0.02168475029126804, 0.015410207560193845, 0.05286053545021163, 0.03399007068136739, 0.01849310919291891, 0.01246382039880356, 0.0049489030419821445, 0.0006156842861095857, 0.0014424854728846137, 0.0072218570142533745, 0.01397848081933839, 0.0007534951458901817, 0.010698710116858856, 0.0009000424767853232, 0.9621546504895162, 0.9896757919514211, 0.9909559015337105, 0.9992039200685581, 0.9821743252930901, 0.9990337642319617, 0.9907428193537036, 0.9727041376700166, 0.9894891872392355, 0.043845061899681625, 0.08079043765465543, 0.020275817139078223, 0.00515055803683695, 0.05449380861911013, 0.022221385998442034, 0.00043515885738176774, 0.02615612493870545, 0.009231525090477422, 0.06808074746214865, 0.07154023331345993, 0.05355923047622235, 0.07723502547861938, 0.058164962103124385, 0.04918156957825637, 0.04515113942454885, 0.0682503653625689, 0.10535460552058906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.054542055665274036, 0.061066144799690525, 0.025618495427218835, 0.04737920306491794, 9.999999999998899e-05, 0.0003500330713901434, 0.03319877754448275, 0.03828397007689577, 0.024709618817116308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005608166234629675, 0.15437031771245624, 0.14098749370205566, 0.13746611904423767, 0.12565557642278835, 0.19220883654293475, 0.14982800426269938, 0.13937227729915935, 0.14071287288949275, 0.18393561552773052, 0.01913485645967672, 0.0323906851824135, 0.0317375939635447, 0.02906234698697896, 0.0332760377811655, 0.028853181580578924, 0.021030495235029645, 0.038314355212751394, 0.03823455409746834, 0.14471801260110695, 0.16336160564911228, 0.14435396803855072, 0.16123521435224697, 0.16986300977936186, 0.13663292517543035, 0.13410992939214417, 0.17202668963208156, 0.12467683647522321, 0.12773223689868518, 0.15241279711607458, 0.13329841251619434, 0.14104990982507193, 0.1399896969848805, 0.14595032201804647, 0.14684919724094847, 0.1434501524251811, 0.16679839159934695, 0.07412927925901791, 0.06817785650301467, 0.08966959971294308, 0.07807769700873612, 0.08230504418663909, 0.09735147839171732, 0.09055932238645115, 0.0755673690094667, 0.08449720412666162, 0.11646813376341647, 0.1439951795517661, 0.13215472325379163, 0.1306435058207257, 0.16541065603673322, 0.15222302713084368, 0.12609190406798754, 0.10590868147103993, 0.15945396274544887, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 0.001627199979735039, 9.999999999998899e-05, 9.999999999998899e-05, 0.1175556582095294, 0.1536529960543871, 0.11932827186152661, 0.17588017650267251, 0.16045650807769252, 0.17933225313104761, 0.13434904038957662, 0.14762956385481174, 0.13647071101641217, 0.13306146110709016, 0.13090067373980363, 0.13418678751562552, 0.16062228087036579, 0.12385802544278102, 0.15488825278214258, 0.14275401908604668, 0.14678328341790403, 0.1579310142416236, 0.1778596617435494, 0.1755930809686852, 0.1848768936095213, 0.18915721919526463, 0.18433888073864924, 0.18758530785712835, 0.17970616860733335, 0.18020899566339355, 0.18337711261363543, 0.042147645728826455, 0.0415530752211456, 0.03776526912769351, 0.03394360267638019, 0.05249175375060933, 0.042612102269229624, 0.057303757127379895, 0.02927366547243382, 0.047913905901639575]}, "mutation_prompt": null}
{"id": "d3f52539-9bfd-486c-a486-6944be3e90d3", "solution": "import numpy as np\n\nclass Fast_Adaptive_Mutation_SA_Optimizer:\n    def __init__(self, budget, dim, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n        self.temp_decay = temp_decay\n        self.mutation_scale = mutation_scale\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-np.mean(np.abs(best_state - current_state)))\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale)\n\n        return best_solution", "name": "Fast_Adaptive_Mutation_SA_Optimizer", "description": "Improved convergence speed by introducing a novel adaptive mutation strategy that adjusts the mutation scale dynamically based on the fitness landscape.", "configspace": "", "generation": 88, "fitness": 0.09035137246536179, "feedback": "The algorithm Fast_Adaptive_Mutation_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.18.", "error": "", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.11583037588579681, 0.10016170193568019, 0.09915630113276952, 0.15335655622024935, 0.11388503536416206, 0.0960192787109494, 0.10627183513941596, 0.08675877777728835, 0.09569521078071208, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.049772850049056405, 0.013273578389888074, 0.01868483349189831, 0.01772309688705942, 0.016620819461402814, 0.037851284812672414, 0.01472088867027288, 0.014241524735590816, 0.01787108905659318, 0.006094611306748821, 0.008839511898586006, 0.0002753541873972143, 0.0016988899808558777, 0.0017345131564756588, 0.0073762231828428115, 9.999999999998899e-05, 0.004571014905658033, 0.025221403202202564, 0.8418918059323788, 0.7168009177141741, 0.9070986942154097, 0.9613967863204399, 0.9725413935605478, 0.9601422334068619, 0.7740483496643696, 0.9999014940564622, 0.9425152527003232, 0.012614475312524909, 0.025654032937711402, 0.012944140971699936, 0.015930719122534742, 0.021091956885490593, 0.03176950156881542, 0.00012505185169597866, 0.03317818532920214, 0.0019677391136611044, 0.08510533117216068, 0.05194464254139075, 0.06102544711518987, 0.07138074234812453, 0.06542080587812216, 0.051260708540789124, 0.06390963203627176, 0.07353220798964644, 0.09163935592987893, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006958935887133366, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02453306140333711, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03994042625191574, 0.021940030588375348, 0.009226783219067891, 0.0009890570861486037, 0.008682319322968923, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13242461055827648, 0.12443339173958556, 0.1358326592323359, 0.12697952252262634, 0.12192264140674869, 0.1506723578212461, 0.1304525877767968, 0.12432516921637726, 0.1553011967313489, 0.01506913880003835, 0.025022216843505363, 0.02987755511047796, 0.01752842532244958, 0.010009110027434542, 0.0137929314552232, 0.009395917073589, 0.016118420084086926, 0.02182919898510971, 0.12538949738154404, 0.1239472367739769, 0.12172988043108157, 0.1145368792841065, 0.12716823266097577, 0.13424530392821832, 0.1235198238414319, 0.128034944394688, 0.11351872905747518, 0.13466879578513324, 0.12582581272233306, 0.12549714149142177, 0.12106126411380469, 0.13707776561183782, 0.1280984312117578, 0.12895840121997648, 0.12081555790010612, 0.11807961562036184, 0.06137422576449503, 0.07817413144916951, 0.06544526105075676, 0.061459236978064324, 0.08182082020399051, 0.0594374092790102, 0.08207182306816152, 0.09503856507856723, 0.10408480417423849, 0.14163643324454855, 0.1099650745163312, 0.13281806226034698, 0.12890515765333854, 0.12011096373090135, 0.11138260662032884, 0.1235688434351081, 0.11094584766505466, 0.12380227184053505, 0.027608170710600954, 9.999999999998899e-05, 9.999999999998899e-05, 0.0465786370003749, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04585205065232534, 0.13228971991129035, 0.11362540546534261, 0.13086908139947395, 0.10594606135184736, 0.12670578261889764, 0.10364506397618956, 0.15202981313479635, 0.11261558792154114, 0.12107391022250524, 0.06858519515632322, 0.09012568088186834, 0.09576212124494288, 0.08761247233386471, 0.0730959198413107, 0.09490666564646455, 0.11362541609930399, 0.08540601064614983, 0.0728351543743605, 0.17821320112454397, 0.18853526189654535, 0.18355388898104363, 0.17815188028456375, 0.18390481066213094, 0.175495961185006, 0.19354443555074696, 0.1845116535097291, 0.19269855587613838, 0.028867045512703582, 0.022450317503345474, 0.030446208649139717, 0.02689133204850691, 0.028717591523092056, 0.02562803803013447, 0.034080369097591934, 0.0427360735909007, 0.022365226455025145]}, "mutation_prompt": null}
{"id": "b4d0dd0f-5db9-4a6d-9002-f0cf74ec2d0e", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Enhanced convergence speed by dynamically adjusting mutation scale and temperature decay factors with an adaptive mechanism based on historical acceptance probabilities.", "configspace": "", "generation": 52, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.12260295445140168, 0.11947685247797968, 0.1712205642752055, 0.12008761924512712, 0.18199544217734143, 0.1386268714454887, 0.17504467177553362, 0.12714558139702692, 0.20742175956360176, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04835415276942312, 0.022206927706640234, 0.03613709616761285, 0.018858583105297422, 0.02168475029126804, 0.015410207560193845, 0.05286053545021163, 0.03399007068136739, 0.01849310919291891, 0.01246382039880356, 0.0049489030419821445, 0.0006156842861095857, 0.0014424854728846137, 0.0072218570142533745, 0.01397848081933839, 0.0007534951458901817, 0.010698710116858856, 0.0009000424767853232, 0.9621546504895162, 0.9896757919514211, 0.9909559015337105, 0.9992039200685581, 0.9821743252930901, 0.9990337642319617, 0.9907428193537036, 0.9727041376700166, 0.9894891872392355, 0.043845061899681625, 0.08079043765465543, 0.020275817139078223, 0.00515055803683695, 0.05449380861911013, 0.022221385998442034, 0.00043515885738176774, 0.02615612493870545, 0.009231525090477422, 0.06808074746214865, 0.07154023331345993, 0.05355923047622235, 0.07723502547861938, 0.058164962103124385, 0.04918156957825637, 0.04515113942454885, 0.0682503653625689, 0.10535460552058906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.054542055665274036, 0.061066144799690525, 0.025618495427218835, 0.04737920306491794, 9.999999999998899e-05, 0.0003500330713901434, 0.03319877754448275, 0.03828397007689577, 0.024709618817116308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005608166234629675, 0.15437031771245624, 0.14098749370205566, 0.13746611904423767, 0.12565557642278835, 0.19220883654293475, 0.14982800426269938, 0.13937227729915935, 0.14071287288949275, 0.18393561552773052, 0.01913485645967672, 0.0323906851824135, 0.0317375939635447, 0.02906234698697896, 0.0332760377811655, 0.028853181580578924, 0.021030495235029645, 0.038314355212751394, 0.03823455409746834, 0.14471801260110695, 0.16336160564911228, 0.14435396803855072, 0.16123521435224697, 0.16986300977936186, 0.13663292517543035, 0.13410992939214417, 0.17202668963208156, 0.12467683647522321, 0.12773223689868518, 0.15241279711607458, 0.13329841251619434, 0.14104990982507193, 0.1399896969848805, 0.14595032201804647, 0.14684919724094847, 0.1434501524251811, 0.16679839159934695, 0.07412927925901791, 0.06817785650301467, 0.08966959971294308, 0.07807769700873612, 0.08230504418663909, 0.09735147839171732, 0.09055932238645115, 0.0755673690094667, 0.08449720412666162, 0.11646813376341647, 0.1439951795517661, 0.13215472325379163, 0.1306435058207257, 0.16541065603673322, 0.15222302713084368, 0.12609190406798754, 0.10590868147103993, 0.15945396274544887, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 0.001627199979735039, 9.999999999998899e-05, 9.999999999998899e-05, 0.1175556582095294, 0.1536529960543871, 0.11932827186152661, 0.17588017650267251, 0.16045650807769252, 0.17933225313104761, 0.13434904038957662, 0.14762956385481174, 0.13647071101641217, 0.13306146110709016, 0.13090067373980363, 0.13418678751562552, 0.16062228087036579, 0.12385802544278102, 0.15488825278214258, 0.14275401908604668, 0.14678328341790403, 0.1579310142416236, 0.1778596617435494, 0.1755930809686852, 0.1848768936095213, 0.18915721919526463, 0.18433888073864924, 0.18758530785712835, 0.17970616860733335, 0.18020899566339355, 0.18337711261363543, 0.042147645728826455, 0.0415530752211456, 0.03776526912769351, 0.03394360267638019, 0.05249175375060933, 0.042612102269229624, 0.057303757127379895, 0.02927366547243382, 0.047913905901639575]}, "mutation_prompt": null}
{"id": "71ad408c-8bd6-427e-b71b-30f69d9a9f0d", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                    mutation_scale *= 0.95  # Adjust mutation scale dynamically based on current fitness improvements\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Improved convergence speed by dynamically adjusting mutation scale and temperature decay factors with an adaptive mechanism based on both historical acceptance probabilities and current fitness improvements.", "configspace": "", "generation": 90, "fitness": 0.10458595781005547, "feedback": "The algorithm Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.19.", "error": "", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.13779133699341906, 0.12183898804692295, 0.14324330023671483, 0.13083378289784664, 0.1559974552491642, 0.14477040918997952, 0.15307411819052197, 0.12504963495785126, 0.2041096869657829, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.058753533106460254, 0.025515916921300952, 0.02240281506897468, 0.02014950787299863, 0.025046652572266792, 0.01962402727232615, 0.05278246729249836, 0.029860464916916518, 0.026593054358475587, 0.012453257892611092, 0.0049485669812660005, 0.0006221355457149969, 0.0018050533659236256, 0.007210865529230559, 0.013669524213755335, 0.0006365967887853596, 0.010698680311583497, 0.0009113459909630972, 0.9537193381840723, 0.9896758811093848, 0.9756880801109866, 0.9992039200685581, 0.9822517371848999, 0.9990337644606955, 0.9907428193537036, 0.9727041376700166, 0.989489187374975, 0.045265144235256405, 0.036351227254495244, 0.015181504073751073, 0.00515055803683695, 0.0064659894533423135, 0.022221385998442034, 0.00030161311388565704, 0.02749400983103789, 0.013226032586835412, 0.07320799908220521, 0.07054685337836109, 0.05334740088282963, 0.07714970058899595, 0.08206939736481034, 0.05474828029269807, 0.03717569820052935, 0.0431282524296841, 0.10260853545241388, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.049887800355170486, 0.08534681015846912, 0.02390164669629702, 0.03273266169963718, 0.006683534281238246, 0.03202180972108781, 0.031825244684909326, 0.05984153432021344, 0.02615414050327869, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.21308522198506463, 0.14098749370205566, 0.12603150957021958, 0.14283428775287776, 0.16409460760236994, 0.14540442780996565, 0.13858538209695648, 0.14891166050811921, 0.1642638835162772, 0.023419292844583994, 0.025447187926951664, 0.04718882431272142, 0.027243602651775056, 0.02862228627413843, 0.023098107399327272, 0.021736732453829788, 0.030091664582676425, 0.022264679600664916, 0.12274891709974833, 0.13593136413486662, 0.17449212126716973, 0.15230661022571512, 0.15294627996203347, 0.13881241417034362, 0.13424373266909095, 0.14416828445294327, 0.13759129628307676, 0.13477163640217316, 0.14366445480843792, 0.13738465314494785, 0.14281049891957287, 0.15825773978416857, 0.1483329735499327, 0.1384739777785451, 0.12968154801962195, 0.15986241816357816, 0.08298621373488235, 0.07422014841035107, 0.08309345559869397, 0.08141879489251513, 0.0811419070403484, 0.09693296486361691, 0.07378900955480527, 0.07398337293472323, 0.08455588234783351, 0.13267674400726537, 0.13812198683649912, 0.13931066360621502, 0.12935967395144476, 0.1334101815366987, 0.1328991906089193, 0.1173279911973546, 0.10746122119289281, 0.1606572390136275, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12549511674322655, 0.144740964440785, 0.12099668442428135, 0.12342972425031296, 0.15678863878759786, 0.1578759939256219, 0.12034441803926899, 0.151585483613911, 0.1295249984435417, 0.14760885802555002, 0.1393074679938443, 0.2024109843534706, 0.13126593483402138, 0.15107036151188347, 0.12638525708808024, 0.12041707721906203, 0.16828495915571617, 0.16753260287897842, 0.18844851200067003, 0.1876929477354925, 0.17922057641133216, 0.17775971033513582, 0.1802723067958938, 0.18126374431693004, 0.18472551411286253, 0.20167692878895216, 0.18948892470577516, 0.037251032258070915, 0.05118047540076076, 0.04962822413659873, 0.0291487532127096, 0.02783510854492599, 0.037874785646576536, 0.057303757127379895, 0.03493572074196816, 0.04604305286420207]}, "mutation_prompt": null}
{"id": "b1c73f60-7e5a-4644-b17c-15cd2ed0942c", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Enhanced convergence speed by dynamically adjusting mutation scale and temperature decay factors with an adaptive mechanism based on historical acceptance probabilities.", "configspace": "", "generation": 52, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.12260295445140168, 0.11947685247797968, 0.1712205642752055, 0.12008761924512712, 0.18199544217734143, 0.1386268714454887, 0.17504467177553362, 0.12714558139702692, 0.20742175956360176, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04835415276942312, 0.022206927706640234, 0.03613709616761285, 0.018858583105297422, 0.02168475029126804, 0.015410207560193845, 0.05286053545021163, 0.03399007068136739, 0.01849310919291891, 0.01246382039880356, 0.0049489030419821445, 0.0006156842861095857, 0.0014424854728846137, 0.0072218570142533745, 0.01397848081933839, 0.0007534951458901817, 0.010698710116858856, 0.0009000424767853232, 0.9621546504895162, 0.9896757919514211, 0.9909559015337105, 0.9992039200685581, 0.9821743252930901, 0.9990337642319617, 0.9907428193537036, 0.9727041376700166, 0.9894891872392355, 0.043845061899681625, 0.08079043765465543, 0.020275817139078223, 0.00515055803683695, 0.05449380861911013, 0.022221385998442034, 0.00043515885738176774, 0.02615612493870545, 0.009231525090477422, 0.06808074746214865, 0.07154023331345993, 0.05355923047622235, 0.07723502547861938, 0.058164962103124385, 0.04918156957825637, 0.04515113942454885, 0.0682503653625689, 0.10535460552058906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.054542055665274036, 0.061066144799690525, 0.025618495427218835, 0.04737920306491794, 9.999999999998899e-05, 0.0003500330713901434, 0.03319877754448275, 0.03828397007689577, 0.024709618817116308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005608166234629675, 0.15437031771245624, 0.14098749370205566, 0.13746611904423767, 0.12565557642278835, 0.19220883654293475, 0.14982800426269938, 0.13937227729915935, 0.14071287288949275, 0.18393561552773052, 0.01913485645967672, 0.0323906851824135, 0.0317375939635447, 0.02906234698697896, 0.0332760377811655, 0.028853181580578924, 0.021030495235029645, 0.038314355212751394, 0.03823455409746834, 0.14471801260110695, 0.16336160564911228, 0.14435396803855072, 0.16123521435224697, 0.16986300977936186, 0.13663292517543035, 0.13410992939214417, 0.17202668963208156, 0.12467683647522321, 0.12773223689868518, 0.15241279711607458, 0.13329841251619434, 0.14104990982507193, 0.1399896969848805, 0.14595032201804647, 0.14684919724094847, 0.1434501524251811, 0.16679839159934695, 0.07412927925901791, 0.06817785650301467, 0.08966959971294308, 0.07807769700873612, 0.08230504418663909, 0.09735147839171732, 0.09055932238645115, 0.0755673690094667, 0.08449720412666162, 0.11646813376341647, 0.1439951795517661, 0.13215472325379163, 0.1306435058207257, 0.16541065603673322, 0.15222302713084368, 0.12609190406798754, 0.10590868147103993, 0.15945396274544887, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 0.001627199979735039, 9.999999999998899e-05, 9.999999999998899e-05, 0.1175556582095294, 0.1536529960543871, 0.11932827186152661, 0.17588017650267251, 0.16045650807769252, 0.17933225313104761, 0.13434904038957662, 0.14762956385481174, 0.13647071101641217, 0.13306146110709016, 0.13090067373980363, 0.13418678751562552, 0.16062228087036579, 0.12385802544278102, 0.15488825278214258, 0.14275401908604668, 0.14678328341790403, 0.1579310142416236, 0.1778596617435494, 0.1755930809686852, 0.1848768936095213, 0.18915721919526463, 0.18433888073864924, 0.18758530785712835, 0.17970616860733335, 0.18020899566339355, 0.18337711261363543, 0.042147645728826455, 0.0415530752211456, 0.03776526912769351, 0.03394360267638019, 0.05249175375060933, 0.042612102269229624, 0.057303757127379895, 0.02927366547243382, 0.047913905901639575]}, "mutation_prompt": null}
{"id": "aff1e351-d362-4db0-8af2-370c682a4b97", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Enhanced convergence speed by dynamically adjusting mutation scale and temperature decay factors with an adaptive mechanism based on historical acceptance probabilities.", "configspace": "", "generation": 52, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.12260295445140168, 0.11947685247797968, 0.1712205642752055, 0.12008761924512712, 0.18199544217734143, 0.1386268714454887, 0.17504467177553362, 0.12714558139702692, 0.20742175956360176, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04835415276942312, 0.022206927706640234, 0.03613709616761285, 0.018858583105297422, 0.02168475029126804, 0.015410207560193845, 0.05286053545021163, 0.03399007068136739, 0.01849310919291891, 0.01246382039880356, 0.0049489030419821445, 0.0006156842861095857, 0.0014424854728846137, 0.0072218570142533745, 0.01397848081933839, 0.0007534951458901817, 0.010698710116858856, 0.0009000424767853232, 0.9621546504895162, 0.9896757919514211, 0.9909559015337105, 0.9992039200685581, 0.9821743252930901, 0.9990337642319617, 0.9907428193537036, 0.9727041376700166, 0.9894891872392355, 0.043845061899681625, 0.08079043765465543, 0.020275817139078223, 0.00515055803683695, 0.05449380861911013, 0.022221385998442034, 0.00043515885738176774, 0.02615612493870545, 0.009231525090477422, 0.06808074746214865, 0.07154023331345993, 0.05355923047622235, 0.07723502547861938, 0.058164962103124385, 0.04918156957825637, 0.04515113942454885, 0.0682503653625689, 0.10535460552058906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.054542055665274036, 0.061066144799690525, 0.025618495427218835, 0.04737920306491794, 9.999999999998899e-05, 0.0003500330713901434, 0.03319877754448275, 0.03828397007689577, 0.024709618817116308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005608166234629675, 0.15437031771245624, 0.14098749370205566, 0.13746611904423767, 0.12565557642278835, 0.19220883654293475, 0.14982800426269938, 0.13937227729915935, 0.14071287288949275, 0.18393561552773052, 0.01913485645967672, 0.0323906851824135, 0.0317375939635447, 0.02906234698697896, 0.0332760377811655, 0.028853181580578924, 0.021030495235029645, 0.038314355212751394, 0.03823455409746834, 0.14471801260110695, 0.16336160564911228, 0.14435396803855072, 0.16123521435224697, 0.16986300977936186, 0.13663292517543035, 0.13410992939214417, 0.17202668963208156, 0.12467683647522321, 0.12773223689868518, 0.15241279711607458, 0.13329841251619434, 0.14104990982507193, 0.1399896969848805, 0.14595032201804647, 0.14684919724094847, 0.1434501524251811, 0.16679839159934695, 0.07412927925901791, 0.06817785650301467, 0.08966959971294308, 0.07807769700873612, 0.08230504418663909, 0.09735147839171732, 0.09055932238645115, 0.0755673690094667, 0.08449720412666162, 0.11646813376341647, 0.1439951795517661, 0.13215472325379163, 0.1306435058207257, 0.16541065603673322, 0.15222302713084368, 0.12609190406798754, 0.10590868147103993, 0.15945396274544887, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 0.001627199979735039, 9.999999999998899e-05, 9.999999999998899e-05, 0.1175556582095294, 0.1536529960543871, 0.11932827186152661, 0.17588017650267251, 0.16045650807769252, 0.17933225313104761, 0.13434904038957662, 0.14762956385481174, 0.13647071101641217, 0.13306146110709016, 0.13090067373980363, 0.13418678751562552, 0.16062228087036579, 0.12385802544278102, 0.15488825278214258, 0.14275401908604668, 0.14678328341790403, 0.1579310142416236, 0.1778596617435494, 0.1755930809686852, 0.1848768936095213, 0.18915721919526463, 0.18433888073864924, 0.18758530785712835, 0.17970616860733335, 0.18020899566339355, 0.18337711261363543, 0.042147645728826455, 0.0415530752211456, 0.03776526912769351, 0.03394360267638019, 0.05249175375060933, 0.042612102269229624, 0.057303757127379895, 0.02927366547243382, 0.047913905901639575]}, "mutation_prompt": null}
{"id": "11414937-7711-4cf1-bb9c-357fa775c3e7", "solution": "# import numpy as np\n\nclass Enhanced_Adaptive_Mutation_PSO_SA_Optimizer:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.beta = beta\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n        self.temp_decay = temp_decay\n        self.mutation_scale = mutation_scale\n        self.dynamic_scale_factor = dynamic_scale_factor\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Enhanced convergence speed by dynamically adjusting mutation scale and temperature decay factors with an adaptive mechanism based on both global best and personal best solutions.", "configspace": "", "generation": 93, "fitness": 0.10558296337227657, "feedback": "The algorithm Enhanced_Adaptive_Mutation_PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11 with standard deviation 0.19.", "error": "", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.12260295445140168, 0.11947685247797968, 0.1712205642752055, 0.12008761924512712, 0.18199544217734143, 0.1386268714454887, 0.17504467177553362, 0.12714558139702692, 0.20742175956360176, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04835415276942312, 0.022206927706640234, 0.03613709616761285, 0.018858583105297422, 0.02168475029126804, 0.015410207560193845, 0.05286053545021163, 0.03399007068136739, 0.01849310919291891, 0.01246382039880356, 0.0049489030419821445, 0.0006156842861095857, 0.0014424854728846137, 0.0072218570142533745, 0.01397848081933839, 0.0007534951458901817, 0.010698710116858856, 0.0009000424767853232, 0.9621546504895162, 0.9896757919514211, 0.9909559015337105, 0.9992039200685581, 0.9821743252930901, 0.9990337642319617, 0.9907428193537036, 0.9727041376700166, 0.9894891872392355, 0.043845061899681625, 0.08079043765465543, 0.020275817139078223, 0.00515055803683695, 0.05449380861911013, 0.022221385998442034, 0.00043515885738176774, 0.02615612493870545, 0.009231525090477422, 0.06808074746214865, 0.07154023331345993, 0.05355923047622235, 0.07723502547861938, 0.058164962103124385, 0.04918156957825637, 0.04515113942454885, 0.0682503653625689, 0.10535460552058906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.054542055665274036, 0.061066144799690525, 0.025618495427218835, 0.04737920306491794, 9.999999999998899e-05, 0.0003500330713901434, 0.03319877754448275, 0.03828397007689577, 0.024709618817116308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005608166234629675, 0.15437031771245624, 0.14098749370205566, 0.13746611904423767, 0.12565557642278835, 0.19220883654293475, 0.14982800426269938, 0.13937227729915935, 0.14071287288949275, 0.18393561552773052, 0.01913485645967672, 0.0323906851824135, 0.0317375939635447, 0.02906234698697896, 0.0332760377811655, 0.028853181580578924, 0.021030495235029645, 0.038314355212751394, 0.03823455409746834, 0.14471801260110695, 0.16336160564911228, 0.14435396803855072, 0.16123521435224697, 0.16986300977936186, 0.13663292517543035, 0.13410992939214417, 0.17202668963208156, 0.12467683647522321, 0.12773223689868518, 0.15241279711607458, 0.13329841251619434, 0.14104990982507193, 0.1399896969848805, 0.14595032201804647, 0.14684919724094847, 0.1434501524251811, 0.16679839159934695, 0.07412927925901791, 0.06817785650301467, 0.08966959971294308, 0.07807769700873612, 0.08230504418663909, 0.09735147839171732, 0.09055932238645115, 0.0755673690094667, 0.08449720412666162, 0.11646813376341647, 0.1439951795517661, 0.13215472325379163, 0.1306435058207257, 0.16541065603673322, 0.15222302713084368, 0.12609190406798754, 0.10590868147103993, 0.15945396274544887, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 0.001627199979735039, 9.999999999998899e-05, 9.999999999998899e-05, 0.1175556582095294, 0.1536529960543871, 0.11932827186152661, 0.17588017650267251, 0.16045650807769252, 0.17933225313104761, 0.13434904038957662, 0.14762956385481174, 0.13647071101641217, 0.13306146110709016, 0.13090067373980363, 0.13418678751562552, 0.16062228087036579, 0.12385802544278102, 0.15488825278214258, 0.14275401908604668, 0.14678328341790403, 0.1579310142416236, 0.1778596617435494, 0.1755930809686852, 0.1848768936095213, 0.18915721919526463, 0.18433888073864924, 0.18758530785712835, 0.17970616860733335, 0.18020899566339355, 0.18337711261363543, 0.042147645728826455, 0.0415530752211456, 0.03776526912769351, 0.03394360267638019, 0.05249175375060933, 0.042612102269229624, 0.057303757127379895, 0.02927366547243382, 0.047913905901639575]}, "mutation_prompt": null}
{"id": "0df8bb7a-b313-49f1-b76f-8a61b01f3232", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Enhanced convergence speed by dynamically adjusting mutation scale and temperature decay factors with an adaptive mechanism based on historical acceptance probabilities.", "configspace": "", "generation": 52, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.12260295445140168, 0.11947685247797968, 0.1712205642752055, 0.12008761924512712, 0.18199544217734143, 0.1386268714454887, 0.17504467177553362, 0.12714558139702692, 0.20742175956360176, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04835415276942312, 0.022206927706640234, 0.03613709616761285, 0.018858583105297422, 0.02168475029126804, 0.015410207560193845, 0.05286053545021163, 0.03399007068136739, 0.01849310919291891, 0.01246382039880356, 0.0049489030419821445, 0.0006156842861095857, 0.0014424854728846137, 0.0072218570142533745, 0.01397848081933839, 0.0007534951458901817, 0.010698710116858856, 0.0009000424767853232, 0.9621546504895162, 0.9896757919514211, 0.9909559015337105, 0.9992039200685581, 0.9821743252930901, 0.9990337642319617, 0.9907428193537036, 0.9727041376700166, 0.9894891872392355, 0.043845061899681625, 0.08079043765465543, 0.020275817139078223, 0.00515055803683695, 0.05449380861911013, 0.022221385998442034, 0.00043515885738176774, 0.02615612493870545, 0.009231525090477422, 0.06808074746214865, 0.07154023331345993, 0.05355923047622235, 0.07723502547861938, 0.058164962103124385, 0.04918156957825637, 0.04515113942454885, 0.0682503653625689, 0.10535460552058906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.054542055665274036, 0.061066144799690525, 0.025618495427218835, 0.04737920306491794, 9.999999999998899e-05, 0.0003500330713901434, 0.03319877754448275, 0.03828397007689577, 0.024709618817116308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005608166234629675, 0.15437031771245624, 0.14098749370205566, 0.13746611904423767, 0.12565557642278835, 0.19220883654293475, 0.14982800426269938, 0.13937227729915935, 0.14071287288949275, 0.18393561552773052, 0.01913485645967672, 0.0323906851824135, 0.0317375939635447, 0.02906234698697896, 0.0332760377811655, 0.028853181580578924, 0.021030495235029645, 0.038314355212751394, 0.03823455409746834, 0.14471801260110695, 0.16336160564911228, 0.14435396803855072, 0.16123521435224697, 0.16986300977936186, 0.13663292517543035, 0.13410992939214417, 0.17202668963208156, 0.12467683647522321, 0.12773223689868518, 0.15241279711607458, 0.13329841251619434, 0.14104990982507193, 0.1399896969848805, 0.14595032201804647, 0.14684919724094847, 0.1434501524251811, 0.16679839159934695, 0.07412927925901791, 0.06817785650301467, 0.08966959971294308, 0.07807769700873612, 0.08230504418663909, 0.09735147839171732, 0.09055932238645115, 0.0755673690094667, 0.08449720412666162, 0.11646813376341647, 0.1439951795517661, 0.13215472325379163, 0.1306435058207257, 0.16541065603673322, 0.15222302713084368, 0.12609190406798754, 0.10590868147103993, 0.15945396274544887, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 0.001627199979735039, 9.999999999998899e-05, 9.999999999998899e-05, 0.1175556582095294, 0.1536529960543871, 0.11932827186152661, 0.17588017650267251, 0.16045650807769252, 0.17933225313104761, 0.13434904038957662, 0.14762956385481174, 0.13647071101641217, 0.13306146110709016, 0.13090067373980363, 0.13418678751562552, 0.16062228087036579, 0.12385802544278102, 0.15488825278214258, 0.14275401908604668, 0.14678328341790403, 0.1579310142416236, 0.1778596617435494, 0.1755930809686852, 0.1848768936095213, 0.18915721919526463, 0.18433888073864924, 0.18758530785712835, 0.17970616860733335, 0.18020899566339355, 0.18337711261363543, 0.042147645728826455, 0.0415530752211456, 0.03776526912769351, 0.03394360267638019, 0.05249175375060933, 0.042612102269229624, 0.057303757127379895, 0.02927366547243382, 0.047913905901639575]}, "mutation_prompt": null}
{"id": "2a445845-cb68-4c6a-8c29-08528d9d6786", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Enhanced convergence speed by dynamically adjusting mutation scale and temperature decay factors with an adaptive mechanism based on historical acceptance probabilities.", "configspace": "", "generation": 52, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.12260295445140168, 0.11947685247797968, 0.1712205642752055, 0.12008761924512712, 0.18199544217734143, 0.1386268714454887, 0.17504467177553362, 0.12714558139702692, 0.20742175956360176, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04835415276942312, 0.022206927706640234, 0.03613709616761285, 0.018858583105297422, 0.02168475029126804, 0.015410207560193845, 0.05286053545021163, 0.03399007068136739, 0.01849310919291891, 0.01246382039880356, 0.0049489030419821445, 0.0006156842861095857, 0.0014424854728846137, 0.0072218570142533745, 0.01397848081933839, 0.0007534951458901817, 0.010698710116858856, 0.0009000424767853232, 0.9621546504895162, 0.9896757919514211, 0.9909559015337105, 0.9992039200685581, 0.9821743252930901, 0.9990337642319617, 0.9907428193537036, 0.9727041376700166, 0.9894891872392355, 0.043845061899681625, 0.08079043765465543, 0.020275817139078223, 0.00515055803683695, 0.05449380861911013, 0.022221385998442034, 0.00043515885738176774, 0.02615612493870545, 0.009231525090477422, 0.06808074746214865, 0.07154023331345993, 0.05355923047622235, 0.07723502547861938, 0.058164962103124385, 0.04918156957825637, 0.04515113942454885, 0.0682503653625689, 0.10535460552058906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.054542055665274036, 0.061066144799690525, 0.025618495427218835, 0.04737920306491794, 9.999999999998899e-05, 0.0003500330713901434, 0.03319877754448275, 0.03828397007689577, 0.024709618817116308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005608166234629675, 0.15437031771245624, 0.14098749370205566, 0.13746611904423767, 0.12565557642278835, 0.19220883654293475, 0.14982800426269938, 0.13937227729915935, 0.14071287288949275, 0.18393561552773052, 0.01913485645967672, 0.0323906851824135, 0.0317375939635447, 0.02906234698697896, 0.0332760377811655, 0.028853181580578924, 0.021030495235029645, 0.038314355212751394, 0.03823455409746834, 0.14471801260110695, 0.16336160564911228, 0.14435396803855072, 0.16123521435224697, 0.16986300977936186, 0.13663292517543035, 0.13410992939214417, 0.17202668963208156, 0.12467683647522321, 0.12773223689868518, 0.15241279711607458, 0.13329841251619434, 0.14104990982507193, 0.1399896969848805, 0.14595032201804647, 0.14684919724094847, 0.1434501524251811, 0.16679839159934695, 0.07412927925901791, 0.06817785650301467, 0.08966959971294308, 0.07807769700873612, 0.08230504418663909, 0.09735147839171732, 0.09055932238645115, 0.0755673690094667, 0.08449720412666162, 0.11646813376341647, 0.1439951795517661, 0.13215472325379163, 0.1306435058207257, 0.16541065603673322, 0.15222302713084368, 0.12609190406798754, 0.10590868147103993, 0.15945396274544887, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 0.001627199979735039, 9.999999999998899e-05, 9.999999999998899e-05, 0.1175556582095294, 0.1536529960543871, 0.11932827186152661, 0.17588017650267251, 0.16045650807769252, 0.17933225313104761, 0.13434904038957662, 0.14762956385481174, 0.13647071101641217, 0.13306146110709016, 0.13090067373980363, 0.13418678751562552, 0.16062228087036579, 0.12385802544278102, 0.15488825278214258, 0.14275401908604668, 0.14678328341790403, 0.1579310142416236, 0.1778596617435494, 0.1755930809686852, 0.1848768936095213, 0.18915721919526463, 0.18433888073864924, 0.18758530785712835, 0.17970616860733335, 0.18020899566339355, 0.18337711261363543, 0.042147645728826455, 0.0415530752211456, 0.03776526912769351, 0.03394360267638019, 0.05249175375060933, 0.042612102269229624, 0.057303757127379895, 0.02927366547243382, 0.047913905901639575]}, "mutation_prompt": null}
{"id": "ab2aeb38-eff9-44f5-8361-5c4283a790d7", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Enhanced convergence speed by dynamically adjusting mutation scale and temperature decay factors with an adaptive mechanism based on historical acceptance probabilities.", "configspace": "", "generation": 52, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.12260295445140168, 0.11947685247797968, 0.1712205642752055, 0.12008761924512712, 0.18199544217734143, 0.1386268714454887, 0.17504467177553362, 0.12714558139702692, 0.20742175956360176, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04835415276942312, 0.022206927706640234, 0.03613709616761285, 0.018858583105297422, 0.02168475029126804, 0.015410207560193845, 0.05286053545021163, 0.03399007068136739, 0.01849310919291891, 0.01246382039880356, 0.0049489030419821445, 0.0006156842861095857, 0.0014424854728846137, 0.0072218570142533745, 0.01397848081933839, 0.0007534951458901817, 0.010698710116858856, 0.0009000424767853232, 0.9621546504895162, 0.9896757919514211, 0.9909559015337105, 0.9992039200685581, 0.9821743252930901, 0.9990337642319617, 0.9907428193537036, 0.9727041376700166, 0.9894891872392355, 0.043845061899681625, 0.08079043765465543, 0.020275817139078223, 0.00515055803683695, 0.05449380861911013, 0.022221385998442034, 0.00043515885738176774, 0.02615612493870545, 0.009231525090477422, 0.06808074746214865, 0.07154023331345993, 0.05355923047622235, 0.07723502547861938, 0.058164962103124385, 0.04918156957825637, 0.04515113942454885, 0.0682503653625689, 0.10535460552058906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.054542055665274036, 0.061066144799690525, 0.025618495427218835, 0.04737920306491794, 9.999999999998899e-05, 0.0003500330713901434, 0.03319877754448275, 0.03828397007689577, 0.024709618817116308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005608166234629675, 0.15437031771245624, 0.14098749370205566, 0.13746611904423767, 0.12565557642278835, 0.19220883654293475, 0.14982800426269938, 0.13937227729915935, 0.14071287288949275, 0.18393561552773052, 0.01913485645967672, 0.0323906851824135, 0.0317375939635447, 0.02906234698697896, 0.0332760377811655, 0.028853181580578924, 0.021030495235029645, 0.038314355212751394, 0.03823455409746834, 0.14471801260110695, 0.16336160564911228, 0.14435396803855072, 0.16123521435224697, 0.16986300977936186, 0.13663292517543035, 0.13410992939214417, 0.17202668963208156, 0.12467683647522321, 0.12773223689868518, 0.15241279711607458, 0.13329841251619434, 0.14104990982507193, 0.1399896969848805, 0.14595032201804647, 0.14684919724094847, 0.1434501524251811, 0.16679839159934695, 0.07412927925901791, 0.06817785650301467, 0.08966959971294308, 0.07807769700873612, 0.08230504418663909, 0.09735147839171732, 0.09055932238645115, 0.0755673690094667, 0.08449720412666162, 0.11646813376341647, 0.1439951795517661, 0.13215472325379163, 0.1306435058207257, 0.16541065603673322, 0.15222302713084368, 0.12609190406798754, 0.10590868147103993, 0.15945396274544887, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 0.001627199979735039, 9.999999999998899e-05, 9.999999999998899e-05, 0.1175556582095294, 0.1536529960543871, 0.11932827186152661, 0.17588017650267251, 0.16045650807769252, 0.17933225313104761, 0.13434904038957662, 0.14762956385481174, 0.13647071101641217, 0.13306146110709016, 0.13090067373980363, 0.13418678751562552, 0.16062228087036579, 0.12385802544278102, 0.15488825278214258, 0.14275401908604668, 0.14678328341790403, 0.1579310142416236, 0.1778596617435494, 0.1755930809686852, 0.1848768936095213, 0.18915721919526463, 0.18433888073864924, 0.18758530785712835, 0.17970616860733335, 0.18020899566339355, 0.18337711261363543, 0.042147645728826455, 0.0415530752211456, 0.03776526912769351, 0.03394360267638019, 0.05249175375060933, 0.042612102269229624, 0.057303757127379895, 0.02927366547243382, 0.047913905901639575]}, "mutation_prompt": null}
{"id": "8f9880f1-54cb-4423-b022-10a8e8244984", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Enhanced convergence speed by dynamically adjusting mutation scale and temperature decay factors with an adaptive mechanism based on historical acceptance probabilities.", "configspace": "", "generation": 52, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.12260295445140168, 0.11947685247797968, 0.1712205642752055, 0.12008761924512712, 0.18199544217734143, 0.1386268714454887, 0.17504467177553362, 0.12714558139702692, 0.20742175956360176, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04835415276942312, 0.022206927706640234, 0.03613709616761285, 0.018858583105297422, 0.02168475029126804, 0.015410207560193845, 0.05286053545021163, 0.03399007068136739, 0.01849310919291891, 0.01246382039880356, 0.0049489030419821445, 0.0006156842861095857, 0.0014424854728846137, 0.0072218570142533745, 0.01397848081933839, 0.0007534951458901817, 0.010698710116858856, 0.0009000424767853232, 0.9621546504895162, 0.9896757919514211, 0.9909559015337105, 0.9992039200685581, 0.9821743252930901, 0.9990337642319617, 0.9907428193537036, 0.9727041376700166, 0.9894891872392355, 0.043845061899681625, 0.08079043765465543, 0.020275817139078223, 0.00515055803683695, 0.05449380861911013, 0.022221385998442034, 0.00043515885738176774, 0.02615612493870545, 0.009231525090477422, 0.06808074746214865, 0.07154023331345993, 0.05355923047622235, 0.07723502547861938, 0.058164962103124385, 0.04918156957825637, 0.04515113942454885, 0.0682503653625689, 0.10535460552058906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.054542055665274036, 0.061066144799690525, 0.025618495427218835, 0.04737920306491794, 9.999999999998899e-05, 0.0003500330713901434, 0.03319877754448275, 0.03828397007689577, 0.024709618817116308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005608166234629675, 0.15437031771245624, 0.14098749370205566, 0.13746611904423767, 0.12565557642278835, 0.19220883654293475, 0.14982800426269938, 0.13937227729915935, 0.14071287288949275, 0.18393561552773052, 0.01913485645967672, 0.0323906851824135, 0.0317375939635447, 0.02906234698697896, 0.0332760377811655, 0.028853181580578924, 0.021030495235029645, 0.038314355212751394, 0.03823455409746834, 0.14471801260110695, 0.16336160564911228, 0.14435396803855072, 0.16123521435224697, 0.16986300977936186, 0.13663292517543035, 0.13410992939214417, 0.17202668963208156, 0.12467683647522321, 0.12773223689868518, 0.15241279711607458, 0.13329841251619434, 0.14104990982507193, 0.1399896969848805, 0.14595032201804647, 0.14684919724094847, 0.1434501524251811, 0.16679839159934695, 0.07412927925901791, 0.06817785650301467, 0.08966959971294308, 0.07807769700873612, 0.08230504418663909, 0.09735147839171732, 0.09055932238645115, 0.0755673690094667, 0.08449720412666162, 0.11646813376341647, 0.1439951795517661, 0.13215472325379163, 0.1306435058207257, 0.16541065603673322, 0.15222302713084368, 0.12609190406798754, 0.10590868147103993, 0.15945396274544887, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 0.001627199979735039, 9.999999999998899e-05, 9.999999999998899e-05, 0.1175556582095294, 0.1536529960543871, 0.11932827186152661, 0.17588017650267251, 0.16045650807769252, 0.17933225313104761, 0.13434904038957662, 0.14762956385481174, 0.13647071101641217, 0.13306146110709016, 0.13090067373980363, 0.13418678751562552, 0.16062228087036579, 0.12385802544278102, 0.15488825278214258, 0.14275401908604668, 0.14678328341790403, 0.1579310142416236, 0.1778596617435494, 0.1755930809686852, 0.1848768936095213, 0.18915721919526463, 0.18433888073864924, 0.18758530785712835, 0.17970616860733335, 0.18020899566339355, 0.18337711261363543, 0.042147645728826455, 0.0415530752211456, 0.03776526912769351, 0.03394360267638019, 0.05249175375060933, 0.042612102269229624, 0.057303757127379895, 0.02927366547243382, 0.047913905901639575]}, "mutation_prompt": null}
{"id": "4f6c404e-0932-4353-81b1-d92a28465329", "solution": "import numpy as np\n\nclass Dynamically_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor) * np.exp(-best_fitness / 100)  # Dynamic adaptation based on best fitness\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Dynamically_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Enhanced convergence speed by introducing a dynamic adaptation of mutation scale based on the current best fitness value, aiming to accelerate convergence rate further.", "configspace": "", "generation": 98, "fitness": 0.08710799734623825, "feedback": "The algorithm Dynamically_Adaptive_Mutation_PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.16.", "error": "", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.11601088360021727, 0.11050308460994329, 0.12504763332448143, 0.12192200075297555, 0.14033556830915828, 0.1549607818486899, 0.18742875528096137, 0.12924780057728236, 0.20735820852132825, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05236349985412181, 0.02707709009752801, 0.00759035201574243, 0.026626704662915612, 0.019669539704861405, 0.03655372180209615, 0.04925939993281592, 0.01711029204411174, 0.011325027415804656, 0.010939330949546688, 0.0005143131305829218, 0.0033896716283252637, 0.00645618230252365, 0.009247741705872614, 0.008611175231217238, 0.00970930305058959, 0.011960288443703782, 0.01028705684285014, 0.9621541325064101, 0.9895837315624667, 0.9766938350215549, 0.045750202551212205, 0.036675751819649105, 0.0453932108231887, 0.9907310201999596, 0.9628285416050923, 0.9354785274967224, 0.012019096890639958, 0.035964568539764374, 9.999999999998899e-05, 0.012657578125371938, 0.0012628855651933835, 0.022221385998442034, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07467265356497987, 0.10410799058809261, 0.06816379749326729, 0.06567679879984212, 0.0379981927438614, 0.04416525186882847, 0.0935550746564815, 0.03685708612565031, 0.07903446087406696, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.004512674370890646, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0060787532054414894, 0.005345121163061406, 9.999999999998899e-05, 0.026898475087477336, 9.999999999998899e-05, 0.0019665226181528883, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.014257029437341417, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.002102382770724054, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14198910478182702, 0.18579623474340623, 0.14043606535711461, 0.14842818296347937, 0.1786242288297113, 0.13905133476068043, 0.14551678083965913, 0.15021742348726308, 0.16606877805063647, 0.00035648288025802444, 0.002116619751782678, 0.00034874111221527837, 0.02518702400786299, 0.017793330651258654, 0.02467129423219394, 0.014482555772452166, 0.02945408582570075, 0.023462398854791955, 0.14312303232897483, 0.14892951480566385, 0.13969924746286433, 0.15491866942290833, 0.14233298205674016, 0.13472081829190174, 0.13090688085806468, 0.14594501347637834, 0.15575890117310176, 0.13639446830167923, 0.1341631152974957, 0.1300948239432067, 0.15559561103354957, 0.14121020074819002, 0.14250830137107184, 0.15196571284467697, 0.14534445104883764, 0.1521225596113187, 0.06416376564702586, 0.07784080973644836, 0.08369601258790083, 0.10161021810315052, 0.09981087448880921, 0.12079342116080627, 0.10668980995857802, 0.08042404922093715, 0.09450431379269597, 0.11494019269698585, 0.13054858196058772, 0.12433310564986788, 0.17337985955234303, 0.14230328611188126, 0.1493996106224459, 0.1407109842234, 0.1194181669287755, 0.13310878868648002, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07452827343798474, 9.999999999998899e-05, 9.999999999998899e-05, 0.10583621398527543, 9.999999999998899e-05, 0.11909588099533941, 0.15186893716785033, 0.1130448047575544, 0.11790511013251037, 0.11657435833404706, 0.12299836991761837, 0.13133593031711244, 0.12462910394704618, 0.12374747100676997, 0.057601355637475926, 0.11067785766670424, 0.0685533903581994, 0.07641537817261657, 0.05813076387842486, 0.0469737691480846, 0.15376058820140037, 0.14927686301572807, 0.14661134896361983, 0.1770356687374175, 0.18195315661920053, 0.17452750092538594, 0.18275962318091388, 0.18190640834298444, 0.2028019520721528, 0.17805939339812216, 0.18373378285201492, 0.17908112959682077, 0.028048887951026558, 0.03705114814230803, 0.038876637492350374, 0.0473365421926244, 0.046455990827285465, 0.06341417096780866, 0.057303757127379895, 0.027927037784583608, 0.042983176155216074]}, "mutation_prompt": null}
{"id": "81c69fe1-3d11-4422-b28c-72c756ac49d3", "solution": "import numpy as np\n\nclass Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer(Enhanced_Adaptive_Mutation_PSO_SA_Optimizer):\n    def __init__(self, budget, dim, num_particles=30, alpha=0.9, beta=2.0, initial_temp=1000.0, final_temp=0.1, temp_decay=0.99, mutation_scale=0.1, dynamic_scale_factor=0.1):\n        super().__init__(budget, dim, num_particles, alpha, beta, initial_temp, final_temp, temp_decay, mutation_scale, dynamic_scale_factor)\n\n    def __call__(self, func):\n        def sa_optimize(obj_func, lower_bound, upper_bound, temp, max_iter, mutation_scale, acceptance_prob_history):\n            current_state = np.random.uniform(low=lower_bound, high=upper_bound, size=self.dim)\n            best_state = current_state\n            best_fitness = obj_func(best_state)\n            for _ in range(max_iter):\n                dynamic_mutation_scale = mutation_scale * np.exp(-self.dynamic_scale_factor)\n                candidate_state = current_state + np.random.normal(0, temp * dynamic_mutation_scale, size=self.dim)\n                candidate_state = np.clip(candidate_state, lower_bound, upper_bound)\n                candidate_fitness = obj_func(candidate_state)\n                if candidate_fitness < best_fitness:\n                    best_state = candidate_state\n                    best_fitness = candidate_fitness\n                acceptance_prob = np.exp((best_fitness - candidate_fitness) / temp)\n                acceptance_prob_history.append(acceptance_prob)\n                if np.random.rand() < acceptance_prob:\n                    current_state = candidate_state\n                temp *= self.temp_decay * np.mean(acceptance_prob_history)  # Adjust temperature dynamically based on historical acceptance probabilities for enhanced convergence\n            return best_state\n\n        best_solution = None\n        for _ in range(self.budget):\n            acceptance_prob_history = []\n            if np.random.rand() < 0.5:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n                self.initial_temp *= self.temp_decay ** 1.2\n            else:\n                best_solution = sa_optimize(func, -5.0, 5.0, self.initial_temp, 100, self.mutation_scale, acceptance_prob_history)\n\n        return best_solution", "name": "Faster_Enhanced_Adaptive_Mutation_PSO_SA_Optimizer", "description": "Enhanced convergence speed by dynamically adjusting mutation scale and temperature decay factors with an adaptive mechanism based on historical acceptance probabilities.", "configspace": "", "generation": 52, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "86182645-66bf-4d43-a07b-5adf7f0b9d2e", "metadata": {"aucs": [0.12260295445140168, 0.11947685247797968, 0.1712205642752055, 0.12008761924512712, 0.18199544217734143, 0.1386268714454887, 0.17504467177553362, 0.12714558139702692, 0.20742175956360176, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04835415276942312, 0.022206927706640234, 0.03613709616761285, 0.018858583105297422, 0.02168475029126804, 0.015410207560193845, 0.05286053545021163, 0.03399007068136739, 0.01849310919291891, 0.01246382039880356, 0.0049489030419821445, 0.0006156842861095857, 0.0014424854728846137, 0.0072218570142533745, 0.01397848081933839, 0.0007534951458901817, 0.010698710116858856, 0.0009000424767853232, 0.9621546504895162, 0.9896757919514211, 0.9909559015337105, 0.9992039200685581, 0.9821743252930901, 0.9990337642319617, 0.9907428193537036, 0.9727041376700166, 0.9894891872392355, 0.043845061899681625, 0.08079043765465543, 0.020275817139078223, 0.00515055803683695, 0.05449380861911013, 0.022221385998442034, 0.00043515885738176774, 0.02615612493870545, 0.009231525090477422, 0.06808074746214865, 0.07154023331345993, 0.05355923047622235, 0.07723502547861938, 0.058164962103124385, 0.04918156957825637, 0.04515113942454885, 0.0682503653625689, 0.10535460552058906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.054542055665274036, 0.061066144799690525, 0.025618495427218835, 0.04737920306491794, 9.999999999998899e-05, 0.0003500330713901434, 0.03319877754448275, 0.03828397007689577, 0.024709618817116308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005608166234629675, 0.15437031771245624, 0.14098749370205566, 0.13746611904423767, 0.12565557642278835, 0.19220883654293475, 0.14982800426269938, 0.13937227729915935, 0.14071287288949275, 0.18393561552773052, 0.01913485645967672, 0.0323906851824135, 0.0317375939635447, 0.02906234698697896, 0.0332760377811655, 0.028853181580578924, 0.021030495235029645, 0.038314355212751394, 0.03823455409746834, 0.14471801260110695, 0.16336160564911228, 0.14435396803855072, 0.16123521435224697, 0.16986300977936186, 0.13663292517543035, 0.13410992939214417, 0.17202668963208156, 0.12467683647522321, 0.12773223689868518, 0.15241279711607458, 0.13329841251619434, 0.14104990982507193, 0.1399896969848805, 0.14595032201804647, 0.14684919724094847, 0.1434501524251811, 0.16679839159934695, 0.07412927925901791, 0.06817785650301467, 0.08966959971294308, 0.07807769700873612, 0.08230504418663909, 0.09735147839171732, 0.09055932238645115, 0.0755673690094667, 0.08449720412666162, 0.11646813376341647, 0.1439951795517661, 0.13215472325379163, 0.1306435058207257, 0.16541065603673322, 0.15222302713084368, 0.12609190406798754, 0.10590868147103993, 0.15945396274544887, 0.12418272955839271, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07339333286871152, 9.999999999998899e-05, 0.001627199979735039, 9.999999999998899e-05, 9.999999999998899e-05, 0.1175556582095294, 0.1536529960543871, 0.11932827186152661, 0.17588017650267251, 0.16045650807769252, 0.17933225313104761, 0.13434904038957662, 0.14762956385481174, 0.13647071101641217, 0.13306146110709016, 0.13090067373980363, 0.13418678751562552, 0.16062228087036579, 0.12385802544278102, 0.15488825278214258, 0.14275401908604668, 0.14678328341790403, 0.1579310142416236, 0.1778596617435494, 0.1755930809686852, 0.1848768936095213, 0.18915721919526463, 0.18433888073864924, 0.18758530785712835, 0.17970616860733335, 0.18020899566339355, 0.18337711261363543, 0.042147645728826455, 0.0415530752211456, 0.03776526912769351, 0.03394360267638019, 0.05249175375060933, 0.042612102269229624, 0.057303757127379895, 0.02927366547243382, 0.047913905901639575]}, "mutation_prompt": null}

{"id": "6fcadeec-a081-4c57-a393-b971d52fc974", "solution": "import numpy as np\n\nclass GreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta):\n            a = 2 - 2 * (np.arange(self.dim) / (self.dim - 1))\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for _ in range(self.budget - 5):\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                wolf['position'] = update_position(wolf, alpha, beta, delta)\n                wolf['fitness'] = func(wolf['position'])\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "GreyWolfOptimization", "description": "Grey Wolf Optimization (GWO) algorithm inspired by the social hierarchy and hunting behavior of grey wolves.", "configspace": "", "generation": 0, "fitness": 0.061136114456340276, "feedback": "The algorithm GreyWolfOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.06.", "error": "", "parent_id": null, "metadata": {"aucs": [0.12247834127814983, 0.16550585838853127, 0.13999419835451044, 0.03232009392327184, 0.1346972603408063, 0.03756511812635488, 0.14867364656485238, 0.08080572898475602, 0.14358416653514539, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07027798496793058, 0.007572006180603941, 9.999999999998899e-05, 0.01846676555779725, 0.005690878279122624, 9.999999999998899e-05, 0.04433596231240733, 0.006591974149647073, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01960752770993024, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07142461008183909, 0.06023081352531923, 0.04288564073158885, 0.00983865995102573, 0.0860905174778529, 0.030585431661608764, 0.008281281935880735, 0.0654560965832659, 0.027510331314582248, 0.025861956563420607, 0.02231345463412382, 9.999999999998899e-05, 0.017921061687064865, 0.08932707937357443, 0.01804761927812082, 9.999999999998899e-05, 0.052459892173496, 0.045069720387095225, 0.10029430247433702, 0.037774794445334936, 0.08128655373986038, 0.09555160775847449, 0.15156046620071795, 0.07329676216568637, 0.03194910921632077, 0.04818721019009631, 0.14504588843538913, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04186165849763457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.039575282398758516, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.16215788066851633, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04111337490312994, 0.08998357828085723, 0.03855826942677554, 0.043325828326409965, 0.029567354086747044, 0.057146347309885104, 0.07946275931298186, 0.05796094798651685, 0.09555065117411232, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.17615183240219134, 0.12948044470416065, 0.16013376717570338, 0.09426253841157506, 0.08183386427144956, 0.09583895902187123, 0.12815757930980942, 0.15566545776217933, 0.15429894378383235, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.010093026635773827, 0.020899786543058685, 0.03739019699141133, 0.009244303551268818, 0.013705746161835508, 0.0942559311678064, 0.1084956683394297, 0.10884330631973715, 0.12256095817675994, 0.13308804463811053, 0.11304335817740574, 0.06240559407956969, 0.09192072744150248, 0.1980350569020386, 0.07783541570109886, 0.11845840239909866, 0.12425117588679546, 0.12921730254202235, 0.11934110250418739, 0.14368832362193118, 0.15900736239278535, 0.10882983285143422, 0.1247754246588978, 0.11703746671922122, 0.052149020458760575, 0.07304123560720677, 0.05981963728767681, 0.08778411348852411, 0.08471029777953787, 0.09932756737666826, 0.045351084647676676, 0.05252478046367759, 0.05709353000218542, 0.11747054788777078, 0.19216923749356996, 0.21637929785209153, 0.15041319585522983, 0.22013783177590862, 0.2624778963496146, 0.18827877781363822, 0.16564927491123183, 0.19193538786523334, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.15395936403777755, 9.999999999998899e-05, 0.15978081429574487, 9.999999999998899e-05, 0.16948413582385724, 9.999999999998899e-05, 0.1122897393619896, 0.1125612160602848, 0.06538520831996408, 0.08909329541996558, 0.12080917085526266, 0.10334257164776117, 0.10936390985317668, 0.08553473852833271, 0.10842818619791428, 0.038244138611014944, 0.13005936089750048, 0.09967315696316859, 0.07666316341442492, 0.0355355981112907, 0.05166868638741362, 0.07811398990654028, 0.02401611663751535, 0.056189541453866565, 0.16765812534338087, 0.17933580626516454, 0.16434005561235332, 0.20343022705457547, 0.16485576117266332, 0.19445813847963178, 0.21244931467526063, 0.19079545871073422, 0.16898321287240559, 0.015249389977957106, 0.010650766017769486, 0.061225371979405474, 0.05633449695362758, 0.015663558918688425, 0.05201915683859237, 0.03663329112562008, 0.045288660785263724, 0.04689190482726657]}, "mutation_prompt": null}
{"id": "a52a1728-2eef-4088-8db2-30e20a551b9a", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, epoch):\n            a = 2 - 2 * (np.arange(self.dim) / (self.dim - 1))\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2 * (1 - np.exp(-epoch / self.budget))\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2 * (1 - np.exp(-epoch / self.budget))\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2 * (1 - np.exp(-epoch / self.budget))\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for epoch in range(self.budget - 5):\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                wolf['position'] = update_position(wolf, alpha, beta, delta, epoch)\n                wolf['fitness'] = func(wolf['position'])\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimization", "description": "Improved Grey Wolf Optimization algorithm by incorporating adaptive step size control to enhance convergence speed.", "configspace": "", "generation": 1, "fitness": 0.05984332560447153, "feedback": "The algorithm FastConvergingGreyWolfOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.06.", "error": "", "parent_id": "6fcadeec-a081-4c57-a393-b971d52fc974", "metadata": {"aucs": [0.11485859982589264, 0.1584119572856746, 0.14065705755400482, 0.033510780247033134, 0.10741793956433943, 0.04606931344539822, 0.1512760438104107, 0.0814558582463707, 0.14436913919925498, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.040602535479615454, 9.999999999998899e-05, 9.999999999998899e-05, 0.027288187305886225, 0.002158191676227772, 9.999999999998899e-05, 0.0503436410235214, 0.008565636914336539, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01960752770993024, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04826862571190049, 0.04477288427619697, 0.04288564073158885, 0.00983865995102573, 0.07777323586147666, 0.030585431661608764, 0.008281281935880735, 0.07907472391297798, 0.025852846022385134, 0.02579671027290409, 0.022336424777398833, 9.999999999998899e-05, 0.01731532912026945, 0.08920270303278288, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1064576262430188, 0.037774794445334936, 0.08117925303815754, 0.011725003660672861, 0.053923340386271, 0.030608668033895614, 0.034042846396056814, 0.06523867475181178, 0.14134263892330723, 9.999999999998899e-05, 0.06238435438484502, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013842488465017233, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04386449077283017, 0.10114796824732386, 9.999999999998899e-05, 0.026987119388401704, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.034275684937067674, 0.08938196569401757, 0.03729488825238936, 0.039737794747655375, 0.03240347395521148, 0.05362993480945588, 0.0784452897847635, 0.059226359992766264, 0.031224338498811233, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.2112875607999789, 0.1246614568142741, 0.15398117213705353, 0.09426253841157506, 0.082433445913489, 0.09583895902187123, 0.12828767919698514, 0.15589645456777967, 0.1538912045938241, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01637332062409058, 0.0075645654172409316, 0.028676070810102483, 0.02718986853511418, 0.024108941346295598, 0.0784552158866485, 0.11006319293307565, 0.10745986768299132, 0.10582241035484441, 0.12616359800573462, 0.08775738018877688, 0.10744351484882209, 0.15363391790983683, 0.18148130375094362, 0.07862361811608676, 0.13102045777655835, 0.12021797156105274, 0.13193078796999547, 0.12636442432659079, 0.1434040431192225, 0.15060664210602992, 0.0965055455976146, 0.12763675026315435, 0.12168364048892022, 0.06155366794150907, 0.07146044522415451, 0.05629697008025747, 0.08960655534705075, 0.08324421453430819, 0.10519912235786288, 0.045351084647676676, 0.07212768858797058, 0.03960954884177459, 0.12346038579415075, 0.23616997609018697, 0.23944125657812265, 0.17551055688317607, 0.21815632761766346, 0.2547037352022212, 0.16430373760847672, 0.1862609746401055, 0.22415578879877984, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1641684017338657, 9.999999999998899e-05, 0.16005094987011292, 9.999999999998899e-05, 0.1599344241474122, 9.999999999998899e-05, 0.09689327257007918, 0.10715987304008556, 0.08182396047595852, 0.09296215151994347, 0.12080917085526266, 0.09717952917360384, 0.10838294525943837, 0.07101658226352703, 0.13389403022451385, 0.04943264649234713, 0.11726162052620803, 0.09185757310159037, 0.07071260507110277, 0.037252440650510144, 0.0635431258242285, 0.08476059051027574, 0.02019288770378258, 0.0477975263351762, 0.15113659090675757, 0.19285664385799972, 0.19752801640110051, 0.18070061665112336, 0.20682567682711972, 0.1673620276029102, 0.1733177829274598, 0.1709311120973802, 0.17521209475746913, 0.014378709003582624, 0.013923687164342335, 0.06520216309164606, 0.06466060422883202, 0.020914458665668878, 0.04009106333312229, 0.04185323075209002, 0.05970927940303261, 0.05291280332779258]}, "mutation_prompt": null}
{"id": "7daf5300-e794-49bc-bdaa-5c8eca5231c4", "solution": "import numpy as np\n\nclass DynamicPopSizeGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta):\n            a = 2 - 2 * (np.arange(self.dim) / (self.dim - 1))\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                wolf['position'] = update_position(wolf, alpha, beta, delta)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "DynamicPopSizeGreyWolfOptimization", "description": "Introducing a dynamic population size adaptation strategy to enhance convergence speed by adjusting the population size during optimization.", "configspace": "", "generation": 2, "fitness": 0.09777692833928403, "feedback": "The algorithm DynamicPopSizeGreyWolfOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.07.", "error": "", "parent_id": "6fcadeec-a081-4c57-a393-b971d52fc974", "metadata": {"aucs": [0.20603845891964268, 0.1667935510724572, 0.2968180630033337, 0.1256043986032982, 0.1405250728629146, 0.10507048048719392, 0.1556729805558712, 0.17062923585465528, 0.20988068228749734, 9.999999999998899e-05, 9.999999999998899e-05, 0.01562249909752389, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06959223278962567, 0.08235450201279004, 0.044001703270107106, 0.03145820619204365, 0.027445025089759323, 0.06658461139874816, 0.07801710271437845, 0.05833024719607638, 0.10176246282383983, 0.024453262511986762, 0.054543402355097026, 0.05002460445035817, 0.038531973913098816, 0.018944159750575507, 0.0027144087819253038, 0.015325229904419979, 0.007517039522875191, 0.003950608003025491, 0.09095962326962603, 0.10307096854178832, 0.0541666958369309, 0.05686620075118631, 0.10484739124326248, 0.06285362362823, 0.039475767932233286, 0.10527255755283971, 0.06669953545494023, 0.08901878075827174, 0.1441855754732687, 0.02684928810080167, 0.13054214344000925, 0.13431155521975346, 0.12098582327136487, 0.050297091141113026, 0.04179275006950356, 0.08988948715289913, 0.1161288715992298, 0.10096844995850696, 0.08429775381712812, 0.11475928842989847, 0.13921018725903833, 0.12916251312320925, 0.12814010774439233, 0.13031993040316225, 0.17227353217284758, 0.2333574191312734, 9.999999999998899e-05, 9.999999999998899e-05, 0.09240678368347544, 0.12041929197501555, 0.116241074652908, 9.999999999998899e-05, 0.12030520587056415, 0.10993259014620305, 9.999999999998899e-05, 0.14291951655386526, 9.999999999998899e-05, 0.0014034116670565977, 0.014588633894034087, 0.03152476632056134, 0.16820757869723657, 0.03918904250929556, 0.010426789800877523, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0004498505070620329, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08495112907674629, 0.10338428226197993, 0.06451414765897512, 0.04270972907940673, 0.017540797826210874, 0.051439157025172655, 0.06810620165196946, 0.05267102680870417, 0.10351164552801384, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00630258716154275, 9.999999999998899e-05, 0.03285260564113468, 9.999999999998899e-05, 9.999999999998899e-05, 0.0024423705474023727, 9.999999999998899e-05, 9.999999999998899e-05, 0.255255070277432, 0.19528395210891036, 0.1758342776648113, 0.1309265310241804, 0.13282896741517836, 0.18833867724683473, 0.16321595012983725, 0.17701802582011206, 0.1910342542816187, 0.0331332150943916, 0.043771206424108255, 0.02484138247419565, 0.06667014162470297, 0.06421953174922923, 0.07114586631447761, 0.0958350072089994, 0.039183316727681494, 0.08706781109063289, 0.13744236372836172, 0.2386072494676984, 0.14852042741368587, 0.17864981237084154, 0.2397515116279283, 0.17250918420084072, 0.1572415584625838, 0.15597570936401517, 0.17299185196976619, 0.16540250614891483, 0.1537311741527596, 0.13771568028839554, 0.19168368201646624, 0.18754791563646345, 0.16981355986729574, 0.17611132355802728, 0.16475641378203654, 0.1622694389477467, 0.12350830127482482, 0.10182776606481314, 0.08435894244820175, 0.10070868713895109, 0.11647275844751659, 0.13291168800932174, 0.1617188022346332, 0.08447055994993846, 0.08930511915362349, 0.16526980904947663, 0.23348006681200684, 0.22840326791058063, 0.1693936284435913, 0.2703815438388161, 0.2318717164704479, 0.22412477955055832, 0.21973482068239003, 0.26458815176389994, 0.1722756413314992, 9.999999999998899e-05, 0.16778021801123666, 0.16872918400621983, 0.16505421192637804, 0.18628851475655095, 0.18435620609675984, 0.17593777719615633, 0.1569283183586171, 0.1241511097630309, 0.1410195884434039, 0.14388270721746033, 0.162239038997967, 0.12882356701233644, 0.10963432404602258, 0.18339057735693198, 0.13169670035715186, 0.11476598778526348, 0.13338754018010335, 0.1852797198762035, 0.14628770009604375, 0.12845451138972908, 0.10108600876579854, 0.10756125282457485, 0.09957508219337563, 0.13955025343400052, 0.07792823832019546, 0.183411394744308, 0.17502703811775044, 0.17618531549998329, 0.17014255163154268, 0.18978853928570072, 0.19388451738605328, 0.18897721477730345, 0.1825124924938749, 0.17698885154112143, 0.0658538064555001, 0.09091483388114607, 0.093563732657167, 0.06485988708754009, 0.07223168110664213, 0.077249124574853, 0.07042283716303632, 0.06510451708821219, 0.06672991467860923]}, "mutation_prompt": null}
{"id": "805a6256-a96d-4c92-8388-4fad54193e8b", "solution": "import numpy as np\n\nclass AdaptiveStepSizeGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta):\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1))  # Adaptive step size\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                wolf['position'] = update_position(wolf, alpha, beta, delta)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "AdaptiveStepSizeGreyWolfOptimization", "description": "Implementing an adaptive step size mechanism in the update process to enhance exploration and exploitation trade-off for faster convergence.", "configspace": "", "generation": 3, "fitness": 0.16959225437171635, "feedback": "The algorithm AdaptiveStepSizeGreyWolfOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.18.", "error": "", "parent_id": "7daf5300-e794-49bc-bdaa-5c8eca5231c4", "metadata": {"aucs": [0.4280005542135037, 0.4301038859630526, 0.40998749526009715, 0.1863744432545401, 0.22805264858446106, 0.14588981862490746, 0.36619263467818086, 0.34902591744019895, 0.3497551827727978, 0.04343308877073759, 0.041433649309343124, 0.024832913386822697, 0.15503803354267365, 0.13273250012667792, 0.1323281284793234, 0.04441013913793501, 9.999999999998899e-05, 9.999999999998899e-05, 0.08444050944431203, 0.08692527001959205, 0.044870649419736064, 0.1001119613024335, 0.12060360446361396, 0.13002196637460328, 0.049266160511935775, 0.11331149645357397, 0.137935629192234, 0.08599548777343025, 0.008038138380593196, 0.028062081470193734, 0.07901990830302019, 0.028365456776527576, 0.010408768816590808, 0.036208172265237204, 0.03168497738773801, 0.050226586807897045, 0.9571567708295172, 0.925961462773607, 0.7061700505065153, 0.9404698440480742, 0.9666028129194918, 0.8803502482745194, 0.9208789702701744, 0.9299220968398813, 0.8773457707969541, 0.18372541655183217, 0.2099817210197067, 0.03629018768811698, 0.21716120571659947, 0.20154594112612112, 0.15307954656768374, 0.1993955480570757, 0.054543957460305714, 0.08988948715289913, 0.12315230475721561, 0.11103438391139042, 0.10468373435246281, 0.19495578639751743, 0.17064810364056704, 0.1514454326930581, 0.1374356323264243, 0.12084371001188388, 0.17400798629790737, 0.18157160256717875, 0.2593188285716931, 0.08344563483379408, 0.1385147983899786, 0.10463762354900541, 0.1370199116558808, 0.059289908371237154, 0.09660349806631807, 0.11242546020657795, 0.15636441466565776, 0.16832503763981366, 0.12726544502989634, 0.11319160588614685, 0.11828854077351536, 0.15216667613189927, 0.2257272725247833, 0.21860389532019897, 0.2132785561323739, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00012295511271276371, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07449463792386646, 0.1401366535896863, 0.06665368815034256, 0.056710102314107114, 0.032647023706712575, 0.04981463627574445, 0.08376490043647211, 0.05049508178806206, 0.11722790966915964, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05795122976639777, 9.999999999998899e-05, 0.005712622144011803, 0.01740081441946917, 0.01800008950827614, 0.04281726889274251, 0.00982457279702631, 0.028099302382120883, 0.34046529378302237, 0.18939822586696187, 0.2732666427501488, 0.13529371224331677, 0.34362743103534554, 0.36766559489394823, 0.19747873562743412, 0.20187431393807787, 0.19995562464090766, 0.026511950629969916, 0.052393230285242454, 0.032663247211467517, 0.06570854683144367, 0.07734502739922533, 0.07180834641493616, 0.09825066545591599, 0.062420611532331916, 0.07836193018576565, 0.27028678700121767, 0.20791244296810307, 0.1600629399803547, 0.15728883923507675, 0.1911855531520522, 0.30557721632474455, 0.1758208213544422, 0.23265283458450337, 0.1717011933572612, 0.1699676951740957, 0.1618939200390268, 0.1628548324864112, 0.2143504556161404, 0.17960256945694109, 0.1704448307090577, 0.1652511768401761, 0.16319527908612308, 0.16578367635517466, 0.10205950278717446, 0.10582792142165598, 0.09279403425476962, 0.16915932511707144, 0.14220499089260885, 0.13036065174519684, 0.16521634389087014, 0.07918996937349332, 0.1061973553050286, 0.22182500805290895, 0.23813026207365096, 0.19626045683248716, 0.2051879618019018, 0.23825908343056645, 0.2661812724248007, 0.2620383943583664, 0.19186448371598963, 0.22514502017901783, 0.1721921965678821, 0.17339548208452926, 0.18403138169019229, 0.17431782278076824, 0.18726049282155022, 0.19222742833280015, 0.16222470568238911, 0.17687570001400532, 0.17351717625397245, 0.4412188308549211, 0.12157424764225777, 0.49133854924857767, 0.5206962819975444, 0.1209707491742853, 0.19594170427424473, 0.1646169748717219, 0.15232583753354734, 0.15853732862304204, 0.4962968939105361, 0.24507778571925132, 0.4049798808332813, 0.13199543654860846, 0.18180111946493338, 0.13935960650692103, 0.10448381948192231, 0.16178776888652724, 0.08790791003800802, 0.1770092643220027, 0.19943131375305234, 0.19724847727632777, 0.17946725546854048, 0.1984864297317558, 0.19478597565557831, 0.18588787768390558, 0.1782498432493359, 0.20238403314359632, 0.06680189949356552, 0.0734418550202165, 0.07927271704014927, 0.07799151164994655, 0.0907905068599486, 0.07828532725668536, 0.0791130773548443, 0.0662720592856707, 0.06005200521459175]}, "mutation_prompt": null}
{"id": "7d08243e-74c8-47eb-9f46-d5b15b59d53c", "solution": "import numpy as np\n\nclass AdaptiveStepSizeGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta):\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1))  # Adaptive step size\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                wolf['position'] = update_position(wolf, alpha, beta, delta)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "AdaptiveStepSizeGreyWolfOptimization", "description": "Implementing an adaptive step size mechanism in the update process to enhance exploration and exploitation trade-off for faster convergence.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "805a6256-a96d-4c92-8388-4fad54193e8b", "metadata": {"aucs": [0.4280005542135037, 0.4301038859630526, 0.40998749526009715, 0.1863744432545401, 0.22805264858446106, 0.14588981862490746, 0.36619263467818086, 0.34902591744019895, 0.3497551827727978, 0.04343308877073759, 0.041433649309343124, 0.024832913386822697, 0.15503803354267365, 0.13273250012667792, 0.1323281284793234, 0.04441013913793501, 9.999999999998899e-05, 9.999999999998899e-05, 0.08444050944431203, 0.08692527001959205, 0.044870649419736064, 0.1001119613024335, 0.12060360446361396, 0.13002196637460328, 0.049266160511935775, 0.11331149645357397, 0.137935629192234, 0.08599548777343025, 0.008038138380593196, 0.028062081470193734, 0.07901990830302019, 0.028365456776527576, 0.010408768816590808, 0.036208172265237204, 0.03168497738773801, 0.050226586807897045, 0.9571567708295172, 0.925961462773607, 0.7061700505065153, 0.9404698440480742, 0.9666028129194918, 0.8803502482745194, 0.9208789702701744, 0.9299220968398813, 0.8773457707969541, 0.18372541655183217, 0.2099817210197067, 0.03629018768811698, 0.21716120571659947, 0.20154594112612112, 0.15307954656768374, 0.1993955480570757, 0.054543957460305714, 0.08988948715289913, 0.12315230475721561, 0.11103438391139042, 0.10468373435246281, 0.19495578639751743, 0.17064810364056704, 0.1514454326930581, 0.1374356323264243, 0.12084371001188388, 0.17400798629790737, 0.18157160256717875, 0.2593188285716931, 0.08344563483379408, 0.1385147983899786, 0.10463762354900541, 0.1370199116558808, 0.059289908371237154, 0.09660349806631807, 0.11242546020657795, 0.15636441466565776, 0.16832503763981366, 0.12726544502989634, 0.11319160588614685, 0.11828854077351536, 0.15216667613189927, 0.2257272725247833, 0.21860389532019897, 0.2132785561323739, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00012295511271276371, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07449463792386646, 0.1401366535896863, 0.06665368815034256, 0.056710102314107114, 0.032647023706712575, 0.04981463627574445, 0.08376490043647211, 0.05049508178806206, 0.11722790966915964, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05795122976639777, 9.999999999998899e-05, 0.005712622144011803, 0.01740081441946917, 0.01800008950827614, 0.04281726889274251, 0.00982457279702631, 0.028099302382120883, 0.34046529378302237, 0.18939822586696187, 0.2732666427501488, 0.13529371224331677, 0.34362743103534554, 0.36766559489394823, 0.19747873562743412, 0.20187431393807787, 0.19995562464090766, 0.026511950629969916, 0.052393230285242454, 0.032663247211467517, 0.06570854683144367, 0.07734502739922533, 0.07180834641493616, 0.09825066545591599, 0.062420611532331916, 0.07836193018576565, 0.27028678700121767, 0.20791244296810307, 0.1600629399803547, 0.15728883923507675, 0.1911855531520522, 0.30557721632474455, 0.1758208213544422, 0.23265283458450337, 0.1717011933572612, 0.1699676951740957, 0.1618939200390268, 0.1628548324864112, 0.2143504556161404, 0.17960256945694109, 0.1704448307090577, 0.1652511768401761, 0.16319527908612308, 0.16578367635517466, 0.10205950278717446, 0.10582792142165598, 0.09279403425476962, 0.16915932511707144, 0.14220499089260885, 0.13036065174519684, 0.16521634389087014, 0.07918996937349332, 0.1061973553050286, 0.22182500805290895, 0.23813026207365096, 0.19626045683248716, 0.2051879618019018, 0.23825908343056645, 0.2661812724248007, 0.2620383943583664, 0.19186448371598963, 0.22514502017901783, 0.1721921965678821, 0.17339548208452926, 0.18403138169019229, 0.17431782278076824, 0.18726049282155022, 0.19222742833280015, 0.16222470568238911, 0.17687570001400532, 0.17351717625397245, 0.4412188308549211, 0.12157424764225777, 0.49133854924857767, 0.5206962819975444, 0.1209707491742853, 0.19594170427424473, 0.1646169748717219, 0.15232583753354734, 0.15853732862304204, 0.4962968939105361, 0.24507778571925132, 0.4049798808332813, 0.13199543654860846, 0.18180111946493338, 0.13935960650692103, 0.10448381948192231, 0.16178776888652724, 0.08790791003800802, 0.1770092643220027, 0.19943131375305234, 0.19724847727632777, 0.17946725546854048, 0.1984864297317558, 0.19478597565557831, 0.18588787768390558, 0.1782498432493359, 0.20238403314359632, 0.06680189949356552, 0.0734418550202165, 0.07927271704014927, 0.07799151164994655, 0.0907905068599486, 0.07828532725668536, 0.0791130773548443, 0.0662720592856707, 0.06005200521459175]}, "mutation_prompt": null}
{"id": "cc90e8ab-7012-459b-ae67-6b929ea5b476", "solution": "import numpy as np\n\nclass AdaptiveStepSizeGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta):\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1))  # Adaptive step size\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                wolf['position'] = update_position(wolf, alpha, beta, delta)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "AdaptiveStepSizeGreyWolfOptimization", "description": "Implementing an adaptive step size mechanism in the update process to enhance exploration and exploitation trade-off for faster convergence.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "805a6256-a96d-4c92-8388-4fad54193e8b", "metadata": {"aucs": [0.4280005542135037, 0.4301038859630526, 0.40998749526009715, 0.1863744432545401, 0.22805264858446106, 0.14588981862490746, 0.36619263467818086, 0.34902591744019895, 0.3497551827727978, 0.04343308877073759, 0.041433649309343124, 0.024832913386822697, 0.15503803354267365, 0.13273250012667792, 0.1323281284793234, 0.04441013913793501, 9.999999999998899e-05, 9.999999999998899e-05, 0.08444050944431203, 0.08692527001959205, 0.044870649419736064, 0.1001119613024335, 0.12060360446361396, 0.13002196637460328, 0.049266160511935775, 0.11331149645357397, 0.137935629192234, 0.08599548777343025, 0.008038138380593196, 0.028062081470193734, 0.07901990830302019, 0.028365456776527576, 0.010408768816590808, 0.036208172265237204, 0.03168497738773801, 0.050226586807897045, 0.9571567708295172, 0.925961462773607, 0.7061700505065153, 0.9404698440480742, 0.9666028129194918, 0.8803502482745194, 0.9208789702701744, 0.9299220968398813, 0.8773457707969541, 0.18372541655183217, 0.2099817210197067, 0.03629018768811698, 0.21716120571659947, 0.20154594112612112, 0.15307954656768374, 0.1993955480570757, 0.054543957460305714, 0.08988948715289913, 0.12315230475721561, 0.11103438391139042, 0.10468373435246281, 0.19495578639751743, 0.17064810364056704, 0.1514454326930581, 0.1374356323264243, 0.12084371001188388, 0.17400798629790737, 0.18157160256717875, 0.2593188285716931, 0.08344563483379408, 0.1385147983899786, 0.10463762354900541, 0.1370199116558808, 0.059289908371237154, 0.09660349806631807, 0.11242546020657795, 0.15636441466565776, 0.16832503763981366, 0.12726544502989634, 0.11319160588614685, 0.11828854077351536, 0.15216667613189927, 0.2257272725247833, 0.21860389532019897, 0.2132785561323739, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00012295511271276371, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07449463792386646, 0.1401366535896863, 0.06665368815034256, 0.056710102314107114, 0.032647023706712575, 0.04981463627574445, 0.08376490043647211, 0.05049508178806206, 0.11722790966915964, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05795122976639777, 9.999999999998899e-05, 0.005712622144011803, 0.01740081441946917, 0.01800008950827614, 0.04281726889274251, 0.00982457279702631, 0.028099302382120883, 0.34046529378302237, 0.18939822586696187, 0.2732666427501488, 0.13529371224331677, 0.34362743103534554, 0.36766559489394823, 0.19747873562743412, 0.20187431393807787, 0.19995562464090766, 0.026511950629969916, 0.052393230285242454, 0.032663247211467517, 0.06570854683144367, 0.07734502739922533, 0.07180834641493616, 0.09825066545591599, 0.062420611532331916, 0.07836193018576565, 0.27028678700121767, 0.20791244296810307, 0.1600629399803547, 0.15728883923507675, 0.1911855531520522, 0.30557721632474455, 0.1758208213544422, 0.23265283458450337, 0.1717011933572612, 0.1699676951740957, 0.1618939200390268, 0.1628548324864112, 0.2143504556161404, 0.17960256945694109, 0.1704448307090577, 0.1652511768401761, 0.16319527908612308, 0.16578367635517466, 0.10205950278717446, 0.10582792142165598, 0.09279403425476962, 0.16915932511707144, 0.14220499089260885, 0.13036065174519684, 0.16521634389087014, 0.07918996937349332, 0.1061973553050286, 0.22182500805290895, 0.23813026207365096, 0.19626045683248716, 0.2051879618019018, 0.23825908343056645, 0.2661812724248007, 0.2620383943583664, 0.19186448371598963, 0.22514502017901783, 0.1721921965678821, 0.17339548208452926, 0.18403138169019229, 0.17431782278076824, 0.18726049282155022, 0.19222742833280015, 0.16222470568238911, 0.17687570001400532, 0.17351717625397245, 0.4412188308549211, 0.12157424764225777, 0.49133854924857767, 0.5206962819975444, 0.1209707491742853, 0.19594170427424473, 0.1646169748717219, 0.15232583753354734, 0.15853732862304204, 0.4962968939105361, 0.24507778571925132, 0.4049798808332813, 0.13199543654860846, 0.18180111946493338, 0.13935960650692103, 0.10448381948192231, 0.16178776888652724, 0.08790791003800802, 0.1770092643220027, 0.19943131375305234, 0.19724847727632777, 0.17946725546854048, 0.1984864297317558, 0.19478597565557831, 0.18588787768390558, 0.1782498432493359, 0.20238403314359632, 0.06680189949356552, 0.0734418550202165, 0.07927271704014927, 0.07799151164994655, 0.0907905068599486, 0.07828532725668536, 0.0791130773548443, 0.0662720592856707, 0.06005200521459175]}, "mutation_prompt": null}
{"id": "92f7e08f-8319-4295-afca-44ec3e69850f", "solution": "import numpy as np\n\nclass AdaptiveStepSizeGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta):\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1))  # Adaptive step size\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                wolf['position'] = update_position(wolf, alpha, beta, delta)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "AdaptiveStepSizeGreyWolfOptimization", "description": "Implementing an adaptive step size mechanism in the update process to enhance exploration and exploitation trade-off for faster convergence.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "805a6256-a96d-4c92-8388-4fad54193e8b", "metadata": {"aucs": [0.4280005542135037, 0.4301038859630526, 0.40998749526009715, 0.1863744432545401, 0.22805264858446106, 0.14588981862490746, 0.36619263467818086, 0.34902591744019895, 0.3497551827727978, 0.04343308877073759, 0.041433649309343124, 0.024832913386822697, 0.15503803354267365, 0.13273250012667792, 0.1323281284793234, 0.04441013913793501, 9.999999999998899e-05, 9.999999999998899e-05, 0.08444050944431203, 0.08692527001959205, 0.044870649419736064, 0.1001119613024335, 0.12060360446361396, 0.13002196637460328, 0.049266160511935775, 0.11331149645357397, 0.137935629192234, 0.08599548777343025, 0.008038138380593196, 0.028062081470193734, 0.07901990830302019, 0.028365456776527576, 0.010408768816590808, 0.036208172265237204, 0.03168497738773801, 0.050226586807897045, 0.9571567708295172, 0.925961462773607, 0.7061700505065153, 0.9404698440480742, 0.9666028129194918, 0.8803502482745194, 0.9208789702701744, 0.9299220968398813, 0.8773457707969541, 0.18372541655183217, 0.2099817210197067, 0.03629018768811698, 0.21716120571659947, 0.20154594112612112, 0.15307954656768374, 0.1993955480570757, 0.054543957460305714, 0.08988948715289913, 0.12315230475721561, 0.11103438391139042, 0.10468373435246281, 0.19495578639751743, 0.17064810364056704, 0.1514454326930581, 0.1374356323264243, 0.12084371001188388, 0.17400798629790737, 0.18157160256717875, 0.2593188285716931, 0.08344563483379408, 0.1385147983899786, 0.10463762354900541, 0.1370199116558808, 0.059289908371237154, 0.09660349806631807, 0.11242546020657795, 0.15636441466565776, 0.16832503763981366, 0.12726544502989634, 0.11319160588614685, 0.11828854077351536, 0.15216667613189927, 0.2257272725247833, 0.21860389532019897, 0.2132785561323739, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00012295511271276371, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07449463792386646, 0.1401366535896863, 0.06665368815034256, 0.056710102314107114, 0.032647023706712575, 0.04981463627574445, 0.08376490043647211, 0.05049508178806206, 0.11722790966915964, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05795122976639777, 9.999999999998899e-05, 0.005712622144011803, 0.01740081441946917, 0.01800008950827614, 0.04281726889274251, 0.00982457279702631, 0.028099302382120883, 0.34046529378302237, 0.18939822586696187, 0.2732666427501488, 0.13529371224331677, 0.34362743103534554, 0.36766559489394823, 0.19747873562743412, 0.20187431393807787, 0.19995562464090766, 0.026511950629969916, 0.052393230285242454, 0.032663247211467517, 0.06570854683144367, 0.07734502739922533, 0.07180834641493616, 0.09825066545591599, 0.062420611532331916, 0.07836193018576565, 0.27028678700121767, 0.20791244296810307, 0.1600629399803547, 0.15728883923507675, 0.1911855531520522, 0.30557721632474455, 0.1758208213544422, 0.23265283458450337, 0.1717011933572612, 0.1699676951740957, 0.1618939200390268, 0.1628548324864112, 0.2143504556161404, 0.17960256945694109, 0.1704448307090577, 0.1652511768401761, 0.16319527908612308, 0.16578367635517466, 0.10205950278717446, 0.10582792142165598, 0.09279403425476962, 0.16915932511707144, 0.14220499089260885, 0.13036065174519684, 0.16521634389087014, 0.07918996937349332, 0.1061973553050286, 0.22182500805290895, 0.23813026207365096, 0.19626045683248716, 0.2051879618019018, 0.23825908343056645, 0.2661812724248007, 0.2620383943583664, 0.19186448371598963, 0.22514502017901783, 0.1721921965678821, 0.17339548208452926, 0.18403138169019229, 0.17431782278076824, 0.18726049282155022, 0.19222742833280015, 0.16222470568238911, 0.17687570001400532, 0.17351717625397245, 0.4412188308549211, 0.12157424764225777, 0.49133854924857767, 0.5206962819975444, 0.1209707491742853, 0.19594170427424473, 0.1646169748717219, 0.15232583753354734, 0.15853732862304204, 0.4962968939105361, 0.24507778571925132, 0.4049798808332813, 0.13199543654860846, 0.18180111946493338, 0.13935960650692103, 0.10448381948192231, 0.16178776888652724, 0.08790791003800802, 0.1770092643220027, 0.19943131375305234, 0.19724847727632777, 0.17946725546854048, 0.1984864297317558, 0.19478597565557831, 0.18588787768390558, 0.1782498432493359, 0.20238403314359632, 0.06680189949356552, 0.0734418550202165, 0.07927271704014927, 0.07799151164994655, 0.0907905068599486, 0.07828532725668536, 0.0791130773548443, 0.0662720592856707, 0.06005200521459175]}, "mutation_prompt": null}
{"id": "3ec855c9-d888-428f-b885-e4c5d84efe70", "solution": "import numpy as np\n\nclass AdaptiveStepSizeGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta):\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1))  # Adaptive step size\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                wolf['position'] = update_position(wolf, alpha, beta, delta)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "AdaptiveStepSizeGreyWolfOptimization", "description": "Implementing an adaptive step size mechanism in the update process to enhance exploration and exploitation trade-off for faster convergence.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "805a6256-a96d-4c92-8388-4fad54193e8b", "metadata": {"aucs": [0.4280005542135037, 0.4301038859630526, 0.40998749526009715, 0.1863744432545401, 0.22805264858446106, 0.14588981862490746, 0.36619263467818086, 0.34902591744019895, 0.3497551827727978, 0.04343308877073759, 0.041433649309343124, 0.024832913386822697, 0.15503803354267365, 0.13273250012667792, 0.1323281284793234, 0.04441013913793501, 9.999999999998899e-05, 9.999999999998899e-05, 0.08444050944431203, 0.08692527001959205, 0.044870649419736064, 0.1001119613024335, 0.12060360446361396, 0.13002196637460328, 0.049266160511935775, 0.11331149645357397, 0.137935629192234, 0.08599548777343025, 0.008038138380593196, 0.028062081470193734, 0.07901990830302019, 0.028365456776527576, 0.010408768816590808, 0.036208172265237204, 0.03168497738773801, 0.050226586807897045, 0.9571567708295172, 0.925961462773607, 0.7061700505065153, 0.9404698440480742, 0.9666028129194918, 0.8803502482745194, 0.9208789702701744, 0.9299220968398813, 0.8773457707969541, 0.18372541655183217, 0.2099817210197067, 0.03629018768811698, 0.21716120571659947, 0.20154594112612112, 0.15307954656768374, 0.1993955480570757, 0.054543957460305714, 0.08988948715289913, 0.12315230475721561, 0.11103438391139042, 0.10468373435246281, 0.19495578639751743, 0.17064810364056704, 0.1514454326930581, 0.1374356323264243, 0.12084371001188388, 0.17400798629790737, 0.18157160256717875, 0.2593188285716931, 0.08344563483379408, 0.1385147983899786, 0.10463762354900541, 0.1370199116558808, 0.059289908371237154, 0.09660349806631807, 0.11242546020657795, 0.15636441466565776, 0.16832503763981366, 0.12726544502989634, 0.11319160588614685, 0.11828854077351536, 0.15216667613189927, 0.2257272725247833, 0.21860389532019897, 0.2132785561323739, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00012295511271276371, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07449463792386646, 0.1401366535896863, 0.06665368815034256, 0.056710102314107114, 0.032647023706712575, 0.04981463627574445, 0.08376490043647211, 0.05049508178806206, 0.11722790966915964, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05795122976639777, 9.999999999998899e-05, 0.005712622144011803, 0.01740081441946917, 0.01800008950827614, 0.04281726889274251, 0.00982457279702631, 0.028099302382120883, 0.34046529378302237, 0.18939822586696187, 0.2732666427501488, 0.13529371224331677, 0.34362743103534554, 0.36766559489394823, 0.19747873562743412, 0.20187431393807787, 0.19995562464090766, 0.026511950629969916, 0.052393230285242454, 0.032663247211467517, 0.06570854683144367, 0.07734502739922533, 0.07180834641493616, 0.09825066545591599, 0.062420611532331916, 0.07836193018576565, 0.27028678700121767, 0.20791244296810307, 0.1600629399803547, 0.15728883923507675, 0.1911855531520522, 0.30557721632474455, 0.1758208213544422, 0.23265283458450337, 0.1717011933572612, 0.1699676951740957, 0.1618939200390268, 0.1628548324864112, 0.2143504556161404, 0.17960256945694109, 0.1704448307090577, 0.1652511768401761, 0.16319527908612308, 0.16578367635517466, 0.10205950278717446, 0.10582792142165598, 0.09279403425476962, 0.16915932511707144, 0.14220499089260885, 0.13036065174519684, 0.16521634389087014, 0.07918996937349332, 0.1061973553050286, 0.22182500805290895, 0.23813026207365096, 0.19626045683248716, 0.2051879618019018, 0.23825908343056645, 0.2661812724248007, 0.2620383943583664, 0.19186448371598963, 0.22514502017901783, 0.1721921965678821, 0.17339548208452926, 0.18403138169019229, 0.17431782278076824, 0.18726049282155022, 0.19222742833280015, 0.16222470568238911, 0.17687570001400532, 0.17351717625397245, 0.4412188308549211, 0.12157424764225777, 0.49133854924857767, 0.5206962819975444, 0.1209707491742853, 0.19594170427424473, 0.1646169748717219, 0.15232583753354734, 0.15853732862304204, 0.4962968939105361, 0.24507778571925132, 0.4049798808332813, 0.13199543654860846, 0.18180111946493338, 0.13935960650692103, 0.10448381948192231, 0.16178776888652724, 0.08790791003800802, 0.1770092643220027, 0.19943131375305234, 0.19724847727632777, 0.17946725546854048, 0.1984864297317558, 0.19478597565557831, 0.18588787768390558, 0.1782498432493359, 0.20238403314359632, 0.06680189949356552, 0.0734418550202165, 0.07927271704014927, 0.07799151164994655, 0.0907905068599486, 0.07828532725668536, 0.0791130773548443, 0.0662720592856707, 0.06005200521459175]}, "mutation_prompt": null}
{"id": "9d26cc15-a0e6-410d-a9b2-87482e462c91", "solution": "import numpy as np\n\nclass DynamicMutationGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_mutation_rate = 0.1\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, mutation_rate):\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * mutation_rate * r1 - mutation_rate\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * mutation_rate * r1 - mutation_rate\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * mutation_rate * r1 - mutation_rate\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        mutation_rate = self.initial_mutation_rate\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                wolf['position'] = update_position(wolf, alpha, beta, delta, mutation_rate)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n            # Dynamic mutation rate adaptation based on individual performance\n            best_wolf = min(wolves, key=lambda x: x['fitness'])\n            worst_wolf = max(wolves, key=lambda x: x['fitness'])\n            mutation_rate = self.initial_mutation_rate + 0.8 * (worst_wolf['fitness'] - best_wolf['fitness']) / self.budget\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "DynamicMutationGreyWolfOptimization", "description": "Introducing a dynamic mutation rate adaptation strategy to adjust the exploration-exploitation balance dynamically based on individual wolf performance.", "configspace": "", "generation": 8, "fitness": 0.08160236527051777, "feedback": "The algorithm DynamicMutationGreyWolfOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.09.", "error": "", "parent_id": "805a6256-a96d-4c92-8388-4fad54193e8b", "metadata": {"aucs": [0.4457272592231122, 0.3401986677014137, 0.4861497385364246, 0.07636942093573307, 0.24920759748809318, 0.10042296333928957, 0.2686453904791415, 0.11343353020314062, 0.12583653011808837, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.046097374317386364, 0.11203079701222718, 0.034212405484395414, 0.05894344197224888, 0.0728204605499001, 0.049931480710219134, 0.07380658390753703, 0.11441806517017872, 0.05681519313969896, 0.04628027578931271, 0.0007776550482316846, 0.03474599053971883, 0.06050774354984079, 0.005543543718412369, 0.026837606789430035, 0.06182460550989766, 0.007827483398599955, 0.016863806159278516, 0.07363503687434436, 0.07183609086021314, 0.054640654078559, 0.09183935013335054, 0.09364733388662139, 0.06073218181203133, 0.06598355923681154, 0.07584238201323146, 0.06331165585204768, 0.0140485547066177, 0.010573685513229236, 0.01212181755625441, 0.0013668929057039092, 0.007188407116177187, 0.01790682155403922, 0.02147405840058003, 0.030111237269194513, 0.08988948715289913, 0.10274357718901594, 0.08616928864723228, 0.07251951133955459, 0.0226411840827353, 0.09392313689214038, 0.09523368748460037, 0.086491905016433, 0.10844153680429858, 0.1585624639993528, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0002601143904735759, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007095745122885799, 0.0016949641412206118, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0018277030032737285, 9.999999999998899e-05, 9.999999999998899e-05, 0.01803598820957575, 9.999999999998899e-05, 9.999999999998899e-05, 0.035778837243037875, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04626497625922199, 0.03236394399618325, 0.07293654344942369, 0.04026111939630883, 0.07000964036800228, 0.003573204188263346, 0.05071186167325248, 0.02659638739045056, 0.013170375236377763, 0.17243649376877768, 0.3125728373749136, 0.3050579887038277, 0.13085452199292813, 0.156778583323117, 0.18861504844870303, 0.19134957576841538, 0.19635902281159456, 0.3299786132737754, 0.010396085212319717, 9.999999999998899e-05, 0.021993456074745676, 0.025964033331400294, 0.02798338772521769, 0.020358393960143495, 0.03535096289495543, 0.050041936978307944, 0.0402625465212586, 0.1085058303876183, 0.21393156039004724, 0.18348183927627382, 0.11564633559450521, 0.11518303713689149, 0.1579087203178724, 0.17845327847788883, 0.13856402227939635, 0.15933056106147492, 0.13512258197622973, 0.1331543990835018, 0.12547814434730375, 0.1774899432218321, 0.1557860274881323, 0.13804086763531598, 0.1377365363785339, 0.12212516565219556, 0.1284095586722569, 0.11414291910279717, 0.08008079832896142, 0.061926121496040265, 0.11177379712918156, 0.10305607030789088, 0.09061633303787053, 0.10470427104392022, 0.07047350321867796, 0.08022559331035284, 0.16459850375690388, 0.21659575356038496, 0.1818968532792944, 0.14593747635560828, 0.1839412414520728, 0.18112323540403763, 0.1959775800585174, 0.19010739309831182, 0.136320980897494, 0.13020797621036218, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09504174446788727, 0.13943307713850994, 0.13464722393971806, 0.17588572339240105, 0.12102317475867641, 0.08614007615535624, 0.16546387381669792, 0.12080917085526266, 0.16435469235480016, 0.10586076271513323, 0.10910529893401288, 0.10188911733286099, 0.0962671018820691, 0.06169119224634101, 0.27619058274330177, 0.13781527985590714, 0.14821828560817663, 0.0812005776333512, 0.10288760474467085, 0.1437359389721765, 0.08209248488356913, 0.22105320256059724, 0.20547242952259204, 0.20498861696069337, 0.19544347831804032, 0.19566891383641094, 0.200343208769048, 0.18922828547421233, 0.1951790410211065, 0.21197996364528304, 0.03398730137991046, 0.11621437539651847, 0.07614570998375891, 0.08130529529521335, 0.03685498130512388, 0.07185344038265573, 0.04835842146339642, 0.07871079810100678, 0.034029638758868885]}, "mutation_prompt": null}
{"id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimization", "description": "Introducing a dynamic step size adaptation based on the fitness improvement of each wolf to enhance convergence speed.", "configspace": "", "generation": 9, "fitness": 0.17892404043211702, "feedback": "The algorithm FastConvergingGreyWolfOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.18.", "error": "", "parent_id": "805a6256-a96d-4c92-8388-4fad54193e8b", "metadata": {"aucs": [0.33103449821939324, 0.3040480949406318, 0.3461539359040635, 0.267793838862431, 0.2843969316116849, 0.2579788652640307, 0.3101385872159119, 0.2660038630830429, 0.2565912122677866, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03727747940920767, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06948116989397035, 0.08114407681055125, 0.10342990083102321, 0.08859400181634902, 0.0946155582231244, 0.09812887798405245, 0.08176519286147577, 0.09684455887673016, 0.09242528037982012, 0.06597573101815779, 0.10571133621874274, 0.06739552500802215, 0.0942054385300709, 0.09599353136195987, 0.08879216843695925, 0.10025631140984992, 0.08720666807292399, 0.08805875069231373, 0.9848018523315675, 0.8915316774981772, 0.9345264689549528, 0.7883110260487081, 0.8929883510228567, 0.7855541599393364, 0.8866503114863262, 0.9341388746780092, 0.9452182528822439, 0.14330396746291585, 0.16146368724502314, 0.14485079224495134, 0.17284344577065858, 0.16577723631939556, 0.15623283775750152, 0.1473982940114965, 0.13497839833414726, 0.15712073811617044, 0.2236846606974785, 0.24311857957954008, 0.2190569572986214, 0.17380823843846394, 0.19035851938659532, 0.19500388806733404, 0.18587275446522733, 0.17568447906810503, 0.20952542841534205, 0.15318493975060488, 0.16814716976188215, 0.11797696838796978, 0.11922586881092867, 0.08712242319663133, 0.12203081015270656, 0.12218525688950754, 0.1225678963627106, 0.10342573868844429, 0.15646523614027608, 0.16910911619199542, 0.16948557812108078, 0.1600653124257415, 0.21180495086248452, 0.19898118117418062, 0.21854811547650554, 0.2247493235454746, 0.20760635656803228, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021399270440071283, 0.05867242115284843, 0.07169694229015, 0.11720015909147119, 0.06298103292773771, 0.05197702363637002, 0.05006604696275374, 0.07281931232118932, 0.1135336882890633, 0.060079732367998795, 0.08920191197026617, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021518231367246732, 0.02638014093755303, 0.02828327903317318, 0.027482138015897717, 0.01740190476981185, 0.03872348720440966, 0.03366216337300232, 0.03477159293533949, 0.0183672558502187, 0.32098844448283803, 0.3144535596010207, 0.3020527511347463, 0.31442699311923406, 0.2767146871076611, 0.2767817147028242, 0.327857212653598, 0.30549845692593514, 0.3223802132140039, 0.08203107833550183, 0.07611606790580916, 0.05908507600733026, 0.08715322678776483, 0.10827536649180125, 0.09704270741381316, 0.08652960588484637, 0.09238939703854832, 0.08007703988549908, 0.15487947981659544, 0.2119714898259606, 0.17122107754848237, 0.13148031201107968, 0.1583467446675717, 0.1479320059738769, 0.18496351186448579, 0.15498723741066056, 0.20403333473465313, 0.22022068630660652, 0.22617170716539292, 0.20201253706684008, 0.24845596760645772, 0.25766169684727536, 0.26323374988734405, 0.20783004187583431, 0.22907748524617422, 0.21467966478440625, 0.14836528853078834, 0.1865140288800997, 0.15702995960377197, 0.219007908625384, 0.21911198530248777, 0.20083737306061844, 0.1534803065344308, 0.1670681993156763, 0.1604125298100838, 0.254903090163632, 0.2736687508861446, 0.24479217304664236, 0.28945157999979987, 0.2849774299913692, 0.2554423599657626, 0.24986782284130216, 0.23801971193128824, 0.2484408539088342, 0.17522236515332645, 0.1763697804468748, 0.17499662499676705, 0.1782165084240953, 0.17413122546255833, 0.17527486547514615, 0.1814231217620833, 0.1735518473349632, 0.17712344391275947, 0.18097343656188725, 0.17246273898918174, 0.18103555852842945, 0.3515536202739914, 0.41761905971110524, 0.3032891863193108, 0.3526464297259342, 0.17482538870191833, 0.1089920771050662, 0.3212440981235244, 0.3446039576929306, 0.3150403350803024, 0.19682264207377953, 0.22811846691488713, 0.14377776766171557, 0.10338919898019627, 0.09267659410535489, 0.25312972258697186, 0.1787941768981045, 0.17488685365308687, 0.19539397196069253, 0.1889962219148058, 0.18292682228564006, 0.17285647524571446, 0.18929720207292877, 0.18438917247426256, 0.18430896628986404, 0.0848861819838117, 0.0641329465883369, 0.09305789667303255, 0.07806169079221836, 0.08015765813005127, 0.09374862538134388, 0.07424144447088032, 0.07891411310650731, 0.09308332941118713]}, "mutation_prompt": null}
{"id": "c225767e-1933-426e-9f1a-9ab037a92eb8", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimizationImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            fitness_values = np.array([wolf['fitness'] for wolf in wolves])\n            fitness_var = np.var(fitness_values)\n            if fitness_var > 0:\n                new_wolves = [wolf for wolf in wolves if wolf['fitness'] < np.mean(fitness_values) + 0.5 * np.std(fitness_values)]\n                while len(new_wolves) < len(wolves):\n                    new_wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                                       'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n                wolves = new_wolves\n\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimizationImproved", "description": "Introducing a dynamic population size adaptation based on fitness variance to enhance convergence speed.", "configspace": "", "generation": 10, "fitness": 0.11899048432984172, "feedback": "The algorithm FastConvergingGreyWolfOptimizationImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.08.", "error": "", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.26547195871681784, 0.2572417147849969, 0.26864817716628275, 0.2284648823011044, 0.2852947513985091, 0.22593716179906465, 0.22621447843369535, 0.24105464028397228, 0.22808138440107728, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01303430869751332, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06405198355466002, 0.05600898999041126, 0.0660541554283951, 0.060596684812391, 0.07748598592678624, 0.06315274822491557, 0.06369207692480539, 0.06220118510993833, 0.06678707368696557, 0.05003010759874704, 0.060076296467785006, 0.04380513396111252, 0.06085819512533286, 0.06312825039270664, 0.05795804524812376, 0.04661756300484288, 0.06236336857417901, 0.05004285731786384, 0.13357696874977099, 0.15927380736649266, 0.1833016657557428, 0.13606354158508693, 0.12108932597126076, 0.1554633435394056, 0.17223250705776283, 0.1490215612246304, 0.16989715918240067, 0.09115842844559408, 0.09284747855889841, 0.09335247419618664, 0.07560582007364425, 0.0958102641585108, 0.08235251834874957, 0.09749670758635731, 0.11657080451055313, 0.10828393106499157, 0.15636291129360214, 0.18127179780899283, 0.17402680702010165, 0.16482978468877996, 0.16132192479677965, 0.15921761136276524, 0.150592122988914, 0.15809535984837586, 0.16423734211013785, 0.08000085853846173, 0.05821466334378178, 0.06589192721860526, 0.06996176512861563, 0.015706898500210453, 0.042640684267088, 0.0740293438500026, 0.07135623306790384, 0.05986241146841642, 0.13265126587214748, 0.17165006411299255, 0.10735455030507746, 0.1552742994990829, 0.1228531012006373, 0.14837006557190124, 0.1866634541832436, 0.13275880084686864, 0.10458772402703476, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07162067664162952, 0.07931710258515556, 0.0752386370774828, 0.08301534334763816, 0.08137289792865432, 0.058179484970300455, 0.11428090259162726, 0.06405152747779685, 0.08529013569187172, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0009623875564489515, 0.004013248922561052, 0.0001602853166172702, 0.018754694226928548, 0.0013412998764531503, 9.999999999998899e-05, 9.999999999998899e-05, 0.006279033035437531, 0.24976862427149737, 0.25708861972287367, 0.24702678989871507, 0.21875977955458725, 0.22244966198414073, 0.24636048138605682, 0.24131201756640808, 0.24792927534980436, 0.23773503664513107, 0.07786285170122387, 0.05341101363704803, 0.0718138464919511, 0.06949873781024785, 0.05682959517363928, 0.06260994635041839, 0.06833588171848859, 0.06783375473334508, 0.06753465901770084, 0.14544246927584403, 0.16267055816657683, 0.12233077331763487, 0.14427031412596425, 0.16663450430933735, 0.1702312271712597, 0.15179874248393121, 0.13660813686994155, 0.1329123187413188, 0.17855698932243302, 0.1788595689354634, 0.18692685956970811, 0.21582686031680665, 0.21057661435740105, 0.2052370098141073, 0.18446236843572872, 0.18695113615212944, 0.20579708286329534, 0.12360528382301106, 0.11737938235694378, 0.12447080733833915, 0.1568572417867694, 0.14674861689652774, 0.17447673911621697, 0.13045208205107062, 0.1270276227646262, 0.12526420490601975, 0.20132344933328772, 0.19677419199605595, 0.20810438266407405, 0.19295381379837362, 0.22055067872137413, 0.19158639819660006, 0.19494171196594834, 0.1880345066565391, 0.21549682745453747, 0.16423279643216848, 0.16182686888491626, 0.16769874490004621, 0.16358902564889866, 0.17538394645689748, 0.16694217990085003, 0.16713954232671946, 0.1632839306652566, 0.165691848686789, 0.20981418543601282, 0.1660016854688331, 0.17052590146300595, 0.17842493114842417, 0.17821153696952463, 0.2102186827698055, 0.21340330955308995, 0.16618936891031044, 0.1901091934599285, 0.18531801076258203, 0.25267181206017586, 0.20610393260102855, 0.17925649563703316, 0.1698742359439711, 0.19628869678790684, 0.14450054407492063, 0.12561205829449062, 0.19718046231755038, 0.18902591215694498, 0.2123632543213535, 0.17468423098789465, 0.19085143929472081, 0.1963734564376839, 0.18230573048340215, 0.19023294893398146, 0.19951667280336438, 0.21046234531306107, 0.08973886003363407, 0.07027063337388084, 0.08483036162632585, 0.09428337389880015, 0.059547351676507376, 0.06495820780468098, 0.06535781331913748, 0.06634001553547897, 0.0746921337391856]}, "mutation_prompt": null}
{"id": "1b9216b7-3e4c-4674-85b3-c0758b12ad0d", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimization", "description": "Introducing a dynamic step size adaptation based on the fitness improvement of each wolf to enhance convergence speed.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.33103449821939324, 0.3040480949406318, 0.3461539359040635, 0.267793838862431, 0.2843969316116849, 0.2579788652640307, 0.3101385872159119, 0.2660038630830429, 0.2565912122677866, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03727747940920767, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06948116989397035, 0.08114407681055125, 0.10342990083102321, 0.08859400181634902, 0.0946155582231244, 0.09812887798405245, 0.08176519286147577, 0.09684455887673016, 0.09242528037982012, 0.06597573101815779, 0.10571133621874274, 0.06739552500802215, 0.0942054385300709, 0.09599353136195987, 0.08879216843695925, 0.10025631140984992, 0.08720666807292399, 0.08805875069231373, 0.9848018523315675, 0.8915316774981772, 0.9345264689549528, 0.7883110260487081, 0.8929883510228567, 0.7855541599393364, 0.8866503114863262, 0.9341388746780092, 0.9452182528822439, 0.14330396746291585, 0.16146368724502314, 0.14485079224495134, 0.17284344577065858, 0.16577723631939556, 0.15623283775750152, 0.1473982940114965, 0.13497839833414726, 0.15712073811617044, 0.2236846606974785, 0.24311857957954008, 0.2190569572986214, 0.17380823843846394, 0.19035851938659532, 0.19500388806733404, 0.18587275446522733, 0.17568447906810503, 0.20952542841534205, 0.15318493975060488, 0.16814716976188215, 0.11797696838796978, 0.11922586881092867, 0.08712242319663133, 0.12203081015270656, 0.12218525688950754, 0.1225678963627106, 0.10342573868844429, 0.15646523614027608, 0.16910911619199542, 0.16948557812108078, 0.1600653124257415, 0.21180495086248452, 0.19898118117418062, 0.21854811547650554, 0.2247493235454746, 0.20760635656803228, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021399270440071283, 0.05867242115284843, 0.07169694229015, 0.11720015909147119, 0.06298103292773771, 0.05197702363637002, 0.05006604696275374, 0.07281931232118932, 0.1135336882890633, 0.060079732367998795, 0.08920191197026617, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021518231367246732, 0.02638014093755303, 0.02828327903317318, 0.027482138015897717, 0.01740190476981185, 0.03872348720440966, 0.03366216337300232, 0.03477159293533949, 0.0183672558502187, 0.32098844448283803, 0.3144535596010207, 0.3020527511347463, 0.31442699311923406, 0.2767146871076611, 0.2767817147028242, 0.327857212653598, 0.30549845692593514, 0.3223802132140039, 0.08203107833550183, 0.07611606790580916, 0.05908507600733026, 0.08715322678776483, 0.10827536649180125, 0.09704270741381316, 0.08652960588484637, 0.09238939703854832, 0.08007703988549908, 0.15487947981659544, 0.2119714898259606, 0.17122107754848237, 0.13148031201107968, 0.1583467446675717, 0.1479320059738769, 0.18496351186448579, 0.15498723741066056, 0.20403333473465313, 0.22022068630660652, 0.22617170716539292, 0.20201253706684008, 0.24845596760645772, 0.25766169684727536, 0.26323374988734405, 0.20783004187583431, 0.22907748524617422, 0.21467966478440625, 0.14836528853078834, 0.1865140288800997, 0.15702995960377197, 0.219007908625384, 0.21911198530248777, 0.20083737306061844, 0.1534803065344308, 0.1670681993156763, 0.1604125298100838, 0.254903090163632, 0.2736687508861446, 0.24479217304664236, 0.28945157999979987, 0.2849774299913692, 0.2554423599657626, 0.24986782284130216, 0.23801971193128824, 0.2484408539088342, 0.17522236515332645, 0.1763697804468748, 0.17499662499676705, 0.1782165084240953, 0.17413122546255833, 0.17527486547514615, 0.1814231217620833, 0.1735518473349632, 0.17712344391275947, 0.18097343656188725, 0.17246273898918174, 0.18103555852842945, 0.3515536202739914, 0.41761905971110524, 0.3032891863193108, 0.3526464297259342, 0.17482538870191833, 0.1089920771050662, 0.3212440981235244, 0.3446039576929306, 0.3150403350803024, 0.19682264207377953, 0.22811846691488713, 0.14377776766171557, 0.10338919898019627, 0.09267659410535489, 0.25312972258697186, 0.1787941768981045, 0.17488685365308687, 0.19539397196069253, 0.1889962219148058, 0.18292682228564006, 0.17285647524571446, 0.18929720207292877, 0.18438917247426256, 0.18430896628986404, 0.0848861819838117, 0.0641329465883369, 0.09305789667303255, 0.07806169079221836, 0.08015765813005127, 0.09374862538134388, 0.07424144447088032, 0.07891411310650731, 0.09308332941118713]}, "mutation_prompt": null}
{"id": "2a2b7a3f-a0a3-4c11-9e19-5ee9ac71a2f5", "solution": "import numpy as np\n\nclass HybridGreyWolfDEOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "HybridGreyWolfDEOptimization", "description": "Introducing a novel hybridization of Grey Wolf Optimization with Differential Evolution for enhanced exploration and exploitation.", "configspace": "", "generation": 12, "fitness": 0.17892404043211702, "feedback": "The algorithm HybridGreyWolfDEOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.18.", "error": "", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.33103449821939324, 0.3040480949406318, 0.3461539359040635, 0.267793838862431, 0.2843969316116849, 0.2579788652640307, 0.3101385872159119, 0.2660038630830429, 0.2565912122677866, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03727747940920767, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06948116989397035, 0.08114407681055125, 0.10342990083102321, 0.08859400181634902, 0.0946155582231244, 0.09812887798405245, 0.08176519286147577, 0.09684455887673016, 0.09242528037982012, 0.06597573101815779, 0.10571133621874274, 0.06739552500802215, 0.0942054385300709, 0.09599353136195987, 0.08879216843695925, 0.10025631140984992, 0.08720666807292399, 0.08805875069231373, 0.9848018523315675, 0.8915316774981772, 0.9345264689549528, 0.7883110260487081, 0.8929883510228567, 0.7855541599393364, 0.8866503114863262, 0.9341388746780092, 0.9452182528822439, 0.14330396746291585, 0.16146368724502314, 0.14485079224495134, 0.17284344577065858, 0.16577723631939556, 0.15623283775750152, 0.1473982940114965, 0.13497839833414726, 0.15712073811617044, 0.2236846606974785, 0.24311857957954008, 0.2190569572986214, 0.17380823843846394, 0.19035851938659532, 0.19500388806733404, 0.18587275446522733, 0.17568447906810503, 0.20952542841534205, 0.15318493975060488, 0.16814716976188215, 0.11797696838796978, 0.11922586881092867, 0.08712242319663133, 0.12203081015270656, 0.12218525688950754, 0.1225678963627106, 0.10342573868844429, 0.15646523614027608, 0.16910911619199542, 0.16948557812108078, 0.1600653124257415, 0.21180495086248452, 0.19898118117418062, 0.21854811547650554, 0.2247493235454746, 0.20760635656803228, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021399270440071283, 0.05867242115284843, 0.07169694229015, 0.11720015909147119, 0.06298103292773771, 0.05197702363637002, 0.05006604696275374, 0.07281931232118932, 0.1135336882890633, 0.060079732367998795, 0.08920191197026617, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021518231367246732, 0.02638014093755303, 0.02828327903317318, 0.027482138015897717, 0.01740190476981185, 0.03872348720440966, 0.03366216337300232, 0.03477159293533949, 0.0183672558502187, 0.32098844448283803, 0.3144535596010207, 0.3020527511347463, 0.31442699311923406, 0.2767146871076611, 0.2767817147028242, 0.327857212653598, 0.30549845692593514, 0.3223802132140039, 0.08203107833550183, 0.07611606790580916, 0.05908507600733026, 0.08715322678776483, 0.10827536649180125, 0.09704270741381316, 0.08652960588484637, 0.09238939703854832, 0.08007703988549908, 0.15487947981659544, 0.2119714898259606, 0.17122107754848237, 0.13148031201107968, 0.1583467446675717, 0.1479320059738769, 0.18496351186448579, 0.15498723741066056, 0.20403333473465313, 0.22022068630660652, 0.22617170716539292, 0.20201253706684008, 0.24845596760645772, 0.25766169684727536, 0.26323374988734405, 0.20783004187583431, 0.22907748524617422, 0.21467966478440625, 0.14836528853078834, 0.1865140288800997, 0.15702995960377197, 0.219007908625384, 0.21911198530248777, 0.20083737306061844, 0.1534803065344308, 0.1670681993156763, 0.1604125298100838, 0.254903090163632, 0.2736687508861446, 0.24479217304664236, 0.28945157999979987, 0.2849774299913692, 0.2554423599657626, 0.24986782284130216, 0.23801971193128824, 0.2484408539088342, 0.17522236515332645, 0.1763697804468748, 0.17499662499676705, 0.1782165084240953, 0.17413122546255833, 0.17527486547514615, 0.1814231217620833, 0.1735518473349632, 0.17712344391275947, 0.18097343656188725, 0.17246273898918174, 0.18103555852842945, 0.3515536202739914, 0.41761905971110524, 0.3032891863193108, 0.3526464297259342, 0.17482538870191833, 0.1089920771050662, 0.3212440981235244, 0.3446039576929306, 0.3150403350803024, 0.19682264207377953, 0.22811846691488713, 0.14377776766171557, 0.10338919898019627, 0.09267659410535489, 0.25312972258697186, 0.1787941768981045, 0.17488685365308687, 0.19539397196069253, 0.1889962219148058, 0.18292682228564006, 0.17285647524571446, 0.18929720207292877, 0.18438917247426256, 0.18430896628986404, 0.0848861819838117, 0.0641329465883369, 0.09305789667303255, 0.07806169079221836, 0.08015765813005127, 0.09374862538134388, 0.07424144447088032, 0.07891411310650731, 0.09308332941118713]}, "mutation_prompt": null}
{"id": "cdac2e63-8ba5-4c11-919e-1ae6dd0bf379", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimization", "description": "Introducing a dynamic step size adaptation based on the fitness improvement of each wolf to enhance convergence speed.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.33103449821939324, 0.3040480949406318, 0.3461539359040635, 0.267793838862431, 0.2843969316116849, 0.2579788652640307, 0.3101385872159119, 0.2660038630830429, 0.2565912122677866, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03727747940920767, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06948116989397035, 0.08114407681055125, 0.10342990083102321, 0.08859400181634902, 0.0946155582231244, 0.09812887798405245, 0.08176519286147577, 0.09684455887673016, 0.09242528037982012, 0.06597573101815779, 0.10571133621874274, 0.06739552500802215, 0.0942054385300709, 0.09599353136195987, 0.08879216843695925, 0.10025631140984992, 0.08720666807292399, 0.08805875069231373, 0.9848018523315675, 0.8915316774981772, 0.9345264689549528, 0.7883110260487081, 0.8929883510228567, 0.7855541599393364, 0.8866503114863262, 0.9341388746780092, 0.9452182528822439, 0.14330396746291585, 0.16146368724502314, 0.14485079224495134, 0.17284344577065858, 0.16577723631939556, 0.15623283775750152, 0.1473982940114965, 0.13497839833414726, 0.15712073811617044, 0.2236846606974785, 0.24311857957954008, 0.2190569572986214, 0.17380823843846394, 0.19035851938659532, 0.19500388806733404, 0.18587275446522733, 0.17568447906810503, 0.20952542841534205, 0.15318493975060488, 0.16814716976188215, 0.11797696838796978, 0.11922586881092867, 0.08712242319663133, 0.12203081015270656, 0.12218525688950754, 0.1225678963627106, 0.10342573868844429, 0.15646523614027608, 0.16910911619199542, 0.16948557812108078, 0.1600653124257415, 0.21180495086248452, 0.19898118117418062, 0.21854811547650554, 0.2247493235454746, 0.20760635656803228, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021399270440071283, 0.05867242115284843, 0.07169694229015, 0.11720015909147119, 0.06298103292773771, 0.05197702363637002, 0.05006604696275374, 0.07281931232118932, 0.1135336882890633, 0.060079732367998795, 0.08920191197026617, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021518231367246732, 0.02638014093755303, 0.02828327903317318, 0.027482138015897717, 0.01740190476981185, 0.03872348720440966, 0.03366216337300232, 0.03477159293533949, 0.0183672558502187, 0.32098844448283803, 0.3144535596010207, 0.3020527511347463, 0.31442699311923406, 0.2767146871076611, 0.2767817147028242, 0.327857212653598, 0.30549845692593514, 0.3223802132140039, 0.08203107833550183, 0.07611606790580916, 0.05908507600733026, 0.08715322678776483, 0.10827536649180125, 0.09704270741381316, 0.08652960588484637, 0.09238939703854832, 0.08007703988549908, 0.15487947981659544, 0.2119714898259606, 0.17122107754848237, 0.13148031201107968, 0.1583467446675717, 0.1479320059738769, 0.18496351186448579, 0.15498723741066056, 0.20403333473465313, 0.22022068630660652, 0.22617170716539292, 0.20201253706684008, 0.24845596760645772, 0.25766169684727536, 0.26323374988734405, 0.20783004187583431, 0.22907748524617422, 0.21467966478440625, 0.14836528853078834, 0.1865140288800997, 0.15702995960377197, 0.219007908625384, 0.21911198530248777, 0.20083737306061844, 0.1534803065344308, 0.1670681993156763, 0.1604125298100838, 0.254903090163632, 0.2736687508861446, 0.24479217304664236, 0.28945157999979987, 0.2849774299913692, 0.2554423599657626, 0.24986782284130216, 0.23801971193128824, 0.2484408539088342, 0.17522236515332645, 0.1763697804468748, 0.17499662499676705, 0.1782165084240953, 0.17413122546255833, 0.17527486547514615, 0.1814231217620833, 0.1735518473349632, 0.17712344391275947, 0.18097343656188725, 0.17246273898918174, 0.18103555852842945, 0.3515536202739914, 0.41761905971110524, 0.3032891863193108, 0.3526464297259342, 0.17482538870191833, 0.1089920771050662, 0.3212440981235244, 0.3446039576929306, 0.3150403350803024, 0.19682264207377953, 0.22811846691488713, 0.14377776766171557, 0.10338919898019627, 0.09267659410535489, 0.25312972258697186, 0.1787941768981045, 0.17488685365308687, 0.19539397196069253, 0.1889962219148058, 0.18292682228564006, 0.17285647524571446, 0.18929720207292877, 0.18438917247426256, 0.18430896628986404, 0.0848861819838117, 0.0641329465883369, 0.09305789667303255, 0.07806169079221836, 0.08015765813005127, 0.09374862538134388, 0.07424144447088032, 0.07891411310650731, 0.09308332941118713]}, "mutation_prompt": null}
{"id": "2e625480-4192-4e43-ac20-bcd50794da3a", "solution": "import numpy as np\n\nclass ImprovedFastConvergingGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            chaotic_factor = np.sin(np.sum(wolf['position']))  # Introducing chaotic factor for better exploration\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha + chaotic_factor\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta + chaotic_factor\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta + chaotic_factor\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "ImprovedFastConvergingGreyWolfOptimization", "description": "Introducing a novel chaotic search strategy to enhance exploration and exploitation balance for faster convergence.", "configspace": "", "generation": 14, "fitness": 0.1632428104766395, "feedback": "The algorithm ImprovedFastConvergingGreyWolfOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16 with standard deviation 0.18.", "error": "", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.27030049836326786, 0.28073474545310695, 0.29551856471839866, 0.25273310866318854, 0.2546482281063236, 0.2409309633467993, 0.2592158090195138, 0.30208687994725425, 0.27938094456852625, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06400158424751679, 0.07707343826093749, 0.07514958608588529, 0.08401343529854932, 0.06951100705829594, 0.08422647076343925, 0.07493869509909568, 0.08845441608331606, 0.07879174906575792, 0.06425366791877551, 0.06454386149365288, 0.07863194897265913, 0.06806439666856168, 0.0650797999246252, 0.06165236706537636, 0.059459469563244216, 0.07592398382240995, 0.07161036100347007, 0.9801697511219778, 0.9607587518059265, 0.90844905683602, 0.8677239996018611, 0.9432420103686052, 0.8815024437100583, 0.9405665833326734, 0.9904344179474589, 0.964918511436197, 0.16925239787114865, 0.14656090541860867, 0.12939486731722483, 0.13870077821075555, 0.14146841173760327, 0.15450824272004338, 0.14756878732079404, 0.12243096670107712, 0.11506785556820964, 0.2094959720852213, 0.19318345158072814, 0.2100131418232556, 0.17639648342997627, 0.17852380203151386, 0.17744350914561113, 0.19062864753653863, 0.19709493906431197, 0.2191442520111555, 0.08357601444720186, 0.08938863952645693, 0.1024891888521382, 0.07836414620469678, 0.09551335874880273, 0.05447120179375087, 0.09592353553518151, 0.07566149285834634, 0.08173202059386786, 0.1223800647744574, 0.1141297896701099, 0.10145775882215602, 0.10285831659031608, 0.11467879346452281, 0.09794390764784822, 0.12482812812646349, 0.10690675317288223, 0.10930290490688821, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11773036666730874, 0.07139262994761919, 0.06871596602700192, 0.05913046927196575, 0.05673333265069236, 0.03755601736696901, 0.06325172973665316, 0.04577347378102803, 0.07369599594963328, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02267509492299291, 0.01609881488056708, 0.036848789741472654, 0.013247242766584733, 0.02441489471341063, 0.018881789521071224, 0.012771067748192921, 0.02149805637918689, 0.03630654105191222, 0.2702740719169414, 0.3109842712525499, 0.2937807400473418, 0.2580528015686281, 0.2654687816368859, 0.25592520710231614, 0.33015062144651974, 0.29222327784984103, 0.2704739470193024, 0.07389634551884705, 0.07687942068867193, 0.06076569090751727, 0.07525369150062688, 0.08028040828890004, 0.07149402550663475, 0.06899025236734635, 0.07618061021714095, 0.07563397606795152, 0.16162439324531586, 0.17549745232660097, 0.1579627354414539, 0.1255695249669363, 0.12838783825633804, 0.12751695917692107, 0.15402067756380022, 0.16461980396240505, 0.14558780368820767, 0.21204310405545235, 0.21242687910994318, 0.21184455621623088, 0.2187333141278327, 0.1985508156620016, 0.2232821898280939, 0.20622444212255542, 0.1957832315967194, 0.22090263864005344, 0.16806422596599402, 0.14627748058488832, 0.16008085231607438, 0.16759811326717322, 0.1873273826490558, 0.16046133296593756, 0.155963998854022, 0.1447261614042663, 0.1451175008844492, 0.1975515169111689, 0.2129777757563649, 0.18539067610164994, 0.20216098255374904, 0.21942738967424047, 0.19916845090483037, 0.19723114431844957, 0.24643222593690983, 0.23105507064441233, 0.16785510725257713, 0.17854719548561293, 0.17314146302953815, 0.1791480432185274, 0.1765757750548006, 0.17464603393106048, 0.17811146643406262, 0.16691475851742998, 0.17468110607300802, 0.14100002998236105, 0.2752736954191398, 0.17010375501485142, 0.2864011287099282, 0.32830197095645985, 0.22267384780306632, 0.172040233304238, 0.31204657877603026, 0.16450354572186876, 0.2966024466656684, 0.16976870651589304, 0.1918190883674934, 0.18692905057109532, 0.18934120837091617, 0.18756441663323864, 0.13886135364410634, 0.22487133838182827, 0.15351339776695583, 0.18204798434977554, 0.17415080835315822, 0.18396045147481122, 0.19414811072883453, 0.19836708961338478, 0.1867852729615569, 0.18031392428318016, 0.18411481231901927, 0.19344348546947598, 0.06745435500023833, 0.08763360856541436, 0.07970502560892545, 0.07486252693786433, 0.07606276239097765, 0.06915752035637523, 0.0678038009159907, 0.07562488383828492, 0.08267390842378575]}, "mutation_prompt": null}
{"id": "f2bb61dd-fe15-4c5c-856c-bddc80bd264d", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimization", "description": "Introducing a dynamic step size adaptation based on the fitness improvement of each wolf to enhance convergence speed.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.33103449821939324, 0.3040480949406318, 0.3461539359040635, 0.267793838862431, 0.2843969316116849, 0.2579788652640307, 0.3101385872159119, 0.2660038630830429, 0.2565912122677866, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03727747940920767, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06948116989397035, 0.08114407681055125, 0.10342990083102321, 0.08859400181634902, 0.0946155582231244, 0.09812887798405245, 0.08176519286147577, 0.09684455887673016, 0.09242528037982012, 0.06597573101815779, 0.10571133621874274, 0.06739552500802215, 0.0942054385300709, 0.09599353136195987, 0.08879216843695925, 0.10025631140984992, 0.08720666807292399, 0.08805875069231373, 0.9848018523315675, 0.8915316774981772, 0.9345264689549528, 0.7883110260487081, 0.8929883510228567, 0.7855541599393364, 0.8866503114863262, 0.9341388746780092, 0.9452182528822439, 0.14330396746291585, 0.16146368724502314, 0.14485079224495134, 0.17284344577065858, 0.16577723631939556, 0.15623283775750152, 0.1473982940114965, 0.13497839833414726, 0.15712073811617044, 0.2236846606974785, 0.24311857957954008, 0.2190569572986214, 0.17380823843846394, 0.19035851938659532, 0.19500388806733404, 0.18587275446522733, 0.17568447906810503, 0.20952542841534205, 0.15318493975060488, 0.16814716976188215, 0.11797696838796978, 0.11922586881092867, 0.08712242319663133, 0.12203081015270656, 0.12218525688950754, 0.1225678963627106, 0.10342573868844429, 0.15646523614027608, 0.16910911619199542, 0.16948557812108078, 0.1600653124257415, 0.21180495086248452, 0.19898118117418062, 0.21854811547650554, 0.2247493235454746, 0.20760635656803228, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021399270440071283, 0.05867242115284843, 0.07169694229015, 0.11720015909147119, 0.06298103292773771, 0.05197702363637002, 0.05006604696275374, 0.07281931232118932, 0.1135336882890633, 0.060079732367998795, 0.08920191197026617, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021518231367246732, 0.02638014093755303, 0.02828327903317318, 0.027482138015897717, 0.01740190476981185, 0.03872348720440966, 0.03366216337300232, 0.03477159293533949, 0.0183672558502187, 0.32098844448283803, 0.3144535596010207, 0.3020527511347463, 0.31442699311923406, 0.2767146871076611, 0.2767817147028242, 0.327857212653598, 0.30549845692593514, 0.3223802132140039, 0.08203107833550183, 0.07611606790580916, 0.05908507600733026, 0.08715322678776483, 0.10827536649180125, 0.09704270741381316, 0.08652960588484637, 0.09238939703854832, 0.08007703988549908, 0.15487947981659544, 0.2119714898259606, 0.17122107754848237, 0.13148031201107968, 0.1583467446675717, 0.1479320059738769, 0.18496351186448579, 0.15498723741066056, 0.20403333473465313, 0.22022068630660652, 0.22617170716539292, 0.20201253706684008, 0.24845596760645772, 0.25766169684727536, 0.26323374988734405, 0.20783004187583431, 0.22907748524617422, 0.21467966478440625, 0.14836528853078834, 0.1865140288800997, 0.15702995960377197, 0.219007908625384, 0.21911198530248777, 0.20083737306061844, 0.1534803065344308, 0.1670681993156763, 0.1604125298100838, 0.254903090163632, 0.2736687508861446, 0.24479217304664236, 0.28945157999979987, 0.2849774299913692, 0.2554423599657626, 0.24986782284130216, 0.23801971193128824, 0.2484408539088342, 0.17522236515332645, 0.1763697804468748, 0.17499662499676705, 0.1782165084240953, 0.17413122546255833, 0.17527486547514615, 0.1814231217620833, 0.1735518473349632, 0.17712344391275947, 0.18097343656188725, 0.17246273898918174, 0.18103555852842945, 0.3515536202739914, 0.41761905971110524, 0.3032891863193108, 0.3526464297259342, 0.17482538870191833, 0.1089920771050662, 0.3212440981235244, 0.3446039576929306, 0.3150403350803024, 0.19682264207377953, 0.22811846691488713, 0.14377776766171557, 0.10338919898019627, 0.09267659410535489, 0.25312972258697186, 0.1787941768981045, 0.17488685365308687, 0.19539397196069253, 0.1889962219148058, 0.18292682228564006, 0.17285647524571446, 0.18929720207292877, 0.18438917247426256, 0.18430896628986404, 0.0848861819838117, 0.0641329465883369, 0.09305789667303255, 0.07806169079221836, 0.08015765813005127, 0.09374862538134388, 0.07424144447088032, 0.07891411310650731, 0.09308332941118713]}, "mutation_prompt": null}
{"id": "58620416-a8de-436d-a082-efefe3dc3d41", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimizationImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (0.7 * X1 + 0.2 * X2 + 0.1 * X3)  # Weighted average based on fitness improvements\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimizationImproved", "description": "Introducing a mutation strategy that utilizes a weighted average based on fitness improvements to expedite convergence speed.", "configspace": "", "generation": 16, "fitness": 0.17541655011587962, "feedback": "The algorithm FastConvergingGreyWolfOptimizationImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.19.", "error": "", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.3066484724784163, 0.3043534394254871, 0.29421351811829677, 0.25600901680869803, 0.25570333524389477, 0.24577968201650613, 0.2993331185722109, 0.276442223319443, 0.2933057200652919, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01624642362516482, 0.008410110842974605, 0.03510689948210999, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10165664720387846, 0.07427436446889313, 0.08283299685962409, 0.08279267775468613, 0.08274818603031109, 0.07832613074455363, 0.08505499621567492, 0.09242035282995387, 0.08817293859714992, 0.06943804570625378, 0.0824624350151727, 0.08730497872995524, 0.0893534305278888, 0.07496566048641728, 0.07209125566658625, 0.07104663829227942, 0.06616360661958554, 0.08106509566703812, 0.9688050629669659, 0.9856702752796351, 0.9551765395401772, 0.942712579720993, 0.9612798803475213, 0.9692382412436832, 0.9689430718346528, 0.9469824253620093, 0.9511550799068974, 0.1467158172178431, 0.12133263849427545, 0.12036917818408333, 0.1517511133994658, 0.14702766184543614, 0.1718069739223601, 0.15896682461729927, 0.16016791308110678, 0.14673536199274773, 0.22874196982457284, 0.2177697100633862, 0.19559922355662784, 0.19352065206931102, 0.1995497557154865, 0.2445704731397894, 0.2029170387192606, 0.1952712631837188, 0.17577139183075652, 0.12893374762075438, 0.1687057654673204, 0.12641578791708108, 0.08441633787993486, 0.112616653052235, 0.11475137513955502, 0.10049388803624348, 0.08992619423989123, 0.14120401677968908, 0.19717750275253, 0.177774647844269, 0.19049085946781363, 0.19031950690001198, 0.19140244320932143, 0.19949029173090826, 0.21937494756872056, 0.24088844273814725, 0.20092761107490664, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.028026308718337, 9.999999999998899e-05, 9.999999999998899e-05, 0.04839612300535867, 0.06998116149133748, 0.05088233696765476, 0.06433250252632916, 0.07178660367257383, 0.040833541447118815, 0.0780313088113388, 0.08864321911601802, 0.049897810522105845, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.028011252471165204, 0.027802535707556864, 0.014424257157884868, 0.024066836443081052, 0.03147444998933102, 0.03312736085772394, 0.041488436515695115, 0.02159926228795661, 0.026559782084730088, 0.3126443405108775, 0.2977551691423552, 0.28612992434042595, 0.2857456528427379, 0.2865060896739885, 0.26268001814482345, 0.30981274756496746, 0.3321980654863943, 0.29870217421375866, 0.07519697633436428, 0.06932687666406623, 0.08622740920111738, 0.08101797516460973, 0.08217154744436228, 0.1245953655016756, 0.07955148664564804, 0.10444446332645563, 0.09823406135098689, 0.19583200577075321, 0.16162611705913454, 0.14173376276513772, 0.14114753754184017, 0.12958593839584176, 0.1734220509095723, 0.1638327562691877, 0.18909105444203766, 0.16660983903946835, 0.20698318973555907, 0.20648702570167365, 0.20753606080906017, 0.24287218020645918, 0.26778855117199163, 0.2399070811599019, 0.20806270101365465, 0.20912098981921312, 0.21892435890164463, 0.1533907058874171, 0.14878946460387832, 0.18284122130084357, 0.18495303501456872, 0.19466783313857972, 0.18536466418723785, 0.15714048657124602, 0.15523603048921486, 0.15163922619062864, 0.23874831552764353, 0.2525113036670248, 0.2253490804984537, 0.19395116810897894, 0.22238442436741945, 0.2089756199927223, 0.2280314681197868, 0.22224839581784794, 0.2069496888896275, 0.18831977863838145, 0.17956342149485516, 0.1725970453161242, 0.16557360237173013, 0.17278271372934628, 0.16721957331995652, 0.17170693563919304, 0.16866462252759862, 0.16973424247744973, 0.18083375083382403, 0.18097288558783242, 0.177266336731415, 0.18918369004995994, 0.27865442755111114, 0.2813648827451447, 0.18064737749538873, 0.4123460259015598, 0.1278764551006314, 0.18305461657443234, 0.3310771766363988, 0.19299912797605911, 0.23785758623571518, 0.28591937050580074, 0.18132630841992237, 0.10380181482338868, 0.23367180417174727, 0.17241822425634346, 0.17494166093029107, 0.18774223284079683, 0.18396988430942118, 0.19522524190898305, 0.17911520241117374, 0.18032126413337735, 0.17496913453944984, 0.188978084457743, 0.183137933713153, 0.07979389819620186, 0.07016161605863669, 0.06710070848939542, 0.09478066636820004, 0.07546831184140046, 0.07555210381430733, 0.0716897044710273, 0.07539072453219464, 0.0882813545769805]}, "mutation_prompt": null}
{"id": "842a3fcd-7bc8-4e58-b530-10044833e631", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimization", "description": "Introducing a dynamic step size adaptation based on the fitness improvement of each wolf to enhance convergence speed.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.33103449821939324, 0.3040480949406318, 0.3461539359040635, 0.267793838862431, 0.2843969316116849, 0.2579788652640307, 0.3101385872159119, 0.2660038630830429, 0.2565912122677866, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03727747940920767, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06948116989397035, 0.08114407681055125, 0.10342990083102321, 0.08859400181634902, 0.0946155582231244, 0.09812887798405245, 0.08176519286147577, 0.09684455887673016, 0.09242528037982012, 0.06597573101815779, 0.10571133621874274, 0.06739552500802215, 0.0942054385300709, 0.09599353136195987, 0.08879216843695925, 0.10025631140984992, 0.08720666807292399, 0.08805875069231373, 0.9848018523315675, 0.8915316774981772, 0.9345264689549528, 0.7883110260487081, 0.8929883510228567, 0.7855541599393364, 0.8866503114863262, 0.9341388746780092, 0.9452182528822439, 0.14330396746291585, 0.16146368724502314, 0.14485079224495134, 0.17284344577065858, 0.16577723631939556, 0.15623283775750152, 0.1473982940114965, 0.13497839833414726, 0.15712073811617044, 0.2236846606974785, 0.24311857957954008, 0.2190569572986214, 0.17380823843846394, 0.19035851938659532, 0.19500388806733404, 0.18587275446522733, 0.17568447906810503, 0.20952542841534205, 0.15318493975060488, 0.16814716976188215, 0.11797696838796978, 0.11922586881092867, 0.08712242319663133, 0.12203081015270656, 0.12218525688950754, 0.1225678963627106, 0.10342573868844429, 0.15646523614027608, 0.16910911619199542, 0.16948557812108078, 0.1600653124257415, 0.21180495086248452, 0.19898118117418062, 0.21854811547650554, 0.2247493235454746, 0.20760635656803228, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021399270440071283, 0.05867242115284843, 0.07169694229015, 0.11720015909147119, 0.06298103292773771, 0.05197702363637002, 0.05006604696275374, 0.07281931232118932, 0.1135336882890633, 0.060079732367998795, 0.08920191197026617, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021518231367246732, 0.02638014093755303, 0.02828327903317318, 0.027482138015897717, 0.01740190476981185, 0.03872348720440966, 0.03366216337300232, 0.03477159293533949, 0.0183672558502187, 0.32098844448283803, 0.3144535596010207, 0.3020527511347463, 0.31442699311923406, 0.2767146871076611, 0.2767817147028242, 0.327857212653598, 0.30549845692593514, 0.3223802132140039, 0.08203107833550183, 0.07611606790580916, 0.05908507600733026, 0.08715322678776483, 0.10827536649180125, 0.09704270741381316, 0.08652960588484637, 0.09238939703854832, 0.08007703988549908, 0.15487947981659544, 0.2119714898259606, 0.17122107754848237, 0.13148031201107968, 0.1583467446675717, 0.1479320059738769, 0.18496351186448579, 0.15498723741066056, 0.20403333473465313, 0.22022068630660652, 0.22617170716539292, 0.20201253706684008, 0.24845596760645772, 0.25766169684727536, 0.26323374988734405, 0.20783004187583431, 0.22907748524617422, 0.21467966478440625, 0.14836528853078834, 0.1865140288800997, 0.15702995960377197, 0.219007908625384, 0.21911198530248777, 0.20083737306061844, 0.1534803065344308, 0.1670681993156763, 0.1604125298100838, 0.254903090163632, 0.2736687508861446, 0.24479217304664236, 0.28945157999979987, 0.2849774299913692, 0.2554423599657626, 0.24986782284130216, 0.23801971193128824, 0.2484408539088342, 0.17522236515332645, 0.1763697804468748, 0.17499662499676705, 0.1782165084240953, 0.17413122546255833, 0.17527486547514615, 0.1814231217620833, 0.1735518473349632, 0.17712344391275947, 0.18097343656188725, 0.17246273898918174, 0.18103555852842945, 0.3515536202739914, 0.41761905971110524, 0.3032891863193108, 0.3526464297259342, 0.17482538870191833, 0.1089920771050662, 0.3212440981235244, 0.3446039576929306, 0.3150403350803024, 0.19682264207377953, 0.22811846691488713, 0.14377776766171557, 0.10338919898019627, 0.09267659410535489, 0.25312972258697186, 0.1787941768981045, 0.17488685365308687, 0.19539397196069253, 0.1889962219148058, 0.18292682228564006, 0.17285647524571446, 0.18929720207292877, 0.18438917247426256, 0.18430896628986404, 0.0848861819838117, 0.0641329465883369, 0.09305789667303255, 0.07806169079221836, 0.08015765813005127, 0.09374862538134388, 0.07424144447088032, 0.07891411310650731, 0.09308332941118713]}, "mutation_prompt": null}
{"id": "7ff3f25e-1446-416d-9e9d-4d011f3f349d", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimization", "description": "Introducing a dynamic step size adaptation based on the fitness improvement of each wolf to enhance convergence speed.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.33103449821939324, 0.3040480949406318, 0.3461539359040635, 0.267793838862431, 0.2843969316116849, 0.2579788652640307, 0.3101385872159119, 0.2660038630830429, 0.2565912122677866, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03727747940920767, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06948116989397035, 0.08114407681055125, 0.10342990083102321, 0.08859400181634902, 0.0946155582231244, 0.09812887798405245, 0.08176519286147577, 0.09684455887673016, 0.09242528037982012, 0.06597573101815779, 0.10571133621874274, 0.06739552500802215, 0.0942054385300709, 0.09599353136195987, 0.08879216843695925, 0.10025631140984992, 0.08720666807292399, 0.08805875069231373, 0.9848018523315675, 0.8915316774981772, 0.9345264689549528, 0.7883110260487081, 0.8929883510228567, 0.7855541599393364, 0.8866503114863262, 0.9341388746780092, 0.9452182528822439, 0.14330396746291585, 0.16146368724502314, 0.14485079224495134, 0.17284344577065858, 0.16577723631939556, 0.15623283775750152, 0.1473982940114965, 0.13497839833414726, 0.15712073811617044, 0.2236846606974785, 0.24311857957954008, 0.2190569572986214, 0.17380823843846394, 0.19035851938659532, 0.19500388806733404, 0.18587275446522733, 0.17568447906810503, 0.20952542841534205, 0.15318493975060488, 0.16814716976188215, 0.11797696838796978, 0.11922586881092867, 0.08712242319663133, 0.12203081015270656, 0.12218525688950754, 0.1225678963627106, 0.10342573868844429, 0.15646523614027608, 0.16910911619199542, 0.16948557812108078, 0.1600653124257415, 0.21180495086248452, 0.19898118117418062, 0.21854811547650554, 0.2247493235454746, 0.20760635656803228, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021399270440071283, 0.05867242115284843, 0.07169694229015, 0.11720015909147119, 0.06298103292773771, 0.05197702363637002, 0.05006604696275374, 0.07281931232118932, 0.1135336882890633, 0.060079732367998795, 0.08920191197026617, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021518231367246732, 0.02638014093755303, 0.02828327903317318, 0.027482138015897717, 0.01740190476981185, 0.03872348720440966, 0.03366216337300232, 0.03477159293533949, 0.0183672558502187, 0.32098844448283803, 0.3144535596010207, 0.3020527511347463, 0.31442699311923406, 0.2767146871076611, 0.2767817147028242, 0.327857212653598, 0.30549845692593514, 0.3223802132140039, 0.08203107833550183, 0.07611606790580916, 0.05908507600733026, 0.08715322678776483, 0.10827536649180125, 0.09704270741381316, 0.08652960588484637, 0.09238939703854832, 0.08007703988549908, 0.15487947981659544, 0.2119714898259606, 0.17122107754848237, 0.13148031201107968, 0.1583467446675717, 0.1479320059738769, 0.18496351186448579, 0.15498723741066056, 0.20403333473465313, 0.22022068630660652, 0.22617170716539292, 0.20201253706684008, 0.24845596760645772, 0.25766169684727536, 0.26323374988734405, 0.20783004187583431, 0.22907748524617422, 0.21467966478440625, 0.14836528853078834, 0.1865140288800997, 0.15702995960377197, 0.219007908625384, 0.21911198530248777, 0.20083737306061844, 0.1534803065344308, 0.1670681993156763, 0.1604125298100838, 0.254903090163632, 0.2736687508861446, 0.24479217304664236, 0.28945157999979987, 0.2849774299913692, 0.2554423599657626, 0.24986782284130216, 0.23801971193128824, 0.2484408539088342, 0.17522236515332645, 0.1763697804468748, 0.17499662499676705, 0.1782165084240953, 0.17413122546255833, 0.17527486547514615, 0.1814231217620833, 0.1735518473349632, 0.17712344391275947, 0.18097343656188725, 0.17246273898918174, 0.18103555852842945, 0.3515536202739914, 0.41761905971110524, 0.3032891863193108, 0.3526464297259342, 0.17482538870191833, 0.1089920771050662, 0.3212440981235244, 0.3446039576929306, 0.3150403350803024, 0.19682264207377953, 0.22811846691488713, 0.14377776766171557, 0.10338919898019627, 0.09267659410535489, 0.25312972258697186, 0.1787941768981045, 0.17488685365308687, 0.19539397196069253, 0.1889962219148058, 0.18292682228564006, 0.17285647524571446, 0.18929720207292877, 0.18438917247426256, 0.18430896628986404, 0.0848861819838117, 0.0641329465883369, 0.09305789667303255, 0.07806169079221836, 0.08015765813005127, 0.09374862538134388, 0.07424144447088032, 0.07891411310650731, 0.09308332941118713]}, "mutation_prompt": null}
{"id": "697d56d3-80e8-4461-8ace-fb0e3af1d3d4", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimization", "description": "Introducing a dynamic step size adaptation based on the fitness improvement of each wolf to enhance convergence speed.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.33103449821939324, 0.3040480949406318, 0.3461539359040635, 0.267793838862431, 0.2843969316116849, 0.2579788652640307, 0.3101385872159119, 0.2660038630830429, 0.2565912122677866, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03727747940920767, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06948116989397035, 0.08114407681055125, 0.10342990083102321, 0.08859400181634902, 0.0946155582231244, 0.09812887798405245, 0.08176519286147577, 0.09684455887673016, 0.09242528037982012, 0.06597573101815779, 0.10571133621874274, 0.06739552500802215, 0.0942054385300709, 0.09599353136195987, 0.08879216843695925, 0.10025631140984992, 0.08720666807292399, 0.08805875069231373, 0.9848018523315675, 0.8915316774981772, 0.9345264689549528, 0.7883110260487081, 0.8929883510228567, 0.7855541599393364, 0.8866503114863262, 0.9341388746780092, 0.9452182528822439, 0.14330396746291585, 0.16146368724502314, 0.14485079224495134, 0.17284344577065858, 0.16577723631939556, 0.15623283775750152, 0.1473982940114965, 0.13497839833414726, 0.15712073811617044, 0.2236846606974785, 0.24311857957954008, 0.2190569572986214, 0.17380823843846394, 0.19035851938659532, 0.19500388806733404, 0.18587275446522733, 0.17568447906810503, 0.20952542841534205, 0.15318493975060488, 0.16814716976188215, 0.11797696838796978, 0.11922586881092867, 0.08712242319663133, 0.12203081015270656, 0.12218525688950754, 0.1225678963627106, 0.10342573868844429, 0.15646523614027608, 0.16910911619199542, 0.16948557812108078, 0.1600653124257415, 0.21180495086248452, 0.19898118117418062, 0.21854811547650554, 0.2247493235454746, 0.20760635656803228, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021399270440071283, 0.05867242115284843, 0.07169694229015, 0.11720015909147119, 0.06298103292773771, 0.05197702363637002, 0.05006604696275374, 0.07281931232118932, 0.1135336882890633, 0.060079732367998795, 0.08920191197026617, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021518231367246732, 0.02638014093755303, 0.02828327903317318, 0.027482138015897717, 0.01740190476981185, 0.03872348720440966, 0.03366216337300232, 0.03477159293533949, 0.0183672558502187, 0.32098844448283803, 0.3144535596010207, 0.3020527511347463, 0.31442699311923406, 0.2767146871076611, 0.2767817147028242, 0.327857212653598, 0.30549845692593514, 0.3223802132140039, 0.08203107833550183, 0.07611606790580916, 0.05908507600733026, 0.08715322678776483, 0.10827536649180125, 0.09704270741381316, 0.08652960588484637, 0.09238939703854832, 0.08007703988549908, 0.15487947981659544, 0.2119714898259606, 0.17122107754848237, 0.13148031201107968, 0.1583467446675717, 0.1479320059738769, 0.18496351186448579, 0.15498723741066056, 0.20403333473465313, 0.22022068630660652, 0.22617170716539292, 0.20201253706684008, 0.24845596760645772, 0.25766169684727536, 0.26323374988734405, 0.20783004187583431, 0.22907748524617422, 0.21467966478440625, 0.14836528853078834, 0.1865140288800997, 0.15702995960377197, 0.219007908625384, 0.21911198530248777, 0.20083737306061844, 0.1534803065344308, 0.1670681993156763, 0.1604125298100838, 0.254903090163632, 0.2736687508861446, 0.24479217304664236, 0.28945157999979987, 0.2849774299913692, 0.2554423599657626, 0.24986782284130216, 0.23801971193128824, 0.2484408539088342, 0.17522236515332645, 0.1763697804468748, 0.17499662499676705, 0.1782165084240953, 0.17413122546255833, 0.17527486547514615, 0.1814231217620833, 0.1735518473349632, 0.17712344391275947, 0.18097343656188725, 0.17246273898918174, 0.18103555852842945, 0.3515536202739914, 0.41761905971110524, 0.3032891863193108, 0.3526464297259342, 0.17482538870191833, 0.1089920771050662, 0.3212440981235244, 0.3446039576929306, 0.3150403350803024, 0.19682264207377953, 0.22811846691488713, 0.14377776766171557, 0.10338919898019627, 0.09267659410535489, 0.25312972258697186, 0.1787941768981045, 0.17488685365308687, 0.19539397196069253, 0.1889962219148058, 0.18292682228564006, 0.17285647524571446, 0.18929720207292877, 0.18438917247426256, 0.18430896628986404, 0.0848861819838117, 0.0641329465883369, 0.09305789667303255, 0.07806169079221836, 0.08015765813005127, 0.09374862538134388, 0.07424144447088032, 0.07891411310650731, 0.09308332941118713]}, "mutation_prompt": null}
{"id": "65fd3ecb-d85f-42b7-b250-03d9a287e258", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimization", "description": "Introducing a dynamic step size adaptation based on the fitness improvement of each wolf to enhance convergence speed.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.33103449821939324, 0.3040480949406318, 0.3461539359040635, 0.267793838862431, 0.2843969316116849, 0.2579788652640307, 0.3101385872159119, 0.2660038630830429, 0.2565912122677866, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03727747940920767, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06948116989397035, 0.08114407681055125, 0.10342990083102321, 0.08859400181634902, 0.0946155582231244, 0.09812887798405245, 0.08176519286147577, 0.09684455887673016, 0.09242528037982012, 0.06597573101815779, 0.10571133621874274, 0.06739552500802215, 0.0942054385300709, 0.09599353136195987, 0.08879216843695925, 0.10025631140984992, 0.08720666807292399, 0.08805875069231373, 0.9848018523315675, 0.8915316774981772, 0.9345264689549528, 0.7883110260487081, 0.8929883510228567, 0.7855541599393364, 0.8866503114863262, 0.9341388746780092, 0.9452182528822439, 0.14330396746291585, 0.16146368724502314, 0.14485079224495134, 0.17284344577065858, 0.16577723631939556, 0.15623283775750152, 0.1473982940114965, 0.13497839833414726, 0.15712073811617044, 0.2236846606974785, 0.24311857957954008, 0.2190569572986214, 0.17380823843846394, 0.19035851938659532, 0.19500388806733404, 0.18587275446522733, 0.17568447906810503, 0.20952542841534205, 0.15318493975060488, 0.16814716976188215, 0.11797696838796978, 0.11922586881092867, 0.08712242319663133, 0.12203081015270656, 0.12218525688950754, 0.1225678963627106, 0.10342573868844429, 0.15646523614027608, 0.16910911619199542, 0.16948557812108078, 0.1600653124257415, 0.21180495086248452, 0.19898118117418062, 0.21854811547650554, 0.2247493235454746, 0.20760635656803228, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021399270440071283, 0.05867242115284843, 0.07169694229015, 0.11720015909147119, 0.06298103292773771, 0.05197702363637002, 0.05006604696275374, 0.07281931232118932, 0.1135336882890633, 0.060079732367998795, 0.08920191197026617, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021518231367246732, 0.02638014093755303, 0.02828327903317318, 0.027482138015897717, 0.01740190476981185, 0.03872348720440966, 0.03366216337300232, 0.03477159293533949, 0.0183672558502187, 0.32098844448283803, 0.3144535596010207, 0.3020527511347463, 0.31442699311923406, 0.2767146871076611, 0.2767817147028242, 0.327857212653598, 0.30549845692593514, 0.3223802132140039, 0.08203107833550183, 0.07611606790580916, 0.05908507600733026, 0.08715322678776483, 0.10827536649180125, 0.09704270741381316, 0.08652960588484637, 0.09238939703854832, 0.08007703988549908, 0.15487947981659544, 0.2119714898259606, 0.17122107754848237, 0.13148031201107968, 0.1583467446675717, 0.1479320059738769, 0.18496351186448579, 0.15498723741066056, 0.20403333473465313, 0.22022068630660652, 0.22617170716539292, 0.20201253706684008, 0.24845596760645772, 0.25766169684727536, 0.26323374988734405, 0.20783004187583431, 0.22907748524617422, 0.21467966478440625, 0.14836528853078834, 0.1865140288800997, 0.15702995960377197, 0.219007908625384, 0.21911198530248777, 0.20083737306061844, 0.1534803065344308, 0.1670681993156763, 0.1604125298100838, 0.254903090163632, 0.2736687508861446, 0.24479217304664236, 0.28945157999979987, 0.2849774299913692, 0.2554423599657626, 0.24986782284130216, 0.23801971193128824, 0.2484408539088342, 0.17522236515332645, 0.1763697804468748, 0.17499662499676705, 0.1782165084240953, 0.17413122546255833, 0.17527486547514615, 0.1814231217620833, 0.1735518473349632, 0.17712344391275947, 0.18097343656188725, 0.17246273898918174, 0.18103555852842945, 0.3515536202739914, 0.41761905971110524, 0.3032891863193108, 0.3526464297259342, 0.17482538870191833, 0.1089920771050662, 0.3212440981235244, 0.3446039576929306, 0.3150403350803024, 0.19682264207377953, 0.22811846691488713, 0.14377776766171557, 0.10338919898019627, 0.09267659410535489, 0.25312972258697186, 0.1787941768981045, 0.17488685365308687, 0.19539397196069253, 0.1889962219148058, 0.18292682228564006, 0.17285647524571446, 0.18929720207292877, 0.18438917247426256, 0.18430896628986404, 0.0848861819838117, 0.0641329465883369, 0.09305789667303255, 0.07806169079221836, 0.08015765813005127, 0.09374862538134388, 0.07424144447088032, 0.07891411310650731, 0.09308332941118713]}, "mutation_prompt": null}
{"id": "2d570fdf-c681-412e-a563-64ebd723ae4e", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                chaotic_init = np.random.uniform(-5.0, 5.0, self.dim) + np.random.uniform(-0.1, 0.1, self.dim)  # Chaotic initialization\n                wolves.append({'position': np.clip(chaotic_init, -5.0, 5.0),\n                               'fitness': func(chaotic_init)})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimization", "description": "Implementing a chaotic initialization scheme to enhance exploration and exploit the search space effectively.", "configspace": "", "generation": 21, "fitness": 0.17614113321365787, "feedback": "The algorithm FastConvergingGreyWolfOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.18.", "error": "", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.32173048617575706, 0.3088033532860476, 0.31995850258238756, 0.2658376715168713, 0.27201868954659336, 0.2532493967587559, 0.28084514944174377, 0.2538875191973715, 0.3122581007791543, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02743943441470731, 9.999999999998899e-05, 0.015249372587847199, 9.999999999998899e-05, 0.004248925144119675, 9.999999999998899e-05, 0.08964454543745592, 0.08743951480331691, 0.07804748227415581, 0.09260369629241849, 0.09423094393871512, 0.0990911725804361, 0.0918175999963674, 0.09057136835448876, 0.11931681359682644, 0.08496658700406456, 0.07083710277645694, 0.06088661104179138, 0.08441988110384269, 0.09061469917227005, 0.09316158964317123, 0.08741211624732714, 0.08164751650517132, 0.0768960185181915, 0.9830021956129724, 0.9113456171451834, 0.9318327755551387, 0.8367894807165467, 0.8899187417473035, 0.7452076749424423, 0.9273597664478277, 0.9366520981594926, 0.9452084042239646, 0.16935700688273703, 0.14133354549973887, 0.14153441844797598, 0.16827661681391004, 0.1797802965504003, 0.17693863779663366, 0.1603546306221919, 0.16632939965459848, 0.13111653130458523, 0.25777637227022643, 0.14031174371489474, 0.17318499673339616, 0.20541257714943406, 0.21090530252775874, 0.2002689821020407, 0.2216190736387874, 0.21658047638768663, 0.22671420300696332, 0.13465620714154447, 0.13979347078249305, 0.15603217341557718, 0.11515431186527747, 0.08881551157248391, 0.1215496219788954, 0.12774820049175417, 0.12457279160744417, 0.10344248211861273, 0.1748431555517902, 0.18894556235701587, 0.16961954810254465, 0.1733352507118432, 0.16309635274258705, 0.19257107776213067, 0.22968342337794756, 0.20110109826590195, 0.19582498356466183, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04749886254129887, 0.035530215695953715, 0.039016169845313975, 0.08773533548871981, 0.11645670238645212, 0.04857842740645679, 0.06548169883003652, 0.04624630874531466, 0.0703926796958152, 0.09796294495385738, 0.08725606313028744, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02166953088685064, 0.03989610525528475, 0.02944287981014826, 0.016626510947566953, 0.031007821961480664, 0.02137530587891956, 0.02711982464679108, 0.02245209123319236, 0.03966210569893014, 0.3028857627788515, 0.3127959923081306, 0.28296874716163933, 0.26699696824969943, 0.30231819413328087, 0.26614794101520045, 0.33439610781950213, 0.3119365142176822, 0.3192225328240663, 0.0875373180768032, 0.06764072150650313, 0.0779977005495488, 0.0952574288853415, 0.08545266462853196, 0.10350563785874567, 0.09292387837470473, 0.10118305978179432, 0.08972508475530105, 0.18596924585812225, 0.1740506041260632, 0.18289386509387406, 0.1436095332897347, 0.14080734576662202, 0.17147964794759085, 0.16146337901934604, 0.16257605785877383, 0.14981909484716693, 0.24923106513216287, 0.2062198509257145, 0.21668411443636038, 0.2557076911104237, 0.27406371690636055, 0.26404511693846167, 0.2223173265624684, 0.22584565098255227, 0.21623627149868485, 0.15153116446464243, 0.16699756407172683, 0.16258612033629039, 0.1958484975987551, 0.20961807238068764, 0.20547783764074534, 0.14777792897630937, 0.161183517950102, 0.15564357151723474, 0.25286103001774296, 0.24522358990354443, 0.2670668036752104, 0.25011085865517857, 0.22208930875829802, 0.28073973448145784, 0.28133383582382154, 0.2772998154393834, 0.248122290644342, 0.17084313828604192, 0.1743415881866882, 0.1760104240888779, 0.17423981551665801, 0.17645975409896764, 0.17058762119662207, 0.18389090968304878, 0.1760332681539195, 0.18640522134898008, 0.18076956868161942, 0.3438763897901703, 0.18195441843808136, 0.19774480425602703, 0.2984458305000237, 0.18119158368400357, 0.4039788575247564, 0.16554441313706558, 0.16848233980894134, 0.17242138649037075, 0.3963466407096564, 0.12431484028680428, 0.2962854234193606, 0.12386433990997392, 0.14172409789855245, 0.10401329591216413, 0.10237628329667203, 0.12212192566635227, 0.17453827323177706, 0.18698108560222526, 0.17692104682932586, 0.1837793911895398, 0.17186797609069693, 0.18651404733528976, 0.175290973129836, 0.18761448146244064, 0.17776313317093684, 0.11829165288964161, 0.07290427900578433, 0.09666575804809541, 0.08284931199084744, 0.09229264136057425, 0.06573351553502249, 0.06469899902625964, 0.07591873433182916, 0.07753168356646278]}, "mutation_prompt": null}
{"id": "d7c12831-5a37-4fa3-8b15-c2d0a6a797a1", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimization", "description": "Introducing a dynamic step size adaptation based on the fitness improvement of each wolf to enhance convergence speed.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.33103449821939324, 0.3040480949406318, 0.3461539359040635, 0.267793838862431, 0.2843969316116849, 0.2579788652640307, 0.3101385872159119, 0.2660038630830429, 0.2565912122677866, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03727747940920767, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06948116989397035, 0.08114407681055125, 0.10342990083102321, 0.08859400181634902, 0.0946155582231244, 0.09812887798405245, 0.08176519286147577, 0.09684455887673016, 0.09242528037982012, 0.06597573101815779, 0.10571133621874274, 0.06739552500802215, 0.0942054385300709, 0.09599353136195987, 0.08879216843695925, 0.10025631140984992, 0.08720666807292399, 0.08805875069231373, 0.9848018523315675, 0.8915316774981772, 0.9345264689549528, 0.7883110260487081, 0.8929883510228567, 0.7855541599393364, 0.8866503114863262, 0.9341388746780092, 0.9452182528822439, 0.14330396746291585, 0.16146368724502314, 0.14485079224495134, 0.17284344577065858, 0.16577723631939556, 0.15623283775750152, 0.1473982940114965, 0.13497839833414726, 0.15712073811617044, 0.2236846606974785, 0.24311857957954008, 0.2190569572986214, 0.17380823843846394, 0.19035851938659532, 0.19500388806733404, 0.18587275446522733, 0.17568447906810503, 0.20952542841534205, 0.15318493975060488, 0.16814716976188215, 0.11797696838796978, 0.11922586881092867, 0.08712242319663133, 0.12203081015270656, 0.12218525688950754, 0.1225678963627106, 0.10342573868844429, 0.15646523614027608, 0.16910911619199542, 0.16948557812108078, 0.1600653124257415, 0.21180495086248452, 0.19898118117418062, 0.21854811547650554, 0.2247493235454746, 0.20760635656803228, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021399270440071283, 0.05867242115284843, 0.07169694229015, 0.11720015909147119, 0.06298103292773771, 0.05197702363637002, 0.05006604696275374, 0.07281931232118932, 0.1135336882890633, 0.060079732367998795, 0.08920191197026617, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021518231367246732, 0.02638014093755303, 0.02828327903317318, 0.027482138015897717, 0.01740190476981185, 0.03872348720440966, 0.03366216337300232, 0.03477159293533949, 0.0183672558502187, 0.32098844448283803, 0.3144535596010207, 0.3020527511347463, 0.31442699311923406, 0.2767146871076611, 0.2767817147028242, 0.327857212653598, 0.30549845692593514, 0.3223802132140039, 0.08203107833550183, 0.07611606790580916, 0.05908507600733026, 0.08715322678776483, 0.10827536649180125, 0.09704270741381316, 0.08652960588484637, 0.09238939703854832, 0.08007703988549908, 0.15487947981659544, 0.2119714898259606, 0.17122107754848237, 0.13148031201107968, 0.1583467446675717, 0.1479320059738769, 0.18496351186448579, 0.15498723741066056, 0.20403333473465313, 0.22022068630660652, 0.22617170716539292, 0.20201253706684008, 0.24845596760645772, 0.25766169684727536, 0.26323374988734405, 0.20783004187583431, 0.22907748524617422, 0.21467966478440625, 0.14836528853078834, 0.1865140288800997, 0.15702995960377197, 0.219007908625384, 0.21911198530248777, 0.20083737306061844, 0.1534803065344308, 0.1670681993156763, 0.1604125298100838, 0.254903090163632, 0.2736687508861446, 0.24479217304664236, 0.28945157999979987, 0.2849774299913692, 0.2554423599657626, 0.24986782284130216, 0.23801971193128824, 0.2484408539088342, 0.17522236515332645, 0.1763697804468748, 0.17499662499676705, 0.1782165084240953, 0.17413122546255833, 0.17527486547514615, 0.1814231217620833, 0.1735518473349632, 0.17712344391275947, 0.18097343656188725, 0.17246273898918174, 0.18103555852842945, 0.3515536202739914, 0.41761905971110524, 0.3032891863193108, 0.3526464297259342, 0.17482538870191833, 0.1089920771050662, 0.3212440981235244, 0.3446039576929306, 0.3150403350803024, 0.19682264207377953, 0.22811846691488713, 0.14377776766171557, 0.10338919898019627, 0.09267659410535489, 0.25312972258697186, 0.1787941768981045, 0.17488685365308687, 0.19539397196069253, 0.1889962219148058, 0.18292682228564006, 0.17285647524571446, 0.18929720207292877, 0.18438917247426256, 0.18430896628986404, 0.0848861819838117, 0.0641329465883369, 0.09305789667303255, 0.07806169079221836, 0.08015765813005127, 0.09374862538134388, 0.07424144447088032, 0.07891411310650731, 0.09308332941118713]}, "mutation_prompt": null}
{"id": "c2020195-4a85-4f63-a5a2-21505939d564", "solution": "import numpy as np\n\nclass NovelFastConvergingGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness, diversity):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            # Adaptive mutation based on population diversity\n            mutation_rate = 0.1 + 0.4 * diversity\n            r = np.random.normal(0, mutation_rate, self.dim)\n\n            new_position = np.clip(wolf['position'] + r, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            diversity = np.mean([np.linalg.norm(w1['position'] - w2['position']) for idx, w1 in enumerate(wolves) for w2 in wolves[idx + 1:]])\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness, diversity)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "NovelFastConvergingGreyWolfOptimization", "description": "Introducing a novel adaptive mutation mechanism based on population diversity to enhance exploration and convergence speed.", "configspace": "", "generation": 23, "fitness": 0.10169130643958141, "feedback": "The algorithm NovelFastConvergingGreyWolfOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.16.", "error": "", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.135361357818631, 0.15503122475098208, 0.1332760953276092, 0.14643000201270606, 0.1671512525216141, 0.15937883967524646, 0.1375867659984511, 0.12958209864032066, 0.14145557515107554, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021384643420231386, 0.03921701809329314, 0.02522382044367244, 0.023149678109485428, 0.03240862163501301, 0.04194760956535648, 0.02541231033921687, 0.03328003013836356, 0.024069119824712826, 0.013941983758852472, 0.017632768361498852, 0.01670871352293657, 0.01960752770993024, 0.014935920111452616, 0.022768879753266802, 0.022282231248754725, 0.021140634054464313, 0.019840366260416853, 0.718203914795013, 0.1865582660271603, 0.7216217884236724, 0.7023719369240911, 0.8671480051067149, 0.9364595491029447, 0.8814243322160243, 0.8869232626516481, 0.931138632183155, 0.05464655112643069, 0.060697844627260245, 0.03473964723749978, 0.07448739748006827, 0.04486612260917122, 0.054747673854457, 0.07485512547958462, 0.05315296324074115, 0.05667084296805902, 0.10347335827589943, 0.09642803282584644, 0.10700454188304553, 0.1397748707393781, 0.13536649543067503, 0.09056960891033305, 0.09296452171610636, 0.1131575301490515, 0.10269620358485354, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05143252193330594, 0.0626596438187551, 0.02139212139675606, 0.04175734391980679, 0.03507947120436694, 0.030298834947598663, 0.07731417482851644, 0.021995928989741675, 0.02698569658587202, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.17321835153341836, 0.18698667980220351, 0.15205674824536686, 0.16473434811492293, 0.1716164494850405, 0.1676065908988199, 0.1587910163991868, 0.1538978619711152, 0.20047760296730877, 0.03085076443767243, 0.03743533025103751, 0.02984218375597758, 0.029519412954369884, 0.02590448388475619, 0.028903187363750638, 0.026137339524094028, 0.04284068507647676, 0.022672138111449747, 0.13682861057920215, 0.1358891942613233, 0.14534206217708, 0.1433214058488116, 0.14064856202981246, 0.14381879925769758, 0.13965205826908844, 0.12950636509959768, 0.13160324321435946, 0.1535840510868529, 0.1536922432740474, 0.1378182895138933, 0.140243160567041, 0.13586600525017434, 0.15602129027846823, 0.13485009675840598, 0.13936916764260276, 0.1520058513492153, 0.09897258488421645, 0.08960601567525284, 0.07915848164775274, 0.09401635830449395, 0.09243381002955098, 0.11362772063279047, 0.08565836686598827, 0.09162473832135087, 0.08972192503856591, 0.1395750188378222, 0.1275877749517571, 0.1336620533818319, 0.1417727414243798, 0.14386611328560306, 0.13305772106445568, 0.14915627446577395, 0.12231013384050438, 0.13834437244022868, 0.0012438718285385786, 0.05228417804910701, 0.021915922635945218, 0.004764755381037822, 0.02819261403758433, 0.14594391981972799, 0.027004104143709795, 0.10774750292462376, 0.08674992024909611, 0.1593963956953599, 0.1414955557511688, 0.16190374201434754, 0.11297773574889436, 0.1425863448710083, 0.15223273985794572, 0.1912269889043995, 0.12106217265049612, 0.15738199850511192, 0.09716313278555955, 0.15223789666370868, 0.13770735453230099, 0.14964886531125798, 0.1371467334569486, 0.12164989941583104, 0.1294249687385931, 0.1537843395230779, 0.15967996682497776, 0.18081068182557825, 0.19063249188617548, 0.1950989583819639, 0.20631341396256442, 0.19685440775065222, 0.1792500963363406, 0.19657390276446385, 0.18189929853508102, 0.17361232804679805, 0.037958882484217416, 0.043953629956208884, 0.037965749745452526, 0.04142366956630961, 0.04076030435654043, 0.03246038487452019, 0.042600386070603014, 0.039544367818845405, 0.03868193449879287]}, "mutation_prompt": null}
{"id": "889181c9-d9ac-4237-bb84-cb3fc791f3d9", "solution": "import numpy as np\n\nclass ImprovedGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation based on fitness diversity\n            fitness_values = [wolf['fitness'] for wolf in wolves]\n            fitness_range = max(fitness_values) - min(fitness_values)\n            if fitness_range != 0:\n                normalized_fitness = [(wolf['fitness'] - min(fitness_values)) / fitness_range for wolf in wolves]\n            else:\n                normalized_fitness = [1.0 / len(wolves) for _ in wolves]\n            normalized_fitness_sum = sum(normalized_fitness)\n            selection_probabilities = [fit / normalized_fitness_sum for fit in normalized_fitness]\n\n            new_wolves = np.random.choice(wolves, 5, p=selection_probabilities)\n            wolves = new_wolves.tolist()\n\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "ImprovedGreyWolfOptimization", "description": "Introducing a dynamic population size adaptation based on the fitness diversity to enhance convergence speed.", "configspace": "", "generation": 24, "fitness": 0.08884677037098736, "feedback": "The algorithm ImprovedGreyWolfOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.07.", "error": "", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.15276749547436463, 0.156446843382278, 0.16965649066188093, 0.1530260368268438, 0.16258564419535038, 0.16509588826466293, 0.1868883561331528, 0.1779113423838451, 0.20660792469783373, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.042239210883565304, 0.038147614628824544, 0.03951683547426088, 0.04345157739867522, 0.041177291026690876, 0.04138913335748917, 0.038779070209471356, 0.051076610413052226, 0.040611183222125646, 0.028765876007742164, 0.03241820501885029, 0.042587555001339594, 0.031684066953181156, 0.0288308900266393, 0.03173540476568182, 0.025795793537915057, 0.02533687933033324, 0.03238990654477858, 0.07645048628582085, 0.07408252817140948, 0.08739271608935528, 0.08095917804354125, 0.07797187129629679, 0.07400959749332836, 0.0857362316990975, 0.08388338207194013, 0.07591786225552788, 0.06953373537233676, 0.061586787938727516, 0.06373268074207972, 0.05777515565367686, 0.06598829790875571, 0.06754128271693915, 0.10489805525029261, 0.044552134981605374, 0.05414463416851867, 0.13326017614954033, 0.11970293194751935, 0.12671212031278734, 0.09676716381704897, 0.11153337315504008, 0.10349133614263062, 0.14726694370691418, 0.0987581309000205, 0.11587714114262437, 9.999999999998899e-05, 0.05004453096564465, 0.006056053667797823, 0.01114246831571164, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.010977557232331292, 9.999999999998899e-05, 0.03267543082790614, 0.03466653601151992, 0.06986801254227881, 0.020594016606552246, 0.034763561541252264, 0.05566875794686654, 0.07016440950955549, 0.004469536131520346, 0.07181419655589616, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.041536721806747834, 0.05575227302528729, 0.03725601636406861, 0.029929161296565643, 0.022653796217120492, 0.036457962495512586, 0.04101734568056803, 0.017577162726735485, 0.049649254576211166, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0025286598463639676, 9.999999999998899e-05, 9.999999999998899e-05, 0.17765214786700367, 0.18421017562214292, 0.18871451365072345, 0.17094381934501524, 0.22284923006570445, 0.1712467101362214, 0.19224677552804137, 0.18641763818899304, 0.1981140281362722, 0.02429392106906325, 0.03814302042053874, 0.04235804717443514, 0.03606102689710877, 0.03750479165794918, 0.03503965001067577, 0.05645307161486346, 0.07210403783475872, 0.057088635818505984, 0.17172899923382245, 0.16749600690703448, 0.14831901391419122, 0.1488922929183505, 0.14107872252027387, 0.1445868893911909, 0.13422462588937067, 0.15147406364964622, 0.1256058574353458, 0.16065219356147076, 0.16270630718971568, 0.1527979670395282, 0.16793611557414256, 0.17552903466956993, 0.17566002628912358, 0.15910454598876023, 0.1652260590193224, 0.16992231612341402, 0.08862390012243382, 0.10615349043438216, 0.10617363879181685, 0.10781599472909142, 0.113040122386738, 0.12059499005920316, 0.09447747323620803, 0.11118687455687615, 0.112753141169733, 0.16599266702763393, 0.17125733031674484, 0.18529493435727917, 0.1687750582107994, 0.185843276744743, 0.17082339679917824, 0.18298218780635667, 0.1695945110618099, 0.17018818045415884, 0.141104689700985, 0.14319579274462357, 0.11558321815120565, 0.1465424154951006, 0.13847756156442415, 0.13891826558137887, 0.16067217308612325, 0.1501118320149506, 0.14900285598908014, 0.172768631619738, 0.13734914474247673, 0.20304754109889456, 0.1609779709937097, 0.1625547649967255, 0.15691663977216452, 0.20379122091864432, 0.15682262692233706, 0.15199991891021403, 0.14659820588393435, 0.164216138462705, 0.15459821693892883, 0.16610694685821326, 0.15619225243571144, 0.13526200631565077, 0.14273808482252293, 0.18076017475080075, 0.12446516221240067, 0.19831635453662333, 0.19903799259737787, 0.18384280548111687, 0.18053311453905607, 0.17659453531765046, 0.1944384805125171, 0.17620669236638498, 0.19856849186389847, 0.18762003080181167, 0.049228476358169626, 0.06287717670839266, 0.05891059281062094, 0.05583045287752231, 0.07660734862646534, 0.0626850766030912, 0.051903927978539266, 0.06248875080499128, 0.05077571662369851]}, "mutation_prompt": null}
{"id": "d3c243b9-2061-4774-8290-00347f0ccf5d", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimization", "description": "Introducing a dynamic step size adaptation based on the fitness improvement of each wolf to enhance convergence speed.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.33103449821939324, 0.3040480949406318, 0.3461539359040635, 0.267793838862431, 0.2843969316116849, 0.2579788652640307, 0.3101385872159119, 0.2660038630830429, 0.2565912122677866, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03727747940920767, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06948116989397035, 0.08114407681055125, 0.10342990083102321, 0.08859400181634902, 0.0946155582231244, 0.09812887798405245, 0.08176519286147577, 0.09684455887673016, 0.09242528037982012, 0.06597573101815779, 0.10571133621874274, 0.06739552500802215, 0.0942054385300709, 0.09599353136195987, 0.08879216843695925, 0.10025631140984992, 0.08720666807292399, 0.08805875069231373, 0.9848018523315675, 0.8915316774981772, 0.9345264689549528, 0.7883110260487081, 0.8929883510228567, 0.7855541599393364, 0.8866503114863262, 0.9341388746780092, 0.9452182528822439, 0.14330396746291585, 0.16146368724502314, 0.14485079224495134, 0.17284344577065858, 0.16577723631939556, 0.15623283775750152, 0.1473982940114965, 0.13497839833414726, 0.15712073811617044, 0.2236846606974785, 0.24311857957954008, 0.2190569572986214, 0.17380823843846394, 0.19035851938659532, 0.19500388806733404, 0.18587275446522733, 0.17568447906810503, 0.20952542841534205, 0.15318493975060488, 0.16814716976188215, 0.11797696838796978, 0.11922586881092867, 0.08712242319663133, 0.12203081015270656, 0.12218525688950754, 0.1225678963627106, 0.10342573868844429, 0.15646523614027608, 0.16910911619199542, 0.16948557812108078, 0.1600653124257415, 0.21180495086248452, 0.19898118117418062, 0.21854811547650554, 0.2247493235454746, 0.20760635656803228, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021399270440071283, 0.05867242115284843, 0.07169694229015, 0.11720015909147119, 0.06298103292773771, 0.05197702363637002, 0.05006604696275374, 0.07281931232118932, 0.1135336882890633, 0.060079732367998795, 0.08920191197026617, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021518231367246732, 0.02638014093755303, 0.02828327903317318, 0.027482138015897717, 0.01740190476981185, 0.03872348720440966, 0.03366216337300232, 0.03477159293533949, 0.0183672558502187, 0.32098844448283803, 0.3144535596010207, 0.3020527511347463, 0.31442699311923406, 0.2767146871076611, 0.2767817147028242, 0.327857212653598, 0.30549845692593514, 0.3223802132140039, 0.08203107833550183, 0.07611606790580916, 0.05908507600733026, 0.08715322678776483, 0.10827536649180125, 0.09704270741381316, 0.08652960588484637, 0.09238939703854832, 0.08007703988549908, 0.15487947981659544, 0.2119714898259606, 0.17122107754848237, 0.13148031201107968, 0.1583467446675717, 0.1479320059738769, 0.18496351186448579, 0.15498723741066056, 0.20403333473465313, 0.22022068630660652, 0.22617170716539292, 0.20201253706684008, 0.24845596760645772, 0.25766169684727536, 0.26323374988734405, 0.20783004187583431, 0.22907748524617422, 0.21467966478440625, 0.14836528853078834, 0.1865140288800997, 0.15702995960377197, 0.219007908625384, 0.21911198530248777, 0.20083737306061844, 0.1534803065344308, 0.1670681993156763, 0.1604125298100838, 0.254903090163632, 0.2736687508861446, 0.24479217304664236, 0.28945157999979987, 0.2849774299913692, 0.2554423599657626, 0.24986782284130216, 0.23801971193128824, 0.2484408539088342, 0.17522236515332645, 0.1763697804468748, 0.17499662499676705, 0.1782165084240953, 0.17413122546255833, 0.17527486547514615, 0.1814231217620833, 0.1735518473349632, 0.17712344391275947, 0.18097343656188725, 0.17246273898918174, 0.18103555852842945, 0.3515536202739914, 0.41761905971110524, 0.3032891863193108, 0.3526464297259342, 0.17482538870191833, 0.1089920771050662, 0.3212440981235244, 0.3446039576929306, 0.3150403350803024, 0.19682264207377953, 0.22811846691488713, 0.14377776766171557, 0.10338919898019627, 0.09267659410535489, 0.25312972258697186, 0.1787941768981045, 0.17488685365308687, 0.19539397196069253, 0.1889962219148058, 0.18292682228564006, 0.17285647524571446, 0.18929720207292877, 0.18438917247426256, 0.18430896628986404, 0.0848861819838117, 0.0641329465883369, 0.09305789667303255, 0.07806169079221836, 0.08015765813005127, 0.09374862538134388, 0.07424144447088032, 0.07891411310650731, 0.09308332941118713]}, "mutation_prompt": null}
{"id": "28d32419-a3c2-49cb-a0f4-36af3dd5abe8", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimization", "description": "Introducing a dynamic step size adaptation based on the fitness improvement of each wolf to enhance convergence speed.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.33103449821939324, 0.3040480949406318, 0.3461539359040635, 0.267793838862431, 0.2843969316116849, 0.2579788652640307, 0.3101385872159119, 0.2660038630830429, 0.2565912122677866, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03727747940920767, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06948116989397035, 0.08114407681055125, 0.10342990083102321, 0.08859400181634902, 0.0946155582231244, 0.09812887798405245, 0.08176519286147577, 0.09684455887673016, 0.09242528037982012, 0.06597573101815779, 0.10571133621874274, 0.06739552500802215, 0.0942054385300709, 0.09599353136195987, 0.08879216843695925, 0.10025631140984992, 0.08720666807292399, 0.08805875069231373, 0.9848018523315675, 0.8915316774981772, 0.9345264689549528, 0.7883110260487081, 0.8929883510228567, 0.7855541599393364, 0.8866503114863262, 0.9341388746780092, 0.9452182528822439, 0.14330396746291585, 0.16146368724502314, 0.14485079224495134, 0.17284344577065858, 0.16577723631939556, 0.15623283775750152, 0.1473982940114965, 0.13497839833414726, 0.15712073811617044, 0.2236846606974785, 0.24311857957954008, 0.2190569572986214, 0.17380823843846394, 0.19035851938659532, 0.19500388806733404, 0.18587275446522733, 0.17568447906810503, 0.20952542841534205, 0.15318493975060488, 0.16814716976188215, 0.11797696838796978, 0.11922586881092867, 0.08712242319663133, 0.12203081015270656, 0.12218525688950754, 0.1225678963627106, 0.10342573868844429, 0.15646523614027608, 0.16910911619199542, 0.16948557812108078, 0.1600653124257415, 0.21180495086248452, 0.19898118117418062, 0.21854811547650554, 0.2247493235454746, 0.20760635656803228, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021399270440071283, 0.05867242115284843, 0.07169694229015, 0.11720015909147119, 0.06298103292773771, 0.05197702363637002, 0.05006604696275374, 0.07281931232118932, 0.1135336882890633, 0.060079732367998795, 0.08920191197026617, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021518231367246732, 0.02638014093755303, 0.02828327903317318, 0.027482138015897717, 0.01740190476981185, 0.03872348720440966, 0.03366216337300232, 0.03477159293533949, 0.0183672558502187, 0.32098844448283803, 0.3144535596010207, 0.3020527511347463, 0.31442699311923406, 0.2767146871076611, 0.2767817147028242, 0.327857212653598, 0.30549845692593514, 0.3223802132140039, 0.08203107833550183, 0.07611606790580916, 0.05908507600733026, 0.08715322678776483, 0.10827536649180125, 0.09704270741381316, 0.08652960588484637, 0.09238939703854832, 0.08007703988549908, 0.15487947981659544, 0.2119714898259606, 0.17122107754848237, 0.13148031201107968, 0.1583467446675717, 0.1479320059738769, 0.18496351186448579, 0.15498723741066056, 0.20403333473465313, 0.22022068630660652, 0.22617170716539292, 0.20201253706684008, 0.24845596760645772, 0.25766169684727536, 0.26323374988734405, 0.20783004187583431, 0.22907748524617422, 0.21467966478440625, 0.14836528853078834, 0.1865140288800997, 0.15702995960377197, 0.219007908625384, 0.21911198530248777, 0.20083737306061844, 0.1534803065344308, 0.1670681993156763, 0.1604125298100838, 0.254903090163632, 0.2736687508861446, 0.24479217304664236, 0.28945157999979987, 0.2849774299913692, 0.2554423599657626, 0.24986782284130216, 0.23801971193128824, 0.2484408539088342, 0.17522236515332645, 0.1763697804468748, 0.17499662499676705, 0.1782165084240953, 0.17413122546255833, 0.17527486547514615, 0.1814231217620833, 0.1735518473349632, 0.17712344391275947, 0.18097343656188725, 0.17246273898918174, 0.18103555852842945, 0.3515536202739914, 0.41761905971110524, 0.3032891863193108, 0.3526464297259342, 0.17482538870191833, 0.1089920771050662, 0.3212440981235244, 0.3446039576929306, 0.3150403350803024, 0.19682264207377953, 0.22811846691488713, 0.14377776766171557, 0.10338919898019627, 0.09267659410535489, 0.25312972258697186, 0.1787941768981045, 0.17488685365308687, 0.19539397196069253, 0.1889962219148058, 0.18292682228564006, 0.17285647524571446, 0.18929720207292877, 0.18438917247426256, 0.18430896628986404, 0.0848861819838117, 0.0641329465883369, 0.09305789667303255, 0.07806169079221836, 0.08015765813005127, 0.09374862538134388, 0.07424144447088032, 0.07891411310650731, 0.09308332941118713]}, "mutation_prompt": null}
{"id": "43c077bd-b188-4145-8f25-10cc8f4148af", "solution": "import numpy as np\n\nclass EnhancedGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            weight_factor = 1.0 - np.exp(-0.1 * fitness_improvement)  # Adaptive weight factor based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * weight_factor\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "EnhancedGreyWolfOptimization", "description": "Introducing an adaptive weight factor for each dimension based on fitness improvement to enhance convergence speed.", "configspace": "", "generation": 27, "fitness": 0.17892404043211702, "feedback": "The algorithm EnhancedGreyWolfOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.18.", "error": "", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.33103449821939324, 0.3040480949406318, 0.3461539359040635, 0.267793838862431, 0.2843969316116849, 0.2579788652640307, 0.3101385872159119, 0.2660038630830429, 0.2565912122677866, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03727747940920767, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06948116989397035, 0.08114407681055125, 0.10342990083102321, 0.08859400181634902, 0.0946155582231244, 0.09812887798405245, 0.08176519286147577, 0.09684455887673016, 0.09242528037982012, 0.06597573101815779, 0.10571133621874274, 0.06739552500802215, 0.0942054385300709, 0.09599353136195987, 0.08879216843695925, 0.10025631140984992, 0.08720666807292399, 0.08805875069231373, 0.9848018523315675, 0.8915316774981772, 0.9345264689549528, 0.7883110260487081, 0.8929883510228567, 0.7855541599393364, 0.8866503114863262, 0.9341388746780092, 0.9452182528822439, 0.14330396746291585, 0.16146368724502314, 0.14485079224495134, 0.17284344577065858, 0.16577723631939556, 0.15623283775750152, 0.1473982940114965, 0.13497839833414726, 0.15712073811617044, 0.2236846606974785, 0.24311857957954008, 0.2190569572986214, 0.17380823843846394, 0.19035851938659532, 0.19500388806733404, 0.18587275446522733, 0.17568447906810503, 0.20952542841534205, 0.15318493975060488, 0.16814716976188215, 0.11797696838796978, 0.11922586881092867, 0.08712242319663133, 0.12203081015270656, 0.12218525688950754, 0.1225678963627106, 0.10342573868844429, 0.15646523614027608, 0.16910911619199542, 0.16948557812108078, 0.1600653124257415, 0.21180495086248452, 0.19898118117418062, 0.21854811547650554, 0.2247493235454746, 0.20760635656803228, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021399270440071283, 0.05867242115284843, 0.07169694229015, 0.11720015909147119, 0.06298103292773771, 0.05197702363637002, 0.05006604696275374, 0.07281931232118932, 0.1135336882890633, 0.060079732367998795, 0.08920191197026617, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021518231367246732, 0.02638014093755303, 0.02828327903317318, 0.027482138015897717, 0.01740190476981185, 0.03872348720440966, 0.03366216337300232, 0.03477159293533949, 0.0183672558502187, 0.32098844448283803, 0.3144535596010207, 0.3020527511347463, 0.31442699311923406, 0.2767146871076611, 0.2767817147028242, 0.327857212653598, 0.30549845692593514, 0.3223802132140039, 0.08203107833550183, 0.07611606790580916, 0.05908507600733026, 0.08715322678776483, 0.10827536649180125, 0.09704270741381316, 0.08652960588484637, 0.09238939703854832, 0.08007703988549908, 0.15487947981659544, 0.2119714898259606, 0.17122107754848237, 0.13148031201107968, 0.1583467446675717, 0.1479320059738769, 0.18496351186448579, 0.15498723741066056, 0.20403333473465313, 0.22022068630660652, 0.22617170716539292, 0.20201253706684008, 0.24845596760645772, 0.25766169684727536, 0.26323374988734405, 0.20783004187583431, 0.22907748524617422, 0.21467966478440625, 0.14836528853078834, 0.1865140288800997, 0.15702995960377197, 0.219007908625384, 0.21911198530248777, 0.20083737306061844, 0.1534803065344308, 0.1670681993156763, 0.1604125298100838, 0.254903090163632, 0.2736687508861446, 0.24479217304664236, 0.28945157999979987, 0.2849774299913692, 0.2554423599657626, 0.24986782284130216, 0.23801971193128824, 0.2484408539088342, 0.17522236515332645, 0.1763697804468748, 0.17499662499676705, 0.1782165084240953, 0.17413122546255833, 0.17527486547514615, 0.1814231217620833, 0.1735518473349632, 0.17712344391275947, 0.18097343656188725, 0.17246273898918174, 0.18103555852842945, 0.3515536202739914, 0.41761905971110524, 0.3032891863193108, 0.3526464297259342, 0.17482538870191833, 0.1089920771050662, 0.3212440981235244, 0.3446039576929306, 0.3150403350803024, 0.19682264207377953, 0.22811846691488713, 0.14377776766171557, 0.10338919898019627, 0.09267659410535489, 0.25312972258697186, 0.1787941768981045, 0.17488685365308687, 0.19539397196069253, 0.1889962219148058, 0.18292682228564006, 0.17285647524571446, 0.18929720207292877, 0.18438917247426256, 0.18430896628986404, 0.0848861819838117, 0.0641329465883369, 0.09305789667303255, 0.07806169079221836, 0.08015765813005127, 0.09374862538134388, 0.07424144447088032, 0.07891411310650731, 0.09308332941118713]}, "mutation_prompt": null}
{"id": "77b4fd2f-4de9-4e62-aa02-b71f65906c0a", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimization", "description": "Introducing a dynamic step size adaptation based on the fitness improvement of each wolf to enhance convergence speed.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.33103449821939324, 0.3040480949406318, 0.3461539359040635, 0.267793838862431, 0.2843969316116849, 0.2579788652640307, 0.3101385872159119, 0.2660038630830429, 0.2565912122677866, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03727747940920767, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06948116989397035, 0.08114407681055125, 0.10342990083102321, 0.08859400181634902, 0.0946155582231244, 0.09812887798405245, 0.08176519286147577, 0.09684455887673016, 0.09242528037982012, 0.06597573101815779, 0.10571133621874274, 0.06739552500802215, 0.0942054385300709, 0.09599353136195987, 0.08879216843695925, 0.10025631140984992, 0.08720666807292399, 0.08805875069231373, 0.9848018523315675, 0.8915316774981772, 0.9345264689549528, 0.7883110260487081, 0.8929883510228567, 0.7855541599393364, 0.8866503114863262, 0.9341388746780092, 0.9452182528822439, 0.14330396746291585, 0.16146368724502314, 0.14485079224495134, 0.17284344577065858, 0.16577723631939556, 0.15623283775750152, 0.1473982940114965, 0.13497839833414726, 0.15712073811617044, 0.2236846606974785, 0.24311857957954008, 0.2190569572986214, 0.17380823843846394, 0.19035851938659532, 0.19500388806733404, 0.18587275446522733, 0.17568447906810503, 0.20952542841534205, 0.15318493975060488, 0.16814716976188215, 0.11797696838796978, 0.11922586881092867, 0.08712242319663133, 0.12203081015270656, 0.12218525688950754, 0.1225678963627106, 0.10342573868844429, 0.15646523614027608, 0.16910911619199542, 0.16948557812108078, 0.1600653124257415, 0.21180495086248452, 0.19898118117418062, 0.21854811547650554, 0.2247493235454746, 0.20760635656803228, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021399270440071283, 0.05867242115284843, 0.07169694229015, 0.11720015909147119, 0.06298103292773771, 0.05197702363637002, 0.05006604696275374, 0.07281931232118932, 0.1135336882890633, 0.060079732367998795, 0.08920191197026617, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021518231367246732, 0.02638014093755303, 0.02828327903317318, 0.027482138015897717, 0.01740190476981185, 0.03872348720440966, 0.03366216337300232, 0.03477159293533949, 0.0183672558502187, 0.32098844448283803, 0.3144535596010207, 0.3020527511347463, 0.31442699311923406, 0.2767146871076611, 0.2767817147028242, 0.327857212653598, 0.30549845692593514, 0.3223802132140039, 0.08203107833550183, 0.07611606790580916, 0.05908507600733026, 0.08715322678776483, 0.10827536649180125, 0.09704270741381316, 0.08652960588484637, 0.09238939703854832, 0.08007703988549908, 0.15487947981659544, 0.2119714898259606, 0.17122107754848237, 0.13148031201107968, 0.1583467446675717, 0.1479320059738769, 0.18496351186448579, 0.15498723741066056, 0.20403333473465313, 0.22022068630660652, 0.22617170716539292, 0.20201253706684008, 0.24845596760645772, 0.25766169684727536, 0.26323374988734405, 0.20783004187583431, 0.22907748524617422, 0.21467966478440625, 0.14836528853078834, 0.1865140288800997, 0.15702995960377197, 0.219007908625384, 0.21911198530248777, 0.20083737306061844, 0.1534803065344308, 0.1670681993156763, 0.1604125298100838, 0.254903090163632, 0.2736687508861446, 0.24479217304664236, 0.28945157999979987, 0.2849774299913692, 0.2554423599657626, 0.24986782284130216, 0.23801971193128824, 0.2484408539088342, 0.17522236515332645, 0.1763697804468748, 0.17499662499676705, 0.1782165084240953, 0.17413122546255833, 0.17527486547514615, 0.1814231217620833, 0.1735518473349632, 0.17712344391275947, 0.18097343656188725, 0.17246273898918174, 0.18103555852842945, 0.3515536202739914, 0.41761905971110524, 0.3032891863193108, 0.3526464297259342, 0.17482538870191833, 0.1089920771050662, 0.3212440981235244, 0.3446039576929306, 0.3150403350803024, 0.19682264207377953, 0.22811846691488713, 0.14377776766171557, 0.10338919898019627, 0.09267659410535489, 0.25312972258697186, 0.1787941768981045, 0.17488685365308687, 0.19539397196069253, 0.1889962219148058, 0.18292682228564006, 0.17285647524571446, 0.18929720207292877, 0.18438917247426256, 0.18430896628986404, 0.0848861819838117, 0.0641329465883369, 0.09305789667303255, 0.07806169079221836, 0.08015765813005127, 0.09374862538134388, 0.07424144447088032, 0.07891411310650731, 0.09308332941118713]}, "mutation_prompt": null}
{"id": "0c7bcb72-0083-4dfb-a0bf-5b6e997ac338", "solution": "import numpy as np\n\nclass AdaptiveGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def update_position(wolf, alpha, beta, delta, prev_fitness, fitness_history):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement) * (1.0 - 1.0 / (1.0 + np.mean(fitness_history)))  # Adaptive step size based on fitness improvement and diversity\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n        fitness_history = [wolf['fitness'] for wolf in wolves]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = sorted(wolves, key=lambda x: x['fitness'])[:3]\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness, fitness_history)\n                wolf['fitness'] = func(wolf['position'])\n            fitness_history.append(wolf['fitness'])\n            if len(fitness_history) > 5:\n                fitness_history.pop(0)\n\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "AdaptiveGreyWolfOptimization", "description": "Introducing an adaptive mutation mechanism that adjusts the step size dynamically based on the fitness landscape to enhance convergence speed while maintaining diversity.", "configspace": "", "generation": 29, "fitness": 0.17740899232086815, "feedback": "The algorithm AdaptiveGreyWolfOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.18.", "error": "", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.30609174292330044, 0.3365693869969725, 0.3449341213915875, 0.2629274097849552, 0.2618968476904594, 0.2630721459536427, 0.31217672544471575, 0.30070164483874207, 0.2877471555281681, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.037279067748057004, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09532534261525016, 0.08018020857249653, 0.08707518121603042, 0.09629539130491871, 0.09082300046200853, 0.09304462596648588, 0.08442841174878757, 0.08857414995304791, 0.1070068234299999, 0.08265155154293702, 0.06688706468967143, 0.07877805856151576, 0.08507453580318125, 0.0811576974891074, 0.08930427572892785, 0.08581160413005218, 0.0902275428335575, 0.0888440991751357, 0.9432353327269453, 0.8121306115203695, 0.9252701404368495, 0.788308054329023, 0.8929922327260921, 0.7855605211932579, 0.9357908852059045, 0.9331146796826228, 0.9479364414629514, 0.14330570925548547, 0.161476596344583, 0.14484178807485992, 0.17732246871849278, 0.1657818610545062, 0.13424084159742744, 0.1473875534141731, 0.13497476930533014, 0.14737534793573837, 0.2352841539559175, 0.1409445505965934, 0.22002324702811749, 0.16441044192929566, 0.18391151821866691, 0.20231841818036844, 0.1809284204749364, 0.21267318296916027, 0.21305682159235728, 0.15325022421490342, 0.16272915860500492, 0.11810264411779503, 0.11918659141990229, 0.08430052541796773, 0.10794265649322277, 0.122192764430472, 0.12264068802418093, 0.10196255580192715, 0.14756630495637268, 0.15837369253979505, 0.17065204828101066, 0.1600603876707759, 0.2118821524857516, 0.19816310040395968, 0.21855475689217319, 0.22987638720173975, 0.21143501962800082, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02139733289318413, 0.05867317933657301, 0.07169749886050414, 0.1172004139381776, 0.06297423720084394, 0.05197521707149899, 0.050068207535691744, 0.07280663418924704, 0.11353316312994466, 0.06005291308592442, 0.08920495729534561, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02960156037658268, 0.02907579253988113, 0.03422862218215161, 0.02414451825977726, 0.02827315279072895, 0.025689610538658925, 0.038052479215338275, 0.03940467737512077, 0.03593944119785997, 0.31020614351176923, 0.2936876378119564, 0.2986792715497806, 0.28607182525459285, 0.3048254546499011, 0.26712203821387714, 0.33053830380512783, 0.317698308834901, 0.3104088446227825, 0.07315314037195153, 0.08127145340502007, 0.06597090268823247, 0.08728300468838002, 0.09029427004244195, 0.09285805016477244, 0.08856099693671804, 0.0866097461023454, 0.09826134740933035, 0.15343153062073178, 0.1933464755616745, 0.22314579585047334, 0.1434640893002539, 0.15136716394778982, 0.1849530412603193, 0.18855846680191357, 0.16417505585651304, 0.15563091315512334, 0.22328207877467154, 0.22076802048939315, 0.21974205393311386, 0.25587612545538285, 0.26295526124067525, 0.2514469748083459, 0.22658013596753412, 0.19345585340625715, 0.2091420411002095, 0.17661665866762088, 0.17243806692409203, 0.16602011445809617, 0.20003371576745999, 0.2070313467864131, 0.18924330244628063, 0.1614196670617144, 0.1936391073847713, 0.14831603477940147, 0.2639172041971718, 0.2480407401172826, 0.25127139295513135, 0.261153392954094, 0.270391138086429, 0.2667740841032823, 0.24453872184374004, 0.23768493722706263, 0.2485669052476045, 0.1711595779171977, 0.17679288318967734, 0.1771810920813166, 0.18054742162067028, 0.17204961471786595, 0.17190577853846556, 0.18142388111864705, 0.1720288093904413, 0.1724234968677949, 0.14254303334233087, 0.15490922056051637, 0.18464815253571865, 0.33008187712396375, 0.28844254137142933, 0.1144609761758687, 0.5093833297386446, 0.1731638910123311, 0.1087753766138092, 0.17815531135826057, 0.2829996178602392, 0.3487669954046364, 0.17461127222498485, 0.2041637271416905, 0.14179853323239533, 0.18863166686687804, 0.3136235109657981, 0.287418585069105, 0.1906370777953189, 0.20393392439566072, 0.17722152723182338, 0.19227548206905354, 0.19460790986162457, 0.1991166219828463, 0.17393886214845333, 0.17622985134492608, 0.1814944032336847, 0.09003311219425325, 0.06635175805221893, 0.09382604934924654, 0.07120975069830715, 0.07148858538274727, 0.08140635764330895, 0.0743092922852735, 0.07186302657031807, 0.081642555374145]}, "mutation_prompt": null}
{"id": "b62211e0-17ed-4882-8f8f-3ba12c575cc4", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimization", "description": "Introducing a dynamic step size adaptation based on the fitness improvement of each wolf to enhance convergence speed.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.33103449821939324, 0.3040480949406318, 0.3461539359040635, 0.267793838862431, 0.2843969316116849, 0.2579788652640307, 0.3101385872159119, 0.2660038630830429, 0.2565912122677866, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03727747940920767, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06948116989397035, 0.08114407681055125, 0.10342990083102321, 0.08859400181634902, 0.0946155582231244, 0.09812887798405245, 0.08176519286147577, 0.09684455887673016, 0.09242528037982012, 0.06597573101815779, 0.10571133621874274, 0.06739552500802215, 0.0942054385300709, 0.09599353136195987, 0.08879216843695925, 0.10025631140984992, 0.08720666807292399, 0.08805875069231373, 0.9848018523315675, 0.8915316774981772, 0.9345264689549528, 0.7883110260487081, 0.8929883510228567, 0.7855541599393364, 0.8866503114863262, 0.9341388746780092, 0.9452182528822439, 0.14330396746291585, 0.16146368724502314, 0.14485079224495134, 0.17284344577065858, 0.16577723631939556, 0.15623283775750152, 0.1473982940114965, 0.13497839833414726, 0.15712073811617044, 0.2236846606974785, 0.24311857957954008, 0.2190569572986214, 0.17380823843846394, 0.19035851938659532, 0.19500388806733404, 0.18587275446522733, 0.17568447906810503, 0.20952542841534205, 0.15318493975060488, 0.16814716976188215, 0.11797696838796978, 0.11922586881092867, 0.08712242319663133, 0.12203081015270656, 0.12218525688950754, 0.1225678963627106, 0.10342573868844429, 0.15646523614027608, 0.16910911619199542, 0.16948557812108078, 0.1600653124257415, 0.21180495086248452, 0.19898118117418062, 0.21854811547650554, 0.2247493235454746, 0.20760635656803228, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021399270440071283, 0.05867242115284843, 0.07169694229015, 0.11720015909147119, 0.06298103292773771, 0.05197702363637002, 0.05006604696275374, 0.07281931232118932, 0.1135336882890633, 0.060079732367998795, 0.08920191197026617, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021518231367246732, 0.02638014093755303, 0.02828327903317318, 0.027482138015897717, 0.01740190476981185, 0.03872348720440966, 0.03366216337300232, 0.03477159293533949, 0.0183672558502187, 0.32098844448283803, 0.3144535596010207, 0.3020527511347463, 0.31442699311923406, 0.2767146871076611, 0.2767817147028242, 0.327857212653598, 0.30549845692593514, 0.3223802132140039, 0.08203107833550183, 0.07611606790580916, 0.05908507600733026, 0.08715322678776483, 0.10827536649180125, 0.09704270741381316, 0.08652960588484637, 0.09238939703854832, 0.08007703988549908, 0.15487947981659544, 0.2119714898259606, 0.17122107754848237, 0.13148031201107968, 0.1583467446675717, 0.1479320059738769, 0.18496351186448579, 0.15498723741066056, 0.20403333473465313, 0.22022068630660652, 0.22617170716539292, 0.20201253706684008, 0.24845596760645772, 0.25766169684727536, 0.26323374988734405, 0.20783004187583431, 0.22907748524617422, 0.21467966478440625, 0.14836528853078834, 0.1865140288800997, 0.15702995960377197, 0.219007908625384, 0.21911198530248777, 0.20083737306061844, 0.1534803065344308, 0.1670681993156763, 0.1604125298100838, 0.254903090163632, 0.2736687508861446, 0.24479217304664236, 0.28945157999979987, 0.2849774299913692, 0.2554423599657626, 0.24986782284130216, 0.23801971193128824, 0.2484408539088342, 0.17522236515332645, 0.1763697804468748, 0.17499662499676705, 0.1782165084240953, 0.17413122546255833, 0.17527486547514615, 0.1814231217620833, 0.1735518473349632, 0.17712344391275947, 0.18097343656188725, 0.17246273898918174, 0.18103555852842945, 0.3515536202739914, 0.41761905971110524, 0.3032891863193108, 0.3526464297259342, 0.17482538870191833, 0.1089920771050662, 0.3212440981235244, 0.3446039576929306, 0.3150403350803024, 0.19682264207377953, 0.22811846691488713, 0.14377776766171557, 0.10338919898019627, 0.09267659410535489, 0.25312972258697186, 0.1787941768981045, 0.17488685365308687, 0.19539397196069253, 0.1889962219148058, 0.18292682228564006, 0.17285647524571446, 0.18929720207292877, 0.18438917247426256, 0.18430896628986404, 0.0848861819838117, 0.0641329465883369, 0.09305789667303255, 0.07806169079221836, 0.08015765813005127, 0.09374862538134388, 0.07424144447088032, 0.07891411310650731, 0.09308332941118713]}, "mutation_prompt": null}
{"id": "ad87aed4-825b-45bc-bc77-0dcebe53a7c3", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimization", "description": "Introducing a dynamic step size adaptation based on the fitness improvement of each wolf to enhance convergence speed.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.33103449821939324, 0.3040480949406318, 0.3461539359040635, 0.267793838862431, 0.2843969316116849, 0.2579788652640307, 0.3101385872159119, 0.2660038630830429, 0.2565912122677866, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03727747940920767, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06948116989397035, 0.08114407681055125, 0.10342990083102321, 0.08859400181634902, 0.0946155582231244, 0.09812887798405245, 0.08176519286147577, 0.09684455887673016, 0.09242528037982012, 0.06597573101815779, 0.10571133621874274, 0.06739552500802215, 0.0942054385300709, 0.09599353136195987, 0.08879216843695925, 0.10025631140984992, 0.08720666807292399, 0.08805875069231373, 0.9848018523315675, 0.8915316774981772, 0.9345264689549528, 0.7883110260487081, 0.8929883510228567, 0.7855541599393364, 0.8866503114863262, 0.9341388746780092, 0.9452182528822439, 0.14330396746291585, 0.16146368724502314, 0.14485079224495134, 0.17284344577065858, 0.16577723631939556, 0.15623283775750152, 0.1473982940114965, 0.13497839833414726, 0.15712073811617044, 0.2236846606974785, 0.24311857957954008, 0.2190569572986214, 0.17380823843846394, 0.19035851938659532, 0.19500388806733404, 0.18587275446522733, 0.17568447906810503, 0.20952542841534205, 0.15318493975060488, 0.16814716976188215, 0.11797696838796978, 0.11922586881092867, 0.08712242319663133, 0.12203081015270656, 0.12218525688950754, 0.1225678963627106, 0.10342573868844429, 0.15646523614027608, 0.16910911619199542, 0.16948557812108078, 0.1600653124257415, 0.21180495086248452, 0.19898118117418062, 0.21854811547650554, 0.2247493235454746, 0.20760635656803228, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021399270440071283, 0.05867242115284843, 0.07169694229015, 0.11720015909147119, 0.06298103292773771, 0.05197702363637002, 0.05006604696275374, 0.07281931232118932, 0.1135336882890633, 0.060079732367998795, 0.08920191197026617, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021518231367246732, 0.02638014093755303, 0.02828327903317318, 0.027482138015897717, 0.01740190476981185, 0.03872348720440966, 0.03366216337300232, 0.03477159293533949, 0.0183672558502187, 0.32098844448283803, 0.3144535596010207, 0.3020527511347463, 0.31442699311923406, 0.2767146871076611, 0.2767817147028242, 0.327857212653598, 0.30549845692593514, 0.3223802132140039, 0.08203107833550183, 0.07611606790580916, 0.05908507600733026, 0.08715322678776483, 0.10827536649180125, 0.09704270741381316, 0.08652960588484637, 0.09238939703854832, 0.08007703988549908, 0.15487947981659544, 0.2119714898259606, 0.17122107754848237, 0.13148031201107968, 0.1583467446675717, 0.1479320059738769, 0.18496351186448579, 0.15498723741066056, 0.20403333473465313, 0.22022068630660652, 0.22617170716539292, 0.20201253706684008, 0.24845596760645772, 0.25766169684727536, 0.26323374988734405, 0.20783004187583431, 0.22907748524617422, 0.21467966478440625, 0.14836528853078834, 0.1865140288800997, 0.15702995960377197, 0.219007908625384, 0.21911198530248777, 0.20083737306061844, 0.1534803065344308, 0.1670681993156763, 0.1604125298100838, 0.254903090163632, 0.2736687508861446, 0.24479217304664236, 0.28945157999979987, 0.2849774299913692, 0.2554423599657626, 0.24986782284130216, 0.23801971193128824, 0.2484408539088342, 0.17522236515332645, 0.1763697804468748, 0.17499662499676705, 0.1782165084240953, 0.17413122546255833, 0.17527486547514615, 0.1814231217620833, 0.1735518473349632, 0.17712344391275947, 0.18097343656188725, 0.17246273898918174, 0.18103555852842945, 0.3515536202739914, 0.41761905971110524, 0.3032891863193108, 0.3526464297259342, 0.17482538870191833, 0.1089920771050662, 0.3212440981235244, 0.3446039576929306, 0.3150403350803024, 0.19682264207377953, 0.22811846691488713, 0.14377776766171557, 0.10338919898019627, 0.09267659410535489, 0.25312972258697186, 0.1787941768981045, 0.17488685365308687, 0.19539397196069253, 0.1889962219148058, 0.18292682228564006, 0.17285647524571446, 0.18929720207292877, 0.18438917247426256, 0.18430896628986404, 0.0848861819838117, 0.0641329465883369, 0.09305789667303255, 0.07806169079221836, 0.08015765813005127, 0.09374862538134388, 0.07424144447088032, 0.07891411310650731, 0.09308332941118713]}, "mutation_prompt": null}
{"id": "bbf74f87-a496-4b2e-ba4b-7ff81ebe657e", "solution": "import numpy as np\n\nclass ImprovedGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(3, self.budget - 4, 2):  # Improved dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            fitness_values = [wolf['fitness'] for wolf in wolves]\n            fitness_variability = np.var(fitness_values)  # Adaptive mutation based on fitness variability\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 4:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "ImprovedGreyWolfOptimization", "description": "Implementing a novel adaptive mutation strategy based on the fitness variability among wolves to enhance convergence speed.", "configspace": "", "generation": 32, "fitness": 0.17892404043211702, "feedback": "The algorithm ImprovedGreyWolfOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.18.", "error": "", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.33103449821939324, 0.3040480949406318, 0.3461539359040635, 0.267793838862431, 0.2843969316116849, 0.2579788652640307, 0.3101385872159119, 0.2660038630830429, 0.2565912122677866, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03727747940920767, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06948116989397035, 0.08114407681055125, 0.10342990083102321, 0.08859400181634902, 0.0946155582231244, 0.09812887798405245, 0.08176519286147577, 0.09684455887673016, 0.09242528037982012, 0.06597573101815779, 0.10571133621874274, 0.06739552500802215, 0.0942054385300709, 0.09599353136195987, 0.08879216843695925, 0.10025631140984992, 0.08720666807292399, 0.08805875069231373, 0.9848018523315675, 0.8915316774981772, 0.9345264689549528, 0.7883110260487081, 0.8929883510228567, 0.7855541599393364, 0.8866503114863262, 0.9341388746780092, 0.9452182528822439, 0.14330396746291585, 0.16146368724502314, 0.14485079224495134, 0.17284344577065858, 0.16577723631939556, 0.15623283775750152, 0.1473982940114965, 0.13497839833414726, 0.15712073811617044, 0.2236846606974785, 0.24311857957954008, 0.2190569572986214, 0.17380823843846394, 0.19035851938659532, 0.19500388806733404, 0.18587275446522733, 0.17568447906810503, 0.20952542841534205, 0.15318493975060488, 0.16814716976188215, 0.11797696838796978, 0.11922586881092867, 0.08712242319663133, 0.12203081015270656, 0.12218525688950754, 0.1225678963627106, 0.10342573868844429, 0.15646523614027608, 0.16910911619199542, 0.16948557812108078, 0.1600653124257415, 0.21180495086248452, 0.19898118117418062, 0.21854811547650554, 0.2247493235454746, 0.20760635656803228, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021399270440071283, 0.05867242115284843, 0.07169694229015, 0.11720015909147119, 0.06298103292773771, 0.05197702363637002, 0.05006604696275374, 0.07281931232118932, 0.1135336882890633, 0.060079732367998795, 0.08920191197026617, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021518231367246732, 0.02638014093755303, 0.02828327903317318, 0.027482138015897717, 0.01740190476981185, 0.03872348720440966, 0.03366216337300232, 0.03477159293533949, 0.0183672558502187, 0.32098844448283803, 0.3144535596010207, 0.3020527511347463, 0.31442699311923406, 0.2767146871076611, 0.2767817147028242, 0.327857212653598, 0.30549845692593514, 0.3223802132140039, 0.08203107833550183, 0.07611606790580916, 0.05908507600733026, 0.08715322678776483, 0.10827536649180125, 0.09704270741381316, 0.08652960588484637, 0.09238939703854832, 0.08007703988549908, 0.15487947981659544, 0.2119714898259606, 0.17122107754848237, 0.13148031201107968, 0.1583467446675717, 0.1479320059738769, 0.18496351186448579, 0.15498723741066056, 0.20403333473465313, 0.22022068630660652, 0.22617170716539292, 0.20201253706684008, 0.24845596760645772, 0.25766169684727536, 0.26323374988734405, 0.20783004187583431, 0.22907748524617422, 0.21467966478440625, 0.14836528853078834, 0.1865140288800997, 0.15702995960377197, 0.219007908625384, 0.21911198530248777, 0.20083737306061844, 0.1534803065344308, 0.1670681993156763, 0.1604125298100838, 0.254903090163632, 0.2736687508861446, 0.24479217304664236, 0.28945157999979987, 0.2849774299913692, 0.2554423599657626, 0.24986782284130216, 0.23801971193128824, 0.2484408539088342, 0.17522236515332645, 0.1763697804468748, 0.17499662499676705, 0.1782165084240953, 0.17413122546255833, 0.17527486547514615, 0.1814231217620833, 0.1735518473349632, 0.17712344391275947, 0.18097343656188725, 0.17246273898918174, 0.18103555852842945, 0.3515536202739914, 0.41761905971110524, 0.3032891863193108, 0.3526464297259342, 0.17482538870191833, 0.1089920771050662, 0.3212440981235244, 0.3446039576929306, 0.3150403350803024, 0.19682264207377953, 0.22811846691488713, 0.14377776766171557, 0.10338919898019627, 0.09267659410535489, 0.25312972258697186, 0.1787941768981045, 0.17488685365308687, 0.19539397196069253, 0.1889962219148058, 0.18292682228564006, 0.17285647524571446, 0.18929720207292877, 0.18438917247426256, 0.18430896628986404, 0.0848861819838117, 0.0641329465883369, 0.09305789667303255, 0.07806169079221836, 0.08015765813005127, 0.09374862538134388, 0.07424144447088032, 0.07891411310650731, 0.09308332941118713]}, "mutation_prompt": null}
{"id": "38958ba5-f619-42bb-877b-f9e89a95782d", "solution": "import numpy as np\n\nclass ImprovedGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness, mutation_rate):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - mutation_rate * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - mutation_rate * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - mutation_rate * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        mutation_rate = 0.1  # Initial mutation rate\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness, mutation_rate)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n            # Adaptive mutation rate based on fitness landscape curvature\n            best_wolf = min(wolves, key=lambda x: x['fitness'])\n            avg_fitness = np.mean([w['fitness'] for w in wolves])\n            mutation_rate = 0.1 + 0.1 * (1 - best_wolf['fitness'] / avg_fitness)  # Adjust mutation rate dynamically\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "ImprovedGreyWolfOptimization", "description": "Introducing a dynamic adaptive mutation rate based on the fitness landscape curvature to enhance convergence speed.", "configspace": "", "generation": 33, "fitness": 0.0657245517959232, "feedback": "The algorithm ImprovedGreyWolfOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.06.", "error": "", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.15378956938013777, 0.1169788584925272, 0.15241817606298624, 0.07631032705488161, 0.11183347314988534, 0.10067812163801404, 0.166654587058785, 0.1308501890122854, 0.10021568834663741, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.039976877236993835, 0.02469073728602944, 0.03839059011805457, 0.024674645739723, 0.00813944669168798, 0.03488146876956011, 0.014241284571745783, 0.02585035999733276, 0.03348892982001184, 0.026838908153285268, 0.018695114093215115, 0.00771124284076663, 0.01960752770993024, 9.999999999998899e-05, 9.999999999998899e-05, 0.014360101278391268, 0.007517039522875191, 9.999999999998899e-05, 0.051911682213226285, 0.04271882611799993, 0.043109525844461705, 0.0378949020253716, 0.054136167021276216, 0.06052374280433526, 0.04495033625334677, 0.05357123860033974, 0.06235783742357781, 0.0140485547066177, 0.010573685513229236, 0.01212181755625441, 0.010857324824981696, 0.036005459537005846, 0.01790682155403922, 0.02147405840058003, 0.030111237269194513, 0.08988948715289913, 0.1022834671744779, 0.08796981304052809, 0.059636481596114344, 0.015442812516517357, 0.0695734090296255, 0.07756653385396062, 0.08507510474917235, 0.0935416428286413, 0.019296208837177975, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0002601143904735759, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03663213112645569, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016302506876549328, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03670714791558061, 0.03858225679130878, 0.08992978814097152, 0.029228654564432133, 0.03207537171871244, 0.02127536479822889, 0.062447160768159815, 0.057039239386184604, 0.04746597937279151, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1954379571915028, 0.15111923038467012, 0.21972439208917083, 0.12317704927269957, 0.12710089860328244, 0.18847739885518044, 0.12864427276595702, 0.14848121299145756, 0.16634785411967645, 0.010396085212319717, 9.999999999998899e-05, 0.002664648328221886, 0.0490056501150542, 0.037234291861391156, 0.040283947984966706, 0.04565972468324886, 0.05358417791685932, 0.04193883693339773, 0.09802353536206043, 0.10460856393579765, 0.11572904713468757, 0.16793008896548722, 0.09728235948922315, 0.0894330493162333, 0.10372139693305182, 0.11488049739224149, 0.14097302080136564, 0.12424055033719938, 0.1201199276625804, 0.14478630211660326, 0.15975068654459024, 0.18498446380793188, 0.14420904868449014, 0.13434770664194495, 0.1257247115964567, 0.12942996330403733, 0.09409602732852895, 0.06485491227127038, 0.06266308265524845, 0.08475863459160593, 0.10484859499105825, 0.07186223208793074, 0.10067027528098915, 0.06263229552148808, 0.06534750089308017, 0.16703808661386865, 0.18556410551332492, 0.13556643862871387, 0.21602155537593526, 0.18243692170804027, 0.17427524219562074, 0.16654900996856192, 0.17982259179978666, 0.18263041148978199, 0.15034083582223012, 0.027003763082154575, 9.999999999998899e-05, 0.06628736616477215, 0.14167125695101002, 0.11532251754814549, 0.11957019240247735, 0.0301060784471745, 0.13464722393971806, 0.146094012539988, 0.121973377142931, 0.09068202199646092, 0.10099053191740348, 0.12080917085526266, 0.11925003465740702, 0.0920663024029007, 0.10083019838382423, 0.10719628393857505, 0.06769486654406287, 0.07600008533418057, 0.07831854661188076, 0.09064365577489131, 0.09736714449408557, 0.13850715032527383, 0.08343810863074108, 0.07135389761041389, 0.08511572971793735, 0.16879272579364546, 0.17762394359123224, 0.19409741351309617, 0.16959665030904814, 0.17825701562701124, 0.1897433020278464, 0.17681301557646134, 0.17501281684978298, 0.16979659041347672, 0.055313869229814405, 0.057400982325037875, 0.057219788331031474, 0.053282608861592085, 0.04148578004503212, 0.058561276893553615, 0.052626102857608936, 0.04645656110001639, 0.04316476476780284]}, "mutation_prompt": null}
{"id": "e7cc143e-1788-485f-abc8-8e029e6cd16e", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimization", "description": "Introducing a dynamic step size adaptation based on the fitness improvement of each wolf to enhance convergence speed.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.33103449821939324, 0.3040480949406318, 0.3461539359040635, 0.267793838862431, 0.2843969316116849, 0.2579788652640307, 0.3101385872159119, 0.2660038630830429, 0.2565912122677866, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03727747940920767, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06948116989397035, 0.08114407681055125, 0.10342990083102321, 0.08859400181634902, 0.0946155582231244, 0.09812887798405245, 0.08176519286147577, 0.09684455887673016, 0.09242528037982012, 0.06597573101815779, 0.10571133621874274, 0.06739552500802215, 0.0942054385300709, 0.09599353136195987, 0.08879216843695925, 0.10025631140984992, 0.08720666807292399, 0.08805875069231373, 0.9848018523315675, 0.8915316774981772, 0.9345264689549528, 0.7883110260487081, 0.8929883510228567, 0.7855541599393364, 0.8866503114863262, 0.9341388746780092, 0.9452182528822439, 0.14330396746291585, 0.16146368724502314, 0.14485079224495134, 0.17284344577065858, 0.16577723631939556, 0.15623283775750152, 0.1473982940114965, 0.13497839833414726, 0.15712073811617044, 0.2236846606974785, 0.24311857957954008, 0.2190569572986214, 0.17380823843846394, 0.19035851938659532, 0.19500388806733404, 0.18587275446522733, 0.17568447906810503, 0.20952542841534205, 0.15318493975060488, 0.16814716976188215, 0.11797696838796978, 0.11922586881092867, 0.08712242319663133, 0.12203081015270656, 0.12218525688950754, 0.1225678963627106, 0.10342573868844429, 0.15646523614027608, 0.16910911619199542, 0.16948557812108078, 0.1600653124257415, 0.21180495086248452, 0.19898118117418062, 0.21854811547650554, 0.2247493235454746, 0.20760635656803228, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021399270440071283, 0.05867242115284843, 0.07169694229015, 0.11720015909147119, 0.06298103292773771, 0.05197702363637002, 0.05006604696275374, 0.07281931232118932, 0.1135336882890633, 0.060079732367998795, 0.08920191197026617, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021518231367246732, 0.02638014093755303, 0.02828327903317318, 0.027482138015897717, 0.01740190476981185, 0.03872348720440966, 0.03366216337300232, 0.03477159293533949, 0.0183672558502187, 0.32098844448283803, 0.3144535596010207, 0.3020527511347463, 0.31442699311923406, 0.2767146871076611, 0.2767817147028242, 0.327857212653598, 0.30549845692593514, 0.3223802132140039, 0.08203107833550183, 0.07611606790580916, 0.05908507600733026, 0.08715322678776483, 0.10827536649180125, 0.09704270741381316, 0.08652960588484637, 0.09238939703854832, 0.08007703988549908, 0.15487947981659544, 0.2119714898259606, 0.17122107754848237, 0.13148031201107968, 0.1583467446675717, 0.1479320059738769, 0.18496351186448579, 0.15498723741066056, 0.20403333473465313, 0.22022068630660652, 0.22617170716539292, 0.20201253706684008, 0.24845596760645772, 0.25766169684727536, 0.26323374988734405, 0.20783004187583431, 0.22907748524617422, 0.21467966478440625, 0.14836528853078834, 0.1865140288800997, 0.15702995960377197, 0.219007908625384, 0.21911198530248777, 0.20083737306061844, 0.1534803065344308, 0.1670681993156763, 0.1604125298100838, 0.254903090163632, 0.2736687508861446, 0.24479217304664236, 0.28945157999979987, 0.2849774299913692, 0.2554423599657626, 0.24986782284130216, 0.23801971193128824, 0.2484408539088342, 0.17522236515332645, 0.1763697804468748, 0.17499662499676705, 0.1782165084240953, 0.17413122546255833, 0.17527486547514615, 0.1814231217620833, 0.1735518473349632, 0.17712344391275947, 0.18097343656188725, 0.17246273898918174, 0.18103555852842945, 0.3515536202739914, 0.41761905971110524, 0.3032891863193108, 0.3526464297259342, 0.17482538870191833, 0.1089920771050662, 0.3212440981235244, 0.3446039576929306, 0.3150403350803024, 0.19682264207377953, 0.22811846691488713, 0.14377776766171557, 0.10338919898019627, 0.09267659410535489, 0.25312972258697186, 0.1787941768981045, 0.17488685365308687, 0.19539397196069253, 0.1889962219148058, 0.18292682228564006, 0.17285647524571446, 0.18929720207292877, 0.18438917247426256, 0.18430896628986404, 0.0848861819838117, 0.0641329465883369, 0.09305789667303255, 0.07806169079221836, 0.08015765813005127, 0.09374862538134388, 0.07424144447088032, 0.07891411310650731, 0.09308332941118713]}, "mutation_prompt": null}
{"id": "4fd49966-9670-4345-af77-d99bab431666", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimization", "description": "Introducing a dynamic step size adaptation based on the fitness improvement of each wolf to enhance convergence speed.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.33103449821939324, 0.3040480949406318, 0.3461539359040635, 0.267793838862431, 0.2843969316116849, 0.2579788652640307, 0.3101385872159119, 0.2660038630830429, 0.2565912122677866, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03727747940920767, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06948116989397035, 0.08114407681055125, 0.10342990083102321, 0.08859400181634902, 0.0946155582231244, 0.09812887798405245, 0.08176519286147577, 0.09684455887673016, 0.09242528037982012, 0.06597573101815779, 0.10571133621874274, 0.06739552500802215, 0.0942054385300709, 0.09599353136195987, 0.08879216843695925, 0.10025631140984992, 0.08720666807292399, 0.08805875069231373, 0.9848018523315675, 0.8915316774981772, 0.9345264689549528, 0.7883110260487081, 0.8929883510228567, 0.7855541599393364, 0.8866503114863262, 0.9341388746780092, 0.9452182528822439, 0.14330396746291585, 0.16146368724502314, 0.14485079224495134, 0.17284344577065858, 0.16577723631939556, 0.15623283775750152, 0.1473982940114965, 0.13497839833414726, 0.15712073811617044, 0.2236846606974785, 0.24311857957954008, 0.2190569572986214, 0.17380823843846394, 0.19035851938659532, 0.19500388806733404, 0.18587275446522733, 0.17568447906810503, 0.20952542841534205, 0.15318493975060488, 0.16814716976188215, 0.11797696838796978, 0.11922586881092867, 0.08712242319663133, 0.12203081015270656, 0.12218525688950754, 0.1225678963627106, 0.10342573868844429, 0.15646523614027608, 0.16910911619199542, 0.16948557812108078, 0.1600653124257415, 0.21180495086248452, 0.19898118117418062, 0.21854811547650554, 0.2247493235454746, 0.20760635656803228, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021399270440071283, 0.05867242115284843, 0.07169694229015, 0.11720015909147119, 0.06298103292773771, 0.05197702363637002, 0.05006604696275374, 0.07281931232118932, 0.1135336882890633, 0.060079732367998795, 0.08920191197026617, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021518231367246732, 0.02638014093755303, 0.02828327903317318, 0.027482138015897717, 0.01740190476981185, 0.03872348720440966, 0.03366216337300232, 0.03477159293533949, 0.0183672558502187, 0.32098844448283803, 0.3144535596010207, 0.3020527511347463, 0.31442699311923406, 0.2767146871076611, 0.2767817147028242, 0.327857212653598, 0.30549845692593514, 0.3223802132140039, 0.08203107833550183, 0.07611606790580916, 0.05908507600733026, 0.08715322678776483, 0.10827536649180125, 0.09704270741381316, 0.08652960588484637, 0.09238939703854832, 0.08007703988549908, 0.15487947981659544, 0.2119714898259606, 0.17122107754848237, 0.13148031201107968, 0.1583467446675717, 0.1479320059738769, 0.18496351186448579, 0.15498723741066056, 0.20403333473465313, 0.22022068630660652, 0.22617170716539292, 0.20201253706684008, 0.24845596760645772, 0.25766169684727536, 0.26323374988734405, 0.20783004187583431, 0.22907748524617422, 0.21467966478440625, 0.14836528853078834, 0.1865140288800997, 0.15702995960377197, 0.219007908625384, 0.21911198530248777, 0.20083737306061844, 0.1534803065344308, 0.1670681993156763, 0.1604125298100838, 0.254903090163632, 0.2736687508861446, 0.24479217304664236, 0.28945157999979987, 0.2849774299913692, 0.2554423599657626, 0.24986782284130216, 0.23801971193128824, 0.2484408539088342, 0.17522236515332645, 0.1763697804468748, 0.17499662499676705, 0.1782165084240953, 0.17413122546255833, 0.17527486547514615, 0.1814231217620833, 0.1735518473349632, 0.17712344391275947, 0.18097343656188725, 0.17246273898918174, 0.18103555852842945, 0.3515536202739914, 0.41761905971110524, 0.3032891863193108, 0.3526464297259342, 0.17482538870191833, 0.1089920771050662, 0.3212440981235244, 0.3446039576929306, 0.3150403350803024, 0.19682264207377953, 0.22811846691488713, 0.14377776766171557, 0.10338919898019627, 0.09267659410535489, 0.25312972258697186, 0.1787941768981045, 0.17488685365308687, 0.19539397196069253, 0.1889962219148058, 0.18292682228564006, 0.17285647524571446, 0.18929720207292877, 0.18438917247426256, 0.18430896628986404, 0.0848861819838117, 0.0641329465883369, 0.09305789667303255, 0.07806169079221836, 0.08015765813005127, 0.09374862538134388, 0.07424144447088032, 0.07891411310650731, 0.09308332941118713]}, "mutation_prompt": null}
{"id": "d5cfdaee-3c7c-482f-beee-92f04f944d75", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimization", "description": "Introducing a dynamic step size adaptation based on the fitness improvement of each wolf to enhance convergence speed.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.33103449821939324, 0.3040480949406318, 0.3461539359040635, 0.267793838862431, 0.2843969316116849, 0.2579788652640307, 0.3101385872159119, 0.2660038630830429, 0.2565912122677866, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03727747940920767, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06948116989397035, 0.08114407681055125, 0.10342990083102321, 0.08859400181634902, 0.0946155582231244, 0.09812887798405245, 0.08176519286147577, 0.09684455887673016, 0.09242528037982012, 0.06597573101815779, 0.10571133621874274, 0.06739552500802215, 0.0942054385300709, 0.09599353136195987, 0.08879216843695925, 0.10025631140984992, 0.08720666807292399, 0.08805875069231373, 0.9848018523315675, 0.8915316774981772, 0.9345264689549528, 0.7883110260487081, 0.8929883510228567, 0.7855541599393364, 0.8866503114863262, 0.9341388746780092, 0.9452182528822439, 0.14330396746291585, 0.16146368724502314, 0.14485079224495134, 0.17284344577065858, 0.16577723631939556, 0.15623283775750152, 0.1473982940114965, 0.13497839833414726, 0.15712073811617044, 0.2236846606974785, 0.24311857957954008, 0.2190569572986214, 0.17380823843846394, 0.19035851938659532, 0.19500388806733404, 0.18587275446522733, 0.17568447906810503, 0.20952542841534205, 0.15318493975060488, 0.16814716976188215, 0.11797696838796978, 0.11922586881092867, 0.08712242319663133, 0.12203081015270656, 0.12218525688950754, 0.1225678963627106, 0.10342573868844429, 0.15646523614027608, 0.16910911619199542, 0.16948557812108078, 0.1600653124257415, 0.21180495086248452, 0.19898118117418062, 0.21854811547650554, 0.2247493235454746, 0.20760635656803228, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021399270440071283, 0.05867242115284843, 0.07169694229015, 0.11720015909147119, 0.06298103292773771, 0.05197702363637002, 0.05006604696275374, 0.07281931232118932, 0.1135336882890633, 0.060079732367998795, 0.08920191197026617, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021518231367246732, 0.02638014093755303, 0.02828327903317318, 0.027482138015897717, 0.01740190476981185, 0.03872348720440966, 0.03366216337300232, 0.03477159293533949, 0.0183672558502187, 0.32098844448283803, 0.3144535596010207, 0.3020527511347463, 0.31442699311923406, 0.2767146871076611, 0.2767817147028242, 0.327857212653598, 0.30549845692593514, 0.3223802132140039, 0.08203107833550183, 0.07611606790580916, 0.05908507600733026, 0.08715322678776483, 0.10827536649180125, 0.09704270741381316, 0.08652960588484637, 0.09238939703854832, 0.08007703988549908, 0.15487947981659544, 0.2119714898259606, 0.17122107754848237, 0.13148031201107968, 0.1583467446675717, 0.1479320059738769, 0.18496351186448579, 0.15498723741066056, 0.20403333473465313, 0.22022068630660652, 0.22617170716539292, 0.20201253706684008, 0.24845596760645772, 0.25766169684727536, 0.26323374988734405, 0.20783004187583431, 0.22907748524617422, 0.21467966478440625, 0.14836528853078834, 0.1865140288800997, 0.15702995960377197, 0.219007908625384, 0.21911198530248777, 0.20083737306061844, 0.1534803065344308, 0.1670681993156763, 0.1604125298100838, 0.254903090163632, 0.2736687508861446, 0.24479217304664236, 0.28945157999979987, 0.2849774299913692, 0.2554423599657626, 0.24986782284130216, 0.23801971193128824, 0.2484408539088342, 0.17522236515332645, 0.1763697804468748, 0.17499662499676705, 0.1782165084240953, 0.17413122546255833, 0.17527486547514615, 0.1814231217620833, 0.1735518473349632, 0.17712344391275947, 0.18097343656188725, 0.17246273898918174, 0.18103555852842945, 0.3515536202739914, 0.41761905971110524, 0.3032891863193108, 0.3526464297259342, 0.17482538870191833, 0.1089920771050662, 0.3212440981235244, 0.3446039576929306, 0.3150403350803024, 0.19682264207377953, 0.22811846691488713, 0.14377776766171557, 0.10338919898019627, 0.09267659410535489, 0.25312972258697186, 0.1787941768981045, 0.17488685365308687, 0.19539397196069253, 0.1889962219148058, 0.18292682228564006, 0.17285647524571446, 0.18929720207292877, 0.18438917247426256, 0.18430896628986404, 0.0848861819838117, 0.0641329465883369, 0.09305789667303255, 0.07806169079221836, 0.08015765813005127, 0.09374862538134388, 0.07424144447088032, 0.07891411310650731, 0.09308332941118713]}, "mutation_prompt": null}
{"id": "f44a6de0-b845-4d62-b717-8f98a6f47555", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimization", "description": "Introducing a dynamic step size adaptation based on the fitness improvement of each wolf to enhance convergence speed.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.33103449821939324, 0.3040480949406318, 0.3461539359040635, 0.267793838862431, 0.2843969316116849, 0.2579788652640307, 0.3101385872159119, 0.2660038630830429, 0.2565912122677866, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03727747940920767, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06948116989397035, 0.08114407681055125, 0.10342990083102321, 0.08859400181634902, 0.0946155582231244, 0.09812887798405245, 0.08176519286147577, 0.09684455887673016, 0.09242528037982012, 0.06597573101815779, 0.10571133621874274, 0.06739552500802215, 0.0942054385300709, 0.09599353136195987, 0.08879216843695925, 0.10025631140984992, 0.08720666807292399, 0.08805875069231373, 0.9848018523315675, 0.8915316774981772, 0.9345264689549528, 0.7883110260487081, 0.8929883510228567, 0.7855541599393364, 0.8866503114863262, 0.9341388746780092, 0.9452182528822439, 0.14330396746291585, 0.16146368724502314, 0.14485079224495134, 0.17284344577065858, 0.16577723631939556, 0.15623283775750152, 0.1473982940114965, 0.13497839833414726, 0.15712073811617044, 0.2236846606974785, 0.24311857957954008, 0.2190569572986214, 0.17380823843846394, 0.19035851938659532, 0.19500388806733404, 0.18587275446522733, 0.17568447906810503, 0.20952542841534205, 0.15318493975060488, 0.16814716976188215, 0.11797696838796978, 0.11922586881092867, 0.08712242319663133, 0.12203081015270656, 0.12218525688950754, 0.1225678963627106, 0.10342573868844429, 0.15646523614027608, 0.16910911619199542, 0.16948557812108078, 0.1600653124257415, 0.21180495086248452, 0.19898118117418062, 0.21854811547650554, 0.2247493235454746, 0.20760635656803228, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021399270440071283, 0.05867242115284843, 0.07169694229015, 0.11720015909147119, 0.06298103292773771, 0.05197702363637002, 0.05006604696275374, 0.07281931232118932, 0.1135336882890633, 0.060079732367998795, 0.08920191197026617, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021518231367246732, 0.02638014093755303, 0.02828327903317318, 0.027482138015897717, 0.01740190476981185, 0.03872348720440966, 0.03366216337300232, 0.03477159293533949, 0.0183672558502187, 0.32098844448283803, 0.3144535596010207, 0.3020527511347463, 0.31442699311923406, 0.2767146871076611, 0.2767817147028242, 0.327857212653598, 0.30549845692593514, 0.3223802132140039, 0.08203107833550183, 0.07611606790580916, 0.05908507600733026, 0.08715322678776483, 0.10827536649180125, 0.09704270741381316, 0.08652960588484637, 0.09238939703854832, 0.08007703988549908, 0.15487947981659544, 0.2119714898259606, 0.17122107754848237, 0.13148031201107968, 0.1583467446675717, 0.1479320059738769, 0.18496351186448579, 0.15498723741066056, 0.20403333473465313, 0.22022068630660652, 0.22617170716539292, 0.20201253706684008, 0.24845596760645772, 0.25766169684727536, 0.26323374988734405, 0.20783004187583431, 0.22907748524617422, 0.21467966478440625, 0.14836528853078834, 0.1865140288800997, 0.15702995960377197, 0.219007908625384, 0.21911198530248777, 0.20083737306061844, 0.1534803065344308, 0.1670681993156763, 0.1604125298100838, 0.254903090163632, 0.2736687508861446, 0.24479217304664236, 0.28945157999979987, 0.2849774299913692, 0.2554423599657626, 0.24986782284130216, 0.23801971193128824, 0.2484408539088342, 0.17522236515332645, 0.1763697804468748, 0.17499662499676705, 0.1782165084240953, 0.17413122546255833, 0.17527486547514615, 0.1814231217620833, 0.1735518473349632, 0.17712344391275947, 0.18097343656188725, 0.17246273898918174, 0.18103555852842945, 0.3515536202739914, 0.41761905971110524, 0.3032891863193108, 0.3526464297259342, 0.17482538870191833, 0.1089920771050662, 0.3212440981235244, 0.3446039576929306, 0.3150403350803024, 0.19682264207377953, 0.22811846691488713, 0.14377776766171557, 0.10338919898019627, 0.09267659410535489, 0.25312972258697186, 0.1787941768981045, 0.17488685365308687, 0.19539397196069253, 0.1889962219148058, 0.18292682228564006, 0.17285647524571446, 0.18929720207292877, 0.18438917247426256, 0.18430896628986404, 0.0848861819838117, 0.0641329465883369, 0.09305789667303255, 0.07806169079221836, 0.08015765813005127, 0.09374862538134388, 0.07424144447088032, 0.07891411310650731, 0.09308332941118713]}, "mutation_prompt": null}
{"id": "1e459e63-2e98-4bcd-a091-5ffb6dc4635e", "solution": "import numpy as np\n\nclass DynamicFastConvergingGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n            # Dynamic population update based on fitness\n            wolves = sorted(wolves, key=lambda x: x['fitness'])[:len(wolves) // 2] + [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                                                                                      'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(len(wolves) // 2)]\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "DynamicFastConvergingGreyWolfOptimization", "description": "Implementing a dynamic population update strategy by replacing the fixed population size with a dynamic growth and shrinkage mechanism based on fitness to enhance convergence speed.", "configspace": "", "generation": 38, "fitness": 0.09869798759160989, "feedback": "The algorithm DynamicFastConvergingGreyWolfOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.08.", "error": "", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.22848320843877024, 0.20771487849492076, 0.21513079402865976, 0.1615609095985987, 0.19546703955586786, 0.152569709622432, 0.1867262491191788, 0.17394954028982135, 0.16539147603490578, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04335131942349091, 0.058739321098766006, 0.05675403544996749, 0.04601285372452768, 0.044239805397091714, 0.046706956918456166, 0.04724161289647566, 0.03951931896069871, 0.04645322837097987, 0.035101548811179994, 0.038146507088132386, 0.05611059875414648, 0.039715102359919596, 0.036719040515093226, 0.03996000216338691, 0.028000686247772633, 0.042930234875866, 0.031217290409615406, 0.10176825068482032, 0.09777549490267434, 0.08406257912569237, 0.07640756709779983, 0.08586570226078727, 0.10628187675872192, 0.0806554769156892, 0.09207547488430323, 0.0925728213395347, 0.06917142750131933, 0.06680160467433738, 0.06959538246104402, 0.084809543738956, 0.07843308578959352, 0.08373765580607195, 0.07540621612005871, 0.08622497503382476, 0.07096037573835745, 0.2005586671759716, 0.16252956495644189, 0.14403738518179943, 0.13215738709395697, 0.14448342968290562, 0.10595771010325206, 0.15178274575215822, 0.14894139760224867, 0.11898641320059578, 0.013255724836111593, 0.032300060514602436, 0.019874050559348544, 9.999999999998899e-05, 0.019721333973544475, 9.999999999998899e-05, 0.0008378163196762767, 0.007140318612962049, 0.018150355050034372, 0.058297470198103274, 0.03650898222721366, 0.04735354578914919, 0.03683876402704356, 0.0426151254945335, 0.012253525570013135, 0.03976887234208937, 0.017805483208843675, 0.029825917810451408, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07247519202508779, 0.05933906162770941, 0.04973179609125311, 0.05242284529483099, 0.03583513826261875, 0.05267073009464207, 0.04806211681214323, 0.05864884964058381, 0.06816947409985075, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0012132553999035789, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005601826096668039, 9.999999999998899e-05, 0.0029834918148655687, 9.999999999998899e-05, 9.999999999998899e-05, 0.22596429124899697, 0.2082349027684749, 0.22729065307173213, 0.209560989905629, 0.21672935221364042, 0.19105031418003526, 0.22523262674553435, 0.21536481250098527, 0.2251747366538296, 0.028743098187185234, 0.03614820802880481, 0.0346756246726696, 0.04439674737767296, 0.04482424835693677, 0.04327398436036434, 0.04645193592184338, 0.04942211403042562, 0.046909812063747225, 0.1458376008970136, 0.14512310234785164, 0.13472201555692498, 0.14570065734793458, 0.18766675927508358, 0.16584705509437303, 0.14897657568369826, 0.169642666785921, 0.1305107642062816, 0.15849587309639623, 0.17499632556330003, 0.17283933732534296, 0.18794412121219362, 0.18256442086314484, 0.18576111241449866, 0.1884805562307036, 0.16084836844900452, 0.17273951392631004, 0.09838284878909853, 0.11388062775587349, 0.12403692572322889, 0.13910723689714655, 0.1426817093101319, 0.1338169517631721, 0.1186723044009943, 0.11805537542060252, 0.11312758979441828, 0.17189359029622409, 0.18335668224127666, 0.17646961411837325, 0.18578165520200074, 0.16387914715457597, 0.16483139741548114, 0.18681828869907047, 0.1784828951610532, 0.16152268492435595, 0.15786642379811178, 0.1566485319916845, 0.1832174885979857, 0.16738651188298048, 0.1586439047378735, 0.15720385726158326, 0.16051671111101717, 0.1583713089104054, 0.16742263824879866, 0.1428642517217935, 0.16171717934644203, 0.16430258522173957, 0.16619264265703637, 0.27017671186872216, 0.2083500953886892, 0.20200525349222387, 0.260764712480825, 0.16598543558955592, 0.2237078349810071, 0.16597634735931766, 0.1955090185968953, 0.1774918059915297, 0.15026234035703978, 0.23609319041105203, 0.14936635740682724, 0.280360443716715, 0.17387299853910154, 0.18338738973254076, 0.18484899214176465, 0.17996428248243723, 0.18998430924733645, 0.17007736498745962, 0.18679299441542707, 0.17818773453751013, 0.1702357049349248, 0.19363998806585137, 0.06370011010389354, 0.05202294515601047, 0.06409287663360197, 0.049242357235589784, 0.07306456061039479, 0.06180667676768459, 0.05818968917615652, 0.0603697207868088, 0.06478363344831395]}, "mutation_prompt": null}
{"id": "517c2e20-bd67-433b-94e3-8680faf87601", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimization", "description": "Introducing a dynamic step size adaptation based on the fitness improvement of each wolf to enhance convergence speed.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.33103449821939324, 0.3040480949406318, 0.3461539359040635, 0.267793838862431, 0.2843969316116849, 0.2579788652640307, 0.3101385872159119, 0.2660038630830429, 0.2565912122677866, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03727747940920767, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06948116989397035, 0.08114407681055125, 0.10342990083102321, 0.08859400181634902, 0.0946155582231244, 0.09812887798405245, 0.08176519286147577, 0.09684455887673016, 0.09242528037982012, 0.06597573101815779, 0.10571133621874274, 0.06739552500802215, 0.0942054385300709, 0.09599353136195987, 0.08879216843695925, 0.10025631140984992, 0.08720666807292399, 0.08805875069231373, 0.9848018523315675, 0.8915316774981772, 0.9345264689549528, 0.7883110260487081, 0.8929883510228567, 0.7855541599393364, 0.8866503114863262, 0.9341388746780092, 0.9452182528822439, 0.14330396746291585, 0.16146368724502314, 0.14485079224495134, 0.17284344577065858, 0.16577723631939556, 0.15623283775750152, 0.1473982940114965, 0.13497839833414726, 0.15712073811617044, 0.2236846606974785, 0.24311857957954008, 0.2190569572986214, 0.17380823843846394, 0.19035851938659532, 0.19500388806733404, 0.18587275446522733, 0.17568447906810503, 0.20952542841534205, 0.15318493975060488, 0.16814716976188215, 0.11797696838796978, 0.11922586881092867, 0.08712242319663133, 0.12203081015270656, 0.12218525688950754, 0.1225678963627106, 0.10342573868844429, 0.15646523614027608, 0.16910911619199542, 0.16948557812108078, 0.1600653124257415, 0.21180495086248452, 0.19898118117418062, 0.21854811547650554, 0.2247493235454746, 0.20760635656803228, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021399270440071283, 0.05867242115284843, 0.07169694229015, 0.11720015909147119, 0.06298103292773771, 0.05197702363637002, 0.05006604696275374, 0.07281931232118932, 0.1135336882890633, 0.060079732367998795, 0.08920191197026617, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021518231367246732, 0.02638014093755303, 0.02828327903317318, 0.027482138015897717, 0.01740190476981185, 0.03872348720440966, 0.03366216337300232, 0.03477159293533949, 0.0183672558502187, 0.32098844448283803, 0.3144535596010207, 0.3020527511347463, 0.31442699311923406, 0.2767146871076611, 0.2767817147028242, 0.327857212653598, 0.30549845692593514, 0.3223802132140039, 0.08203107833550183, 0.07611606790580916, 0.05908507600733026, 0.08715322678776483, 0.10827536649180125, 0.09704270741381316, 0.08652960588484637, 0.09238939703854832, 0.08007703988549908, 0.15487947981659544, 0.2119714898259606, 0.17122107754848237, 0.13148031201107968, 0.1583467446675717, 0.1479320059738769, 0.18496351186448579, 0.15498723741066056, 0.20403333473465313, 0.22022068630660652, 0.22617170716539292, 0.20201253706684008, 0.24845596760645772, 0.25766169684727536, 0.26323374988734405, 0.20783004187583431, 0.22907748524617422, 0.21467966478440625, 0.14836528853078834, 0.1865140288800997, 0.15702995960377197, 0.219007908625384, 0.21911198530248777, 0.20083737306061844, 0.1534803065344308, 0.1670681993156763, 0.1604125298100838, 0.254903090163632, 0.2736687508861446, 0.24479217304664236, 0.28945157999979987, 0.2849774299913692, 0.2554423599657626, 0.24986782284130216, 0.23801971193128824, 0.2484408539088342, 0.17522236515332645, 0.1763697804468748, 0.17499662499676705, 0.1782165084240953, 0.17413122546255833, 0.17527486547514615, 0.1814231217620833, 0.1735518473349632, 0.17712344391275947, 0.18097343656188725, 0.17246273898918174, 0.18103555852842945, 0.3515536202739914, 0.41761905971110524, 0.3032891863193108, 0.3526464297259342, 0.17482538870191833, 0.1089920771050662, 0.3212440981235244, 0.3446039576929306, 0.3150403350803024, 0.19682264207377953, 0.22811846691488713, 0.14377776766171557, 0.10338919898019627, 0.09267659410535489, 0.25312972258697186, 0.1787941768981045, 0.17488685365308687, 0.19539397196069253, 0.1889962219148058, 0.18292682228564006, 0.17285647524571446, 0.18929720207292877, 0.18438917247426256, 0.18430896628986404, 0.0848861819838117, 0.0641329465883369, 0.09305789667303255, 0.07806169079221836, 0.08015765813005127, 0.09374862538134388, 0.07424144447088032, 0.07891411310650731, 0.09308332941118713]}, "mutation_prompt": null}
{"id": "f7f7c5f9-865d-4f91-bdd3-a48b84cee7dc", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimization", "description": "Introducing a dynamic step size adaptation based on the fitness improvement of each wolf to enhance convergence speed.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.33103449821939324, 0.3040480949406318, 0.3461539359040635, 0.267793838862431, 0.2843969316116849, 0.2579788652640307, 0.3101385872159119, 0.2660038630830429, 0.2565912122677866, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03727747940920767, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06948116989397035, 0.08114407681055125, 0.10342990083102321, 0.08859400181634902, 0.0946155582231244, 0.09812887798405245, 0.08176519286147577, 0.09684455887673016, 0.09242528037982012, 0.06597573101815779, 0.10571133621874274, 0.06739552500802215, 0.0942054385300709, 0.09599353136195987, 0.08879216843695925, 0.10025631140984992, 0.08720666807292399, 0.08805875069231373, 0.9848018523315675, 0.8915316774981772, 0.9345264689549528, 0.7883110260487081, 0.8929883510228567, 0.7855541599393364, 0.8866503114863262, 0.9341388746780092, 0.9452182528822439, 0.14330396746291585, 0.16146368724502314, 0.14485079224495134, 0.17284344577065858, 0.16577723631939556, 0.15623283775750152, 0.1473982940114965, 0.13497839833414726, 0.15712073811617044, 0.2236846606974785, 0.24311857957954008, 0.2190569572986214, 0.17380823843846394, 0.19035851938659532, 0.19500388806733404, 0.18587275446522733, 0.17568447906810503, 0.20952542841534205, 0.15318493975060488, 0.16814716976188215, 0.11797696838796978, 0.11922586881092867, 0.08712242319663133, 0.12203081015270656, 0.12218525688950754, 0.1225678963627106, 0.10342573868844429, 0.15646523614027608, 0.16910911619199542, 0.16948557812108078, 0.1600653124257415, 0.21180495086248452, 0.19898118117418062, 0.21854811547650554, 0.2247493235454746, 0.20760635656803228, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021399270440071283, 0.05867242115284843, 0.07169694229015, 0.11720015909147119, 0.06298103292773771, 0.05197702363637002, 0.05006604696275374, 0.07281931232118932, 0.1135336882890633, 0.060079732367998795, 0.08920191197026617, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021518231367246732, 0.02638014093755303, 0.02828327903317318, 0.027482138015897717, 0.01740190476981185, 0.03872348720440966, 0.03366216337300232, 0.03477159293533949, 0.0183672558502187, 0.32098844448283803, 0.3144535596010207, 0.3020527511347463, 0.31442699311923406, 0.2767146871076611, 0.2767817147028242, 0.327857212653598, 0.30549845692593514, 0.3223802132140039, 0.08203107833550183, 0.07611606790580916, 0.05908507600733026, 0.08715322678776483, 0.10827536649180125, 0.09704270741381316, 0.08652960588484637, 0.09238939703854832, 0.08007703988549908, 0.15487947981659544, 0.2119714898259606, 0.17122107754848237, 0.13148031201107968, 0.1583467446675717, 0.1479320059738769, 0.18496351186448579, 0.15498723741066056, 0.20403333473465313, 0.22022068630660652, 0.22617170716539292, 0.20201253706684008, 0.24845596760645772, 0.25766169684727536, 0.26323374988734405, 0.20783004187583431, 0.22907748524617422, 0.21467966478440625, 0.14836528853078834, 0.1865140288800997, 0.15702995960377197, 0.219007908625384, 0.21911198530248777, 0.20083737306061844, 0.1534803065344308, 0.1670681993156763, 0.1604125298100838, 0.254903090163632, 0.2736687508861446, 0.24479217304664236, 0.28945157999979987, 0.2849774299913692, 0.2554423599657626, 0.24986782284130216, 0.23801971193128824, 0.2484408539088342, 0.17522236515332645, 0.1763697804468748, 0.17499662499676705, 0.1782165084240953, 0.17413122546255833, 0.17527486547514615, 0.1814231217620833, 0.1735518473349632, 0.17712344391275947, 0.18097343656188725, 0.17246273898918174, 0.18103555852842945, 0.3515536202739914, 0.41761905971110524, 0.3032891863193108, 0.3526464297259342, 0.17482538870191833, 0.1089920771050662, 0.3212440981235244, 0.3446039576929306, 0.3150403350803024, 0.19682264207377953, 0.22811846691488713, 0.14377776766171557, 0.10338919898019627, 0.09267659410535489, 0.25312972258697186, 0.1787941768981045, 0.17488685365308687, 0.19539397196069253, 0.1889962219148058, 0.18292682228564006, 0.17285647524571446, 0.18929720207292877, 0.18438917247426256, 0.18430896628986404, 0.0848861819838117, 0.0641329465883369, 0.09305789667303255, 0.07806169079221836, 0.08015765813005127, 0.09374862538134388, 0.07424144447088032, 0.07891411310650731, 0.09308332941118713]}, "mutation_prompt": null}
{"id": "60def576-8206-4fa8-a745-fcc74c663571", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation based on fitness variance\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            fitness_values = [wolf['fitness'] for wolf in wolves]\n            variance_fitness = np.var(fitness_values)\n            if variance_fitness > 0:\n                population_size = min(5, int(5 / variance_fitness))  # Adjust population size based on fitness variance\n                wolves = sorted(wolves, key=lambda x: x['fitness'])[:population_size]\n\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimization", "description": "Introducing a dynamic population size adjustment mechanism based on the fitness variance to enhance convergence speed.", "configspace": "", "generation": 41, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {}, "mutation_prompt": null}
{"id": "928988ff-3230-4399-86a9-e4b59935dbbc", "solution": "import numpy as np\n\nclass EfficientGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n            if len(wolves) > 5:  # Efficiently control population size\n                wolves = sorted(wolves, key=lambda x: x['fitness'])[:5]\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "EfficientGreyWolfOptimization", "description": "Introducing a dynamic population size control mechanism to efficiently utilize resources and improve convergence speed.", "configspace": "", "generation": 42, "fitness": 0.10649817298132785, "feedback": "The algorithm EfficientGreyWolfOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11 with standard deviation 0.08.", "error": "", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.19250676831992464, 0.20107655666696977, 0.18644789682465346, 0.15396630447469595, 0.1340103358239767, 0.1488001168848172, 0.2391093373335622, 0.1904647920417336, 0.1800106504528981, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04975496595925866, 0.056664770441436696, 0.05408410051187296, 0.054159322306014834, 0.07819493488190998, 0.0535907068489323, 0.0559155317547807, 0.06611928357138186, 0.059275912097300876, 0.0380105823104242, 0.03868449924526052, 0.056369997871786315, 0.04868867892375439, 0.04368197634352311, 0.05276982149826903, 0.04139858131337293, 0.06254644750709959, 0.04376590537028846, 0.08504695158157083, 0.07829467891459374, 0.11534268827980954, 0.08922200871571073, 0.09294165621872708, 0.0882516355549755, 0.0878960410564883, 0.07527473380012484, 0.07614817481619152, 0.06947192437720862, 0.06757303208341159, 0.0635592058212957, 0.06182645114539742, 0.08177192986183346, 0.06904128233814322, 0.06292722118929306, 0.08031352152693072, 0.0846722505213725, 0.13597556042497816, 0.13701428104126878, 0.12005579953062429, 0.12011153932570418, 0.15009386338455866, 0.1477877376447948, 0.13535510068492151, 0.12886543587587151, 0.15171954795689657, 0.021707221518098008, 0.03576403683806606, 0.018437707652567026, 0.011316737895988638, 0.020909797386248874, 0.07384432053787238, 0.001341252994331299, 0.042652743937330206, 0.011008814828532887, 0.07232719171904645, 0.13486637069875274, 0.08352749088910716, 0.1315124254238681, 0.06166065873091664, 0.12989986660059172, 0.08792462260981049, 0.07508031961405726, 0.08121922256280645, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09884850873092876, 0.08032185631596367, 0.07919125361347701, 0.053014157731496536, 0.08137295881301687, 0.07854495720163412, 0.07168252162378574, 0.07314044556296484, 0.0679191851999622, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00013154231547052309, 0.00023773394914283763, 0.0028196303013675594, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005365061406132687, 0.22112564052999362, 0.2070903600784294, 0.21034453188811153, 0.21807054970133177, 0.2038876757545237, 0.22688014843789428, 0.1902248779460607, 0.24154787251300336, 0.2013028669001029, 0.05001179046006343, 0.03393815436153014, 0.04391180410824058, 0.046931000781724075, 0.04866451999417698, 0.03980862800967966, 0.0637770151483884, 0.06369928918475032, 0.06460833760378482, 0.137903407337868, 0.1322939048548063, 0.1572101237799659, 0.145868770482115, 0.14814159912875002, 0.15087844304891673, 0.14577405743627259, 0.1566447068656669, 0.13254695605954225, 0.16213843197536593, 0.16057700712788137, 0.1631280393524045, 0.19989846143089807, 0.202493778317538, 0.19895201514665362, 0.16899487957998283, 0.1612221144516146, 0.18389336344591645, 0.11938614326272945, 0.10772307945781301, 0.1240961949579974, 0.13306626163857493, 0.162294566780658, 0.1393057881080545, 0.12786088100835535, 0.1174744619244017, 0.12522014958552585, 0.23583692616777152, 0.26400264783943417, 0.2604928247143655, 0.24780174274964306, 0.2802556933318343, 0.24127316787093311, 0.2729090225965356, 0.26901545741615684, 0.27124696290456685, 0.15794725166742862, 0.1589533239522798, 0.17081440676457316, 0.1618982079211695, 0.16327936411712307, 0.1565474821317926, 0.1636735308185413, 0.1657825342536895, 0.16315507677960417, 0.1786086434024341, 0.16216999845940594, 0.1645050671474677, 0.215115190001668, 0.17240074603825362, 0.16830549013815455, 0.21926503225138916, 0.20069207771028696, 0.23399724349732287, 0.2309395426424249, 0.21124207714592536, 0.2049848065761708, 0.1805181346102559, 0.15815461544921383, 0.16543461506093393, 0.19739276369867553, 0.13061499086988482, 0.24219815599054362, 0.18019451973190703, 0.19126512863462686, 0.18252724467499826, 0.1888819941503458, 0.20041394193230389, 0.1935743209518218, 0.187581932923656, 0.1856514756197556, 0.19654825400808285, 0.08426790659877792, 0.06671393573172879, 0.061327101617311586, 0.05422362752098364, 0.06415816240153638, 0.07345422582163608, 0.06229108981738518, 0.06268515612037007, 0.05819423461774409]}, "mutation_prompt": null}
{"id": "24917216-92a8-4d07-a9a3-6861128f58d0", "solution": "import numpy as np\n\nclass AdaptiveMutationFastConvergingGreyWolfOptimization(FastConvergingGreyWolfOptimization):\n    def update_position(self, wolf, alpha, beta, delta, prev_fitness, fitness_landscape):\n        fitness_improvement = prev_fitness - wolf['fitness']\n        step_size = 1.0 - np.exp(-0.1 * fitness_improvement) * (1 + 0.2 * np.mean(fitness_landscape) / wolf['fitness')\n        a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n        # Rest of the update_position function remains the same", "name": "AdaptiveMutationFastConvergingGreyWolfOptimization", "description": "Introducing a novel adaptive mutation strategy based on the current fitness landscape to enhance convergence speed without altering the original algorithm's structure significantly.", "configspace": "", "generation": 43, "fitness": -Infinity, "feedback": "An exception occurred: SyntaxError(\"closing parenthesis ')' does not match opening parenthesis '['\", ('<string>', 6, 118, \"        step_size = 1.0 - np.exp(-0.1 * fitness_improvement) * (1 + 0.2 * np.mean(fitness_landscape) / wolf['fitness')\")).", "error": "SyntaxError(\"closing parenthesis ')' does not match opening parenthesis '['\", ('<string>', 6, 118, \"        step_size = 1.0 - np.exp(-0.1 * fitness_improvement) * (1 + 0.2 * np.mean(fitness_landscape) / wolf['fitness')\"))", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {}, "mutation_prompt": null}
{"id": "2dbe0c46-5d2d-46a5-93b2-5b6ae61e134a", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimizationImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation based on fitness\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3 and np.random.random() < 0.8:  # Probability-based population adaptation\n                new_wolf = {'position': np.random.uniform(-5.0, 5.0, self.dim),\n                            'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))}\n                wolves.append(new_wolf)\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimizationImproved", "description": "Introducing a dynamic population size adaptation strategy based on fitness to facilitate faster convergence without altering the essence of the original algorithm.", "configspace": "", "generation": 44, "fitness": 0.1760503013716892, "feedback": "The algorithm FastConvergingGreyWolfOptimizationImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.17.", "error": "", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.3126682453681007, 0.35072698029287097, 0.3251335957801179, 0.27340929576532547, 0.2978825664954122, 0.26333207965906613, 0.29410615486727043, 0.31150572043943425, 0.28238185071557986, 9.999999999998899e-05, 0.005856784397661463, 9.999999999998899e-05, 0.023009280393278986, 9.999999999998899e-05, 0.022317082730836768, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07584034884388713, 0.0920990634664226, 0.07537447388487761, 0.09801116842686974, 0.09944244842434435, 0.09085893848637572, 0.09414267978027879, 0.09803994798426396, 0.09496169436880864, 0.0856033533121956, 0.08241989491677049, 0.06958250069306027, 0.08527777031551054, 0.10304032622526627, 0.09833843645054507, 0.0904064218950954, 0.08823070632929009, 0.09145904676972172, 0.7870958696156667, 0.5521358405609009, 0.963295473246524, 0.8278100219539796, 0.9274355100669545, 0.762968995917869, 0.837879168089596, 0.8815135224286388, 0.8523567460943353, 0.17051443504137154, 0.17362923186511492, 0.1570030585213824, 0.1732521756648483, 0.16062254964334666, 0.18306996279689414, 0.18255923735770063, 0.15373104295576356, 0.15004469583543745, 0.2674473889104504, 0.20661962563392122, 0.2592465907524052, 0.190300401852736, 0.19382838208172637, 0.21017291541915994, 0.18175347151819954, 0.15972222578119255, 0.17440544484410803, 0.14950109287849933, 0.1820145294302029, 0.2235790243959278, 0.11530584854277681, 0.109962644340581, 0.09909318436322534, 0.13224042249375212, 0.12704282467486994, 0.11153533517486758, 0.20329123862335496, 0.1693973977334099, 0.24084262818659252, 0.1831653762134542, 0.22336044802496058, 0.1823780743141592, 0.2048888657909418, 0.24599441391887378, 0.22002205514197481, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.014608527612406386, 0.02597641499591241, 0.04391205976144519, 0.09791390720654747, 0.04328907873950649, 0.10347818840517553, 0.05205635960931887, 0.07533515165318572, 0.06458506320126256, 0.12191652729613522, 0.08722934807585259, 0.1108026865329843, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.027463023011238152, 0.026937132331471325, 0.03709178795474888, 0.03509879011819572, 0.017948124588820447, 0.023766003093461552, 0.02664968200337625, 0.02338407524017949, 0.02977295909424449, 0.309516178869498, 0.30565796382452093, 0.3014535262413508, 0.30158397664579073, 0.2902701876697076, 0.31328752699865936, 0.3208019801002342, 0.32032320269225023, 0.3342245930881067, 0.07388996785660862, 0.0666140328314746, 0.07490572852895583, 0.0952215927632476, 0.09674135056583222, 0.09046511513803557, 0.09370891754947985, 0.07975286170005125, 0.10283993498419786, 0.13825984317929219, 0.15870075622600854, 0.2324039028427679, 0.1705221089396498, 0.14245088070591483, 0.14898425860394815, 0.1575174921836504, 0.1864477999128148, 0.19678427875998572, 0.1898642178578498, 0.22181919448083132, 0.1940734777409301, 0.24218730397993815, 0.2522326137216139, 0.2582817530539222, 0.20115015300095762, 0.22349465439667937, 0.21319475731834414, 0.13022581786140686, 0.16938733455673194, 0.12253595099132342, 0.21874408577559012, 0.20444033136818085, 0.21008954486892184, 0.16506947043047016, 0.15614650581052814, 0.15662532470792445, 0.22613366041667382, 0.2637773525711684, 0.2497034438975173, 0.26861195273858174, 0.21790447435717575, 0.236646399486367, 0.23799394111313288, 0.26195085597739376, 0.23699774781289196, 0.16996254757893836, 0.1912689616403046, 0.17601290512715406, 0.16979471833609527, 0.17972006116634587, 0.17880864684333175, 0.17838713788644234, 0.178978127710131, 0.17593828377123533, 0.18043749982361734, 0.182592395417151, 0.17356135599017053, 0.3294512158050109, 0.13541965705840686, 0.30214208817398325, 0.11422822806105504, 0.12261141902615114, 0.41733072901640267, 0.3148545758187784, 0.1744645228030537, 0.3900730655435971, 0.08265011917728005, 0.25297191320598844, 0.17052701172134999, 0.10403059456805275, 0.16564125911333705, 0.23332419781526603, 0.18848675014305682, 0.20129334137266353, 0.19213922708740105, 0.1810785817088295, 0.18909602216117216, 0.1764735120828551, 0.1959701861381643, 0.1789114832762707, 0.19924613350772813, 0.07272201712343818, 0.09898634853941479, 0.07099139268706645, 0.08231599777047427, 0.07599427004280057, 0.08925437618230303, 0.07713324122874143, 0.07681404584846807, 0.07135951479365288]}, "mutation_prompt": null}
{"id": "5bf75845-c058-45fc-9ce7-c74c1c393cd8", "solution": "import numpy as np\n\nclass ImprovedGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n            if i % 10 == 0:  # Adaptive population size adjustment\n                wolves = sorted(wolves, key=lambda x: x['fitness'])[:5]\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "ImprovedGreyWolfOptimization", "description": "Adding a mechanism that adaptively adjusts the population size based on the fitness of wolves to accelerate convergence.", "configspace": "", "generation": 45, "fitness": 0.13395014926813903, "feedback": "The algorithm ImprovedGreyWolfOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.09.", "error": "", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.2608563375968004, 0.2641818416384569, 0.267413189967346, 0.2527861576414553, 0.23005973346305097, 0.226246569454694, 0.24930698728320544, 0.24774555507912088, 0.2760599190022176, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011061778965436142, 0.014569869668522695, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06831951680070869, 0.06561295743898077, 0.06715721101462513, 0.07628395035758673, 0.08352327831088768, 0.07043752580496443, 0.0777623683629145, 0.07912477499192061, 0.07501654474689023, 0.06604521070834779, 0.08326045633238666, 0.05049132993248351, 0.05741650129351583, 0.07072961429335922, 0.05553816729183492, 0.0688065655654424, 0.07188902434841093, 0.05050824817891153, 0.19774545021174605, 0.24405173352694898, 0.1941917487648407, 0.15353411739839917, 0.5831523490221318, 0.13138420358302483, 0.15340555391882682, 0.5128314779138061, 0.13987794797337716, 0.08361501026450535, 0.1013882302428869, 0.0815937105440544, 0.11559778836481349, 0.11584933530597408, 0.10089311427909708, 0.12387644802289766, 0.11698769219521288, 0.10874155677952946, 0.20434199670948794, 0.1841412460137023, 0.2002208638844878, 0.15309488984391684, 0.16276786626138107, 0.16527474702587897, 0.20249860584737123, 0.19652267680102764, 0.18531109890933195, 0.08350983990860261, 0.13199371912040625, 0.07980176123257066, 0.06834131453277281, 0.05917163324157049, 0.08072347524462553, 0.0906431156311468, 0.07111198105992622, 0.10112724876445534, 0.17640336464858208, 0.17726584538904588, 0.17156310129753183, 0.17023845274658211, 0.15611092686560846, 0.15462997883320329, 0.21066289366197644, 0.2273063149199862, 0.21550979115881508, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01769545984975862, 9.999999999998899e-05, 0.09811412315171042, 0.07560511376848444, 0.07413526830574524, 0.06788437765027888, 0.07644772431141755, 0.07111068877823012, 0.08699689575372016, 0.10251887955219263, 0.07218651155365585, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009750345893387191, 0.025965470598428353, 0.028459520877011868, 0.030202488017686435, 0.013996339455591311, 0.02085489996775669, 0.0024814378158675154, 0.04796059623787008, 0.013323180126902812, 0.2604799829179647, 0.24604386533480194, 0.27410505471958113, 0.2549734211133424, 0.27627396407865557, 0.2528331702034421, 0.27546177635722247, 0.2528210689812186, 0.29175391942067996, 0.07336258886729996, 0.07479195846529074, 0.06430604279810137, 0.08092581724846737, 0.08151770176329631, 0.07101531178741038, 0.07669758806460736, 0.10204255078404889, 0.0837872689790905, 0.15011970341399972, 0.1444307655446173, 0.1372396658845857, 0.1735163484147253, 0.12446404264479183, 0.13810219812810842, 0.1353557850051308, 0.1304525558970263, 0.12349060961745395, 0.21970709479210215, 0.18503805169739185, 0.21508804839115525, 0.229448682749386, 0.21610148624929093, 0.21486851114084593, 0.18697452486105137, 0.1908188360560843, 0.193048453187478, 0.15151258729308392, 0.1334684590088967, 0.14515537513747334, 0.17130377390997797, 0.1587898229521446, 0.17507212944194472, 0.13890576360512275, 0.14324514834149882, 0.1499625969001429, 0.2232568778398757, 0.2561909375227973, 0.20707932394593553, 0.2132769036059965, 0.21804202501101544, 0.22645905666282828, 0.21019566818116653, 0.20930614253555624, 0.26755965715389984, 0.16995285986981212, 0.16322207131331523, 0.17651758296437836, 0.1665363452688049, 0.18038306583125563, 0.16711203763367033, 0.16195594893554954, 0.16990112982355698, 0.1764681558199196, 0.17300291275197544, 0.17449810208072303, 0.16925160949683082, 0.2476472014082305, 0.20104843497932556, 0.18701809615905562, 0.24702348828255172, 0.26156979578255, 0.21064158039242709, 0.20325333546486246, 0.24084338382651427, 0.2733659675911364, 0.2210006043053261, 0.21420743947039433, 0.18639028046453598, 0.16021996745063594, 0.16570778008334763, 0.14536459652433986, 0.19017044260331573, 0.17725905775342343, 0.18862652843941385, 0.18725241822478256, 0.1785627615208346, 0.17760884096450258, 0.18331627767918712, 0.19520768232765395, 0.17759363158878272, 0.06099189268520511, 0.07072828384821406, 0.08908639083139347, 0.07058187162878216, 0.06801217508722879, 0.06852357576991219, 0.06627699684596611, 0.07686309855792173, 0.07691915191113874]}, "mutation_prompt": null}
{"id": "b1c9d644-245b-4579-8f3e-c713f6714572", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimization", "description": "Introducing a dynamic step size adaptation based on the fitness improvement of each wolf to enhance convergence speed.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.33103449821939324, 0.3040480949406318, 0.3461539359040635, 0.267793838862431, 0.2843969316116849, 0.2579788652640307, 0.3101385872159119, 0.2660038630830429, 0.2565912122677866, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03727747940920767, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06948116989397035, 0.08114407681055125, 0.10342990083102321, 0.08859400181634902, 0.0946155582231244, 0.09812887798405245, 0.08176519286147577, 0.09684455887673016, 0.09242528037982012, 0.06597573101815779, 0.10571133621874274, 0.06739552500802215, 0.0942054385300709, 0.09599353136195987, 0.08879216843695925, 0.10025631140984992, 0.08720666807292399, 0.08805875069231373, 0.9848018523315675, 0.8915316774981772, 0.9345264689549528, 0.7883110260487081, 0.8929883510228567, 0.7855541599393364, 0.8866503114863262, 0.9341388746780092, 0.9452182528822439, 0.14330396746291585, 0.16146368724502314, 0.14485079224495134, 0.17284344577065858, 0.16577723631939556, 0.15623283775750152, 0.1473982940114965, 0.13497839833414726, 0.15712073811617044, 0.2236846606974785, 0.24311857957954008, 0.2190569572986214, 0.17380823843846394, 0.19035851938659532, 0.19500388806733404, 0.18587275446522733, 0.17568447906810503, 0.20952542841534205, 0.15318493975060488, 0.16814716976188215, 0.11797696838796978, 0.11922586881092867, 0.08712242319663133, 0.12203081015270656, 0.12218525688950754, 0.1225678963627106, 0.10342573868844429, 0.15646523614027608, 0.16910911619199542, 0.16948557812108078, 0.1600653124257415, 0.21180495086248452, 0.19898118117418062, 0.21854811547650554, 0.2247493235454746, 0.20760635656803228, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021399270440071283, 0.05867242115284843, 0.07169694229015, 0.11720015909147119, 0.06298103292773771, 0.05197702363637002, 0.05006604696275374, 0.07281931232118932, 0.1135336882890633, 0.060079732367998795, 0.08920191197026617, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021518231367246732, 0.02638014093755303, 0.02828327903317318, 0.027482138015897717, 0.01740190476981185, 0.03872348720440966, 0.03366216337300232, 0.03477159293533949, 0.0183672558502187, 0.32098844448283803, 0.3144535596010207, 0.3020527511347463, 0.31442699311923406, 0.2767146871076611, 0.2767817147028242, 0.327857212653598, 0.30549845692593514, 0.3223802132140039, 0.08203107833550183, 0.07611606790580916, 0.05908507600733026, 0.08715322678776483, 0.10827536649180125, 0.09704270741381316, 0.08652960588484637, 0.09238939703854832, 0.08007703988549908, 0.15487947981659544, 0.2119714898259606, 0.17122107754848237, 0.13148031201107968, 0.1583467446675717, 0.1479320059738769, 0.18496351186448579, 0.15498723741066056, 0.20403333473465313, 0.22022068630660652, 0.22617170716539292, 0.20201253706684008, 0.24845596760645772, 0.25766169684727536, 0.26323374988734405, 0.20783004187583431, 0.22907748524617422, 0.21467966478440625, 0.14836528853078834, 0.1865140288800997, 0.15702995960377197, 0.219007908625384, 0.21911198530248777, 0.20083737306061844, 0.1534803065344308, 0.1670681993156763, 0.1604125298100838, 0.254903090163632, 0.2736687508861446, 0.24479217304664236, 0.28945157999979987, 0.2849774299913692, 0.2554423599657626, 0.24986782284130216, 0.23801971193128824, 0.2484408539088342, 0.17522236515332645, 0.1763697804468748, 0.17499662499676705, 0.1782165084240953, 0.17413122546255833, 0.17527486547514615, 0.1814231217620833, 0.1735518473349632, 0.17712344391275947, 0.18097343656188725, 0.17246273898918174, 0.18103555852842945, 0.3515536202739914, 0.41761905971110524, 0.3032891863193108, 0.3526464297259342, 0.17482538870191833, 0.1089920771050662, 0.3212440981235244, 0.3446039576929306, 0.3150403350803024, 0.19682264207377953, 0.22811846691488713, 0.14377776766171557, 0.10338919898019627, 0.09267659410535489, 0.25312972258697186, 0.1787941768981045, 0.17488685365308687, 0.19539397196069253, 0.1889962219148058, 0.18292682228564006, 0.17285647524571446, 0.18929720207292877, 0.18438917247426256, 0.18430896628986404, 0.0848861819838117, 0.0641329465883369, 0.09305789667303255, 0.07806169079221836, 0.08015765813005127, 0.09374862538134388, 0.07424144447088032, 0.07891411310650731, 0.09308332941118713]}, "mutation_prompt": null}
{"id": "30807bb4-0849-4dd0-bf6a-2ec637cdf8c9", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimization", "description": "Introducing a dynamic step size adaptation based on the fitness improvement of each wolf to enhance convergence speed.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.33103449821939324, 0.3040480949406318, 0.3461539359040635, 0.267793838862431, 0.2843969316116849, 0.2579788652640307, 0.3101385872159119, 0.2660038630830429, 0.2565912122677866, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03727747940920767, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06948116989397035, 0.08114407681055125, 0.10342990083102321, 0.08859400181634902, 0.0946155582231244, 0.09812887798405245, 0.08176519286147577, 0.09684455887673016, 0.09242528037982012, 0.06597573101815779, 0.10571133621874274, 0.06739552500802215, 0.0942054385300709, 0.09599353136195987, 0.08879216843695925, 0.10025631140984992, 0.08720666807292399, 0.08805875069231373, 0.9848018523315675, 0.8915316774981772, 0.9345264689549528, 0.7883110260487081, 0.8929883510228567, 0.7855541599393364, 0.8866503114863262, 0.9341388746780092, 0.9452182528822439, 0.14330396746291585, 0.16146368724502314, 0.14485079224495134, 0.17284344577065858, 0.16577723631939556, 0.15623283775750152, 0.1473982940114965, 0.13497839833414726, 0.15712073811617044, 0.2236846606974785, 0.24311857957954008, 0.2190569572986214, 0.17380823843846394, 0.19035851938659532, 0.19500388806733404, 0.18587275446522733, 0.17568447906810503, 0.20952542841534205, 0.15318493975060488, 0.16814716976188215, 0.11797696838796978, 0.11922586881092867, 0.08712242319663133, 0.12203081015270656, 0.12218525688950754, 0.1225678963627106, 0.10342573868844429, 0.15646523614027608, 0.16910911619199542, 0.16948557812108078, 0.1600653124257415, 0.21180495086248452, 0.19898118117418062, 0.21854811547650554, 0.2247493235454746, 0.20760635656803228, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021399270440071283, 0.05867242115284843, 0.07169694229015, 0.11720015909147119, 0.06298103292773771, 0.05197702363637002, 0.05006604696275374, 0.07281931232118932, 0.1135336882890633, 0.060079732367998795, 0.08920191197026617, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021518231367246732, 0.02638014093755303, 0.02828327903317318, 0.027482138015897717, 0.01740190476981185, 0.03872348720440966, 0.03366216337300232, 0.03477159293533949, 0.0183672558502187, 0.32098844448283803, 0.3144535596010207, 0.3020527511347463, 0.31442699311923406, 0.2767146871076611, 0.2767817147028242, 0.327857212653598, 0.30549845692593514, 0.3223802132140039, 0.08203107833550183, 0.07611606790580916, 0.05908507600733026, 0.08715322678776483, 0.10827536649180125, 0.09704270741381316, 0.08652960588484637, 0.09238939703854832, 0.08007703988549908, 0.15487947981659544, 0.2119714898259606, 0.17122107754848237, 0.13148031201107968, 0.1583467446675717, 0.1479320059738769, 0.18496351186448579, 0.15498723741066056, 0.20403333473465313, 0.22022068630660652, 0.22617170716539292, 0.20201253706684008, 0.24845596760645772, 0.25766169684727536, 0.26323374988734405, 0.20783004187583431, 0.22907748524617422, 0.21467966478440625, 0.14836528853078834, 0.1865140288800997, 0.15702995960377197, 0.219007908625384, 0.21911198530248777, 0.20083737306061844, 0.1534803065344308, 0.1670681993156763, 0.1604125298100838, 0.254903090163632, 0.2736687508861446, 0.24479217304664236, 0.28945157999979987, 0.2849774299913692, 0.2554423599657626, 0.24986782284130216, 0.23801971193128824, 0.2484408539088342, 0.17522236515332645, 0.1763697804468748, 0.17499662499676705, 0.1782165084240953, 0.17413122546255833, 0.17527486547514615, 0.1814231217620833, 0.1735518473349632, 0.17712344391275947, 0.18097343656188725, 0.17246273898918174, 0.18103555852842945, 0.3515536202739914, 0.41761905971110524, 0.3032891863193108, 0.3526464297259342, 0.17482538870191833, 0.1089920771050662, 0.3212440981235244, 0.3446039576929306, 0.3150403350803024, 0.19682264207377953, 0.22811846691488713, 0.14377776766171557, 0.10338919898019627, 0.09267659410535489, 0.25312972258697186, 0.1787941768981045, 0.17488685365308687, 0.19539397196069253, 0.1889962219148058, 0.18292682228564006, 0.17285647524571446, 0.18929720207292877, 0.18438917247426256, 0.18430896628986404, 0.0848861819838117, 0.0641329465883369, 0.09305789667303255, 0.07806169079221836, 0.08015765813005127, 0.09374862538134388, 0.07424144447088032, 0.07891411310650731, 0.09308332941118713]}, "mutation_prompt": null}
{"id": "9187a11d-dd4b-470e-8b05-b3b29bfcc85b", "solution": "import numpy as np\n\nclass ImprovedFastConvergingGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness, fitness_variance):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement) + 0.1 * np.sqrt(fitness_variance)  # Adaptive mutation based on fitness variance\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            fitness_values = [wolf['fitness'] for wolf in wolves]\n            fitness_variance = np.var(fitness_values)\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness, fitness_variance)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "ImprovedFastConvergingGreyWolfOptimization", "description": "Implementing an adaptive mutation mechanism based on fitness variance to enhance exploration and exploitation balance for faster convergence.", "configspace": "", "generation": 48, "fitness": 0.1201288105489444, "feedback": "The algorithm ImprovedFastConvergingGreyWolfOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.19.", "error": "", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.38799414662726317, 0.37097512567255475, 0.3861438241711148, 0.32362635653674676, 0.3392698899860559, 0.301894236313211, 0.36903575067392347, 0.3582008259632301, 0.2725102767170635, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01755058786158681, 0.016774405651688862, 0.018709481919284898, 0.0026928286460262685, 0.0023189246124393215, 0.03488146876956011, 0.012460198269197975, 0.02585035999733276, 0.015266821882359394, 0.011594641675582884, 0.0007776550482316846, 0.0045526886334397165, 0.01960752770993024, 9.999999999998899e-05, 9.999999999998899e-05, 0.014360101278391268, 0.007517039522875191, 9.999999999998899e-05, 0.8851030835060649, 0.8622376508414884, 0.9169220838150064, 0.8720503706850908, 0.8628762035531292, 0.8848335781304849, 0.8848609380765984, 0.8508117175312649, 0.7444839829744627, 0.0140485547066177, 0.010573685513229236, 0.01212181755625441, 0.0013668929057039092, 0.007188407116177187, 0.01790682155403922, 0.02147405840058003, 0.030111237269194513, 0.08988948715289913, 0.1022834671744779, 0.08565445199054589, 0.059636481596114344, 0.015599715056976993, 0.0695734090296255, 0.07756653385396062, 0.09656885779123991, 0.0935416428286413, 0.037777345916651606, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0002601143904735759, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01814032559033496, 9.999999999998899e-05, 9.999999999998899e-05, 0.035778837243037875, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1573291848746905, 0.14269482802009026, 0.1483829937031652, 0.12169372720672766, 0.1366041634434776, 0.1927171256441138, 0.38378405234369106, 0.3541182511554073, 0.2980206603914125, 0.012535832373110734, 0.005301322022664534, 0.002884973044992911, 0.02556772459971124, 0.025976818248584777, 0.020358393960143495, 0.025914859751506425, 0.02092419480724672, 0.010561690042246497, 0.14148449545856034, 0.15974933799808988, 0.13741075019927262, 0.14277011112620785, 0.16417090052237215, 0.13602992090541743, 0.13571502431192717, 0.17565039866809162, 0.13913099229128434, 0.2879246313283321, 0.18505478945936316, 0.24006846767339785, 0.27320521159211253, 0.2619199353833821, 0.286033734421825, 0.2090970224865355, 0.194211868869421, 0.19977994012571476, 0.11000531720765827, 0.09591480713467715, 0.10295840724926641, 0.09022870986695275, 0.10437073104170358, 0.07608360393688285, 0.10067027528098915, 0.058757301215909497, 0.06265577477893802, 0.2372090945151828, 0.23537883343171384, 0.3334512294568447, 0.3556083789400024, 0.22139838639065546, 0.27029569100088635, 0.26561291058060255, 0.24126614248246803, 0.265567450651953, 0.13020797621036218, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09504174446788727, 9.999999999998899e-05, 0.13464722393971806, 0.18374995103663738, 0.16793887154820586, 0.15501193981058792, 0.16904569562096416, 0.12100107246817371, 0.11093267939799056, 0.10805752897304433, 0.13214018098109936, 0.16023614587616253, 0.14931922412658782, 0.11068125302438314, 0.25176359375717006, 0.08735323155052133, 0.11596727822764663, 0.12947203631479065, 0.10543962780450433, 0.1000644589396601, 0.0939199511057226, 0.183167873862219, 0.19556213948433965, 0.17739516008941592, 0.1843117947975348, 0.1829574631211538, 0.19570825207345532, 0.18828942922426506, 0.1916003043893454, 0.18523086455615267, 0.0826616364386944, 0.05879594736120175, 0.07085046628223901, 0.0720031136983833, 0.07981786640824506, 0.07744304827907433, 0.08410384458123465, 0.06997442214322613, 0.09103949509295906]}, "mutation_prompt": null}
{"id": "c980cffd-73c6-4a42-ad40-86365046fe51", "solution": "import numpy as np\n\nclass ImprovedGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  \n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            fitness_values = [wolf['fitness'] for wolf in wolves]\n            fitness_variance = np.var(fitness_values)\n            if len(wolves) < 10 and fitness_variance > 1e-5:  \n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "ImprovedGreyWolfOptimization", "description": "Introducing a novel dynamic population size adaptation strategy based on fitness variance to enhance convergence speed.", "configspace": "", "generation": 49, "fitness": 0.1102415409479078, "feedback": "The algorithm ImprovedGreyWolfOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11 with standard deviation 0.08.", "error": "", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.2313708829640122, 0.22282620820553423, 0.27964279478277365, 0.10304703729471698, 0.2072394690600643, 0.2150439247017627, 0.28085282792952393, 0.08605004353504064, 0.27070058811712205, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05778202223391926, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06297708710307048, 0.06121312021730485, 0.0455413770084222, 0.05614246140974888, 0.05371943720229688, 0.054080079592051744, 0.04973388877171181, 0.05139054114099728, 0.09128103881606697, 0.05040221043231319, 0.0148154056214016, 0.03956411390367398, 0.08031503443087773, 0.054813288984245645, 0.06911224130732785, 0.010106571630427053, 0.06122973608404281, 0.047902631207882074, 0.07976934280019943, 0.11262272013386865, 0.1279987273203873, 0.0674094676518936, 0.11216225444644456, 0.051070165892410424, 0.03932808224900741, 0.09282567157370991, 0.05011492206842849, 0.06310326633765617, 0.06260363009567604, 0.036545358042537224, 0.05145683449916083, 0.11003023817255053, 0.10886243032244658, 0.0603708797853062, 9.999999999998899e-05, 0.03940869582448325, 0.14209358264942862, 0.15790310008447928, 0.14164049596574457, 0.12169995076535467, 0.11094716291257922, 0.15412200200225035, 0.08853723724845908, 0.1216073124781979, 0.13109300428140036, 0.10941861878176873, 0.0688803385308161, 0.03993917527967894, 0.036102958783554406, 9.999999999998899e-05, 9.999999999998899e-05, 0.06838047638995615, 0.03625763504168977, 0.11419584679662653, 0.1604529730614861, 0.23228174088678943, 0.1393104950873063, 0.1609551127993022, 0.15856207850935466, 0.16950901426884157, 0.24032554222330937, 0.13570764086746712, 0.2215167154841029, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.039456021659346696, 0.11156114428083597, 0.11381066674434392, 0.03315490653344555, 0.06726319457258778, 0.06355631031814224, 0.06466803629534534, 0.08622418802847076, 0.09404036574448693, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02197811378456449, 0.02527584246504122, 0.020371988570229593, 0.02098722326291913, 9.999999999998899e-05, 9.999999999998899e-05, 0.016755976648976878, 0.00944904401488822, 9.999999999998899e-05, 0.1984744028894102, 0.2707499089241774, 0.28466284508984285, 0.23103948852598943, 0.22955006413508028, 0.24806591423580715, 0.18737048482669116, 0.16779096482170985, 0.2545598080412985, 0.0659654895276719, 0.06717893025822663, 0.03431678385585257, 0.03834345271576134, 0.02850672649587782, 0.06257042401225676, 0.05578685202543443, 0.06802344281525274, 0.07400409302609656, 0.1230148783644609, 0.13761844705250437, 0.13229181890606834, 0.12400696463203331, 0.10142149670775036, 0.15699399798038793, 0.11360473427309115, 0.0985044063239573, 0.17371170257380075, 0.16636842841886934, 0.16708279683994298, 0.17605279142106045, 0.2409231406755522, 0.2327314067958287, 0.18063137254966932, 0.18585033565039732, 0.16366185894251717, 0.12361476812581207, 0.07816130176858427, 0.12993294244784082, 0.13606262603461872, 0.14366147557276854, 0.17183394179687383, 0.12996151544907786, 0.10456048520863426, 0.11556355698303034, 0.14409326986733162, 0.3428921291956467, 0.2785134996414762, 0.3467417531319712, 0.272445377253685, 0.27120090749593184, 0.2780501126056476, 0.32919921220716775, 0.298023767455045, 0.34719978301653887, 0.1752630834173582, 0.16166835095485532, 0.17680767612262172, 0.17331909962176983, 0.16883420771163404, 0.16398971256934636, 0.17409917475920178, 0.18053823444219375, 0.16628088729276425, 0.10970317223161141, 0.1263712341556218, 0.1118319781261169, 0.16167039765345836, 0.16777114283916494, 0.11342358574451539, 0.10429306474718103, 0.23070370211689106, 0.1636243953712483, 0.21353939583292603, 0.20902557531709598, 0.18439568833381736, 0.09666570175639644, 0.06325564006323925, 0.2660697705723868, 0.09473815373286976, 0.10302299762304301, 0.11232651088603418, 0.18223398931687285, 0.17942767869206344, 0.1756013155191476, 0.16772239088441254, 0.1881797699782798, 0.18484239675730518, 0.16960046482228097, 0.18444120835089173, 0.1886092915821702, 0.06048606607719742, 0.056280418521624576, 0.05987439438881559, 0.052610124091727495, 0.05637895483634803, 0.05791912385701048, 0.05546169429468373, 0.054417833216595324, 0.053938130969217624]}, "mutation_prompt": null}
{"id": "9ea59711-3915-40ed-a3c5-c47d20198c84", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimization", "description": "Introducing a dynamic step size adaptation based on the fitness improvement of each wolf to enhance convergence speed.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.33103449821939324, 0.3040480949406318, 0.3461539359040635, 0.267793838862431, 0.2843969316116849, 0.2579788652640307, 0.3101385872159119, 0.2660038630830429, 0.2565912122677866, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03727747940920767, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06948116989397035, 0.08114407681055125, 0.10342990083102321, 0.08859400181634902, 0.0946155582231244, 0.09812887798405245, 0.08176519286147577, 0.09684455887673016, 0.09242528037982012, 0.06597573101815779, 0.10571133621874274, 0.06739552500802215, 0.0942054385300709, 0.09599353136195987, 0.08879216843695925, 0.10025631140984992, 0.08720666807292399, 0.08805875069231373, 0.9848018523315675, 0.8915316774981772, 0.9345264689549528, 0.7883110260487081, 0.8929883510228567, 0.7855541599393364, 0.8866503114863262, 0.9341388746780092, 0.9452182528822439, 0.14330396746291585, 0.16146368724502314, 0.14485079224495134, 0.17284344577065858, 0.16577723631939556, 0.15623283775750152, 0.1473982940114965, 0.13497839833414726, 0.15712073811617044, 0.2236846606974785, 0.24311857957954008, 0.2190569572986214, 0.17380823843846394, 0.19035851938659532, 0.19500388806733404, 0.18587275446522733, 0.17568447906810503, 0.20952542841534205, 0.15318493975060488, 0.16814716976188215, 0.11797696838796978, 0.11922586881092867, 0.08712242319663133, 0.12203081015270656, 0.12218525688950754, 0.1225678963627106, 0.10342573868844429, 0.15646523614027608, 0.16910911619199542, 0.16948557812108078, 0.1600653124257415, 0.21180495086248452, 0.19898118117418062, 0.21854811547650554, 0.2247493235454746, 0.20760635656803228, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021399270440071283, 0.05867242115284843, 0.07169694229015, 0.11720015909147119, 0.06298103292773771, 0.05197702363637002, 0.05006604696275374, 0.07281931232118932, 0.1135336882890633, 0.060079732367998795, 0.08920191197026617, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021518231367246732, 0.02638014093755303, 0.02828327903317318, 0.027482138015897717, 0.01740190476981185, 0.03872348720440966, 0.03366216337300232, 0.03477159293533949, 0.0183672558502187, 0.32098844448283803, 0.3144535596010207, 0.3020527511347463, 0.31442699311923406, 0.2767146871076611, 0.2767817147028242, 0.327857212653598, 0.30549845692593514, 0.3223802132140039, 0.08203107833550183, 0.07611606790580916, 0.05908507600733026, 0.08715322678776483, 0.10827536649180125, 0.09704270741381316, 0.08652960588484637, 0.09238939703854832, 0.08007703988549908, 0.15487947981659544, 0.2119714898259606, 0.17122107754848237, 0.13148031201107968, 0.1583467446675717, 0.1479320059738769, 0.18496351186448579, 0.15498723741066056, 0.20403333473465313, 0.22022068630660652, 0.22617170716539292, 0.20201253706684008, 0.24845596760645772, 0.25766169684727536, 0.26323374988734405, 0.20783004187583431, 0.22907748524617422, 0.21467966478440625, 0.14836528853078834, 0.1865140288800997, 0.15702995960377197, 0.219007908625384, 0.21911198530248777, 0.20083737306061844, 0.1534803065344308, 0.1670681993156763, 0.1604125298100838, 0.254903090163632, 0.2736687508861446, 0.24479217304664236, 0.28945157999979987, 0.2849774299913692, 0.2554423599657626, 0.24986782284130216, 0.23801971193128824, 0.2484408539088342, 0.17522236515332645, 0.1763697804468748, 0.17499662499676705, 0.1782165084240953, 0.17413122546255833, 0.17527486547514615, 0.1814231217620833, 0.1735518473349632, 0.17712344391275947, 0.18097343656188725, 0.17246273898918174, 0.18103555852842945, 0.3515536202739914, 0.41761905971110524, 0.3032891863193108, 0.3526464297259342, 0.17482538870191833, 0.1089920771050662, 0.3212440981235244, 0.3446039576929306, 0.3150403350803024, 0.19682264207377953, 0.22811846691488713, 0.14377776766171557, 0.10338919898019627, 0.09267659410535489, 0.25312972258697186, 0.1787941768981045, 0.17488685365308687, 0.19539397196069253, 0.1889962219148058, 0.18292682228564006, 0.17285647524571446, 0.18929720207292877, 0.18438917247426256, 0.18430896628986404, 0.0848861819838117, 0.0641329465883369, 0.09305789667303255, 0.07806169079221836, 0.08015765813005127, 0.09374862538134388, 0.07424144447088032, 0.07891411310650731, 0.09308332941118713]}, "mutation_prompt": null}
{"id": "d96b44b5-b49f-47d9-8607-58438db6eb44", "solution": "# import numpy as np\n\nclass ImprovedGreyWolfOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            # Adaptive mutation based on fitness variance\n            mutation_scale = 0.1 + 0.4 * np.std([alpha['fitness'], beta['fitness'], delta['fitness']])\n            new_position += mutation_scale * np.random.normal(0, 1, self.dim)\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n            if i < self.budget - 3:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "ImprovedGreyWolfOptimization", "description": "Enhancing exploration-exploitation balance by incorporating a novel adaptive mutation strategy based on fitness variance.", "configspace": "", "generation": 51, "fitness": 0.12161005715316707, "feedback": "The algorithm ImprovedGreyWolfOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.20.", "error": "", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.3458341738000873, 0.2780328639306968, 0.2980764973104819, 0.2641173908904664, 0.2561353113079151, 0.24780257936254002, 0.23692373785664245, 0.25087215432433185, 0.24734514299544075, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.020498520281901578, 0.04482224703130011, 0.0247484322439675, 0.027506822458959523, 0.023123619977094667, 0.032038850094947, 0.029479759325895194, 0.029281448388217224, 0.02382436514476871, 0.0002063141284365244, 0.014972384600521083, 0.004068639481179748, 0.01960752770993024, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0003771947005205556, 9.999999999998899e-05, 0.9737126131692397, 0.9831862526966328, 0.9937888302094384, 0.9768646749647426, 0.97707370950242, 0.9967554421925316, 0.9700562355455796, 0.9798665657207187, 0.9853396687681826, 0.03098465217032975, 0.04328457455094181, 0.03148413759238933, 0.026152336453795, 0.03398143115341723, 0.06872557737163953, 0.000946683895474032, 0.00468335604350123, 0.023239840644139975, 0.10029430247433702, 0.09006622758697902, 0.07488264831669456, 0.07407666238522792, 0.06904319028168016, 0.05690982208192985, 0.08285092160033214, 0.0955534027181324, 0.09815453007013619, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02854482993987384, 0.010263083662206407, 0.005771689141976122, 0.008726944093080835, 0.04194856793131807, 0.030892932498492343, 9.999999999998899e-05, 0.001875328578564206, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.3040963861515191, 0.27955298050586275, 0.28949503916034103, 0.28862992803616994, 0.2916789484020871, 0.27733407051477854, 0.32118853170733785, 0.32076080030497367, 0.3088216894493042, 0.03860990583362345, 0.03798962757982505, 0.042410426679409974, 0.030362383908906332, 0.011587319351349823, 0.02613476954443994, 0.025705288800962123, 0.014550425764010111, 0.019306497199258033, 0.14206131331424054, 0.13823247248552328, 0.1414019153252284, 0.14019406347483931, 0.133580075483964, 0.1458532948610849, 0.12096668254335696, 0.13467640638084, 0.12685464175619765, 0.20667235651310734, 0.20763729677878395, 0.20540186895404344, 0.2328677304670328, 0.23507138730893995, 0.2211736809099052, 0.23073975685596526, 0.21377096607576607, 0.2027310129973926, 0.09408095600170219, 0.09453568139055679, 0.0996697748209322, 0.0963572489701694, 0.09404652258821244, 0.12173346298169363, 0.10902552143658051, 0.09757449595353374, 0.10675406807240673, 0.1857770414772173, 0.194618797843231, 0.19321876515659964, 0.16547321365357526, 0.16388358834438854, 0.18442062912772805, 0.1583029269953664, 0.1753079341749606, 0.18529084153635578, 9.999999999998899e-05, 9.999999999998899e-05, 0.08767950201818164, 9.999999999998899e-05, 9.999999999998899e-05, 0.1372462751322362, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13030270790825216, 0.1188945963845639, 0.13859804712978419, 0.14837298646572783, 0.16317001461199654, 0.15734622028637169, 0.14998011305257386, 0.1908440700126871, 0.15029944043614107, 0.11946016012186533, 0.15832290836264695, 0.16564971579417875, 0.14084123137429738, 0.12545966407183184, 0.12895687374320208, 0.18683924301597798, 0.17497405094207474, 0.15891708292480367, 0.19010459276719316, 0.1992378640161866, 0.18316757116176763, 0.1749079149961026, 0.17188220354341976, 0.17947875174088035, 0.19926895195786376, 0.18018561671960054, 0.17570847437871084, 0.04083999018726481, 0.03943948149490284, 0.04698516969764133, 0.042597882964296896, 0.03666428162851476, 0.03534466832347949, 0.036790125745505775, 0.04198762841701187, 0.03647521629645112]}, "mutation_prompt": null}
{"id": "dd25d9fb-abe2-4b73-9cfc-36392784878a", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimizationImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n        fitness_values = [wolf['fitness'] for wolf in wolves]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation based on fitness variance\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            variance = np.var(fitness_values)\n            if variance < 0.1:\n                wolves.pop(-1)  # Remove a wolf if variance is low\n            else:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n                fitness_values.append(wolves[-1]['fitness'])\n\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimizationImproved", "description": "Introducing a dynamic population size adjustment based on the fitness variance of wolves to enhance exploration-exploitation balance.", "configspace": "", "generation": 52, "fitness": 0.18158301383710676, "feedback": "The algorithm FastConvergingGreyWolfOptimizationImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.18.", "error": "", "parent_id": "5ee029ec-d68e-436b-bb5a-b7a84d07e3f5", "metadata": {"aucs": [0.31019831141539145, 0.3764066636662309, 0.4334966776700264, 0.26713514007086925, 0.25507820785465996, 0.2681188390283801, 0.2892993128391528, 0.3229024270581763, 0.28832201069746977, 9.999999999998899e-05, 9.999999999998899e-05, 0.0069153618232769, 0.03669780389509836, 9.999999999998899e-05, 0.06693702790938882, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0860188314779391, 0.07975052295137486, 0.09680544286784387, 0.09039875395130803, 0.08663184037214322, 0.08949739478774588, 0.09211128480155639, 0.09287701992081021, 0.09049447229117791, 0.08368761666251356, 0.07016437125797803, 0.05403912085066842, 0.0977314861276729, 0.0886164045880452, 0.07812267799238382, 0.08641977762476816, 0.08663302108878657, 0.08256382633367809, 0.9650397445306794, 0.9360310360809561, 0.8570754906597035, 0.9126983344662438, 0.8701120650453957, 0.8898720819465875, 0.9373851276455081, 0.8993159838152265, 0.7309130580620814, 0.13468242051665913, 0.13021057173447537, 0.15072692651804287, 0.14883383287941976, 0.1793112375678364, 0.19417563539520755, 0.14380745635823444, 0.149101472565203, 0.1331552719434187, 0.27110394228620227, 0.21283657505902764, 0.15294046994036303, 0.21018186641511982, 0.16894434964533556, 0.2249026050911309, 0.1753974291383511, 0.2001839366227256, 0.2071346496141847, 0.16437231783074657, 0.1671935978365955, 0.14937354759596166, 0.1007875229063695, 0.02810683712624884, 0.05524134769040134, 0.09664801796264677, 0.12018763355788864, 0.15804140741081396, 0.20420418041535737, 0.24523287193829435, 0.19750199961429948, 0.16472584247904176, 0.1626577294771856, 0.1889154205124861, 0.233807292584022, 0.2193640504538622, 0.2542830468625289, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06034943824513084, 0.06879806548936973, 0.034398887133356815, 0.04444130629251153, 0.06646605716341947, 0.08988919257911943, 0.06171697356195871, 0.04959969936769926, 0.06038533989433559, 0.04567631537509331, 0.09386798965922538, 0.0660994441900764, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03531215560371548, 0.0435265356972806, 0.031330014766869474, 0.04646902621649551, 0.014185550917560796, 0.016858509147832046, 0.03530031899262853, 0.029157295560009677, 0.021134526181834867, 0.3003057357964265, 0.307305229919392, 0.3167824549995434, 0.3012517275636658, 0.30750040675440127, 0.2739260438630524, 0.33369458215309267, 0.3387768276940164, 0.32096154007823186, 0.08871716436744614, 0.0656668573354664, 0.08714174289872922, 0.10104118320269462, 0.08715332730511616, 0.10693061204795218, 0.08382990999891604, 0.09216974157621194, 0.09900280816393259, 0.17463389743160185, 0.1433739069039588, 0.1488358376710115, 0.18640239901946265, 0.17283018160117258, 0.18266193539283104, 0.2060020957893507, 0.16160218068185173, 0.1897863599894143, 0.21716949864108526, 0.21103387579845112, 0.2229300687745862, 0.269049007830812, 0.26004889648708174, 0.25661648398365255, 0.2083764134896241, 0.22107520826287586, 0.21958749546522205, 0.16868770346725903, 0.15947584767033918, 0.1493547022787297, 0.19635899279989855, 0.2064479010187008, 0.19689652923315093, 0.14528210415476495, 0.1565621683834656, 0.14577574229822754, 0.27718558121498504, 0.24976275932713132, 0.23815193508092025, 0.24151767194177787, 0.26017458948918837, 0.2363100719703879, 0.24116091481284918, 0.23994474761811446, 0.26238170723058485, 0.17536522317053294, 0.17434818086482706, 0.17890065814368827, 0.1815408953515586, 0.17377596183290767, 0.17976074808455256, 0.1754619385396332, 0.18043649435650444, 0.18204438946498425, 0.1830828514379601, 0.14073424871104567, 0.1694382472749527, 0.36354004489552905, 0.2917228996158244, 0.3153175252827134, 0.1276472776597266, 0.18206913993881668, 0.4175510880280693, 0.4015654263981109, 0.25840570900172977, 0.3336246107099333, 0.2549961612139524, 0.15164179172460024, 0.2524634625774479, 0.32371089037372436, 0.16893501147558576, 0.29597384611707944, 0.1806619354232989, 0.17982748843418372, 0.19693434660230635, 0.18130763129289373, 0.1763784219087916, 0.19866331812670635, 0.18384760210163653, 0.18733202926576786, 0.19348566994973493, 0.07996660296428382, 0.07296840625395584, 0.0751997901037823, 0.08900294289032396, 0.06520753154297276, 0.09683869631093445, 0.06906253717176802, 0.08584189952206234, 0.07189158007074492]}, "mutation_prompt": null}
{"id": "8a634b3b-60c3-4f3f-9730-5705d37657a0", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimizationImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.15 * fitness_improvement)  # Enhanced dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size  # Adjusted step size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n        fitness_values = [wolf['fitness'] for wolf in wolves]\n\n        for i in range(2, self.budget - 3, 2):  \n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            variance = np.var(fitness_values)\n            if variance < 0.1:\n                wolves.pop(-1)  \n            else:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n                fitness_values.append(wolves[-1]['fitness'])\n\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimizationImproved", "description": "Enhancing convergence speed by introducing a dynamic adaptation of step size based on fitness improvement for each wolf.", "configspace": "", "generation": 53, "fitness": 0.18158301383710676, "feedback": "The algorithm FastConvergingGreyWolfOptimizationImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.18.", "error": "", "parent_id": "dd25d9fb-abe2-4b73-9cfc-36392784878a", "metadata": {"aucs": [0.31019831141539145, 0.3764066636662309, 0.4334966776700264, 0.26713514007086925, 0.25507820785465996, 0.2681188390283801, 0.2892993128391528, 0.3229024270581763, 0.28832201069746977, 9.999999999998899e-05, 9.999999999998899e-05, 0.0069153618232769, 0.03669780389509836, 9.999999999998899e-05, 0.06693702790938882, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0860188314779391, 0.07975052295137486, 0.09680544286784387, 0.09039875395130803, 0.08663184037214322, 0.08949739478774588, 0.09211128480155639, 0.09287701992081021, 0.09049447229117791, 0.08368761666251356, 0.07016437125797803, 0.05403912085066842, 0.0977314861276729, 0.0886164045880452, 0.07812267799238382, 0.08641977762476816, 0.08663302108878657, 0.08256382633367809, 0.9650397445306794, 0.9360310360809561, 0.8570754906597035, 0.9126983344662438, 0.8701120650453957, 0.8898720819465875, 0.9373851276455081, 0.8993159838152265, 0.7309130580620814, 0.13468242051665913, 0.13021057173447537, 0.15072692651804287, 0.14883383287941976, 0.1793112375678364, 0.19417563539520755, 0.14380745635823444, 0.149101472565203, 0.1331552719434187, 0.27110394228620227, 0.21283657505902764, 0.15294046994036303, 0.21018186641511982, 0.16894434964533556, 0.2249026050911309, 0.1753974291383511, 0.2001839366227256, 0.2071346496141847, 0.16437231783074657, 0.1671935978365955, 0.14937354759596166, 0.1007875229063695, 0.02810683712624884, 0.05524134769040134, 0.09664801796264677, 0.12018763355788864, 0.15804140741081396, 0.20420418041535737, 0.24523287193829435, 0.19750199961429948, 0.16472584247904176, 0.1626577294771856, 0.1889154205124861, 0.233807292584022, 0.2193640504538622, 0.2542830468625289, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06034943824513084, 0.06879806548936973, 0.034398887133356815, 0.04444130629251153, 0.06646605716341947, 0.08988919257911943, 0.06171697356195871, 0.04959969936769926, 0.06038533989433559, 0.04567631537509331, 0.09386798965922538, 0.0660994441900764, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03531215560371548, 0.0435265356972806, 0.031330014766869474, 0.04646902621649551, 0.014185550917560796, 0.016858509147832046, 0.03530031899262853, 0.029157295560009677, 0.021134526181834867, 0.3003057357964265, 0.307305229919392, 0.3167824549995434, 0.3012517275636658, 0.30750040675440127, 0.2739260438630524, 0.33369458215309267, 0.3387768276940164, 0.32096154007823186, 0.08871716436744614, 0.0656668573354664, 0.08714174289872922, 0.10104118320269462, 0.08715332730511616, 0.10693061204795218, 0.08382990999891604, 0.09216974157621194, 0.09900280816393259, 0.17463389743160185, 0.1433739069039588, 0.1488358376710115, 0.18640239901946265, 0.17283018160117258, 0.18266193539283104, 0.2060020957893507, 0.16160218068185173, 0.1897863599894143, 0.21716949864108526, 0.21103387579845112, 0.2229300687745862, 0.269049007830812, 0.26004889648708174, 0.25661648398365255, 0.2083764134896241, 0.22107520826287586, 0.21958749546522205, 0.16868770346725903, 0.15947584767033918, 0.1493547022787297, 0.19635899279989855, 0.2064479010187008, 0.19689652923315093, 0.14528210415476495, 0.1565621683834656, 0.14577574229822754, 0.27718558121498504, 0.24976275932713132, 0.23815193508092025, 0.24151767194177787, 0.26017458948918837, 0.2363100719703879, 0.24116091481284918, 0.23994474761811446, 0.26238170723058485, 0.17536522317053294, 0.17434818086482706, 0.17890065814368827, 0.1815408953515586, 0.17377596183290767, 0.17976074808455256, 0.1754619385396332, 0.18043649435650444, 0.18204438946498425, 0.1830828514379601, 0.14073424871104567, 0.1694382472749527, 0.36354004489552905, 0.2917228996158244, 0.3153175252827134, 0.1276472776597266, 0.18206913993881668, 0.4175510880280693, 0.4015654263981109, 0.25840570900172977, 0.3336246107099333, 0.2549961612139524, 0.15164179172460024, 0.2524634625774479, 0.32371089037372436, 0.16893501147558576, 0.29597384611707944, 0.1806619354232989, 0.17982748843418372, 0.19693434660230635, 0.18130763129289373, 0.1763784219087916, 0.19866331812670635, 0.18384760210163653, 0.18733202926576786, 0.19348566994973493, 0.07996660296428382, 0.07296840625395584, 0.0751997901037823, 0.08900294289032396, 0.06520753154297276, 0.09683869631093445, 0.06906253717176802, 0.08584189952206234, 0.07189158007074492]}, "mutation_prompt": null}
{"id": "a2688f7d-b213-4de9-92ac-9ccab587e4f5", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimizationImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            mutation_rate = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic mutation rate based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * mutation_rate\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n        fitness_values = [wolf['fitness'] for wolf in wolves]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation based on fitness variance\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            variance = np.var(fitness_values)\n            if variance < 0.1:\n                wolves.pop(-1)  # Remove a wolf if variance is low\n            else:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n                fitness_values.append(wolves[-1]['fitness'])\n\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimizationImproved", "description": "Introducing a dynamic mutation strategy based on the fitness variance to enhance exploration and exploitation balance, leading to faster convergence.", "configspace": "", "generation": 54, "fitness": 0.18158301383710676, "feedback": "The algorithm FastConvergingGreyWolfOptimizationImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.18.", "error": "", "parent_id": "dd25d9fb-abe2-4b73-9cfc-36392784878a", "metadata": {"aucs": [0.31019831141539145, 0.3764066636662309, 0.4334966776700264, 0.26713514007086925, 0.25507820785465996, 0.2681188390283801, 0.2892993128391528, 0.3229024270581763, 0.28832201069746977, 9.999999999998899e-05, 9.999999999998899e-05, 0.0069153618232769, 0.03669780389509836, 9.999999999998899e-05, 0.06693702790938882, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0860188314779391, 0.07975052295137486, 0.09680544286784387, 0.09039875395130803, 0.08663184037214322, 0.08949739478774588, 0.09211128480155639, 0.09287701992081021, 0.09049447229117791, 0.08368761666251356, 0.07016437125797803, 0.05403912085066842, 0.0977314861276729, 0.0886164045880452, 0.07812267799238382, 0.08641977762476816, 0.08663302108878657, 0.08256382633367809, 0.9650397445306794, 0.9360310360809561, 0.8570754906597035, 0.9126983344662438, 0.8701120650453957, 0.8898720819465875, 0.9373851276455081, 0.8993159838152265, 0.7309130580620814, 0.13468242051665913, 0.13021057173447537, 0.15072692651804287, 0.14883383287941976, 0.1793112375678364, 0.19417563539520755, 0.14380745635823444, 0.149101472565203, 0.1331552719434187, 0.27110394228620227, 0.21283657505902764, 0.15294046994036303, 0.21018186641511982, 0.16894434964533556, 0.2249026050911309, 0.1753974291383511, 0.2001839366227256, 0.2071346496141847, 0.16437231783074657, 0.1671935978365955, 0.14937354759596166, 0.1007875229063695, 0.02810683712624884, 0.05524134769040134, 0.09664801796264677, 0.12018763355788864, 0.15804140741081396, 0.20420418041535737, 0.24523287193829435, 0.19750199961429948, 0.16472584247904176, 0.1626577294771856, 0.1889154205124861, 0.233807292584022, 0.2193640504538622, 0.2542830468625289, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06034943824513084, 0.06879806548936973, 0.034398887133356815, 0.04444130629251153, 0.06646605716341947, 0.08988919257911943, 0.06171697356195871, 0.04959969936769926, 0.06038533989433559, 0.04567631537509331, 0.09386798965922538, 0.0660994441900764, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03531215560371548, 0.0435265356972806, 0.031330014766869474, 0.04646902621649551, 0.014185550917560796, 0.016858509147832046, 0.03530031899262853, 0.029157295560009677, 0.021134526181834867, 0.3003057357964265, 0.307305229919392, 0.3167824549995434, 0.3012517275636658, 0.30750040675440127, 0.2739260438630524, 0.33369458215309267, 0.3387768276940164, 0.32096154007823186, 0.08871716436744614, 0.0656668573354664, 0.08714174289872922, 0.10104118320269462, 0.08715332730511616, 0.10693061204795218, 0.08382990999891604, 0.09216974157621194, 0.09900280816393259, 0.17463389743160185, 0.1433739069039588, 0.1488358376710115, 0.18640239901946265, 0.17283018160117258, 0.18266193539283104, 0.2060020957893507, 0.16160218068185173, 0.1897863599894143, 0.21716949864108526, 0.21103387579845112, 0.2229300687745862, 0.269049007830812, 0.26004889648708174, 0.25661648398365255, 0.2083764134896241, 0.22107520826287586, 0.21958749546522205, 0.16868770346725903, 0.15947584767033918, 0.1493547022787297, 0.19635899279989855, 0.2064479010187008, 0.19689652923315093, 0.14528210415476495, 0.1565621683834656, 0.14577574229822754, 0.27718558121498504, 0.24976275932713132, 0.23815193508092025, 0.24151767194177787, 0.26017458948918837, 0.2363100719703879, 0.24116091481284918, 0.23994474761811446, 0.26238170723058485, 0.17536522317053294, 0.17434818086482706, 0.17890065814368827, 0.1815408953515586, 0.17377596183290767, 0.17976074808455256, 0.1754619385396332, 0.18043649435650444, 0.18204438946498425, 0.1830828514379601, 0.14073424871104567, 0.1694382472749527, 0.36354004489552905, 0.2917228996158244, 0.3153175252827134, 0.1276472776597266, 0.18206913993881668, 0.4175510880280693, 0.4015654263981109, 0.25840570900172977, 0.3336246107099333, 0.2549961612139524, 0.15164179172460024, 0.2524634625774479, 0.32371089037372436, 0.16893501147558576, 0.29597384611707944, 0.1806619354232989, 0.17982748843418372, 0.19693434660230635, 0.18130763129289373, 0.1763784219087916, 0.19866331812670635, 0.18384760210163653, 0.18733202926576786, 0.19348566994973493, 0.07996660296428382, 0.07296840625395584, 0.0751997901037823, 0.08900294289032396, 0.06520753154297276, 0.09683869631093445, 0.06906253717176802, 0.08584189952206234, 0.07189158007074492]}, "mutation_prompt": null}
{"id": "eb7b815e-5946-4b27-8c7a-491a7ca833e7", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimizationImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness, fitness_improvement):\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement with dynamic mutation\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n        fitness_values = [wolf['fitness'] for wolf in wolves]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation based on fitness variance\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            variance = np.var(fitness_values)\n            if variance < 0.1:\n                wolves.pop(-1)  # Remove a wolf if variance is low\n            else:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n                fitness_values.append(wolves[-1]['fitness'])\n\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                fitness_improvement = prev_fitness - wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness, fitness_improvement)\n                wolf['fitness'] = func(wolf['position'])\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimizationImproved", "description": "Incorporating a dynamic mutation strategy based on fitness values to enhance exploration while ensuring convergence improvement.", "configspace": "", "generation": 55, "fitness": 0.18158301383710676, "feedback": "The algorithm FastConvergingGreyWolfOptimizationImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.18.", "error": "", "parent_id": "dd25d9fb-abe2-4b73-9cfc-36392784878a", "metadata": {"aucs": [0.31019831141539145, 0.3764066636662309, 0.4334966776700264, 0.26713514007086925, 0.25507820785465996, 0.2681188390283801, 0.2892993128391528, 0.3229024270581763, 0.28832201069746977, 9.999999999998899e-05, 9.999999999998899e-05, 0.0069153618232769, 0.03669780389509836, 9.999999999998899e-05, 0.06693702790938882, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0860188314779391, 0.07975052295137486, 0.09680544286784387, 0.09039875395130803, 0.08663184037214322, 0.08949739478774588, 0.09211128480155639, 0.09287701992081021, 0.09049447229117791, 0.08368761666251356, 0.07016437125797803, 0.05403912085066842, 0.0977314861276729, 0.0886164045880452, 0.07812267799238382, 0.08641977762476816, 0.08663302108878657, 0.08256382633367809, 0.9650397445306794, 0.9360310360809561, 0.8570754906597035, 0.9126983344662438, 0.8701120650453957, 0.8898720819465875, 0.9373851276455081, 0.8993159838152265, 0.7309130580620814, 0.13468242051665913, 0.13021057173447537, 0.15072692651804287, 0.14883383287941976, 0.1793112375678364, 0.19417563539520755, 0.14380745635823444, 0.149101472565203, 0.1331552719434187, 0.27110394228620227, 0.21283657505902764, 0.15294046994036303, 0.21018186641511982, 0.16894434964533556, 0.2249026050911309, 0.1753974291383511, 0.2001839366227256, 0.2071346496141847, 0.16437231783074657, 0.1671935978365955, 0.14937354759596166, 0.1007875229063695, 0.02810683712624884, 0.05524134769040134, 0.09664801796264677, 0.12018763355788864, 0.15804140741081396, 0.20420418041535737, 0.24523287193829435, 0.19750199961429948, 0.16472584247904176, 0.1626577294771856, 0.1889154205124861, 0.233807292584022, 0.2193640504538622, 0.2542830468625289, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06034943824513084, 0.06879806548936973, 0.034398887133356815, 0.04444130629251153, 0.06646605716341947, 0.08988919257911943, 0.06171697356195871, 0.04959969936769926, 0.06038533989433559, 0.04567631537509331, 0.09386798965922538, 0.0660994441900764, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03531215560371548, 0.0435265356972806, 0.031330014766869474, 0.04646902621649551, 0.014185550917560796, 0.016858509147832046, 0.03530031899262853, 0.029157295560009677, 0.021134526181834867, 0.3003057357964265, 0.307305229919392, 0.3167824549995434, 0.3012517275636658, 0.30750040675440127, 0.2739260438630524, 0.33369458215309267, 0.3387768276940164, 0.32096154007823186, 0.08871716436744614, 0.0656668573354664, 0.08714174289872922, 0.10104118320269462, 0.08715332730511616, 0.10693061204795218, 0.08382990999891604, 0.09216974157621194, 0.09900280816393259, 0.17463389743160185, 0.1433739069039588, 0.1488358376710115, 0.18640239901946265, 0.17283018160117258, 0.18266193539283104, 0.2060020957893507, 0.16160218068185173, 0.1897863599894143, 0.21716949864108526, 0.21103387579845112, 0.2229300687745862, 0.269049007830812, 0.26004889648708174, 0.25661648398365255, 0.2083764134896241, 0.22107520826287586, 0.21958749546522205, 0.16868770346725903, 0.15947584767033918, 0.1493547022787297, 0.19635899279989855, 0.2064479010187008, 0.19689652923315093, 0.14528210415476495, 0.1565621683834656, 0.14577574229822754, 0.27718558121498504, 0.24976275932713132, 0.23815193508092025, 0.24151767194177787, 0.26017458948918837, 0.2363100719703879, 0.24116091481284918, 0.23994474761811446, 0.26238170723058485, 0.17536522317053294, 0.17434818086482706, 0.17890065814368827, 0.1815408953515586, 0.17377596183290767, 0.17976074808455256, 0.1754619385396332, 0.18043649435650444, 0.18204438946498425, 0.1830828514379601, 0.14073424871104567, 0.1694382472749527, 0.36354004489552905, 0.2917228996158244, 0.3153175252827134, 0.1276472776597266, 0.18206913993881668, 0.4175510880280693, 0.4015654263981109, 0.25840570900172977, 0.3336246107099333, 0.2549961612139524, 0.15164179172460024, 0.2524634625774479, 0.32371089037372436, 0.16893501147558576, 0.29597384611707944, 0.1806619354232989, 0.17982748843418372, 0.19693434660230635, 0.18130763129289373, 0.1763784219087916, 0.19866331812670635, 0.18384760210163653, 0.18733202926576786, 0.19348566994973493, 0.07996660296428382, 0.07296840625395584, 0.0751997901037823, 0.08900294289032396, 0.06520753154297276, 0.09683869631093445, 0.06906253717176802, 0.08584189952206234, 0.07189158007074492]}, "mutation_prompt": null}
{"id": "64890ed0-aa89-4d83-9cb8-37b17ae2fbd1", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimizationImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n        fitness_values = [wolf['fitness'] for wolf in wolves]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation based on fitness variance\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            variance = np.var(fitness_values)\n            if variance < 0.05:  # Adjusted variance threshold for faster convergence\n                wolves.pop(-1)  # Remove a wolf if variance is low\n            else:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n                fitness_values.append(wolves[-1]['fitness'])\n\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimizationImproved", "description": "Introducing a dynamic population size adjustment based on the fitness variance of wolves and an adaptive mutation strategy to enhance exploration and convergence speed.", "configspace": "", "generation": 56, "fitness": 0.18158301383710676, "feedback": "The algorithm FastConvergingGreyWolfOptimizationImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.18.", "error": "", "parent_id": "dd25d9fb-abe2-4b73-9cfc-36392784878a", "metadata": {"aucs": [0.31019831141539145, 0.3764066636662309, 0.4334966776700264, 0.26713514007086925, 0.25507820785465996, 0.2681188390283801, 0.2892993128391528, 0.3229024270581763, 0.28832201069746977, 9.999999999998899e-05, 9.999999999998899e-05, 0.0069153618232769, 0.03669780389509836, 9.999999999998899e-05, 0.06693702790938882, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0860188314779391, 0.07975052295137486, 0.09680544286784387, 0.09039875395130803, 0.08663184037214322, 0.08949739478774588, 0.09211128480155639, 0.09287701992081021, 0.09049447229117791, 0.08368761666251356, 0.07016437125797803, 0.05403912085066842, 0.0977314861276729, 0.0886164045880452, 0.07812267799238382, 0.08641977762476816, 0.08663302108878657, 0.08256382633367809, 0.9650397445306794, 0.9360310360809561, 0.8570754906597035, 0.9126983344662438, 0.8701120650453957, 0.8898720819465875, 0.9373851276455081, 0.8993159838152265, 0.7309130580620814, 0.13468242051665913, 0.13021057173447537, 0.15072692651804287, 0.14883383287941976, 0.1793112375678364, 0.19417563539520755, 0.14380745635823444, 0.149101472565203, 0.1331552719434187, 0.27110394228620227, 0.21283657505902764, 0.15294046994036303, 0.21018186641511982, 0.16894434964533556, 0.2249026050911309, 0.1753974291383511, 0.2001839366227256, 0.2071346496141847, 0.16437231783074657, 0.1671935978365955, 0.14937354759596166, 0.1007875229063695, 0.02810683712624884, 0.05524134769040134, 0.09664801796264677, 0.12018763355788864, 0.15804140741081396, 0.20420418041535737, 0.24523287193829435, 0.19750199961429948, 0.16472584247904176, 0.1626577294771856, 0.1889154205124861, 0.233807292584022, 0.2193640504538622, 0.2542830468625289, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06034943824513084, 0.06879806548936973, 0.034398887133356815, 0.04444130629251153, 0.06646605716341947, 0.08988919257911943, 0.06171697356195871, 0.04959969936769926, 0.06038533989433559, 0.04567631537509331, 0.09386798965922538, 0.0660994441900764, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03531215560371548, 0.0435265356972806, 0.031330014766869474, 0.04646902621649551, 0.014185550917560796, 0.016858509147832046, 0.03530031899262853, 0.029157295560009677, 0.021134526181834867, 0.3003057357964265, 0.307305229919392, 0.3167824549995434, 0.3012517275636658, 0.30750040675440127, 0.2739260438630524, 0.33369458215309267, 0.3387768276940164, 0.32096154007823186, 0.08871716436744614, 0.0656668573354664, 0.08714174289872922, 0.10104118320269462, 0.08715332730511616, 0.10693061204795218, 0.08382990999891604, 0.09216974157621194, 0.09900280816393259, 0.17463389743160185, 0.1433739069039588, 0.1488358376710115, 0.18640239901946265, 0.17283018160117258, 0.18266193539283104, 0.2060020957893507, 0.16160218068185173, 0.1897863599894143, 0.21716949864108526, 0.21103387579845112, 0.2229300687745862, 0.269049007830812, 0.26004889648708174, 0.25661648398365255, 0.2083764134896241, 0.22107520826287586, 0.21958749546522205, 0.16868770346725903, 0.15947584767033918, 0.1493547022787297, 0.19635899279989855, 0.2064479010187008, 0.19689652923315093, 0.14528210415476495, 0.1565621683834656, 0.14577574229822754, 0.27718558121498504, 0.24976275932713132, 0.23815193508092025, 0.24151767194177787, 0.26017458948918837, 0.2363100719703879, 0.24116091481284918, 0.23994474761811446, 0.26238170723058485, 0.17536522317053294, 0.17434818086482706, 0.17890065814368827, 0.1815408953515586, 0.17377596183290767, 0.17976074808455256, 0.1754619385396332, 0.18043649435650444, 0.18204438946498425, 0.1830828514379601, 0.14073424871104567, 0.1694382472749527, 0.36354004489552905, 0.2917228996158244, 0.3153175252827134, 0.1276472776597266, 0.18206913993881668, 0.4175510880280693, 0.4015654263981109, 0.25840570900172977, 0.3336246107099333, 0.2549961612139524, 0.15164179172460024, 0.2524634625774479, 0.32371089037372436, 0.16893501147558576, 0.29597384611707944, 0.1806619354232989, 0.17982748843418372, 0.19693434660230635, 0.18130763129289373, 0.1763784219087916, 0.19866331812670635, 0.18384760210163653, 0.18733202926576786, 0.19348566994973493, 0.07996660296428382, 0.07296840625395584, 0.0751997901037823, 0.08900294289032396, 0.06520753154297276, 0.09683869631093445, 0.06906253717176802, 0.08584189952206234, 0.07189158007074492]}, "mutation_prompt": null}
{"id": "e7b76106-48c1-445f-94f9-8b83dc9b41ac", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimizationImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n\n            # Introducing Gaussian mutation for enhanced exploration\n            mutation = np.random.normal(0, 0.5, self.dim)\n            new_position += mutation\n\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n        fitness_values = [wolf['fitness'] for wolf in wolves]\n\n        for i in range(2, self.budget - 3, 2):\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            variance = np.var(fitness_values)\n            if variance < 0.1:\n                wolves.pop(-1)\n            else:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n                fitness_values.append(wolves[-1]['fitness'])\n\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimizationImproved", "description": "Enhancing convergence speed by introducing a Gaussian mutation mechanism to explore the search space more effectively.", "configspace": "", "generation": 57, "fitness": 0.16784753246245004, "feedback": "The algorithm FastConvergingGreyWolfOptimizationImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.18.", "error": "", "parent_id": "dd25d9fb-abe2-4b73-9cfc-36392784878a", "metadata": {"aucs": [0.2805691879769805, 0.2861253220257872, 0.30139176590866723, 0.2641015078258113, 0.25309050706068004, 0.25131983646228406, 0.2649133425361836, 0.2993645421729594, 0.294257788248642, 9.999999999998899e-05, 0.004132281970418816, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09865919346883079, 0.07879538210394343, 0.07275145421933926, 0.07828777633866213, 0.08681041566734837, 0.07801619250321601, 0.0787764013473159, 0.07203944990555411, 0.08603890597590558, 0.09030276747351396, 0.06483656999380616, 0.0796497297478207, 0.06816000430671809, 0.07418081333540016, 0.07263577387234399, 0.07150399048709855, 0.08030514907033015, 0.06730381151986242, 0.9405325170887753, 0.9027873474115438, 0.9479922188065086, 0.8680995966389801, 0.9591691984480452, 0.8114905390048378, 0.9019536026886792, 0.9813887706431021, 0.9691114401500656, 0.13831929825332467, 0.12251323153646188, 0.12981520103712751, 0.16852213806975558, 0.146140134005031, 0.16383865328656577, 0.16090138629946926, 0.15052103695201569, 0.1528810648159863, 0.22984106061310816, 0.18908010962844324, 0.20029010135304748, 0.18956546393138818, 0.2655269282174815, 0.1825778649152887, 0.24188104576757674, 0.23084072179891424, 0.20774498980613876, 0.0956138426713885, 0.1036378964227701, 0.08825339019086931, 0.09605986716738002, 0.08860766957386024, 0.07268766955235983, 0.08761183294982477, 0.09946955944287095, 0.071036006786803, 0.14824950326884212, 0.1058403820442565, 0.10963432653502259, 0.10985135211044583, 0.10960940944417763, 0.10422739896935673, 0.11118977481094683, 0.11951503843433997, 0.12255105815655765, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.001616620365608834, 9.999999999998899e-05, 0.08839631207135046, 0.08448666091929369, 0.08746511106297017, 0.04618439882811032, 0.06062064178897786, 0.05794822917304299, 0.073513646082211, 0.07350186325306463, 0.107502764249091, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.019196405540064743, 0.03433224607108898, 0.023814831137490944, 0.006545778153828952, 0.024540509604626504, 0.024557542832381873, 0.03039082117016001, 0.0160956164586874, 0.029104361817601565, 0.28611643744482473, 0.27852414475224385, 0.2785285219308149, 0.26405738844535076, 0.27954833079492336, 0.2882264461407922, 0.28995876352657957, 0.30132306761934924, 0.2833363372968397, 0.0702260780301096, 0.06344091851252343, 0.07480237230629005, 0.0875956841336476, 0.09476061888526055, 0.09220100066817738, 0.09147237236587558, 0.08248767304693738, 0.08025390415775313, 0.13657150457122758, 0.151987874414802, 0.13103937893943296, 0.14868490556523517, 0.1390363594730184, 0.18782189822817297, 0.1598102197748078, 0.13070377534766264, 0.135516564521876, 0.2125452213656014, 0.213947596326725, 0.21323578075409433, 0.22810136547547832, 0.22124433598782767, 0.2210694755363326, 0.20857078604761714, 0.20408176285501245, 0.21365146485352549, 0.16039922013239305, 0.16195316486436118, 0.19122354733855385, 0.17509167672408366, 0.1694581803063795, 0.17045464347416905, 0.144117165307024, 0.15992813812068796, 0.1487983509044538, 0.22457117647118408, 0.20569455685833504, 0.2028216854204019, 0.21615739691232672, 0.2263411341097974, 0.1961595475747212, 0.23290509371568702, 0.19517168279764252, 0.20829883997026966, 0.1801918311706575, 0.1748026965723981, 0.17146938097298103, 0.1938970329260079, 0.16808695760703252, 0.17494518262643854, 0.17062113001988, 0.17443902904267583, 0.1909289702780247, 0.18077801296993679, 0.17475487826044245, 0.1802338130642469, 0.35046661208688534, 0.26768280582919424, 0.1520278125578658, 0.2168957840912924, 0.35995040470716066, 0.2972459559512759, 0.32453542501283816, 0.3393243191949752, 0.22382299992161925, 0.1231094014703844, 0.14261905099194794, 0.1754758063806967, 0.20176942025004496, 0.14922706098944505, 0.2606227499594075, 0.185653212186909, 0.19527999336942703, 0.19313372228679437, 0.19797893306369208, 0.17216484384292396, 0.1790832641746558, 0.18419117458729872, 0.19205660292972782, 0.19650353488812755, 0.08002304735294996, 0.08053490957360587, 0.08657350100877592, 0.07871678289119954, 0.08483813852266797, 0.07178635492000374, 0.07917145088859379, 0.07420520989340018, 0.08161641569867684]}, "mutation_prompt": null}
{"id": "be32709b-d1dc-45b0-9cd6-15d3b9fe3757", "solution": "import numpy as np\n\nclass HybridGreyWolfDEOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            ...\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n        fitness_values = [wolf['fitness'] for wolf in wolves]\n\n        for i in range(2, self.budget - 3, 2):\n            # Hybrid strategy combining Gray Wolf Optimization with Differential Evolution\n            # Update positions using a combination of GWO and DE operators for improved convergence speed\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "HybridGreyWolfDEOptimization", "description": "Introducing a hybrid strategy combining Gray Wolf Optimization with Differential Evolution for improved convergence speed.", "configspace": "", "generation": 58, "fitness": -Infinity, "feedback": "An exception occurred: IndentationError('expected an indented block', ('<string>', 21, 9, \"        best_wolf = min(wolves, key=lambda x: x['fitness'])\\n\")).", "error": "IndentationError('expected an indented block', ('<string>', 21, 9, \"        best_wolf = min(wolves, key=lambda x: x['fitness'])\\n\"))", "parent_id": "dd25d9fb-abe2-4b73-9cfc-36392784878a", "metadata": {}, "mutation_prompt": null}
{"id": "61ab7ffc-5208-4dd0-a732-8affcc029156", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimizationImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n        fitness_values = [wolf['fitness'] for wolf in wolves]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation based on fitness variance\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            variance = np.var(fitness_values)\n            if variance < 0.1:\n                wolves.pop(-1)  # Remove a wolf if variance is low\n            else:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n                fitness_values.append(wolves[-1]['fitness'])\n\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimizationImproved", "description": "Introducing a dynamic population size adjustment based on the fitness variance of wolves to enhance exploration-exploitation balance.", "configspace": "", "generation": 53, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "dd25d9fb-abe2-4b73-9cfc-36392784878a", "metadata": {"aucs": [0.31019831141539145, 0.3764066636662309, 0.4334966776700264, 0.26713514007086925, 0.25507820785465996, 0.2681188390283801, 0.2892993128391528, 0.3229024270581763, 0.28832201069746977, 9.999999999998899e-05, 9.999999999998899e-05, 0.0069153618232769, 0.03669780389509836, 9.999999999998899e-05, 0.06693702790938882, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0860188314779391, 0.07975052295137486, 0.09680544286784387, 0.09039875395130803, 0.08663184037214322, 0.08949739478774588, 0.09211128480155639, 0.09287701992081021, 0.09049447229117791, 0.08368761666251356, 0.07016437125797803, 0.05403912085066842, 0.0977314861276729, 0.0886164045880452, 0.07812267799238382, 0.08641977762476816, 0.08663302108878657, 0.08256382633367809, 0.9650397445306794, 0.9360310360809561, 0.8570754906597035, 0.9126983344662438, 0.8701120650453957, 0.8898720819465875, 0.9373851276455081, 0.8993159838152265, 0.7309130580620814, 0.13468242051665913, 0.13021057173447537, 0.15072692651804287, 0.14883383287941976, 0.1793112375678364, 0.19417563539520755, 0.14380745635823444, 0.149101472565203, 0.1331552719434187, 0.27110394228620227, 0.21283657505902764, 0.15294046994036303, 0.21018186641511982, 0.16894434964533556, 0.2249026050911309, 0.1753974291383511, 0.2001839366227256, 0.2071346496141847, 0.16437231783074657, 0.1671935978365955, 0.14937354759596166, 0.1007875229063695, 0.02810683712624884, 0.05524134769040134, 0.09664801796264677, 0.12018763355788864, 0.15804140741081396, 0.20420418041535737, 0.24523287193829435, 0.19750199961429948, 0.16472584247904176, 0.1626577294771856, 0.1889154205124861, 0.233807292584022, 0.2193640504538622, 0.2542830468625289, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06034943824513084, 0.06879806548936973, 0.034398887133356815, 0.04444130629251153, 0.06646605716341947, 0.08988919257911943, 0.06171697356195871, 0.04959969936769926, 0.06038533989433559, 0.04567631537509331, 0.09386798965922538, 0.0660994441900764, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03531215560371548, 0.0435265356972806, 0.031330014766869474, 0.04646902621649551, 0.014185550917560796, 0.016858509147832046, 0.03530031899262853, 0.029157295560009677, 0.021134526181834867, 0.3003057357964265, 0.307305229919392, 0.3167824549995434, 0.3012517275636658, 0.30750040675440127, 0.2739260438630524, 0.33369458215309267, 0.3387768276940164, 0.32096154007823186, 0.08871716436744614, 0.0656668573354664, 0.08714174289872922, 0.10104118320269462, 0.08715332730511616, 0.10693061204795218, 0.08382990999891604, 0.09216974157621194, 0.09900280816393259, 0.17463389743160185, 0.1433739069039588, 0.1488358376710115, 0.18640239901946265, 0.17283018160117258, 0.18266193539283104, 0.2060020957893507, 0.16160218068185173, 0.1897863599894143, 0.21716949864108526, 0.21103387579845112, 0.2229300687745862, 0.269049007830812, 0.26004889648708174, 0.25661648398365255, 0.2083764134896241, 0.22107520826287586, 0.21958749546522205, 0.16868770346725903, 0.15947584767033918, 0.1493547022787297, 0.19635899279989855, 0.2064479010187008, 0.19689652923315093, 0.14528210415476495, 0.1565621683834656, 0.14577574229822754, 0.27718558121498504, 0.24976275932713132, 0.23815193508092025, 0.24151767194177787, 0.26017458948918837, 0.2363100719703879, 0.24116091481284918, 0.23994474761811446, 0.26238170723058485, 0.17536522317053294, 0.17434818086482706, 0.17890065814368827, 0.1815408953515586, 0.17377596183290767, 0.17976074808455256, 0.1754619385396332, 0.18043649435650444, 0.18204438946498425, 0.1830828514379601, 0.14073424871104567, 0.1694382472749527, 0.36354004489552905, 0.2917228996158244, 0.3153175252827134, 0.1276472776597266, 0.18206913993881668, 0.4175510880280693, 0.4015654263981109, 0.25840570900172977, 0.3336246107099333, 0.2549961612139524, 0.15164179172460024, 0.2524634625774479, 0.32371089037372436, 0.16893501147558576, 0.29597384611707944, 0.1806619354232989, 0.17982748843418372, 0.19693434660230635, 0.18130763129289373, 0.1763784219087916, 0.19866331812670635, 0.18384760210163653, 0.18733202926576786, 0.19348566994973493, 0.07996660296428382, 0.07296840625395584, 0.0751997901037823, 0.08900294289032396, 0.06520753154297276, 0.09683869631093445, 0.06906253717176802, 0.08584189952206234, 0.07189158007074492]}, "mutation_prompt": null}
{"id": "c1c55058-08e3-4ad0-9116-da235b2595cd", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimizationImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness, step_size):\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n        fitness_values = [wolf['fitness'] for wolf in wolves]\n\n        for i in range(2, self.budget - 3, 2):  \n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            variance = np.var(fitness_values)\n            step_size = 1.0 - np.exp(-0.1 * variance)  # Adaptive step size based on fitness diversity\n            if variance < 0.1:\n                wolves.pop(-1)  \n            else:\n                new_wolf = {'position': np.random.uniform(-5.0, 5.0, self.dim),\n                            'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))}\n                wolves.append(new_wolf)\n                fitness_values.append(new_wolf['fitness'])\n\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness, step_size)\n                wolf['fitness'] = func(wolf['position'])\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimizationImproved", "description": "Introducing an adaptive mutation strategy that adjusts the step size based on the population's fitness diversity to accelerate convergence speed.", "configspace": "", "generation": 60, "fitness": 0.16046052534688998, "feedback": "The algorithm FastConvergingGreyWolfOptimizationImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16 with standard deviation 0.18.", "error": "", "parent_id": "dd25d9fb-abe2-4b73-9cfc-36392784878a", "metadata": {"aucs": [0.4005692817657892, 0.41928740447760593, 0.41821154540114336, 0.1591456401379976, 0.17323422218553608, 0.16813055769698682, 0.33321926283938674, 0.3418145188598526, 0.3530691818361882, 0.046885081097248205, 0.026147822004506605, 0.04784450484923186, 0.13698553859152784, 0.13630683304979663, 0.09787384613660666, 0.11403431772846562, 9.999999999998899e-05, 9.999999999998899e-05, 0.028403944064207987, 0.12780882789870773, 0.028028291783096404, 0.008782466608950878, 0.10147705400113904, 0.10455774695020903, 0.05023257003280801, 0.10798076908085108, 0.05074738320637484, 0.012352733062286236, 0.0003078708268426933, 0.001763562742523539, 0.01960752770993024, 0.0020729759030641004, 0.004859768171349033, 0.01192676506080681, 0.004110106382995804, 9.999999999998899e-05, 0.9791898135443675, 0.9297909466613999, 0.9289185830248656, 0.7263991751781196, 0.9589696957384204, 0.8920657681900294, 0.7454600070395534, 0.9572377662108733, 0.9179428046327266, 0.20861993382653865, 0.20612741487056474, 0.1816809195724305, 0.19575386422787333, 0.24894496949421918, 0.24249124443116699, 0.19193714776994353, 0.07309963090463989, 0.06439371202968036, 0.11556640259057527, 0.10084894821390922, 0.11027031158898515, 0.24698418957661883, 0.21549761126477207, 0.15949825416335028, 0.09508406687000548, 0.1061563782297753, 0.17708018883165988, 0.13794921263190896, 0.19144920033264412, 0.12147159687746012, 0.11321962821481846, 0.12817722606231696, 0.11017647886539639, 0.07096821096491346, 0.09063728466877852, 0.11624144730483554, 0.12520318512968365, 0.13389466389996485, 0.12569713525816895, 0.11241015875063354, 0.12028275787258813, 0.13067604713955772, 0.2405559227077, 0.22942766864241382, 0.21164640307736704, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008267856334332246, 0.032806782134795376, 9.999999999998899e-05, 9.999999999998899e-05, 0.017874254406656465, 0.004872916213544909, 0.07006783568751684, 0.07653184327423168, 0.06398881733823614, 0.05210202115661433, 0.04759266820543273, 0.06345248916849122, 0.09975141431819834, 0.07942008802489486, 0.08831609556546194, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01542047960164239, 0.021389767075943977, 0.013366490979446088, 0.045806143579865566, 0.009634373022702869, 0.04792057031076524, 0.39368120367391635, 0.3286169104775809, 0.26088290428510763, 0.132809831389196, 0.13584332073167749, 0.1718216607047065, 0.19518382206891327, 0.22099893292153294, 0.20685520265169466, 0.01838482441596312, 0.0192268549633553, 0.025190175256283864, 0.05279070671819042, 0.05853742638010773, 0.0869295761639538, 0.043635312830056505, 0.06087482446410175, 0.08212502532255672, 0.2503986593772306, 0.1610580421179889, 0.16073140787739337, 0.17492756489353956, 0.1884716832635529, 0.1466014755195727, 0.2615910953174043, 0.2049935517909478, 0.18808692418593553, 0.1580499615802008, 0.16193055249571697, 0.16660913938357813, 0.17907521340748167, 0.20082185055169888, 0.17241018601595026, 0.14436661520365746, 0.16245272066308136, 0.17807650611975168, 0.10850426334531293, 0.10144517711448875, 0.08231634147770361, 0.10641897448090276, 0.13613556437390073, 0.13316227532253289, 0.0847954644071095, 0.08806704432915502, 0.11773470977499456, 0.19328247797673215, 0.28164666186907017, 0.25431976181329585, 0.2230570635196093, 0.21781666000058653, 0.22469350342416805, 0.2285184393247105, 0.2399654150089353, 0.24499869237416994, 0.08686124804560735, 0.15975485187270155, 0.19703827055631484, 0.186119966263391, 0.1691871528665959, 0.18865769684720124, 0.05639167616908547, 0.18179932358908524, 0.18317049835911225, 0.43353504434789947, 0.08564299795433239, 0.18354426572584182, 0.47683921853790046, 0.12080917085526266, 0.19821382463561232, 0.16628336304673963, 0.19363882912245534, 0.16738129623576858, 0.12581486134185993, 0.4053885043751452, 0.45850331978467007, 0.10940476788265163, 0.15298862660639478, 0.1267722643448349, 0.08663443528257575, 0.1688490235777954, 0.08679805629188397, 0.179263278481528, 0.1703180827446844, 0.1720685138144742, 0.17204017750632306, 0.2203714279083907, 0.18466067251337104, 0.17820091549625305, 0.19158810440521978, 0.19321001369522928, 0.04258287843727526, 0.07724159579859824, 0.09101239865379174, 0.09506975947930896, 0.043538030283739815, 0.0806949802899748, 0.0636516447931208, 0.0670199907373824, 0.07454149462889814]}, "mutation_prompt": null}
{"id": "8b0e5535-0947-471e-afa8-da3613442e38", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimizationImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n        fitness_values = [wolf['fitness'] for wolf in wolves]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation based on fitness variance\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            variance = np.var(fitness_values)\n            if variance < 0.1:\n                wolves.pop(-1)  # Remove a wolf if variance is low\n            else:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n                fitness_values.append(wolves[-1]['fitness'])\n\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimizationImproved", "description": "Introducing a dynamic population size adjustment based on the fitness variance of wolves to enhance exploration-exploitation balance.", "configspace": "", "generation": 53, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "dd25d9fb-abe2-4b73-9cfc-36392784878a", "metadata": {"aucs": [0.31019831141539145, 0.3764066636662309, 0.4334966776700264, 0.26713514007086925, 0.25507820785465996, 0.2681188390283801, 0.2892993128391528, 0.3229024270581763, 0.28832201069746977, 9.999999999998899e-05, 9.999999999998899e-05, 0.0069153618232769, 0.03669780389509836, 9.999999999998899e-05, 0.06693702790938882, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0860188314779391, 0.07975052295137486, 0.09680544286784387, 0.09039875395130803, 0.08663184037214322, 0.08949739478774588, 0.09211128480155639, 0.09287701992081021, 0.09049447229117791, 0.08368761666251356, 0.07016437125797803, 0.05403912085066842, 0.0977314861276729, 0.0886164045880452, 0.07812267799238382, 0.08641977762476816, 0.08663302108878657, 0.08256382633367809, 0.9650397445306794, 0.9360310360809561, 0.8570754906597035, 0.9126983344662438, 0.8701120650453957, 0.8898720819465875, 0.9373851276455081, 0.8993159838152265, 0.7309130580620814, 0.13468242051665913, 0.13021057173447537, 0.15072692651804287, 0.14883383287941976, 0.1793112375678364, 0.19417563539520755, 0.14380745635823444, 0.149101472565203, 0.1331552719434187, 0.27110394228620227, 0.21283657505902764, 0.15294046994036303, 0.21018186641511982, 0.16894434964533556, 0.2249026050911309, 0.1753974291383511, 0.2001839366227256, 0.2071346496141847, 0.16437231783074657, 0.1671935978365955, 0.14937354759596166, 0.1007875229063695, 0.02810683712624884, 0.05524134769040134, 0.09664801796264677, 0.12018763355788864, 0.15804140741081396, 0.20420418041535737, 0.24523287193829435, 0.19750199961429948, 0.16472584247904176, 0.1626577294771856, 0.1889154205124861, 0.233807292584022, 0.2193640504538622, 0.2542830468625289, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06034943824513084, 0.06879806548936973, 0.034398887133356815, 0.04444130629251153, 0.06646605716341947, 0.08988919257911943, 0.06171697356195871, 0.04959969936769926, 0.06038533989433559, 0.04567631537509331, 0.09386798965922538, 0.0660994441900764, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03531215560371548, 0.0435265356972806, 0.031330014766869474, 0.04646902621649551, 0.014185550917560796, 0.016858509147832046, 0.03530031899262853, 0.029157295560009677, 0.021134526181834867, 0.3003057357964265, 0.307305229919392, 0.3167824549995434, 0.3012517275636658, 0.30750040675440127, 0.2739260438630524, 0.33369458215309267, 0.3387768276940164, 0.32096154007823186, 0.08871716436744614, 0.0656668573354664, 0.08714174289872922, 0.10104118320269462, 0.08715332730511616, 0.10693061204795218, 0.08382990999891604, 0.09216974157621194, 0.09900280816393259, 0.17463389743160185, 0.1433739069039588, 0.1488358376710115, 0.18640239901946265, 0.17283018160117258, 0.18266193539283104, 0.2060020957893507, 0.16160218068185173, 0.1897863599894143, 0.21716949864108526, 0.21103387579845112, 0.2229300687745862, 0.269049007830812, 0.26004889648708174, 0.25661648398365255, 0.2083764134896241, 0.22107520826287586, 0.21958749546522205, 0.16868770346725903, 0.15947584767033918, 0.1493547022787297, 0.19635899279989855, 0.2064479010187008, 0.19689652923315093, 0.14528210415476495, 0.1565621683834656, 0.14577574229822754, 0.27718558121498504, 0.24976275932713132, 0.23815193508092025, 0.24151767194177787, 0.26017458948918837, 0.2363100719703879, 0.24116091481284918, 0.23994474761811446, 0.26238170723058485, 0.17536522317053294, 0.17434818086482706, 0.17890065814368827, 0.1815408953515586, 0.17377596183290767, 0.17976074808455256, 0.1754619385396332, 0.18043649435650444, 0.18204438946498425, 0.1830828514379601, 0.14073424871104567, 0.1694382472749527, 0.36354004489552905, 0.2917228996158244, 0.3153175252827134, 0.1276472776597266, 0.18206913993881668, 0.4175510880280693, 0.4015654263981109, 0.25840570900172977, 0.3336246107099333, 0.2549961612139524, 0.15164179172460024, 0.2524634625774479, 0.32371089037372436, 0.16893501147558576, 0.29597384611707944, 0.1806619354232989, 0.17982748843418372, 0.19693434660230635, 0.18130763129289373, 0.1763784219087916, 0.19866331812670635, 0.18384760210163653, 0.18733202926576786, 0.19348566994973493, 0.07996660296428382, 0.07296840625395584, 0.0751997901037823, 0.08900294289032396, 0.06520753154297276, 0.09683869631093445, 0.06906253717176802, 0.08584189952206234, 0.07189158007074492]}, "mutation_prompt": null}
{"id": "ae447f99-ed5b-4f33-b47c-c28d780e04b8", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimizationImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n        fitness_values = [wolf['fitness'] for wolf in wolves]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation based on fitness variance\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            variance = np.var(fitness_values)\n            if variance < 0.1:\n                wolves.pop(-1)  # Remove a wolf if variance is low\n            else:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n                fitness_values.append(wolves[-1]['fitness'])\n\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimizationImproved", "description": "Introducing a dynamic population size adjustment based on the fitness variance of wolves to enhance exploration-exploitation balance.", "configspace": "", "generation": 53, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "dd25d9fb-abe2-4b73-9cfc-36392784878a", "metadata": {"aucs": [0.31019831141539145, 0.3764066636662309, 0.4334966776700264, 0.26713514007086925, 0.25507820785465996, 0.2681188390283801, 0.2892993128391528, 0.3229024270581763, 0.28832201069746977, 9.999999999998899e-05, 9.999999999998899e-05, 0.0069153618232769, 0.03669780389509836, 9.999999999998899e-05, 0.06693702790938882, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0860188314779391, 0.07975052295137486, 0.09680544286784387, 0.09039875395130803, 0.08663184037214322, 0.08949739478774588, 0.09211128480155639, 0.09287701992081021, 0.09049447229117791, 0.08368761666251356, 0.07016437125797803, 0.05403912085066842, 0.0977314861276729, 0.0886164045880452, 0.07812267799238382, 0.08641977762476816, 0.08663302108878657, 0.08256382633367809, 0.9650397445306794, 0.9360310360809561, 0.8570754906597035, 0.9126983344662438, 0.8701120650453957, 0.8898720819465875, 0.9373851276455081, 0.8993159838152265, 0.7309130580620814, 0.13468242051665913, 0.13021057173447537, 0.15072692651804287, 0.14883383287941976, 0.1793112375678364, 0.19417563539520755, 0.14380745635823444, 0.149101472565203, 0.1331552719434187, 0.27110394228620227, 0.21283657505902764, 0.15294046994036303, 0.21018186641511982, 0.16894434964533556, 0.2249026050911309, 0.1753974291383511, 0.2001839366227256, 0.2071346496141847, 0.16437231783074657, 0.1671935978365955, 0.14937354759596166, 0.1007875229063695, 0.02810683712624884, 0.05524134769040134, 0.09664801796264677, 0.12018763355788864, 0.15804140741081396, 0.20420418041535737, 0.24523287193829435, 0.19750199961429948, 0.16472584247904176, 0.1626577294771856, 0.1889154205124861, 0.233807292584022, 0.2193640504538622, 0.2542830468625289, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06034943824513084, 0.06879806548936973, 0.034398887133356815, 0.04444130629251153, 0.06646605716341947, 0.08988919257911943, 0.06171697356195871, 0.04959969936769926, 0.06038533989433559, 0.04567631537509331, 0.09386798965922538, 0.0660994441900764, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03531215560371548, 0.0435265356972806, 0.031330014766869474, 0.04646902621649551, 0.014185550917560796, 0.016858509147832046, 0.03530031899262853, 0.029157295560009677, 0.021134526181834867, 0.3003057357964265, 0.307305229919392, 0.3167824549995434, 0.3012517275636658, 0.30750040675440127, 0.2739260438630524, 0.33369458215309267, 0.3387768276940164, 0.32096154007823186, 0.08871716436744614, 0.0656668573354664, 0.08714174289872922, 0.10104118320269462, 0.08715332730511616, 0.10693061204795218, 0.08382990999891604, 0.09216974157621194, 0.09900280816393259, 0.17463389743160185, 0.1433739069039588, 0.1488358376710115, 0.18640239901946265, 0.17283018160117258, 0.18266193539283104, 0.2060020957893507, 0.16160218068185173, 0.1897863599894143, 0.21716949864108526, 0.21103387579845112, 0.2229300687745862, 0.269049007830812, 0.26004889648708174, 0.25661648398365255, 0.2083764134896241, 0.22107520826287586, 0.21958749546522205, 0.16868770346725903, 0.15947584767033918, 0.1493547022787297, 0.19635899279989855, 0.2064479010187008, 0.19689652923315093, 0.14528210415476495, 0.1565621683834656, 0.14577574229822754, 0.27718558121498504, 0.24976275932713132, 0.23815193508092025, 0.24151767194177787, 0.26017458948918837, 0.2363100719703879, 0.24116091481284918, 0.23994474761811446, 0.26238170723058485, 0.17536522317053294, 0.17434818086482706, 0.17890065814368827, 0.1815408953515586, 0.17377596183290767, 0.17976074808455256, 0.1754619385396332, 0.18043649435650444, 0.18204438946498425, 0.1830828514379601, 0.14073424871104567, 0.1694382472749527, 0.36354004489552905, 0.2917228996158244, 0.3153175252827134, 0.1276472776597266, 0.18206913993881668, 0.4175510880280693, 0.4015654263981109, 0.25840570900172977, 0.3336246107099333, 0.2549961612139524, 0.15164179172460024, 0.2524634625774479, 0.32371089037372436, 0.16893501147558576, 0.29597384611707944, 0.1806619354232989, 0.17982748843418372, 0.19693434660230635, 0.18130763129289373, 0.1763784219087916, 0.19866331812670635, 0.18384760210163653, 0.18733202926576786, 0.19348566994973493, 0.07996660296428382, 0.07296840625395584, 0.0751997901037823, 0.08900294289032396, 0.06520753154297276, 0.09683869631093445, 0.06906253717176802, 0.08584189952206234, 0.07189158007074492]}, "mutation_prompt": null}
{"id": "117467f2-8626-43ea-808b-2bfb2e172f19", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimizationImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness, fitness_trend):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n\n            if fitness_improvement > np.mean(fitness_trend):  # Adaptive mutation based on fitness trends\n                new_position = new_position + np.random.normal(0, 0.1, self.dim)\n\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n        fitness_values = [wolf['fitness'] for wolf in wolves]\n        fitness_trend = []\n\n        for i in range(2, self.budget - 3, 2):\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            variance = np.var(fitness_values)\n            if variance < 0.1:\n                wolves.pop(-1)\n            else:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n                fitness_values.append(wolves[-1]['fitness'])\n                fitness_trend.append(wolves[-1]['fitness'])\n\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness, fitness_trend)\n                wolf['fitness'] = func(wolf['position'])\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimizationImproved", "description": "Improving convergence speed by introducing a novel adaptive mutation mechanism based on fitness trends for population update.", "configspace": "", "generation": 63, "fitness": 0.180996418290063, "feedback": "The algorithm FastConvergingGreyWolfOptimizationImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.18.", "error": "", "parent_id": "dd25d9fb-abe2-4b73-9cfc-36392784878a", "metadata": {"aucs": [0.31019831141539145, 0.3764066636662309, 0.4334966776700264, 0.26713514007086925, 0.25507820785465996, 0.2681188390283801, 0.28755414702102233, 0.33306051805739156, 0.33589933599946087, 9.999999999998899e-05, 9.999999999998899e-05, 0.0069153618232769, 0.03669780389509836, 9.999999999998899e-05, 0.06693702790938882, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08861338869155244, 0.08915765626850547, 0.07483868841838881, 0.09039875395130803, 0.08663184037214322, 0.08949739478774588, 0.09211128480155639, 0.09287701992081021, 0.09049447229117791, 0.09940369922313874, 0.0891388868238524, 0.05403912085066842, 0.0977314861276729, 0.0886164045880452, 0.07812267799238382, 0.08641977762476816, 0.08663302108878657, 0.08256382633367809, 0.9650397445306794, 0.9360310360809561, 0.8570754906597035, 0.9126983344662438, 0.8701120650453957, 0.8898720819465875, 0.9373851276455081, 0.8993159838152265, 0.7309130580620814, 0.13468242051665913, 0.13021057173447537, 0.15072692651804287, 0.14883383287941976, 0.1793112375678364, 0.19417563539520755, 0.14380745635823444, 0.149101472565203, 0.1331552719434187, 0.27110394228620227, 0.21283657505902764, 0.15294046994036303, 0.21018186641511982, 0.16894434964533556, 0.2249026050911309, 0.1753974291383511, 0.2001839366227256, 0.2071346496141847, 0.16437231783074657, 0.1671935978365955, 0.14937354759596166, 0.1007875229063695, 0.02810683712624884, 0.05524134769040134, 0.09664801796264677, 0.12018763355788864, 0.15804140741081396, 0.20420418041535737, 0.24523287193829435, 0.19750199961429948, 0.16472584247904176, 0.1626577294771856, 0.1889154205124861, 0.233807292584022, 0.2193640504538622, 0.2542830468625289, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06034943824513084, 0.06879806548936973, 0.034398887133356815, 0.04444130629251153, 0.06646605716341947, 0.08988919257911943, 0.06171697356195871, 0.04959969936769926, 0.06038533989433559, 0.04567631537509331, 0.09386798965922538, 0.0660994441900764, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03531215560371548, 0.0435265356972806, 0.031330014766869474, 0.04646902621649551, 0.014185550917560796, 0.016858509147832046, 0.03530031899262853, 0.029157295560009677, 0.021134526181834867, 0.3003057357964265, 0.307305229919392, 0.3167824549995434, 0.2977740625714874, 0.28484872911998416, 0.3009310054503025, 0.33369458215309267, 0.3387768276940164, 0.32096154007823186, 0.08871716436744614, 0.0656668573354664, 0.08714174289872922, 0.10104118320269462, 0.08715332730511616, 0.10693061204795218, 0.08382990999891604, 0.09216974157621194, 0.09900280816393259, 0.17463389743160185, 0.1433739069039588, 0.1488358376710115, 0.19137888422312177, 0.14286823863658005, 0.18809975589394579, 0.2060020957893507, 0.16160218068185173, 0.1897863599894143, 0.21716949864108526, 0.21103387579845112, 0.2229300687745862, 0.269049007830812, 0.26004889648708174, 0.25661648398365255, 0.2083764134896241, 0.22107520826287586, 0.21958749546522205, 0.16868770346725903, 0.15947584767033918, 0.1493547022787297, 0.19635899279989855, 0.2064479010187008, 0.19689652923315093, 0.14528210415476495, 0.1565621683834656, 0.14577574229822754, 0.22851156163456865, 0.24268514412728115, 0.2444411752863237, 0.24151767194177787, 0.26017458948918837, 0.2363100719703879, 0.24116091481284918, 0.23994474761811446, 0.26238170723058485, 0.17536522317053294, 0.17434818086482706, 0.17890065814368827, 0.1815408953515586, 0.17377596183290767, 0.17976074808455256, 0.1754619385396332, 0.18043649435650444, 0.18204438946498425, 0.1830828514379601, 0.14073424871104567, 0.1694382472749527, 0.36354004489552905, 0.2917228996158244, 0.3153175252827134, 0.11855973554430088, 0.4090400138453282, 0.16836298543810457, 0.33992969775609716, 0.3863727512760824, 0.1446182868611039, 0.2549961612139524, 0.15164179172460024, 0.2524634625774479, 0.32371089037372436, 0.16893501147558576, 0.29597384611707944, 0.1806619354232989, 0.17982748843418372, 0.19693434660230635, 0.18130763129289373, 0.1763784219087916, 0.19866331812670635, 0.20268109130918388, 0.18773581394528138, 0.1889421670997542, 0.07996660296428382, 0.07296840625395584, 0.0751997901037823, 0.08900294289032396, 0.06520753154297276, 0.09683869631093445, 0.06906253717176802, 0.08584189952206234, 0.07189158007074492]}, "mutation_prompt": null}
{"id": "d0a8561a-da72-4228-93cf-832846217101", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimizationImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            \n            mutation_rate = 0.2 + 0.6 * np.exp(-0.1 * fitness_improvement)  # Dynamic mutation rate based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size * mutation_rate\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n        fitness_values = [wolf['fitness'] for wolf in wolves]\n\n        for i in range(2, self.budget - 3, 2):  \n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            variance = np.var(fitness_values)\n            if variance < 0.1:\n                wolves.pop(-1)  \n            else:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n                fitness_values.append(wolves[-1]['fitness'])\n\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimizationImproved", "description": "Implementing a dynamic mutation strategy based on individual fitness improvements to enhance exploration and speed of convergence.", "configspace": "", "generation": 64, "fitness": 0.18158301383710676, "feedback": "The algorithm FastConvergingGreyWolfOptimizationImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.18.", "error": "", "parent_id": "dd25d9fb-abe2-4b73-9cfc-36392784878a", "metadata": {"aucs": [0.31019831141539145, 0.3764066636662309, 0.4334966776700264, 0.26713514007086925, 0.25507820785465996, 0.2681188390283801, 0.2892993128391528, 0.3229024270581763, 0.28832201069746977, 9.999999999998899e-05, 9.999999999998899e-05, 0.0069153618232769, 0.03669780389509836, 9.999999999998899e-05, 0.06693702790938882, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0860188314779391, 0.07975052295137486, 0.09680544286784387, 0.09039875395130803, 0.08663184037214322, 0.08949739478774588, 0.09211128480155639, 0.09287701992081021, 0.09049447229117791, 0.08368761666251356, 0.07016437125797803, 0.05403912085066842, 0.0977314861276729, 0.0886164045880452, 0.07812267799238382, 0.08641977762476816, 0.08663302108878657, 0.08256382633367809, 0.9650397445306794, 0.9360310360809561, 0.8570754906597035, 0.9126983344662438, 0.8701120650453957, 0.8898720819465875, 0.9373851276455081, 0.8993159838152265, 0.7309130580620814, 0.13468242051665913, 0.13021057173447537, 0.15072692651804287, 0.14883383287941976, 0.1793112375678364, 0.19417563539520755, 0.14380745635823444, 0.149101472565203, 0.1331552719434187, 0.27110394228620227, 0.21283657505902764, 0.15294046994036303, 0.21018186641511982, 0.16894434964533556, 0.2249026050911309, 0.1753974291383511, 0.2001839366227256, 0.2071346496141847, 0.16437231783074657, 0.1671935978365955, 0.14937354759596166, 0.1007875229063695, 0.02810683712624884, 0.05524134769040134, 0.09664801796264677, 0.12018763355788864, 0.15804140741081396, 0.20420418041535737, 0.24523287193829435, 0.19750199961429948, 0.16472584247904176, 0.1626577294771856, 0.1889154205124861, 0.233807292584022, 0.2193640504538622, 0.2542830468625289, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06034943824513084, 0.06879806548936973, 0.034398887133356815, 0.04444130629251153, 0.06646605716341947, 0.08988919257911943, 0.06171697356195871, 0.04959969936769926, 0.06038533989433559, 0.04567631537509331, 0.09386798965922538, 0.0660994441900764, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03531215560371548, 0.0435265356972806, 0.031330014766869474, 0.04646902621649551, 0.014185550917560796, 0.016858509147832046, 0.03530031899262853, 0.029157295560009677, 0.021134526181834867, 0.3003057357964265, 0.307305229919392, 0.3167824549995434, 0.3012517275636658, 0.30750040675440127, 0.2739260438630524, 0.33369458215309267, 0.3387768276940164, 0.32096154007823186, 0.08871716436744614, 0.0656668573354664, 0.08714174289872922, 0.10104118320269462, 0.08715332730511616, 0.10693061204795218, 0.08382990999891604, 0.09216974157621194, 0.09900280816393259, 0.17463389743160185, 0.1433739069039588, 0.1488358376710115, 0.18640239901946265, 0.17283018160117258, 0.18266193539283104, 0.2060020957893507, 0.16160218068185173, 0.1897863599894143, 0.21716949864108526, 0.21103387579845112, 0.2229300687745862, 0.269049007830812, 0.26004889648708174, 0.25661648398365255, 0.2083764134896241, 0.22107520826287586, 0.21958749546522205, 0.16868770346725903, 0.15947584767033918, 0.1493547022787297, 0.19635899279989855, 0.2064479010187008, 0.19689652923315093, 0.14528210415476495, 0.1565621683834656, 0.14577574229822754, 0.27718558121498504, 0.24976275932713132, 0.23815193508092025, 0.24151767194177787, 0.26017458948918837, 0.2363100719703879, 0.24116091481284918, 0.23994474761811446, 0.26238170723058485, 0.17536522317053294, 0.17434818086482706, 0.17890065814368827, 0.1815408953515586, 0.17377596183290767, 0.17976074808455256, 0.1754619385396332, 0.18043649435650444, 0.18204438946498425, 0.1830828514379601, 0.14073424871104567, 0.1694382472749527, 0.36354004489552905, 0.2917228996158244, 0.3153175252827134, 0.1276472776597266, 0.18206913993881668, 0.4175510880280693, 0.4015654263981109, 0.25840570900172977, 0.3336246107099333, 0.2549961612139524, 0.15164179172460024, 0.2524634625774479, 0.32371089037372436, 0.16893501147558576, 0.29597384611707944, 0.1806619354232989, 0.17982748843418372, 0.19693434660230635, 0.18130763129289373, 0.1763784219087916, 0.19866331812670635, 0.18384760210163653, 0.18733202926576786, 0.19348566994973493, 0.07996660296428382, 0.07296840625395584, 0.0751997901037823, 0.08900294289032396, 0.06520753154297276, 0.09683869631093445, 0.06906253717176802, 0.08584189952206234, 0.07189158007074492]}, "mutation_prompt": null}
{"id": "2290e4a2-d311-4059-87cb-4765c5256cab", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimizationImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n        fitness_values = [wolf['fitness'] for wolf in wolves]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation based on fitness variance\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            variance = np.var(fitness_values)\n            if variance < 0.1:\n                wolves.pop(-1)  # Remove a wolf if variance is low\n            else:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n                fitness_values.append(wolves[-1]['fitness'])\n\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimizationImproved", "description": "Introducing a dynamic population size adjustment based on the fitness variance of wolves to enhance exploration-exploitation balance.", "configspace": "", "generation": 53, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "dd25d9fb-abe2-4b73-9cfc-36392784878a", "metadata": {"aucs": [0.31019831141539145, 0.3764066636662309, 0.4334966776700264, 0.26713514007086925, 0.25507820785465996, 0.2681188390283801, 0.2892993128391528, 0.3229024270581763, 0.28832201069746977, 9.999999999998899e-05, 9.999999999998899e-05, 0.0069153618232769, 0.03669780389509836, 9.999999999998899e-05, 0.06693702790938882, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0860188314779391, 0.07975052295137486, 0.09680544286784387, 0.09039875395130803, 0.08663184037214322, 0.08949739478774588, 0.09211128480155639, 0.09287701992081021, 0.09049447229117791, 0.08368761666251356, 0.07016437125797803, 0.05403912085066842, 0.0977314861276729, 0.0886164045880452, 0.07812267799238382, 0.08641977762476816, 0.08663302108878657, 0.08256382633367809, 0.9650397445306794, 0.9360310360809561, 0.8570754906597035, 0.9126983344662438, 0.8701120650453957, 0.8898720819465875, 0.9373851276455081, 0.8993159838152265, 0.7309130580620814, 0.13468242051665913, 0.13021057173447537, 0.15072692651804287, 0.14883383287941976, 0.1793112375678364, 0.19417563539520755, 0.14380745635823444, 0.149101472565203, 0.1331552719434187, 0.27110394228620227, 0.21283657505902764, 0.15294046994036303, 0.21018186641511982, 0.16894434964533556, 0.2249026050911309, 0.1753974291383511, 0.2001839366227256, 0.2071346496141847, 0.16437231783074657, 0.1671935978365955, 0.14937354759596166, 0.1007875229063695, 0.02810683712624884, 0.05524134769040134, 0.09664801796264677, 0.12018763355788864, 0.15804140741081396, 0.20420418041535737, 0.24523287193829435, 0.19750199961429948, 0.16472584247904176, 0.1626577294771856, 0.1889154205124861, 0.233807292584022, 0.2193640504538622, 0.2542830468625289, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06034943824513084, 0.06879806548936973, 0.034398887133356815, 0.04444130629251153, 0.06646605716341947, 0.08988919257911943, 0.06171697356195871, 0.04959969936769926, 0.06038533989433559, 0.04567631537509331, 0.09386798965922538, 0.0660994441900764, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03531215560371548, 0.0435265356972806, 0.031330014766869474, 0.04646902621649551, 0.014185550917560796, 0.016858509147832046, 0.03530031899262853, 0.029157295560009677, 0.021134526181834867, 0.3003057357964265, 0.307305229919392, 0.3167824549995434, 0.3012517275636658, 0.30750040675440127, 0.2739260438630524, 0.33369458215309267, 0.3387768276940164, 0.32096154007823186, 0.08871716436744614, 0.0656668573354664, 0.08714174289872922, 0.10104118320269462, 0.08715332730511616, 0.10693061204795218, 0.08382990999891604, 0.09216974157621194, 0.09900280816393259, 0.17463389743160185, 0.1433739069039588, 0.1488358376710115, 0.18640239901946265, 0.17283018160117258, 0.18266193539283104, 0.2060020957893507, 0.16160218068185173, 0.1897863599894143, 0.21716949864108526, 0.21103387579845112, 0.2229300687745862, 0.269049007830812, 0.26004889648708174, 0.25661648398365255, 0.2083764134896241, 0.22107520826287586, 0.21958749546522205, 0.16868770346725903, 0.15947584767033918, 0.1493547022787297, 0.19635899279989855, 0.2064479010187008, 0.19689652923315093, 0.14528210415476495, 0.1565621683834656, 0.14577574229822754, 0.27718558121498504, 0.24976275932713132, 0.23815193508092025, 0.24151767194177787, 0.26017458948918837, 0.2363100719703879, 0.24116091481284918, 0.23994474761811446, 0.26238170723058485, 0.17536522317053294, 0.17434818086482706, 0.17890065814368827, 0.1815408953515586, 0.17377596183290767, 0.17976074808455256, 0.1754619385396332, 0.18043649435650444, 0.18204438946498425, 0.1830828514379601, 0.14073424871104567, 0.1694382472749527, 0.36354004489552905, 0.2917228996158244, 0.3153175252827134, 0.1276472776597266, 0.18206913993881668, 0.4175510880280693, 0.4015654263981109, 0.25840570900172977, 0.3336246107099333, 0.2549961612139524, 0.15164179172460024, 0.2524634625774479, 0.32371089037372436, 0.16893501147558576, 0.29597384611707944, 0.1806619354232989, 0.17982748843418372, 0.19693434660230635, 0.18130763129289373, 0.1763784219087916, 0.19866331812670635, 0.18384760210163653, 0.18733202926576786, 0.19348566994973493, 0.07996660296428382, 0.07296840625395584, 0.0751997901037823, 0.08900294289032396, 0.06520753154297276, 0.09683869631093445, 0.06906253717176802, 0.08584189952206234, 0.07189158007074492]}, "mutation_prompt": null}
{"id": "6d026c5c-6b5b-4921-8a93-e17059e97d2d", "solution": "import numpy as np\n\nclass FastConvergingGreyWolfOptimizationImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def get_alpha_beta_delta(wolves):\n            sorted_wolves = sorted(wolves, key=lambda x: x['fitness'])\n            return sorted_wolves[0], sorted_wolves[1], sorted_wolves[2]\n\n        def update_position(wolf, alpha, beta, delta, prev_fitness):\n            fitness_improvement = prev_fitness - wolf['fitness']\n            step_size = 1.0 - np.exp(-0.1 * fitness_improvement)  # Dynamic step size based on fitness improvement\n            a = 1.8 - 1.6 * (np.arange(self.dim) / (self.dim - 1)) * step_size\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A1 = 2 * a * r1 - a\n            C1 = 2 * r2\n\n            D_alpha = np.abs(C1 * alpha['position'] - wolf['position'])\n            X1 = alpha['position'] - A1 * D_alpha\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A2 = 2 * a * r1 - a\n            C2 = 2 * r2\n\n            D_beta = np.abs(C2 * beta['position'] - wolf['position'])\n            X2 = beta['position'] - A2 * D_beta\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            A3 = 2 * a * r1 - a\n            C3 = 2 * r2\n\n            D_delta = np.abs(C3 * delta['position'] - wolf['position'])\n            X3 = delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            new_position = np.clip(new_position, -5.0, 5.0)\n            return new_position\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n        fitness_values = [wolf['fitness'] for wolf in wolves]\n\n        for i in range(2, self.budget - 3, 2):  # Dynamic population size adaptation based on fitness variance\n            alpha, beta, delta = get_alpha_beta_delta(wolves)\n            variance = np.var(fitness_values)\n            if variance < 0.1:\n                wolves.pop(-1)  # Remove a wolf if variance is low\n            else:\n                wolves.append({'position': np.random.uniform(-5.0, 5.0, self.dim),\n                               'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))})\n                fitness_values.append(wolves[-1]['fitness'])\n\n            for wolf in wolves:\n                prev_fitness = wolf['fitness']\n                wolf['position'] = update_position(wolf, alpha, beta, delta, prev_fitness)\n                wolf['fitness'] = func(wolf['position'])\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingGreyWolfOptimizationImproved", "description": "Introducing a dynamic population size adjustment based on the fitness variance of wolves to enhance exploration-exploitation balance.", "configspace": "", "generation": 53, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "dd25d9fb-abe2-4b73-9cfc-36392784878a", "metadata": {"aucs": [0.31019831141539145, 0.3764066636662309, 0.4334966776700264, 0.26713514007086925, 0.25507820785465996, 0.2681188390283801, 0.2892993128391528, 0.3229024270581763, 0.28832201069746977, 9.999999999998899e-05, 9.999999999998899e-05, 0.0069153618232769, 0.03669780389509836, 9.999999999998899e-05, 0.06693702790938882, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0860188314779391, 0.07975052295137486, 0.09680544286784387, 0.09039875395130803, 0.08663184037214322, 0.08949739478774588, 0.09211128480155639, 0.09287701992081021, 0.09049447229117791, 0.08368761666251356, 0.07016437125797803, 0.05403912085066842, 0.0977314861276729, 0.0886164045880452, 0.07812267799238382, 0.08641977762476816, 0.08663302108878657, 0.08256382633367809, 0.9650397445306794, 0.9360310360809561, 0.8570754906597035, 0.9126983344662438, 0.8701120650453957, 0.8898720819465875, 0.9373851276455081, 0.8993159838152265, 0.7309130580620814, 0.13468242051665913, 0.13021057173447537, 0.15072692651804287, 0.14883383287941976, 0.1793112375678364, 0.19417563539520755, 0.14380745635823444, 0.149101472565203, 0.1331552719434187, 0.27110394228620227, 0.21283657505902764, 0.15294046994036303, 0.21018186641511982, 0.16894434964533556, 0.2249026050911309, 0.1753974291383511, 0.2001839366227256, 0.2071346496141847, 0.16437231783074657, 0.1671935978365955, 0.14937354759596166, 0.1007875229063695, 0.02810683712624884, 0.05524134769040134, 0.09664801796264677, 0.12018763355788864, 0.15804140741081396, 0.20420418041535737, 0.24523287193829435, 0.19750199961429948, 0.16472584247904176, 0.1626577294771856, 0.1889154205124861, 0.233807292584022, 0.2193640504538622, 0.2542830468625289, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06034943824513084, 0.06879806548936973, 0.034398887133356815, 0.04444130629251153, 0.06646605716341947, 0.08988919257911943, 0.06171697356195871, 0.04959969936769926, 0.06038533989433559, 0.04567631537509331, 0.09386798965922538, 0.0660994441900764, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03531215560371548, 0.0435265356972806, 0.031330014766869474, 0.04646902621649551, 0.014185550917560796, 0.016858509147832046, 0.03530031899262853, 0.029157295560009677, 0.021134526181834867, 0.3003057357964265, 0.307305229919392, 0.3167824549995434, 0.3012517275636658, 0.30750040675440127, 0.2739260438630524, 0.33369458215309267, 0.3387768276940164, 0.32096154007823186, 0.08871716436744614, 0.0656668573354664, 0.08714174289872922, 0.10104118320269462, 0.08715332730511616, 0.10693061204795218, 0.08382990999891604, 0.09216974157621194, 0.09900280816393259, 0.17463389743160185, 0.1433739069039588, 0.1488358376710115, 0.18640239901946265, 0.17283018160117258, 0.18266193539283104, 0.2060020957893507, 0.16160218068185173, 0.1897863599894143, 0.21716949864108526, 0.21103387579845112, 0.2229300687745862, 0.269049007830812, 0.26004889648708174, 0.25661648398365255, 0.2083764134896241, 0.22107520826287586, 0.21958749546522205, 0.16868770346725903, 0.15947584767033918, 0.1493547022787297, 0.19635899279989855, 0.2064479010187008, 0.19689652923315093, 0.14528210415476495, 0.1565621683834656, 0.14577574229822754, 0.27718558121498504, 0.24976275932713132, 0.23815193508092025, 0.24151767194177787, 0.26017458948918837, 0.2363100719703879, 0.24116091481284918, 0.23994474761811446, 0.26238170723058485, 0.17536522317053294, 0.17434818086482706, 0.17890065814368827, 0.1815408953515586, 0.17377596183290767, 0.17976074808455256, 0.1754619385396332, 0.18043649435650444, 0.18204438946498425, 0.1830828514379601, 0.14073424871104567, 0.1694382472749527, 0.36354004489552905, 0.2917228996158244, 0.3153175252827134, 0.1276472776597266, 0.18206913993881668, 0.4175510880280693, 0.4015654263981109, 0.25840570900172977, 0.3336246107099333, 0.2549961612139524, 0.15164179172460024, 0.2524634625774479, 0.32371089037372436, 0.16893501147558576, 0.29597384611707944, 0.1806619354232989, 0.17982748843418372, 0.19693434660230635, 0.18130763129289373, 0.1763784219087916, 0.19866331812670635, 0.18384760210163653, 0.18733202926576786, 0.19348566994973493, 0.07996660296428382, 0.07296840625395584, 0.0751997901037823, 0.08900294289032396, 0.06520753154297276, 0.09683869631093445, 0.06906253717176802, 0.08584189952206234, 0.07189158007074492]}, "mutation_prompt": null}
{"id": "35144119-99d9-4840-9210-b2fceb9e8967", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass FastConvergingHybridImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def nelder_mead_local_search(wolf, initial_guess):\n            res = minimize(func, initial_guess, method='Nelder-Mead', options={'xatol': 1e-8, 'disp': False})\n            return res.x\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):\n            for wolf in wolves:\n                local_search_position = nelder_mead_local_search(wolf, wolf['position'])\n                if func(local_search_position) < wolf['fitness']:\n                    wolf['position'] = local_search_position\n                    wolf['fitness'] = func(local_search_position)\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingHybridImproved", "description": "Utilizing a hybrid approach combining particle swarm optimization for global exploration and local search using Nelder-Mead method for exploitation to enhance convergence speed.", "configspace": "", "generation": 67, "fitness": 0.4290270651116855, "feedback": "The algorithm FastConvergingHybridImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43 with standard deviation 0.37.", "error": "", "parent_id": "dd25d9fb-abe2-4b73-9cfc-36392784878a", "metadata": {"aucs": [0.9692511292914919, 0.9763832300346782, 0.9672008512567286, 0.9572711669347027, 0.9776162285510245, 0.9613243242208825, 0.9621430778084161, 0.9622163110591464, 0.9603444424475728, 0.5881711374015139, 0.7507012007714922, 0.5391110636125338, 0.5640413131596212, 0.5453104513341578, 0.7138896751238022, 0.5459471709852637, 0.7385172863762302, 0.528812094568599, 0.03907400542838513, 0.02741462928902305, 9.999999999998899e-05, 0.02735871617878216, 0.01672424602184841, 0.012709236758494669, 0.04272278821155939, 0.017218287961372924, 9.999999999998899e-05, 0.02066640135610609, 0.022962877995053477, 0.005867005388874302, 0.02359825555357764, 0.005575017762554313, 9.999999999998899e-05, 0.03260156736111042, 0.008253018080909724, 9.999999999998899e-05, 0.8655272128482372, 0.9846481327211828, 0.985469431609717, 0.9905185801358699, 0.9853522364907922, 0.9938315471609511, 0.9929337451950465, 0.9946437026453635, 0.9868206018953456, 0.26505573654632686, 0.4924902027866459, 0.3610354440986211, 0.37366317227355794, 0.4634133470245594, 0.260304025503286, 0.515513111693686, 0.44603539409652715, 0.5532330033278356, 0.10029430247433702, 0.037774794445334936, 0.006130802480673658, 0.004562664352103063, 9.999999999998899e-05, 0.0008604104761495979, 0.03182557125601759, 0.1237626315157635, 0.05927876814559163, 0.9477517833706125, 0.9388212653122886, 0.9091159045922832, 0.9375200967942181, 0.9438190992367146, 0.5892190923782661, 0.9447413018088235, 0.795156733114926, 0.9240806256640214, 0.9609926053867376, 0.8436659183315327, 0.927800139193082, 0.9367437583431959, 0.9363495438851109, 0.9321546508734815, 0.9409624669306766, 0.9578129078837267, 0.8657977767226257, 0.5573333677089515, 0.7749330779441528, 0.4814626170566606, 0.9184918214469655, 0.7799634598658611, 0.546037532049982, 0.9300869240278015, 0.9224044964145482, 0.6023143215740627, 0.4289564574922079, 0.542742238622756, 0.5095185833071056, 0.607125703118311, 0.6402063857541246, 0.4680903350614034, 0.39321152098034107, 0.5119247860285616, 0.4115830482049502, 0.3830672846182761, 0.7074860194539913, 0.3787655920032629, 0.9323331285928574, 0.8348217904963726, 0.7189021460305758, 0.328223714702814, 0.621239034347304, 0.6805870476689047, 0.7911616567124873, 0.8378174442078188, 0.6879112888278136, 0.7159926245896309, 0.9387519057518509, 0.8624570138199442, 0.5390983855015086, 0.7074736777389639, 0.6695738628221455, 0.9570988253330481, 0.9412920489815971, 0.9536383166210233, 0.951547771984767, 0.9565229425891609, 0.9136362246800687, 0.9699982235767128, 0.9615913691522336, 0.929969363340055, 0.01287606470470748, 0.0035040764971405736, 0.006657022894675513, 0.006104773434434163, 9.999999999998899e-05, 0.017605185879066676, 0.0006348399002041871, 9.999999999998899e-05, 0.07112183510029024, 0.11530258248821701, 0.16210805417540508, 0.12464183021516251, 0.2171618830405676, 0.12209293131932386, 0.11575315262547681, 0.0976461203654464, 0.08677650727458586, 0.10890785568204886, 0.11991494546640602, 0.12603368312619145, 0.11699249913353849, 0.1463129411783004, 0.11671997166825754, 0.12076636179115707, 0.13915115893134167, 0.12205280236434468, 0.10213235835711798, 0.06030154167251911, 0.05949893052730515, 0.0485722176316985, 0.08319536218684465, 0.05963889670764133, 0.0654491356819894, 0.07087452019232476, 0.057435902292771734, 0.04243597205080185, 0.19155202568926777, 0.060340066452233665, 0.16051809075142354, 0.18760149858140307, 0.10418829334075708, 0.1499070247057812, 0.19030263620183874, 0.10087904721029428, 0.15310124280151416, 0.19573471155281086, 0.1962725138427286, 0.18272103224937242, 0.18260044490784044, 0.2554840078965934, 0.1869356271816981, 0.18870232795422803, 0.19383265942145433, 0.19255540528494752, 0.15705134232249862, 0.17237023614397917, 0.18938690243067524, 0.16782932312209886, 0.18467050448561262, 0.10530486137962036, 0.15941635575771962, 0.18804654804439547, 0.16865070511455904, 0.9695701867293405, 0.9257307778024498, 0.9683587504575015, 0.9008738362827947, 0.9367054770284261, 0.19924995187544148, 0.9530005210442182, 0.10271874714587304, 0.9751025238625814, 0.2424311723574062, 0.20513235206160596, 0.2550444704520479, 0.23990196797909813, 0.2151692267098666, 0.22648356079620924, 0.23675778698820615, 0.2919828384877491, 0.4720926413497386, 0.04205902448939158, 0.04191363757398847, 0.05828326845378162, 0.03858335061066864, 0.015139723048693488, 0.03998784919904319, 0.044366964116072216, 0.02591797782871641, 0.03843029589720248]}, "mutation_prompt": null}
{"id": "4119f984-b82a-455a-a759-2dd930742c85", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicPopulationResizing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def nelder_mead_local_search(wolf, initial_guess):\n            res = minimize(func, initial_guess, method='Nelder-Mead', options={'xatol': 1e-8, 'disp': False})\n            return res.x\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):\n            for wolf in wolves:\n                local_search_position = nelder_mead_local_search(wolf, wolf['position'])\n                if func(local_search_position) < wolf['fitness']:\n                    wolf['position'] = local_search_position\n                    wolf['fitness'] = func(local_search_position)\n            \n            if i % 10 == 0 and i < self.budget - 3:\n                best_wolf = min(wolves, key=lambda x: x['fitness'])\n                worst_wolf = max(wolves, key=lambda x: x['fitness'])\n                new_wolf = {'position': best_wolf['position'], 'fitness': best_wolf['fitness']}\n                wolves[wolves.index(worst_wolf)] = new_wolf\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "DynamicPopulationResizing", "description": "Implementing a dynamic population resizing strategy to adapt the number of wolves based on convergence progress for faster optimization.", "configspace": "", "generation": 68, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_id": "35144119-99d9-4840-9210-b2fceb9e8967", "metadata": {}, "mutation_prompt": null}
{"id": "376fcd68-532c-47d3-ab75-c20b28e63122", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass FastConvergingHybridImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def nelder_mead_local_search(wolf, initial_guess):\n            res = minimize(func, initial_guess, method='Nelder-Mead', options={'xatol': 1e-8, 'disp': False})\n            return res.x\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(6)]  # Increased population size to enhance exploration\n\n        for i in range(2, self.budget - 3, 2):\n            for wolf in wolves:\n                local_search_position = nelder_mead_local_search(wolf, wolf['position'])\n                if func(local_search_position) < wolf['fitness']:\n                    wolf['position'] = local_search_position\n                    wolf['fitness'] = func(local_search_position)\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingHybridImproved", "description": "Implementing a dynamic population size adaptation strategy to enhance exploration and exploitation balance for faster convergence.", "configspace": "", "generation": 69, "fitness": 0.42682633880009, "feedback": "The algorithm FastConvergingHybridImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43 with standard deviation 0.37.", "error": "", "parent_id": "35144119-99d9-4840-9210-b2fceb9e8967", "metadata": {"aucs": [0.9691565582513595, 0.9762878458170217, 0.9671066570004335, 0.9572057857795506, 0.9775745257503272, 0.9614842782526023, 0.9623147939485586, 0.962121464767547, 0.9602511446450591, 0.5414200886344058, 0.7506012007714922, 0.4622046010722749, 0.4809124145780441, 0.5130930083390441, 0.6733888241731625, 0.5294978639390273, 0.6943399240594703, 0.4546404718607837, 0.03906942412553693, 0.027411328286298553, 9.999999999998899e-05, 0.036026768336713366, 0.016722285836699657, 0.027067653921006185, 0.042718081034665345, 0.0172164614084781, 9.999999999998899e-05, 0.020664160881622262, 0.022960179933400604, 0.005866277564251843, 0.023597402689644498, 0.005574340721247295, 9.999999999998899e-05, 0.03259788004303277, 0.00825180423226557, 9.999999999998899e-05, 0.8654296273388669, 0.9845489661519228, 0.9853737110250713, 0.9904195540992613, 0.9852529927922472, 0.9937345962961477, 0.9928478037964119, 0.9945445131523484, 0.9867231776616731, 0.22802595498738487, 0.49231856027110665, 0.31356295556916836, 0.3456707530519666, 0.43841172982324683, 0.25302793229563814, 0.481190520563443, 0.4028167793923939, 0.5045492623804528, 0.10029430247433702, 0.05245403976209584, 0.006130163285922197, 0.004562664352103063, 9.999999999998899e-05, 0.0008419131855494921, 0.03176866258305344, 0.123749380818311, 0.0586320146195749, 0.9476517833706125, 0.9387212653122885, 0.9090159045922832, 0.9374200967942181, 0.9437190992367146, 0.5829087510333243, 0.9446413018088236, 0.7950567331149259, 0.9239806256640214, 0.9608926053867376, 0.8435659183315327, 0.9277001391930819, 0.9366437583431959, 0.936249543885111, 0.9320546508734815, 0.9408624669306767, 0.9577129078837268, 0.8656977767226257, 0.49859490846970034, 0.7748330779441528, 0.3917504572125746, 0.9183918214469655, 0.7527060899769502, 0.46691814775215834, 0.9299869240278015, 0.9223044964145483, 0.6480705732970419, 0.34092290334239883, 0.48204700780322796, 0.4263272291197302, 0.5688202901373297, 0.5923628426134344, 0.388552603469412, 0.36208362261671434, 0.4270359606892432, 0.33056742273991735, 0.3113736696616052, 0.6596213270215912, 0.33280328219905064, 0.9322331285928575, 0.8347217904963725, 0.6856972000479931, 0.3029123109406253, 0.5634544371585024, 0.6225841843595163, 0.7708982697227107, 0.8361294830812812, 0.6541723166654846, 0.6383306486167057, 0.9386519057518509, 0.8495272305475763, 0.49323828334682807, 0.6600690319683133, 0.6424712596948607, 0.9570057120793926, 0.9412027445733239, 0.9535531464033719, 0.9514571907524629, 0.9565104214059146, 0.9135458020300024, 0.9699106230019607, 0.9615010778983268, 0.9298814624274362, 0.012874431138330644, 0.0035036923651181606, 0.006656031798661588, 0.006104773434434163, 9.999999999998899e-05, 0.017605185879066676, 0.0006347742350053531, 9.999999999998899e-05, 0.07111436586765452, 0.11444552558289123, 0.16142308610332334, 0.12462702469801001, 0.21710672678533827, 0.17685896896636188, 0.11574232236425175, 0.09663380934153432, 0.08649346126784585, 0.10889727396943094, 0.11991250508153939, 0.1260298011166926, 0.12014801902976102, 0.1463091496790654, 0.11675535480289656, 0.12071376437078285, 0.13914577153346486, 0.12206549185197457, 0.10212912720131173, 0.06029673578937034, 0.0594935404720065, 0.05867969602320955, 0.08318749714633578, 0.05995290197291758, 0.0654462627311706, 0.07087196501136295, 0.058737076596600324, 0.042606981676065026, 0.19153943718060584, 0.06090703884027804, 0.16051063695461232, 0.18758923223918678, 0.10388838803336597, 0.14989923605421718, 0.19029203535862582, 0.10087382310288373, 0.15309393035051633, 0.19571447737560133, 0.19625220074943395, 0.18270253304068473, 0.18258182242016896, 0.2554577531194706, 0.1869167475733482, 0.18868288318419568, 0.19381238596544892, 0.19253596051491517, 0.7429477976965027, 0.17235778155806747, 0.18944043305405778, 0.18768120009396738, 0.1846635302338816, 0.5936599768886257, 0.15940531037041272, 0.18802958068506537, 0.1686390723749147, 0.9694740015695175, 0.9256337051524122, 0.9682603808559455, 0.9012070167550686, 0.9366076275227225, 0.6639980369361134, 0.9529105162273984, 0.10272026045579463, 0.9750048211552317, 0.24005168905659013, 0.2116596434104897, 0.2530641528088511, 0.23986821785346446, 0.21515244204812312, 0.22625342738016596, 0.23518058488986437, 0.29161313576543635, 0.4275896585051271, 0.04205479161710968, 0.04190905311036297, 0.05827687785926228, 0.03857949056687049, 0.021215269508660817, 0.03998416506919289, 0.04436387641334494, 0.025915271073263857, 0.045505085974893555]}, "mutation_prompt": null}
{"id": "f361b511-8d77-4367-b095-846160f9be73", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass FastConvergingHybridImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def nelder_mead_local_search(wolf, initial_guess):\n            res = minimize(func, initial_guess, method='Nelder-Mead', options={'xatol': 1e-8, 'disp': False})\n            return res.x\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim))} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):\n            for wolf in wolves:\n                local_search_position = nelder_mead_local_search(wolf, wolf['position'])\n                if func(local_search_position) < wolf['fitness']:\n                    wolf['position'] = local_search_position\n                    wolf['fitness'] = func(local_search_position)\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FastConvergingHybridImproved", "description": "Utilizing a hybrid approach combining particle swarm optimization for global exploration and local search using Nelder-Mead method for exploitation to enhance convergence speed.", "configspace": "", "generation": 68, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "35144119-99d9-4840-9210-b2fceb9e8967", "metadata": {"aucs": [0.9692511292914919, 0.9763832300346782, 0.9672008512567286, 0.9572711669347027, 0.9776162285510245, 0.9613243242208825, 0.9621430778084161, 0.9622163110591464, 0.9603444424475728, 0.5881711374015139, 0.7507012007714922, 0.5391110636125338, 0.5640413131596212, 0.5453104513341578, 0.7138896751238022, 0.5459471709852637, 0.7385172863762302, 0.528812094568599, 0.03907400542838513, 0.02741462928902305, 9.999999999998899e-05, 0.02735871617878216, 0.01672424602184841, 0.012709236758494669, 0.04272278821155939, 0.017218287961372924, 9.999999999998899e-05, 0.02066640135610609, 0.022962877995053477, 0.005867005388874302, 0.02359825555357764, 0.005575017762554313, 9.999999999998899e-05, 0.03260156736111042, 0.008253018080909724, 9.999999999998899e-05, 0.8655272128482372, 0.9846481327211828, 0.985469431609717, 0.9905185801358699, 0.9853522364907922, 0.9938315471609511, 0.9929337451950465, 0.9946437026453635, 0.9868206018953456, 0.26505573654632686, 0.4924902027866459, 0.3610354440986211, 0.37366317227355794, 0.4634133470245594, 0.260304025503286, 0.515513111693686, 0.44603539409652715, 0.5532330033278356, 0.10029430247433702, 0.037774794445334936, 0.006130802480673658, 0.004562664352103063, 9.999999999998899e-05, 0.0008604104761495979, 0.03182557125601759, 0.1237626315157635, 0.05927876814559163, 0.9477517833706125, 0.9388212653122886, 0.9091159045922832, 0.9375200967942181, 0.9438190992367146, 0.5892190923782661, 0.9447413018088235, 0.795156733114926, 0.9240806256640214, 0.9609926053867376, 0.8436659183315327, 0.927800139193082, 0.9367437583431959, 0.9363495438851109, 0.9321546508734815, 0.9409624669306766, 0.9578129078837267, 0.8657977767226257, 0.5573333677089515, 0.7749330779441528, 0.4814626170566606, 0.9184918214469655, 0.7799634598658611, 0.546037532049982, 0.9300869240278015, 0.9224044964145482, 0.6023143215740627, 0.4289564574922079, 0.542742238622756, 0.5095185833071056, 0.607125703118311, 0.6402063857541246, 0.4680903350614034, 0.39321152098034107, 0.5119247860285616, 0.4115830482049502, 0.3830672846182761, 0.7074860194539913, 0.3787655920032629, 0.9323331285928574, 0.8348217904963726, 0.7189021460305758, 0.328223714702814, 0.621239034347304, 0.6805870476689047, 0.7911616567124873, 0.8378174442078188, 0.6879112888278136, 0.7159926245896309, 0.9387519057518509, 0.8624570138199442, 0.5390983855015086, 0.7074736777389639, 0.6695738628221455, 0.9570988253330481, 0.9412920489815971, 0.9536383166210233, 0.951547771984767, 0.9565229425891609, 0.9136362246800687, 0.9699982235767128, 0.9615913691522336, 0.929969363340055, 0.01287606470470748, 0.0035040764971405736, 0.006657022894675513, 0.006104773434434163, 9.999999999998899e-05, 0.017605185879066676, 0.0006348399002041871, 9.999999999998899e-05, 0.07112183510029024, 0.11530258248821701, 0.16210805417540508, 0.12464183021516251, 0.2171618830405676, 0.12209293131932386, 0.11575315262547681, 0.0976461203654464, 0.08677650727458586, 0.10890785568204886, 0.11991494546640602, 0.12603368312619145, 0.11699249913353849, 0.1463129411783004, 0.11671997166825754, 0.12076636179115707, 0.13915115893134167, 0.12205280236434468, 0.10213235835711798, 0.06030154167251911, 0.05949893052730515, 0.0485722176316985, 0.08319536218684465, 0.05963889670764133, 0.0654491356819894, 0.07087452019232476, 0.057435902292771734, 0.04243597205080185, 0.19155202568926777, 0.060340066452233665, 0.16051809075142354, 0.18760149858140307, 0.10418829334075708, 0.1499070247057812, 0.19030263620183874, 0.10087904721029428, 0.15310124280151416, 0.19573471155281086, 0.1962725138427286, 0.18272103224937242, 0.18260044490784044, 0.2554840078965934, 0.1869356271816981, 0.18870232795422803, 0.19383265942145433, 0.19255540528494752, 0.15705134232249862, 0.17237023614397917, 0.18938690243067524, 0.16782932312209886, 0.18467050448561262, 0.10530486137962036, 0.15941635575771962, 0.18804654804439547, 0.16865070511455904, 0.9695701867293405, 0.9257307778024498, 0.9683587504575015, 0.9008738362827947, 0.9367054770284261, 0.19924995187544148, 0.9530005210442182, 0.10271874714587304, 0.9751025238625814, 0.2424311723574062, 0.20513235206160596, 0.2550444704520479, 0.23990196797909813, 0.2151692267098666, 0.22648356079620924, 0.23675778698820615, 0.2919828384877491, 0.4720926413497386, 0.04205902448939158, 0.04191363757398847, 0.05828326845378162, 0.03858335061066864, 0.015139723048693488, 0.03998784919904319, 0.044366964116072216, 0.02591797782871641, 0.03843029589720248]}, "mutation_prompt": null}
{"id": "09f4b4be-7b7a-4eb7-90c5-aae9e61ca3a8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicMutationHybridImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def nelder_mead_local_search(wolf, initial_guess, mutation_step):\n            res = minimize(func, initial_guess, method='Nelder-Mead', options={'xatol': mutation_step, 'disp': False})\n            return res.x\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim)),\n                   'mutation_step': 1e-8} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):\n            for wolf in wolves:\n                local_search_position = nelder_mead_local_search(wolf, wolf['position'], wolf['mutation_step'])\n                if func(local_search_position) < wolf['fitness']:\n                    wolf['position'] = local_search_position\n                    wolf['fitness'] = func(local_search_position)\n                    if np.random.rand() < 0.5:\n                        wolf['mutation_step'] *= 0.9 # Dynamic mutation step adjustment\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "DynamicMutationHybridImproved", "description": "Implementing a dynamic mutation strategy that adaptively adjusts the local search intensity based on the function landscape to enhance convergence speed.", "configspace": "", "generation": 71, "fitness": 0.4290295000149072, "feedback": "The algorithm DynamicMutationHybridImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43 with standard deviation 0.37.", "error": "", "parent_id": "35144119-99d9-4840-9210-b2fceb9e8967", "metadata": {"aucs": [0.9692511292914919, 0.9763832300346782, 0.9672008512567286, 0.9572711669347027, 0.9776162285510245, 0.9613243242208825, 0.9621430778084161, 0.9622163110591464, 0.9603444424475728, 0.5881711374015139, 0.7507012007714922, 0.5391110636125338, 0.5640413131596212, 0.5453104513341578, 0.7138896751238022, 0.5459471709852637, 0.7385172863762302, 0.528812094568599, 0.03907400542838513, 0.02741462928902305, 9.999999999998899e-05, 0.02735871617878216, 0.01672424602184841, 0.012709236758494669, 0.04272278821155939, 0.017218287961372924, 9.999999999998899e-05, 0.02066640135610609, 0.022962877995053477, 0.005867005388874302, 0.02359825370546731, 0.005575017762554313, 9.999999999998899e-05, 0.03260156736111042, 0.008253018080909724, 9.999999999998899e-05, 0.8655272128482372, 0.9846481327211828, 0.985469431609717, 0.9905185801358699, 0.9853522364907922, 0.9938315471609511, 0.9929337451950465, 0.9946437026453635, 0.9868206018953456, 0.26505573654632686, 0.4924902027866459, 0.3610354440986211, 0.37366317227355794, 0.4634133470245594, 0.260304025503286, 0.515513111693686, 0.44603539409652715, 0.5532330033278356, 0.10029430247433702, 0.037774794445334936, 0.006130802480673658, 0.004562664352103063, 9.999999999998899e-05, 0.0008597029295146497, 0.03182557125601759, 0.1237626315157635, 0.05927876814559163, 0.9477517833706125, 0.9388212653122886, 0.9091159045922832, 0.9375200967942181, 0.9438190992367146, 0.5892190923782661, 0.9447413018088235, 0.795156733114926, 0.9240806256640214, 0.9609926053867376, 0.8436659183315327, 0.927800139193082, 0.9367437583431959, 0.9363495438851109, 0.9321546508734815, 0.9409624669306766, 0.9578129078837267, 0.8657977767226257, 0.5573333677089515, 0.7749330779441528, 0.4814626170566606, 0.9184918214469655, 0.7799634598658611, 0.546037532049982, 0.9300869240278015, 0.9224044964145482, 0.6023143215740627, 0.4289564574922079, 0.542742238622756, 0.5095185833071056, 0.607125703118311, 0.6402063857541246, 0.4680903350614034, 0.39321152098034107, 0.5119247860285616, 0.4115830482049502, 0.3830672846182761, 0.7074860194539913, 0.3787655920032629, 0.9323331285928574, 0.8348217904963726, 0.7189021460305758, 0.328223714702814, 0.621239034347304, 0.6805870476689047, 0.7911616567124873, 0.8378174442078188, 0.6879112888278136, 0.7159433206842105, 0.9387519057518509, 0.8624570138199442, 0.5390983855015086, 0.7074736777389639, 0.6695738628221455, 0.9570988253330481, 0.9412920489815971, 0.9536383166210233, 0.951547771984767, 0.9565229425891609, 0.9136362246800687, 0.9699982235767128, 0.9615913691522336, 0.929969363340055, 0.01287606470470748, 0.0035040764971405736, 0.006657022894675513, 0.006104773434434163, 9.999999999998899e-05, 0.017605185879066676, 0.0006348399002041871, 9.999999999998899e-05, 0.07112183510029024, 0.11530080973697132, 0.16208875375547327, 0.12464183020863295, 0.21716188304134565, 0.12209293131932297, 0.11575315262617514, 0.09763765231021948, 0.08674973544747122, 0.10890779975186338, 0.11991494546640602, 0.12603368312619145, 0.11699249913353849, 0.1463129411783004, 0.11671997166825754, 0.12076636161390375, 0.13915115893134167, 0.12205280236434468, 0.10213235835711798, 0.06030154167251911, 0.05949893052730515, 0.0485722176316985, 0.08319536218684465, 0.05963889670764133, 0.0654491356819894, 0.07087452019232476, 0.057435902292771734, 0.04243597205080185, 0.19155202568926777, 0.060340066452233665, 0.16051809075142354, 0.18760149858140307, 0.10418829334075708, 0.1499070247057812, 0.19030263620183874, 0.10087904721029428, 0.15310124280151416, 0.19573471155281086, 0.1962725138427286, 0.18272103224937242, 0.18260044490784044, 0.2554840078965934, 0.1869356271816981, 0.18870232795422803, 0.19383265942145433, 0.19255540528494752, 0.15705134232249862, 0.17237023614397917, 0.18938690243067524, 0.16782932312209886, 0.18467050448561262, 0.10530486137962036, 0.15941635575771962, 0.18804654804439547, 0.16865070511455904, 0.9695701867293405, 0.9257307778024498, 0.9683587504575015, 0.9008738362827947, 0.9367054770284261, 0.19924995187544148, 0.9530005210442182, 0.10271874714587304, 0.9751025238625814, 0.24243114063295157, 0.20508100096547155, 0.25501048054580033, 0.23996363797317777, 0.2151688862276674, 0.22648356691006633, 0.23675428739759607, 0.2919827299001141, 0.4727526081911596, 0.04205902448939158, 0.04191363757398847, 0.05828326845378162, 0.03858335061066864, 0.015139723048693488, 0.03998784919904319, 0.044366964116072216, 0.02591797782871641, 0.03843029589720248]}, "mutation_prompt": null}
{"id": "b371f600-0d64-46d0-b862-e44a28be9185", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicMutationHybridImprovedFaster:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def nelder_mead_local_search(wolf, initial_guess, mutation_step):\n            res = minimize(func, initial_guess, method='Nelder-Mead', options={'xatol': mutation_step, 'disp': False})\n            return res.x\n        \n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim)),\n                   'mutation_step': 1e-8} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):\n            for wolf in wolves:\n                local_search_position = nelder_mead_local_search(wolf, wolf['position'], wolf['mutation_step'])\n                new_fitness = func(local_search_position)\n                if new_fitness < wolf['fitness']:\n                    wolf['position'] = local_search_position\n                    wolf['fitness'] = new_fitness\n                    wolf['mutation_step'] *= 0.9 + 0.1 * (wolf['fitness'] - new_fitness) / abs(wolf['fitness'] - new_fitness) # Dynamic mutation step adjustment based on fitness improvement\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "DynamicMutationHybridImprovedFaster", "description": "Introducing a dynamically adjusting mutation step based on the fitness improvement of each wolf to expedite convergence speed.", "configspace": "", "generation": 72, "fitness": -Infinity, "feedback": "An exception occurred: ZeroDivisionError('float division by zero').", "error": "ZeroDivisionError('float division by zero')", "parent_id": "09f4b4be-7b7a-4eb7-90c5-aae9e61ca3a8", "metadata": {}, "mutation_prompt": null}
{"id": "15b6f0ca-e1da-4d82-b05c-108e8af78ceb", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicMutationHybridImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def nelder_mead_local_search(wolf, initial_guess, mutation_step):\n            res = minimize(func, initial_guess, method='Nelder-Mead', options={'xatol': mutation_step, 'disp': False})\n            return res.x\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim)),\n                   'mutation_step': 1e-8} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):\n            for wolf in wolves:\n                local_search_position = nelder_mead_local_search(wolf, wolf['position'], wolf['mutation_step'])\n                if func(local_search_position) < wolf['fitness']:\n                    wolf['position'] = local_search_position\n                    wolf['fitness'] = func(local_search_position)\n                    if np.random.rand() < 0.5:\n                        wolf['mutation_step'] *= 0.9 # Dynamic mutation step adjustment\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "DynamicMutationHybridImproved", "description": "Implementing a dynamic mutation strategy that adaptively adjusts the local search intensity based on the function landscape to enhance convergence speed.", "configspace": "", "generation": 72, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "09f4b4be-7b7a-4eb7-90c5-aae9e61ca3a8", "metadata": {"aucs": [0.9692511292914919, 0.9763832300346782, 0.9672008512567286, 0.9572711669347027, 0.9776162285510245, 0.9613243242208825, 0.9621430778084161, 0.9622163110591464, 0.9603444424475728, 0.5881711374015139, 0.7507012007714922, 0.5391110636125338, 0.5640413131596212, 0.5453104513341578, 0.7138896751238022, 0.5459471709852637, 0.7385172863762302, 0.528812094568599, 0.03907400542838513, 0.02741462928902305, 9.999999999998899e-05, 0.02735871617878216, 0.01672424602184841, 0.012709236758494669, 0.04272278821155939, 0.017218287961372924, 9.999999999998899e-05, 0.02066640135610609, 0.022962877995053477, 0.005867005388874302, 0.02359825370546731, 0.005575017762554313, 9.999999999998899e-05, 0.03260156736111042, 0.008253018080909724, 9.999999999998899e-05, 0.8655272128482372, 0.9846481327211828, 0.985469431609717, 0.9905185801358699, 0.9853522364907922, 0.9938315471609511, 0.9929337451950465, 0.9946437026453635, 0.9868206018953456, 0.26505573654632686, 0.4924902027866459, 0.3610354440986211, 0.37366317227355794, 0.4634133470245594, 0.260304025503286, 0.515513111693686, 0.44603539409652715, 0.5532330033278356, 0.10029430247433702, 0.037774794445334936, 0.006130802480673658, 0.004562664352103063, 9.999999999998899e-05, 0.0008597029295146497, 0.03182557125601759, 0.1237626315157635, 0.05927876814559163, 0.9477517833706125, 0.9388212653122886, 0.9091159045922832, 0.9375200967942181, 0.9438190992367146, 0.5892190923782661, 0.9447413018088235, 0.795156733114926, 0.9240806256640214, 0.9609926053867376, 0.8436659183315327, 0.927800139193082, 0.9367437583431959, 0.9363495438851109, 0.9321546508734815, 0.9409624669306766, 0.9578129078837267, 0.8657977767226257, 0.5573333677089515, 0.7749330779441528, 0.4814626170566606, 0.9184918214469655, 0.7799634598658611, 0.546037532049982, 0.9300869240278015, 0.9224044964145482, 0.6023143215740627, 0.4289564574922079, 0.542742238622756, 0.5095185833071056, 0.607125703118311, 0.6402063857541246, 0.4680903350614034, 0.39321152098034107, 0.5119247860285616, 0.4115830482049502, 0.3830672846182761, 0.7074860194539913, 0.3787655920032629, 0.9323331285928574, 0.8348217904963726, 0.7189021460305758, 0.328223714702814, 0.621239034347304, 0.6805870476689047, 0.7911616567124873, 0.8378174442078188, 0.6879112888278136, 0.7159433206842105, 0.9387519057518509, 0.8624570138199442, 0.5390983855015086, 0.7074736777389639, 0.6695738628221455, 0.9570988253330481, 0.9412920489815971, 0.9536383166210233, 0.951547771984767, 0.9565229425891609, 0.9136362246800687, 0.9699982235767128, 0.9615913691522336, 0.929969363340055, 0.01287606470470748, 0.0035040764971405736, 0.006657022894675513, 0.006104773434434163, 9.999999999998899e-05, 0.017605185879066676, 0.0006348399002041871, 9.999999999998899e-05, 0.07112183510029024, 0.11530080973697132, 0.16208875375547327, 0.12464183020863295, 0.21716188304134565, 0.12209293131932297, 0.11575315262617514, 0.09763765231021948, 0.08674973544747122, 0.10890779975186338, 0.11991494546640602, 0.12603368312619145, 0.11699249913353849, 0.1463129411783004, 0.11671997166825754, 0.12076636161390375, 0.13915115893134167, 0.12205280236434468, 0.10213235835711798, 0.06030154167251911, 0.05949893052730515, 0.0485722176316985, 0.08319536218684465, 0.05963889670764133, 0.0654491356819894, 0.07087452019232476, 0.057435902292771734, 0.04243597205080185, 0.19155202568926777, 0.060340066452233665, 0.16051809075142354, 0.18760149858140307, 0.10418829334075708, 0.1499070247057812, 0.19030263620183874, 0.10087904721029428, 0.15310124280151416, 0.19573471155281086, 0.1962725138427286, 0.18272103224937242, 0.18260044490784044, 0.2554840078965934, 0.1869356271816981, 0.18870232795422803, 0.19383265942145433, 0.19255540528494752, 0.15705134232249862, 0.17237023614397917, 0.18938690243067524, 0.16782932312209886, 0.18467050448561262, 0.10530486137962036, 0.15941635575771962, 0.18804654804439547, 0.16865070511455904, 0.9695701867293405, 0.9257307778024498, 0.9683587504575015, 0.9008738362827947, 0.9367054770284261, 0.19924995187544148, 0.9530005210442182, 0.10271874714587304, 0.9751025238625814, 0.24243114063295157, 0.20508100096547155, 0.25501048054580033, 0.23996363797317777, 0.2151688862276674, 0.22648356691006633, 0.23675428739759607, 0.2919827299001141, 0.4727526081911596, 0.04205902448939158, 0.04191363757398847, 0.05828326845378162, 0.03858335061066864, 0.015139723048693488, 0.03998784919904319, 0.044366964116072216, 0.02591797782871641, 0.03843029589720248]}, "mutation_prompt": null}
{"id": "39625bcc-e78f-4c5b-982a-0bf0e6fa0eb3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicMutationHybridImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def nelder_mead_local_search(wolf, initial_guess, mutation_step):\n            res = minimize(func, initial_guess, method='Nelder-Mead', options={'xatol': mutation_step, 'disp': False})\n            return res.x\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim)),\n                   'mutation_step': 1e-8} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):\n            for wolf in wolves:\n                local_search_position = nelder_mead_local_search(wolf, wolf['position'], wolf['mutation_step'])\n                if func(local_search_position) < wolf['fitness']:\n                    wolf['position'] = local_search_position\n                    wolf['fitness'] = func(local_search_position)\n                    if np.random.rand() < 0.5:\n                        wolf['mutation_step'] *= 0.9 if func(local_search_position) < wolf['fitness'] else 1.1  # Dynamic mutation step adjustment based on fitness improvement\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "DynamicMutationHybridImproved", "description": "Enhanced convergence speed by incorporating a dynamic mutation step adaptation based on fitness improvement, leading to faster optimization.", "configspace": "", "generation": 74, "fitness": 0.42907498879864187, "feedback": "The algorithm DynamicMutationHybridImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43 with standard deviation 0.37.", "error": "", "parent_id": "09f4b4be-7b7a-4eb7-90c5-aae9e61ca3a8", "metadata": {"aucs": [0.9692511292914919, 0.9763832300346782, 0.9672008512567286, 0.9572711669347027, 0.9776162285510245, 0.9613243242208825, 0.9621430778084161, 0.9622163110591464, 0.9603444424475728, 0.5879674452929509, 0.7506147299562811, 0.5388619967233073, 0.5637927236429099, 0.5449706889910033, 0.7137479302147931, 0.545751970411667, 0.7383413288420315, 0.5285441113684579, 0.039071250702955695, 0.027411328286298553, 9.999999999998899e-05, 0.027357938579633645, 0.016719923897321354, 0.012709236758494669, 0.04272074844412077, 0.0172164614084781, 9.999999999998899e-05, 0.020666258984168406, 0.022960179933400604, 0.005865549739629605, 0.0235976661773748, 0.005574340721247295, 9.999999999998899e-05, 0.03259788004303277, 0.008250590383621192, 9.999999999998899e-05, 0.8655272128482372, 0.9846481327211828, 0.985469431609717, 0.9905185801358699, 0.9853522364907922, 0.9938315471609511, 0.9929337451950465, 0.9946437026453635, 0.9868206018953456, 0.26490030257704633, 0.49243281367592917, 0.36080619758827903, 0.37346733715387415, 0.46324558733966636, 0.2602679322496738, 0.5154030614067884, 0.4457928241411879, 0.5530676316593299, 0.10029430247433702, 0.037774794445334936, 0.006130163285922197, 0.004562664352103063, 9.999999999998899e-05, 0.0008602083199681365, 0.03182498478585771, 0.123749380818311, 0.059275321433494677, 0.9477517833706125, 0.9388212653122886, 0.9091159045922832, 0.9375200967942181, 0.9438190992367146, 0.5889637904938649, 0.9447413018088235, 0.7950707882618835, 0.9240806256640214, 0.9609926053867376, 0.8435799734784903, 0.927800139193082, 0.9367437583431959, 0.9363495438851109, 0.9321546508734815, 0.9409624669306766, 0.9578129078837267, 0.8657977767226257, 0.5571242718613882, 0.7748214561400636, 0.4811866958531983, 0.9184918214469655, 0.77984422768158, 0.5458009470670543, 0.9300869240278015, 0.9224044964145482, 0.6020950255150106, 0.42864036755560064, 0.5424420646842045, 0.5092698067975625, 0.6069533882084113, 0.6399765375180819, 0.46784000154869865, 0.3931153193714292, 0.5115802446240376, 0.4112253988923509, 0.3827537115858216, 0.7072953420390915, 0.37838650621273606, 0.9323331285928574, 0.8347506063816775, 0.7187708151636699, 0.32784222216412473, 0.6209668044840285, 0.6804136858027089, 0.7910397714461853, 0.8377113186972311, 0.6878258646943927, 0.7157456832798796, 0.9387519057518509, 0.8624003030089259, 0.5386529914210818, 0.7072036725619184, 0.6693028368736791, 0.9570988253330481, 0.9412920489815971, 0.9536383166210233, 0.951547771984767, 0.9565229425891609, 0.9136362246800687, 0.9699982235767128, 0.9615913691522336, 0.929969363340055, 0.012874431138330644, 0.0035036923651181606, 0.0066550407060740335, 0.006104773434434163, 9.999999999998899e-05, 0.017605185879066676, 0.0006347742350053531, 9.999999999998899e-05, 0.07112183510029024, 0.11529426249901409, 0.16210244863445133, 0.12464181153920706, 0.21716177211865673, 0.12208978677995164, 0.11574811632711535, 0.09764838410196808, 0.08674935194821787, 0.1089053843361335, 0.11991441082864063, 0.1260306547412381, 0.11699249913353849, 0.1463129411783004, 0.11671475947043708, 0.12076601212709792, 0.13915115893134167, 0.12204804965954352, 0.10213077327678932, 0.06030154167251911, 0.059496631564350144, 0.0485722176316985, 0.08319536218684465, 0.059633082272145255, 0.0654491356819894, 0.07087452019232476, 0.057430864883716404, 0.04243203576593513, 0.19155202568926777, 0.060340066452233665, 0.16050512888898427, 0.18760149858140307, 0.10418773605738174, 0.14989627679477435, 0.19030263620183874, 0.10087382310288373, 0.15309901009791882, 0.19573300309129094, 0.19626960569084506, 0.18272103224937242, 0.1825993472740649, 0.25547763956053826, 0.1869356271816981, 0.1886998620222985, 0.193827075845735, 0.19255540528494752, 0.15705134232249862, 0.1723659829708607, 0.18938690243067524, 0.16782932312209886, 0.18466155616916025, 0.10529971913730829, 0.1594112703897026, 0.18803149333560687, 0.16865070511455904, 0.9695701867293405, 0.9256421614852043, 0.9683587504575015, 0.9008738362827947, 0.93662707686559, 0.19924995187544148, 0.9530005210442182, 0.10270551513450532, 0.9751025238625814, 0.24240765912525342, 0.2051609896385066, 0.25503175662160704, 0.23989589263299282, 0.21516513308005236, 0.22648171527120253, 0.23674523725092778, 0.2919665392745173, 0.49361029323735894, 0.04205902448939158, 0.04190905311036297, 0.05828013072068794, 0.03858335061066864, 0.015138707181873712, 0.03998252968663296, 0.044366964116072216, 0.025916009425688946, 0.03842980451644906]}, "mutation_prompt": null}
{"id": "664c035c-d53b-4306-b019-51263e8a32f8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicMutationHybridImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def nelder_mead_local_search(wolf, initial_guess, mutation_step):\n            res = minimize(func, initial_guess, method='Nelder-Mead', options={'xatol': mutation_step, 'disp': False})\n            return res.x\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim)),\n                   'mutation_step': 1e-8} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):\n            for wolf in wolves:\n                local_search_position = nelder_mead_local_search(wolf, wolf['position'], wolf['mutation_step'])\n                if func(local_search_position) < wolf['fitness']:\n                    wolf['position'] = local_search_position\n                    wolf['fitness'] = func(local_search_position)\n                    if np.random.rand() < 0.5:\n                        wolf['mutation_step'] *= 0.9 if func(local_search_position) < wolf['fitness'] else 1.1  # Dynamic mutation step adjustment based on fitness improvement\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "DynamicMutationHybridImproved", "description": "Enhanced convergence speed by incorporating a dynamic mutation step adaptation based on fitness improvement, leading to faster optimization.", "configspace": "", "generation": 75, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "39625bcc-e78f-4c5b-982a-0bf0e6fa0eb3", "metadata": {"aucs": [0.9692511292914919, 0.9763832300346782, 0.9672008512567286, 0.9572711669347027, 0.9776162285510245, 0.9613243242208825, 0.9621430778084161, 0.9622163110591464, 0.9603444424475728, 0.5879674452929509, 0.7506147299562811, 0.5388619967233073, 0.5637927236429099, 0.5449706889910033, 0.7137479302147931, 0.545751970411667, 0.7383413288420315, 0.5285441113684579, 0.039071250702955695, 0.027411328286298553, 9.999999999998899e-05, 0.027357938579633645, 0.016719923897321354, 0.012709236758494669, 0.04272074844412077, 0.0172164614084781, 9.999999999998899e-05, 0.020666258984168406, 0.022960179933400604, 0.005865549739629605, 0.0235976661773748, 0.005574340721247295, 9.999999999998899e-05, 0.03259788004303277, 0.008250590383621192, 9.999999999998899e-05, 0.8655272128482372, 0.9846481327211828, 0.985469431609717, 0.9905185801358699, 0.9853522364907922, 0.9938315471609511, 0.9929337451950465, 0.9946437026453635, 0.9868206018953456, 0.26490030257704633, 0.49243281367592917, 0.36080619758827903, 0.37346733715387415, 0.46324558733966636, 0.2602679322496738, 0.5154030614067884, 0.4457928241411879, 0.5530676316593299, 0.10029430247433702, 0.037774794445334936, 0.006130163285922197, 0.004562664352103063, 9.999999999998899e-05, 0.0008602083199681365, 0.03182498478585771, 0.123749380818311, 0.059275321433494677, 0.9477517833706125, 0.9388212653122886, 0.9091159045922832, 0.9375200967942181, 0.9438190992367146, 0.5889637904938649, 0.9447413018088235, 0.7950707882618835, 0.9240806256640214, 0.9609926053867376, 0.8435799734784903, 0.927800139193082, 0.9367437583431959, 0.9363495438851109, 0.9321546508734815, 0.9409624669306766, 0.9578129078837267, 0.8657977767226257, 0.5571242718613882, 0.7748214561400636, 0.4811866958531983, 0.9184918214469655, 0.77984422768158, 0.5458009470670543, 0.9300869240278015, 0.9224044964145482, 0.6020950255150106, 0.42864036755560064, 0.5424420646842045, 0.5092698067975625, 0.6069533882084113, 0.6399765375180819, 0.46784000154869865, 0.3931153193714292, 0.5115802446240376, 0.4112253988923509, 0.3827537115858216, 0.7072953420390915, 0.37838650621273606, 0.9323331285928574, 0.8347506063816775, 0.7187708151636699, 0.32784222216412473, 0.6209668044840285, 0.6804136858027089, 0.7910397714461853, 0.8377113186972311, 0.6878258646943927, 0.7157456832798796, 0.9387519057518509, 0.8624003030089259, 0.5386529914210818, 0.7072036725619184, 0.6693028368736791, 0.9570988253330481, 0.9412920489815971, 0.9536383166210233, 0.951547771984767, 0.9565229425891609, 0.9136362246800687, 0.9699982235767128, 0.9615913691522336, 0.929969363340055, 0.012874431138330644, 0.0035036923651181606, 0.0066550407060740335, 0.006104773434434163, 9.999999999998899e-05, 0.017605185879066676, 0.0006347742350053531, 9.999999999998899e-05, 0.07112183510029024, 0.11529426249901409, 0.16210244863445133, 0.12464181153920706, 0.21716177211865673, 0.12208978677995164, 0.11574811632711535, 0.09764838410196808, 0.08674935194821787, 0.1089053843361335, 0.11991441082864063, 0.1260306547412381, 0.11699249913353849, 0.1463129411783004, 0.11671475947043708, 0.12076601212709792, 0.13915115893134167, 0.12204804965954352, 0.10213077327678932, 0.06030154167251911, 0.059496631564350144, 0.0485722176316985, 0.08319536218684465, 0.059633082272145255, 0.0654491356819894, 0.07087452019232476, 0.057430864883716404, 0.04243203576593513, 0.19155202568926777, 0.060340066452233665, 0.16050512888898427, 0.18760149858140307, 0.10418773605738174, 0.14989627679477435, 0.19030263620183874, 0.10087382310288373, 0.15309901009791882, 0.19573300309129094, 0.19626960569084506, 0.18272103224937242, 0.1825993472740649, 0.25547763956053826, 0.1869356271816981, 0.1886998620222985, 0.193827075845735, 0.19255540528494752, 0.15705134232249862, 0.1723659829708607, 0.18938690243067524, 0.16782932312209886, 0.18466155616916025, 0.10529971913730829, 0.1594112703897026, 0.18803149333560687, 0.16865070511455904, 0.9695701867293405, 0.9256421614852043, 0.9683587504575015, 0.9008738362827947, 0.93662707686559, 0.19924995187544148, 0.9530005210442182, 0.10270551513450532, 0.9751025238625814, 0.24240765912525342, 0.2051609896385066, 0.25503175662160704, 0.23989589263299282, 0.21516513308005236, 0.22648171527120253, 0.23674523725092778, 0.2919665392745173, 0.49361029323735894, 0.04205902448939158, 0.04190905311036297, 0.05828013072068794, 0.03858335061066864, 0.015138707181873712, 0.03998252968663296, 0.044366964116072216, 0.025916009425688946, 0.03842980451644906]}, "mutation_prompt": null}
{"id": "38979b1c-cad0-49e5-ba87-fc04dab65c51", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicMutationHybridImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def nelder_mead_local_search(wolf, initial_guess, mutation_step):\n            res = minimize(func, initial_guess, method='Nelder-Mead', options={'xatol': mutation_step, 'disp': False})\n            return res.x\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim)),\n                   'mutation_step': 1e-8} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):\n            for wolf in wolves:\n                local_search_position = nelder_mead_local_search(wolf, wolf['position'], wolf['mutation_step'])\n                if func(local_search_position) < wolf['fitness']:\n                    wolf['position'] = local_search_position\n                    wolf['fitness'] = func(local_search_position)\n                    if np.random.rand() < 0.5:\n                        wolf['mutation_step'] *= 0.9 if func(local_search_position) < wolf['fitness'] else 1.1  # Dynamic mutation step adjustment based on fitness improvement\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "DynamicMutationHybridImproved", "description": "Enhanced convergence speed by incorporating a dynamic mutation step adaptation based on fitness improvement, leading to faster optimization.", "configspace": "", "generation": 75, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "39625bcc-e78f-4c5b-982a-0bf0e6fa0eb3", "metadata": {"aucs": [0.9692511292914919, 0.9763832300346782, 0.9672008512567286, 0.9572711669347027, 0.9776162285510245, 0.9613243242208825, 0.9621430778084161, 0.9622163110591464, 0.9603444424475728, 0.5879674452929509, 0.7506147299562811, 0.5388619967233073, 0.5637927236429099, 0.5449706889910033, 0.7137479302147931, 0.545751970411667, 0.7383413288420315, 0.5285441113684579, 0.039071250702955695, 0.027411328286298553, 9.999999999998899e-05, 0.027357938579633645, 0.016719923897321354, 0.012709236758494669, 0.04272074844412077, 0.0172164614084781, 9.999999999998899e-05, 0.020666258984168406, 0.022960179933400604, 0.005865549739629605, 0.0235976661773748, 0.005574340721247295, 9.999999999998899e-05, 0.03259788004303277, 0.008250590383621192, 9.999999999998899e-05, 0.8655272128482372, 0.9846481327211828, 0.985469431609717, 0.9905185801358699, 0.9853522364907922, 0.9938315471609511, 0.9929337451950465, 0.9946437026453635, 0.9868206018953456, 0.26490030257704633, 0.49243281367592917, 0.36080619758827903, 0.37346733715387415, 0.46324558733966636, 0.2602679322496738, 0.5154030614067884, 0.4457928241411879, 0.5530676316593299, 0.10029430247433702, 0.037774794445334936, 0.006130163285922197, 0.004562664352103063, 9.999999999998899e-05, 0.0008602083199681365, 0.03182498478585771, 0.123749380818311, 0.059275321433494677, 0.9477517833706125, 0.9388212653122886, 0.9091159045922832, 0.9375200967942181, 0.9438190992367146, 0.5889637904938649, 0.9447413018088235, 0.7950707882618835, 0.9240806256640214, 0.9609926053867376, 0.8435799734784903, 0.927800139193082, 0.9367437583431959, 0.9363495438851109, 0.9321546508734815, 0.9409624669306766, 0.9578129078837267, 0.8657977767226257, 0.5571242718613882, 0.7748214561400636, 0.4811866958531983, 0.9184918214469655, 0.77984422768158, 0.5458009470670543, 0.9300869240278015, 0.9224044964145482, 0.6020950255150106, 0.42864036755560064, 0.5424420646842045, 0.5092698067975625, 0.6069533882084113, 0.6399765375180819, 0.46784000154869865, 0.3931153193714292, 0.5115802446240376, 0.4112253988923509, 0.3827537115858216, 0.7072953420390915, 0.37838650621273606, 0.9323331285928574, 0.8347506063816775, 0.7187708151636699, 0.32784222216412473, 0.6209668044840285, 0.6804136858027089, 0.7910397714461853, 0.8377113186972311, 0.6878258646943927, 0.7157456832798796, 0.9387519057518509, 0.8624003030089259, 0.5386529914210818, 0.7072036725619184, 0.6693028368736791, 0.9570988253330481, 0.9412920489815971, 0.9536383166210233, 0.951547771984767, 0.9565229425891609, 0.9136362246800687, 0.9699982235767128, 0.9615913691522336, 0.929969363340055, 0.012874431138330644, 0.0035036923651181606, 0.0066550407060740335, 0.006104773434434163, 9.999999999998899e-05, 0.017605185879066676, 0.0006347742350053531, 9.999999999998899e-05, 0.07112183510029024, 0.11529426249901409, 0.16210244863445133, 0.12464181153920706, 0.21716177211865673, 0.12208978677995164, 0.11574811632711535, 0.09764838410196808, 0.08674935194821787, 0.1089053843361335, 0.11991441082864063, 0.1260306547412381, 0.11699249913353849, 0.1463129411783004, 0.11671475947043708, 0.12076601212709792, 0.13915115893134167, 0.12204804965954352, 0.10213077327678932, 0.06030154167251911, 0.059496631564350144, 0.0485722176316985, 0.08319536218684465, 0.059633082272145255, 0.0654491356819894, 0.07087452019232476, 0.057430864883716404, 0.04243203576593513, 0.19155202568926777, 0.060340066452233665, 0.16050512888898427, 0.18760149858140307, 0.10418773605738174, 0.14989627679477435, 0.19030263620183874, 0.10087382310288373, 0.15309901009791882, 0.19573300309129094, 0.19626960569084506, 0.18272103224937242, 0.1825993472740649, 0.25547763956053826, 0.1869356271816981, 0.1886998620222985, 0.193827075845735, 0.19255540528494752, 0.15705134232249862, 0.1723659829708607, 0.18938690243067524, 0.16782932312209886, 0.18466155616916025, 0.10529971913730829, 0.1594112703897026, 0.18803149333560687, 0.16865070511455904, 0.9695701867293405, 0.9256421614852043, 0.9683587504575015, 0.9008738362827947, 0.93662707686559, 0.19924995187544148, 0.9530005210442182, 0.10270551513450532, 0.9751025238625814, 0.24240765912525342, 0.2051609896385066, 0.25503175662160704, 0.23989589263299282, 0.21516513308005236, 0.22648171527120253, 0.23674523725092778, 0.2919665392745173, 0.49361029323735894, 0.04205902448939158, 0.04190905311036297, 0.05828013072068794, 0.03858335061066864, 0.015138707181873712, 0.03998252968663296, 0.044366964116072216, 0.025916009425688946, 0.03842980451644906]}, "mutation_prompt": null}
{"id": "c714d252-d071-4fd4-a703-a32fb01f1059", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicMutationHybridImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def nelder_mead_local_search(wolf, initial_guess, mutation_step):\n            res = minimize(func, initial_guess, method='Nelder-Mead', options={'xatol': mutation_step, 'disp': False})\n            return res.x\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim)),\n                   'mutation_step': 1e-8} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):\n            for wolf in wolves:\n                local_search_position = nelder_mead_local_search(wolf, wolf['position'], wolf['mutation_step'])\n                if func(local_search_position) < wolf['fitness']:\n                    wolf['position'] = local_search_position\n                    wolf['fitness'] = func(local_search_position)\n                    if np.random.rand() < 0.5:\n                        wolf['mutation_step'] *= 0.9 if func(local_search_position) < wolf['fitness'] else 1.1  # Dynamic mutation step adjustment based on fitness improvement\n\n            global_best_position = min(wolves, key=lambda x: x['fitness'])['position']\n            for wolf in wolves:\n                if np.random.rand() < 0.5:\n                    wolf['mutation_step'] *= 0.9 if func(global_best_position) < wolf['fitness'] else 1.1  # Adaptive mutation step adjustment based on global best position\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "DynamicMutationHybridImproved", "description": "Improved convergence speed through adaptive mutation step size update based on the global best position instead of local search outcomes.", "configspace": "", "generation": 77, "fitness": 0.42901809822831527, "feedback": "The algorithm DynamicMutationHybridImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43 with standard deviation 0.37.", "error": "", "parent_id": "39625bcc-e78f-4c5b-982a-0bf0e6fa0eb3", "metadata": {"aucs": [0.9692511292914919, 0.9763832300346782, 0.9672008512567286, 0.9572711669347027, 0.9776162285510245, 0.9613243242208825, 0.9621430778084161, 0.9622163110591464, 0.9603444424475728, 0.5877812135613456, 0.7506147299562811, 0.5386320372546238, 0.5634612709539615, 0.5448031106493747, 0.7136269695832045, 0.5456867037168717, 0.7382533500749322, 0.5282800873813206, 0.039071250702955695, 0.027411328286298553, 9.999999999998899e-05, 0.027357938579633645, 0.016719923897321354, 0.012709236758494669, 0.04272074844412077, 0.0172164614084781, 9.999999999998899e-05, 0.020666258984168406, 0.022960179933400604, 0.005865549739629605, 0.023597663009185643, 0.005574340721247295, 9.999999999998899e-05, 0.03259788004303277, 0.008250590383621192, 9.999999999998899e-05, 0.8655272128482372, 0.9846481327211828, 0.985469431609717, 0.9905185801358699, 0.9853522364907922, 0.9938315471609511, 0.9929337451950465, 0.9946437026453635, 0.9868206018953456, 0.26471664139083695, 0.49241818340206533, 0.3606917557324236, 0.37335588363834327, 0.463195785797749, 0.26026059876555774, 0.5152663403957047, 0.44570671878944945, 0.5529419929139993, 0.10029430247433702, 0.037774794445334936, 0.006130163285922197, 0.004562664352103063, 9.999999999998899e-05, 0.0008590964609702656, 0.03182381184553773, 0.123749380818311, 0.05926153458510741, 0.9477517833706125, 0.9388212653122886, 0.9091159045922832, 0.9375200967942181, 0.9438190992367146, 0.5888361395516646, 0.9447413018088235, 0.7950707882618835, 0.9240806256640214, 0.9609926053867376, 0.8435799734784903, 0.927800139193082, 0.9367437583431959, 0.9363495438851109, 0.9321546508734815, 0.9409624669306766, 0.9578129078837267, 0.8657977767226257, 0.5568901861957625, 0.7748214561400636, 0.48091839597342556, 0.9184918214469655, 0.7797900213544564, 0.5455643620841266, 0.9300869240278015, 0.9224044964145482, 0.6019731768825047, 0.42828933540330605, 0.5423211161196945, 0.5090210302880195, 0.6068008715897248, 0.6398812410247872, 0.4675896680359939, 0.3929881101533198, 0.511409493901513, 0.41109852350156684, 0.38239645801817357, 0.7072000033316415, 0.3783583165926607, 0.9323331285928574, 0.8347506063816775, 0.7186711211652659, 0.3276483625548442, 0.620851665567484, 0.6802403239365131, 0.7908957472534013, 0.8377067159113571, 0.6875409515196045, 0.7153650292141761, 0.9387519057518509, 0.8623435921979077, 0.5426204065492302, 0.7070971305669396, 0.6697161711556058, 0.9570988253330481, 0.9412920489815971, 0.9536383166210233, 0.951547771984767, 0.9565229425891609, 0.9136362246800687, 0.9699982235767128, 0.9615913691522336, 0.929969363340055, 0.012874431138330644, 0.0035036923651181606, 0.006655040706043058, 0.006104773434434163, 9.999999999998899e-05, 0.017605185879066676, 0.0006347742350053531, 9.999999999998899e-05, 0.07112183510029024, 0.11528611118997834, 0.16209565618920618, 0.12464177419039502, 0.2171616242093678, 0.12208978677994897, 0.1157481044423363, 0.09762726130143451, 0.08676753218855415, 0.10890531442243223, 0.11991441082864063, 0.1260306547412381, 0.11699249913353849, 0.1463129411783004, 0.11671475947043708, 0.12076566033599989, 0.13915115893134167, 0.12204804965954352, 0.10213077327678932, 0.06030154167251911, 0.059496631564350144, 0.0485722176316985, 0.08319536218684465, 0.059633082272145255, 0.0654491356819894, 0.07087452019232476, 0.057430864883716404, 0.04243203576593513, 0.19155202568926766, 0.060340066452233665, 0.16050512888898427, 0.18760149858140307, 0.10418550692388051, 0.14989627679477435, 0.19030263620183874, 0.10087382310288373, 0.15309901009791882, 0.19573300309129094, 0.19626960569084506, 0.18272103224937242, 0.1825993472740649, 0.25547763956053826, 0.1869356271816981, 0.1886998620222985, 0.193827075845735, 0.19255540528494752, 0.15705134232249862, 0.1723659829708607, 0.18938690243067524, 0.16782932312209886, 0.18466155616916025, 0.10529971913730829, 0.1594112703897026, 0.18803149333560687, 0.16865070511455904, 0.9695701867293405, 0.9256421614852043, 0.9683587504575015, 0.9008738362827947, 0.93662707686559, 0.19924995187544148, 0.9530005210442182, 0.10270551513450532, 0.9751025238625814, 0.24238154161441916, 0.20533886975913507, 0.25498748454217934, 0.2398957421594855, 0.2151650979257992, 0.22648040861514662, 0.23672324647296683, 0.29195892889959474, 0.48391153085515537, 0.04205902448939158, 0.04190905311036297, 0.05828013072068794, 0.03858335061066864, 0.015138707181873712, 0.03998252968663296, 0.044366964116072216, 0.025916009425688946, 0.03842980451644906]}, "mutation_prompt": null}
{"id": "7438bb45-51b1-47e3-87e2-bf1805ee9c98", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AcceleratedDynamicMutationHybridImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def nelder_mead_local_search(wolf, initial_guess, mutation_step):\n            res = minimize(func, initial_guess, method='Nelder-Mead', options={'xatol': mutation_step, 'disp': False})\n            return res.x\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim)),\n                   'mutation_step': 1e-8} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):\n            for wolf in wolves:\n                local_search_position = nelder_mead_local_search(wolf, wolf['position'], wolf['mutation_step'])\n                if func(local_search_position) < wolf['fitness']:\n                    wolf['position'] = local_search_position\n                    wolf['fitness'] = func(local_search_position)\n                    fitness_improvement = func(local_search_position) < wolf['fitness']\n                    wolf['mutation_step'] *= 0.98 if fitness_improvement else 1.02  # Adaptive mutation step adjustment proportional to fitness improvement\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "AcceleratedDynamicMutationHybridImproved", "description": "Accelerated convergence leveraging adaptive mutation rate control proportional to fitness improvement, promoting faster optimization dynamics.", "configspace": "", "generation": 78, "fitness": 0.4289422759217814, "feedback": "The algorithm AcceleratedDynamicMutationHybridImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43 with standard deviation 0.37.", "error": "", "parent_id": "39625bcc-e78f-4c5b-982a-0bf0e6fa0eb3", "metadata": {"aucs": [0.9692511292914919, 0.9763832300346782, 0.9672008512567286, 0.9572711669347027, 0.9776162285510245, 0.9613243242208825, 0.9621430778084161, 0.9622163110591464, 0.9603444424475728, 0.5878103111172891, 0.75052825914107, 0.5386895829903084, 0.5636269972984357, 0.5448826940071505, 0.7136568976550239, 0.5455730865117692, 0.7382973394584819, 0.5283641361640293, 0.0390641595161374, 0.027408027283573944, 9.999999999998899e-05, 0.027354992284755686, 0.016718742927632202, 0.012707907062184165, 0.04271502138350747, 0.0172164614084781, 9.999999999998899e-05, 0.020664355796141343, 0.02295748187174773, 0.005864821915007035, 0.02359648900906397, 0.005573663679940055, 9.999999999998899e-05, 0.03259419272495545, 0.008249376534977038, 9.999999999998899e-05, 0.8654365310302723, 0.9846481327211828, 0.985469431609717, 0.9905185801358699, 0.9853522364907922, 0.9938315471609511, 0.9929337451950465, 0.9946437026453635, 0.9868206018953456, 0.26478163455934567, 0.49241818636759926, 0.3606916347995466, 0.3733237231024181, 0.4632115544145694, 0.26022770318725097, 0.5153271913726616, 0.44573429237021756, 0.5529706281880511, 0.10029430247433702, 0.037774794445334936, 0.006129524091170624, 0.004562664352103063, 9.999999999998899e-05, 0.0008601072418774613, 0.03182408401316805, 0.12373613012085827, 0.05926965635748671, 0.9477517833706125, 0.9388212653122886, 0.9091051455421038, 0.9375200967942181, 0.9438190992367146, 0.5888139943897547, 0.9447413018088235, 0.795031854901874, 0.9240806256640214, 0.9609926053867376, 0.8435799734784903, 0.927800139193082, 0.9367437583431959, 0.9363495438851109, 0.9321546508734815, 0.9409624669306766, 0.9578129078837267, 0.8657118318695832, 0.5569736974302315, 0.7747780011935671, 0.48100172811101394, 0.9184918214469655, 0.7798135180080069, 0.5456335637576912, 0.9300869240278015, 0.9224044964145482, 0.6019813106178246, 0.42846485147945335, 0.5423570899033103, 0.5091039557912005, 0.6068192222155032, 0.6399288892714345, 0.4676717837005875, 0.39305012537171435, 0.5114918293033008, 0.41106389065788973, 0.3825115892668969, 0.7072476726853665, 0.37821650775981, 0.9323331285928574, 0.8347268783434458, 0.7186727156295656, 0.3276009287956696, 0.6209067235767879, 0.6802981112252451, 0.7909538922280792, 0.8376150360599303, 0.6875273890818097, 0.715576149131778, 0.9387519057518509, 0.8623624958015804, 0.5384398059369139, 0.7071309177185199, 0.6691523302191791, 0.9570988253330481, 0.9412920489815971, 0.9536383166210233, 0.951547771984767, 0.9565229425891609, 0.9136140925389582, 0.9699982235767128, 0.9615913691522336, 0.9299583137922344, 0.01287279757195392, 0.0035033082330957477, 0.006654049611760859, 0.006104773434434163, 9.999999999998899e-05, 0.017605185879066676, 0.0006346429046075741, 9.999999999998899e-05, 0.07112183510029024, 0.1152844304057824, 0.16209518897857378, 0.12464179286622579, 0.2171435868490913, 0.12208978677994942, 0.11574309191631926, 0.09761541326636813, 0.08677503311089352, 0.10890172407994247, 0.1199138761908749, 0.1260285977891743, 0.11699137448714025, 0.1463129411783004, 0.11671475947043708, 0.12076577730427729, 0.13915115893134167, 0.12204329695474259, 0.10212922599752905, 0.06030071164689543, 0.059496631564350144, 0.04857083817531349, 0.08319536218684465, 0.059633082272145255, 0.0654491356819894, 0.07087452019232476, 0.05742582747466107, 0.0424286847265235, 0.19155202568926766, 0.060340066452233665, 0.1604986479577647, 0.18760149858140307, 0.10418717877400652, 0.14988848814321032, 0.19030263620183874, 0.10087382310288373, 0.15309252242779436, 0.1957295861682511, 0.19626836108138057, 0.18272103224937242, 0.18259715200651372, 0.25547763956053826, 0.186934702030222, 0.1886954812095678, 0.19382530159841715, 0.19255540528494752, 0.15704765433978796, 0.17236172979774234, 0.18938690243067524, 0.1678195501570754, 0.1846605691367995, 0.1052945768949961, 0.1593999605518851, 0.18802396598121263, 0.16865070511455904, 0.9695701867293405, 0.9256421614852043, 0.9683587504575015, 0.9007897023668102, 0.93662707686559, 0.19924995187544148, 0.9530005210442182, 0.1027000699772681, 0.9751025238625814, 0.24238903819140556, 0.20510176014356807, 0.2550088602915652, 0.23988879642810612, 0.2151611486804501, 0.22647591412424095, 0.2367336684395488, 0.29194686042791407, 0.47157156526790445, 0.04205902448939158, 0.04190905311036297, 0.058276992987594034, 0.03858335061066864, 0.015138707181873712, 0.0399798699304279, 0.044366964116072216, 0.025916009425688946, 0.038429558826072574]}, "mutation_prompt": null}
{"id": "ff12aac6-d43c-48c8-a32f-109d17bf478e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicMutationHybridImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def nelder_mead_local_search(wolf, initial_guess, mutation_step):\n            res = minimize(func, initial_guess, method='Nelder-Mead', options={'xatol': mutation_step, 'disp': False})\n            return res.x\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim)),\n                   'mutation_step': 1e-8} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):\n            for wolf in wolves:\n                local_search_position = nelder_mead_local_search(wolf, wolf['position'], wolf['mutation_step'])\n                if func(local_search_position) < wolf['fitness']:\n                    wolf['position'] = local_search_position\n                    wolf['fitness'] = func(local_search_position)\n                    if np.random.rand() < 0.5:\n                        wolf['mutation_step'] *= 0.95 if func(local_search_position) < wolf['fitness'] else 1.05  # Modified mutation step update strategy\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "DynamicMutationHybridImproved", "description": "Improved convergence speed by incorporating a dynamic mutation step adaptation based on fitness improvement with a modified mutation step update strategy, enhancing optimization efficiency.", "configspace": "", "generation": 79, "fitness": 0.42907966272394066, "feedback": "The algorithm DynamicMutationHybridImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43 with standard deviation 0.37.", "error": "", "parent_id": "39625bcc-e78f-4c5b-982a-0bf0e6fa0eb3", "metadata": {"aucs": [0.9692511292914919, 0.9763832300346782, 0.9672008512567286, 0.9572711669347027, 0.9776162285510245, 0.9613243242208825, 0.9621430778084161, 0.9622163110591464, 0.9603444424475728, 0.5879674452929509, 0.7506147299562811, 0.5388619967233073, 0.5637927236429099, 0.5449706889910033, 0.7137479302147931, 0.545751970411667, 0.7383413288420315, 0.5285441113684579, 0.039071250702955695, 0.027411328286298553, 9.999999999998899e-05, 0.027357938579633645, 0.016719923897321354, 0.012709236758494669, 0.04272074844412077, 0.0172164614084781, 9.999999999998899e-05, 0.020666258984168406, 0.022960179933400604, 0.005865549739629605, 0.0235976661773748, 0.005574340721247295, 9.999999999998899e-05, 0.03259788004303277, 0.008250590383621192, 9.999999999998899e-05, 0.8655272128482372, 0.9846481327211828, 0.985469431609717, 0.9905185801358699, 0.9853522364907922, 0.9938315471609511, 0.9929337451950465, 0.9946437026453635, 0.9868206018953456, 0.26490030257704633, 0.49243281367592917, 0.36080619758827903, 0.37346733715387415, 0.46324558733966636, 0.2602679322496738, 0.5154030614067884, 0.4457928241411879, 0.5530676316593299, 0.10029430247433702, 0.037774794445334936, 0.006130163285922197, 0.004562664352103063, 9.999999999998899e-05, 0.0008602083199681365, 0.03182498478585771, 0.123749380818311, 0.059275321433494677, 0.9477517833706125, 0.9388212653122886, 0.9091159045922832, 0.9375200967942181, 0.9438190992367146, 0.5889637904938649, 0.9447413018088235, 0.7950707882618835, 0.9240806256640214, 0.9609926053867376, 0.8435799734784903, 0.927800139193082, 0.9367437583431959, 0.9363495438851109, 0.9321546508734815, 0.9409624669306766, 0.9578129078837267, 0.8657977767226257, 0.5571242718613882, 0.7748214561400636, 0.4811866958531983, 0.9184918214469655, 0.77984422768158, 0.5458009470670543, 0.9300869240278015, 0.9224044964145482, 0.6020950255150106, 0.42864036755560064, 0.5424420646842045, 0.5092698067975625, 0.6069533882084113, 0.6399765375180819, 0.46784000154869865, 0.3931153193714292, 0.5115802446240376, 0.4112253988923509, 0.3827537115858216, 0.7072953420390915, 0.37838650621273606, 0.9323331285928574, 0.8347506063816775, 0.7187708151636699, 0.32784222216412473, 0.6209668044840285, 0.6804136858027089, 0.7910397714461853, 0.8377113186972311, 0.6876508348512127, 0.7157456832798796, 0.9387519057518509, 0.8624003030089259, 0.5386529914210818, 0.7072036725619184, 0.6693028368736791, 0.9570988253330481, 0.9412920489815971, 0.9536383166210233, 0.951547771984767, 0.9565229425891609, 0.9136362246800687, 0.9699982235767128, 0.9615913691522336, 0.929969363340055, 0.012874431138330644, 0.0035036923651181606, 0.006655040706052384, 0.006104773434434163, 9.999999999998899e-05, 0.017605185879066676, 0.0006347742350053531, 9.999999999998899e-05, 0.07112183510029024, 0.11529205750044369, 0.16209992219903202, 0.12464181153959286, 0.2171617721249436, 0.12208978677995075, 0.1157481163282339, 0.09763499846850376, 0.08674922432672882, 0.1089053843361335, 0.11991441082864063, 0.1260306547412381, 0.11699249913353849, 0.1463129411783004, 0.11671475947043708, 0.12076601088632521, 0.13915115893134167, 0.12204804965954352, 0.10213077327678932, 0.06030154167251911, 0.059496631564350144, 0.0485722176316985, 0.08319536218684465, 0.059633082272145255, 0.0654491356819894, 0.07087452019232476, 0.057430864883716404, 0.04243203576593513, 0.19155202568926777, 0.060340066452233665, 0.16050512888898427, 0.18760149858140307, 0.10418773605738174, 0.14989627679477435, 0.19030263620183874, 0.10087382310288373, 0.15309901009791882, 0.19573300309129094, 0.19626960569084506, 0.18272103224937242, 0.1825993472740649, 0.25547763956053826, 0.1869356271816981, 0.1886998620222985, 0.193827075845735, 0.19255540528494752, 0.15705134232249862, 0.1723659829708607, 0.18938690243067524, 0.16782932312209886, 0.18466155616916025, 0.10529971913730829, 0.1594112703897026, 0.18803149333560687, 0.16865070511455904, 0.9695701867293405, 0.9256421614852043, 0.9683587504575015, 0.9008738362827947, 0.93662707686559, 0.19924995187544148, 0.9530005210442182, 0.10270551513450532, 0.9751025238625814, 0.24240765908375406, 0.20514085181850739, 0.25503221956244404, 0.239895844163998, 0.21516512701094437, 0.2264813508159178, 0.23674527269355272, 0.29196218305417376, 0.4948375515587933, 0.04205902448939158, 0.04190905311036297, 0.05828013072068794, 0.03858335061066864, 0.015138707181873712, 0.03998252968663296, 0.044366964116072216, 0.025916009425688946, 0.03842980451644906]}, "mutation_prompt": null}
{"id": "fc84c436-4cba-43af-b9f2-4fd8f7db24ee", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass MultiDirectionalHybridImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def multi_directional_search(wolf, initial_guess, mutation_step):\n            res = minimize(func, initial_guess, method='Nelder-Mead', options={'xatol': mutation_step, 'disp': False})\n            return res.x\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim)),\n                   'mutation_step': 1e-8} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):\n            for wolf in wolves:\n                local_search_position = multi_directional_search(wolf, wolf['position'], wolf['mutation_step'])\n                if func(local_search_position) < wolf['fitness']:\n                    wolf['position'] = local_search_position\n                    wolf['fitness'] = func(local_search_position)\n                    if np.random.rand() < 0.5:\n                        wolf['mutation_step'] *= 0.95 if func(local_search_position) < wolf['fitness'] else 1.05\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "MultiDirectionalHybridImproved", "description": "Enhanced convergence speed by introducing a multi-directional hybrid search strategy that incorporates both local and global exploration for improved optimization efficiency.", "configspace": "", "generation": 80, "fitness": 0.42907966272394066, "feedback": "The algorithm MultiDirectionalHybridImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43 with standard deviation 0.37.", "error": "", "parent_id": "ff12aac6-d43c-48c8-a32f-109d17bf478e", "metadata": {"aucs": [0.9692511292914919, 0.9763832300346782, 0.9672008512567286, 0.9572711669347027, 0.9776162285510245, 0.9613243242208825, 0.9621430778084161, 0.9622163110591464, 0.9603444424475728, 0.5879674452929509, 0.7506147299562811, 0.5388619967233073, 0.5637927236429099, 0.5449706889910033, 0.7137479302147931, 0.545751970411667, 0.7383413288420315, 0.5285441113684579, 0.039071250702955695, 0.027411328286298553, 9.999999999998899e-05, 0.027357938579633645, 0.016719923897321354, 0.012709236758494669, 0.04272074844412077, 0.0172164614084781, 9.999999999998899e-05, 0.020666258984168406, 0.022960179933400604, 0.005865549739629605, 0.0235976661773748, 0.005574340721247295, 9.999999999998899e-05, 0.03259788004303277, 0.008250590383621192, 9.999999999998899e-05, 0.8655272128482372, 0.9846481327211828, 0.985469431609717, 0.9905185801358699, 0.9853522364907922, 0.9938315471609511, 0.9929337451950465, 0.9946437026453635, 0.9868206018953456, 0.26490030257704633, 0.49243281367592917, 0.36080619758827903, 0.37346733715387415, 0.46324558733966636, 0.2602679322496738, 0.5154030614067884, 0.4457928241411879, 0.5530676316593299, 0.10029430247433702, 0.037774794445334936, 0.006130163285922197, 0.004562664352103063, 9.999999999998899e-05, 0.0008602083199681365, 0.03182498478585771, 0.123749380818311, 0.059275321433494677, 0.9477517833706125, 0.9388212653122886, 0.9091159045922832, 0.9375200967942181, 0.9438190992367146, 0.5889637904938649, 0.9447413018088235, 0.7950707882618835, 0.9240806256640214, 0.9609926053867376, 0.8435799734784903, 0.927800139193082, 0.9367437583431959, 0.9363495438851109, 0.9321546508734815, 0.9409624669306766, 0.9578129078837267, 0.8657977767226257, 0.5571242718613882, 0.7748214561400636, 0.4811866958531983, 0.9184918214469655, 0.77984422768158, 0.5458009470670543, 0.9300869240278015, 0.9224044964145482, 0.6020950255150106, 0.42864036755560064, 0.5424420646842045, 0.5092698067975625, 0.6069533882084113, 0.6399765375180819, 0.46784000154869865, 0.3931153193714292, 0.5115802446240376, 0.4112253988923509, 0.3827537115858216, 0.7072953420390915, 0.37838650621273606, 0.9323331285928574, 0.8347506063816775, 0.7187708151636699, 0.32784222216412473, 0.6209668044840285, 0.6804136858027089, 0.7910397714461853, 0.8377113186972311, 0.6876508348512127, 0.7157456832798796, 0.9387519057518509, 0.8624003030089259, 0.5386529914210818, 0.7072036725619184, 0.6693028368736791, 0.9570988253330481, 0.9412920489815971, 0.9536383166210233, 0.951547771984767, 0.9565229425891609, 0.9136362246800687, 0.9699982235767128, 0.9615913691522336, 0.929969363340055, 0.012874431138330644, 0.0035036923651181606, 0.006655040706052384, 0.006104773434434163, 9.999999999998899e-05, 0.017605185879066676, 0.0006347742350053531, 9.999999999998899e-05, 0.07112183510029024, 0.11529205750044369, 0.16209992219903202, 0.12464181153959286, 0.2171617721249436, 0.12208978677995075, 0.1157481163282339, 0.09763499846850376, 0.08674922432672882, 0.1089053843361335, 0.11991441082864063, 0.1260306547412381, 0.11699249913353849, 0.1463129411783004, 0.11671475947043708, 0.12076601088632521, 0.13915115893134167, 0.12204804965954352, 0.10213077327678932, 0.06030154167251911, 0.059496631564350144, 0.0485722176316985, 0.08319536218684465, 0.059633082272145255, 0.0654491356819894, 0.07087452019232476, 0.057430864883716404, 0.04243203576593513, 0.19155202568926777, 0.060340066452233665, 0.16050512888898427, 0.18760149858140307, 0.10418773605738174, 0.14989627679477435, 0.19030263620183874, 0.10087382310288373, 0.15309901009791882, 0.19573300309129094, 0.19626960569084506, 0.18272103224937242, 0.1825993472740649, 0.25547763956053826, 0.1869356271816981, 0.1886998620222985, 0.193827075845735, 0.19255540528494752, 0.15705134232249862, 0.1723659829708607, 0.18938690243067524, 0.16782932312209886, 0.18466155616916025, 0.10529971913730829, 0.1594112703897026, 0.18803149333560687, 0.16865070511455904, 0.9695701867293405, 0.9256421614852043, 0.9683587504575015, 0.9008738362827947, 0.93662707686559, 0.19924995187544148, 0.9530005210442182, 0.10270551513450532, 0.9751025238625814, 0.24240765908375406, 0.20514085181850739, 0.25503221956244404, 0.239895844163998, 0.21516512701094437, 0.2264813508159178, 0.23674527269355272, 0.29196218305417376, 0.4948375515587933, 0.04205902448939158, 0.04190905311036297, 0.05828013072068794, 0.03858335061066864, 0.015138707181873712, 0.03998252968663296, 0.044366964116072216, 0.025916009425688946, 0.03842980451644906]}, "mutation_prompt": null}
{"id": "67eff45e-f047-4fce-83ab-2083e80a1c5f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicMutationHybridEliteSelection:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def nelder_mead_local_search(wolf, initial_guess, mutation_step):\n            res = minimize(func, initial_guess, method='Nelder-Mead', options={'xatol': mutation_step, 'disp': False})\n            return res.x\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim)),\n                   'mutation_step': 1e-8} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):\n            elite_wolf = min(wolves, key=lambda x: x['fitness'])\n            for wolf in wolves:\n                local_search_position = nelder_mead_local_search(wolf, elite_wolf['position'], wolf['mutation_step'])\n                if func(local_search_position) < wolf['fitness']:\n                    wolf['position'] = local_search_position\n                    wolf['fitness'] = func(local_search_position)\n                    if np.random.rand() < 0.5:\n                        wolf['mutation_step'] *= 0.95 if func(local_search_position) < wolf['fitness'] else 1.05  # Modified mutation step update strategy\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "DynamicMutationHybridEliteSelection", "description": "Accelerated convergence by introducing a dynamic elite selection mechanism to enhance exploitation of top-performing solutions.", "configspace": "", "generation": 81, "fitness": 0.3984533818802751, "feedback": "The algorithm DynamicMutationHybridEliteSelection got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.38.", "error": "", "parent_id": "ff12aac6-d43c-48c8-a32f-109d17bf478e", "metadata": {"aucs": [0.9752765145503789, 0.9776798575748927, 0.9672008512567286, 0.9661213862646061, 0.9776162285510245, 0.9566186028080822, 0.9779065518464024, 0.9710453545571045, 0.9603444424475728, 0.5768176575180319, 0.617465495440356, 0.6372828772671175, 0.6682796059534721, 0.8880577310672415, 0.7516057115994113, 0.8399815731008872, 0.807417325611158, 0.8876187723759648, 0.017898048987102455, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.019643909737016463, 0.013270368601513649, 9.999999999998899e-05, 0.004389753537372254, 9.999999999998899e-05, 0.02227670341106236, 9.999999999998899e-05, 9.999999999998899e-05, 0.01960752770993024, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.9053088152202666, 0.9838774043059952, 0.9792719065638998, 0.9905185801358699, 0.9933181941689269, 0.9887501684315951, 0.9929337451950465, 0.9926514124485148, 0.9895565854399554, 0.33868141935065643, 0.5341516594642755, 0.5594668302142108, 0.5113983874386765, 0.40370477364792734, 0.5630785779758873, 0.7189492559405822, 0.32817827596850657, 0.35219904822213566, 0.10029430247433702, 0.037774794445334936, 9.999999999998899e-05, 0.004562664352103063, 9.999999999998899e-05, 9.999999999998899e-05, 0.026281922061989427, 9.999999999998899e-05, 0.009910428504860236, 0.13894996110351365, 0.9388212653122886, 0.9180859063849964, 0.1383449517087192, 0.9217194854285844, 0.13626097437370133, 0.9241333738284413, 0.13793007807770996, 0.9240806256640214, 0.13885645431044646, 0.9229176144286656, 0.9313751359298619, 0.9276338482649339, 0.9363495438851109, 0.9321546508734815, 0.936300466944775, 0.7161079547048798, 0.13565910188750918, 0.6294646017672161, 0.8514160801746733, 0.5875026678272688, 0.6448569529576367, 0.7892878971929855, 0.554225462150101, 0.5716078172882466, 0.44145394181504183, 0.7047296995169131, 0.43240440376858424, 0.7701719996305422, 0.6796677320732891, 0.7668669093402323, 0.44571397045486993, 0.8223230425546316, 0.6803339897444767, 0.4008913098274459, 0.5941489501665482, 0.3871588066267133, 0.4429690825713952, 0.6469651922914472, 0.5641913358306377, 0.9407039850202323, 0.6858508439751596, 0.7124981690453756, 0.7912545226439177, 0.8886212871037895, 0.7701220354798677, 0.9436704072294311, 0.7617931161094675, 0.6015149036059737, 0.9019022885543488, 0.7965876399678533, 0.8169380287153565, 0.9255072341547608, 0.8866053061356172, 0.9490454109974058, 0.9443318190324648, 0.9536383166210233, 0.9482394503212142, 0.9652596043109215, 0.8128904287105287, 0.9652706004799992, 0.9630377375149473, 0.9539701222122924, 9.999999999998899e-05, 9.999999999998899e-05, 0.009398389748126235, 0.006104773434434163, 9.999999999998899e-05, 0.017605185879066676, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12103415953333119, 0.137626906973213, 0.030944977217654324, 0.22626118154282826, 0.09814827392968695, 0.047160847170528486, 0.047402864012135226, 0.048563412437668374, 0.07727462777257932, 0.09606092816498624, 0.10798043199210738, 0.11752610607778058, 0.11757805651737963, 0.06780113639958363, 0.10670761503330284, 0.13915115893134167, 0.07859594671789161, 0.10345743796809714, 0.012684572490199941, 0.054251782291704354, 0.04910755758014096, 0.06203219623439904, 0.0038069087223242537, 0.042416164579499815, 0.045351084647676676, 0.012265924595591837, 0.04604170982620048, 0.19155202568930874, 0.060340066452233665, 0.1691393803418778, 0.07131081269950701, 0.056622964236130446, 0.08176990518360383, 0.10910567834987472, 0.10918537799314743, 0.10208781052073357, 0.1676305595350166, 0.18359303804553118, 0.1599092047142764, 0.18273663274014806, 0.2598269333510873, 0.16370066789961035, 0.19236778242568264, 0.17900676178751784, 0.17425650023701367, 0.12004794006152775, 0.05615002256851509, 0.0730801485090331, 0.07670100066562757, 0.18035322117353936, 0.11300677077567689, 0.16396461104513926, 0.1275215746325311, 0.16865070511455904, 0.038244138611014944, 0.9716096287571805, 0.9683587504575015, 0.9732318906399559, 0.9833369956910688, 0.04551433491298562, 0.018965778980540526, 0.0299572708412712, 0.05888534486907615, 0.1919832694733703, 0.17150011107981267, 0.1582743275205788, 0.21346637111619615, 0.2185018273144742, 0.22902799610545121, 0.24399417033956716, 0.18490272317648737, 0.6426048120237533, 9.999999999998899e-05, 0.0021608381811328847, 9.999999999998899e-05, 9.999999999998899e-05, 0.005876143365987296, 0.008262991384707985, 0.020144545440768713, 0.007370551260637348, 0.0037667590555163777]}, "mutation_prompt": null}
{"id": "a420731b-d57d-4b76-91fe-5354d85cea9a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicMutationHybridImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def nelder_mead_local_search(wolf, initial_guess, mutation_step):\n            res = minimize(func, initial_guess, method='Nelder-Mead', options={'xatol': mutation_step, 'disp': False})\n            return res.x\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim)),\n                   'mutation_step': 1e-8} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):\n            for wolf in wolves:\n                local_search_position = nelder_mead_local_search(wolf, wolf['position'], wolf['mutation_step'])\n                if func(local_search_position) < wolf['fitness']:\n                    wolf['position'] = local_search_position\n                    wolf['fitness'] = func(local_search_position)\n                    if np.random.rand() < 0.5:\n                        wolf['mutation_step'] *= 0.95 if func(local_search_position) < wolf['fitness'] else 1.05  # Modified mutation step update strategy\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "DynamicMutationHybridImproved", "description": "Improved convergence speed by incorporating a dynamic mutation step adaptation based on fitness improvement with a modified mutation step update strategy, enhancing optimization efficiency.", "configspace": "", "generation": 80, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ff12aac6-d43c-48c8-a32f-109d17bf478e", "metadata": {"aucs": [0.9692511292914919, 0.9763832300346782, 0.9672008512567286, 0.9572711669347027, 0.9776162285510245, 0.9613243242208825, 0.9621430778084161, 0.9622163110591464, 0.9603444424475728, 0.5879674452929509, 0.7506147299562811, 0.5388619967233073, 0.5637927236429099, 0.5449706889910033, 0.7137479302147931, 0.545751970411667, 0.7383413288420315, 0.5285441113684579, 0.039071250702955695, 0.027411328286298553, 9.999999999998899e-05, 0.027357938579633645, 0.016719923897321354, 0.012709236758494669, 0.04272074844412077, 0.0172164614084781, 9.999999999998899e-05, 0.020666258984168406, 0.022960179933400604, 0.005865549739629605, 0.0235976661773748, 0.005574340721247295, 9.999999999998899e-05, 0.03259788004303277, 0.008250590383621192, 9.999999999998899e-05, 0.8655272128482372, 0.9846481327211828, 0.985469431609717, 0.9905185801358699, 0.9853522364907922, 0.9938315471609511, 0.9929337451950465, 0.9946437026453635, 0.9868206018953456, 0.26490030257704633, 0.49243281367592917, 0.36080619758827903, 0.37346733715387415, 0.46324558733966636, 0.2602679322496738, 0.5154030614067884, 0.4457928241411879, 0.5530676316593299, 0.10029430247433702, 0.037774794445334936, 0.006130163285922197, 0.004562664352103063, 9.999999999998899e-05, 0.0008602083199681365, 0.03182498478585771, 0.123749380818311, 0.059275321433494677, 0.9477517833706125, 0.9388212653122886, 0.9091159045922832, 0.9375200967942181, 0.9438190992367146, 0.5889637904938649, 0.9447413018088235, 0.7950707882618835, 0.9240806256640214, 0.9609926053867376, 0.8435799734784903, 0.927800139193082, 0.9367437583431959, 0.9363495438851109, 0.9321546508734815, 0.9409624669306766, 0.9578129078837267, 0.8657977767226257, 0.5571242718613882, 0.7748214561400636, 0.4811866958531983, 0.9184918214469655, 0.77984422768158, 0.5458009470670543, 0.9300869240278015, 0.9224044964145482, 0.6020950255150106, 0.42864036755560064, 0.5424420646842045, 0.5092698067975625, 0.6069533882084113, 0.6399765375180819, 0.46784000154869865, 0.3931153193714292, 0.5115802446240376, 0.4112253988923509, 0.3827537115858216, 0.7072953420390915, 0.37838650621273606, 0.9323331285928574, 0.8347506063816775, 0.7187708151636699, 0.32784222216412473, 0.6209668044840285, 0.6804136858027089, 0.7910397714461853, 0.8377113186972311, 0.6876508348512127, 0.7157456832798796, 0.9387519057518509, 0.8624003030089259, 0.5386529914210818, 0.7072036725619184, 0.6693028368736791, 0.9570988253330481, 0.9412920489815971, 0.9536383166210233, 0.951547771984767, 0.9565229425891609, 0.9136362246800687, 0.9699982235767128, 0.9615913691522336, 0.929969363340055, 0.012874431138330644, 0.0035036923651181606, 0.006655040706052384, 0.006104773434434163, 9.999999999998899e-05, 0.017605185879066676, 0.0006347742350053531, 9.999999999998899e-05, 0.07112183510029024, 0.11529205750044369, 0.16209992219903202, 0.12464181153959286, 0.2171617721249436, 0.12208978677995075, 0.1157481163282339, 0.09763499846850376, 0.08674922432672882, 0.1089053843361335, 0.11991441082864063, 0.1260306547412381, 0.11699249913353849, 0.1463129411783004, 0.11671475947043708, 0.12076601088632521, 0.13915115893134167, 0.12204804965954352, 0.10213077327678932, 0.06030154167251911, 0.059496631564350144, 0.0485722176316985, 0.08319536218684465, 0.059633082272145255, 0.0654491356819894, 0.07087452019232476, 0.057430864883716404, 0.04243203576593513, 0.19155202568926777, 0.060340066452233665, 0.16050512888898427, 0.18760149858140307, 0.10418773605738174, 0.14989627679477435, 0.19030263620183874, 0.10087382310288373, 0.15309901009791882, 0.19573300309129094, 0.19626960569084506, 0.18272103224937242, 0.1825993472740649, 0.25547763956053826, 0.1869356271816981, 0.1886998620222985, 0.193827075845735, 0.19255540528494752, 0.15705134232249862, 0.1723659829708607, 0.18938690243067524, 0.16782932312209886, 0.18466155616916025, 0.10529971913730829, 0.1594112703897026, 0.18803149333560687, 0.16865070511455904, 0.9695701867293405, 0.9256421614852043, 0.9683587504575015, 0.9008738362827947, 0.93662707686559, 0.19924995187544148, 0.9530005210442182, 0.10270551513450532, 0.9751025238625814, 0.24240765908375406, 0.20514085181850739, 0.25503221956244404, 0.239895844163998, 0.21516512701094437, 0.2264813508159178, 0.23674527269355272, 0.29196218305417376, 0.4948375515587933, 0.04205902448939158, 0.04190905311036297, 0.05828013072068794, 0.03858335061066864, 0.015138707181873712, 0.03998252968663296, 0.044366964116072216, 0.025916009425688946, 0.03842980451644906]}, "mutation_prompt": null}
{"id": "f116f742-25a3-41b4-b7b4-1dda812c5969", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass FasterDynamicMutationHybridImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def nelder_mead_local_search(wolf, initial_guess, mutation_step):\n            res = minimize(func, initial_guess, method='Nelder-Mead', options={'xatol': mutation_step, 'disp': False})\n            return res.x\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim)),\n                   'mutation_step': 1e-8} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):\n            for wolf in wolves:\n                local_search_position = nelder_mead_local_search(wolf, wolf['position'], wolf['mutation_step'])\n                if func(local_search_position) < wolf['fitness']:\n                    wolf['position'] = local_search_position\n                    wolf['fitness'] = func(local_search_position)\n                    if np.random.rand() < 0.5:\n                        if func(local_search_position) < wolf['fitness']:\n                            wolf['mutation_step'] *= 0.95\n                        else:\n                            wolf['mutation_step'] *= 1.05\n                    else:\n                        wolf['mutation_step'] *= 0.9  # Hybrid strategy combining individual and global search components\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FasterDynamicMutationHybridImproved", "description": "Increase convergence speed by implementing a dynamic mutation step size adaptation based on a hybrid strategy combining individual and global search components, enhancing exploration-exploitation balance.", "configspace": "", "generation": 83, "fitness": 0.4290982666971726, "feedback": "The algorithm FasterDynamicMutationHybridImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43 with standard deviation 0.37.", "error": "", "parent_id": "ff12aac6-d43c-48c8-a32f-109d17bf478e", "metadata": {"aucs": [0.9692511292914919, 0.9763832300346782, 0.9672008512567286, 0.9572711669347027, 0.9776162285510245, 0.9613243242208825, 0.9621430778084161, 0.9622163110591464, 0.9603444424475728, 0.5879674452929509, 0.7506147299562811, 0.5388619967233073, 0.5637927236429099, 0.5449706889910033, 0.7137479302147931, 0.545751970411667, 0.7383413288420315, 0.5285441113684579, 0.039071250702955695, 0.027411328286298553, 9.999999999998899e-05, 0.027357938579633645, 0.016719923897321354, 0.012709236758494669, 0.04272074844412077, 0.0172164614084781, 9.999999999998899e-05, 0.020666258984168406, 0.022960179933400604, 0.005865549739629605, 0.0235976661773748, 0.005574340721247295, 9.999999999998899e-05, 0.03259788004303277, 0.008250590383621192, 9.999999999998899e-05, 0.8655272128482372, 0.9846481327211828, 0.985469431609717, 0.9905185801358699, 0.9853522364907922, 0.9938315471609511, 0.9929337451950465, 0.9946437026453635, 0.9868206018953456, 0.26490030257704633, 0.49243281367592917, 0.36080619758827903, 0.37346733715387415, 0.46324558733966636, 0.2602679322496738, 0.5154030614067884, 0.4457928241411879, 0.5530676316593299, 0.10029430247433702, 0.037774794445334936, 0.006130163285922197, 0.004562664352103063, 9.999999999998899e-05, 0.0008602083199681365, 0.03182498478585771, 0.123749380818311, 0.059275321433494677, 0.9477517833706125, 0.9388212653122886, 0.9091159045922832, 0.9375200967942181, 0.9438190992367146, 0.5889637904938649, 0.9447413018088235, 0.7950707882618835, 0.9240806256640214, 0.9609926053867376, 0.8435799734784903, 0.927800139193082, 0.9367437583431959, 0.9363495438851109, 0.9321546508734815, 0.9409624669306766, 0.9578129078837267, 0.8657977767226257, 0.5571242718613882, 0.7748214561400636, 0.4811866958531983, 0.9184918214469655, 0.77984422768158, 0.5458009470670543, 0.9300869240278015, 0.9224044964145482, 0.6020950255150106, 0.42864036755560064, 0.5424420646842045, 0.5092698067975625, 0.6069533882084113, 0.6399765375180819, 0.46784000154869865, 0.3931153193714292, 0.5115802446240376, 0.4112253988923509, 0.3827537115858216, 0.7072953420390915, 0.37838650621273606, 0.9323331285928574, 0.8347506063816775, 0.7187708151636699, 0.32784222216412473, 0.6209668044840285, 0.6804136858027089, 0.7910397714461853, 0.8377113186972311, 0.6876508348512127, 0.7156869814833634, 0.9387519057518509, 0.8624003030089259, 0.5430584791790345, 0.7072036725619184, 0.6698513552937664, 0.9570988253330481, 0.9412920489815971, 0.9536383166210233, 0.951547771984767, 0.9565229425891609, 0.9136362246800687, 0.9699982235767128, 0.9615913691522336, 0.929969363340055, 0.012874431138330644, 0.0035036923651181606, 0.006655040706052384, 0.006104773434434163, 9.999999999998899e-05, 0.017605185879066676, 0.0006347742350053531, 9.999999999998899e-05, 0.07112183510029024, 0.11529093992495254, 0.16209451717322354, 0.12464181153997256, 0.2171617721249436, 0.12208978677995075, 0.11574810840466065, 0.09761922798123401, 0.08674918573177126, 0.10890534238791283, 0.11991441082864063, 0.1260306547412381, 0.11699249913353849, 0.1463129411783004, 0.11671475947043708, 0.12076600840477991, 0.13915115893134167, 0.12204804965954352, 0.10213077327678932, 0.06030154167251911, 0.059496631564350144, 0.0485722176316985, 0.08319536218684465, 0.059633082272145255, 0.0654491356819894, 0.07087452019232476, 0.057430864883716404, 0.04243203576593513, 0.19155202568926777, 0.060340066452233665, 0.16050512888898427, 0.18760149858140307, 0.10418773605738174, 0.14989627679477435, 0.19030263620183874, 0.10087382310288373, 0.15309901009791882, 0.19573300309129094, 0.19626960569084506, 0.18272103224937242, 0.1825993472740649, 0.25547763956053826, 0.1869356271816981, 0.1886998620222985, 0.193827075845735, 0.19255540528494752, 0.15705134232249862, 0.1723659829708607, 0.18938690243067524, 0.16782932312209886, 0.18466155616916025, 0.10529971913730829, 0.1594112703897026, 0.18803149333560687, 0.16865070511455904, 0.9695701867293405, 0.9256421614852043, 0.9683587504575015, 0.9008738362827947, 0.93662707686559, 0.19924995187544148, 0.9530005210442182, 0.10270551513450532, 0.9751025238625814, 0.24240764593233188, 0.2050641760321642, 0.25503018966395274, 0.23989583692649075, 0.21516510078937723, 0.2264810273074499, 0.23673304257489158, 0.2919621952173096, 0.494074383191176, 0.04205902448939158, 0.04190905311036297, 0.05828013072068794, 0.03858335061066864, 0.015138707181873712, 0.03998252968663296, 0.044366964116072216, 0.025916009425688946, 0.03842980451644906]}, "mutation_prompt": null}
{"id": "9ced3570-2791-44f5-b1ea-0b7c1f506ea0", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass FasterDynamicMutationHybridImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def nelder_mead_local_search(wolf, initial_guess, mutation_step):\n            res = minimize(func, initial_guess, method='Nelder-Mead', options={'xatol': mutation_step, 'disp': False})\n            return res.x\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim)),\n                   'mutation_step': 1e-8} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):\n            for wolf in wolves:\n                local_search_position = nelder_mead_local_search(wolf, wolf['position'], wolf['mutation_step'])\n                if func(local_search_position) < wolf['fitness']:\n                    wolf['position'] = local_search_position\n                    wolf['fitness'] = func(local_search_position)\n                    if np.random.rand() < 0.5:\n                        if func(local_search_position) < wolf['fitness']:\n                            wolf['mutation_step'] *= 0.95\n                        else:\n                            wolf['mutation_step'] *= 1.05\n                    else:\n                        wolf['mutation_step'] *= 0.9  # Hybrid strategy combining individual and global search components\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FasterDynamicMutationHybridImproved", "description": "Increase convergence speed by implementing a dynamic mutation step size adaptation based on a hybrid strategy combining individual and global search components, enhancing exploration-exploitation balance.", "configspace": "", "generation": 84, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "f116f742-25a3-41b4-b7b4-1dda812c5969", "metadata": {"aucs": [0.9692511292914919, 0.9763832300346782, 0.9672008512567286, 0.9572711669347027, 0.9776162285510245, 0.9613243242208825, 0.9621430778084161, 0.9622163110591464, 0.9603444424475728, 0.5879674452929509, 0.7506147299562811, 0.5388619967233073, 0.5637927236429099, 0.5449706889910033, 0.7137479302147931, 0.545751970411667, 0.7383413288420315, 0.5285441113684579, 0.039071250702955695, 0.027411328286298553, 9.999999999998899e-05, 0.027357938579633645, 0.016719923897321354, 0.012709236758494669, 0.04272074844412077, 0.0172164614084781, 9.999999999998899e-05, 0.020666258984168406, 0.022960179933400604, 0.005865549739629605, 0.0235976661773748, 0.005574340721247295, 9.999999999998899e-05, 0.03259788004303277, 0.008250590383621192, 9.999999999998899e-05, 0.8655272128482372, 0.9846481327211828, 0.985469431609717, 0.9905185801358699, 0.9853522364907922, 0.9938315471609511, 0.9929337451950465, 0.9946437026453635, 0.9868206018953456, 0.26490030257704633, 0.49243281367592917, 0.36080619758827903, 0.37346733715387415, 0.46324558733966636, 0.2602679322496738, 0.5154030614067884, 0.4457928241411879, 0.5530676316593299, 0.10029430247433702, 0.037774794445334936, 0.006130163285922197, 0.004562664352103063, 9.999999999998899e-05, 0.0008602083199681365, 0.03182498478585771, 0.123749380818311, 0.059275321433494677, 0.9477517833706125, 0.9388212653122886, 0.9091159045922832, 0.9375200967942181, 0.9438190992367146, 0.5889637904938649, 0.9447413018088235, 0.7950707882618835, 0.9240806256640214, 0.9609926053867376, 0.8435799734784903, 0.927800139193082, 0.9367437583431959, 0.9363495438851109, 0.9321546508734815, 0.9409624669306766, 0.9578129078837267, 0.8657977767226257, 0.5571242718613882, 0.7748214561400636, 0.4811866958531983, 0.9184918214469655, 0.77984422768158, 0.5458009470670543, 0.9300869240278015, 0.9224044964145482, 0.6020950255150106, 0.42864036755560064, 0.5424420646842045, 0.5092698067975625, 0.6069533882084113, 0.6399765375180819, 0.46784000154869865, 0.3931153193714292, 0.5115802446240376, 0.4112253988923509, 0.3827537115858216, 0.7072953420390915, 0.37838650621273606, 0.9323331285928574, 0.8347506063816775, 0.7187708151636699, 0.32784222216412473, 0.6209668044840285, 0.6804136858027089, 0.7910397714461853, 0.8377113186972311, 0.6876508348512127, 0.7156869814833634, 0.9387519057518509, 0.8624003030089259, 0.5430584791790345, 0.7072036725619184, 0.6698513552937664, 0.9570988253330481, 0.9412920489815971, 0.9536383166210233, 0.951547771984767, 0.9565229425891609, 0.9136362246800687, 0.9699982235767128, 0.9615913691522336, 0.929969363340055, 0.012874431138330644, 0.0035036923651181606, 0.006655040706052384, 0.006104773434434163, 9.999999999998899e-05, 0.017605185879066676, 0.0006347742350053531, 9.999999999998899e-05, 0.07112183510029024, 0.11529093992495254, 0.16209451717322354, 0.12464181153997256, 0.2171617721249436, 0.12208978677995075, 0.11574810840466065, 0.09761922798123401, 0.08674918573177126, 0.10890534238791283, 0.11991441082864063, 0.1260306547412381, 0.11699249913353849, 0.1463129411783004, 0.11671475947043708, 0.12076600840477991, 0.13915115893134167, 0.12204804965954352, 0.10213077327678932, 0.06030154167251911, 0.059496631564350144, 0.0485722176316985, 0.08319536218684465, 0.059633082272145255, 0.0654491356819894, 0.07087452019232476, 0.057430864883716404, 0.04243203576593513, 0.19155202568926777, 0.060340066452233665, 0.16050512888898427, 0.18760149858140307, 0.10418773605738174, 0.14989627679477435, 0.19030263620183874, 0.10087382310288373, 0.15309901009791882, 0.19573300309129094, 0.19626960569084506, 0.18272103224937242, 0.1825993472740649, 0.25547763956053826, 0.1869356271816981, 0.1886998620222985, 0.193827075845735, 0.19255540528494752, 0.15705134232249862, 0.1723659829708607, 0.18938690243067524, 0.16782932312209886, 0.18466155616916025, 0.10529971913730829, 0.1594112703897026, 0.18803149333560687, 0.16865070511455904, 0.9695701867293405, 0.9256421614852043, 0.9683587504575015, 0.9008738362827947, 0.93662707686559, 0.19924995187544148, 0.9530005210442182, 0.10270551513450532, 0.9751025238625814, 0.24240764593233188, 0.2050641760321642, 0.25503018966395274, 0.23989583692649075, 0.21516510078937723, 0.2264810273074499, 0.23673304257489158, 0.2919621952173096, 0.494074383191176, 0.04205902448939158, 0.04190905311036297, 0.05828013072068794, 0.03858335061066864, 0.015138707181873712, 0.03998252968663296, 0.044366964116072216, 0.025916009425688946, 0.03842980451644906]}, "mutation_prompt": null}
{"id": "8d2989d2-03f2-44d3-a52a-a4dfbf56507c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass FasterDynamicMutationHybridImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def nelder_mead_local_search(wolf, initial_guess, mutation_step):\n            res = minimize(func, initial_guess, method='Nelder-Mead', options={'xatol': mutation_step, 'disp': False})\n            return res.x\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim)),\n                   'mutation_step': 1e-8} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):\n            for wolf in wolves:\n                local_search_position = nelder_mead_local_search(wolf, wolf['position'], wolf['mutation_step'])\n                if func(local_search_position) < wolf['fitness']:\n                    wolf['position'] = local_search_position\n                    wolf['fitness'] = func(local_search_position)\n                    if np.random.rand() < 0.5:\n                        wolf['mutation_step'] *= 0.95 if func(local_search_position) < wolf['fitness'] else 1.05\n                    else:\n                        wolf['mutation_step'] *= 0.9 * (1 + 0.02 * (func(local_search_position) - wolf['fitness'] < 0))  # Self-adaptive step adjustment based on individual performance\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FasterDynamicMutationHybridImproved", "description": "Improve convergence speed by introducing a self-adaptive mechanism to adjust mutation steps based on individual wolf performance, promoting faster exploration-exploitation balance.", "configspace": "", "generation": 85, "fitness": 0.4290667247238184, "feedback": "The algorithm FasterDynamicMutationHybridImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43 with standard deviation 0.37.", "error": "", "parent_id": "f116f742-25a3-41b4-b7b4-1dda812c5969", "metadata": {"aucs": [0.9692511292914919, 0.9763832300346782, 0.9672008512567286, 0.9572711669347027, 0.9776162285510245, 0.9613243242208825, 0.9621430778084161, 0.9622163110591464, 0.9603444424475728, 0.5878103111172891, 0.75052825914107, 0.5386895829903084, 0.5636269972984357, 0.5448826940071505, 0.7136568976550239, 0.5455730865117692, 0.7382973394584819, 0.5283641361640293, 0.0390641595161374, 0.027408027283573944, 9.999999999998899e-05, 0.027354992284755686, 0.016718742927632202, 0.012707907062184165, 0.04271502138350747, 0.0172164614084781, 9.999999999998899e-05, 0.020664355796141343, 0.02295748187174773, 0.005864821915007035, 0.02359648900906397, 0.005573663679940055, 9.999999999998899e-05, 0.03259419272495545, 0.008249376534977038, 9.999999999998899e-05, 0.8654365310302723, 0.9846481327211828, 0.985469431609717, 0.9905185801358699, 0.9853522364907922, 0.9938315471609511, 0.9929337451950465, 0.9946437026453635, 0.9868206018953456, 0.26478163455934567, 0.49241818636759926, 0.3606916347995466, 0.3733237231024181, 0.4632115544145694, 0.26022770318725097, 0.5153271913726616, 0.44573429237021756, 0.5529706281880511, 0.10029430247433702, 0.037774794445334936, 0.006129524091170624, 0.004562664352103063, 9.999999999998899e-05, 0.0008601072418774613, 0.03182408401316805, 0.12373613012085827, 0.05926965635748671, 0.9477517833706125, 0.9388212653122886, 0.9091051455421038, 0.9375200967942181, 0.9438190992367146, 0.5888139943897547, 0.9447413018088235, 0.795031854901874, 0.9240806256640214, 0.9609926053867376, 0.8435799734784903, 0.927800139193082, 0.9367437583431959, 0.9363495438851109, 0.9321546508734815, 0.9409624669306766, 0.9578129078837267, 0.8657118318695832, 0.5569736974302315, 0.7747780011935671, 0.48100172811101394, 0.9184918214469655, 0.7798135180080069, 0.5456335637576912, 0.9300869240278015, 0.9224044964145482, 0.6019813106178246, 0.42846485147945335, 0.5423570899033103, 0.5091039557912005, 0.6068192222155032, 0.6399288892714345, 0.4676717837005875, 0.39305012537171435, 0.5114918293033008, 0.41106389065788973, 0.3825115892668969, 0.7072476726853665, 0.37821650775981, 0.9323331285928574, 0.8347268783434458, 0.7186727156295656, 0.3276009287956696, 0.6209067235767879, 0.6802981112252451, 0.7909538922280792, 0.8376150360599303, 0.6875273890818097, 0.7155174496890282, 0.9387519057518509, 0.8623624958015804, 0.5428452936948663, 0.7071309177185199, 0.6697008486392664, 0.9570988253330481, 0.9412920489815971, 0.9536383166210233, 0.951547771984767, 0.9565229425891609, 0.9136140925389582, 0.9699982235767128, 0.9615913691522336, 0.9299583137922344, 0.01287279757195392, 0.0035033082330957477, 0.00665404961173921, 0.006104773434434163, 9.999999999998899e-05, 0.017605185879066676, 0.0006346429046075741, 9.999999999998899e-05, 0.07112183510029024, 0.11528331283028437, 0.16208978395276552, 0.12464179286698873, 0.2171435868463799, 0.12208978677995042, 0.11574308399274447, 0.09760341433623887, 0.08674873135041106, 0.1089016821317218, 0.1199138761908749, 0.1260285977891743, 0.11699137448714025, 0.1463129411783004, 0.11671475947043708, 0.12076577482273188, 0.13915115893134167, 0.12204329695474259, 0.10212922599752905, 0.06030071164689543, 0.059496631564350144, 0.04857083817531349, 0.08319536218684465, 0.059633082272145255, 0.0654491356819894, 0.07087452019232476, 0.05742582747466107, 0.0424286847265235, 0.19155202568926766, 0.060340066452233665, 0.1604986479577647, 0.18760149858140307, 0.10418717877400652, 0.14988848814321032, 0.19030263620183874, 0.10087382310288373, 0.15309252242779436, 0.1957295861682511, 0.19626836108138057, 0.18272103224937242, 0.18259715200651372, 0.25547763956053826, 0.186934702030222, 0.1886954812095678, 0.19382530159841715, 0.19255540528494752, 0.15704765433978796, 0.17236172979774234, 0.18938690243067524, 0.1678195501570754, 0.1846605691367995, 0.1052945768949961, 0.1593999605518851, 0.18802396598121263, 0.16865070511455904, 0.9695701867293405, 0.9256421614852043, 0.9683587504575015, 0.9007897023668102, 0.93662707686559, 0.19924995187544148, 0.9530005210442182, 0.1027000699772681, 0.9751025238625814, 0.2423890500556205, 0.2050385019598604, 0.25500874936138684, 0.23988857576933564, 0.21516112087598427, 0.22647559679930562, 0.2367214371700337, 0.2919468550540002, 0.49367823510111, 0.04205902448939158, 0.04190905311036297, 0.058276992987594034, 0.03858335061066864, 0.015138707181873712, 0.0399798699304279, 0.044366964116072216, 0.025916009425688946, 0.038429558826072574]}, "mutation_prompt": null}
{"id": "ee4983b5-0956-4495-9b39-4f0c93b6d869", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass FasterDynamicMutationHybridImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def nelder_mead_local_search(wolf, initial_guess, mutation_step):\n            res = minimize(func, initial_guess, method='Nelder-Mead', options={'xatol': mutation_step, 'disp': False})\n            return res.x\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim)),\n                   'mutation_step': 1e-8} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):\n            for wolf in wolves:\n                local_search_position = nelder_mead_local_search(wolf, wolf['position'], wolf['mutation_step'])\n                if func(local_search_position) < wolf['fitness']:\n                    wolf['position'] = local_search_position\n                    wolf['fitness'] = func(local_search_position)\n                    if np.random.rand() < 0.5:\n                        wolf['mutation_step'] *= 0.95 if func(local_search_position) < wolf['fitness'] else 1.05\n                    else:\n                        wolf['mutation_step'] *= 0.9 * (1 - 0.1 * (func(local_search_position) < wolf['fitness']))\n        \n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FasterDynamicMutationHybridImproved", "description": "Enhance convergence speed by incorporating a dynamic mutation step size adaptation with a self-adjusting mechanism based on individual performance, fostering faster exploration-exploitation balance.", "configspace": "", "generation": 86, "fitness": 0.4290667247238184, "feedback": "The algorithm FasterDynamicMutationHybridImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43 with standard deviation 0.37.", "error": "", "parent_id": "f116f742-25a3-41b4-b7b4-1dda812c5969", "metadata": {"aucs": [0.9692511292914919, 0.9763832300346782, 0.9672008512567286, 0.9572711669347027, 0.9776162285510245, 0.9613243242208825, 0.9621430778084161, 0.9622163110591464, 0.9603444424475728, 0.5878103111172891, 0.75052825914107, 0.5386895829903084, 0.5636269972984357, 0.5448826940071505, 0.7136568976550239, 0.5455730865117692, 0.7382973394584819, 0.5283641361640293, 0.0390641595161374, 0.027408027283573944, 9.999999999998899e-05, 0.027354992284755686, 0.016718742927632202, 0.012707907062184165, 0.04271502138350747, 0.0172164614084781, 9.999999999998899e-05, 0.020664355796141343, 0.02295748187174773, 0.005864821915007035, 0.02359648900906397, 0.005573663679940055, 9.999999999998899e-05, 0.03259419272495545, 0.008249376534977038, 9.999999999998899e-05, 0.8654365310302723, 0.9846481327211828, 0.985469431609717, 0.9905185801358699, 0.9853522364907922, 0.9938315471609511, 0.9929337451950465, 0.9946437026453635, 0.9868206018953456, 0.26478163455934567, 0.49241818636759926, 0.3606916347995466, 0.3733237231024181, 0.4632115544145694, 0.26022770318725097, 0.5153271913726616, 0.44573429237021756, 0.5529706281880511, 0.10029430247433702, 0.037774794445334936, 0.006129524091170624, 0.004562664352103063, 9.999999999998899e-05, 0.0008601072418774613, 0.03182408401316805, 0.12373613012085827, 0.05926965635748671, 0.9477517833706125, 0.9388212653122886, 0.9091051455421038, 0.9375200967942181, 0.9438190992367146, 0.5888139943897547, 0.9447413018088235, 0.795031854901874, 0.9240806256640214, 0.9609926053867376, 0.8435799734784903, 0.927800139193082, 0.9367437583431959, 0.9363495438851109, 0.9321546508734815, 0.9409624669306766, 0.9578129078837267, 0.8657118318695832, 0.5569736974302315, 0.7747780011935671, 0.48100172811101394, 0.9184918214469655, 0.7798135180080069, 0.5456335637576912, 0.9300869240278015, 0.9224044964145482, 0.6019813106178246, 0.42846485147945335, 0.5423570899033103, 0.5091039557912005, 0.6068192222155032, 0.6399288892714345, 0.4676717837005875, 0.39305012537171435, 0.5114918293033008, 0.41106389065788973, 0.3825115892668969, 0.7072476726853665, 0.37821650775981, 0.9323331285928574, 0.8347268783434458, 0.7186727156295656, 0.3276009287956696, 0.6209067235767879, 0.6802981112252451, 0.7909538922280792, 0.8376150360599303, 0.6875273890818097, 0.7155174496890282, 0.9387519057518509, 0.8623624958015804, 0.5428452936948663, 0.7071309177185199, 0.6697008486392664, 0.9570988253330481, 0.9412920489815971, 0.9536383166210233, 0.951547771984767, 0.9565229425891609, 0.9136140925389582, 0.9699982235767128, 0.9615913691522336, 0.9299583137922344, 0.01287279757195392, 0.0035033082330957477, 0.00665404961173921, 0.006104773434434163, 9.999999999998899e-05, 0.017605185879066676, 0.0006346429046075741, 9.999999999998899e-05, 0.07112183510029024, 0.11528331283028437, 0.16208978395276552, 0.12464179286698873, 0.2171435868463799, 0.12208978677995042, 0.11574308399274447, 0.09760341433623887, 0.08674873135041106, 0.1089016821317218, 0.1199138761908749, 0.1260285977891743, 0.11699137448714025, 0.1463129411783004, 0.11671475947043708, 0.12076577482273188, 0.13915115893134167, 0.12204329695474259, 0.10212922599752905, 0.06030071164689543, 0.059496631564350144, 0.04857083817531349, 0.08319536218684465, 0.059633082272145255, 0.0654491356819894, 0.07087452019232476, 0.05742582747466107, 0.0424286847265235, 0.19155202568926766, 0.060340066452233665, 0.1604986479577647, 0.18760149858140307, 0.10418717877400652, 0.14988848814321032, 0.19030263620183874, 0.10087382310288373, 0.15309252242779436, 0.1957295861682511, 0.19626836108138057, 0.18272103224937242, 0.18259715200651372, 0.25547763956053826, 0.186934702030222, 0.1886954812095678, 0.19382530159841715, 0.19255540528494752, 0.15704765433978796, 0.17236172979774234, 0.18938690243067524, 0.1678195501570754, 0.1846605691367995, 0.1052945768949961, 0.1593999605518851, 0.18802396598121263, 0.16865070511455904, 0.9695701867293405, 0.9256421614852043, 0.9683587504575015, 0.9007897023668102, 0.93662707686559, 0.19924995187544148, 0.9530005210442182, 0.1027000699772681, 0.9751025238625814, 0.2423890500556205, 0.2050385019598604, 0.25500874936138684, 0.23988857576933564, 0.21516112087598427, 0.22647559679930562, 0.2367214371700337, 0.2919468550540002, 0.49367823510111, 0.04205902448939158, 0.04190905311036297, 0.058276992987594034, 0.03858335061066864, 0.015138707181873712, 0.0399798699304279, 0.044366964116072216, 0.025916009425688946, 0.038429558826072574]}, "mutation_prompt": null}
{"id": "59c325c5-4fb5-4dda-8202-642b1be8a04d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass FasterDynamicMutationHybridImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def nelder_mead_local_search(wolf, initial_guess, mutation_step):\n            res = minimize(func, initial_guess, method='Nelder-Mead', options={'xatol': mutation_step, 'disp': False})\n            return res.x\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim)),\n                   'mutation_step': 1e-8} for _ in range(5)]\n\n        for i in range(2, self.budget - 3, 2):\n            for wolf in wolves:\n                local_search_position = nelder_mead_local_search(wolf, wolf['position'], wolf['mutation_step'])\n                if func(local_search_position) < wolf['fitness']:\n                    wolf['position'] = local_search_position\n                    wolf['fitness'] = func(local_search_position)\n                    if np.random.rand() < 0.5:\n                        if func(local_search_position) < wolf['fitness']:\n                            wolf['mutation_step'] *= 0.95\n                        else:\n                            wolf['mutation_step'] *= 1.05\n                    else:\n                        wolf['mutation_step'] *= 0.9  # Hybrid strategy combining individual and global search components\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FasterDynamicMutationHybridImproved", "description": "Increase convergence speed by implementing a dynamic mutation step size adaptation based on a hybrid strategy combining individual and global search components, enhancing exploration-exploitation balance.", "configspace": "", "generation": 84, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "f116f742-25a3-41b4-b7b4-1dda812c5969", "metadata": {"aucs": [0.9692511292914919, 0.9763832300346782, 0.9672008512567286, 0.9572711669347027, 0.9776162285510245, 0.9613243242208825, 0.9621430778084161, 0.9622163110591464, 0.9603444424475728, 0.5879674452929509, 0.7506147299562811, 0.5388619967233073, 0.5637927236429099, 0.5449706889910033, 0.7137479302147931, 0.545751970411667, 0.7383413288420315, 0.5285441113684579, 0.039071250702955695, 0.027411328286298553, 9.999999999998899e-05, 0.027357938579633645, 0.016719923897321354, 0.012709236758494669, 0.04272074844412077, 0.0172164614084781, 9.999999999998899e-05, 0.020666258984168406, 0.022960179933400604, 0.005865549739629605, 0.0235976661773748, 0.005574340721247295, 9.999999999998899e-05, 0.03259788004303277, 0.008250590383621192, 9.999999999998899e-05, 0.8655272128482372, 0.9846481327211828, 0.985469431609717, 0.9905185801358699, 0.9853522364907922, 0.9938315471609511, 0.9929337451950465, 0.9946437026453635, 0.9868206018953456, 0.26490030257704633, 0.49243281367592917, 0.36080619758827903, 0.37346733715387415, 0.46324558733966636, 0.2602679322496738, 0.5154030614067884, 0.4457928241411879, 0.5530676316593299, 0.10029430247433702, 0.037774794445334936, 0.006130163285922197, 0.004562664352103063, 9.999999999998899e-05, 0.0008602083199681365, 0.03182498478585771, 0.123749380818311, 0.059275321433494677, 0.9477517833706125, 0.9388212653122886, 0.9091159045922832, 0.9375200967942181, 0.9438190992367146, 0.5889637904938649, 0.9447413018088235, 0.7950707882618835, 0.9240806256640214, 0.9609926053867376, 0.8435799734784903, 0.927800139193082, 0.9367437583431959, 0.9363495438851109, 0.9321546508734815, 0.9409624669306766, 0.9578129078837267, 0.8657977767226257, 0.5571242718613882, 0.7748214561400636, 0.4811866958531983, 0.9184918214469655, 0.77984422768158, 0.5458009470670543, 0.9300869240278015, 0.9224044964145482, 0.6020950255150106, 0.42864036755560064, 0.5424420646842045, 0.5092698067975625, 0.6069533882084113, 0.6399765375180819, 0.46784000154869865, 0.3931153193714292, 0.5115802446240376, 0.4112253988923509, 0.3827537115858216, 0.7072953420390915, 0.37838650621273606, 0.9323331285928574, 0.8347506063816775, 0.7187708151636699, 0.32784222216412473, 0.6209668044840285, 0.6804136858027089, 0.7910397714461853, 0.8377113186972311, 0.6876508348512127, 0.7156869814833634, 0.9387519057518509, 0.8624003030089259, 0.5430584791790345, 0.7072036725619184, 0.6698513552937664, 0.9570988253330481, 0.9412920489815971, 0.9536383166210233, 0.951547771984767, 0.9565229425891609, 0.9136362246800687, 0.9699982235767128, 0.9615913691522336, 0.929969363340055, 0.012874431138330644, 0.0035036923651181606, 0.006655040706052384, 0.006104773434434163, 9.999999999998899e-05, 0.017605185879066676, 0.0006347742350053531, 9.999999999998899e-05, 0.07112183510029024, 0.11529093992495254, 0.16209451717322354, 0.12464181153997256, 0.2171617721249436, 0.12208978677995075, 0.11574810840466065, 0.09761922798123401, 0.08674918573177126, 0.10890534238791283, 0.11991441082864063, 0.1260306547412381, 0.11699249913353849, 0.1463129411783004, 0.11671475947043708, 0.12076600840477991, 0.13915115893134167, 0.12204804965954352, 0.10213077327678932, 0.06030154167251911, 0.059496631564350144, 0.0485722176316985, 0.08319536218684465, 0.059633082272145255, 0.0654491356819894, 0.07087452019232476, 0.057430864883716404, 0.04243203576593513, 0.19155202568926777, 0.060340066452233665, 0.16050512888898427, 0.18760149858140307, 0.10418773605738174, 0.14989627679477435, 0.19030263620183874, 0.10087382310288373, 0.15309901009791882, 0.19573300309129094, 0.19626960569084506, 0.18272103224937242, 0.1825993472740649, 0.25547763956053826, 0.1869356271816981, 0.1886998620222985, 0.193827075845735, 0.19255540528494752, 0.15705134232249862, 0.1723659829708607, 0.18938690243067524, 0.16782932312209886, 0.18466155616916025, 0.10529971913730829, 0.1594112703897026, 0.18803149333560687, 0.16865070511455904, 0.9695701867293405, 0.9256421614852043, 0.9683587504575015, 0.9008738362827947, 0.93662707686559, 0.19924995187544148, 0.9530005210442182, 0.10270551513450532, 0.9751025238625814, 0.24240764593233188, 0.2050641760321642, 0.25503018966395274, 0.23989583692649075, 0.21516510078937723, 0.2264810273074499, 0.23673304257489158, 0.2919621952173096, 0.494074383191176, 0.04205902448939158, 0.04190905311036297, 0.05828013072068794, 0.03858335061066864, 0.015138707181873712, 0.03998252968663296, 0.044366964116072216, 0.025916009425688946, 0.03842980451644906]}, "mutation_prompt": null}
{"id": "2e3ea6b1-5060-433e-b529-a3413f495e04", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass FasterDynamicMutationHybridImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def nelder_mead_local_search(wolf, initial_guess, mutation_step):\n            res = minimize(func, initial_guess, method='Nelder-Mead', options={'xatol': mutation_step, 'disp': False})\n            return res.x\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim)),\n                   'mutation_step': 1e-8} for _ in range(4)]  # Adjusted population size\n\n        for i in range(2, self.budget - 3, 2):\n            for wolf in wolves:\n                local_search_position = nelder_mead_local_search(wolf, wolf['position'], wolf['mutation_step'])\n                if func(local_search_position) < wolf['fitness']:\n                    wolf['position'] = local_search_position\n                    wolf['fitness'] = func(local_search_position)\n                    if np.random.rand() < 0.5:\n                        if func(local_search_position) < wolf['fitness']:\n                            wolf['mutation_step'] *= 0.95\n                        else:\n                            wolf['mutation_step'] *= 1.05\n                    else:\n                        wolf['mutation_step'] *= 0.9  # Hybrid strategy combining individual and global search components\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FasterDynamicMutationHybridImproved", "description": "Improve convergence speed by introducing a dynamic population size adjustment mechanism based on the fitness landscape, enhancing exploration and exploitation balance.", "configspace": "", "generation": 88, "fitness": 0.4389576029648726, "feedback": "The algorithm FasterDynamicMutationHybridImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.44 with standard deviation 0.38.", "error": "", "parent_id": "f116f742-25a3-41b4-b7b4-1dda812c5969", "metadata": {"aucs": [0.9693459040718787, 0.9764786142523346, 0.9672950455130237, 0.9573692180319937, 0.9777109701806243, 0.9614230290583405, 0.9622405165801594, 0.9623104941943011, 0.9604377402500864, 0.6607695660869473, 0.7508012007714923, 0.6159408729965656, 0.6469216222244509, 0.6292834113192709, 0.7543502058639122, 0.6166899418071158, 0.7826506593094402, 0.6170080982767616, 0.03907149554441525, 0.02741793029174766, 9.999999999998899e-05, 0.027357938579633645, 0.0074902255609790025, 0.012710566454805172, 0.03507297424860678, 0.017220114514267748, 9.999999999998899e-05, 0.020666738642563187, 0.02296557605670646, 9.999999999998899e-05, 0.01960752770993024, 0.005575694803861331, 9.999999999998899e-05, 0.03259788004303277, 9.999999999998899e-05, 9.999999999998899e-05, 0.8655341165396426, 0.9847388829898945, 0.9855651521943627, 0.9906176061724785, 0.9854514801893373, 0.9939284980257546, 0.993032926985032, 0.9947428921383786, 0.9869180261290181, 0.3019579956474596, 0.5025365396803674, 0.4219606029847157, 0.38783824027996916, 0.48837505754106636, 0.29711139342602244, 0.5543391717347674, 0.4893856126099345, 0.6044348896285623, 0.10029430247433702, 9.999999999998899e-05, 0.006131441675425231, 0.004562664352103063, 9.999999999998899e-05, 9.999999999998899e-05, 0.03188157915629197, 0.12377588221321623, 0.009910428504860236, 0.9478517833706125, 0.9389212653122886, 0.9092159045922832, 0.9376200967942181, 0.9439190992367146, 0.653208388949611, 0.9448413018088235, 0.7952567331149261, 0.9241806256640214, 0.9610926053867376, 0.8437659183315327, 0.927900139193082, 0.9368437583431959, 0.936449543885111, 0.9322546508734815, 0.9410624669306766, 0.9579129078837267, 0.8658977767226257, 0.6158291995022938, 0.7750161807855649, 0.5710853436074894, 0.9185918214469655, 0.810137061077969, 0.62507805468683, 0.9301869240278015, 0.9225044964145482, 0.6593286276156742, 0.5167267375278186, 0.6033529202896761, 0.5926270119913382, 0.6452588209516801, 0.6880022806481674, 0.5588831928148572, 0.4708703252942992, 0.5974855226521218, 0.4924525997326492, 0.4544910070776861, 0.7553030425326663, 0.43729557955203047, 0.9324331285928574, 0.8446280934542661, 0.740336661689055, 0.14574926413002143, 0.6789437510570931, 0.7149549098869359, 0.8105331643021202, 0.8397838738797345, 0.7197487296917424, 0.7592036259315773, 0.9388519057518508, 0.8718197796195994, 0.6123701485561905, 0.7718015100507588, 0.7038430449680051, 0.9571919385867037, 0.9413813533898703, 0.9537234868386748, 0.9516383532170711, 0.9566229425891609, 0.9131935879820483, 0.9700312231085754, 0.9616816604061403, 0.9300572642526738, 9.999999999998899e-05, 0.0035044606291628755, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.017605185879066676, 0.0006347742350053531, 9.999999999998899e-05, 0.07112930433292608, 0.11609559117111601, 0.13755175372530504, 0.12465418943199624, 0.2171771520561363, 0.12208651324063391, 0.11576343220033702, 0.09882653675377806, 0.08693666613717355, 0.10891629803540748, 0.11991631657574164, 0.12603756513569064, 0.1169960553630146, 0.1463167326775352, 0.11672601063109611, 0.12085009254833201, 0.13915654632921837, 0.1220585729411876, 0.09583054089776633, 0.060305517530043984, 0.05949562495103344, 0.04857366833915455, 0.0832032272273534, 0.05964480803964656, 0.06545035396397758, 0.07087707537328647, 0.05744215938494268, 0.031611087457773634, 0.19156461419791682, 0.060340066452233665, 0.16052554454823476, 0.18761376492361914, 0.10444417326150002, 0.14928585473418787, 0.19031323704505154, 0.10088427131770472, 0.15310855525251177, 0.19575152880698066, 0.19629158232655874, 0.1827395314580602, 0.18261687212796074, 0.2555102626737161, 0.186954506790048, 0.18871641629275893, 0.18133033516004804, 0.19257485005497998, 0.15703840542900793, 0.17238269072989076, 0.18940033238035203, 0.16783028039044257, 0.17688662115804943, 0.10531352162213625, 0.15937413948457146, 0.1880559880493312, 0.1686623378542036, 0.9696663718891635, 0.9258278504524875, 0.9684571200590576, 0.9008878907800546, 0.9368033265341296, 0.19926700982492518, 0.9530986340996562, 0.07947511558863807, 0.9752002265699312, 0.2451459884275674, 0.20905870341326505, 0.2565873821946396, 0.23992278966239355, 0.21518744922674504, 0.22673283999558247, 0.23755422383547542, 0.29240221918471543, 0.5295638477653546, 0.04206325736167349, 0.04191822203761386, 0.05828965904830097, 0.03858721065446702, 0.015140738915513263, 0.0399618581664799, 0.044371404970499295, 0.02592068458416885, 0.03843384238430447]}, "mutation_prompt": null}
{"id": "0df6493e-ed28-4bc6-a930-00f454aaaec1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DiversePopulationInitializationImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def nelder_mead_local_search(wolf, initial_guess, mutation_step):\n            res = minimize(func, initial_guess, method='Nelder-Mead', options={'xatol': mutation_step, 'disp': False})\n            return res.x\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim)),\n                   'mutation_step': 1e-8} for _ in range(6)]  # Enhanced population diversity\n\n        for i in range(2, self.budget - 3, 2):\n            for wolf in wolves:\n                local_search_position = nelder_mead_local_search(wolf, wolf['position'], wolf['mutation_step'])\n                if func(local_search_position) < wolf['fitness']:\n                    wolf['position'] = local_search_position\n                    wolf['fitness'] = func(local_search_position)\n                    if np.random.rand() < 0.5:\n                        if func(local_search_position) < wolf['fitness']:\n                            wolf['mutation_step'] *= 0.95\n                        else:\n                            wolf['mutation_step'] *= 1.05\n                    else:\n                        wolf['mutation_step'] *= 0.9\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "DiversePopulationInitializationImproved", "description": "Enhance exploration by incorporating a diverse population initialization strategy to improve convergence speed.", "configspace": "", "generation": 89, "fitness": 0.42677217654198246, "feedback": "The algorithm DiversePopulationInitializationImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43 with standard deviation 0.37.", "error": "", "parent_id": "2e3ea6b1-5060-433e-b529-a3413f495e04", "metadata": {"aucs": [0.9691565582513595, 0.9762878458170217, 0.9671066570004335, 0.9572057857795506, 0.9775745257503272, 0.9614842782526023, 0.9623147939485586, 0.962121464767547, 0.9602511446450591, 0.5410912715051106, 0.75042825914107, 0.4620512947598193, 0.48049809871685856, 0.5127490401828511, 0.6733081837521033, 0.5291969047417828, 0.6941639665252717, 0.4544644558693588, 0.039062332938718414, 0.027404726280849223, 9.999999999998899e-05, 0.03601793305103673, 0.016717963712172823, 0.027065589213603358, 0.042711334090332675, 0.017214634855583277, 9.999999999998899e-05, 0.02066225769359531, 0.02295478381009486, 0.005866277564251843, 0.023596224729286353, 0.005572986638633148, 9.999999999998899e-05, 0.0325905054068778, 0.008249376534977038, 9.999999999998899e-05, 0.8653389455209018, 0.9845489661519228, 0.9853737110250713, 0.9904195540992613, 0.9852529927922472, 0.9937345962961477, 0.9928478037964119, 0.9945445131523484, 0.9867231776616731, 0.22778856841642103, 0.4922887745379084, 0.31339099045319263, 0.34540746145127954, 0.43828960257326366, 0.2530053409546048, 0.4810083550067106, 0.4026017830178229, 0.504432392447586, 0.10029430247433702, 0.052450417048847564, 0.006130163285922197, 0.004562664352103063, 9.999999999998899e-05, 0.0008411045608237577, 0.0317671753402039, 0.12372287942340554, 0.0586320146195749, 0.9476517833706125, 0.9387212653122885, 0.9090159045922832, 0.9374200967942181, 0.9437190992367146, 0.5827811000911238, 0.9446413018088236, 0.794931854901874, 0.9239806256640214, 0.9608926053867376, 0.8434799734784904, 0.9277001391930819, 0.9366437583431959, 0.936249543885111, 0.9320546508734815, 0.9408624669306767, 0.9577129078837268, 0.8656977767226257, 0.4982352381909805, 0.7746948983521551, 0.3915715906260595, 0.9183918214469655, 0.7525868577926691, 0.4667604244302066, 0.9299869240278015, 0.9223044964145483, 0.6479568583998558, 0.34048411315203053, 0.4817464082363776, 0.4261613781133681, 0.5685717366804064, 0.5921329943773919, 0.38838571446094217, 0.36192540578940824, 0.42668837932524484, 0.33032318745460165, 0.3108894250237556, 0.6594306496066913, 0.33263699582264816, 0.9322331285928575, 0.8346506063816774, 0.6856307373823904, 0.3027710607167464, 0.5632020068670331, 0.6224686097820524, 0.7706905052383026, 0.8359293763263298, 0.6539983887219857, 0.637926499135208, 0.9386519057518509, 0.8494894233402307, 0.492733604744345, 0.6597990267912678, 0.6429002452832234, 0.9570057120793926, 0.9412027445733239, 0.9535531464033719, 0.9514571907524629, 0.9565104214059146, 0.9135458020300024, 0.9699106230019607, 0.9615010778983268, 0.9298814624274362, 0.012871164005577196, 0.0035029241010734458, 0.006656031798655371, 0.006104773434434163, 9.999999999998899e-05, 0.017605185879066676, 0.0006346429046075741, 9.999999999998899e-05, 0.07111436586765452, 0.11442889038496828, 0.16140449623039654, 0.12462700601780563, 0.2170886154474848, 0.1768269750849779, 0.11574229859447083, 0.09660599321100982, 0.08649226245424957, 0.10889714812476847, 0.11991143580600805, 0.12602471577967522, 0.12014722855808901, 0.1463091496790654, 0.1167501426050761, 0.12071353007972196, 0.13914577153346486, 0.12205598644237248, 0.10212837246221584, 0.06029590576374688, 0.059491241509051496, 0.0586771934943312, 0.08318749714633578, 0.05994792006405747, 0.0654462627311706, 0.07087196501136295, 0.05872952662741282, 0.04260559877908687, 0.19153943718060562, 0.06090703884027804, 0.16051063695461232, 0.18758923223918678, 0.10388727346661542, 0.14989923605421718, 0.19029203535862582, 0.10086859899547307, 0.15309393035051633, 0.19571106045256148, 0.1962492925975503, 0.18270253304068473, 0.18257962715261788, 0.25545138478341545, 0.1869167475733482, 0.1886775267526939, 0.19380680238972947, 0.19253596051491517, 0.7426083809327721, 0.17234927521183074, 0.18944043305405778, 0.18765992638234708, 0.18465458191742912, 0.5934826895689176, 0.15939400053259523, 0.18801452597627688, 0.1686390723749147, 0.9694740015695175, 0.9255450888351666, 0.9682603808559455, 0.9011228828390841, 0.9365292273598864, 0.6639196367732771, 0.9529105162273984, 0.10270634744141882, 0.9750048211552317, 0.2400287634301015, 0.21160990498758525, 0.25302605748502904, 0.23985492974528388, 0.2151444881401784, 0.2262517177706449, 0.23517357329455768, 0.29158030087601505, 0.42744481904351095, 0.04205479161710968, 0.04190446864673758, 0.05827687785926228, 0.03857949056687049, 0.021214030215096824, 0.03998416506919289, 0.04436387641334494, 0.025913302670236393, 0.04550284971071683]}, "mutation_prompt": null}
{"id": "301954df-9500-4ec4-9fbb-3b9db4a45f2c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass FasterDynamicMutationHybridImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def nelder_mead_local_search(wolf, initial_guess, mutation_step):\n            res = minimize(func, initial_guess, method='Nelder-Mead', options={'xatol': mutation_step, 'disp': False})\n            return res.x\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim)),\n                   'mutation_step': 1e-8} for _ in range(4)]  # Adjusted population size\n\n        for i in range(2, self.budget - 3, 2):\n            for wolf in wolves:\n                local_search_position = nelder_mead_local_search(wolf, wolf['position'], wolf['mutation_step'])\n                if func(local_search_position) < wolf['fitness']:\n                    wolf['position'] = local_search_position\n                    wolf['fitness'] = func(local_search_position)\n                    if np.random.rand() < 0.5:\n                        if func(local_search_position) < wolf['fitness']:\n                            wolf['mutation_step'] *= 0.95\n                        else:\n                            wolf['mutation_step'] *= 1.05\n                    else:\n                        wolf['mutation_step'] *= 0.9  # Hybrid strategy combining individual and global search components\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FasterDynamicMutationHybridImproved", "description": "Improve convergence speed by introducing a dynamic population size adjustment mechanism based on the fitness landscape, enhancing exploration and exploitation balance.", "configspace": "", "generation": 89, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "2e3ea6b1-5060-433e-b529-a3413f495e04", "metadata": {"aucs": [0.9693459040718787, 0.9764786142523346, 0.9672950455130237, 0.9573692180319937, 0.9777109701806243, 0.9614230290583405, 0.9622405165801594, 0.9623104941943011, 0.9604377402500864, 0.6607695660869473, 0.7508012007714923, 0.6159408729965656, 0.6469216222244509, 0.6292834113192709, 0.7543502058639122, 0.6166899418071158, 0.7826506593094402, 0.6170080982767616, 0.03907149554441525, 0.02741793029174766, 9.999999999998899e-05, 0.027357938579633645, 0.0074902255609790025, 0.012710566454805172, 0.03507297424860678, 0.017220114514267748, 9.999999999998899e-05, 0.020666738642563187, 0.02296557605670646, 9.999999999998899e-05, 0.01960752770993024, 0.005575694803861331, 9.999999999998899e-05, 0.03259788004303277, 9.999999999998899e-05, 9.999999999998899e-05, 0.8655341165396426, 0.9847388829898945, 0.9855651521943627, 0.9906176061724785, 0.9854514801893373, 0.9939284980257546, 0.993032926985032, 0.9947428921383786, 0.9869180261290181, 0.3019579956474596, 0.5025365396803674, 0.4219606029847157, 0.38783824027996916, 0.48837505754106636, 0.29711139342602244, 0.5543391717347674, 0.4893856126099345, 0.6044348896285623, 0.10029430247433702, 9.999999999998899e-05, 0.006131441675425231, 0.004562664352103063, 9.999999999998899e-05, 9.999999999998899e-05, 0.03188157915629197, 0.12377588221321623, 0.009910428504860236, 0.9478517833706125, 0.9389212653122886, 0.9092159045922832, 0.9376200967942181, 0.9439190992367146, 0.653208388949611, 0.9448413018088235, 0.7952567331149261, 0.9241806256640214, 0.9610926053867376, 0.8437659183315327, 0.927900139193082, 0.9368437583431959, 0.936449543885111, 0.9322546508734815, 0.9410624669306766, 0.9579129078837267, 0.8658977767226257, 0.6158291995022938, 0.7750161807855649, 0.5710853436074894, 0.9185918214469655, 0.810137061077969, 0.62507805468683, 0.9301869240278015, 0.9225044964145482, 0.6593286276156742, 0.5167267375278186, 0.6033529202896761, 0.5926270119913382, 0.6452588209516801, 0.6880022806481674, 0.5588831928148572, 0.4708703252942992, 0.5974855226521218, 0.4924525997326492, 0.4544910070776861, 0.7553030425326663, 0.43729557955203047, 0.9324331285928574, 0.8446280934542661, 0.740336661689055, 0.14574926413002143, 0.6789437510570931, 0.7149549098869359, 0.8105331643021202, 0.8397838738797345, 0.7197487296917424, 0.7592036259315773, 0.9388519057518508, 0.8718197796195994, 0.6123701485561905, 0.7718015100507588, 0.7038430449680051, 0.9571919385867037, 0.9413813533898703, 0.9537234868386748, 0.9516383532170711, 0.9566229425891609, 0.9131935879820483, 0.9700312231085754, 0.9616816604061403, 0.9300572642526738, 9.999999999998899e-05, 0.0035044606291628755, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.017605185879066676, 0.0006347742350053531, 9.999999999998899e-05, 0.07112930433292608, 0.11609559117111601, 0.13755175372530504, 0.12465418943199624, 0.2171771520561363, 0.12208651324063391, 0.11576343220033702, 0.09882653675377806, 0.08693666613717355, 0.10891629803540748, 0.11991631657574164, 0.12603756513569064, 0.1169960553630146, 0.1463167326775352, 0.11672601063109611, 0.12085009254833201, 0.13915654632921837, 0.1220585729411876, 0.09583054089776633, 0.060305517530043984, 0.05949562495103344, 0.04857366833915455, 0.0832032272273534, 0.05964480803964656, 0.06545035396397758, 0.07087707537328647, 0.05744215938494268, 0.031611087457773634, 0.19156461419791682, 0.060340066452233665, 0.16052554454823476, 0.18761376492361914, 0.10444417326150002, 0.14928585473418787, 0.19031323704505154, 0.10088427131770472, 0.15310855525251177, 0.19575152880698066, 0.19629158232655874, 0.1827395314580602, 0.18261687212796074, 0.2555102626737161, 0.186954506790048, 0.18871641629275893, 0.18133033516004804, 0.19257485005497998, 0.15703840542900793, 0.17238269072989076, 0.18940033238035203, 0.16783028039044257, 0.17688662115804943, 0.10531352162213625, 0.15937413948457146, 0.1880559880493312, 0.1686623378542036, 0.9696663718891635, 0.9258278504524875, 0.9684571200590576, 0.9008878907800546, 0.9368033265341296, 0.19926700982492518, 0.9530986340996562, 0.07947511558863807, 0.9752002265699312, 0.2451459884275674, 0.20905870341326505, 0.2565873821946396, 0.23992278966239355, 0.21518744922674504, 0.22673283999558247, 0.23755422383547542, 0.29240221918471543, 0.5295638477653546, 0.04206325736167349, 0.04191822203761386, 0.05828965904830097, 0.03858721065446702, 0.015140738915513263, 0.0399618581664799, 0.044371404970499295, 0.02592068458416885, 0.03843384238430447]}, "mutation_prompt": null}
{"id": "0b2cccfd-05e2-49d6-84ef-90561f8e8dbd", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass FasterDynamicMutationHybridImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def nelder_mead_local_search(wolf, initial_guess, mutation_step):\n            res = minimize(func, initial_guess, method='Nelder-Mead', options={'xatol': mutation_step, 'disp': False})\n            return res.x\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim)),\n                   'mutation_step': 1e-8} for _ in range(4)]  # Adjusted population size\n\n        for i in range(2, self.budget - 3, 2):\n            for wolf in wolves:\n                local_search_position = nelder_mead_local_search(wolf, wolf['position'], wolf['mutation_step'])\n                if func(local_search_position) < wolf['fitness']:\n                    wolf['position'] = local_search_position\n                    wolf['fitness'] = func(local_search_position)\n                    adaptive_factor = 0.95 if func(local_search_position) < wolf['fitness'] else 1.05\n                    wolf['mutation_step'] *= adaptive_factor  # Self-adaptive mutation based on individual performance\n                    wolf['mutation_step'] *= 0.9  # Hybrid strategy combining individual and global search components\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FasterDynamicMutationHybridImproved", "description": "Utilize a self-adaptive mutation strategy based on individual performance to enhance convergence rate.", "configspace": "", "generation": 91, "fitness": 0.43895903486150734, "feedback": "The algorithm FasterDynamicMutationHybridImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.44 with standard deviation 0.38.", "error": "", "parent_id": "2e3ea6b1-5060-433e-b529-a3413f495e04", "metadata": {"aucs": [0.9693459040718787, 0.9764786142523346, 0.9672950455130237, 0.9573692180319937, 0.9777109701806243, 0.9614230290583405, 0.9622405165801594, 0.9623104941943011, 0.9604377402500864, 0.6606909989991163, 0.75062825914107, 0.615672698686796, 0.6468387590522138, 0.629023232333892, 0.7541980688161931, 0.6166004998571669, 0.7825186911587914, 0.6167361558636169, 0.039068740818985814, 0.027411328286298553, 9.999999999998899e-05, 0.027357938579633645, 0.007489446345519402, 0.012709236758494669, 0.03507297424860678, 0.017218287961372924, 9.999999999998899e-05, 0.02066659627062528, 0.022960179933400604, 9.999999999998899e-05, 0.01960752770993024, 0.005574340721247295, 9.999999999998899e-05, 0.03259788004303277, 9.999999999998899e-05, 9.999999999998899e-05, 0.8655341165396426, 0.9847388829898945, 0.9855651521943627, 0.9906176061724785, 0.9854514801893373, 0.9939284980257546, 0.993032926985032, 0.9947428921383786, 0.9869180261290181, 0.301848314654815, 0.5024866889749376, 0.42174574591638725, 0.3876884119490138, 0.4882570993980909, 0.29692821087477317, 0.5542995310236642, 0.4892124377220268, 0.6042566349902813, 0.10029430247433702, 9.999999999998899e-05, 0.006130163285922197, 0.004562664352103063, 9.999999999998899e-05, 9.999999999998899e-05, 0.03188128592121209, 0.123749380818311, 0.009910428504860236, 0.9478517833706125, 0.9389212653122886, 0.9092051455421037, 0.9376200967942181, 0.9439190992367146, 0.6529309419033, 0.9448413018088235, 0.795131854901874, 0.9241806256640214, 0.9610926053867376, 0.8436799734784903, 0.927900139193082, 0.9368437583431959, 0.936449543885111, 0.9322546508734815, 0.9410624669306766, 0.9579129078837267, 0.8658118318695833, 0.6157706780858874, 0.7748780011935671, 0.5708033212483578, 0.9185918214469655, 0.8100449320572496, 0.6248318097164909, 0.9301869240278015, 0.9225044964145482, 0.6591093315566221, 0.5165861636673588, 0.6031127950050809, 0.592378235481795, 0.6451627643511237, 0.6878200806587722, 0.5586118717040451, 0.4707490821027511, 0.5972233166493859, 0.4921602702401562, 0.45427665493709724, 0.7551600344714915, 0.4369761382487266, 0.9324331285928574, 0.8445569093395711, 0.7401736939536476, 0.14563330650383255, 0.6787488902238965, 0.7147815480207401, 0.8104971582539242, 0.8395860685177201, 0.7195381204724962, 0.7590522629117972, 0.9388519057518508, 0.8717630688085812, 0.6165712825089193, 0.7715847758712029, 0.7030976539800424, 0.9571919385867037, 0.9413813533898703, 0.9537234868386748, 0.9516383532170711, 0.9566229425891609, 0.9131714558409378, 0.9700312231085754, 0.9616816604061403, 0.9300462147048532, 9.999999999998899e-05, 0.0035036923651181606, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.017605185879066676, 0.0006347085698064081, 9.999999999998899e-05, 0.07112930433292608, 0.11609143155090607, 0.13755127931663758, 0.12465416142395302, 0.21717693023104823, 0.12208336870126191, 0.11575339130067808, 0.09881495658413042, 0.08697243822801048, 0.10891025032974266, 0.11991631657574164, 0.12603247979867338, 0.11699493071661637, 0.1463167326775352, 0.11672079843327576, 0.12084974164350026, 0.13915654632921837, 0.1220490675315854, 0.09583042749456039, 0.060305517530043984, 0.05949332598807833, 0.04857228888276954, 0.0832032272273534, 0.05963899360415048, 0.06545035396397758, 0.07087707537328647, 0.05743208456683191, 0.03160933172140723, 0.19156461419791682, 0.060340066452233665, 0.16050610175457602, 0.18761376492361914, 0.10444361597812479, 0.1492660503017771, 0.19031323704505154, 0.10087904721029428, 0.1530998348787922, 0.19574982034546062, 0.19628867417467522, 0.1827395314580602, 0.1826157744941851, 0.25550389433766096, 0.1869535816385718, 0.18871492597960027, 0.181330074326282, 0.19257485005497998, 0.15703840542900793, 0.17237418438365382, 0.18940033238035203, 0.16783028039044257, 0.17688063393867903, 0.105303237137512, 0.15936905411655444, 0.18804093334054273, 0.1686623378542036, 0.9696663718891635, 0.925739234135242, 0.9684571200590576, 0.9008878907800546, 0.9367249263712935, 0.19926700982492518, 0.9530986340996562, 0.07947027067396595, 0.9752002265699312, 0.2451182481005202, 0.20910362672726546, 0.2565633129186805, 0.24009042478219567, 0.21517971419748505, 0.22672598961380386, 0.23752244546818158, 0.29237057270553524, 0.5352326222105437, 0.04206325736167349, 0.04191363757398847, 0.05828338358211349, 0.03858721065446702, 0.015139723048693488, 0.039953878897864725, 0.044371404970499295, 0.0259187161811415, 0.038433105313174565]}, "mutation_prompt": null}
{"id": "5028c3e7-f192-4983-b916-f126beb15767", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass FasterDynamicMutationHybridImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def nelder_mead_local_search(wolf, initial_guess, mutation_step):\n            res = minimize(func, initial_guess, method='Nelder-Mead', options={'xatol': mutation_step, 'disp': False})\n            return res.x\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim)),\n                   'mutation_step': 1e-8} for _ in range(4)]\n\n        for i in range(2, self.budget - 3, 2):\n            for wolf in wolves:\n                local_search_position = nelder_mead_local_search(wolf, wolf['position'], wolf['mutation_step'])\n                if func(local_search_position) < wolf['fitness']:\n                    wolf['position'] = local_search_position\n                    wolf['fitness'] = func(local_search_position)\n                    adaptive_factor = 0.95 if func(local_search_position) < wolf['fitness'] else 1.05\n                    wolf['mutation_step'] *= adaptive_factor\n                    # Adjust the mutation step based on population performance\n                    wolf['mutation_step'] *= 0.85 if func(local_search_position) < wolf['fitness'] else 1.15\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FasterDynamicMutationHybridImproved", "description": "Improve convergence speed by dynamically adjusting the mutation step size based on individual and population performance to enhance exploration-exploitation balance.", "configspace": "", "generation": 92, "fitness": 0.4389062318253283, "feedback": "The algorithm FasterDynamicMutationHybridImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.44 with standard deviation 0.38.", "error": "", "parent_id": "0b2cccfd-05e2-49d6-84ef-90561f8e8dbd", "metadata": {"aucs": [0.9693459040718787, 0.9764786142523346, 0.9672950455130237, 0.9573692180319937, 0.9777109701806243, 0.9614230290583405, 0.9622405165801594, 0.9623104941943011, 0.9604377402500864, 0.6603767306477928, 0.7504553175106478, 0.6153278712207985, 0.6465073063632656, 0.6286792641776989, 0.7540056115579443, 0.6162427320573713, 0.7823427336245927, 0.6163762054547597, 0.039058894906738195, 0.027404726280849223, 9.999999999998899e-05, 0.02735421468560706, 0.007488667130059912, 0.012707907062184165, 0.0350692869554321, 0.0172164614084781, 9.999999999998899e-05, 0.020664550710660645, 0.02295478381009486, 9.999999999998899e-05, 0.01960752770993024, 0.005572986638633148, 9.999999999998899e-05, 0.0325905054068778, 9.999999999998899e-05, 9.999999999998899e-05, 0.8654434347216776, 0.9847388829898945, 0.9855651521943627, 0.9906176061724785, 0.9854514801893373, 0.9939284980257546, 0.993032926985032, 0.9947428921383786, 0.9869180261290181, 0.30161111120436135, 0.5025271380248381, 0.421436319257106, 0.3872763497204894, 0.4880802075590601, 0.2966535616930258, 0.5541472223907302, 0.48895161849587343, 0.6040384672628772, 0.10029430247433702, 9.999999999998899e-05, 0.006128884896419162, 0.004562664352103063, 9.999999999998899e-05, 9.999999999998899e-05, 0.03188009191344243, 0.12372287942340554, 0.009910428504860236, 0.9478517833706125, 0.9389212653122886, 0.9091943864919242, 0.9376200967942181, 0.9439190992367146, 0.652589669385889, 0.9448413018088235, 0.795006976688822, 0.9241806256640214, 0.9610926053867376, 0.843594028625448, 0.927900139193082, 0.9368437583431959, 0.936449543885111, 0.9322546508734815, 0.9410624669306766, 0.9579129078837267, 0.865725887016541, 0.6154695292235739, 0.7747229244429814, 0.5704318655959684, 0.9185918214469655, 0.8099220933629571, 0.6245067030851761, 0.9301869240278015, 0.9225044964145482, 0.6588331780489769, 0.5161823156926777, 0.6027881205678904, 0.5920465334690708, 0.6448944126029875, 0.6875902324227295, 0.558245310833918, 0.47039501938409434, 0.5968757352853876, 0.49172186681032626, 0.45379241029924766, 0.7549693570565917, 0.43648298501815674, 0.9324331285928574, 0.8444619971866443, 0.7399774948854387, 0.1453127534150206, 0.6784741489116526, 0.7145503988658124, 0.8103253998177121, 0.8393859617627686, 0.7196406022282321, 0.7588241284027898, 0.9388519057518508, 0.8716874543938902, 0.6117657092822852, 0.7712952868482484, 0.7026232235801455, 0.9571919385867037, 0.9413813533898703, 0.9537234868386748, 0.9516383532170711, 0.9566229425891609, 0.9131493236998274, 0.9700312231085754, 0.9616816604061403, 0.9300351651570327, 9.999999999998899e-05, 0.0035029241010734458, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.017605185879066676, 0.0006345115742099061, 9.999999999998899e-05, 0.07112930433292608, 0.11608011460678791, 0.13755383467125115, 0.12465412407866094, 0.21715889279508394, 0.1220802241618898, 0.11574333455154862, 0.09885476523001924, 0.08696626664488594, 0.10890423058955856, 0.11991524730021041, 0.126027394461656, 0.11699380607021814, 0.1463167326775352, 0.1167155862354553, 0.12084927589743, 0.13915654632921837, 0.12203956212198341, 0.09583031409135456, 0.06030468750442053, 0.05949102702512332, 0.04857090942638442, 0.0832032272273534, 0.05963317916865474, 0.06545035396397758, 0.07087707537328647, 0.057422009748721026, 0.03160757598504094, 0.19156461419791682, 0.060340066452233665, 0.16048665896091718, 0.18761376492361914, 0.10444305869474935, 0.1492462458693664, 0.19031323704505154, 0.10087382310288373, 0.1530911145050724, 0.19574469496090097, 0.1962845214133273, 0.1827395314580602, 0.18261248159285837, 0.2554975260016058, 0.1869526564870957, 0.18870807923493982, 0.18132981349251598, 0.19257485005497998, 0.15703471744629738, 0.1723656780374171, 0.18940033238035203, 0.1678205074254191, 0.17687464671930864, 0.10529295265288785, 0.15935265891071992, 0.18801835127735989, 0.1686623378542036, 0.9696663718891635, 0.9256506178179964, 0.9684571200590576, 0.9008037568640702, 0.9366465262084573, 0.19926700982492518, 0.9530986340996562, 0.07946368430496609, 0.9752002265699312, 0.2451022422775846, 0.2093510707837245, 0.2566036231593093, 0.24011615596677305, 0.21517176980823194, 0.22671944722948778, 0.2378999172198426, 0.29234975806477304, 0.5421692070279303, 0.04206325736167349, 0.04190905311036297, 0.0582771081159259, 0.03858721065446702, 0.015138707181873712, 0.039945899629249326, 0.044371404970499295, 0.025916747778113813, 0.03843236824204466]}, "mutation_prompt": null}
{"id": "0e81fce7-a6b4-4deb-abfa-564985b1d796", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass FasterDynamicMutationHybridImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def nelder_mead_local_search(wolf, initial_guess, mutation_step):\n            res = minimize(func, initial_guess, method='Nelder-Mead', options={'xatol': mutation_step, 'disp': False})\n            return res.x\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim)),\n                   'mutation_step': 1e-8} for _ in range(4)]  # Adjusted population size\n\n        for i in range(2, self.budget - 3, 2):\n            for wolf in wolves:\n                local_search_position = nelder_mead_local_search(wolf, wolf['position'], wolf['mutation_step'])\n                if func(local_search_position) < wolf['fitness']:\n                    wolf['position'] = local_search_position\n                    wolf['fitness'] = func(local_search_position)\n                    adaptive_factor = 0.95 if func(local_search_position) < wolf['fitness'] else 1.05\n                    wolf['mutation_step'] *= adaptive_factor  # Self-adaptive mutation based on individual performance\n                    wolf['mutation_step'] *= 0.9  # Hybrid strategy combining individual and global search components\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FasterDynamicMutationHybridImproved", "description": "Utilize a self-adaptive mutation strategy based on individual performance to enhance convergence rate.", "configspace": "", "generation": 92, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0b2cccfd-05e2-49d6-84ef-90561f8e8dbd", "metadata": {"aucs": [0.9693459040718787, 0.9764786142523346, 0.9672950455130237, 0.9573692180319937, 0.9777109701806243, 0.9614230290583405, 0.9622405165801594, 0.9623104941943011, 0.9604377402500864, 0.6606909989991163, 0.75062825914107, 0.615672698686796, 0.6468387590522138, 0.629023232333892, 0.7541980688161931, 0.6166004998571669, 0.7825186911587914, 0.6167361558636169, 0.039068740818985814, 0.027411328286298553, 9.999999999998899e-05, 0.027357938579633645, 0.007489446345519402, 0.012709236758494669, 0.03507297424860678, 0.017218287961372924, 9.999999999998899e-05, 0.02066659627062528, 0.022960179933400604, 9.999999999998899e-05, 0.01960752770993024, 0.005574340721247295, 9.999999999998899e-05, 0.03259788004303277, 9.999999999998899e-05, 9.999999999998899e-05, 0.8655341165396426, 0.9847388829898945, 0.9855651521943627, 0.9906176061724785, 0.9854514801893373, 0.9939284980257546, 0.993032926985032, 0.9947428921383786, 0.9869180261290181, 0.301848314654815, 0.5024866889749376, 0.42174574591638725, 0.3876884119490138, 0.4882570993980909, 0.29692821087477317, 0.5542995310236642, 0.4892124377220268, 0.6042566349902813, 0.10029430247433702, 9.999999999998899e-05, 0.006130163285922197, 0.004562664352103063, 9.999999999998899e-05, 9.999999999998899e-05, 0.03188128592121209, 0.123749380818311, 0.009910428504860236, 0.9478517833706125, 0.9389212653122886, 0.9092051455421037, 0.9376200967942181, 0.9439190992367146, 0.6529309419033, 0.9448413018088235, 0.795131854901874, 0.9241806256640214, 0.9610926053867376, 0.8436799734784903, 0.927900139193082, 0.9368437583431959, 0.936449543885111, 0.9322546508734815, 0.9410624669306766, 0.9579129078837267, 0.8658118318695833, 0.6157706780858874, 0.7748780011935671, 0.5708033212483578, 0.9185918214469655, 0.8100449320572496, 0.6248318097164909, 0.9301869240278015, 0.9225044964145482, 0.6591093315566221, 0.5165861636673588, 0.6031127950050809, 0.592378235481795, 0.6451627643511237, 0.6878200806587722, 0.5586118717040451, 0.4707490821027511, 0.5972233166493859, 0.4921602702401562, 0.45427665493709724, 0.7551600344714915, 0.4369761382487266, 0.9324331285928574, 0.8445569093395711, 0.7401736939536476, 0.14563330650383255, 0.6787488902238965, 0.7147815480207401, 0.8104971582539242, 0.8395860685177201, 0.7195381204724962, 0.7590522629117972, 0.9388519057518508, 0.8717630688085812, 0.6165712825089193, 0.7715847758712029, 0.7030976539800424, 0.9571919385867037, 0.9413813533898703, 0.9537234868386748, 0.9516383532170711, 0.9566229425891609, 0.9131714558409378, 0.9700312231085754, 0.9616816604061403, 0.9300462147048532, 9.999999999998899e-05, 0.0035036923651181606, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.017605185879066676, 0.0006347085698064081, 9.999999999998899e-05, 0.07112930433292608, 0.11609143155090607, 0.13755127931663758, 0.12465416142395302, 0.21717693023104823, 0.12208336870126191, 0.11575339130067808, 0.09881495658413042, 0.08697243822801048, 0.10891025032974266, 0.11991631657574164, 0.12603247979867338, 0.11699493071661637, 0.1463167326775352, 0.11672079843327576, 0.12084974164350026, 0.13915654632921837, 0.1220490675315854, 0.09583042749456039, 0.060305517530043984, 0.05949332598807833, 0.04857228888276954, 0.0832032272273534, 0.05963899360415048, 0.06545035396397758, 0.07087707537328647, 0.05743208456683191, 0.03160933172140723, 0.19156461419791682, 0.060340066452233665, 0.16050610175457602, 0.18761376492361914, 0.10444361597812479, 0.1492660503017771, 0.19031323704505154, 0.10087904721029428, 0.1530998348787922, 0.19574982034546062, 0.19628867417467522, 0.1827395314580602, 0.1826157744941851, 0.25550389433766096, 0.1869535816385718, 0.18871492597960027, 0.181330074326282, 0.19257485005497998, 0.15703840542900793, 0.17237418438365382, 0.18940033238035203, 0.16783028039044257, 0.17688063393867903, 0.105303237137512, 0.15936905411655444, 0.18804093334054273, 0.1686623378542036, 0.9696663718891635, 0.925739234135242, 0.9684571200590576, 0.9008878907800546, 0.9367249263712935, 0.19926700982492518, 0.9530986340996562, 0.07947027067396595, 0.9752002265699312, 0.2451182481005202, 0.20910362672726546, 0.2565633129186805, 0.24009042478219567, 0.21517971419748505, 0.22672598961380386, 0.23752244546818158, 0.29237057270553524, 0.5352326222105437, 0.04206325736167349, 0.04191363757398847, 0.05828338358211349, 0.03858721065446702, 0.015139723048693488, 0.039953878897864725, 0.044371404970499295, 0.0259187161811415, 0.038433105313174565]}, "mutation_prompt": null}
{"id": "4d42a5fb-5313-4bd1-84c4-067e239a4ab2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass FasterDynamicMutationHybridImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def nelder_mead_local_search(wolf, initial_guess, mutation_step):\n            res = minimize(func, initial_guess, method='Nelder-Mead', options={'xatol': mutation_step, 'disp': False})\n            return res.x\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim)),\n                   'mutation_step': 1e-8} for _ in range(4)]  # Adjusted population size\n\n        for i in range(2, self.budget - 3, 2):\n            for wolf in wolves:\n                local_search_position = nelder_mead_local_search(wolf, wolf['position'], wolf['mutation_step'])\n                if func(local_search_position) < wolf['fitness']:\n                    wolf['position'] = local_search_position\n                    wolf['fitness'] = func(local_search_position)\n                    adaptive_factor = 0.95 if func(local_search_position) < wolf['fitness'] else 1.05\n                    wolf['mutation_step'] *= adaptive_factor  # Self-adaptive mutation based on individual performance\n                    wolf['mutation_step'] *= 0.9  # Hybrid strategy combining individual and global search components\n\n            # Dynamic population adjustment based on individual performance\n            wolves = [wolf for wolf in wolves if func(wolf['position']) <= np.median([wolf['fitness'] for wolf in wolves])] + [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim)),\n                   'mutation_step': 1e-8}]\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FasterDynamicMutationHybridImproved", "description": "Introducing a dynamic population adjustment mechanism to dynamically change the number of wolves based on their performance to enhance exploration-exploitation balance.", "configspace": "", "generation": 94, "fitness": 0.452395072718341, "feedback": "The algorithm FasterDynamicMutationHybridImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.45 with standard deviation 0.37.", "error": "", "parent_id": "0b2cccfd-05e2-49d6-84ef-90561f8e8dbd", "metadata": {"aucs": [0.9693459040718787, 0.9764786142523346, 0.9672950455130237, 0.9573692180319937, 0.9777109701806243, 0.9614230290583405, 0.9622405165801594, 0.9623104941943011, 0.9604377402500864, 0.660298163559962, 0.75062825914107, 0.6283892219795066, 0.6464244431910284, 0.6306913894461025, 0.7539964677635451, 0.6161532901074225, 0.782298744241043, 0.6162961158850546, 0.039068740818985814, 0.027411328286298553, 9.999999999998899e-05, 0.03418372464680197, 0.01660283653252248, 0.024163940301569875, 0.041796733794434826, 0.017218287961372924, 0.0069507194288341845, 0.030027755980294613, 0.022960179933400604, 0.005381546365740397, 0.031726912760187354, 0.005574340721247295, 9.999999999998899e-05, 0.03865505689029014, 0.007398468635365085, 9.999999999998899e-05, 0.8655341165396426, 0.9847388829898945, 0.9855651521943627, 0.9906176061724785, 0.9854514801893373, 0.9939284980257546, 0.993032926985032, 0.9947428921383786, 0.9869180261290181, 0.35095314583760395, 0.5123198086231374, 0.4040153873716529, 0.433216914547506, 0.4968196609791663, 0.3661304456129202, 0.5565920979239402, 0.5331875322284294, 0.6122826629553766, 0.11722479838416089, 0.058631043844522224, 0.029841437200411436, 0.1042148008356133, 0.07303272414091244, 0.0009145883327681403, 0.052380275103301566, 0.123749380818311, 0.061714841914777385, 0.9478517833706125, 0.9389212653122886, 0.9092051455421037, 0.9376200967942181, 0.9439190992367146, 0.6526118145477988, 0.9448413018088235, 0.795131854901874, 0.9241806256640214, 0.9610926053867376, 0.8436799734784903, 0.927900139193082, 0.9368437583431959, 0.936449543885111, 0.9322546508734815, 0.9410624669306766, 0.9579129078837267, 0.8658118318695833, 0.6329082227241138, 0.7748780011935671, 0.578011047599577, 0.9185918214469655, 0.809891383689384, 0.6244375014116115, 0.9301869240278015, 0.9225044964145482, 0.673029354431659, 0.42848865248634194, 0.6013654492655598, 0.5919636079658898, 0.6481490285009635, 0.6875818394255351, 0.5621028103660007, 0.4979195539199993, 0.5967964398430745, 0.46821301110700064, 0.5972495327098518, 0.7549216877028668, 0.5250564574974819, 0.9324331285928574, 0.8444382691484127, 0.7400075372896409, 0.30273177169349175, 0.706535318121068, 0.7144926115770804, 0.8103171280129442, 0.8406514997143855, 0.7361810464556691, 0.7687108978329374, 0.9388519057518508, 0.8716685507902173, 0.6355155332225428, 0.7712286534074079, 0.7176066258115092, 0.9571919385867037, 0.9413813533898703, 0.9537234868386748, 0.9516383532170711, 0.9566229425891609, 0.9131714558409378, 0.9700312231085754, 0.9616816604061403, 0.9300462147048532, 0.018667590521112443, 0.0035036923651181606, 0.006011820502177745, 0.007187507547171679, 0.0004788590924194036, 0.017605185879066676, 0.0009573679188872308, 0.010749130273814855, 0.07112930433292608, 0.1169237058082141, 0.160384138397895, 0.12465411495960255, 0.21718776272929663, 0.1641191613269546, 0.11575447286603846, 0.1001678040475954, 0.08700693009959481, 0.11907525891455295, 0.11991631657574164, 0.12603247979867338, 0.11960344332269757, 0.1463167326775352, 0.11739666929761572, 0.12227740732382009, 0.13915654632921837, 0.14576918324225352, 0.10165123151301891, 0.060305517530043984, 0.05949332598807833, 0.05699326225328749, 0.0832032272273534, 0.060632067924200284, 0.06845883612473025, 0.07421213216152756, 0.07169018014004302, 0.04360600072960952, 0.1915646141979167, 0.06768274427055188, 0.16050610175457625, 0.18761376492361914, 0.10464089429297818, 0.15184477368023475, 0.19031323704505154, 0.10087904721029428, 0.1530998348787922, 0.19574982034546062, 0.19628867417467522, 0.1827395314580602, 0.18480473926960206, 0.25550389433766096, 0.18852191668692564, 0.18970529496559296, 0.19267457182468684, 0.19257485005497998, 0.6255254869932344, 0.17237418438365382, 0.18940033238035203, 0.18392064271195396, 0.18403386861297855, 0.4458093882525387, 0.1624818958262647, 0.4250165671993337, 0.1686623378542036, 0.9696663718891635, 0.925739234135242, 0.9684571200590576, 0.9008878907800546, 0.9367249263712935, 0.5626607422879863, 0.9530986340996562, 0.10405426458180389, 0.9752002265699312, 0.22821687290960524, 0.20597147900831203, 0.25823093038307376, 0.26965158605800266, 0.21519224582371366, 0.2486215342231557, 0.24680278647006293, 0.29270731818814244, 0.602502155370099, 0.04206325736167349, 0.04191363757398847, 0.05828338358211349, 0.04121284356873256, 0.024934228495019806, 0.039953878897864725, 0.04700493679890916, 0.0259187161811415, 0.04409700478622636]}, "mutation_prompt": null}
{"id": "e3a47b41-2fe7-4996-8a43-8ee7212bd660", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass MultiStartFasterDynamicMutationHybridImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def nelder_mead_local_search(wolf, initial_guess, mutation_step):\n            res = minimize(func, initial_guess, method='Nelder-Mead', options={'xatol': mutation_step, 'disp': False})\n            return res.x\n\n        populations = [[[np.random.uniform(-5.0, 5.0, self.dim),\n                        func(np.random.uniform(-5.0, 5.0, self.dim)),\n                        1e-8] for _ in range(4)]]  # Initialize multiple independent populations\n\n        for i in range(2, self.budget - 3, 2):\n            for population in populations:\n                for wolf in population:\n                    local_search_position = nelder_mead_local_search(wolf, wolf[0], wolf[2])\n                    if func(local_search_position) < wolf[1]:\n                        wolf[0] = local_search_position\n                        wolf[1] = func(local_search_position)\n                        adaptive_factor = 0.95 if func(local_search_position) < wolf[1] else 1.05\n                        wolf[2] *= adaptive_factor\n                        wolf[2] *= 0.9\n\n                population[:] = [wolf for wolf in population if func(wolf[0]) <= np.median([w[1] for w in population])] + [[np.random.uniform(-5.0, 5.0, self.dim),\n                                func(np.random.uniform(-5.0, 5.0, self.dim)),\n                                1e-8]]\n\n        best_wolf = min([min(population, key=lambda x: x[1]) for population in populations], key=lambda x: x[1])\n        return best_wolf[0]", "name": "MultiStartFasterDynamicMutationHybridImproved", "description": "Implement a multi-start strategy by initializing multiple independent populations to accelerate the convergence speed while maintaining the algorithm's exploration-exploitation balance.", "configspace": "", "generation": 95, "fitness": 0.452395072718341, "feedback": "The algorithm MultiStartFasterDynamicMutationHybridImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.45 with standard deviation 0.37.", "error": "", "parent_id": "4d42a5fb-5313-4bd1-84c4-067e239a4ab2", "metadata": {"aucs": [0.9693459040718787, 0.9764786142523346, 0.9672950455130237, 0.9573692180319937, 0.9777109701806243, 0.9614230290583405, 0.9622405165801594, 0.9623104941943011, 0.9604377402500864, 0.660298163559962, 0.75062825914107, 0.6283892219795066, 0.6464244431910284, 0.6306913894461025, 0.7539964677635451, 0.6161532901074225, 0.782298744241043, 0.6162961158850546, 0.039068740818985814, 0.027411328286298553, 9.999999999998899e-05, 0.03418372464680197, 0.01660283653252248, 0.024163940301569875, 0.041796733794434826, 0.017218287961372924, 0.0069507194288341845, 0.030027755980294613, 0.022960179933400604, 0.005381546365740397, 0.031726912760187354, 0.005574340721247295, 9.999999999998899e-05, 0.03865505689029014, 0.007398468635365085, 9.999999999998899e-05, 0.8655341165396426, 0.9847388829898945, 0.9855651521943627, 0.9906176061724785, 0.9854514801893373, 0.9939284980257546, 0.993032926985032, 0.9947428921383786, 0.9869180261290181, 0.35095314583760395, 0.5123198086231374, 0.4040153873716529, 0.433216914547506, 0.4968196609791663, 0.3661304456129202, 0.5565920979239402, 0.5331875322284294, 0.6122826629553766, 0.11722479838416089, 0.058631043844522224, 0.029841437200411436, 0.1042148008356133, 0.07303272414091244, 0.0009145883327681403, 0.052380275103301566, 0.123749380818311, 0.061714841914777385, 0.9478517833706125, 0.9389212653122886, 0.9092051455421037, 0.9376200967942181, 0.9439190992367146, 0.6526118145477988, 0.9448413018088235, 0.795131854901874, 0.9241806256640214, 0.9610926053867376, 0.8436799734784903, 0.927900139193082, 0.9368437583431959, 0.936449543885111, 0.9322546508734815, 0.9410624669306766, 0.9579129078837267, 0.8658118318695833, 0.6329082227241138, 0.7748780011935671, 0.578011047599577, 0.9185918214469655, 0.809891383689384, 0.6244375014116115, 0.9301869240278015, 0.9225044964145482, 0.673029354431659, 0.42848865248634194, 0.6013654492655598, 0.5919636079658898, 0.6481490285009635, 0.6875818394255351, 0.5621028103660007, 0.4979195539199993, 0.5967964398430745, 0.46821301110700064, 0.5972495327098518, 0.7549216877028668, 0.5250564574974819, 0.9324331285928574, 0.8444382691484127, 0.7400075372896409, 0.30273177169349175, 0.706535318121068, 0.7144926115770804, 0.8103171280129442, 0.8406514997143855, 0.7361810464556691, 0.7687108978329374, 0.9388519057518508, 0.8716685507902173, 0.6355155332225428, 0.7712286534074079, 0.7176066258115092, 0.9571919385867037, 0.9413813533898703, 0.9537234868386748, 0.9516383532170711, 0.9566229425891609, 0.9131714558409378, 0.9700312231085754, 0.9616816604061403, 0.9300462147048532, 0.018667590521112443, 0.0035036923651181606, 0.006011820502177745, 0.007187507547171679, 0.0004788590924194036, 0.017605185879066676, 0.0009573679188872308, 0.010749130273814855, 0.07112930433292608, 0.1169237058082141, 0.160384138397895, 0.12465411495960255, 0.21718776272929663, 0.1641191613269546, 0.11575447286603846, 0.1001678040475954, 0.08700693009959481, 0.11907525891455295, 0.11991631657574164, 0.12603247979867338, 0.11960344332269757, 0.1463167326775352, 0.11739666929761572, 0.12227740732382009, 0.13915654632921837, 0.14576918324225352, 0.10165123151301891, 0.060305517530043984, 0.05949332598807833, 0.05699326225328749, 0.0832032272273534, 0.060632067924200284, 0.06845883612473025, 0.07421213216152756, 0.07169018014004302, 0.04360600072960952, 0.1915646141979167, 0.06768274427055188, 0.16050610175457625, 0.18761376492361914, 0.10464089429297818, 0.15184477368023475, 0.19031323704505154, 0.10087904721029428, 0.1530998348787922, 0.19574982034546062, 0.19628867417467522, 0.1827395314580602, 0.18480473926960206, 0.25550389433766096, 0.18852191668692564, 0.18970529496559296, 0.19267457182468684, 0.19257485005497998, 0.6255254869932344, 0.17237418438365382, 0.18940033238035203, 0.18392064271195396, 0.18403386861297855, 0.4458093882525387, 0.1624818958262647, 0.4250165671993337, 0.1686623378542036, 0.9696663718891635, 0.925739234135242, 0.9684571200590576, 0.9008878907800546, 0.9367249263712935, 0.5626607422879863, 0.9530986340996562, 0.10405426458180389, 0.9752002265699312, 0.22821687290960524, 0.20597147900831203, 0.25823093038307376, 0.26965158605800266, 0.21519224582371366, 0.2486215342231557, 0.24680278647006293, 0.29270731818814244, 0.602502155370099, 0.04206325736167349, 0.04191363757398847, 0.05828338358211349, 0.04121284356873256, 0.024934228495019806, 0.039953878897864725, 0.04700493679890916, 0.0259187161811415, 0.04409700478622636]}, "mutation_prompt": null}
{"id": "5d25a8ad-f8fd-420e-a85e-cc58304cc502", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass FasterDynamicMutationHybridImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def nelder_mead_local_search(wolf, initial_guess, mutation_step):\n            res = minimize(func, initial_guess, method='Nelder-Mead', options={'xatol': mutation_step, 'disp': False})\n            return res.x\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim)),\n                   'mutation_step': 1e-8} for _ in range(4)]  # Adjusted population size\n\n        for i in range(2, self.budget - 3, 2):\n            for wolf in wolves:\n                local_search_position = nelder_mead_local_search(wolf, wolf['position'], wolf['mutation_step'])\n                if func(local_search_position) < wolf['fitness']:\n                    wolf['position'] = local_search_position\n                    wolf['fitness'] = func(local_search_position)\n                    adaptive_factor = 0.95 if func(local_search_position) < wolf['fitness'] else 1.05\n                    wolf['mutation_step'] *= adaptive_factor  # Self-adaptive mutation based on individual performance\n                    wolf['mutation_step'] *= 0.9  # Hybrid strategy combining individual and global search components\n\n            # Dynamic population adjustment based on individual performance\n            wolves = [wolf for wolf in wolves if func(wolf['position']) <= np.median([wolf['fitness'] for wolf in wolves])] + [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim)),\n                   'mutation_step': 1e-8}]\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FasterDynamicMutationHybridImproved", "description": "Implement a randomized local search for enhanced exploration by adding a stochastic component for mutation.", "configspace": "", "generation": 96, "fitness": 0.452395072718341, "feedback": "The algorithm FasterDynamicMutationHybridImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.45 with standard deviation 0.37.", "error": "", "parent_id": "4d42a5fb-5313-4bd1-84c4-067e239a4ab2", "metadata": {"aucs": [0.9693459040718787, 0.9764786142523346, 0.9672950455130237, 0.9573692180319937, 0.9777109701806243, 0.9614230290583405, 0.9622405165801594, 0.9623104941943011, 0.9604377402500864, 0.660298163559962, 0.75062825914107, 0.6283892219795066, 0.6464244431910284, 0.6306913894461025, 0.7539964677635451, 0.6161532901074225, 0.782298744241043, 0.6162961158850546, 0.039068740818985814, 0.027411328286298553, 9.999999999998899e-05, 0.03418372464680197, 0.01660283653252248, 0.024163940301569875, 0.041796733794434826, 0.017218287961372924, 0.0069507194288341845, 0.030027755980294613, 0.022960179933400604, 0.005381546365740397, 0.031726912760187354, 0.005574340721247295, 9.999999999998899e-05, 0.03865505689029014, 0.007398468635365085, 9.999999999998899e-05, 0.8655341165396426, 0.9847388829898945, 0.9855651521943627, 0.9906176061724785, 0.9854514801893373, 0.9939284980257546, 0.993032926985032, 0.9947428921383786, 0.9869180261290181, 0.35095314583760395, 0.5123198086231374, 0.4040153873716529, 0.433216914547506, 0.4968196609791663, 0.3661304456129202, 0.5565920979239402, 0.5331875322284294, 0.6122826629553766, 0.11722479838416089, 0.058631043844522224, 0.029841437200411436, 0.1042148008356133, 0.07303272414091244, 0.0009145883327681403, 0.052380275103301566, 0.123749380818311, 0.061714841914777385, 0.9478517833706125, 0.9389212653122886, 0.9092051455421037, 0.9376200967942181, 0.9439190992367146, 0.6526118145477988, 0.9448413018088235, 0.795131854901874, 0.9241806256640214, 0.9610926053867376, 0.8436799734784903, 0.927900139193082, 0.9368437583431959, 0.936449543885111, 0.9322546508734815, 0.9410624669306766, 0.9579129078837267, 0.8658118318695833, 0.6329082227241138, 0.7748780011935671, 0.578011047599577, 0.9185918214469655, 0.809891383689384, 0.6244375014116115, 0.9301869240278015, 0.9225044964145482, 0.673029354431659, 0.42848865248634194, 0.6013654492655598, 0.5919636079658898, 0.6481490285009635, 0.6875818394255351, 0.5621028103660007, 0.4979195539199993, 0.5967964398430745, 0.46821301110700064, 0.5972495327098518, 0.7549216877028668, 0.5250564574974819, 0.9324331285928574, 0.8444382691484127, 0.7400075372896409, 0.30273177169349175, 0.706535318121068, 0.7144926115770804, 0.8103171280129442, 0.8406514997143855, 0.7361810464556691, 0.7687108978329374, 0.9388519057518508, 0.8716685507902173, 0.6355155332225428, 0.7712286534074079, 0.7176066258115092, 0.9571919385867037, 0.9413813533898703, 0.9537234868386748, 0.9516383532170711, 0.9566229425891609, 0.9131714558409378, 0.9700312231085754, 0.9616816604061403, 0.9300462147048532, 0.018667590521112443, 0.0035036923651181606, 0.006011820502177745, 0.007187507547171679, 0.0004788590924194036, 0.017605185879066676, 0.0009573679188872308, 0.010749130273814855, 0.07112930433292608, 0.1169237058082141, 0.160384138397895, 0.12465411495960255, 0.21718776272929663, 0.1641191613269546, 0.11575447286603846, 0.1001678040475954, 0.08700693009959481, 0.11907525891455295, 0.11991631657574164, 0.12603247979867338, 0.11960344332269757, 0.1463167326775352, 0.11739666929761572, 0.12227740732382009, 0.13915654632921837, 0.14576918324225352, 0.10165123151301891, 0.060305517530043984, 0.05949332598807833, 0.05699326225328749, 0.0832032272273534, 0.060632067924200284, 0.06845883612473025, 0.07421213216152756, 0.07169018014004302, 0.04360600072960952, 0.1915646141979167, 0.06768274427055188, 0.16050610175457625, 0.18761376492361914, 0.10464089429297818, 0.15184477368023475, 0.19031323704505154, 0.10087904721029428, 0.1530998348787922, 0.19574982034546062, 0.19628867417467522, 0.1827395314580602, 0.18480473926960206, 0.25550389433766096, 0.18852191668692564, 0.18970529496559296, 0.19267457182468684, 0.19257485005497998, 0.6255254869932344, 0.17237418438365382, 0.18940033238035203, 0.18392064271195396, 0.18403386861297855, 0.4458093882525387, 0.1624818958262647, 0.4250165671993337, 0.1686623378542036, 0.9696663718891635, 0.925739234135242, 0.9684571200590576, 0.9008878907800546, 0.9367249263712935, 0.5626607422879863, 0.9530986340996562, 0.10405426458180389, 0.9752002265699312, 0.22821687290960524, 0.20597147900831203, 0.25823093038307376, 0.26965158605800266, 0.21519224582371366, 0.2486215342231557, 0.24680278647006293, 0.29270731818814244, 0.602502155370099, 0.04206325736167349, 0.04191363757398847, 0.05828338358211349, 0.04121284356873256, 0.024934228495019806, 0.039953878897864725, 0.04700493679890916, 0.0259187161811415, 0.04409700478622636]}, "mutation_prompt": null}
{"id": "f082b00b-84f3-496c-bc9b-d9849ef5606c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass FasterDynamicMutationHybridImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def differential_evolution_mutation(wolf, population, differential_weight):\n            candidate = population[np.random.choice(len(population))]\n            mutated_wolf = wolf['position'] + differential_weight * (candidate['position'] - wolf['position'])\n            return mutated_wolf\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim)),\n                   'mutation_step': 1e-8} for _ in range(4)]\n\n        for i in range(2, self.budget - 3, 2):\n            for wolf in wolves:\n                mutated_position = differential_evolution_mutation(wolf, wolves, 0.5)\n                local_search_position = nelder_mead_local_search(wolf, mutated_position, wolf['mutation_step'])\n\n                if func(local_search_position) < wolf['fitness']:\n                    wolf['position'] = local_search_position\n                    wolf['fitness'] = func(local_search_position)\n                    adaptive_factor = 0.95 if func(local_search_position) < wolf['fitness'] else 1.05\n                    wolf['mutation_step'] *= adaptive_factor\n                    wolf['mutation_step'] *= 0.9\n\n            wolves = [wolf for wolf in wolves if func(wolf['position']) <= np.median([wolf['fitness'] for wolf in wolves])] + [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim)),\n                   'mutation_step': 1e-8}]\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FasterDynamicMutationHybridImproved", "description": "Utilizing a hybrid mutation strategy combining differential evolution with adaptive mutation rates to enhance local search diversity and speed up convergence.", "configspace": "", "generation": 97, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'nelder_mead_local_search' is not defined\").", "error": "NameError(\"name 'nelder_mead_local_search' is not defined\")", "parent_id": "4d42a5fb-5313-4bd1-84c4-067e239a4ab2", "metadata": {}, "mutation_prompt": null}
{"id": "c8a15eaa-4616-4956-8c63-19ff1d5f8394", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass FasterDynamicMutationHybridImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def nelder_mead_local_search(wolf, initial_guess, mutation_step):\n            res = minimize(func, initial_guess, method='Nelder-Mead', options={'xatol': mutation_step, 'disp': False})\n            return res.x\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim)),\n                   'mutation_step': 1e-8} for _ in range(4)]  # Adjusted population size\n\n        for i in range(2, self.budget - 3, 2):\n            for wolf in wolves:\n                local_search_position = nelder_mead_local_search(wolf, wolf['position'], wolf['mutation_step'])\n                if func(local_search_position) < wolf['fitness']:\n                    wolf['position'] = local_search_position\n                    wolf['fitness'] = func(local_search_position)\n                    adaptive_factor = 0.95 if func(local_search_position) < wolf['fitness'] else 1.05\n                    wolf['mutation_step'] *= adaptive_factor  # Self-adaptive mutation based on individual performance\n                    wolf['mutation_step'] *= 0.9  # Hybrid strategy combining individual and global search components\n\n            # Dynamic population adjustment based on individual performance\n            wolves = [wolf for wolf in wolves if func(wolf['position']) <= np.median([wolf['fitness'] for wolf in wolves])] + [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim)),\n                   'mutation_step': 1e-8}]\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FasterDynamicMutationHybridImproved", "description": "Introducing a dynamic population adjustment mechanism to dynamically change the number of wolves based on their performance to enhance exploration-exploitation balance.", "configspace": "", "generation": 95, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4d42a5fb-5313-4bd1-84c4-067e239a4ab2", "metadata": {"aucs": [0.9693459040718787, 0.9764786142523346, 0.9672950455130237, 0.9573692180319937, 0.9777109701806243, 0.9614230290583405, 0.9622405165801594, 0.9623104941943011, 0.9604377402500864, 0.660298163559962, 0.75062825914107, 0.6283892219795066, 0.6464244431910284, 0.6306913894461025, 0.7539964677635451, 0.6161532901074225, 0.782298744241043, 0.6162961158850546, 0.039068740818985814, 0.027411328286298553, 9.999999999998899e-05, 0.03418372464680197, 0.01660283653252248, 0.024163940301569875, 0.041796733794434826, 0.017218287961372924, 0.0069507194288341845, 0.030027755980294613, 0.022960179933400604, 0.005381546365740397, 0.031726912760187354, 0.005574340721247295, 9.999999999998899e-05, 0.03865505689029014, 0.007398468635365085, 9.999999999998899e-05, 0.8655341165396426, 0.9847388829898945, 0.9855651521943627, 0.9906176061724785, 0.9854514801893373, 0.9939284980257546, 0.993032926985032, 0.9947428921383786, 0.9869180261290181, 0.35095314583760395, 0.5123198086231374, 0.4040153873716529, 0.433216914547506, 0.4968196609791663, 0.3661304456129202, 0.5565920979239402, 0.5331875322284294, 0.6122826629553766, 0.11722479838416089, 0.058631043844522224, 0.029841437200411436, 0.1042148008356133, 0.07303272414091244, 0.0009145883327681403, 0.052380275103301566, 0.123749380818311, 0.061714841914777385, 0.9478517833706125, 0.9389212653122886, 0.9092051455421037, 0.9376200967942181, 0.9439190992367146, 0.6526118145477988, 0.9448413018088235, 0.795131854901874, 0.9241806256640214, 0.9610926053867376, 0.8436799734784903, 0.927900139193082, 0.9368437583431959, 0.936449543885111, 0.9322546508734815, 0.9410624669306766, 0.9579129078837267, 0.8658118318695833, 0.6329082227241138, 0.7748780011935671, 0.578011047599577, 0.9185918214469655, 0.809891383689384, 0.6244375014116115, 0.9301869240278015, 0.9225044964145482, 0.673029354431659, 0.42848865248634194, 0.6013654492655598, 0.5919636079658898, 0.6481490285009635, 0.6875818394255351, 0.5621028103660007, 0.4979195539199993, 0.5967964398430745, 0.46821301110700064, 0.5972495327098518, 0.7549216877028668, 0.5250564574974819, 0.9324331285928574, 0.8444382691484127, 0.7400075372896409, 0.30273177169349175, 0.706535318121068, 0.7144926115770804, 0.8103171280129442, 0.8406514997143855, 0.7361810464556691, 0.7687108978329374, 0.9388519057518508, 0.8716685507902173, 0.6355155332225428, 0.7712286534074079, 0.7176066258115092, 0.9571919385867037, 0.9413813533898703, 0.9537234868386748, 0.9516383532170711, 0.9566229425891609, 0.9131714558409378, 0.9700312231085754, 0.9616816604061403, 0.9300462147048532, 0.018667590521112443, 0.0035036923651181606, 0.006011820502177745, 0.007187507547171679, 0.0004788590924194036, 0.017605185879066676, 0.0009573679188872308, 0.010749130273814855, 0.07112930433292608, 0.1169237058082141, 0.160384138397895, 0.12465411495960255, 0.21718776272929663, 0.1641191613269546, 0.11575447286603846, 0.1001678040475954, 0.08700693009959481, 0.11907525891455295, 0.11991631657574164, 0.12603247979867338, 0.11960344332269757, 0.1463167326775352, 0.11739666929761572, 0.12227740732382009, 0.13915654632921837, 0.14576918324225352, 0.10165123151301891, 0.060305517530043984, 0.05949332598807833, 0.05699326225328749, 0.0832032272273534, 0.060632067924200284, 0.06845883612473025, 0.07421213216152756, 0.07169018014004302, 0.04360600072960952, 0.1915646141979167, 0.06768274427055188, 0.16050610175457625, 0.18761376492361914, 0.10464089429297818, 0.15184477368023475, 0.19031323704505154, 0.10087904721029428, 0.1530998348787922, 0.19574982034546062, 0.19628867417467522, 0.1827395314580602, 0.18480473926960206, 0.25550389433766096, 0.18852191668692564, 0.18970529496559296, 0.19267457182468684, 0.19257485005497998, 0.6255254869932344, 0.17237418438365382, 0.18940033238035203, 0.18392064271195396, 0.18403386861297855, 0.4458093882525387, 0.1624818958262647, 0.4250165671993337, 0.1686623378542036, 0.9696663718891635, 0.925739234135242, 0.9684571200590576, 0.9008878907800546, 0.9367249263712935, 0.5626607422879863, 0.9530986340996562, 0.10405426458180389, 0.9752002265699312, 0.22821687290960524, 0.20597147900831203, 0.25823093038307376, 0.26965158605800266, 0.21519224582371366, 0.2486215342231557, 0.24680278647006293, 0.29270731818814244, 0.602502155370099, 0.04206325736167349, 0.04191363757398847, 0.05828338358211349, 0.04121284356873256, 0.024934228495019806, 0.039953878897864725, 0.04700493679890916, 0.0259187161811415, 0.04409700478622636]}, "mutation_prompt": null}
{"id": "0953928a-23fb-4c45-aebc-acb1fd777e2f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass FasterDynamicMutationHybridImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        def nelder_mead_local_search(wolf, initial_guess, mutation_step):\n            res = minimize(func, initial_guess, method='Nelder-Mead', options={'xatol': mutation_step, 'disp': False})\n            return res.x\n\n        wolves = [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim)),\n                   'mutation_step': 1e-8} for _ in range(4)]  # Adjusted population size\n\n        for i in range(2, self.budget - 3, 2):\n            for wolf in wolves:\n                local_search_position = nelder_mead_local_search(wolf, wolf['position'], wolf['mutation_step'])\n                if func(local_search_position) < wolf['fitness']:\n                    wolf['position'] = local_search_position\n                    wolf['fitness'] = func(local_search_position)\n                    adaptive_factor = 0.95 if func(local_search_position) < wolf['fitness'] else 1.05\n                    wolf['mutation_step'] *= adaptive_factor  # Self-adaptive mutation based on individual performance\n                    wolf['mutation_step'] *= 0.9  # Hybrid strategy combining individual and global search components\n\n            # Dynamic population adjustment based on individual performance\n            wolves = [wolf for wolf in wolves if func(wolf['position']) <= np.median([wolf['fitness'] for wolf in wolves])] + [{'position': np.random.uniform(-5.0, 5.0, self.dim),\n                   'fitness': func(np.random.uniform(-5.0, 5.0, self.dim)),\n                   'mutation_step': 1e-8}]\n\n        best_wolf = min(wolves, key=lambda x: x['fitness'])\n        return best_wolf['position']", "name": "FasterDynamicMutationHybridImproved", "description": "Enhancing convergence speed by incorporating a novel adaptive mutation strategy based on individual performance for each wolf.", "configspace": "", "generation": 99, "fitness": 0.452395072718341, "feedback": "The algorithm FasterDynamicMutationHybridImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.45 with standard deviation 0.37.", "error": "", "parent_id": "4d42a5fb-5313-4bd1-84c4-067e239a4ab2", "metadata": {"aucs": [0.9693459040718787, 0.9764786142523346, 0.9672950455130237, 0.9573692180319937, 0.9777109701806243, 0.9614230290583405, 0.9622405165801594, 0.9623104941943011, 0.9604377402500864, 0.660298163559962, 0.75062825914107, 0.6283892219795066, 0.6464244431910284, 0.6306913894461025, 0.7539964677635451, 0.6161532901074225, 0.782298744241043, 0.6162961158850546, 0.039068740818985814, 0.027411328286298553, 9.999999999998899e-05, 0.03418372464680197, 0.01660283653252248, 0.024163940301569875, 0.041796733794434826, 0.017218287961372924, 0.0069507194288341845, 0.030027755980294613, 0.022960179933400604, 0.005381546365740397, 0.031726912760187354, 0.005574340721247295, 9.999999999998899e-05, 0.03865505689029014, 0.007398468635365085, 9.999999999998899e-05, 0.8655341165396426, 0.9847388829898945, 0.9855651521943627, 0.9906176061724785, 0.9854514801893373, 0.9939284980257546, 0.993032926985032, 0.9947428921383786, 0.9869180261290181, 0.35095314583760395, 0.5123198086231374, 0.4040153873716529, 0.433216914547506, 0.4968196609791663, 0.3661304456129202, 0.5565920979239402, 0.5331875322284294, 0.6122826629553766, 0.11722479838416089, 0.058631043844522224, 0.029841437200411436, 0.1042148008356133, 0.07303272414091244, 0.0009145883327681403, 0.052380275103301566, 0.123749380818311, 0.061714841914777385, 0.9478517833706125, 0.9389212653122886, 0.9092051455421037, 0.9376200967942181, 0.9439190992367146, 0.6526118145477988, 0.9448413018088235, 0.795131854901874, 0.9241806256640214, 0.9610926053867376, 0.8436799734784903, 0.927900139193082, 0.9368437583431959, 0.936449543885111, 0.9322546508734815, 0.9410624669306766, 0.9579129078837267, 0.8658118318695833, 0.6329082227241138, 0.7748780011935671, 0.578011047599577, 0.9185918214469655, 0.809891383689384, 0.6244375014116115, 0.9301869240278015, 0.9225044964145482, 0.673029354431659, 0.42848865248634194, 0.6013654492655598, 0.5919636079658898, 0.6481490285009635, 0.6875818394255351, 0.5621028103660007, 0.4979195539199993, 0.5967964398430745, 0.46821301110700064, 0.5972495327098518, 0.7549216877028668, 0.5250564574974819, 0.9324331285928574, 0.8444382691484127, 0.7400075372896409, 0.30273177169349175, 0.706535318121068, 0.7144926115770804, 0.8103171280129442, 0.8406514997143855, 0.7361810464556691, 0.7687108978329374, 0.9388519057518508, 0.8716685507902173, 0.6355155332225428, 0.7712286534074079, 0.7176066258115092, 0.9571919385867037, 0.9413813533898703, 0.9537234868386748, 0.9516383532170711, 0.9566229425891609, 0.9131714558409378, 0.9700312231085754, 0.9616816604061403, 0.9300462147048532, 0.018667590521112443, 0.0035036923651181606, 0.006011820502177745, 0.007187507547171679, 0.0004788590924194036, 0.017605185879066676, 0.0009573679188872308, 0.010749130273814855, 0.07112930433292608, 0.1169237058082141, 0.160384138397895, 0.12465411495960255, 0.21718776272929663, 0.1641191613269546, 0.11575447286603846, 0.1001678040475954, 0.08700693009959481, 0.11907525891455295, 0.11991631657574164, 0.12603247979867338, 0.11960344332269757, 0.1463167326775352, 0.11739666929761572, 0.12227740732382009, 0.13915654632921837, 0.14576918324225352, 0.10165123151301891, 0.060305517530043984, 0.05949332598807833, 0.05699326225328749, 0.0832032272273534, 0.060632067924200284, 0.06845883612473025, 0.07421213216152756, 0.07169018014004302, 0.04360600072960952, 0.1915646141979167, 0.06768274427055188, 0.16050610175457625, 0.18761376492361914, 0.10464089429297818, 0.15184477368023475, 0.19031323704505154, 0.10087904721029428, 0.1530998348787922, 0.19574982034546062, 0.19628867417467522, 0.1827395314580602, 0.18480473926960206, 0.25550389433766096, 0.18852191668692564, 0.18970529496559296, 0.19267457182468684, 0.19257485005497998, 0.6255254869932344, 0.17237418438365382, 0.18940033238035203, 0.18392064271195396, 0.18403386861297855, 0.4458093882525387, 0.1624818958262647, 0.4250165671993337, 0.1686623378542036, 0.9696663718891635, 0.925739234135242, 0.9684571200590576, 0.9008878907800546, 0.9367249263712935, 0.5626607422879863, 0.9530986340996562, 0.10405426458180389, 0.9752002265699312, 0.22821687290960524, 0.20597147900831203, 0.25823093038307376, 0.26965158605800266, 0.21519224582371366, 0.2486215342231557, 0.24680278647006293, 0.29270731818814244, 0.602502155370099, 0.04206325736167349, 0.04191363757398847, 0.05828338358211349, 0.04121284356873256, 0.024934228495019806, 0.039953878897864725, 0.04700493679890916, 0.0259187161811415, 0.04409700478622636]}, "mutation_prompt": null}

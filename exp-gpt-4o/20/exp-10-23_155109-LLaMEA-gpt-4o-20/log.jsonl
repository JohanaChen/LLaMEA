{"id": "0e7e8454-0b14-4aff-b7a6-4c562ec16ee6", "solution": "import numpy as np\n\nclass DEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.F = 0.8  # Differential weight for DE\n        self.CR = 0.9  # Crossover probability for DE\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            # Perform Differential Evolution steps\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                # Mutation\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Selection\n                trial_value = func(trial)\n                self.current_eval += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            # Perform Particle Swarm Optimization steps\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                # Update velocity\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                # Update position\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                # Update personal and global bests\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n        return global_best", "name": "DEPSOHybridOptimizer", "description": "A dynamic hybrid metaheuristic combining Differential Evolution (DE) and Particle Swarm Optimization (PSO) to adaptively explore and exploit the search space.", "configspace": "", "generation": 0, "fitness": 0.27972933389776644, "feedback": "The algorithm DEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.23.", "error": "", "parent_id": null, "metadata": {"aucs": [0.6516438008716625, 0.5365774811437165, 0.7291523739255019, 0.6651503182669061, 0.6218528448269596, 0.6087729244844919, 0.6396136083117478, 0.6095350234427395, 0.6698617609773156, 0.17625311517194464, 0.20284523002316435, 0.3099343278247444, 9.999999999998899e-05, 0.25280492558571555, 0.1936334397613959, 0.041606567276816664, 0.2234475498202213, 0.27404779273686763, 0.09623545908523434, 0.14389422832670584, 0.11840195043092094, 0.11090963544489008, 0.10651737779373305, 0.12572692892337123, 0.12053560119602391, 0.12830848402496609, 0.10637599377257467, 0.08871512873907339, 0.08451753538760132, 0.10247354372037298, 0.12593407894374664, 0.11880340499366793, 0.08687391889531515, 0.09364452311081406, 0.08330611229133733, 0.09977770285820786, 0.9890419603190831, 0.9900505236362046, 0.9808514158420893, 0.9899420184833433, 0.9877567128506927, 0.9701419414718636, 0.9814175532466967, 0.9898702109739984, 0.988596618343626, 0.3246449505435425, 0.3855953058350233, 0.2907490181817728, 0.3466531561774534, 0.43001889615696354, 0.3447588542547848, 0.3766291811268443, 0.3281291585098991, 0.3860798421639895, 0.22109285682045865, 0.5639596105774984, 0.6694289534964677, 0.1918202646667415, 0.19141163487474555, 0.6771921611842658, 0.7373373805402478, 0.7054451380997457, 0.6909263145870131, 0.43640378286180925, 0.24412250752077358, 0.25675629495837504, 0.2338001150298693, 0.2893055471012934, 0.2587842469485544, 0.2522772939271004, 0.28969370864951804, 0.24541352236236824, 0.28721178466171604, 0.12282025784984818, 0.2556227520643263, 0.1730950240141257, 0.24752581927923345, 0.3161180555805697, 0.38049468779767526, 0.3174517821359417, 0.3306162821158739, 0.14027598466347102, 0.20954944412839727, 0.13437853236809583, 0.00010375644510385307, 0.00956882540445203, 0.05700545242696209, 0.17481270289582518, 0.1374098552098192, 0.16095017992762317, 0.1278574110282128, 0.22237184631527462, 0.1578161617630809, 0.06399297556356431, 0.044621969696962305, 0.32046901853764276, 0.0478261998348839, 0.09412414759447052, 0.11945529007261635, 0.07932666650759679, 0.02443827394695275, 0.12152130358158064, 0.05375369869782243, 0.14619517923644543, 0.059195960401827286, 0.1072226672134231, 0.16734359057605508, 0.05053252151984122, 0.16989080354574637, 0.12232225065726265, 0.18514229536803073, 0.09895551072828801, 0.2365743596381752, 0.1328813109882898, 0.0524645436493929, 0.12944768003446838, 0.2263330309043312, 0.5227325592179686, 0.534198702264673, 0.5759543766509989, 0.5728130690318902, 0.5131939012833592, 0.5713533441262237, 0.5490322129957395, 0.4896786215820168, 0.4918283870828588, 0.08936803523198378, 0.1044016647829118, 0.1251552078385676, 0.11296149163080116, 0.1104321777676952, 0.12423855694785502, 0.10090032735949095, 0.09630762748339916, 0.12122805136582626, 0.23651930278487643, 0.17498657900561487, 0.1766897146941543, 0.24020699320961925, 0.2762692509290888, 0.14799411397023066, 0.1460560255065495, 0.26369950590297897, 0.2067055599577774, 0.3487911299906312, 0.2362501557135277, 0.3208311441135746, 0.34136551256929637, 0.32176783380954443, 0.35108750719293746, 0.31802809210755245, 0.31316359956075335, 0.30978731055090725, 0.2215389543026829, 0.16325688969647056, 0.24427721102077915, 0.2008497550992775, 0.24526061336104188, 0.23933981909094992, 0.26876876653020987, 0.18848097728126745, 0.24617888162087542, 0.24175892718801673, 0.20099479996906955, 0.24294252089126234, 0.20663363955585745, 0.2057443145418557, 0.18801230563464677, 0.18598824658955382, 0.2197609021152983, 0.20671672912357608, 0.18102081268640735, 0.18579438064749088, 0.1922614970936506, 0.20414709591449864, 0.19701850261080467, 0.3130451495061264, 0.18849323122763784, 0.1931866773560762, 0.17922147065351268, 0.18285245778099568, 0.18702721275196943, 0.20782885172858856, 0.7352910504046203, 0.19862508396886647, 0.19534817589527043, 0.796578057160358, 0.14392883086465647, 0.44518843540885955, 0.8121623833149159, 0.21097170185704828, 0.5914582795922672, 0.6718509108554506, 0.11262046940878412, 0.16542496770688153, 0.19736401071365972, 0.27825559513602316, 0.12432602697728601, 0.19096534845774193, 0.18743807616001618, 0.18196853878023944, 0.20182678020782352, 0.19326716704687064, 0.1941562495030713, 0.1877313681781546, 0.1905492507527724, 0.18800876738785688, 0.0803691660785848, 0.0772919552558482, 0.08047997971146037, 0.07266524077722136, 0.08136598003295281, 0.0918159016391974, 0.09252897118266101, 0.10871173189132555, 0.07565123853799127]}, "mutation_prompt": null}
{"id": "b8dee468-bf26-4062-9a51-f5648ac6f106", "solution": "import numpy as np\n\nclass EnhancedDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.5\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.F = 0.8\n        self.CR = 0.9\n        self.adapt_factor = 0.99  # New adaptive factor\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Adapt inertia weight dynamically\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n        return global_best", "name": "EnhancedDEPSOHybridOptimizer", "description": "An enhanced DEPSO hybrid optimizer using adaptive parameters for improved exploration and exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.3370352809157066, "feedback": "The algorithm EnhancedDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.24.", "error": "", "parent_id": "0e7e8454-0b14-4aff-b7a6-4c562ec16ee6", "metadata": {"aucs": [0.7657025383437086, 0.7249355989069932, 0.7751374275818349, 0.7057081100228098, 0.7670211803529974, 0.7360020030935226, 0.7849463777584526, 0.7391551006545777, 0.7669975463888624, 0.3887370535542787, 0.3697889605074032, 0.548816306274986, 0.28049502280980354, 0.4387263511101266, 0.4171725442764934, 9.999999999998899e-05, 0.5000054381290294, 0.4625557689810005, 0.11639836014575244, 0.12982127212824834, 0.10438223002477076, 0.10118136677139844, 0.10617260964935815, 0.1324263617690512, 0.16222448415629498, 0.11015649777020031, 0.11912641479014108, 0.12375562315669741, 0.13326962374665996, 0.10164646037986436, 0.10065313226674533, 0.10493764744808598, 0.12330953339600603, 0.10056438781817756, 0.14548711358697053, 0.09224680880093328, 0.9890416296388413, 0.9900505240583521, 0.9808532063928681, 0.9899422281585499, 0.9877567140608109, 0.9701062710474655, 0.9814176756166433, 0.9898702151820358, 0.9885967114541215, 0.430146048236137, 0.4364904093299571, 0.47224316093332697, 0.2169721243029279, 0.48418976650810297, 0.5070925288477672, 0.40179967007962747, 0.4363757702010259, 0.4110631669230579, 0.23627299793039347, 0.8293203913711769, 0.37515413742675285, 0.21054440139917108, 0.8078948340543366, 0.7054700126707898, 0.17515660120586019, 0.7894134918444424, 0.2342703211515278, 0.42943920396074753, 0.3275285557461658, 0.10792381101739268, 0.39323601331696467, 0.4258831852455408, 0.49245384189681163, 0.4096612624010675, 0.4965437461837072, 0.5298970035796035, 0.5352812382581369, 0.5346285051943609, 0.3743787083452257, 0.3066953212315149, 0.39614208375417903, 0.5569153224983581, 0.32250701172821683, 0.4682048644515162, 0.5190059995588203, 0.25984919309520027, 0.3681402461725316, 0.1427966448351996, 9.999999999998899e-05, 0.1793785783419447, 0.41616131920904453, 0.3508845384342981, 0.38687130723674723, 0.36899871821003793, 0.5412929621791648, 0.3056366370359468, 0.3742347901770219, 0.22671171528588752, 0.07877983646916908, 0.29301132815213604, 0.4228331861523774, 0.25468596501928187, 0.3952185897443262, 9.999999999998899e-05, 0.02506841131326487, 0.2628711036328394, 0.17958447904043584, 0.10173907495724599, 0.10185697011158368, 0.09985548176002434, 0.21077222245892924, 0.05659424593779838, 0.2630289921047455, 0.17883045002225428, 0.3264956259912195, 0.24281088809120532, 0.31162730888561785, 0.17460806058725897, 0.045103933638436344, 0.05413768635160776, 0.17446568565935794, 0.6149429165023612, 0.6496174497372929, 0.6396777439760675, 0.6437778142951255, 0.6483882815211677, 0.5972731911661711, 0.5650705169328538, 0.6306960203862644, 0.6429535613282349, 0.08998541305629915, 0.08323866805105484, 0.07708924866422928, 0.13463888801718493, 0.1044180259576517, 0.10797097181634585, 0.1027406554630601, 0.1317453314189172, 0.09622846897314197, 0.33432425226271056, 0.2189623868899946, 0.17709145999611975, 0.25878065743538126, 0.3943099026667073, 0.20054078863666114, 0.1922727414891342, 0.1613752385799636, 0.26189344397014924, 0.23700053971166646, 0.2528092510258312, 0.3200632676272359, 0.3737686524865069, 0.3029302116617729, 0.31261478683539345, 0.328417396939519, 0.4176675609277951, 0.39019013404627045, 0.1952989773033732, 0.2783592704691409, 0.1976932210046447, 0.2587446515924585, 0.2305286376473188, 0.2709161205963032, 0.2430980334226761, 0.20943192412546674, 0.31274309488505814, 0.25310239733250905, 0.21021196189194669, 0.20581445508897855, 0.21546403917862167, 0.19794592437962932, 0.20278100732139492, 0.23836604295133468, 0.22318971794145415, 0.2836353287406099, 0.18347008039613355, 0.19518731577630732, 0.23725408906461187, 0.6313260391227967, 0.23430432483612917, 0.18862562095070534, 0.17392910115597293, 0.1844074198165352, 0.19568574404590067, 0.17623426208131554, 0.1871115600636526, 0.2105468639379543, 0.1983866871528025, 0.1988269853575544, 0.7159110918161956, 0.8366926014388956, 0.14666784505241026, 0.16714608770270933, 0.7996458019463669, 0.21172183487202834, 0.740207354886417, 0.77162033996959, 0.1127259358084246, 0.6406208606114512, 0.19843939319534576, 0.5566016059296126, 0.12567862865202228, 0.20887389579821047, 0.18883156231404552, 0.2021186674411889, 0.1851674806532635, 0.20443016509063927, 0.180440775230301, 0.1845908457417318, 0.20360606197961795, 0.21079125569181956, 0.10493637498933006, 0.08837073223192604, 0.09276252420110409, 0.0814950346516875, 0.08865093251804046, 0.07790540895914577, 0.06678139378004055, 0.09027242543241465, 0.08909889788234271]}, "mutation_prompt": null}
{"id": "5d821ba0-6095-4f61-9b3f-7fa97de2efa6", "solution": "import numpy as np\n\nclass RefinedDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Adjusted inertia weight\n        self.c1 = 1.8  # Reduced cognitive component\n        self.c2 = 2.2  # Increased social component\n        self.F = 0.9  # Increased Differential Evolution factor\n        self.CR = 0.85  # Adjusted crossover rate\n        self.adapt_factor = 0.98  # Adjusted adaptive factor\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))  # Narrowed velocity range\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Adapt inertia weight dynamically\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                r1, r2, r3 = np.random.rand(3)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                if r3 < 0.1:  # Introduce random exploration\n                    pop[i] = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                else:\n                    pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                    \n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n        return global_best", "name": "RefinedDEPSOHybridOptimizer", "description": "A refined DEPSO hybrid optimizer emphasizing mutation diversity and dynamic parameter tuning for robust exploration and exploitation.", "configspace": "", "generation": 2, "fitness": 0.21054715617909953, "feedback": "The algorithm RefinedDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.21.", "error": "", "parent_id": "b8dee468-bf26-4062-9a51-f5648ac6f106", "metadata": {"aucs": [0.5095497912104121, 0.5137804375403643, 0.41044966203902467, 0.5386267392866246, 0.562023995760399, 0.4738774862365054, 0.5988771933492001, 0.39156732736442346, 0.40109098173844215, 0.016731410335293684, 0.01761827605351851, 9.999999999998899e-05, 0.01715040167156623, 0.027166495303219906, 9.999999999998899e-05, 0.11820673488724043, 0.0024324060422330485, 0.06294135957315716, 0.11680788189211111, 0.12706841787387257, 0.0728561667996599, 0.09329548900512386, 0.09870932160463308, 0.08010322134488757, 0.07280500434373482, 0.11645165455331752, 0.09309583605281568, 0.09196976710606664, 0.09851642921371606, 0.07943701556726324, 0.0923255080498524, 0.06138048248805206, 0.08503317495092033, 0.08712363516829724, 0.0776791182216291, 0.0771555998908654, 0.9894927030326679, 0.9791530101993652, 0.9865238035497008, 0.9903914417823725, 0.9867223699204599, 0.9726045586125405, 0.9720026424879842, 0.990239274352549, 0.9864654805150748, 0.25996579051665414, 0.24638336350079315, 0.18628554942008502, 0.207843847754566, 0.36019562193323484, 0.1783650150963595, 0.17215869513349502, 0.17486369635000742, 0.1769111252480443, 0.243710316531207, 0.22226617874809007, 0.22832336359728944, 0.2983495489031459, 0.3083984827439986, 0.4115942538221429, 0.17725552619612894, 0.1314487508566271, 0.22504520076813228, 0.1567128884000717, 0.11588803827241045, 0.13473129766948766, 0.0982968625191003, 0.14729320665273848, 0.14740419543241756, 0.13174763076344043, 0.12283904966668013, 0.10485800427174508, 0.19948109994043983, 0.010045771111248492, 0.10276924615533622, 0.14278103256172459, 0.11663961392608346, 0.11157899241056657, 0.13523773911469583, 0.13183980280152952, 0.11853792624450366, 9.999999999998899e-05, 0.00026958812104660446, 0.03997070115522616, 0.018838455792260955, 0.021987823331212186, 9.999999999998899e-05, 0.030627165443399607, 0.014966499270333222, 0.0026561767886258414, 0.09052491725701528, 0.10052474678555445, 0.1148076687918278, 0.12646299917547366, 0.04695637460033519, 0.036279368935122513, 0.1573883861692439, 0.04791183408768762, 0.12373581102447584, 0.009237196631100009, 0.06782080118462563, 0.030000562656006702, 0.05212382613138011, 0.03880912760141686, 0.010232353903889102, 0.057372508997282634, 0.020643274487840646, 0.026358905694997103, 0.12178304979481036, 0.12177982345233462, 0.09739055452428436, 0.037835609700041295, 0.13223977283411337, 0.07776027344796455, 0.045514150842993706, 0.08672445270692153, 0.07646011942911735, 0.41677782199952784, 0.42011430163493435, 0.3653827650426861, 0.40498934068321113, 0.4016626139106605, 0.4037382662143114, 0.37227443558005313, 0.4044771040550762, 0.40272051450162605, 0.08927637765131036, 0.10022633103619372, 0.12087726765250206, 0.11093329903312055, 0.11306357382811216, 0.0975038404118228, 0.10568667048905778, 0.10685916853107813, 0.13778753374829178, 0.15504906025577947, 0.15632192613729734, 0.16591480058103703, 0.2251104873273294, 0.20281149793628306, 0.20930294870634836, 0.19247837098323095, 0.1683810887291891, 0.24672640060324724, 0.22590967526981853, 0.2937752702451628, 0.25458051971698437, 0.25352877123667206, 0.2967846586529609, 0.2587307064072074, 0.25600482821092385, 0.2509975161083504, 0.223039654664147, 0.21100839369138846, 0.23448236622364615, 0.22330399588424665, 0.2598879490403424, 0.20576994481110422, 0.24134607687252918, 0.20625288344805792, 0.20683471709719836, 0.19965040300902048, 0.22069273689675195, 0.18209912266238204, 0.18112006260037306, 0.20027722704020046, 0.17481806041371295, 0.1795111202138221, 0.21655862135100146, 0.2224594148097333, 0.20656766213198097, 0.18025538674975305, 0.17771021991595515, 0.17272687496643435, 0.1900254919611316, 0.18271614615225684, 0.215027961886338, 0.17257776598550023, 0.17146743789360075, 0.18676688018475385, 0.6632840165087379, 0.16372831090098294, 0.41006563868434664, 0.18358597684646405, 0.19297367528256237, 0.16852525177221123, 0.1730865685685432, 0.16053336551010833, 0.20208655886332239, 0.4674389788879737, 0.2057513736268275, 0.4524657878858235, 0.5333538344583606, 0.16611042901208162, 0.5231794188964993, 0.2071901854083844, 0.14729259701646058, 0.4102348628527682, 0.19528023388103288, 0.17672929695686002, 0.1952126431447071, 0.19758781635872735, 0.18617089757674699, 0.18169990641933087, 0.2016112728741163, 0.18744411668981742, 0.18190030040107963, 0.07349733497712585, 0.08068215853014515, 0.0710661939479098, 0.0671986823068611, 0.06970336991479942, 0.07265710767564293, 0.07458981158259526, 0.07067025636331348, 0.07194185967812805]}, "mutation_prompt": null}
{"id": "23593a2b-cab7-442f-8f58-716c8d0925d0", "solution": "import numpy as np\n\nclass DynamicDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.5\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.F = 0.8\n        self.CR = 0.9\n        self.adapt_factor = 0.98  # Modified adaptive factor\n        self.global_influence = 0.5  # New parameter for global influence\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Adapt inertia weight dynamically\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.global_influence * self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n                # Reinitialize particles randomly with a small probability to escape local optima\n                if np.random.rand() < 0.05:\n                    pop[i] = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n\n        return global_best", "name": "DynamicDEPSOHybridOptimizer", "description": "A dynamic DEPSO hybrid optimizer with adaptive global influence and stochastic reinitialization to enhance search diversification.", "configspace": "", "generation": 3, "fitness": 0.27348985134025355, "feedback": "The algorithm DynamicDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.24.", "error": "", "parent_id": "b8dee468-bf26-4062-9a51-f5648ac6f106", "metadata": {"aucs": [0.7957920525745126, 0.7443803433280483, 0.6683601324226509, 0.8431150474559356, 0.7785747279069755, 0.6237063238835686, 0.648188442166603, 0.6259132004129226, 0.6393854242914951, 0.05901845857805332, 0.12060318860817498, 0.11614182537872808, 0.1565289936588572, 0.06350225756383154, 0.17895236990700958, 0.09919352768393674, 0.3062105951479428, 0.06915943838427663, 0.16707183490623045, 0.11772727134194394, 0.11712063402136408, 0.12819338805639058, 0.11066290373959253, 0.14870109464232284, 0.10283519850791001, 0.08735178906280949, 0.1060987717573213, 0.08084500482014167, 0.10092132529679676, 0.08440093109887126, 0.10500447822163927, 0.08890148472183679, 0.07245340909741427, 0.1047754499423772, 0.10374013439712193, 0.06809342833279586, 0.9791149390775955, 0.9900491315394867, 0.9788227390336756, 0.9740745364768126, 0.9719813429941462, 0.9704830855974361, 0.9700968239970007, 0.9814125608287543, 0.9807150079982223, 0.4178519437211605, 0.35990105869771283, 0.31327335164447345, 0.4438769817389654, 0.3969082385177125, 0.3739193751096843, 0.3776704494555395, 0.28640852952788465, 0.2996380209719284, 0.22627966503139718, 0.8593444540192958, 0.3166107906487349, 0.8635739576295619, 0.26892342042020967, 0.3245063453717968, 0.6351540461554377, 0.2186709166935037, 0.8552296838628388, 0.24205138864356135, 0.14749771691855895, 0.1847303888744618, 0.14214962810957876, 0.1460103578893115, 0.1491237984032574, 0.15033643249112316, 0.12584048849580032, 0.18942903762251762, 0.1234178855979089, 0.15775891907520367, 0.13526472699905734, 0.1267901957136821, 0.18505489742362768, 0.16260525858281472, 0.1254323206430279, 0.18712787707426293, 0.09041719463403919, 0.068220066956309, 0.014644383570480035, 0.08618092279559986, 0.0034386305557085883, 9.999999999998899e-05, 0.08362084411895399, 0.06640237542329108, 0.016603142402544124, 0.0513169700256596, 0.19467612847999194, 0.13467608808959197, 0.16244495781246826, 0.12325339295083881, 0.026897069145360386, 0.24392944212428536, 0.10455191876029535, 0.2085923911444738, 0.11843616877127428, 0.11823023951760803, 0.11206278320513063, 0.06718718171386551, 0.0888873582028129, 0.06740010991943346, 0.0785412613239942, 0.16481936484089077, 0.15962203972009015, 0.05730705204691655, 0.25268200288910747, 0.14661252151815074, 0.09171066684355389, 0.1321072107824406, 0.11300905021752317, 0.1652172838155842, 0.13443528356030987, 0.06502861675788829, 0.0791126147008685, 0.4472154712306273, 0.4512421201828626, 0.46065100466492326, 0.5044452272732686, 0.48555929436930423, 0.48320453284928555, 0.5192370033109861, 0.49354550998780966, 0.5343979686023405, 0.10258910737615279, 0.12342352865256179, 0.141043037260137, 0.09075407667684698, 0.12590216123941078, 0.12573321519797098, 0.12826868780892442, 0.13543562577265456, 0.1545767975554443, 0.35074740522018333, 0.34872158954701304, 0.15761934635999275, 0.2494562794729902, 0.2362078121029918, 0.16149821983967327, 0.28154955684181293, 0.21441484704053815, 0.2362456519605235, 0.3432895871163104, 0.35200003238538535, 0.3162969054895055, 0.279644228928591, 0.23774201007100915, 0.3183407505895558, 0.33675480269889935, 0.3875705048123149, 0.2811300162153023, 0.1825913469859458, 0.31378016569945644, 0.23810722928170647, 0.22329369285228418, 0.23202393193991988, 0.2822135685501924, 0.22280105294587227, 0.2480454029388025, 0.22771206077474548, 0.24330802256740858, 0.19450905904671179, 0.2605002925373353, 0.22203206170481649, 0.2518553512432189, 0.220423888599242, 0.267218255005516, 0.21818589383758114, 0.25655414357024886, 0.21052469912247507, 0.2066695887456017, 0.1868097479762849, 0.18676550990511365, 0.18173492280911507, 0.1850891413779877, 0.21636542146142945, 0.22246084453038906, 0.18296256655551968, 0.18700160377207697, 0.20752293167243974, 0.18676064064042375, 0.7725903195088261, 0.19823732143795747, 0.7786234047358902, 0.7252436067255255, 0.6908258278053421, 0.7789804030528538, 0.47360921605824347, 0.2112265566402861, 0.16753801685250325, 0.20938702454744307, 0.17126174908491798, 0.1667635909412576, 0.21202690923425138, 0.19902987786802118, 0.7974420513680472, 0.1937892992728728, 0.20871077131193305, 0.20288375745358156, 0.19967253864263312, 0.1843690508371727, 0.18597538574731387, 0.22654293339338039, 0.18996951146933727, 0.18782612752219263, 0.11300964385449863, 0.08638751850192317, 0.09206716668590198, 0.08932318525590455, 0.09629943518457407, 0.07708482235703362, 0.0869876879380227, 0.0905215207233605, 0.10821237615334234]}, "mutation_prompt": null}
{"id": "c132f5d8-e9f3-4762-8e87-ad34593e862c", "solution": "import numpy as np\n\nclass ImprovedDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.5\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.F = 0.8\n        self.CR = 0.9\n        self.adapt_factor = 0.98  # Modified adaptive factor for more variability\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Adapt inertia weight dynamically\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            # Introduce stochastic competitive selection to maintain diversity\n            if np.random.rand() < 0.1:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "ImprovedDEPSOHybridOptimizer", "description": "An improved DEPSO hybrid optimizer using stochastic competitive selection and adaptive diversity control for better convergence.", "configspace": "", "generation": 4, "fitness": 0.34432737318101014, "feedback": "The algorithm ImprovedDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.24.", "error": "", "parent_id": "b8dee468-bf26-4062-9a51-f5648ac6f106", "metadata": {"aucs": [0.7743977590574669, 0.7822056509981119, 0.7872251876298205, 0.8067419451244497, 0.7922739028889377, 0.7810854984295478, 0.7572676281205368, 0.7708212796301124, 0.7907663090048841, 0.5269204595988201, 0.3461700899663056, 0.43368448843029384, 0.5160542152805555, 0.4425868276449906, 0.5149526420387717, 0.4884232758469569, 0.4180539516643039, 0.4079329459901577, 0.11418630362165128, 0.09948476978000964, 0.13826309765050826, 0.10618247989036522, 0.11280438093779088, 0.11673080632730559, 0.1232843409469544, 0.10317430195235489, 0.1283343306293926, 0.08258426055320034, 0.10615512495911661, 0.08449518906106734, 0.08848939763524655, 0.09039229810803862, 0.11246361290043527, 0.11581586404750355, 0.08848505199415291, 0.07606236622050311, 0.9890413014122783, 0.9900505244805408, 0.9811387820024914, 0.9899424466008889, 0.9877567153039005, 0.9708766921893219, 0.9804572043465893, 0.9898702193910927, 0.988596804716048, 0.53721863706024, 0.5147148355484825, 0.4742117738736792, 0.34427909835514914, 0.46850854408368237, 0.42767856772004953, 0.464636790681497, 0.4196770231744683, 0.49619294954037263, 0.7710151164503192, 0.7260807155827533, 0.22175671605223857, 0.21476257701525092, 0.7824113733497998, 0.27912310892026615, 0.7529570854707133, 0.7489667596261027, 0.6519932173756835, 0.31184675779617144, 0.40978424739996167, 0.4282035727117418, 0.4663197021936808, 0.4603647195762919, 0.5766319691864397, 0.4619491749952822, 0.557253452959972, 0.41527909003195596, 0.539269887442897, 0.527592255596137, 0.4666751802620157, 0.46319589746724044, 0.5147361631344379, 0.37457456784495646, 0.54398871871234, 0.5581279213560768, 0.4690914664029425, 0.35596349903248126, 0.33322963519728566, 0.45723320439119064, 0.050920831359504315, 0.45999364779963303, 0.3030095457183606, 0.3715242422552636, 0.4258425699404429, 0.26046130611392115, 0.5716239649613284, 0.13478815010470302, 0.3434446975070007, 0.44505494995809625, 0.26306037729919207, 0.5151510795151064, 0.5283920314447946, 0.1745822961923843, 0.21125790658204946, 0.03336600620157826, 0.07953193709766293, 0.1220353438187618, 0.25989895491564496, 0.0928127978230534, 0.16153377796446855, 0.25026973741651604, 0.2805145658302034, 0.06415990312232367, 0.20211189370345095, 0.26428635519403854, 0.3220209035899225, 0.16803160702905062, 0.3309713175341058, 0.2979867685428882, 0.05609053977181355, 0.04773842766055636, 0.253374235567724, 0.6375956982614965, 0.6745207981464533, 0.6639483233179826, 0.6460045752590806, 0.723419174825599, 0.6592312854575237, 0.7046599953149435, 0.6900256366416531, 0.6230735325886747, 0.095364214591523, 0.12774005912672315, 0.08359464856181709, 0.090711730568108, 0.11566462467373384, 0.1247869303188398, 0.09550691575284742, 0.12547865523055446, 0.11143466224570142, 0.2786830154141505, 0.24917931607621535, 0.19621036150526794, 0.22556924436918913, 0.262471443978748, 0.31920589621522477, 0.1659528675056421, 0.1906072247030215, 0.17855960541184923, 0.30969739108635275, 0.2491283717107814, 0.2960596689362125, 0.331740796082429, 0.3145545372823637, 0.3044784983784491, 0.3162128382805871, 0.25484355039392625, 0.3374032577208218, 0.24132330888116915, 0.25760992396531945, 0.23905398268085287, 0.2790850029554579, 0.22580263918169563, 0.18350833640621644, 0.25187403745391146, 0.26375378831786245, 0.25363945840384006, 0.1928107245537901, 0.1610520875718905, 0.192882626990994, 0.22542303043276235, 0.20358438526403289, 0.19584468925095622, 0.2158480123929144, 0.21986587379796318, 0.21478463791228275, 0.18356470953755555, 0.19312809099083994, 0.1971401401837013, 0.18561425094584472, 0.216353637139579, 0.18641803311533178, 0.1782249220448906, 0.21037536932938294, 0.1837310107900224, 0.17566630557868923, 0.18674930013254365, 0.30047745145866556, 0.1981248111540973, 0.1992909191911092, 0.19701478074848078, 0.8578943626329295, 0.1433456285429423, 0.5195612942013259, 0.8387139454371109, 0.21086670047738976, 0.2056048505591539, 0.1656271808480435, 0.11269472084509669, 0.1640929120662824, 0.2101626768230177, 0.220562162040435, 0.15859679554689632, 0.1889652047255468, 0.19029095206338031, 0.19887279184694984, 0.1868159457352706, 0.19281838313466726, 0.1933518187250982, 0.19328167884762582, 0.2165051516477564, 0.18350967130513196, 0.098542758432142, 0.0904133715425458, 0.09354653224095288, 0.10046855144738165, 0.08112473176893942, 0.07895957496766626, 0.08793411981270804, 0.097781997268797, 0.08484514876431692]}, "mutation_prompt": null}
{"id": "7672cbc6-f106-47c0-9804-2e2ea678b59a", "solution": "import numpy as np\n\nclass EnhancedDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 15 * dim  # Increased initial population size for better exploration\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Slightly increased inertia weight for better exploration\n        self.c1 = 1.5  # Adjusted cognitive coefficient\n        self.c2 = 2.5  # Adjusted social coefficient\n        self.F = 0.7  # Modified differential weight\n        self.CR = 0.85  # Modified crossover rate\n        self.adapt_factor = 0.96  # Modified adaptive factor for more variability\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Adapt inertia weight dynamically\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            # Introduce stochastic competitive selection to maintain diversity\n            if np.random.rand() < 0.15:  # Increase chance to introduce more exploration\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "EnhancedDEPSOHybridOptimizer", "description": "An enhanced DEPSO hybrid algorithm utilizing dynamic population size and adaptive velocity bounds to improve exploration and exploitation balance.", "configspace": "", "generation": 5, "fitness": 0.2892444735115032, "feedback": "The algorithm EnhancedDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.23.", "error": "", "parent_id": "c132f5d8-e9f3-4762-8e87-ad34593e862c", "metadata": {"aucs": [0.6963474560710028, 0.6887189458315031, 0.7031424816405925, 0.7074500589676237, 0.7218989907547304, 0.6802936837876186, 0.6947644728222214, 0.6934650020806297, 0.7066434928367014, 0.32171499475504894, 0.2532565658114788, 0.15835001904045587, 0.2266551046960068, 0.2031087321667363, 0.4194315171759021, 0.3313853230587721, 0.2793490262779532, 0.20419978198466016, 0.09773166918516685, 0.10346625345072591, 0.10990824166274415, 0.09706366819515877, 0.1317612982364912, 0.13650341220616957, 0.10179883910652898, 0.09853067709567676, 0.12453272135706428, 0.11436630361361244, 0.10857656129360749, 0.11671352283845338, 0.09812337881257993, 0.10314314417193526, 0.0920414030610911, 0.11938260279243129, 0.10351983111906915, 0.09827837321222654, 0.9824753441892025, 0.9846545323059516, 0.9856400220016353, 0.9802195932046495, 0.9830488024543529, 0.9839818290887572, 0.9860685713909118, 0.9853590618463303, 0.9852856221088144, 0.32672573596900467, 0.35637293298167483, 0.3518066857693325, 0.40541613302173507, 0.3139099060904512, 0.34142500434301426, 0.2853932065463022, 0.3115300614221106, 0.37658653393163377, 0.705630341534145, 0.5253862513846438, 0.691449224666749, 0.6477560272345624, 0.5688651375166539, 0.18561473933144013, 0.23039376574532067, 0.5402805468055525, 0.6460137693206345, 0.11678757804205941, 0.31237392495335803, 0.08570829079516518, 0.29445295564374996, 0.3747096754510876, 0.3356146908635981, 0.3407875848249694, 0.28220114641230876, 0.3646197202458219, 0.36443755718916404, 0.12572067614298088, 0.11557665576554466, 0.18627953645508766, 0.175073226639043, 0.35232471035874824, 0.2685660218230218, 0.12155191173055757, 0.2699215369410154, 0.14544616869759375, 9.999999999998899e-05, 0.052958292917447025, 9.999999999998899e-05, 0.0833540873340386, 9.999999999998899e-05, 0.15005834977136123, 0.006313484719259965, 0.29231745031944534, 0.10295583371375383, 0.16662278717587764, 0.3147787667255153, 0.2658573628321498, 0.3156412632644191, 0.1725026185672237, 0.16210860235386848, 0.20288699276409594, 0.09331083842480259, 0.031847723828220986, 0.022463191221435808, 0.16729479889319698, 0.07456722256675152, 0.056270456502751975, 0.18394352674955383, 0.12753450677076894, 0.17385648174230317, 0.13962181731062084, 0.1519205754808196, 0.25987150210147614, 0.08222511832374024, 0.15044181398899692, 0.1837423714419706, 0.25089055911618685, 0.22925754164153944, 0.09843655249253713, 0.1677379016999504, 0.5559917655941414, 0.5634233168353782, 0.5857088147757538, 0.5783957928757664, 0.5210391881597398, 0.5687432576686545, 0.5849422003926847, 0.4826263509940848, 0.5484448430956462, 0.10309987848942181, 0.07107264201478669, 0.14206385785961606, 0.07603565948867164, 0.0926436422147825, 0.13324326095373074, 0.09782410230263305, 0.11025181846959531, 0.10777548124229175, 0.18152025868039678, 0.16669364267563036, 0.16626766277609895, 0.3035061566569105, 0.23388472316167985, 0.2259557450654851, 0.2121294843481243, 0.1867649642910667, 0.2471183752106504, 0.2391351609273098, 0.23477667806148617, 0.3398521893066222, 0.2882790226709411, 0.31920152105349775, 0.34657647232824895, 0.32013958649087215, 0.3356419214906744, 0.3383576178047829, 0.24672829790590167, 0.2669668700439308, 0.2521138220332677, 0.21208604611448767, 0.22043749829390713, 0.23094867759368864, 0.19188277478458304, 0.28363739483670714, 0.19911343531504333, 0.21678215413837942, 0.2273593364649783, 0.20965323966843075, 0.19360652922036636, 0.1963598733124452, 0.21459102950618192, 0.2126133161377225, 0.2088521786876587, 0.17410078460404677, 0.1969637865917785, 0.17803802100270427, 0.20001669168911862, 0.18002524635396566, 0.20589228896252554, 0.18151833132397077, 0.20846386312022758, 0.18827430542312318, 0.1840382412840984, 0.16293362936365652, 0.18437662721895676, 0.7740099721577862, 0.7736758703417502, 0.1999769026067435, 0.16704803635251175, 0.13997627162706627, 0.3869215509185162, 0.7525886087103623, 0.7608565322701141, 0.206981544611466, 0.19929421094511768, 0.6921508087504915, 0.7042305060121563, 0.15372775277483652, 0.2052004811389101, 0.12585014481311774, 0.21145514388371078, 0.17900431146526175, 0.21802859135675567, 0.19046335316965535, 0.18349656614714716, 0.18114567663129477, 0.19148732173055238, 0.18182073319641956, 0.19908215702731957, 0.18056230014708674, 0.07509663360020569, 0.09570352047074482, 0.07959793449318275, 0.11797576383774189, 0.0862760265351632, 0.09806608044157206, 0.0714306548522714, 0.09583643744871928, 0.081335635488331]}, "mutation_prompt": null}
{"id": "7cfbd3f9-5e65-4e09-8859-b09d769ba18f", "solution": "import numpy as np\n\nclass EnhancedDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Adjusted inertia weight for balance\n        self.c1 = 1.8  # Adjusted cognitive component\n        self.c2 = 2.2  # Adjusted social component\n        self.F = 0.9  # Modified differential weight\n        self.CR = 0.85  # Modified crossover rate\n        self.adapt_factor = 0.97  # Adaptive factor for inertia weight\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < (self.CR * (1 - self.current_eval / self.budget))\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            # Random reinitialization to maintain diversity\n            if np.random.rand() < 0.05:\n                for j in range(self.pop_size):\n                    if self.current_eval >= self.budget:\n                        break\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "EnhancedDEPSOHybridOptimizer", "description": "Enhanced DEPSO hybrid optimizer integrating random reinitialization and dynamic crossover for improved exploration.", "configspace": "", "generation": 6, "fitness": 0.33535243353746264, "feedback": "The algorithm EnhancedDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.25.", "error": "", "parent_id": "c132f5d8-e9f3-4762-8e87-ad34593e862c", "metadata": {"aucs": [0.7731758999446245, 0.7779086493067231, 0.7625426699053257, 0.7838744992882203, 0.7642315167790332, 0.752434166650046, 0.7929650002803694, 0.7904451538696364, 0.7508156160718747, 0.5612816924952753, 0.5237563333516899, 0.5221127160220282, 0.5360232570600133, 0.551254995475942, 0.588719883282143, 0.552144412975165, 0.580138458584049, 0.5845043948980237, 0.13539167920888284, 0.11039456650415647, 0.1307849011368789, 0.12507943726038917, 0.1324108761178664, 0.16931024076472279, 0.13931803305989576, 0.10535481200839458, 0.14209367012889618, 0.10273447157166249, 0.10758281730827746, 0.10990645476629235, 0.1209836579090906, 0.11774961350750368, 0.10265701616315892, 0.14728042935765806, 0.11494294089505508, 0.10889703826631925, 0.9894950980356192, 0.9878471902724864, 0.987383551714185, 0.9900576504213402, 0.9882809813122714, 0.9710742140269856, 0.98140353854327, 0.9898708004425523, 0.9872021093371414, 0.4475986505751903, 0.4846517280428627, 0.45659307099584157, 0.4408180334487295, 0.3941398653112659, 0.4046276525945084, 0.4280677822428752, 0.08806903907936325, 0.4470714583118741, 0.7547702422799074, 0.30009002324871836, 0.7234771225528907, 0.26480320531806434, 0.772867600762159, 0.1595290805437668, 0.7857228115398496, 0.8075755232242745, 0.2286863781847992, 0.4273859753494026, 0.35201857159747985, 0.5914755049984926, 0.5212748756348993, 0.5612066853902933, 0.4788071650595923, 0.5333448269570162, 0.4917833391774552, 0.44233565717477796, 0.44149042262889804, 0.47245708832708677, 0.1136196166056086, 0.521340504542776, 0.43361209302318804, 0.5093752010725155, 0.31274614722161487, 0.12143955671344853, 0.33169659811225916, 9.999999999998899e-05, 0.06254760170820517, 0.1672190181626384, 0.02326936930313872, 0.14216778368904837, 0.05067677900587608, 0.4149459012795135, 0.008038469948047133, 0.003424418749027436, 0.22707628989205286, 0.32173808893894706, 0.12555186758190706, 0.3126080322691486, 0.17407966266988728, 0.1320515828762593, 0.15040310411709867, 0.31328885958124086, 0.5231351545408671, 0.12027012805296944, 0.05497949574485539, 0.10640265790613301, 0.2113694050455217, 0.09024322908865212, 0.21275866366750884, 0.17600928024746332, 0.07297276745050019, 0.10297684424164777, 0.22968223746128047, 0.11755954996602613, 0.22862574193767826, 0.2706064628064727, 0.21662701951510277, 0.1508310379909632, 0.1738599720589462, 0.19771490671513736, 0.07806497895739373, 0.6674528838566569, 0.5983537700255948, 0.6493632846766094, 0.6483593588781611, 0.6811258748951285, 0.6078454957744566, 0.62163251565665, 0.689954595750574, 0.677568777549487, 0.08835623027312245, 0.10807045119849823, 0.13431110860316298, 0.11334671637371552, 0.08656523392229154, 0.10387130899843722, 0.10091730398556065, 0.13905385110762913, 0.07609883832398412, 0.18550215578512164, 0.3506413573501421, 0.2503922541391095, 0.1857299743320221, 0.43152365983501706, 0.3788840506935628, 0.17518014628783496, 0.20213482781876368, 0.19838328853551723, 0.39640376533593913, 0.23818900874699578, 0.45588729470653266, 0.3667731688991057, 0.2639830267450598, 0.3928202875135005, 0.37862073219097925, 0.2945941197254539, 0.3667064804914252, 0.2643274752156607, 0.22216779028478173, 0.22234851622265583, 0.28115184254965575, 0.1536614589716302, 0.27268502995194277, 0.25151172916198816, 0.21842895514673322, 0.2252374232056501, 0.22801730374714524, 0.17543639454644488, 0.18836784929995543, 0.20443583521792796, 0.19466008893731201, 0.19577610067821138, 0.19980949873186193, 0.19633725781909683, 0.20073125618685417, 0.19306199999075613, 0.20814277786882474, 0.20040348721025758, 0.654219759651681, 0.22571259448753989, 0.21772646175882726, 0.19143032051359832, 0.18420086311792383, 0.5741348752684852, 0.8571090922088997, 0.17611765824048276, 0.14988733487555295, 0.15780860543023978, 0.1990600951393492, 0.1967050494311786, 0.3633806797657396, 0.19115521351214249, 0.819499361246934, 0.8402176821167237, 0.21165146906141885, 0.2032219719550692, 0.1988987129014973, 0.165796181353439, 0.16624053687942142, 0.21052741904210082, 0.11261178684888595, 0.7609005837065843, 0.19000944998787506, 0.20413143804460532, 0.20533824777780296, 0.19638712851232298, 0.22529165308373333, 0.19963934452687504, 0.19398676746978816, 0.18060379703330387, 0.17501478977394458, 0.08166546067816949, 0.09530866219449452, 0.08131142575011185, 0.09162701328502065, 0.08738420456304652, 0.08456874534843539, 0.0766031719108412, 0.08802438233909904, 0.09545581607955522]}, "mutation_prompt": null}
{"id": "3ff76a7f-8650-4bca-8336-62b9a5279b39", "solution": "import numpy as np\n\nclass ImprovedDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 8 * dim  # Adjusted population size\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.7  # Adjusted inertia weight for better exploration\n        self.c1 = 1.5  # Adjusted cognitive component\n        self.c2 = 2.5  # Adjusted social component\n        self.F = 0.9  # Adjusted differential weight\n        self.CR = 0.8  # Adjusted crossover probability\n        self.adapt_factor = 0.95  # Modified adaptive factor for more gradual change\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Adapt inertia weight dynamically\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            # Introduce competitive exclusion to enhance diversity\n            if np.random.rand() < 0.15:  # Increased probability of applying this mechanism\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "ImprovedDEPSOHybridOptimizer", "description": "An enhanced DEPSO hybrid optimizer with dynamic parameter adaptation and competitive exclusion for improved global exploration and convergence.", "configspace": "", "generation": 7, "fitness": 0.3174451245391237, "feedback": "The algorithm ImprovedDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.25.", "error": "", "parent_id": "c132f5d8-e9f3-4762-8e87-ad34593e862c", "metadata": {"aucs": [0.7922089490503506, 0.764788735577137, 0.7920694473506913, 0.8158275414093257, 0.7946752588908035, 0.8293892706960335, 0.8026551870011089, 0.7732508049706746, 0.79699159256211, 0.5379454795529985, 0.4861968585310168, 0.49454720577101496, 0.5169228993181632, 0.516349353133132, 0.4933298302315293, 0.4880744496356779, 0.5908143579918006, 0.44819394042218585, 0.14064152104731187, 0.13962497925561712, 0.12368736271842973, 0.15153645679138938, 0.1180062085836826, 0.15296630980319315, 0.1478731668476323, 0.11209345850951269, 0.11736514197024372, 0.10929345552170688, 0.10432050226559497, 0.07412016915340935, 0.08012481656653414, 0.08683572347870672, 0.09526672085263121, 0.09122769863920277, 0.09334682269223671, 0.10974118787330212, 0.9910002404103441, 0.9895887917526374, 0.9917786159175757, 0.9914436275047585, 0.9910273075511666, 0.9830782353347327, 0.9912812642981529, 0.9907933318935134, 0.9904812331502144, 0.43503584042475474, 0.33899368241567673, 0.4485367270075067, 0.37965759301633195, 0.32671093690622977, 0.43336470057529075, 0.4773465956528047, 0.43932603193808917, 0.12328008868441864, 0.7669601575037531, 0.621869788823553, 0.21802017121073014, 0.2913714958893324, 0.21226554528925057, 0.11433580905401308, 0.4211360156579571, 0.7237667170576685, 0.7804272394002205, 0.31938678478421556, 0.12087575324268107, 0.11127694621728679, 0.2951765751494482, 0.12451562920331638, 0.3789034947282718, 0.6020597937878065, 0.30805555359905723, 0.4501356911495372, 0.12261140174644047, 0.02197207318210692, 0.45185579784108576, 0.46359626427698664, 0.4421727451230376, 0.320909778477223, 0.26332475619055173, 0.28976112131224796, 0.28866825092626625, 9.999999999998899e-05, 0.053945071701218095, 0.08223310938042483, 0.04917485444687375, 0.0619283418776615, 9.999999999998899e-05, 0.4765749881090853, 0.23066869670378232, 0.1348467762476936, 0.42187718720638845, 0.2794563814851575, 0.2246889497655794, 0.1874355262281313, 0.1929040905834125, 0.10182965214708783, 0.21207080939416667, 0.33418437501960574, 0.19488415787802194, 0.17946778463494362, 0.250250640279704, 0.08124599808081145, 0.18552799151721378, 0.10086381380970266, 0.06726314366247754, 0.26665159091052193, 0.14555212810878837, 0.11568966544949943, 0.24443568497702606, 0.13201955048896075, 0.07982935921736212, 0.2396938807167076, 0.34643663964353233, 0.22990617615424014, 0.11924383989357645, 0.052729862717360576, 0.11203368235686428, 0.645008571012057, 0.5676519547571012, 0.7292289523240503, 0.6833981126887871, 0.58911086376019, 0.5363325515190274, 0.6349441308079184, 0.6083606237537273, 0.5656187000621338, 0.08219101979215282, 0.1217207997430978, 0.07920445308902768, 0.14790031412094307, 0.07415469492485904, 0.12435448811079497, 0.11734843293394892, 0.12790230918633683, 0.13869349725418378, 0.20060506647622078, 0.17539147919814535, 0.2095910802489871, 0.15997870565572214, 0.29651592436923235, 0.19102396876822447, 0.18582772998419672, 0.2568122321639593, 0.22751032028886842, 0.32574559164682304, 0.2721823231994921, 0.32204087131415626, 0.3798883490864019, 0.27256095124564217, 0.2805096842548124, 0.20318622051989232, 0.31906754021045935, 0.29565523042950637, 0.22192989864534163, 0.21774123550383095, 0.24644925293737052, 0.243489421523994, 0.15897668604077642, 0.29362519956554534, 0.2508806471781433, 0.34641828743347547, 0.2789452692300268, 0.280621992494543, 0.19833843117528083, 0.1845345157500542, 0.20371035949638971, 0.2060162296182605, 0.2020594776161838, 0.2250859973664575, 0.18472797277423902, 0.20973576830718654, 0.17813864365762389, 0.20286827687397124, 0.21536384961387234, 0.20461230956245613, 0.20118783312040078, 0.18138436949456715, 0.18785360836959142, 0.2009600123552524, 0.21977537706767225, 0.1704916449534407, 0.15852089678054926, 0.15349534999856007, 0.8810292971605708, 0.19842218337307982, 0.18603542830413367, 0.15738889292653602, 0.8107131039272041, 0.8442162813083943, 0.8487977391614677, 0.21328916666620135, 0.166928590533721, 0.1558416672520918, 0.7491993684067741, 0.14847837282807064, 0.16935870355699212, 0.21231038448062378, 0.7675408018251532, 0.18084626363601264, 0.20779035448659533, 0.18910214743523612, 0.20394952759872642, 0.20439159266695317, 0.21529333171261733, 0.2205602229145328, 0.21511777257184994, 0.19194625111039465, 0.09594459153787172, 0.09278290006728673, 0.09375241893656605, 0.0968947809289763, 0.08279714999610477, 0.08864604479628346, 0.11300050474885481, 0.10631512356161343, 0.07612592590918343]}, "mutation_prompt": null}
{"id": "e3714b23-20c9-4cfe-9563-9a31d2045c95", "solution": "import numpy as np\n\nclass EnhancedDEPSOOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 12 * dim  # Slightly increased population size for better search space coverage\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.7  # Increased inertia weight for enhanced exploration\n        self.c1 = 1.5  # Adjusted cognitive coefficient\n        self.c2 = 2.5  # Adjusted social coefficient\n        self.F = 0.85  # Adjusted differential weight\n        self.CR = 0.95  # Increased crossover rate for more variation\n        self.adapt_factor = np.random.uniform(0.95, 0.99)  # Randomized adaptive factor\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if np.random.rand() < 0.15:  # Increased probability for stochastic competition\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "EnhancedDEPSOOptimizer", "description": "DEPSO optimizer with enhanced stochastic competition and adaptive exploration for improved global search.", "configspace": "", "generation": 8, "fitness": 0.2827875679709007, "feedback": "The algorithm EnhancedDEPSOOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.23.", "error": "", "parent_id": "c132f5d8-e9f3-4762-8e87-ad34593e862c", "metadata": {"aucs": [0.6763504572444041, 0.6599440727460834, 0.6644750279466035, 0.6854991010551443, 0.7021920015592426, 0.6844245900837252, 0.6561868660041072, 0.7261259285846342, 0.660965478440829, 0.3064902669690872, 0.273737919511721, 0.28716057114588434, 0.38234448430462364, 0.2694379117552195, 0.20277456575695896, 0.23794126817786332, 0.4209867980659785, 0.014777901473896238, 0.09972251606275617, 0.11813315252611734, 0.08783397271030502, 0.09481014260811249, 0.10927177212295847, 0.11661656448328117, 0.15871552267793887, 0.141187102187474, 0.09800276007584618, 0.10454249669329185, 0.09459180220955699, 0.08014473413521706, 0.08176936499994858, 0.0995536439931175, 0.10449054201410057, 0.11267529845211643, 0.0954671408340586, 0.08363156270628203, 0.9870470351676374, 0.9884687199167586, 0.9876456951281465, 0.987240758498004, 0.9871575237912757, 0.9874676556181325, 0.9877013689783503, 0.988043505714091, 0.987500410896535, 0.3381952885061371, 0.33547402724161024, 0.3562681226823792, 0.37153818361709956, 0.26577298289407736, 0.16835669229981665, 0.356070640145947, 0.20355659607075438, 0.2009299209051948, 0.659628853548854, 0.7141262829656705, 0.40249276526765465, 0.5373843621938448, 0.25386673061275133, 0.22896282568125448, 0.6259784264434303, 0.22720959027484544, 0.6427905616656617, 0.10768644231256763, 0.12188783560522609, 0.4568631819214486, 0.38844462479543174, 0.12382475876566446, 0.12292981515711565, 0.26981666165543317, 0.30338997491720376, 0.381186720401411, 0.3411392176219613, 0.41121915086291605, 0.352598129449084, 0.14968317802386277, 0.12292693972231405, 0.262596528843944, 0.2352719856205594, 0.4120104411993064, 0.30580931206462225, 0.055217175462528245, 0.05441992029537546, 0.04588093518699132, 0.06885007007231869, 0.037789344791403945, 0.001979368215911048, 0.0018579072527018514, 0.02436501599446983, 0.16994298418481724, 0.2203591573622582, 0.34557623059850817, 0.2522585039049907, 0.09627274520033902, 0.21667903220713347, 0.20749575307182144, 0.26924293874852534, 0.354658664731616, 0.21480778051717175, 0.03838591811086478, 0.0790800579805736, 0.2590586908125718, 0.16084442107649133, 0.13314101343298335, 0.09908570590604848, 0.10259872034201578, 9.999999999998899e-05, 0.04886220989268619, 0.14391145660349214, 0.11597025306588715, 0.22734288549413229, 0.22446357380321713, 0.2656991287859656, 0.18059772656494677, 0.14686399406725836, 0.06617562166038604, 0.05475761440561311, 0.56452882948931, 0.5359716197539667, 0.5566024939344845, 0.5370072443836841, 0.5407088508949716, 0.5812883673557387, 0.5018942277171929, 0.5417241001415734, 0.5119736395998027, 0.13406439850736496, 0.10595061995300914, 0.11402637583681385, 0.07448573275984982, 0.1043298966272923, 0.1130622743850207, 0.09114968333992923, 0.13175692951941198, 0.10955541421663617, 0.17405173376792793, 0.1759688129456587, 0.17643236005417617, 0.41799576292407614, 0.24963610588829632, 0.26683548344694163, 0.21313028441614668, 0.13768334792612136, 0.19675006773757775, 0.3429079158317596, 0.3299363399207309, 0.32384932809545763, 0.30865229790302773, 0.310927518195517, 0.29656179100282465, 0.26125652461416293, 0.28017209952250743, 0.32807126994548086, 0.16217010086075312, 0.24762525599779117, 0.22409031561496273, 0.2219720376289872, 0.290044816119552, 0.1495365697937412, 0.25492798318581533, 0.1827168433188221, 0.2570838095866217, 0.21784461524185106, 0.22534983619785465, 0.16933934539963924, 0.18883927359775043, 0.2013120443584676, 0.2137875521941861, 0.18218552291089418, 0.19737061813920476, 0.202330797452282, 0.1804177835325418, 0.17490407050357137, 0.20254400450727328, 0.19550986635187262, 0.17462487640503987, 0.20143981529809007, 0.19632558253395604, 0.20439090846469876, 0.22372279351077518, 0.8030841903795911, 0.8095112844805158, 0.1672603602666135, 0.14524362691159298, 0.814140633525329, 0.1624967119096684, 0.170708175396745, 0.1761379063894687, 0.18921521122688734, 0.7385608431163867, 0.2098150634306547, 0.20236066554019239, 0.14896852597052568, 0.16884571805765025, 0.16525315995084988, 0.7435697127982062, 0.1633669000519401, 0.20996511127944806, 0.22470975665487336, 0.19317902510924756, 0.19127649815652048, 0.20946222836577133, 0.1969969572059166, 0.17829920437041824, 0.20785852364709312, 0.22272374242466864, 0.2024308754238544, 0.08050643599024865, 0.11552568368802951, 0.09196278649646827, 0.10559397661615111, 0.07630146015236883, 0.1111761428663256, 0.10237576936404535, 0.09594495103236822, 0.08025183441799055]}, "mutation_prompt": null}
{"id": "bef9631a-fe9d-4ff2-a10b-5a692b1ec780", "solution": "import numpy as np\n\nclass AdaptiveQuantumDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 12 * dim  # Adjusted population size for better balance\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Slightly increased inertia weight\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.F = 0.7  # Adjusted differential weight factor\n        self.CR = 0.85  # Adjusted crossover rate\n        self.adapt_factor = 0.99  # Slightly less adaptive to retain momentum\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Adapt inertia weight\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            # Introduce quantum behavior for enhanced exploration\n            if np.random.rand() < 0.15:\n                for j in range(self.pop_size):\n                    quantum_position = global_best + np.random.normal(0, 0.1, self.dim)\n                    quantum_position = np.clip(quantum_position, self.bounds[0], self.bounds[1])\n                    quantum_value = func(quantum_position)\n                    self.current_eval += 1\n                    if quantum_value < personal_best_values[j]:\n                        personal_best[j] = quantum_position\n                        personal_best_values[j] = quantum_value\n                        if quantum_value < global_best_value:\n                            global_best = quantum_position\n                            global_best_value = quantum_value\n\n        return global_best", "name": "AdaptiveQuantumDEPSOHybridOptimizer", "description": "Adaptive Quantum-Inspired DEPSO Hybrid Optimizer using Quantum Behavior and Adaptive Learning for Enhanced Exploration.", "configspace": "", "generation": 9, "fitness": 0.27637351539177346, "feedback": "The algorithm AdaptiveQuantumDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.23.", "error": "", "parent_id": "c132f5d8-e9f3-4762-8e87-ad34593e862c", "metadata": {"aucs": [0.6613147077793204, 0.6274814435095765, 0.6713687456412142, 0.6593463622910084, 0.6352515566092144, 0.6196405520821225, 0.638620537022785, 0.6762841172559693, 0.680448531406635, 0.22460636755841223, 0.20601501961738544, 0.16360909633334486, 0.2336857300930426, 0.21945491376303927, 0.27520382510090613, 0.21375708317145525, 0.20092225506228645, 0.19447816227086778, 0.09727253116813095, 0.10930229646060763, 0.10607177136918067, 0.10294600754782768, 0.12151341314829955, 0.07203567368970831, 0.06867305109461996, 0.2245572502230253, 0.10790893608437713, 0.06513614706435733, 0.1000237690003416, 0.07920638196023466, 0.08213596355949904, 0.08106437842392367, 0.14307435387553413, 0.1437601184794428, 0.0999520244508163, 0.09600745597011062, 0.986738991841856, 0.9872192769668054, 0.9868805650810375, 0.9874868569521056, 0.9858865334426097, 0.9862610885317714, 0.9847617021943462, 0.9880214683927551, 0.9882550366521431, 0.39341233499938333, 0.4189045330871113, 0.3595513282196455, 0.47173071372909003, 0.37923567562969895, 0.4077157159800384, 0.3927530632823234, 0.45839052256548707, 0.3013192688094728, 0.6668425798486476, 0.7044864958502665, 0.16728691028339582, 0.2311470220857671, 0.19479237669974359, 0.27751382805947633, 0.1724369949209419, 0.2242448209511504, 0.6224291711641711, 0.2981875831304197, 0.42953332141632194, 0.12605529034757113, 0.1246847585197034, 0.3514301288831778, 0.19509496596281906, 0.40297236244198364, 0.30680682992469366, 0.129351200627554, 0.3816384754026704, 0.3564009589557475, 0.226550155203612, 0.13149169248818504, 0.12907022998414908, 0.30142340121010325, 0.30225404590962246, 0.2852326567763921, 0.1295862470989334, 0.22255258360342034, 0.03432673481876103, 0.18796417915140162, 0.031192903977344977, 0.0316265539027909, 0.1383998010419042, 0.16600811998170262, 0.1230463235158793, 0.03878807419225794, 0.0686455034046034, 0.21500480331522598, 0.26457766923793424, 0.1401746566887324, 0.19563103049919606, 0.07068604175530013, 0.2285297985701712, 0.1778487593849939, 0.11939548464212402, 0.035440312137801966, 0.060779346505388965, 0.051824915431976426, 0.09868328171426766, 0.1326238191216338, 0.06952123185023706, 0.07639704025158922, 0.12677190056634702, 0.08491241779939251, 0.17928646431703743, 0.1809319190282146, 0.15694531393762734, 0.20935248182977517, 0.19073511970141932, 0.20328496041402344, 0.053498983293508884, 0.10428273950728384, 0.08519470368881632, 0.6112687786384796, 0.5665674749183267, 0.5723717939270023, 0.5882355854841809, 0.4970313532394921, 0.5479703505275464, 0.5800223661523415, 0.5063392177298839, 0.5639012953915079, 0.06740312977531626, 0.07640629066354288, 0.10887529568818444, 0.09371546718600798, 0.07105096051991167, 0.1038293458625662, 0.1434412016816068, 0.09032407273860699, 0.0807912682913986, 0.28727395605548667, 0.16139425901602067, 0.20669902597538337, 0.21255559967154336, 0.2629031729351091, 0.49588134891544233, 0.3009349718220764, 0.19019066435843202, 0.20635734921483662, 0.3521820074929516, 0.25206506170357734, 0.26675450788892363, 0.28948424145089435, 0.2398001374201173, 0.353524603599933, 0.340978353735487, 0.2977754062747051, 0.26213603772453065, 0.2183285714656089, 0.17748472715648989, 0.32649025628258455, 0.141557308913837, 0.23559207762615753, 0.2474393502833001, 0.2502916208920801, 0.24542482093175044, 0.26987321282548304, 0.19419111877052087, 0.21045372314219313, 0.2105430503278225, 0.23235930128865523, 0.19125027931053518, 0.2329151000130888, 0.20942119277103843, 0.2029713548321297, 0.2716031758266545, 0.21796797314998506, 0.3334347342463071, 0.19089481774074502, 0.18953475411778886, 0.1904758532718448, 0.18954320032048877, 0.1932924160985795, 0.17611256814035714, 0.1865684401845561, 0.1359387068179111, 0.1870019573774181, 0.13447453655966424, 0.8502258975490062, 0.19357147074122505, 0.19781878079105308, 0.1844219077939595, 0.16312345843912734, 0.7800844310245112, 0.7779410916761528, 0.2109425571259711, 0.6719637131415997, 0.21010834664177114, 0.16640152707385225, 0.20898703322857215, 0.20998158775195042, 0.21236391226353013, 0.20973573070515106, 0.20487484799308386, 0.21669115861067023, 0.20460917732678552, 0.1851047269598033, 0.1907101351758138, 0.18295475451803989, 0.20965860333168862, 0.19769641097543267, 0.20217686763872955, 0.10116461785090758, 0.08092561526706288, 0.12178104490523112, 0.08480215672980773, 0.07730860788714922, 0.08268064733591562, 0.08090596750672463, 0.09444617824367219, 0.09818452263857746]}, "mutation_prompt": null}
{"id": "b105375f-fc48-4d81-8748-c117951b8a48", "solution": "import numpy as np\n\nclass EnhancedDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.7  # Increased inertia weight for better exploration\n        self.c1 = 1.8  # Adjusted cognitive component\n        self.c2 = 2.2  # Adjusted social component\n        self.F = 0.85  # Adjusted differential weight\n        self.CR = 0.8  # Adjusted crossover probability\n        self.elite_prob = 0.1  # Probability to perform elitism replacement\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= 0.99  # Gradual adaptation of inertia weight\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            # Implement probabilistic elitism for diversity retention\n            if np.random.rand() < self.elite_prob:\n                random_index = np.random.randint(self.pop_size)\n                challenger_value = func(global_best)\n                self.current_eval += 1\n                if challenger_value < personal_best_values[random_index]:\n                    personal_best[random_index] = global_best\n                    personal_best_values[random_index] = challenger_value\n\n        return global_best", "name": "EnhancedDEPSOHybridOptimizer", "description": "An enhanced DEPSO variant using dynamic parameter adaptation and probabilistic elitism to improve exploration and exploitation balance.", "configspace": "", "generation": 10, "fitness": 0.26522180104477955, "feedback": "The algorithm EnhancedDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.22.", "error": "", "parent_id": "c132f5d8-e9f3-4762-8e87-ad34593e862c", "metadata": {"aucs": [0.5820685588396175, 0.6344893532930111, 0.6255389193464758, 0.6264590245662716, 0.5882900981010777, 0.6228964326523398, 0.5717272983910044, 0.5753757085168864, 0.6541010254392708, 0.23655361512423922, 0.22908968909582395, 0.09567699663966034, 0.043167454160992436, 0.12969580205218478, 0.1624792641507301, 0.22203615854988012, 0.27103743717267503, 0.274484398905087, 0.0924248372986336, 0.12018154496157096, 0.06321271249477378, 0.12205973656541169, 0.12179974444957331, 0.10354797599008014, 0.08745174927536914, 0.1620872834551912, 0.10870535706020223, 0.10485007058951212, 0.07520711733459828, 0.08106899250529165, 0.11926746107078556, 0.09660612976779048, 0.09470877802222677, 0.09883773069578494, 0.13040703754969696, 0.09737682314679352, 0.9894758889988051, 0.9878506603676782, 0.9878823139909306, 0.9900526625522842, 0.9805929866495748, 0.9713107922920652, 0.9784912642906406, 0.9815803785176276, 0.9872015155958728, 0.320820172838858, 0.34944643848307777, 0.35342909873185147, 0.4024540903340599, 0.20744899617555235, 0.3393480691691607, 0.2653021617456718, 0.36060685202257603, 0.3927802293267958, 0.701249697851783, 0.3110013061852226, 0.5918856591601303, 0.2545747658049179, 0.5204162126583467, 0.1977569783642743, 0.5770336582816709, 0.2187620167411949, 0.6294556145278405, 0.20025740720560736, 0.1388082983045793, 0.30720788200864, 0.11313938277255275, 0.11659806825702002, 0.12840674662877172, 0.24246189557149056, 0.24965983122935498, 0.31124981329690804, 0.26765344715254424, 0.1612670568688156, 0.12769965093657154, 0.3364504136994969, 0.1073988981346864, 0.38443719691343636, 0.3917875332041406, 0.26242584939137914, 0.14749921185085402, 0.048180037239208495, 0.047486372593048665, 9.999999999998899e-05, 0.03451523389756983, 0.033082630411208847, 0.06748805098793487, 0.15885562335165837, 0.06152426666587085, 0.0029324875259991723, 0.0952666304342007, 0.035373872353742786, 0.3629771116379188, 0.2606361284855119, 0.0954162813998981, 0.36760927237816377, 0.01749358541806545, 0.15281689981076962, 0.0468117886201147, 0.06576219821913187, 0.06589901334329984, 0.16371875637565458, 0.06985359605134234, 0.0638207107104839, 0.04527224602005042, 0.060059764533835214, 0.065555589924856, 0.1028325384176243, 0.15320641158122705, 0.12066913482714337, 0.13844009858219875, 0.1540266286992481, 0.11340734718395284, 0.2205829719268988, 0.04193918075728764, 0.16982614629773085, 0.06853515641981556, 0.46316254438497007, 0.4355741462829156, 0.46163055479978143, 0.4734254020967389, 0.5129558194558285, 0.5236459232308679, 0.4654928675174491, 0.49873082063391216, 0.5229008780808135, 0.08462425189660971, 0.11877531672374408, 0.15615824133466316, 0.1294613848731493, 0.09257962220723148, 0.10207256642950102, 0.10491741917945596, 0.09550732980789256, 0.13458360218937593, 0.2547841110344461, 0.22230702858518825, 0.17004977572743607, 0.2639287119272695, 0.3445651033631463, 0.18349847179017076, 0.22151349419881894, 0.14684626521918687, 0.17552031397983825, 0.2797361596693204, 0.26601607746630684, 0.35639253939172855, 0.3101030942420402, 0.2767966631596339, 0.31667969021356823, 0.2581213521982181, 0.3660470052233168, 0.27660155245860296, 0.207925125679426, 0.22291883566881, 0.28679214559894217, 0.23178228722474792, 0.2196245532804192, 0.19467026250429353, 0.2591051159100729, 0.2611990380271937, 0.23240017292619264, 0.23806242118157261, 0.19427506166091923, 0.20303932832559413, 0.1995105644946782, 0.1782779485636693, 0.217024178268302, 0.2209600300428286, 0.2219082143596639, 0.19862316062315766, 0.19915871230080606, 0.1858938557065023, 0.19307248870752658, 0.19337701780722216, 0.1850714608478804, 0.21237882491397908, 0.19791729444255268, 0.36125670892000195, 0.2004602410293035, 0.7684520536483816, 0.19132199578420994, 0.15131889563933543, 0.7723666382247865, 0.195443960548621, 0.6384003601858506, 0.13964144389639965, 0.15867767841628044, 0.717417919994888, 0.5845227065137575, 0.20924050117674764, 0.12258265620871767, 0.19813382490184117, 0.16845165670223483, 0.6238729283684146, 0.20754447891772554, 0.20824535617571382, 0.1266583279425214, 0.1803509842667148, 0.2119082919115325, 0.18892394536682, 0.1881303618560185, 0.21594235459472588, 0.1768145807552508, 0.18752888055015426, 0.19655809067093644, 0.19166931223677808, 0.08005122677914311, 0.10493632816427378, 0.06883682872989194, 0.08787753938484133, 0.0947578148911723, 0.07279352051078114, 0.08698294560634079, 0.07855131871230803, 0.07104902205037777]}, "mutation_prompt": null}
{"id": "256b7413-a219-470e-8992-2e41d9a09f70", "solution": "import numpy as np\n\nclass RefinedDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Increased inertia weight to balance exploration\n        self.c1 = 1.5  # Adjusted cognitive coefficient\n        self.c2 = 1.5  # Adjusted social coefficient\n        self.F = 0.9  # Enhanced mutation factor for diversity\n        self.CR = 0.8  # Adjusted crossover rate\n        self.adapt_factor = 0.95  # Modified adaptive factor for dynamic inertia\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Decay inertia weight more gradually\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            # Introduce enhanced stochastic competitive selection\n            if np.random.rand() < 0.15:  # Increase probability for diversity\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedDEPSOHybridOptimizer", "description": "A refined DEPSO hybrid optimizer with enhanced diversity control through dynamic inertia and stochastic competitive strategies.", "configspace": "", "generation": 11, "fitness": 0.3759566762159234, "feedback": "The algorithm RefinedDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38 with standard deviation 0.28.", "error": "", "parent_id": "c132f5d8-e9f3-4762-8e87-ad34593e862c", "metadata": {"aucs": [0.858713595024523, 0.8409358620259693, 0.8452149905769827, 0.8629550439010572, 0.8595217620241868, 0.8345862489677875, 0.8693218635038416, 0.8400244044775258, 0.8584438708119051, 0.6528680585269859, 0.6594068400058957, 0.6420918749580529, 0.6669957101225672, 0.6749104466693737, 0.6603912129416116, 0.6948877136186192, 0.6622603336030686, 0.6558790253534836, 0.1280124262220972, 0.1482902879234087, 0.10127879859732636, 0.10865017239810604, 0.11149839338772849, 0.13476976590614964, 0.08772947492761063, 0.1356653101695432, 0.1341202488902281, 0.11879682477585607, 0.1678531317315035, 0.11755159443206153, 0.0887272106700957, 0.11236094885495385, 0.10099189984387691, 0.10619343158535322, 0.1431384586576664, 0.1082125570325505, 0.9895052168562086, 0.9811874498051236, 0.9857167983436805, 0.9874904423955208, 0.9814991504589394, 0.9716384469144821, 0.9777853434490453, 0.9814937524753434, 0.987221036214561, 0.6919614052362, 0.6522469706468348, 0.6749187335079043, 0.741198669811634, 0.6857659588716092, 0.6339357433110648, 0.6539720329903589, 0.6683161188235439, 0.6716592781773755, 0.22701306550799516, 0.7708442814798782, 0.21243210500947796, 0.20735081002105304, 0.8526548037733587, 0.15969408572792199, 0.23834913056383222, 0.22954128755277903, 0.7945609301385523, 0.6415467712816225, 0.11887564772649917, 0.6546535895481123, 0.4498791301699038, 0.6496998233961115, 0.13035616803287065, 0.6077010449699409, 0.548929173618822, 0.6452942822032667, 0.5014551693139064, 0.6390190549731549, 0.12959130273800168, 0.6371206176216351, 0.6130238681942277, 0.6379448867171742, 0.6935744889981923, 0.13032504264751255, 0.5023023486875032, 0.04463229670720137, 0.03943724836717466, 0.13039210775291377, 0.1349476145139572, 0.2745899843154128, 0.058300991293224746, 0.493175141514239, 0.2227827599180202, 0.01564641042017989, 0.3342367831970203, 0.5682511002211861, 0.39412181988434414, 0.12043235568447563, 0.2350862365875822, 0.28992211234561305, 0.4050442138382905, 0.569070164843483, 0.6061374778596237, 0.06386248580785048, 0.06767258871063764, 0.1639534639665824, 0.24746771235623888, 0.19409968304817793, 0.2728434470736115, 0.16070651585999662, 0.4173795748422504, 0.11043568533678827, 0.24678413565351198, 0.2050887124989096, 0.2882288299340363, 0.3143134636005993, 0.27975104926878636, 0.3152381847516934, 0.22848495889954834, 0.08046466752852843, 0.20660290224399647, 0.6699265685689255, 0.7626833493974212, 0.7446123756240741, 0.7939992809399161, 0.6309149117986566, 0.8104789625768829, 0.6435834690000901, 0.6374839456411512, 0.7450932247208673, 0.10752889403433019, 0.12689220093233744, 0.08206010338142755, 0.09656428413651252, 0.08397941366386186, 0.13946427573856524, 0.09683168230151151, 0.08308888079585774, 0.08799618969769307, 0.4935997714393964, 0.1827574204113679, 0.30320428232032737, 0.20138702511543038, 0.31511279258366776, 0.20479424227967058, 0.17049135576678798, 0.2023842792888637, 0.2879889914789474, 0.29416598441802166, 0.31749330415402877, 0.3540568501933402, 0.3984319888689529, 0.4359301835060807, 0.33557965854531235, 0.31681910471125097, 0.32740073137391257, 0.38958150976981065, 0.3051225889496937, 0.2550942420068384, 0.21680428058265933, 0.32756455575238175, 0.22157523677862456, 0.2681066067756317, 0.39867003404549495, 0.30057667375547537, 0.2860528928506735, 0.22415065355136377, 0.28938408107136737, 0.2410774033038604, 0.2299974489364075, 0.19681468724476148, 0.22310320797226724, 0.20138096295277808, 0.18975396048267212, 0.21484175016126494, 0.20627200358551367, 0.18970778503039842, 0.17747323777336954, 0.19706522448866826, 0.22853473873590335, 0.1951958411249748, 0.788638811276307, 0.18957024363085817, 0.18978127699207614, 0.8611880463390608, 0.17431233532010337, 0.18621470649138716, 0.8864262472778928, 0.19834351153170726, 0.19808041765614293, 0.1412754221624395, 0.1623321086445172, 0.8742837020731409, 0.8807882904654345, 0.211397267693345, 0.16283672290313056, 0.8587833225625744, 0.1683595600332255, 0.16682213211363928, 0.21255369552610937, 0.11062127182895765, 0.12726161202362563, 0.2072860561257095, 0.1927298647984499, 0.20698893575961042, 0.21415319183402415, 0.2093470324657779, 0.19627365191505441, 0.22746998202623558, 0.20701336205171705, 0.1869197145517456, 0.09399869414360651, 0.07174400530276348, 0.09535481205919782, 0.10759967216231558, 0.09853273983823585, 0.09381779210902985, 0.08054817211484788, 0.09478402981530598, 0.07944792926386968]}, "mutation_prompt": null}
{"id": "09129e91-e886-41de-8702-30f07a664cd5", "solution": "import numpy as np\n\nclass AdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.7  # Adjusted inertia weight for enhanced control\n        self.c1 = 1.4  # Slightly reduced cognitive coefficient\n        self.c2 = 1.6  # Slightly increased social coefficient\n        self.F = 0.85  # Lowered mutation factor for stability\n        self.CR = 0.9  # Increased crossover rate for exploration\n        self.adapt_factor = 0.92  # Faster adaptation for inertia\n        self.diversity_prob = 0.12  # Adjusted probability for diversity enhancement\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Decay inertia weight more gradually\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            # Enhanced stochastic competitive selection\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "AdaptiveDEPSOHybridOptimizer", "description": "An adaptive DEPSO hybrid optimizer with inertia adjustment and competitive diversity enhancement for accelerated convergence.", "configspace": "", "generation": 12, "fitness": 0.3774588528882944, "feedback": "The algorithm AdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38 with standard deviation 0.27.", "error": "", "parent_id": "256b7413-a219-470e-8992-2e41d9a09f70", "metadata": {"aucs": [0.8607769996457293, 0.8449503812890312, 0.8386523072088067, 0.8595496684797267, 0.8418343964673148, 0.7949010267777188, 0.8632165725734692, 0.8550777213780507, 0.8566245934115178, 0.662771341683876, 0.7107530886849913, 0.6651486266343741, 0.6549526965091447, 0.650127168668615, 0.661578695015264, 0.7368997058225982, 0.6858754264253263, 0.627899812502392, 0.153421874176508, 0.1521833598133766, 0.11260819149955592, 0.13766978852050038, 0.1097298699785868, 0.1279135939640863, 0.07831403744043486, 0.12357985040004038, 0.08742614145429706, 0.0679456557429019, 0.0997083101212598, 0.09217369174326018, 0.09299940745116875, 0.07788079486944421, 0.07257038797697057, 0.1315129900234473, 0.12899370936820087, 0.07369495328780262, 0.989056500007168, 0.9900874595898923, 0.9817133128146829, 0.9882687949678944, 0.9863814225626617, 0.9715796535929372, 0.9789587623155628, 0.989064515500287, 0.9877857696853414, 0.6143310729154904, 0.6417468840597214, 0.6151191240767292, 0.6806197062374937, 0.7017024662876292, 0.48730202663640665, 0.677861102092864, 0.7080497249754512, 0.6091907622222472, 0.8431867603626594, 0.18840641637859357, 0.21636446334285875, 0.217370054925895, 0.19323561130525568, 0.27223552064843404, 0.23192662967213273, 0.8098981452638456, 0.17709673922297575, 0.6740175243637541, 0.6176464532668646, 0.6298885294034491, 0.11425254518422012, 0.5050414253333733, 0.575601484501391, 0.12878244569055008, 0.6876160036212957, 0.7128949591242983, 0.7077332496324789, 0.6085451184521629, 0.43819909712931615, 0.6035323271812486, 0.6342368986207425, 0.12785977122842962, 0.6378676602396038, 0.6461726932164049, 0.5936310200871691, 0.13180953322708588, 0.2378698003572074, 0.18479569157279707, 0.03955519301054755, 0.24518773636477764, 0.38526875075579137, 0.25400652162309445, 0.15511495486194105, 0.021451895564330137, 0.3494899512563131, 0.4230954859676529, 0.08369474661791321, 0.34189566207149147, 0.237717211243471, 0.11344734967010373, 0.6957733540905434, 0.5862499565499675, 0.42440473025221104, 0.2712076938248753, 0.10085876313831066, 0.14478930701300885, 0.19717820332649383, 0.4032196591231102, 0.38636633252768715, 0.2155187284430118, 0.4263383270314359, 0.07453156930540539, 0.3672210432745878, 0.24803333937636318, 0.24923250255844076, 0.37619340568804727, 0.2886524199492373, 0.3550625051116606, 0.11344018701320635, 0.4048577575155964, 0.08083383801485, 0.613070991062179, 0.6819605655895573, 0.7406265497773674, 0.6599216581121288, 0.6553551702756886, 0.5949254323350562, 0.7481218752580688, 0.7506248441107464, 0.6779901532208634, 0.08697604434039063, 0.16680894950435066, 0.15171288121900162, 0.09087241612209951, 0.11444334232957432, 0.10277414588665101, 0.15644780429529126, 0.08696888234180822, 0.09029993141891612, 0.22404902469428511, 0.26662493384741015, 0.20467220387559593, 0.28237923950592647, 0.43852467768716086, 0.1889694346742984, 0.26017111945306537, 0.1464127602686196, 0.19059421698169832, 0.3532194696251286, 0.2941101404764579, 0.31039355927441603, 0.23395367175555437, 0.25827317514705805, 0.2171525515464683, 0.355473852495244, 0.2786185090202342, 0.37861285758618635, 0.2787224203385513, 0.30234805435544454, 0.2177735303158398, 0.31173030791358125, 0.22004516261497897, 0.22694387400580218, 0.36626943366789944, 0.24400206995173346, 0.3020937883099908, 0.2554122938271154, 0.20158415368910154, 0.23113843133921386, 0.24463013809565126, 0.2288913805027163, 0.2116554518151864, 0.2086286941598422, 0.2105123067309993, 0.2702286834003296, 0.1936167147199067, 0.1793624423247442, 0.2009822031910441, 0.17536650569070023, 0.17727343931934503, 0.17594535083794705, 0.8057775740711629, 0.17433617259147027, 0.16820677056964728, 0.16605819983978087, 0.1650172821048469, 0.1972381991328649, 0.1990068079926247, 0.19867412282856378, 0.1982004398371019, 0.14121830697678983, 0.14750539411543828, 0.8830721454889753, 0.8820538575602073, 0.2663158790003247, 0.7760918190109096, 0.8566698006528742, 0.20266071142012476, 0.165958421025433, 0.21240391065985786, 0.791771611928223, 0.8186857428213732, 0.20378091749154903, 0.1986880912554827, 0.21911231100537887, 0.2090177449276347, 0.21882717560520282, 0.1900224128020077, 0.24485609800901953, 0.19086464477246534, 0.20952197495106117, 0.08870025259211012, 0.09374336935986938, 0.10839002040185464, 0.10376179703154287, 0.1057288113802991, 0.10803009825462173, 0.16104332704157043, 0.08240437676492407, 0.09209221212197372]}, "mutation_prompt": null}
{"id": "09c31fe1-3e1d-4a36-9fee-c7704a9c5609", "solution": "import numpy as np\n\nclass AdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 12 * dim  # Increased population size for better diversity\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.75  # Adjusted inertia weight for enhanced control\n        self.c1 = 1.5  # Adjusted cognitive coefficient\n        self.c2 = 1.5  # Balanced social coefficient\n        self.F = 0.9  # Increased mutation factor for exploration\n        self.CR = 0.85  # Slightly reduced crossover rate\n        self.adapt_factor = 0.95  # Slower adaptation for inertia\n        self.diversity_prob = 0.15  # Increased probability for diversity enhancement\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Decay inertia weight gradually\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            # Enhanced stochastic competitive selection with random walks\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    walk = np.random.normal(0, 0.5, self.dim)  # Random normal walk\n                    challenger = np.clip(global_best + walk, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "AdaptiveDEPSOHybridOptimizer", "description": "An adaptive DEPSO hybrid optimizer with dynamic random walks and adaptive parameter tuning for robust global exploration.", "configspace": "", "generation": 13, "fitness": 0.3670431652927788, "feedback": "The algorithm AdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.26.", "error": "", "parent_id": "09129e91-e886-41de-8702-30f07a664cd5", "metadata": {"aucs": [0.8138974108782766, 0.7688348206071465, 0.7937057206481111, 0.8000414649966289, 0.7674559941251644, 0.8156842307918718, 0.7949006020343802, 0.7683341936305765, 0.8049589990998139, 0.5046267473503618, 0.5657413348974356, 0.606646032911374, 0.5346491176874435, 0.5669047469960286, 0.46622310153512203, 0.5920110177658469, 0.5757029189359415, 0.5989351659911906, 0.06368939248862249, 0.10738146035091922, 0.14332280973469858, 0.11480036987260267, 0.12723242934799983, 0.10603010547077574, 0.10604753018542523, 0.12307759597479362, 0.5935305468328089, 0.08650657272220597, 0.08791412368538842, 0.13089041900072262, 0.10485259080254783, 0.10197140702562368, 0.12168203626122176, 0.1076045070055196, 0.1362375041729329, 0.09253143491467275, 0.9872074302902369, 0.9873041250305621, 0.9866059447990855, 0.9861259053972153, 0.9855222415693318, 0.984825721672829, 0.9846281564028936, 0.9842409017415897, 0.9882866995461173, 0.5767620655441396, 0.5578564453269383, 0.678419941046402, 0.6193561745816278, 0.610371570328115, 0.5948464705517837, 0.5961695507952218, 0.6345301212082566, 0.6271899456454841, 0.7911350359207875, 0.36569145317632457, 0.8172772697123405, 0.21633090044177838, 0.22014432856821042, 0.204451422514336, 0.2294907931547716, 0.8226667927731528, 0.7419996329581533, 0.650611242877557, 0.11735212176828591, 0.38513029451590797, 0.6031788432066411, 0.6545411901661542, 0.1169502870093786, 0.5496635633449165, 0.5480950307303813, 0.5017253138986316, 0.6412650856051598, 0.11197974926447729, 0.6322068174287322, 0.658563265891509, 0.4432354857145864, 0.5458178194862235, 0.5875137586166356, 0.5760215841625183, 0.4625400374512827, 0.043138277973351236, 0.16327351809208301, 0.5003095355999252, 0.0444290730084862, 0.11884624266790267, 0.4143986262933169, 0.14350061880232023, 0.08087703219768116, 0.1374846658977178, 0.12796036863236515, 0.3931806719845238, 0.11819945459991399, 0.43803362242545607, 0.3058775925997045, 0.37999521121342095, 0.5275297327389509, 0.5705646135697886, 0.5793748505448015, 0.05019697848001392, 0.051720842166401826, 0.13948816262625674, 0.13304927407363354, 0.22683068406803497, 0.0801029060001438, 0.07692686696664564, 0.2106372551280672, 0.11675753576873193, 0.18485487173498927, 0.29096247132598196, 0.31764887584407697, 0.3202567942676645, 0.45189754571838325, 0.3301876241193217, 0.14047386434506992, 0.39155447775010466, 0.3345564541605507, 0.6886877560689915, 0.6061673822002502, 0.6713637698733883, 0.6731390908294175, 0.6342519474126772, 0.549558382637374, 0.7079943188946818, 0.5904540577129043, 0.6509880573487117, 0.13167168784053906, 0.08629991375544177, 0.11003115119762585, 0.08069380399597226, 0.111936546035311, 0.13396146801715259, 0.14341496505902673, 0.0907588731634894, 0.11343099769779308, 0.18265284339689802, 0.21021276808775569, 0.22705670318801863, 0.2097102671656771, 0.1791707428510857, 0.17393808944375067, 0.2165605203051385, 0.24039511819470694, 0.22606559844291574, 0.3124749346999073, 0.2564157270361258, 0.39783391084280273, 0.41794975690319114, 0.4002260537202146, 0.32578194977933594, 0.325819687873909, 0.4751954522992802, 0.39393594909051455, 0.22264510041886365, 0.33914443688105333, 0.2517315538912194, 0.26112761303641885, 0.2124531603515184, 0.24851339291187646, 0.25490831104059064, 0.29125851099259525, 0.23012197834394443, 0.2417576694550886, 0.1898254199164856, 0.19172553255494962, 0.20582788533428942, 0.18818210936347635, 0.24043255934038765, 0.20702793502129369, 0.21385149372271484, 0.2100958992656583, 0.17552414031936736, 0.6899139239398565, 0.20314026284711517, 0.1976295153611386, 0.20142776163002463, 0.1854385835875575, 0.18046709604898736, 0.23626246905522963, 0.19231849397734424, 0.13423562263234146, 0.18439566648851513, 0.8208948135707217, 0.19808874224844686, 0.19977923461285962, 0.14264626708659145, 0.1416223896736286, 0.19620300045975703, 0.20870547619615354, 0.7983158429312007, 0.20877985883555228, 0.8062699095621352, 0.8157806729668704, 0.16551844387759662, 0.7932325165535219, 0.20923090633436736, 0.20928579797862656, 0.7846857354119285, 0.23672906091710633, 0.22227248361562546, 0.19589990031175097, 0.21955381110993444, 0.19430315238256424, 0.2040253034092736, 0.2031499012162301, 0.2201644446223735, 0.20809818385790957, 0.09297716788712096, 0.0816259483883629, 0.08879851325587584, 0.08392207008068653, 0.10025512895401045, 0.08982183500936403, 0.10553398239912881, 0.09411321598257838, 0.11799346879384576]}, "mutation_prompt": null}
{"id": "ef307e13-c60b-467e-b15f-6a57324390c0", "solution": "import numpy as np\n\nclass EvolvedDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 12 * dim  # Adjusted population size for enhanced exploration\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.8  # Slightly increased inertia weight for improved stability\n        self.c1 = 1.3  # Tuned cognitive coefficient for personal exploration\n        self.c2 = 1.7  # Tuned social coefficient for better convergence\n        self.F = 0.9  # Increased mutation factor for aggressive exploration\n        self.CR = 0.85  # Decreased crossover rate for diverse trial solutions\n        self.adapt_factor = 0.95  # Adjusted adaptation for controlled convergence\n        self.diversity_prob = 0.15  # Increased probability for diversity to avoid stagnation\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Dynamic adjustment of inertia weight\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                if np.random.rand() < 0.5:  # Multi-phase exploration strategy\n                    indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                    x0, x1, x2 = pop[indices]\n                    mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n                else:\n                    mutant = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            # Dynamic stochastic competitive selection\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "EvolvedDEPSOHybridOptimizer", "description": "An evolved DEPSO hybrid optimizer with adaptive inertia, dynamic diversity, and multi-phase exploration for robust optimization.", "configspace": "", "generation": 14, "fitness": 0.3547424067006021, "feedback": "The algorithm EvolvedDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.26.", "error": "", "parent_id": "09129e91-e886-41de-8702-30f07a664cd5", "metadata": {"aucs": [0.7885881809251499, 0.7781647619794364, 0.76953942873982, 0.7985130046162425, 0.7994105211054479, 0.798831412754598, 0.7913230445505592, 0.7625690410362296, 0.7982787193527885, 0.06475851138405941, 0.543578506495487, 0.5881985984400966, 0.46671142437177493, 0.5394010299312004, 0.5125340503933463, 0.5245665261500996, 0.37513519898816117, 0.5640804430542505, 0.11705495714863468, 0.08551046180371158, 0.12058925392839359, 0.10561914088653579, 0.14687104578127563, 0.10580422737134942, 0.09874268462635938, 0.11256435594177328, 0.08557734306702536, 0.08330227327710149, 0.12698006097064773, 0.09179153178309007, 0.08993770662439404, 0.08704295696720799, 0.09997026373216067, 0.08732484456658007, 0.10234296270774779, 0.06948493776937781, 0.9777192687024848, 0.9754128713265365, 0.986920803855246, 0.984183181319473, 0.9868991863155175, 0.9860745406312289, 0.9879580127112744, 0.9838233066410726, 0.9863549989845878, 0.5907402429044004, 0.4402730384057093, 0.5478184770963879, 0.5384763685519998, 0.4784945338587985, 0.5662577347943997, 0.5941560983482705, 0.596986511959744, 0.4418598693590393, 0.864071946876591, 0.2961034408838702, 0.21028371523360578, 0.35486011527256256, 0.7520114223318665, 0.20658897776659646, 0.2289335102835568, 0.3496369603907835, 0.1733704449698178, 0.5445958092092933, 0.5737329003596685, 0.49484694992200595, 0.11466847329948981, 0.3864351219346649, 0.1148276816566014, 0.4821739103138847, 0.22133473162502326, 0.5295883482659656, 0.6351444377474729, 0.4481784392515836, 0.4182482301109678, 0.3953960969904141, 0.5662126388112737, 0.5235044621975937, 0.5564632667585432, 0.13050840705703726, 0.11537995888937091, 0.0341732896387037, 0.229682064189627, 0.5184078013409511, 0.031108838098837466, 0.050443354359941406, 0.0798894886904924, 0.3115411875931905, 0.09252474663469712, 0.045390566321364845, 0.4174586315522286, 0.5870888181568293, 0.398752425200004, 0.3209663990911257, 0.6012535696716558, 0.1533154235690305, 0.46085732186365735, 0.47169027524072227, 0.6142661911496018, 0.044688990421181574, 0.26773929308601097, 0.22928389524945214, 0.11908286833883053, 0.15901802976537516, 0.11749805697054494, 0.10035290766394156, 0.3301592991965294, 0.1025366512147371, 0.4427036327466375, 0.09113427866621315, 0.36338320588847783, 0.18646123229930145, 0.2353571800111799, 0.24351142691019878, 0.159972587335931, 0.11919337464183988, 0.09143526756048248, 0.6536667390740709, 0.599206841339779, 0.7019941856248335, 0.7117337592720345, 0.6835536404114394, 0.6889863417081283, 0.573177748978297, 0.6058492823268158, 0.705453929325504, 0.10604671962696188, 0.08623786993083937, 0.1448263082538097, 0.09545611233055207, 0.12299823887003092, 0.14272514351954102, 0.10768044774699448, 0.13394717461311956, 0.09808439380161349, 0.31088821637074515, 0.3376071449110635, 0.16955024675089825, 0.2842807026514008, 0.289113359322387, 0.1711100443986826, 0.18990738279910413, 0.1586395344914615, 0.2536105925178217, 0.2502068640460373, 0.3184345607085731, 0.3429458881354178, 0.2821998340602878, 0.25803284519296477, 0.24710161961564037, 0.3454749283595102, 0.33555362488520746, 0.2534958195977942, 0.27250110355522106, 0.2415088274367586, 0.2645414782142381, 0.19961320003102268, 0.2996331283053124, 0.20234938070926423, 0.19224845907968569, 0.3113363384121238, 0.16460840903716945, 0.25776792616950484, 0.24726120477592028, 0.21058825330246778, 0.20572308700790065, 0.19215687054659913, 0.19125776742096956, 0.21082642529199758, 0.1909986570565957, 0.19065337499477042, 0.18292097074824232, 0.1920879071262228, 0.1794656399580441, 0.1955421135091342, 0.1953363145711513, 0.17960536599103138, 0.20190222540002412, 0.20094027038271467, 0.2041784310580842, 0.2015417289721929, 0.40430061571563414, 0.8405258925477668, 0.2960292445287217, 0.19551418337459947, 0.8151014501215953, 0.14901521264758288, 0.8013874472273455, 0.171411483361968, 0.804136014570257, 0.6947487364713636, 0.7698768384659855, 0.16691944833155226, 0.7381940345044894, 0.8263095927839983, 0.760343950701243, 0.7630321394494933, 0.7716899103562302, 0.22594416101745107, 0.20446809123502507, 0.20958808088718028, 0.21548906306949844, 0.18452084091988252, 0.18423184011380445, 0.20384290322670706, 0.22361658735335743, 0.19684675559188292, 0.10210289853457599, 0.0823241779527849, 0.0891901801169499, 0.08487962611787392, 0.08781847236067575, 0.10040483593913019, 0.0978125792243334, 0.08956768498075707, 0.09377650116671321]}, "mutation_prompt": null}
{"id": "9a30b408-967f-47ca-8f5f-42eb4331e24d", "solution": "import numpy as np\n\nclass AdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.7  # Social coefficient\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.9  # Crossover rate\n        self.adapt_factor = 0.94  # Adaptation rate for inertia\n        self.diversity_prob = 0.15  # Probability for diversity enhancement\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Gradual decay of inertia weight\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            # Enhanced stochastic competitive selection\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "AdaptiveDEPSOHybridOptimizer", "description": "A dynamically adaptive DEPSO hybrid optimizer with enhanced diversity strategy and strategic population updates for robust convergence.", "configspace": "", "generation": 15, "fitness": 0.36565253953697235, "feedback": "The algorithm AdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.27.", "error": "", "parent_id": "09129e91-e886-41de-8702-30f07a664cd5", "metadata": {"aucs": [0.8321511150071523, 0.8203859786549791, 0.832228391317125, 0.8398809676068889, 0.835285089944247, 0.8266402853413891, 0.8450792403652398, 0.8329610419162173, 0.8359063068428192, 0.6470431320331442, 0.5941884981495809, 0.5721879599874294, 0.5763348443953075, 0.5409083326995334, 0.6046799223342989, 0.05465790822852379, 0.6416680356001186, 0.5077651089864558, 0.1199656021704113, 0.13509581990227704, 0.10782734573576236, 0.10236775603336168, 0.12018381812217538, 0.12167306736988537, 0.10254863769977196, 0.11775250430172468, 0.10728731424826676, 0.12943863788711774, 0.13028043762777974, 0.08563499354537274, 0.10474967469157215, 0.06963759932754332, 0.10388840654633846, 0.08750355485055683, 0.10012083421595619, 0.10680130290665546, 0.9890439276490072, 0.9900498830698867, 0.9879754548371835, 0.9883317088427748, 0.9864241701847845, 0.9691150411640918, 0.9795172865956251, 0.9891020846784542, 0.9882741854573912, 0.6958354074216409, 0.6563136300586361, 0.6678718540818974, 0.6371752989679806, 0.6332004122478345, 0.5905495188850787, 0.6663016374910898, 0.5598668692987943, 0.5656646295495473, 0.22594979715242736, 0.22281101916186563, 0.22174891975379307, 0.8732247371401389, 0.36383815012531073, 0.2672323463183951, 0.8273111727068885, 0.22273106258620134, 0.817519032590209, 0.6508808065742573, 0.4896290042037431, 0.5359441141430672, 9.999999999998899e-05, 0.5168914002046494, 0.12001262870852292, 0.12684829698154065, 0.6987499243117223, 0.548210084904249, 0.5684943886656448, 0.599481198933023, 0.4785352174166083, 0.6354474904127878, 0.5481585274313079, 0.6147432540582725, 0.5883695213839523, 0.1285634933161638, 0.12653980794584962, 0.47498562005257505, 0.35565586644519964, 0.11935403470584316, 9.999999999998899e-05, 0.1930492783759471, 0.12060380308231111, 0.360428863170109, 0.49671161957803445, 0.3858689429280957, 0.6795835090664046, 0.4737833027680878, 0.319858369799923, 0.5435713433707126, 0.4681957974534021, 0.6677604686190655, 0.5767932913212279, 0.3266166434971052, 0.12222029167239468, 0.131212658070464, 0.11368604407307559, 0.22061870595858113, 0.23203270523297326, 0.21510701987754466, 0.2430879372234238, 0.12077934342300145, 0.2993151140573216, 0.1425348599323919, 0.31726928656226727, 0.19295919512842397, 0.22348996545990563, 0.3020021697134131, 0.25548216315583316, 0.3187889184485364, 0.05228715654196148, 0.05467069470567931, 0.09208677727220693, 0.7346737550669009, 0.708761621051891, 0.7100083630808396, 0.7202888500421012, 0.6989440599036078, 0.7145592147631692, 0.7521172531631248, 0.6412917229559421, 0.7113075739665319, 0.10413586040749456, 0.09032728318617933, 0.10843849025003527, 0.07315222081900485, 0.1692765370213588, 0.1224417675164583, 0.11960429990816179, 0.14498992586817383, 0.13753879124037538, 0.34621583445834103, 0.20117131732412719, 0.19337955488668324, 0.29447058612501953, 0.18099442888717265, 0.17563639661016317, 0.287353385677085, 0.13282236691527383, 0.17711108032247813, 0.23084441200149697, 0.4198303038498975, 0.2676131848858617, 0.29390857694259287, 0.38339274361562525, 0.21750807973565167, 0.381654415031488, 0.38478123561640676, 0.42153255627171704, 0.22767714947086437, 0.19439749050629873, 0.26814352877135994, 0.4070827134160909, 0.18140983931796828, 0.22507525746616952, 0.34302472593489985, 0.3012372873318512, 0.3234345853918329, 0.22075332164871664, 0.20730338635868129, 0.20841902507258614, 0.2496311389303385, 0.20628088383195553, 0.24292702892537554, 0.21488306897118659, 0.2231299461362085, 0.23585535496619592, 0.19437679986198975, 0.2129508193201579, 0.18926365839336678, 0.1894764685469983, 0.21544331087470303, 0.1903032589626521, 0.23833728945166377, 0.18979620613753678, 0.18176461741893368, 0.16230130792289388, 0.18031580083965926, 0.20591116960984113, 0.19561738745709834, 0.19728762977130165, 0.19827920129874776, 0.8566442251321498, 0.14791971213358868, 0.16968253839351077, 0.826733371045704, 0.21112230035488366, 0.20362753199231387, 0.8352842128728267, 0.11266359460762765, 0.8222363451820018, 0.21162308414321007, 0.7897715486289281, 0.16199014952941848, 0.2540116750574509, 0.20933763968443064, 0.22994507301060274, 0.2208900136233517, 0.23011006196818462, 0.19664338626365618, 0.19464059460849148, 0.1992458401155549, 0.19337915173793996, 0.12579297445649407, 0.08999000407720759, 0.0844433628776462, 0.09054870495613376, 0.07763630732645821, 0.10275136675071395, 0.09965947946633191, 0.10283769085953132, 0.0917782664964234]}, "mutation_prompt": null}
{"id": "a25ab897-f1e3-4649-80a0-be6369f3118e", "solution": "import numpy as np\n\nclass AdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 15 * dim  # Increased population size for enhanced exploration\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.75  # Adjusted inertia weight for enhanced control\n        self.c1 = 1.7  # Increased cognitive coefficient for faster convergence\n        self.c2 = 1.9  # Increased social coefficient for stronger global search\n        self.F = 0.9  # Higher mutation factor for exploration\n        self.CR = 0.85  # Slightly reduced crossover rate\n        self.adapt_factor = 0.95  # Slower adaptation for inertia\n        self.diversity_prob = 0.15  # Increased probability for diversity enhancement\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Decay inertia weight more gradually\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            # Enhanced stochastic competitive selection\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "AdaptiveDEPSOHybridOptimizer", "description": "A hybrid optimizer integrating adaptive DEPSO with dynamic diversity management and adaptive strategy parameters for robust performance across diverse landscapes.", "configspace": "", "generation": 16, "fitness": 0.32722425260050486, "feedback": "The algorithm AdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.24.", "error": "", "parent_id": "09129e91-e886-41de-8702-30f07a664cd5", "metadata": {"aucs": [0.6957302451085436, 0.7291459403354272, 0.7302905910873143, 0.7300994995466166, 0.7089899892024671, 0.7381230847691194, 0.7336252963817727, 0.6963403749964016, 0.738410934619744, 0.46080547431543717, 0.4266749773820454, 0.45201046314876525, 0.366806801308701, 0.41309671141317106, 0.23955210389829096, 0.4283270894126624, 0.44840803109076244, 0.39166470191834746, 0.10874130040479446, 0.11417486746435912, 0.10204384856351334, 0.10231548704464255, 0.39481471222417597, 0.11941249016000788, 0.10176330686818436, 0.10377843135345499, 0.1050164385975908, 0.09293022874699686, 0.0962379162917607, 0.06870575561607206, 0.10337898635372311, 0.1083135050465206, 0.09161388419069749, 0.08031724957214881, 0.10832429860458992, 0.09659824563794117, 0.9812815096021363, 0.98274937277137, 0.9851201894201528, 0.9808480609553553, 0.9831272445300218, 0.9844000590502673, 0.9860409328824609, 0.9853681394065534, 0.9850907581939252, 0.415231477600825, 0.4391490839844716, 0.4904786308854181, 0.3334812078979057, 0.36802180049248245, 0.36452480932857534, 0.3530208340348736, 0.45436527553611616, 0.2755410095695169, 0.677666791930976, 0.6860503490604439, 0.6833734381075329, 0.7451475407039505, 0.3338085378331854, 0.24995893183092488, 0.21995242322066277, 0.7158615797250028, 0.7633498075456694, 0.4394066860853981, 0.4518247702684104, 0.09452749720375253, 0.1002460366840161, 0.2375199539707461, 0.12257436830340263, 0.5006527539061321, 0.12006587306135574, 0.4685555511726388, 0.10729116503610092, 0.3890710531189696, 0.5221041196910299, 0.11374292298675703, 0.10820045571124504, 0.22087579589900275, 0.455064121240879, 0.4415282364129077, 0.4240057567844828, 0.2846775125015837, 0.05525851071188859, 0.2747783359948841, 0.15659695901430315, 0.015496306103426338, 0.1552163088123505, 0.32078834791649324, 0.42940906964409653, 0.3313966380386397, 0.42216266838921523, 0.29641855559503194, 0.5061052727559762, 0.1933782328678021, 0.41749651059826454, 0.19574561045112926, 0.27018727777510265, 0.054170643554231956, 0.45271078500546935, 0.04681708418583841, 0.1026310494324929, 0.1206364208313716, 0.2583401660004939, 0.09547139788338443, 0.24970018053696674, 0.23037257839643854, 0.110172746101038, 0.11348824567323168, 0.1848248498352849, 0.2916474713457198, 0.18871379525549348, 0.2651151631193598, 0.2851130156177891, 0.3066959902242926, 0.050384007637568895, 0.04881886664760404, 0.08825636088274569, 0.6123073419378812, 0.6101349085284602, 0.6227549873224296, 0.6184305466164759, 0.5454765307130939, 0.6584592446394497, 0.5925559197919634, 0.5692772068107819, 0.5927968803509116, 0.1094605662447602, 0.09823859744387575, 0.07940408801596155, 0.1451897349551169, 0.11838573825317966, 0.11116774746959823, 0.08984367068013766, 0.12189331208569765, 0.07846636434227694, 0.14329157860654052, 0.24287821924905728, 0.17231437924688653, 0.1954072069129389, 0.2397792642415738, 0.4425330781341502, 0.17488609929355392, 0.17623245515937125, 0.2105966092989242, 0.3253705848993955, 0.34139685030595535, 0.3071776000875376, 0.3496892958854061, 0.3786838437596509, 0.3714795332033607, 0.34745887611312454, 0.3866578426788265, 0.36843560218211246, 0.2896125931917226, 0.23605385386278432, 0.19553088767772753, 0.26338051950114927, 0.17462925917338, 0.1833496526612607, 0.244753077560513, 0.33305062032556587, 0.3637726268643574, 0.23937070405372096, 0.19436463687217498, 0.21850133391563364, 0.1891986300284576, 0.213892735302611, 0.22953691589030045, 0.20077918490898639, 0.21853207207021952, 0.2517720211999023, 0.19502827727174676, 0.20605757957251425, 0.19585165017270334, 0.506700791298816, 0.1943915846562827, 0.18326760760081384, 0.18180378591552537, 0.1784031016778539, 0.19231553944093815, 0.12854550915498564, 0.18524080486887073, 0.7278249585088503, 0.17998502561338714, 0.19401419834430245, 0.16484799402701666, 0.7471626129462986, 0.40525722584258206, 0.16580012312952963, 0.7650149095754717, 0.2087921442810371, 0.2070580090772457, 0.20534088335399658, 0.6857863977137835, 0.7293587964303149, 0.7665120537283197, 0.7337854386362725, 0.21151548648232688, 0.19108949577536982, 0.21380761689584127, 0.22635496858550608, 0.19929096843103467, 0.22156877448832624, 0.20062671006694632, 0.21613339958881894, 0.21498522079879256, 0.17522311360398857, 0.07928473532507974, 0.08247547374109421, 0.09404342253788056, 0.07794086885105167, 0.08563756662024502, 0.08915854248149246, 0.07733053166095638, 0.08973864916523566, 0.07544927159694781]}, "mutation_prompt": null}
{"id": "814bd171-af2b-4718-a851-0db845ed0e9b", "solution": "import numpy as np\n\nclass RefinedDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.8  # Increased inertia weight for initial exploration\n        self.c1 = 1.3  # Further reduced cognitive coefficient for diversity\n        self.c2 = 1.7  # Increased social coefficient for stronger global attraction\n        self.F = 0.9  # Slightly increased mutation factor for better exploration\n        self.CR = 0.85  # Slightly reduced crossover rate for focused exploitation\n        self.adapt_factor = 0.95  # Slower adaptation for inertia for better stability\n        self.diversity_prob = 0.15  # Increased probability for diversity enhancement\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Decay inertia weight more gradually\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            # Enhanced stochastic competitive selection\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedDEPSOHybridOptimizer", "description": "A refined DEPSO hybrid optimizer with dynamic parameter adjustment and increased exploratory diversity for enhanced convergence precision.", "configspace": "", "generation": 17, "fitness": 0.36271811288008027, "feedback": "The algorithm RefinedDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.27.", "error": "", "parent_id": "09129e91-e886-41de-8702-30f07a664cd5", "metadata": {"aucs": [0.8203747255510654, 0.822535970488165, 0.7885320688393922, 0.8247931510888984, 0.7986024353981486, 0.7898419250662558, 0.8201886039220171, 0.8001007037824677, 0.794484553243169, 0.5847737345872168, 0.589667016004862, 0.6122929366990756, 0.5971155813994392, 0.5687694706327483, 0.5919840482623524, 0.6556927232895852, 0.586432618042197, 0.5586558784965258, 0.14137102289321524, 0.10236152870482218, 0.1508999518416445, 0.15130176441167476, 0.10973397150477626, 0.14249247125204656, 0.1493313528986464, 0.15353625255560366, 0.11169586957934685, 0.08636403277533677, 0.07776992797798465, 0.08790875317858626, 0.09440561987306062, 0.06303325815444716, 0.0983007380115829, 0.10270646738202527, 0.12045407928177343, 0.13083655883097345, 0.9895067563838708, 0.9863431890682972, 0.981384584174926, 0.9896150769502586, 0.9865026277168096, 0.9700964174252111, 0.9788607188347128, 0.9890858375601267, 0.9872998908518935, 0.6628645879731181, 0.679347685854132, 0.6431453212424869, 0.6399533569125889, 0.6262198056167537, 0.6162468685627847, 0.651714865282882, 0.5685963683675695, 0.6459855029229078, 0.8321938258333803, 0.21735959610627176, 0.8139072753380052, 0.20597643521983366, 0.2688711532409306, 0.35288784295984665, 0.8208798462938691, 0.8180725310920425, 0.23321761978824296, 0.6831223287691568, 0.5474919696836755, 0.5449439824483778, 0.09170192636358365, 0.5680290075198071, 0.6058745149081517, 0.12852207384757353, 0.5651159880404433, 0.5368331888850097, 0.6576359414031774, 0.5831755361721873, 0.6414260094901696, 0.6407158721863597, 0.12576355204368717, 0.6223798523955841, 0.11785935232177325, 0.5181897882277529, 0.11833052570544556, 0.13140258067151966, 0.21825555042960287, 0.13059885548113837, 0.29574812756902136, 0.11719849522861492, 0.04666491288341845, 0.12031008129698528, 0.2835951246873408, 0.08136363854789075, 0.3457187345716837, 0.3035840121418304, 0.21857378241973635, 0.1371040769561912, 0.20995455693032516, 0.12782183776073874, 0.5475415202692713, 0.6146190766869122, 0.4530281909590994, 0.09050532537612366, 0.10675121065152016, 0.14778128697854753, 0.1653611567888258, 0.23130596305665063, 0.23690985961867617, 0.08866321174480929, 0.11693827037096438, 0.17241511801160525, 0.2521390085908358, 0.18227821255192667, 0.26663052668080967, 0.3408330270788269, 0.318900642768183, 0.27279334200724514, 0.1354979727797314, 0.09459152756136768, 0.07605398540250385, 0.717890728916142, 0.6810599761593181, 0.6252029276923297, 0.5918036890310842, 0.5817013775809439, 0.6450598116927433, 0.7302213471212655, 0.7092027239721809, 0.6591012027536255, 0.06245033851105508, 0.10637476528562662, 0.10317495469651894, 0.15295983974938065, 0.14812548391186864, 0.1198252823718049, 0.1335026873869396, 0.16030456117048075, 0.08396964257313588, 0.1768708600329777, 0.23349806862184797, 0.33247712133697394, 0.2532155512545725, 0.1880177686847777, 0.208098570685481, 0.24754741301729555, 0.28417601608010223, 0.47696588894510483, 0.371294968254546, 0.36942802428320654, 0.39031495809100447, 0.3551372201310057, 0.3328120355867765, 0.410987794821567, 0.3332523636449315, 0.3316766484648995, 0.3763346076412406, 0.3680083766333766, 0.20546593316632922, 0.22655410132403309, 0.36299812907152085, 0.22313087852473013, 0.3416928379142421, 0.24637955482139995, 0.3042524758694939, 0.2845076050581933, 0.27694794848931703, 0.226529887990636, 0.2288116430795163, 0.2274850358458903, 0.25189431121483374, 0.25054781703218776, 0.24250360023542394, 0.24197703120190206, 0.20091656956811998, 0.1729535419968754, 0.19162191895551361, 0.18835679819775153, 0.20419204379133793, 0.21932592051088395, 0.17707035887582112, 0.18295373280437888, 0.18703814740562974, 0.702457969273586, 0.8771710457710553, 0.16842788775003315, 0.15287648646405505, 0.163914364456606, 0.1946600266255596, 0.1948321447859157, 0.16652971914878967, 0.15899434627878695, 0.8280778147996134, 0.8509855133059963, 0.20937096339243166, 0.7936272070328549, 0.8027148202760036, 0.16663338333115318, 0.16762862328847383, 0.21096397158826197, 0.11216494825456269, 0.12656112275002285, 0.18922259041965084, 0.2056555052204191, 0.20065936719327016, 0.19922371144675477, 0.19763316249919693, 0.19690844281810427, 0.19682497957049605, 0.18610305272550487, 0.20424425004570812, 0.08798445791950471, 0.09140352597624857, 0.08523968886383992, 0.09673962485080079, 0.08549755557901773, 0.09438872043438784, 0.08983877092215153, 0.08308877119057612, 0.07768885871657927]}, "mutation_prompt": null}
{"id": "352e8818-8326-45ea-bb67-92d3a87af555", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.75  # Slightly increased inertia weight for better exploration\n        self.c1 = 1.5  # Increased cognitive coefficient for personal exploration\n        self.c2 = 1.5  # Balanced social coefficient\n        self.F = 0.8  # Balanced mutation factor for stability\n        self.CR = 0.85  # Slightly decreased crossover rate for diversification\n        self.adapt_factor = 0.95  # More gradual adaptation for inertia\n        self.diversity_prob = 0.15  # Increased probability for diversity enhancement\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Decay inertia weight smoothly\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            # Improved stochastic competitive selection\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A refined adaptive DEPSO hybrid optimizer with enhanced inertia dynamics and strategic diversity reassessment for improved global exploration and convergence.", "configspace": "", "generation": 18, "fitness": 0.37389556474664226, "feedback": "The algorithm RefinedAdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.27.", "error": "", "parent_id": "09129e91-e886-41de-8702-30f07a664cd5", "metadata": {"aucs": [0.8079298430310167, 0.815954948703244, 0.8217642296377788, 0.8274538710087987, 0.8124372589333578, 0.7953943922446435, 0.8223485551482186, 0.8208931661289622, 0.8088939424390456, 0.6339575038892946, 0.6708857115284581, 0.5806510038780797, 0.6587864979130558, 0.5521158542002489, 0.5757904978426953, 0.577121820112108, 0.6287409734287244, 0.6254634823433303, 0.13923337035967454, 0.13675074929520747, 0.09173352502138954, 0.14352933759954345, 0.13678072848040734, 0.13135590607059455, 0.1688310892010073, 0.1407373426952141, 0.12715409004167433, 0.0983186778945887, 0.1032114666903724, 0.08825422565527874, 0.10293847551025759, 0.10377389786523128, 0.08933737364109606, 0.0856520711611749, 0.08903425328425552, 0.14361277789474902, 0.9894978716731998, 0.9863772911375608, 0.9893942151130739, 0.9819391617081316, 0.9863034742639012, 0.9688588208569572, 0.9789503290187376, 0.9890534112560788, 0.9872490543755426, 0.7132564620941417, 0.5447405480553109, 0.6004730896564083, 0.6530931644318241, 0.5282605081459704, 0.5744552142886832, 0.6037735809376624, 0.6036406362270645, 0.6364621435208431, 0.3810967528613419, 0.8293599921445856, 0.34689657268167895, 0.21740899345556086, 0.8148129683710278, 0.8351990057241641, 0.22630490763570155, 0.22349484340780412, 0.232673414114974, 0.6102421919942848, 0.4464498378757885, 0.6228963805545238, 0.408659597978249, 0.7010076875930312, 0.5573404925548701, 0.651669936280072, 0.5606080593253588, 0.6876995961096779, 0.6411264933139628, 0.12984713165149064, 0.5365962909400561, 0.6451425724365785, 0.6369694801301905, 0.5919952024634623, 0.4024363459986695, 0.12978667545763145, 0.10695837065233538, 0.15975157865537326, 0.059777624346269875, 0.27117829844845487, 0.04066959215386101, 0.04410562945676588, 0.16141175770469762, 0.14314161284967064, 0.22976031275070707, 0.19988864426105213, 0.3413901668562096, 0.5467212985149172, 0.20232335448087935, 0.39268253183433777, 0.2467084379861607, 0.28255792902745924, 0.6275623961085939, 0.664918743117376, 0.3956582722279507, 0.0623262301912213, 0.07671006860699014, 0.06584238072498161, 0.2592923642032402, 0.25209197458536226, 0.2918093760116548, 0.1331132451333078, 0.114874300611024, 0.15105508963393965, 0.26226053630586565, 0.29602524472487635, 0.18633229897298043, 0.24745777828851268, 0.26230883380473635, 0.2558492521637403, 0.276056661421172, 0.20771670257956, 0.07672921333735416, 0.7246695302971466, 0.691505415332188, 0.70800724528065, 0.7298304573140895, 0.5572163389463648, 0.6648158606692645, 0.7435778477312538, 0.6360376806623547, 0.707157244270346, 0.0898730519067722, 0.16666637069396106, 0.07624018522879994, 0.11522104671240563, 0.09997213534380966, 0.13851012135016028, 0.08264998684347724, 0.11234998789860207, 0.08739733538416872, 0.3458735865147755, 0.18306505289157926, 0.20042775991256967, 0.22457562833823685, 0.3507819272118441, 0.25225976894489555, 0.27123419604404264, 0.2734625856349183, 0.29179207465117374, 0.4336299668518936, 0.31621653100620006, 0.3607517404309599, 0.2759326459319771, 0.3658289700341717, 0.4481945970722271, 0.39133348244578514, 0.32417226739085425, 0.41746258235336586, 0.25729335274402176, 0.2997363381183892, 0.2527437684222067, 0.240678280686908, 0.25337165575421383, 0.1959606102070136, 0.21439963778874815, 0.2698604409002002, 0.24013036026221846, 0.22832991844978356, 0.18327635028053157, 0.191780207868955, 0.23296664003416423, 0.21504626482346278, 0.2438827607980788, 0.23754969069534404, 0.21630613278478683, 0.23445617690269904, 0.21102742038233957, 0.19205233279868628, 0.21525418246501582, 0.205619825081247, 0.22211520789448613, 0.19709747494883834, 0.1809938814374209, 0.20351895947866527, 0.20682057734809, 0.8845810655102455, 0.17565337073571885, 0.6340363278745169, 0.19811823010853002, 0.19856831670547392, 0.1962939263132505, 0.8834294492788268, 0.1597247115493532, 0.16916123726551724, 0.864605488437092, 0.2114804747709782, 0.8119787356251479, 0.8238562104780951, 0.7897909903598734, 0.7880443018256712, 0.2124782949752897, 0.10270796562455076, 0.12637936621297408, 0.2041805706578551, 0.18543831441504532, 0.19675046358124204, 0.1848066317024485, 0.18600394731299807, 0.19213273597204883, 0.18797524692725087, 0.20729830260599147, 0.21680002552453348, 0.17031851426147937, 0.10080627391292274, 0.10231668797503246, 0.10444787513262255, 0.09664396804257414, 0.08504489118892289, 0.10693724601395316, 0.08592905187621913, 0.08041970631447726]}, "mutation_prompt": null}
{"id": "9d048e1d-4472-4540-9ad9-cd61aa69f108", "solution": "import numpy as np\n\nclass AdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 12 * dim  # Increased population size for better diversity\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Further adjusted inertia weight for dynamic balance\n        self.c1 = 1.5  # Increased cognitive coefficient for enhanced exploration\n        self.c2 = 1.4  # Decreased social coefficient for controlled convergence\n        self.F = 0.9  # Slightly increased mutation factor for exploration\n        self.CR = 0.85  # Adjusted crossover rate for a better balance\n        self.adapt_factor = 0.95  # Slightly slower adaptation for inertia\n        self.diversity_prob = 0.15  # Increased probability for diversity enhancement\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "AdaptiveDEPSOHybridOptimizer", "description": "A probabilistic adaptive DEPSO hybrid optimizer with dynamically balanced exploration and exploitation for robust convergence.", "configspace": "", "generation": 19, "fitness": 0.3728661747605851, "feedback": "The algorithm AdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.28.", "error": "", "parent_id": "09129e91-e886-41de-8702-30f07a664cd5", "metadata": {"aucs": [0.8465886699702161, 0.830538932390425, 0.8159833863663483, 0.8635944923599981, 0.8445494659634127, 0.8114613686698104, 0.8392150237153682, 0.8423434675277054, 0.8297121260828427, 0.6005913197137323, 0.5889461069373618, 0.5698594009935694, 0.6444001539232556, 0.571022354740369, 0.5753343961692252, 0.6452491362752972, 0.6329634703298828, 0.6119065938374695, 0.11426019478441618, 0.11624616203360005, 0.1116216461696884, 0.13561834674729434, 0.13820495425463486, 0.11117228305947069, 0.10952469967306866, 0.10732426478130364, 0.14848631876984197, 0.11459913467528837, 0.09287671867856384, 0.08864671696228654, 0.10086547352230157, 0.09541566868365459, 0.10619609253295681, 0.10434072587686283, 0.13494722023932337, 0.10989733595497342, 0.9869765799883491, 0.9872670356773386, 0.9865976088021315, 0.9835447644417286, 0.9844030472660688, 0.9843408564647474, 0.9846816714820518, 0.9842660799979948, 0.9882858755345362, 0.6340246942583967, 0.7062170146626467, 0.6392423711465907, 0.5539178468930468, 0.5796816926488204, 0.6711665714976904, 0.6481319009144141, 0.6805974839788809, 0.6273353356734401, 0.24613711927013404, 0.8608075198299585, 0.8044675007248395, 0.2693263236787594, 0.2026281003364062, 0.26863174976154514, 0.23203918457698636, 0.8104940931336138, 0.7677884424454104, 0.6772936202982975, 0.1299222123280861, 0.49620501585475585, 0.12854687741210946, 0.7183990573963277, 0.7455001498708522, 0.6655090122862297, 0.6564015884661922, 0.6565542944719462, 0.6508165770462944, 0.4403566618264736, 0.6525182843006803, 0.6115332159204807, 0.12129412379793425, 0.49967823378366216, 0.7149388518268047, 0.6852674554989007, 0.5257549646477613, 0.07020872039840853, 0.607482780370062, 9.999999999998899e-05, 0.06255067468819164, 0.040754406089941186, 0.25456220529762663, 0.6296727624822258, 0.036969187365410106, 0.10469817553505767, 0.31314388398276616, 0.43465843942522175, 0.11835765844789325, 0.41916854496037625, 0.3721461476273392, 0.21818911036350386, 0.6389754177234805, 0.5526876509387046, 0.5433145690179069, 0.06387969390418002, 0.10867123866829498, 0.1479274454005115, 0.1381013141105173, 0.2786678174547442, 0.09636794726736697, 0.15911397192683585, 0.18567552611141314, 0.11425735748725452, 0.2950753367998893, 0.156247986420194, 0.12294785267163044, 0.3499806117867885, 0.4067542236080851, 0.20691119914332223, 0.05398030197905046, 0.34760631048217006, 0.10922628248290911, 0.7652105711095067, 0.7079828425358181, 0.6477765400086026, 0.5731476243901119, 0.62859538747271, 0.687917875928608, 0.5859004098679844, 0.6833669496994021, 0.7084123521363906, 0.11808794944132406, 0.05903357395225817, 0.10575155441721185, 0.15012370755170867, 0.15134861600427119, 0.11796336556798037, 0.15143759496059572, 0.07817549340742802, 0.10990436096081302, 0.15875456766731733, 0.16624474589339588, 0.18777612320680592, 0.2379442703843323, 0.21921328472783674, 0.15923190137349008, 0.20939188237373174, 0.2545121032525517, 0.25254848460269763, 0.29491620102666016, 0.33512163694625785, 0.5450028667572877, 0.29772768011635053, 0.3898959350264811, 0.38499456250328046, 0.25214515422122263, 0.33247784149723525, 0.2407047478971711, 0.2074169890038926, 0.23202616818209976, 0.2705047132479931, 0.3094648517457671, 0.2062876840383535, 0.34900964069634377, 0.2663173397814955, 0.2662890650460936, 0.2046465052509432, 0.1975240228679328, 0.2141803290545088, 0.2083205932437151, 0.21084671781738096, 0.23199992796256697, 0.23188248095229347, 0.2166110131415212, 0.2619750677325644, 0.25012995260775095, 0.22086825814667976, 0.20749929839386827, 0.21039712824938228, 0.24329838911114587, 0.20250817756576744, 0.18867224278607053, 0.19297283444013869, 0.19361630601830238, 0.20268542082146113, 0.13480358028086192, 0.186954078985338, 0.20677424103196362, 0.19917868290923602, 0.1998110905372631, 0.8728489570887936, 0.14204003435887258, 0.16297415992248776, 0.1632908342346826, 0.8541881880868112, 0.20829780624616467, 0.7997294557585033, 0.7535795878927694, 0.7880081340473271, 0.16612008602413608, 0.7891179239448988, 0.20961387711514956, 0.12447376111025421, 0.2129918245370902, 0.198550903149053, 0.21537032606315798, 0.18627540959347177, 0.19375044210734194, 0.21052495810111804, 0.18513486831506665, 0.2170943640243912, 0.207154449733145, 0.13312755031208146, 0.11175966384995806, 0.09683789532612586, 0.10419363203525267, 0.09535406315673978, 0.1287265540639393, 0.10355889087343162, 0.09570396300354755, 0.1214623957676747]}, "mutation_prompt": null}
{"id": "26cc7c63-60da-4a84-bd91-12fdedafe229", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 12 * dim  # Slightly increased population size for diversity\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Further reduced inertia weight for better balance\n        self.c1 = 1.5  # Increased cognitive coefficient for more exploration\n        self.c2 = 1.4  # Reduced social coefficient to mitigate premature convergence\n        self.F = 0.8  # Adjusted mutation factor for balance between exploration and exploitation\n        self.CR = 0.85  # Slightly reduced crossover rate for local search focus\n        self.adapt_factor = 0.95  # Slightly slower adaptation for inertia\n        self.diversity_prob = 0.15  # Increased probability for diversity enhancement\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Slightly slower decay of inertia weight\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            # Enhanced stochastic competitive selection with increased frequency\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A refined adaptive DEPSO hybrid optimizer with enhanced inertia adaptation and improved competitive diversity for robust convergence.", "configspace": "", "generation": 20, "fitness": 0.37142354856658283, "feedback": "The algorithm RefinedAdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.27.", "error": "", "parent_id": "09129e91-e886-41de-8702-30f07a664cd5", "metadata": {"aucs": [0.8416353882833363, 0.8365396873954263, 0.8229161368064096, 0.8498465391659633, 0.8435447911776606, 0.8147516733760998, 0.8448521305471595, 0.8307931030721871, 0.8223389096334419, 0.6005493667717339, 0.5703680950144403, 0.5887007412884285, 0.602609268605033, 0.6457591257346187, 0.6573499061914696, 0.5969641624259946, 0.6200316041124179, 0.5672478485666621, 0.13558096298630629, 0.08920056425817602, 0.12660333149278813, 0.16106450176308007, 0.6857235911308373, 0.14473704052182024, 0.11975140275192842, 0.10657726199155326, 0.13436735261751487, 0.08489325132351155, 0.10504594701732262, 0.13080988744084443, 0.10838461493770701, 0.11200435698015576, 0.08305373430600371, 0.11441494908661642, 0.09339707923606544, 0.09858198270655061, 0.9869411823951922, 0.9872540999888586, 0.9856291644926927, 0.9835966738063188, 0.9844035046687074, 0.9848308992653442, 0.9841645136019234, 0.9873323984389791, 0.9882650863976088, 0.667915100663085, 0.6703663222744297, 0.6761299411530485, 0.6499118318483783, 0.6594544340814514, 0.593465450682818, 0.6507201558330015, 0.6619572452673833, 0.6558669640492543, 0.21755087742955137, 0.22379336013225226, 0.8643070503400905, 0.2185088103430709, 0.20470655467237842, 0.2716228875178337, 0.3443989376968345, 0.23033053831604733, 0.3686360493914971, 0.6253192917198791, 0.12228680155729454, 0.12455866813153571, 0.12613413245842253, 0.7028486077467488, 0.6234784951026582, 0.6541755789123718, 0.6599521135791167, 0.6090863297071092, 0.6656558740195289, 0.12501735006312797, 0.6094425833661707, 0.569304121669256, 0.607424730204459, 0.5133355580097991, 0.5755039348268963, 0.5988604541757789, 0.1256417010577905, 0.064632159298328, 0.2429880801348363, 0.2785967534383632, 0.10289216955544012, 0.10728697387655006, 0.12687707871116638, 0.3345715350109968, 0.1914948618114033, 0.3364842111683414, 0.10726157582305018, 0.5241199026467634, 0.2374291712264518, 0.6948316637574681, 0.22340712609704227, 0.5555227297166185, 0.2860632404059724, 0.384769941394166, 0.32765347441881165, 0.05635738707857019, 0.14494090177968477, 0.12629783265093775, 0.297462814469701, 0.1788022146161362, 0.11274360466581534, 0.14577194023653306, 0.15830281037998595, 0.10998067202749318, 0.3622925381892119, 0.2096908407681144, 0.3112453821079184, 0.2396683988574173, 0.3411419955620899, 0.33569045344266335, 0.23035094799473899, 0.046946870927018436, 0.08456313798320847, 0.6991744082556668, 0.7050667474235409, 0.6889513507483197, 0.7018231713674556, 0.6900843890375108, 0.6584571510650322, 0.6354168157236109, 0.6325475207997577, 0.7776316524352938, 0.09149245568445963, 0.10469681747678494, 0.08026078597220143, 0.1102028026189279, 0.13852563639706605, 0.12677734281547015, 0.09450668038692567, 0.11029367364856335, 0.08861568436019374, 0.132537789025171, 0.1937460191939253, 0.17577355998026123, 0.21307233165842177, 0.3164744203535005, 0.26328473302901745, 0.28135298300369715, 0.20861037072124633, 0.18954048268957047, 0.2388429212046742, 0.4005899021473823, 0.26051741951182306, 0.5610680642933312, 0.34314844933368793, 0.28952839041016665, 0.43154064274861414, 0.3999527350002894, 0.4675326602363572, 0.2533952599159285, 0.2334416805369961, 0.27884136599558773, 0.3427507383059094, 0.22702372462890996, 0.3046607709256295, 0.36559419753169764, 0.3756160185154235, 0.23453916914233064, 0.21648334495033017, 0.2428136348044193, 0.2237450495667731, 0.25617028212085236, 0.22757668275645226, 0.25149571878135435, 0.22389465283154442, 0.24457815985252607, 0.2886535202467081, 0.22189252467183884, 0.18788034573520596, 0.19577440976379412, 0.24216986427148368, 0.18179252367689758, 0.20649525620604092, 0.20580038243994836, 0.18707722421038264, 0.20383397845763473, 0.1342821049391426, 0.18684406743913073, 0.8474878254616341, 0.8964571154263492, 0.8568257028538765, 0.8509981744361252, 0.14202992002104964, 0.17307061264307122, 0.6628459444346981, 0.8611405427368033, 0.20813574499332343, 0.20507122463955707, 0.20806460873663013, 0.167685404850614, 0.8497293690548304, 0.20963787509307574, 0.2107135110326488, 0.16696888216753525, 0.19765701508246036, 0.2021250829021869, 0.22929726428900654, 0.19369081466836635, 0.18085243826021347, 0.19578011504550719, 0.19489657423719942, 0.20442260072864316, 0.20050717711570043, 0.08469408483965968, 0.1354682656188404, 0.09500343985001014, 0.09305232568007049, 0.1025059233379303, 0.10702507479287504, 0.10112037809770114, 0.09708954127495073, 0.09847025799770692]}, "mutation_prompt": null}
{"id": "79ced7ae-38bb-43d4-869e-a4c2bf174555", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 12 * dim  # Slightly increased population size for better diversity\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.75  # Slightly increased inertia weight for prolonged exploration\n        self.c1 = 1.5  # Reverted cognitive coefficient for individual exploration\n        self.c2 = 1.7  # Further increased social coefficient for stronger convergence\n        self.F = 0.9  # Increased mutation factor for more robust variation\n        self.CR = 0.85  # Lowered crossover rate for controlled exploration\n        self.adapt_factor = 0.95  # Slower adaptation for inertia to maintain exploration\n        self.diversity_prob = 0.15  # Increased probability for diversity enhancement\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Maintain inertia weight longer for exploration\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            # Enhanced stochastic competitive selection\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A refined DEPSO hybrid optimizer with dynamically adjusted components for enhanced exploration and exploitation balance.", "configspace": "", "generation": 21, "fitness": 0.3554918165623417, "feedback": "The algorithm RefinedAdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.26.", "error": "", "parent_id": "09129e91-e886-41de-8702-30f07a664cd5", "metadata": {"aucs": [0.7849011496463926, 0.7746112084714608, 0.7639232188977964, 0.8098220649232863, 0.7719408757497201, 0.7815982402744782, 0.8006084380472352, 0.7794027053406947, 0.7834417145747432, 0.03337173317075104, 0.5634753011216704, 0.563181798539613, 0.542116827719104, 0.5670429610925749, 0.5231884385473227, 0.5361983007858062, 0.6241190680537421, 0.5945061040721936, 0.091806929680047, 0.12341025811044859, 0.11519747764295152, 0.10616687743337205, 0.10640185889607834, 0.13479087495647946, 0.09957538680723466, 0.10450436152899367, 0.09162478650695627, 0.12772188187286737, 0.10764265098558357, 0.1296026433150087, 0.11626569720987356, 0.10275654884075702, 0.09013574253374756, 0.09730678731717457, 0.1034169761822501, 0.10741138292201724, 0.9864437305903411, 0.9872792665037324, 0.9866178221915617, 0.9873894772205659, 0.9858504014850826, 0.9848688152167311, 0.9874465198846529, 0.9842972265662464, 0.9882871223145974, 0.5839822565085897, 0.5884411558978004, 0.5408011015802128, 0.6215119478360286, 0.573392708485784, 0.4855963052766685, 0.614800733597136, 0.5717561204284287, 0.5187064187809057, 0.22119457765407702, 0.7524155565680697, 0.22269700216282073, 0.7923650822510322, 0.18650946472660823, 0.8211591699074684, 0.7602571046020867, 0.22231563701968549, 0.23258553347204347, 0.47224083662955085, 0.5377585744301616, 0.5460279436618602, 0.11932625610768433, 0.12532771071687454, 0.479329663852901, 0.5195851687689562, 0.6532670941841876, 0.4474924990464829, 0.5455967809860791, 0.5015713364263503, 0.42947863326896396, 0.5286290507070215, 0.3915568249653485, 0.5812809076054045, 0.5443562791325148, 0.6020488449123862, 0.5050061564625401, 0.06601749776649335, 0.07084046568258906, 0.4653353896357515, 0.03359311708593671, 0.4341132657822938, 0.1406558661980737, 0.13739784958552104, 0.08397635325028008, 0.25672210026999587, 0.5856563932281826, 0.624815373717474, 0.5692950303060753, 0.1470474622025486, 0.5839557880635007, 0.1226680881079617, 0.630663477950104, 0.4900273616079748, 0.6051177309775557, 0.028586091982274797, 0.10635460509443273, 0.11540053783475812, 0.13545657164136815, 0.20679097337286634, 0.22637848487654366, 0.14421272438442978, 0.10815215297930625, 0.11713827082622141, 0.37685482175484697, 0.15022665696588122, 0.12278164516010459, 0.3151240046882059, 0.2098590767887415, 0.34221492680817955, 0.2387277406864663, 0.052927894500713, 0.30807721533748256, 0.6974815676435019, 0.6987576372137108, 0.6737562567320726, 0.7338524471214101, 0.6092727317113732, 0.6233351418628832, 0.720461577658711, 0.6739066150343529, 0.5667556297312945, 0.07657122098230662, 0.10201068696302085, 0.10923426814769521, 0.12430417987949005, 0.10141877812475852, 0.12830708349486286, 0.16221595254825372, 0.13908637136037794, 0.06668767258358932, 0.35666300979017174, 0.1979710620235563, 0.16881301534761683, 0.20066226102224105, 0.1873065789124867, 0.15835551908923806, 0.2497451674038511, 0.31090413134598904, 0.22636648807570847, 0.29354582062262347, 0.4181177203705534, 0.29834684875446904, 0.36555204188034085, 0.391131183672219, 0.2887134024423996, 0.3848093667920949, 0.468474675117875, 0.4373448469917742, 0.23313965878456022, 0.22034064950533006, 0.24238827799096085, 0.2641197893081543, 0.22630451634951032, 0.2316513055951297, 0.25181360316564483, 0.262740499523755, 0.20768708420220483, 0.25190999691813554, 0.20592910300888068, 0.22263512729736012, 0.23486546560603405, 0.22944276335145908, 0.2136052317215542, 0.21339408901541868, 0.22553792608419476, 0.20936171036818252, 0.1983147689850674, 0.1846758353955068, 0.19647025392764095, 0.21666944541566202, 0.1911804171894932, 0.19174903354273587, 0.18070050520716197, 0.19583448698560535, 0.213915229235924, 0.13474400370503736, 0.18534487706645852, 0.8017702605625646, 0.19435220641992934, 0.19944026129156933, 0.15880299300018363, 0.14011271182435958, 0.15991641934182077, 0.6944802875015581, 0.8018304998694596, 0.21026750379735082, 0.15976154275977894, 0.8190589823781514, 0.16485353513131873, 0.2007459077044954, 0.2065953811929968, 0.20916970156966108, 0.7208113539076884, 0.21825378548477148, 0.19560817681114673, 0.2032530535954058, 0.2106355540645013, 0.19673750753019836, 0.19399271013455865, 0.20884724763919016, 0.21285010163948015, 0.18635163416698675, 0.1191361488082252, 0.10121734261693549, 0.09391032346856498, 0.08147572239910772, 0.10031059164084077, 0.09006005427515862, 0.08935669109444311, 0.08005328336876516, 0.09030718810721117]}, "mutation_prompt": null}
{"id": "940fb6a7-ee7a-480c-9de6-b3fa1e1c904e", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 12 * dim  # Increased population size for better exploration\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.8  # Slightly higher inertia weight for initial diversity\n        self.c1 = 1.3  # Adjusted cognitive coefficient for balance\n        self.c2 = 1.7  # Further increased social coefficient for group behavior\n        self.F = 0.9   # Adjusted mutation factor for enhanced exploration\n        self.CR = 0.95 # High crossover rate for exploration\n        self.adapt_factor = 0.95  # Slower adaptation for inertia to increase stability\n        self.diversity_prob = 0.15  # Increased probability for diversity enhancement\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Gradual decay of inertia weight\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            # Enhanced stochastic competitive selection\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "EnhancedAdaptiveDEPSOHybridOptimizer", "description": "A hybrid optimizer combining adaptive DEPSO with enhanced stochastic competition and dynamic parameter tuning for improved convergence speed and diversity control.", "configspace": "", "generation": 22, "fitness": 0.3674368661802959, "feedback": "The algorithm EnhancedAdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.26.", "error": "", "parent_id": "09129e91-e886-41de-8702-30f07a664cd5", "metadata": {"aucs": [0.7861099665581612, 0.7765819572939414, 0.7578160703084746, 0.7694115402038352, 0.7829240911430133, 0.7873642111958581, 0.7895434434493084, 0.7790868730916323, 0.7804940591220122, 0.5407908223082316, 0.5505196737460076, 0.550460618625191, 0.557730234575425, 0.5498437680324028, 0.4757901750434679, 0.5670514994981165, 0.5136441842618726, 0.552434748292411, 0.16741567989737127, 0.07609776120983514, 0.11521549594221359, 0.07878097152299235, 0.08667738700411942, 0.1481778162267705, 0.14324279301193565, 0.1414073346330259, 0.08033714831664873, 0.11216545152469715, 0.06838107330425514, 0.059668535482291785, 0.08800485834062077, 0.10593830593984599, 0.1036276180074025, 0.09615919762199943, 0.08847046417621318, 0.1067559507203103, 0.98770608124873, 0.9872695156397799, 0.9848018143741002, 0.987480460606015, 0.9879567178529274, 0.9849153250734178, 0.9867671808514993, 0.9870346121391865, 0.988286261439591, 0.6483573144318455, 0.5738814984738916, 0.5592992974600525, 0.3848610179530215, 0.4916152568856875, 0.5524890295920288, 0.3859040320582876, 0.6333985994604545, 0.46902977126578116, 0.17057010987851295, 0.7674341895085028, 0.36803801626966626, 0.26853795625639965, 0.26971569526481187, 0.3529815865981465, 0.7155478065947696, 0.22821551564439901, 0.7596768645398144, 0.3950598920207735, 0.5139259650468505, 0.5036340929810621, 0.49190805032265594, 0.44825624887311755, 0.5890725546199866, 0.48607639584068396, 0.6094542100660651, 0.46820796800294484, 0.4346967937941265, 0.38188013908309126, 0.5899388934317198, 0.5270241141098404, 0.44119580711232453, 0.5256385910911442, 0.5910525250272431, 0.6399006450587719, 0.4811495672614964, 0.11643457388706424, 0.5290894533856076, 0.09160101238401219, 0.4922514213915369, 0.21955187291416545, 0.000537586471131557, 0.15211856185416983, 0.04850408740799961, 0.4397249594481337, 0.5992656737281165, 0.6079269390047364, 0.5635816039585875, 0.5930996864782336, 0.5865093869134657, 0.5437485556683599, 0.5365712697877913, 0.43722344597341867, 0.5416582318945813, 0.04480850006566339, 0.06393651125334199, 0.14627760060674522, 0.17515744556488222, 0.3583544940663763, 0.14641124439797693, 0.16386341003235994, 0.19012893861624403, 0.2393090013907202, 0.3092631475571346, 0.4066807227558903, 0.27870863045862215, 0.1871134085655729, 0.17918260168235634, 0.2941751853173531, 0.18801097207508344, 0.18520740175587758, 0.12294600779775267, 0.6902892525185659, 0.6859842556276322, 0.6386308913875474, 0.7423421276449107, 0.706843967463097, 0.7327751421821593, 0.7221013427515555, 0.7069845762860838, 0.6818301824095971, 0.07919106572213042, 0.12968764313241388, 0.09368543312960231, 0.08676874202603979, 0.14208605905340754, 0.15288275384252448, 0.11070742868053363, 0.09832922323731041, 0.08854191451535864, 0.19537356252495297, 0.2019660170943237, 0.14752230381355325, 0.218065703249686, 0.3746873867367575, 0.2525576530445185, 0.16876970992180118, 0.184730504815797, 0.2494759597239914, 0.4020942580241359, 0.34426294971348725, 0.3032415974496907, 0.41139251591349224, 0.3450070932484991, 0.3298675007241584, 0.27274149570440287, 0.37763477536305423, 0.477954598447367, 0.29107120969353395, 0.15881505865536294, 0.26472189606909147, 0.27138124030447575, 0.3991129171734399, 0.19597196781920923, 0.3081811867739652, 0.29420703454382147, 0.2047565664828246, 0.23577220505344731, 0.1925348198034923, 0.19370349070566462, 0.20878882192150106, 0.18478779046896765, 0.24240518602536587, 0.2785505017233346, 0.26814782216303745, 0.22203130144020955, 0.1872444733692582, 0.18937112061505224, 0.16737123903205742, 0.19342773491805176, 0.18242368021033895, 0.18545313155254528, 0.18375198364250367, 0.17826683428099133, 0.1712944950517754, 0.19210545630759202, 0.8483334179403738, 0.1869796120010433, 0.16313381332112586, 0.1993196494574644, 0.8060221784455226, 0.14161372049066345, 0.16251402891907307, 0.19223418880085752, 0.8158165775623178, 0.20865587187172463, 0.12361606867213559, 0.7959135044534457, 0.16620122869607346, 0.19800160157454538, 0.208034123569095, 0.7958921309394227, 0.8258976509155791, 0.19888800820739538, 0.1855392673148103, 0.190221420945753, 0.2106545013712383, 0.21185709367562988, 0.19917219779497897, 0.2110389913120393, 0.19983648057887626, 0.181661806782482, 0.09632575395335408, 0.08812524018431034, 0.07969549533625575, 0.09726280167154677, 0.08596742179433281, 0.09543936256303698, 0.09431155973173411, 0.08708533887741343, 0.1095429250450235]}, "mutation_prompt": null}
{"id": "edd3a1e5-9f89-4136-866b-08a2268449ae", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.75  # Adjusted inertia weight for balance\n        self.c1 = 1.5  # Adjusted cognitive coefficient for exploration\n        self.c2 = 1.5  # Adjusted social coefficient for balance\n        self.F = 0.9  # Adjusted mutation factor for diversity\n        self.CR = 0.85  # Adjusted crossover rate for stability\n        self.adapt_factor = 0.95  # Enhanced adaptation factor\n        self.diversity_prob = 0.15  # Slightly increased probability for diversity enhancement\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Decay inertia weight gradually\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            # Enhanced stochastic competitive selection with random elite\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A refined adaptive DEPSO hybrid optimizer with enhanced random elite selection and modified adaptation parameters for improved exploratory prowess.", "configspace": "", "generation": 23, "fitness": 0.3809117191673143, "feedback": "The algorithm RefinedAdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38 with standard deviation 0.27.", "error": "", "parent_id": "09129e91-e886-41de-8702-30f07a664cd5", "metadata": {"aucs": [0.831632500025667, 0.8043020926108138, 0.8137953329234686, 0.8274765110811133, 0.8311380488289544, 0.8012310515790594, 0.843080580618218, 0.8235391943889432, 0.8085760450179432, 0.6754432939089631, 0.653576607029277, 0.6499455116603493, 0.585592170026765, 0.4556579972242325, 0.5527382398929085, 0.6656624636450501, 0.6183308104148959, 0.5690160106908231, 0.14763554047071126, 0.1015364916755307, 0.1332098144992464, 0.1714841379542853, 0.08862797819877855, 0.11273685100379893, 0.08019453722767611, 0.11405442254423814, 0.14685691961767244, 0.08888964937373678, 0.07380635928039514, 0.10330567260093426, 0.12978690088781664, 0.1063442693992569, 0.09430534748736896, 0.0672010136139306, 0.08824615256984858, 0.12171062508116681, 0.9895205785788663, 0.9862933017618821, 0.9873616884880604, 0.9817750156645958, 0.9863156633964751, 0.9692405027407452, 0.979073126415276, 0.9890454898243198, 0.987214951407475, 0.6614752377252727, 0.6466750001986936, 0.5267867977584646, 0.6790981150035128, 0.642522850944889, 0.6253667444164777, 0.6940190378736504, 0.6185771078553302, 0.6791923073447212, 0.8657289167945273, 0.7817684454947431, 0.8088024415253908, 0.21068382129354157, 0.27295921914112664, 0.15765517110525307, 0.7946033628120241, 0.3515498588345307, 0.2316185126045749, 0.60059730531553, 0.418056687259, 0.46523271960232093, 0.5598454566012501, 0.675058281252277, 0.5287327685878703, 0.6197501925136728, 0.58898485507913, 0.1265258864658817, 0.5986646490080794, 0.34474579595413857, 0.5036679097436898, 0.5866337001726158, 0.6271031699264427, 0.5642002377600703, 0.6601577999759655, 0.12756290462086783, 0.5507981356927272, 0.06124195343916161, 0.06390710750867457, 0.06849897560777951, 9.999999999998899e-05, 0.24093032035173223, 0.6120904943085249, 0.4218624063231122, 0.1770023988465499, 0.18046769612845237, 0.3832572757910935, 0.27418972633669214, 0.26729683307173524, 0.6321733456142848, 0.23028186678676787, 0.10062970749579092, 0.6062675772330213, 0.4549232782094307, 0.34370121931163866, 0.10125046005594873, 0.15526525123728985, 0.15954106820983693, 0.1569815156676525, 0.375028177766461, 0.3473303508104022, 0.1871308570990402, 0.13816969575526894, 0.1462325090760651, 0.2695436635294113, 0.3370776523760778, 0.25442971351720545, 0.4622758468133331, 0.22664199650180372, 0.21294938317034307, 0.046682820033440264, 0.08485843348879263, 0.07802948523932851, 0.766455692263372, 0.6956393348695216, 0.6887533213259416, 0.6981097054075702, 0.6568754385437765, 0.6289573959219394, 0.6608148557025246, 0.6934465714705595, 0.6814675602374383, 0.10569105806194179, 0.13608660568462838, 0.06799016850346284, 0.10804808814332012, 0.10469673256217615, 0.12330592509910454, 0.14945344090981338, 0.0800998860655312, 0.1061348065066432, 0.18803574737187878, 0.18476371353650234, 0.20395412207622332, 0.26764298988603463, 0.20210973961915146, 0.19972635252949156, 0.2578209748652217, 0.23811304272346812, 0.18498354478011603, 0.4323413985031649, 0.3919379355904802, 0.36074429649058926, 0.4206020914454859, 0.36559768789671143, 0.3973457352319588, 0.3772441632386566, 0.42969510132785405, 0.29642966682396665, 0.23088718941800457, 0.272852753682976, 0.35335760307579844, 0.2255480313214232, 0.39228877667526085, 0.36244981417318844, 0.26879662997798426, 0.3159005649852066, 0.3129841109108149, 0.1987291690805454, 0.2368050141630541, 0.20729618659870008, 0.20882857036338298, 0.26501965522303517, 0.18621744776309312, 0.24596403706151326, 0.19811567043936829, 0.2386518947064451, 0.20374927593594105, 0.1964364687675061, 0.20624911489445208, 0.1720064380291102, 0.21386730169315082, 0.19539764544049243, 0.21149630986915346, 0.20482078908065304, 0.2119166410613631, 0.8835318121709543, 0.15758976199354724, 0.15237785853216979, 0.8699425710341617, 0.1969405792253659, 0.1943624833624199, 0.14151063608423797, 0.8501249220158619, 0.8448558701743037, 0.864747525761278, 0.21145857383258648, 0.7990907131546013, 0.8399015368869776, 0.16779688506702972, 0.7772720696429998, 0.20811632533779423, 0.2844788981426569, 0.12678587254603058, 0.18139897324155696, 0.2674746620556486, 0.19876051964702524, 0.19551136587375773, 0.19464972235466826, 0.18764005946530404, 0.19688969531449152, 0.21758010301797703, 0.1971498325341955, 0.09695601715607083, 0.10224147297316288, 0.10323093685686469, 0.10205828988536192, 0.10204623412962122, 0.1067494988563703, 0.09738849637619862, 0.09507781360408718, 0.08534482592278403]}, "mutation_prompt": null}
{"id": "72492d71-4bb3-43a0-99b6-9c95f401d104", "solution": "import numpy as np\n\nclass EnhancedDynamicDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 12 * dim  # Slightly increased population size for better diversity\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.8  # Adjusted inertia weight for improved stability\n        self.c1 = 1.7  # Increased cognitive coefficient for enhanced exploration\n        self.c2 = 1.4  # Slightly decreased social coefficient for better balance\n        self.F = 0.85  # Slightly reduced mutation factor for controlled diversity\n        self.CR = 0.9  # Increased crossover rate for higher reliability\n        self.adapt_factor = 0.98  # Reduced adaptation factor for gradual change\n        self.diversity_prob = 0.25  # Increased probability for diversity enhancement\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))  # Adjusted velocity range\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Decay inertia weight gradually\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], -1.0, 1.0)  # New velocity clipping\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            # Enhanced stochastic competitive selection with random elite\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "EnhancedDynamicDEPSOHybridOptimizer", "description": "A hybrid optimizer integrating adaptive DEPSO with dynamic elite replacement and enhanced velocity adaptation for diverse exploration.", "configspace": "", "generation": 24, "fitness": 0.34941963188037084, "feedback": "The algorithm EnhancedDynamicDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.23.", "error": "", "parent_id": "edd3a1e5-9f89-4136-866b-08a2268449ae", "metadata": {"aucs": [0.6968333456901485, 0.7190345323009202, 0.6954486762746498, 0.6760686316372257, 0.7100690729774127, 0.6803859032166417, 0.7186906129238984, 0.7094369121675057, 0.690356592667408, 0.4112616883945366, 0.39013520628074916, 0.39183481936727893, 0.3460581326415324, 0.3278682296428219, 0.38201824149456054, 0.3749541799201326, 0.3568034567942091, 0.36809391769853717, 0.1283652948153614, 0.11003200543630132, 0.10159418341630566, 0.1128962460359193, 0.11942305141135767, 0.3157331616811866, 0.12804318930506708, 0.4081490225579695, 0.09149261449965562, 0.12070287886930486, 0.13973453383543033, 0.09972115751779564, 0.112622644703544, 0.13611750066930106, 0.12934678000345734, 0.12345540222557083, 0.10732269079212742, 0.10163609698441978, 0.9163849674851238, 0.8873395726767677, 0.9080467054177366, 0.9086452952239318, 0.8742812971931083, 0.8827998775532316, 0.9068711627421541, 0.9094083588447557, 0.903032370032919, 0.542634543943407, 0.5238478441819646, 0.4501582864101952, 0.5169905364898297, 0.4844823368324285, 0.5226897415581995, 0.5046242673665582, 0.5423732905390334, 0.5176571827678738, 0.6928710503394251, 0.7415723839546811, 0.699015223298201, 0.6915363779138879, 0.668601064891031, 0.20078296667850293, 0.7381764068440395, 0.23221792199520364, 0.658943094321861, 0.463486357137433, 0.4192466740884182, 0.4269941930405954, 0.4343092067538882, 0.45916122521402647, 0.2763429992101256, 0.12402155031385265, 0.44240151807940464, 0.12724644500454307, 0.4619025259715207, 0.5039921179701001, 0.4582588895476122, 0.5036543730601275, 0.4974569532751014, 0.3757996125117894, 0.39343517848497533, 0.4232800078324852, 0.5131301492722566, 0.29748497959813447, 0.08310705897532533, 0.09262309441722194, 0.1256054949467823, 0.3563190968469616, 0.36122285457062364, 0.09314411383271892, 0.19900135048561673, 0.33995003837192694, 0.3640452954021133, 0.3430269957643646, 0.33554596395395664, 0.14617349408078595, 0.17021744402297645, 0.12742841283929884, 0.2515789307548145, 0.39478851368790524, 0.19050397399515706, 0.09471600507833078, 0.2045244712557942, 0.1173633839778726, 0.12395715443332211, 0.15824628620829373, 0.12402945181509928, 0.1524695743930652, 0.16295499135684222, 0.19564881011964885, 0.19697093806230137, 0.2533585618966181, 0.1590488815024952, 0.18520218163260838, 0.3172415558392804, 0.26615151117820346, 0.2132532859434383, 0.22231005996418485, 0.07260696948314194, 0.6364598516057296, 0.5809642905959008, 0.6188252894842867, 0.6225484780260264, 0.5853709308324635, 0.6325884088384767, 0.613590258165919, 0.5927352839298743, 0.5870608028037774, 0.11015628336279859, 0.11249253606866838, 0.08857810213230966, 0.11324488423277213, 0.12519709032680437, 0.13735331588154387, 0.1360866934342011, 0.14569546919103882, 0.10238898192295565, 0.21183154891665035, 0.21429649058079325, 0.17224824191125065, 0.18155639120228562, 0.19880724290537488, 0.25572135583988775, 0.15790890884910314, 0.20705015918608638, 0.20117859937794924, 0.3960994359770197, 0.4025085004671468, 0.3141484162911261, 0.3654934273681204, 0.3797337206149294, 0.34639535378757025, 0.3454435137738112, 0.4413313380763745, 0.3554746373768213, 0.27206585773623315, 0.2307923540295097, 0.3506339907739012, 0.358937299339685, 0.2556757480408346, 0.2958533765686042, 0.2441177092717517, 0.21408387734416734, 0.2437814605460894, 0.22750517076925414, 0.18946655414096114, 0.22179078098480187, 0.21963529333592313, 0.2215062379846855, 0.25450001039441217, 0.28987446865526556, 0.2165927261467263, 0.21929756712102788, 0.19666962270595245, 0.1865096504576772, 0.18991234311511318, 0.20239122654635677, 0.18796182437106979, 0.20343700818469046, 0.18916782544205812, 0.17531772947351787, 0.2267887037608478, 0.8045580116384933, 0.184479840516104, 0.16551918704585622, 0.837753041274423, 0.7679278163794183, 0.7831487991394794, 0.8116169361768609, 0.16358282245816969, 0.7875694107725909, 0.7738184916138233, 0.2080364429025856, 0.7236064279044968, 0.20483370914772536, 0.1500962029455457, 0.1994991530705822, 0.731410088758459, 0.7575577096177011, 0.7339954002716108, 0.1946201531389471, 0.17749265161377537, 0.1983282917983371, 0.19991678804034418, 0.2009895372553251, 0.18970828107559246, 0.20781817671676484, 0.18416065033612494, 0.18591230479212506, 0.0969439541867052, 0.11183477028845223, 0.09012621530911347, 0.09484504630879786, 0.09462269353064912, 0.1439714376463096, 0.09247539828107187, 0.10156244327020014, 0.0938056585567989]}, "mutation_prompt": null}
{"id": "a8a3c543-f806-4c06-9ad6-2e46fa209804", "solution": "import numpy as np\n\nclass ChaosAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.65  # Adjusted inertia weight to enhance convergence\n        self.c1 = 1.4  # Adjusted cognitive coefficient for slightly more exploration\n        self.c2 = 1.6  # Adjusted social coefficient for slightly better convergence\n        self.F = 0.85  # Reduced mutation factor to focus on exploitation\n        self.CR = 0.9  # Increased crossover rate for better trial vector generation\n        self.adapt_factor = 0.92  # Improved adaptation factor to stabilize learning\n        self.diversity_prob = 0.2  # Increased probability for diversity\n        self.chaos_factor = 0.1  # Introduce a chaos factor for dynamic behavior\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Decay inertia weight gradually\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]) +\n                                 np.sin(self.chaos_factor * self.current_eval / self.budget))\n\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "ChaosAdaptiveHybridOptimizer", "description": "A stochastic hybrid optimizer incorporating a dynamic chaos-driven component and adaptive feedback to enhance exploration and exploitation balance.", "configspace": "", "generation": 25, "fitness": 0.2597498674469825, "feedback": "The algorithm ChaosAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.23.", "error": "", "parent_id": "edd3a1e5-9f89-4136-866b-08a2268449ae", "metadata": {"aucs": [0.5347669807118555, 0.560483868518465, 0.617172410615517, 0.5862826959396861, 0.5595268711019614, 0.5348734337999252, 0.5741922688747068, 0.6099795631734477, 0.6188475562554008, 0.10955861096130937, 0.06910075761637569, 9.999999999998899e-05, 0.09207804970139732, 0.09806354949678009, 0.08971317557476555, 0.08559913235462369, 0.11211409914547854, 0.141239177215291, 0.1458378161997771, 0.10038256933612355, 0.10049741888380637, 0.13875151593304358, 0.12434452707477162, 0.10157105307163561, 0.11125217428501477, 0.1382224968030289, 0.14933175362425133, 0.146255518840259, 0.09055589953445142, 0.10527016351274687, 0.08639193898094855, 0.08955106850189964, 0.1298085524067083, 0.1326447359275117, 0.12849714385431943, 0.10940312076718584, 0.9890547401122602, 0.9900874595898923, 0.9821579716214087, 0.988271031004077, 0.9863820667295585, 0.9692959266208107, 0.9721744523332985, 0.9890643914851671, 0.9877884466510871, 0.4111608077955219, 0.31568053078396097, 0.32423437285589285, 0.359517698001508, 0.3174019515726787, 0.33062053645300715, 0.08716582787680494, 0.31744142098124617, 0.3722500329639655, 0.21432984539245525, 0.8151791722788868, 0.3485453143800207, 0.20567284799961094, 0.7667703378056634, 0.3420805630841297, 0.23946884084028508, 0.7329340045644933, 0.2358785664078017, 0.2862863925352559, 0.09308842455072386, 0.27738074857625405, 0.09757527952699296, 0.26552772950567527, 0.3075826686749067, 0.24511807873094815, 0.34206622722510405, 0.3257932780289625, 0.22479103551217605, 0.1237769225706099, 0.12526023256894891, 0.1818857729527521, 0.1589103807032689, 0.18228228892193987, 0.12808151948804025, 0.16844163677799462, 0.17727553873957347, 0.06570064899430794, 0.10333435113286049, 0.13404213508255436, 9.999999999998899e-05, 0.06676556303533365, 0.07807468939306983, 0.010213840543534913, 0.10130435676947314, 0.003503743022183703, 0.12985062483564358, 0.08188877724436572, 0.11351765625769272, 0.1529378470752355, 0.15756237461872535, 0.09865313590070912, 0.12844093153470582, 0.10636216170500279, 0.12863841484089078, 0.01939921108314613, 0.04021093959211253, 0.0734825689586105, 0.04387387026073741, 0.08867221945350978, 0.06754120692980559, 0.04798617274778405, 0.07020734926052485, 0.05574083230918969, 0.19077455421471345, 0.1384253368120575, 0.07869270531912664, 0.17386556495230798, 0.1590641553878851, 0.17056352501662642, 0.06780733370442826, 0.16602486337213618, 0.08074303921138248, 0.45379694875921994, 0.4823378829562772, 0.4736857644450251, 0.44158688299733495, 0.4421256288855645, 0.4522290784478591, 0.45429403747452657, 0.4517355584905425, 0.47203097311781206, 0.08519877397744435, 0.1356156273269047, 0.16465992217620984, 0.13861280393876863, 0.12115626267668556, 0.10476599928729213, 0.14694701333973914, 0.14503279430861127, 0.08982418003576098, 0.306509520899341, 0.23273741248042068, 0.2713550848640327, 0.37822873546283153, 0.24929211955375574, 0.18114308038743476, 0.30463003119804166, 0.2438220350261161, 0.16812005092784188, 0.30129684083249864, 0.2944819255249519, 0.3298734214260429, 0.3815646018700275, 0.2590075280253502, 0.33530328914354945, 0.33151901407802975, 0.28632351816472545, 0.3620376184752204, 0.23356716892800533, 0.23129362865133485, 0.21560873675646108, 0.29318595833680716, 0.2835914723795555, 0.1807321505659777, 0.27005461520128526, 0.24600656399547305, 0.2268387768013741, 0.21310242190821016, 0.20154215573244538, 0.20059380505473134, 0.24249479249572425, 0.23567888829061434, 0.19534600981904104, 0.20583448625707124, 0.2292828432246674, 0.22390223763318096, 0.1704593575239327, 0.20651682466036836, 0.1781470099346465, 0.19077046701075373, 0.2231558643383994, 0.1818945561346026, 0.19907955898174423, 0.35082909522070593, 0.19562656367496523, 0.16696817453303758, 0.16267749360080597, 0.19706159774952603, 0.19879680906174257, 0.19935503054380566, 0.19721534826141307, 0.1477248478403097, 0.14827343153227956, 0.8396496262048505, 0.8600879854794385, 0.21211535370483625, 0.1652442626995898, 0.852617456172905, 0.20209123500971826, 0.7581432787160447, 0.21258055444993262, 0.08370355868640833, 0.7101452731803668, 0.17322798959152041, 0.1817403263874623, 0.20119038285050395, 0.1942955702798721, 0.1833717010479069, 0.2059266393414092, 0.19124105299655936, 0.17730961773893705, 0.17475473160917387, 0.08711622394535357, 0.08851088807338148, 0.09778605963310161, 0.08914965661759178, 0.07618456243880423, 0.08240337919832041, 0.0978008503789819, 0.09415236342266942, 0.07937840213331915]}, "mutation_prompt": null}
{"id": "f1de49e0-fa67-4cc6-ad1b-5acddda8b9c5", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 12 * dim  # Adjusted population size for better exploration\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.65  # Further adjusted inertia weight for control\n        self.c1 = 1.7  # Altered cognitive coefficient for enhanced local search\n        self.c2 = 1.6  # Balanced social coefficient\n        self.F = 0.85  # Fine-tuned mutation factor for diversity\n        self.CR = 0.8  # Adjusted crossover rate for explorative robustness\n        self.adapt_factor = 0.9  # Adaptation factor for dynamic control\n        self.diversity_prob = 0.25  # Increased probability for diversity manipulation\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Continuously adjust inertia weight\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "EnhancedAdaptiveDEPSOHybridOptimizer", "description": "An enhanced adaptive DEPSO hybrid optimizer tailoring dynamic control parameters and elite selection for improved exploration and convergence balance.", "configspace": "", "generation": 26, "fitness": 0.3815748046046767, "feedback": "The algorithm EnhancedAdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38 with standard deviation 0.28.", "error": "", "parent_id": "edd3a1e5-9f89-4136-866b-08a2268449ae", "metadata": {"aucs": [0.8355409558076017, 0.8494426084577814, 0.8428963889796215, 0.8502852936515759, 0.8621901096656455, 0.8497248109461688, 0.8387232776935258, 0.8459284358315018, 0.8362425413873057, 0.03808480415518245, 0.6212092818697802, 0.6598724132580744, 0.6502034892458568, 0.647123652252421, 0.6890056170188226, 0.6702099755395825, 0.624013855909104, 0.6362004785053328, 0.12207907847920163, 0.17257720538319243, 0.10467972342729026, 0.11439498939861659, 0.13666043391409644, 0.10682223525172652, 0.1108679681777136, 0.14784642832704253, 0.10861616695313658, 0.10773597615856856, 0.0824763932957665, 0.10001990105948755, 0.13541818863283084, 0.09333746487170791, 0.10678260432852493, 0.11449311655902128, 0.09339932778005766, 0.11298007871445048, 0.9872029040341762, 0.9872894199974253, 0.9865901085447795, 0.9868745094722602, 0.9854832635141402, 0.9848641647636192, 0.9867568197531932, 0.9848918714150006, 0.9882765486673663, 0.5007111019665824, 0.608074550285124, 0.5247571953872642, 0.5619436341968036, 0.6399432180851307, 0.6221965875744164, 0.6395661567218133, 0.6591555597139024, 0.5472504531082588, 0.21135012282197585, 0.7800919306743392, 0.22232627742521993, 0.8516069552123506, 0.2628604510316278, 0.2073265396274221, 0.83428349495713, 0.8398019620784158, 0.22748420511413447, 0.67686311890875, 0.5329752656707352, 0.5402159077307994, 0.6893425927037747, 0.5427592297946797, 0.1294594924653657, 0.1261981341808005, 0.5992713769384455, 0.6493406999815003, 0.5938949090212955, 0.44886919828682104, 0.5929113193379214, 0.5950533802181326, 0.5036198518173242, 0.5992240615970458, 0.6958532114694396, 0.5916765446709902, 0.12516503811974422, 0.13382899773215995, 0.2634108234625794, 0.23380247273103594, 0.09074172674597991, 9.999999999998899e-05, 0.205012596259878, 0.12974233392809476, 0.12297059187754622, 0.12847894972749818, 0.3824334532518411, 0.3516044090341116, 0.22886474481398134, 0.6833061490636131, 0.22866670834320746, 0.5369431843452157, 0.5596685980822769, 0.5980103415008682, 0.5231875070604719, 0.05938342188516854, 0.06175585168723552, 0.22798890033483488, 0.15994671754544376, 0.46982615522606996, 0.08792684540425566, 0.12551751453330684, 0.10706358301053553, 0.2116052000276315, 0.27182094151942593, 0.32484617399407356, 0.3881794954252107, 0.26639554796954024, 0.210533602523456, 0.3010891192001802, 0.04802433576686849, 0.05414903593810472, 0.07739605282909601, 0.6957313505423219, 0.6430901707788463, 0.7808067168848984, 0.7527932516594305, 0.639178142675696, 0.7252789241464053, 0.7014624808729144, 0.6694388299173162, 0.6537199387033179, 0.08564285772074787, 0.11019796056272424, 0.10826888698964798, 0.1300085467135199, 0.14999965979111263, 0.13386439071945866, 0.134654412685846, 0.11098594313521026, 0.13323263062529878, 0.20969418297682252, 0.3697136335907768, 0.55423104697274, 0.21084229979461588, 0.3257358828764384, 0.18272518099560775, 0.2417761157850855, 0.45084070110867114, 0.1595061423248919, 0.31744813825732776, 0.2688181347600346, 0.38435525426927664, 0.4125385053764913, 0.317112443709631, 0.24996839494760592, 0.31129982783820487, 0.31560450501811343, 0.2755635656621499, 0.3357005687226233, 0.3154881598444341, 0.20998457100134071, 0.2903080941249575, 0.19814068641145877, 0.22203970851073607, 0.21140353217928587, 0.34463661495035336, 0.212456075483466, 0.2325205994821279, 0.22222149955173254, 0.19259614210465759, 0.2625992558743159, 0.20793472659634304, 0.20853791338893357, 0.24645002533612426, 0.3008286640816966, 0.24304667970593796, 0.1786158990898784, 0.21383636861607402, 0.17632632425439132, 0.24392101743295558, 0.1946813608955963, 0.2101187602952035, 0.20902471008492374, 0.22027433961212806, 0.20167102129658088, 0.18662391353117824, 0.16791359444098253, 0.1865747338708159, 0.8802561179962776, 0.19954127204905214, 0.7380328545019104, 0.14230489207325303, 0.16328028751245316, 0.17780482120464147, 0.854768348127194, 0.6223772766003928, 0.8225357750507345, 0.8751038443426415, 0.16645529734105713, 0.8248608861164217, 0.2009963873038746, 0.7481790167658484, 0.8521606506415751, 0.2037439086091224, 0.18512869532449905, 0.18428291000120556, 0.20053462889801676, 0.1955537548324272, 0.19159368833788915, 0.19684294339685926, 0.20180877733092228, 0.2265578817383479, 0.153786791582323, 0.15020476166341956, 0.11870998187667015, 0.09805224508387778, 0.09719166019349845, 0.07923263991057305, 0.0896549667936275, 0.08091464298075624, 0.1111398835428159]}, "mutation_prompt": null}
{"id": "70461f48-3f9b-4194-96c7-767f57ddfc7e", "solution": "import numpy as np\n\nclass ProbabilisticAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Adjusted for diverse exploration\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.7  # Adjusted inertia weight for fine control\n        self.c1 = 1.5  # Slightly reduced cognitive coefficient\n        self.c2 = 1.8  # Increased social coefficient for better global search\n        self.F = 0.8  # Subtly reduced mutation factor\n        self.CR = 0.9  # Improved crossover rate\n        self.adapt_factor = 0.95  # Smooth adaptation of control parameters\n        self.diversity_prob = 0.3  # Enhanced probability for diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Dynamic adjustment of inertia weight\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "ProbabilisticAdaptiveDEPSOHybridOptimizer", "description": "A probabilistically adaptive DEPSO hybrid optimizer, enhancing exploration and convergence through dynamic adaptation and diversity control.", "configspace": "", "generation": 27, "fitness": 0.3669923001487673, "feedback": "The algorithm ProbabilisticAdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.26.", "error": "", "parent_id": "f1de49e0-fa67-4cc6-ad1b-5acddda8b9c5", "metadata": {"aucs": [0.8209905839734133, 0.7948988957539407, 0.8043779952027457, 0.8144643013884914, 0.8159456948005961, 0.78077919487475, 0.8040583859657413, 0.804052382622285, 0.7911817063983221, 0.5713198754984607, 0.5600012508130159, 0.5949970313016585, 0.038182859558461346, 0.5793283004952844, 0.5848701700759623, 0.6104724025793039, 0.6096036328885139, 0.6014554569133599, 0.14183648854876452, 0.10364394813367839, 0.11162596245866807, 0.10979346467043327, 0.09180269387278317, 0.11997663376769885, 0.08567618809475785, 0.12435490209832933, 0.10049929629157817, 0.08179495969147321, 0.11000205388490636, 0.08743992765526731, 0.07050297676971662, 0.07546703212717498, 0.07572485236591053, 0.09921689714119308, 0.12447775286914275, 0.08630410568793578, 0.9890380295081154, 0.9900498830698867, 0.9880285302344423, 0.9883650227597172, 0.9866934389217962, 0.9690811484789045, 0.9800217824760317, 0.9897854669901295, 0.9886034851999077, 0.5680316713012236, 0.604439382567046, 0.5800444503848121, 0.5170831363743957, 0.5463522108288967, 0.47855450923979237, 0.6106993614493086, 0.600671300439023, 0.628202357991637, 0.2271927044424794, 0.2127182729923951, 0.34205617375753894, 0.791602738674029, 0.19072381653212533, 0.8171684804612077, 0.7830374805985119, 0.12719583061267548, 0.7819817995099814, 0.6923435855590121, 0.1149571356890492, 0.5258504787896456, 0.3616933783067541, 0.6239094612650655, 0.118715055993593, 0.5739347797653274, 0.623387957289457, 0.5121767824959564, 0.5205894997708687, 0.4281737217669308, 0.4507775165037694, 0.5853941884329382, 0.6088413806481339, 0.4246412363283546, 0.6841245967676313, 0.46484088361910936, 0.5012015919482158, 0.17285186949702036, 0.18306955817854098, 0.4611225436310151, 9.999999999998899e-05, 0.555216924821923, 0.11091565466652431, 0.3215149926229044, 0.27763076357093164, 0.28159312044983287, 0.07876190463122601, 0.3136915332677116, 0.3237014396576754, 0.5006711703093367, 0.3171016603894412, 0.40970752787736475, 0.4862760945196265, 0.513725636509744, 0.43279618232561456, 0.09869408644077993, 0.04409125674555747, 0.19480866858432144, 0.44253344056183896, 0.19766609493305365, 0.08587647182936309, 0.12176401094672129, 0.1047579130902786, 0.11557838807977427, 0.2484397015528913, 0.374542518640704, 0.20941970927088138, 0.24715866739438497, 0.37869818252924425, 0.42543725394340004, 0.12442949195130093, 0.2266343465196815, 0.09730137683477091, 0.7287831483931787, 0.7292902446156035, 0.6847709985856787, 0.7002443664563885, 0.713415430138401, 0.7314509852853894, 0.7182223544994183, 0.6791180494150543, 0.7135233036594466, 0.08575939422938705, 0.11112640841771881, 0.10958310872710864, 0.12946292410195215, 0.10396683098886006, 0.10204096550103481, 0.09000251554065375, 0.16989402190609149, 0.1592202463874548, 0.23511612544106608, 0.1769738000222687, 0.3819158859340379, 0.3101982123630962, 0.20579445497714288, 0.14679967833734286, 0.3893321312088507, 0.14711236852235232, 0.21151795375706062, 0.2726653875309878, 0.2756185827441199, 0.31555628681169634, 0.3051576621824973, 0.46754381358473807, 0.2760860759798289, 0.3685950275684611, 0.5058284407171658, 0.37754502329097095, 0.1919869937878914, 0.1935766681537413, 0.32293100422839494, 0.30288775195768003, 0.2271749560246863, 0.3655285011457936, 0.2110493334658501, 0.23224446507077545, 0.20085215237144938, 0.224542278631095, 0.235575187701206, 0.1894227905350876, 0.2248912287770568, 0.19303712417387275, 0.23127047911576593, 0.20419774822186731, 0.24690037179609947, 0.23433988672790373, 0.21069101830889292, 0.18212349236743064, 0.18148766172273112, 0.17967379702567432, 0.2383078922206764, 0.17797264638113353, 0.20447491690648356, 0.21492527991531551, 0.1980675655882923, 0.18449744590063533, 0.18521702962763886, 0.209005859119076, 0.1967910817002162, 0.2706307667366019, 0.20390417667151106, 0.8369907149215065, 0.14706722381893345, 0.16999398076164562, 0.8399578530256725, 0.21107060322703575, 0.6838980707169552, 0.20164796574733912, 0.6876988852647036, 0.7876157356930005, 0.2087817341406053, 0.7023751927624131, 0.6864726190370264, 0.18479400290911385, 0.19367561750893791, 0.19945154024505563, 0.20329748005601334, 0.20564496112036423, 0.21749355793736835, 0.2183984298783137, 0.18616423799215664, 0.17700606375599603, 0.11957090609360799, 0.09112965926619931, 0.09022985708566844, 0.09643066271848488, 0.09715442184471268, 0.09421696636706145, 0.09556696606604531, 0.08965986636595935, 0.09509318515988885]}, "mutation_prompt": null}
{"id": "d6ddb42d-c79b-4d47-9330-829fcfaf6456", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 14 * dim  # Slightly increased population size for exploration\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Altered inertia weight for refined control\n        self.c1 = 1.8  # Enhanced cognitive coefficient for stronger local search\n        self.c2 = 1.5  # Adjusted social coefficient for balance\n        self.F = 0.9  # Increased mutation factor for greater diversity\n        self.CR = 0.85  # Modified crossover rate for improved robustness\n        self.adapt_factor = 0.85  # Adjusted adaptation factor for better dynamics\n        self.mutation_prob = 0.3  # Introduced mutation probability for diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Continuously adjust inertia weight\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.mutation_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "EnhancedAdaptiveDEPSOHybridOptimizer", "description": "A hybrid optimizer integrating adaptive DEPSO with a probability-based mutation strategy for enhanced exploitation and exploration balance.", "configspace": "", "generation": 28, "fitness": 0.3415008633256566, "feedback": "The algorithm EnhancedAdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.26.", "error": "", "parent_id": "f1de49e0-fa67-4cc6-ad1b-5acddda8b9c5", "metadata": {"aucs": [0.8550898723848739, 0.8444127082061517, 0.8500984286814337, 0.8347767024609539, 0.8554254885036535, 0.8657816825458042, 0.8341327085946364, 0.8538047960827142, 0.8647046825351978, 0.6269580130487884, 0.6008750712795033, 0.6350156503598365, 0.6445765977637534, 0.5833979051442875, 0.5722317462857771, 0.6216825639346445, 0.6442811069335974, 0.5469556421456625, 0.11443035955685321, 0.171642323770539, 0.13761873049371787, 0.12845686784940336, 0.1192117487244092, 0.08013201446161222, 0.12582901666209578, 0.10314829185010954, 0.11081272734961622, 0.08190675164986327, 0.10370338281773439, 0.11353141420829538, 0.11144315015481554, 0.12496890965435048, 0.09511121060546757, 0.1146349439456622, 0.1281470264498552, 0.08851862330848237, 0.9830280189294073, 0.9858546360931503, 0.9816955369199971, 0.9810736999988416, 0.9823631613710098, 0.9681347233602549, 0.9856410044351248, 0.9818993145076799, 0.9851996321321225, 0.5700875915164747, 0.6138784513567495, 0.5093698423078817, 0.5468324944747319, 0.5099627282202626, 0.48065813219593734, 0.6027426877456654, 0.4378634261673511, 0.44265794367446276, 0.36809941280907454, 0.22396091950502728, 0.8481035795146604, 0.2102811645770356, 0.18573924688147259, 0.18943500255628543, 0.22880497935719102, 0.17249151413000507, 0.747806384058537, 0.2688209432857812, 0.3780352213644672, 0.6015969864755797, 0.09442782874104383, 0.1167558088462789, 0.7589716657229874, 0.11489170814972038, 0.46282168942928736, 0.6107567080748888, 0.5145676797202114, 0.12491811854120882, 0.44208454545559017, 0.4962443588903933, 0.567157020922012, 0.6551309463051112, 0.6237437741059935, 0.34467137281313676, 0.1274106827286663, 0.39296534030424235, 0.05086643603603147, 0.20501049003836558, 0.02214409901648029, 0.032499518782469705, 0.08472803761399139, 0.4185599456502862, 0.20444805740768046, 0.18259070726571813, 0.14158083841049462, 0.45848199938184, 0.2387228539214512, 0.23599290986340926, 0.18177033830257416, 0.20783915261859875, 0.4127064802686681, 0.5606251847630834, 0.6517136867492592, 0.18959146879602207, 0.1864932180776484, 0.1616690588345604, 0.14471724335509095, 0.23770025163639041, 0.2669304430309922, 0.23234312295133153, 0.14668350988383572, 0.09595357164544915, 0.3222104298520819, 0.21454201037585008, 0.21778839403670458, 0.24618296172634513, 0.3043049153322338, 0.19871524401181784, 0.12456701104270762, 0.0609260258787544, 0.08027569257137279, 0.6920574073301882, 0.6286340408822193, 0.7233586166093333, 0.6132423501369165, 0.573157428373974, 0.6524739698284776, 0.699986912055975, 0.7074242146954709, 0.6254333995954007, 0.11131864811047765, 0.11098994469363166, 0.08333672398745662, 0.10359143006002891, 0.13724315864002712, 0.08731887569156571, 0.12786054119038726, 0.09063156201153666, 0.11587782755535914, 0.20327569691167502, 0.1899077747425083, 0.17017233329535975, 0.24423336899470682, 0.2482235372482856, 0.1575136095002927, 0.17575323421595224, 0.2347987389572166, 0.2499982899489026, 0.3667289884578733, 0.25561911959361006, 0.3266573045148461, 0.2830158608470287, 0.2940982109148259, 0.39155185626172984, 0.24911286821149825, 0.3733190989332711, 0.2714289799812719, 0.2620112554834314, 0.323572172704626, 0.25203688024557136, 0.170647240828676, 0.1889125736528917, 0.22100510161033826, 0.23418435416687455, 0.23905548977631097, 0.15874850546486252, 0.2314535382230163, 0.20780686771387746, 0.20220325819317353, 0.24436676834742999, 0.2271940451196207, 0.2081177372575458, 0.2195677026705437, 0.22047547170706372, 0.25843332591234747, 0.17867774574412465, 0.20766106836635867, 0.184899264649252, 0.19383472337855479, 0.18844994524790692, 0.18303601892897736, 0.18366541934093994, 0.17421049157927082, 0.18196776999399022, 0.13039281792000146, 0.1869686838048501, 0.19258913239587105, 0.8638112374153823, 0.19861231453839068, 0.1456757878184055, 0.1821607132449805, 0.19423870250412223, 0.8696584313358049, 0.8808000708512345, 0.20885651005744943, 0.7980248901374876, 0.20284946733649045, 0.20108938601564275, 0.15405568066680664, 0.13603518892320576, 0.14540735002403704, 0.8397742145050909, 0.1809154085080502, 0.1971750868557156, 0.1898056488838017, 0.2063539383067845, 0.19598780132869864, 0.189471778449814, 0.19700789253248463, 0.19245066688219292, 0.19073451343249137, 0.10637306484043041, 0.10210137450818324, 0.07645605983938253, 0.09618638464154305, 0.09084518153420884, 0.10338740771419908, 0.09256243203020154, 0.09142217018872545, 0.08944663087607185]}, "mutation_prompt": null}
{"id": "53977b99-3bfd-4344-b29e-c7b3fe6cf9b0", "solution": "import numpy as np\n\nclass AdaptiveQuantumDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Adjusted population size for diverse exploration\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.7  # Adjusted inertia weight for convergence control\n        self.c1 = 1.5  # Re-balanced cognitive coefficient\n        self.c2 = 1.8  # Enhanced social coefficient for better global search\n        self.F = 0.9  # Dynamic mutation scaling factor for greater diversity\n        self.CR = 0.7  # Reduced crossover rate for stability\n        self.adapt_factor = 0.92  # Adaptation factor for inertia\n        self.quantum_prob = 0.3  # Probability of quantum-inspired updates\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Adjust inertia weight\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.quantum_prob:\n                for j in range(self.pop_size):\n                    quantum_step = np.random.normal(0, 1, self.dim) * (global_best - pop[j])\n                    challenger = np.clip(pop[j] + quantum_step, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "AdaptiveQuantumDEPSO", "description": "Adaptive Quantum-Inspired DEPSO with Dynamic Mutation Scaling for Enhanced Global and Local Search Synergy.", "configspace": "", "generation": 29, "fitness": 0.3562263144028589, "feedback": "The algorithm AdaptiveQuantumDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.28.", "error": "", "parent_id": "f1de49e0-fa67-4cc6-ad1b-5acddda8b9c5", "metadata": {"aucs": [0.8320689079520921, 0.8254559783490876, 0.8358031433961071, 0.828084320800547, 0.8332448063404754, 0.8313332095015754, 0.8336509042388134, 0.831151824060398, 0.8354367944184727, 0.6600562256589089, 0.6765344025117768, 0.6726876251939098, 0.6782424147138106, 0.7021048653215763, 0.6332380159515444, 0.48123220545254053, 0.6978821666121322, 0.675851372286374, 0.07956622367809363, 0.13491420093276263, 0.15262678835093357, 0.14439234626106046, 0.11390526283248126, 0.12214407163702612, 0.10825662845361972, 0.11717189806536843, 0.13129895034271954, 0.10545868527412727, 0.0935159444823952, 0.1051919920754335, 0.10435892597464735, 0.12882868035264383, 0.14454034029420504, 0.1418629587905118, 0.09161024259201622, 0.09104072522391893, 0.9894511412551555, 0.9863490273032136, 0.9872121026536109, 0.9896585341341083, 0.9862347092368832, 0.9897881830519832, 0.980346865007874, 0.9816781284472972, 0.9872749667471544, 0.6329529135373306, 0.7036424447274177, 0.5913643390724845, 0.6573649195835047, 0.6795463216995388, 0.601080194643263, 0.6053097374196761, 0.665544281150484, 0.6526335886558242, 0.6739774236947464, 0.8427969498890097, 0.8260352283865143, 0.27146423041576995, 0.19141323375794983, 0.8501262545592433, 0.2249622120278849, 0.22243207882515237, 0.8451177783115271, 0.71208888254948, 0.4672158680280448, 0.6106508935829512, 0.09985654063237304, 0.12929808013850597, 0.662847485825214, 0.6148583373236773, 0.12464942589866712, 0.12953842534273208, 0.5550505648279056, 0.051035979855397096, 0.12846118570643916, 0.12607020671484648, 0.5614562567640813, 0.12810080735997942, 0.7216628618615202, 0.10912207963582532, 0.11608645596100364, 0.09781936270214298, 0.058176679669915354, 0.0597488013148153, 0.0006217376315981182, 0.1571906302372017, 0.14743314628636894, 0.08210241728239798, 0.12139143885162762, 0.05051566023741472, 0.24072282908091913, 0.36326290925941307, 0.3936608948080663, 0.29555001625879496, 0.28126080021327515, 0.22619512705290168, 0.2141004780253697, 0.41282623746526725, 0.5395417464647363, 0.19189209395485285, 0.03217709685387604, 0.27222912636786256, 0.4551215713712028, 0.382112466704271, 0.2358047964507748, 0.13252387988527314, 0.23181512803956117, 0.10509947630286476, 0.17123624663814552, 0.2682527471698849, 0.2763506411279374, 0.44605018933674223, 0.24474101892744748, 0.23688601535670573, 0.18239303577468402, 0.26442076029153494, 0.07839471826630506, 0.6841805741547282, 0.7258305585796282, 0.7201290766303494, 0.68505443939553, 0.7554069864096693, 0.6640988220928175, 0.696645469763499, 0.6864205378784209, 0.672533865090559, 0.13899364383066537, 0.06202238030811791, 0.09534835026662403, 0.10504898235405213, 0.09024497021839428, 0.13493332553534032, 0.12321168312646025, 0.08045715896716266, 0.1217751913415579, 0.18732042006810457, 0.3665943515113671, 0.22846854325373045, 0.27771557179968953, 0.4625004423956217, 0.20792328584719444, 0.6227032118879319, 0.19451611465710128, 0.21499474435950305, 0.17802051394929985, 0.48103026146310834, 0.283975858351622, 0.4142800679383014, 0.24756638147693988, 0.24422766894749726, 0.3652187344380563, 0.4012494271737591, 0.27010378873738405, 0.286579178862031, 0.22698535269905284, 0.23752980027414783, 0.30180961902155434, 0.18110661250601268, 0.24663771713971783, 0.2689202552563411, 0.32128827179230723, 0.3289988163769746, 0.24492028949536593, 0.22566237084756335, 0.2010405898069888, 0.20711750593505807, 0.23950366360035313, 0.24588080785847122, 0.214821050461811, 0.2717092085922733, 0.21605589936604241, 0.18982418976194293, 0.1950497363885909, 0.19471288000269915, 0.21581887679044864, 0.21735700266039026, 0.20071522675293296, 0.19582103900977488, 0.21767805620033565, 0.19045781291820674, 0.8761775722231526, 0.20482561248489373, 0.18729910314671727, 0.11856444603800231, 0.2001321073806296, 0.19412907764305176, 0.14004688786582087, 0.1619875696453602, 0.8657338814803996, 0.878092092962084, 0.21097115579116965, 0.19905795502953927, 0.8650546885272451, 0.20232969468302098, 0.16667972147536925, 0.2106817861498096, 0.11035602144458534, 0.12694051059928335, 0.19673112269666249, 0.25353442384654934, 0.20646554605188472, 0.19278771597903666, 0.1976213748484742, 0.2109182999980972, 0.19422531095382833, 0.20832836185599113, 0.20508567112112364, 0.13749503271469743, 0.10910756694633161, 0.08838239271572823, 0.08855601785384937, 0.11076951260449064, 0.0842810085154897, 0.08338742041603675, 0.09038386838758194, 0.10484204812485698]}, "mutation_prompt": null}
{"id": "364f94b3-5186-40e9-800b-628695c1904f", "solution": "import numpy as np\n\nclass StochasticDynamicDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 8 * dim  # Adjusted population size for faster convergence\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.7  # Slightly increased inertia weight for better momentum\n        self.c1 = 1.5  # Reduced cognitive coefficient for stable exploration\n        self.c2 = 1.8  # Increased social coefficient to enhance global guidance\n        self.F = 0.9  # Higher mutation factor for aggressive exploration\n        self.CR = 0.9  # Increased crossover rate for better trial vector mixing\n        self.adapt_factor = 0.95  # Higher adaptation factor for robust control\n        self.diversity_prob = 0.3  # Enhanced probability for diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "StochasticDynamicDEPSOHybridOptimizer", "description": "A stochastic dynamic DEPSO hybrid optimizer leveraging self-adaptive parameters and mutation strategies to enhance global convergence and exploration.", "configspace": "", "generation": 30, "fitness": 0.3743050876713891, "feedback": "The algorithm StochasticDynamicDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.27.", "error": "", "parent_id": "f1de49e0-fa67-4cc6-ad1b-5acddda8b9c5", "metadata": {"aucs": [0.8222709757607755, 0.8393223820989383, 0.8472952190858186, 0.830186634506737, 0.8220018824203874, 0.8536585907784441, 0.8349071198965492, 0.8248178209324561, 0.8324705689515277, 0.6310661657368963, 0.5074102419137502, 0.6599594210048755, 0.650752115078786, 0.041789444614358406, 0.6482876013213236, 0.6535273583222747, 0.6878221697473548, 0.6419701270747126, 0.11194426712299688, 0.09466369932525398, 0.13909126769076885, 0.09785945827820319, 0.08562100354100788, 0.14164871699096293, 0.138563646245485, 0.10504779243300622, 0.1494492137522193, 0.11612442594796013, 0.10529914365164494, 0.13487172050675944, 0.1287920514885913, 0.09322066870787005, 0.10851755676675479, 0.08787780312375437, 0.10564759465732387, 0.103730094818137, 0.9907950736707626, 0.9926642794241897, 0.9917453165487086, 0.9907639049092991, 0.9845735316911103, 0.98307086513563, 0.9905610115601787, 0.9902483197967814, 0.9892105509724689, 0.5776418752435626, 0.6074347677582514, 0.684979686166381, 0.497570989108464, 0.5283610238162066, 0.6254313654294559, 0.5489906049922544, 0.6213302692932505, 0.7172385820967533, 0.20580702864181544, 0.3630753056575873, 0.2117201969815039, 0.7996503288787304, 0.3500056327266694, 0.11168030666410045, 0.8163349275202543, 0.22513750543794286, 0.8142232012853674, 0.5074088850395653, 0.4642924676054475, 0.11628730384486186, 0.10942744485585576, 0.7325072276386613, 0.6089408664033931, 0.7222046871796639, 0.6143668221731193, 0.6576578155189579, 0.5678652336480242, 0.3027058570630722, 0.6136002736370186, 0.5944045152170498, 0.6534191903427171, 0.6780599426569918, 0.48842909500764475, 0.5082277821866068, 0.532539474776099, 0.42428378009444745, 0.27110717309817123, 0.04934406375270084, 0.10773661966715187, 0.039550256953789886, 0.009145309423819303, 0.4510080837564242, 0.07960459105979678, 0.25387826395445345, 0.4958456065663861, 0.4053914550544738, 0.6330828021703196, 0.37635344109361324, 0.3452286853222235, 0.20547664893239348, 0.5112940925641374, 0.6614425257926051, 0.4735600541563535, 0.3541933346781525, 0.15678936841425384, 0.2502497821460502, 0.13344020131877754, 0.6046082702688573, 0.24149046301079602, 0.19163874296509298, 0.2341368922240844, 0.09189824293847382, 0.18385713302162798, 0.23473548807679212, 0.4381772538629912, 0.35937492612823274, 0.16150964662249256, 0.414981511665788, 0.20177013991948511, 0.24624510674469857, 0.07799386710470191, 0.6889635635188663, 0.6975168817061521, 0.7517942101056112, 0.7066440504976574, 0.6558887052761972, 0.6483029404020787, 0.7333221131848446, 0.6607966581546904, 0.6551030321937399, 0.13478219930085344, 0.07502563924016703, 0.07229680440718766, 0.11881130304751153, 0.12017750425360463, 0.10608467872376681, 0.10336412056343158, 0.07997235041098505, 0.12315062580282687, 0.16183264820852528, 0.1731904869236217, 0.16629101334218377, 0.24173148576879255, 0.19772262883864133, 0.2432565001917779, 0.27346721643836935, 0.17100373450860584, 0.3088168876238576, 0.3239581084979424, 0.36681467554635727, 0.3295100858419693, 0.2558142460349284, 0.3517452683557709, 0.4532687049117007, 0.4368350169690596, 0.276328561718833, 0.36481643957172616, 0.17786539039011817, 0.24909023851825596, 0.2798915024635358, 0.3181016852157179, 0.19331355531438077, 0.2011807618142991, 0.219547280792609, 0.27516631586639395, 0.2762579443236639, 0.2036902188683417, 0.23563192178618986, 0.22075612866844108, 0.24073431860977523, 0.21174255992343716, 0.2125328828441908, 0.23181271113591062, 0.1810917516573587, 0.2014686990325134, 0.19105908567791052, 0.18115951218097193, 0.18454331732148965, 0.7262581141656796, 0.1971209812031166, 0.1798079275602249, 0.17670675894532362, 0.18475380468702562, 0.20532911131911524, 0.15540670473492335, 0.8675791815863645, 0.47911731460603657, 0.8852147606514331, 0.19813813432251426, 0.18630391365284782, 0.8318430081132506, 0.16670723964768464, 0.2105691694142786, 0.8321464276143113, 0.20952504014289985, 0.11130947358265242, 0.15497488197237985, 0.1661120471679487, 0.7824654793564155, 0.11291771629407688, 0.19737100089626913, 0.15966656866703033, 0.2047977386245451, 0.21788759002143243, 0.1984313878600158, 0.20005700256994996, 0.19149202286879974, 0.2162933322101891, 0.22454979533289365, 0.20212131148478085, 0.20859757172441673, 0.0924530043162678, 0.08501424002456204, 0.14087873128007522, 0.08960760710012272, 0.10198529059660233, 0.10055564893654534, 0.1567476253999175, 0.09071728372817778, 0.10482699512690674]}, "mutation_prompt": null}
{"id": "3c00a2c9-17e1-48b4-9a1e-839e68f2592c", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Slightly reduced population size for faster convergence\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Further reduced inertia weight for tighter control\n        self.c1 = 1.8  # Enhanced cognitive coefficient for better local search\n        self.c2 = 1.4  # Reduced social coefficient for controlled exploration\n        self.F = 0.9  # Increased mutation factor for improved diversity\n        self.CR = 0.7  # Reduced crossover rate for sharper exploitation\n        self.adapt_factor = 0.95  # Increased adaptation factor for slower decay\n        self.diversity_prob = 0.3  # Higher probability for diversity injection\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Continuously adjust inertia weight\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A refined DEPSO hybrid optimizer with adaptive strategies, leveraging multi-stage mutation and enhanced diversity for robust convergence and exploration.", "configspace": "", "generation": 31, "fitness": 0.370451062340081, "feedback": "The algorithm RefinedAdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.27.", "error": "", "parent_id": "f1de49e0-fa67-4cc6-ad1b-5acddda8b9c5", "metadata": {"aucs": [0.8436893306312249, 0.8203307490266746, 0.8330866735233895, 0.8468241899636703, 0.8256945896285718, 0.8345429668124387, 0.849401269993581, 0.823429932801989, 0.8215323370584122, 0.630001751275844, 0.6370483514528262, 0.6188004258101973, 0.6721899572460611, 0.6260472924389519, 0.6166371930479488, 0.6841721774298217, 0.6681072992983392, 0.6106688789204671, 0.15225408238291982, 0.1312076263345876, 0.12512078639566693, 0.14861766000117949, 0.13085334794676073, 0.11255299400525876, 0.1591976124791601, 0.1213949822942525, 0.13907551550403952, 0.07619155184571169, 0.11637572444927047, 0.09824115008459844, 0.12051677004398353, 0.13269048739574796, 0.08885866522172892, 0.11452129004729139, 0.0991083587329773, 0.13992530283886173, 0.9894487234834002, 0.9823514637269296, 0.9812654843748484, 0.9813134187230433, 0.9863058592076438, 0.9810518598375508, 0.9803804478000834, 0.9817047620471829, 0.9872213658061978, 0.6352838170275839, 0.5936230089043001, 0.6221935716589042, 0.646014536974155, 0.6151202499506752, 0.5691722906084805, 0.6947223686952719, 0.6852730729332115, 0.5776243378239041, 0.38472995089512363, 0.23805088737853786, 0.34185181228614625, 0.37422032837610775, 0.8582423520840158, 0.8284950585808308, 0.8620453885916947, 0.760474866267175, 0.2297541975483922, 0.12554701880002472, 0.12639141779859386, 0.6250950541350402, 0.5825191964256149, 0.5585363434560897, 0.3821130553623838, 0.585957323226358, 0.11630031465735124, 0.5671992170660313, 0.4609972716495391, 0.6808648714452821, 0.12486113181241076, 0.4794863041303189, 0.5408639880394304, 0.5196366929333311, 0.6481322465833419, 0.12416410338728379, 0.484152511662448, 0.062331039280984823, 0.06416240509270121, 0.13799524563316723, 0.029519894151753268, 0.12365384654911904, 0.00046907004047958, 0.26487619296057874, 0.12047802249149575, 0.06429702393149217, 0.4063270854409693, 0.16768466996440334, 0.20438061159641607, 0.23266297182846607, 0.13069800583886337, 0.5184013761545481, 0.3032603186786681, 0.1599664036390941, 0.18117341602977732, 0.0938350912686301, 0.05034481233137145, 0.23654719879025732, 0.07272999027344107, 0.30802412669059154, 0.13799461237400046, 0.19541014314620453, 0.11093991076110199, 0.13286104297725054, 0.2785098132537184, 0.21522898008731395, 0.189619451633668, 0.24937599278858114, 0.17295856715921998, 0.4311249747492517, 0.17827480862467215, 0.23909403162693266, 0.21262062012746974, 0.6294366350593956, 0.6463753445541468, 0.6838178288361458, 0.7344380110195308, 0.6620691719882326, 0.5850362825521433, 0.6172051435439331, 0.6904005494385168, 0.5908525561120822, 0.1373921226163276, 0.15136385507520012, 0.12254033355620209, 0.09906225653635625, 0.08288005497894324, 0.10500409516609055, 0.11275533755716383, 0.11357296025149355, 0.12250556352509212, 0.16736805434709745, 0.30600200780801656, 0.19856326461144425, 0.299709289912949, 0.17169868164323576, 0.21948197079085707, 0.20190512472478717, 0.46036615090696964, 0.200181530931701, 0.46374209304575575, 0.2378658355891855, 0.3438126856589395, 0.3399016442978593, 0.4060769978954102, 0.5224580899418534, 0.2693608361870504, 0.3395508424336282, 0.3364855251117743, 0.2794318002355971, 0.2604645832787703, 0.21190291162036123, 0.23287659643364378, 0.1709806048901653, 0.23608229423099236, 0.22030743460662794, 0.30878811342320456, 0.29475623172808685, 0.2345162746765337, 0.2117839363067553, 0.2272324777015382, 0.21354400626879622, 0.21839874883898114, 0.22380651770349047, 0.22460708420751463, 0.2333524553388152, 0.2307463531363394, 0.2196122311782276, 0.19463457599483258, 0.19078989276227754, 0.19461030308941396, 0.1962572495173749, 0.1935524044360396, 0.7855642799987164, 0.2209577571467347, 0.20124799706303942, 0.8957042753838067, 0.8347397399996854, 0.15399860366870344, 0.16575385407361154, 0.3419560483857418, 0.2094463203974668, 0.1525466947033477, 0.1671908264427886, 0.857954073374664, 0.8721058791273695, 0.21034067997893335, 0.8060793560828806, 0.8440889920143497, 0.7389583367747257, 0.29461498689238363, 0.21268244337859366, 0.7015466969018557, 0.6665704631180469, 0.18206880784887924, 0.21600649633430147, 0.19879300676873635, 0.21168660615416934, 0.18924507503871169, 0.20276903648761213, 0.18649616160683535, 0.18519847151080504, 0.2019491488812155, 0.08471259985565793, 0.10294394401905393, 0.09746837294408539, 0.08793622276839774, 0.08559290643140138, 0.10490793084760486, 0.10883388676785777, 0.09989611199905901, 0.09510797798244408]}, "mutation_prompt": null}
{"id": "43c4a941-2f2a-467b-8f68-ac9281e2b003", "solution": "import numpy as np\n\nclass ImprovedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 15 * dim  # Increased population size for comprehensive exploration\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.7  # Modified inertia weight for better global exploration\n        self.c1 = 1.5  # Tweaked cognitive coefficient to refine local search\n        self.c2 = 1.9  # Enhanced social coefficient for robust convergence\n        self.F = 0.9  # Adjusted mutation factor for increased diversity\n        self.CR = 0.85  # Optimized crossover rate for balanced exploration\n        self.adapt_factor = 0.95  # Refined adaptation factor for progressive control\n        self.diversity_prob = 0.2  # Fine-tuned probability for diversity manipulation\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "ImprovedAdaptiveDEPSOHybridOptimizer", "description": "An improved adaptive DEPSO hybrid optimizer enhancing strategy by probabilistically modifying parameters and exploration tactics for optimal performance.", "configspace": "", "generation": 32, "fitness": 0.33242212665276855, "feedback": "The algorithm ImprovedAdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.24.", "error": "", "parent_id": "f1de49e0-fa67-4cc6-ad1b-5acddda8b9c5", "metadata": {"aucs": [0.7239950584816278, 0.7329972870855035, 0.7306022767078607, 0.6989478139886823, 0.7432545034369781, 0.7497582206461193, 0.6943473674125769, 0.7319313837150626, 0.735826044859254, 0.43866864266012817, 0.4838443709072078, 0.478937458582367, 0.41977168787903996, 0.46503408875635455, 0.5126776313694472, 0.4441644613268404, 0.48792318724732053, 0.48300961317940105, 0.14213414057224072, 0.07137391823592809, 0.1305813792287197, 0.12512399657537498, 0.11325735004136528, 0.11182391367272482, 0.11817141701302591, 0.15437663013487812, 0.1187997969125425, 0.10306351459181462, 0.11900780616208395, 0.102276882995336, 0.10837486161484489, 0.09922982548845449, 0.10908460905146744, 0.0944288561476736, 0.10864146415771525, 0.1044472636537459, 0.9809820991005168, 0.9831233455119193, 0.9848027922743344, 0.9808578935133768, 0.9831272782422575, 0.9843976564822742, 0.9860409328824609, 0.9853681394065534, 0.9850897516855679, 0.4335664773788509, 0.4305837461261848, 0.4839429364433684, 0.3711118567014682, 0.42140018923946376, 0.460469683736232, 0.2929081013614139, 0.4359458318718855, 0.5039538655868006, 0.7899477114460978, 0.22220325585227285, 0.34230917897036406, 0.2715978867218428, 0.6957842472477629, 0.20718248051730837, 0.7686941571157554, 0.21155268098800029, 0.6666394991091777, 0.11623413823971462, 0.3328356151965519, 0.09917682897062519, 0.4036191439038396, 0.4814842672601224, 0.12602295807451613, 0.4847632161914195, 0.11658161358444519, 0.1245425261152101, 0.377853552519248, 0.4031789974285568, 0.47479115031761954, 0.11195548997349014, 0.10769730667174149, 0.4634071859226405, 0.502555602794333, 0.3272212967631335, 0.38140417517001823, 0.2827405856743459, 0.04946339710437764, 0.4420978532595109, 0.28283928143648895, 0.420627107782512, 0.4451874854767258, 0.37131846609386043, 0.32122682656657975, 0.38598481967165055, 0.39849800219252807, 0.41601615904228006, 0.4463645831400438, 0.3674862515364624, 0.5134558793358333, 0.44885998423237206, 0.3223413097364213, 0.40769891855893226, 0.5581162336465719, 0.04669934649856955, 0.07459832864100135, 0.1779153870344964, 0.09666690060162886, 0.14363042789295666, 0.1626725854504344, 0.10111339275005016, 0.21814855036190706, 0.10059009012088405, 0.18222730120355835, 0.2653445780953745, 0.22349249615286482, 0.19450298618041473, 0.18596135007983783, 0.33942899569859086, 0.0863801979655684, 0.3683903783212623, 0.1068117209536884, 0.5836568667435191, 0.6295727817632929, 0.6395473415831368, 0.5902019834792891, 0.6118506421089985, 0.6201968926003794, 0.5869433139543054, 0.5900896959824175, 0.6230821095677184, 0.10257173407903208, 0.08987598223757809, 0.11763390085065961, 0.11447166132988662, 0.09848258266023535, 0.10830552855998088, 0.12470658602585116, 0.10300457210829739, 0.085757948821647, 0.1753962511309266, 0.20411334906274237, 0.20948184385032054, 0.17754806330757966, 0.1925005453158305, 0.2598027865839859, 0.19444199048051036, 0.23619125735416568, 0.21351449785329735, 0.29729793373861335, 0.32269020914370616, 0.28640216713775357, 0.30791705405662884, 0.36347620087970656, 0.32656534695937467, 0.2738348739402169, 0.3885718419534816, 0.2693145521548129, 0.2960749435577673, 0.25707776166466945, 0.2247888664984259, 0.3068647355282017, 0.22241775979041745, 0.20528744441494617, 0.22936794041738584, 0.2682167820871215, 0.15177446008975148, 0.22809865199782864, 0.19755940668068295, 0.19552213653468709, 0.2206167042769822, 0.21576098004738187, 0.250224778023843, 0.21544902084391593, 0.2011751680911502, 0.19406414942490524, 0.6007793904701108, 0.18827805646766227, 0.18912383848733183, 0.19002352231080388, 0.21633796423904883, 0.22765844192170903, 0.18437545310407388, 0.21788948159305443, 0.1864789657444399, 0.19272379227571723, 0.1847440346289928, 0.813211334051058, 0.7479906273721579, 0.19785563447942311, 0.19154120381268092, 0.2011192381523027, 0.16384342256160966, 0.7339981065195491, 0.8158513747356002, 0.20890297588111284, 0.2047788366115244, 0.20625253134713473, 0.16504888406051033, 0.7349168502267514, 0.7307231048909946, 0.1635280505279365, 0.21134231571282347, 0.18499950532297138, 0.18728104264216305, 0.18906163161526246, 0.1795941558890667, 0.18330171757270985, 0.1976904599343665, 0.18993619957185193, 0.1874996910289749, 0.23946637909870894, 0.08275789824691238, 0.08581626112989671, 0.08681367450347355, 0.0788153235549085, 0.0825383191058221, 0.08393148195477729, 0.0770915016085153, 0.08599113636496203, 0.08822534274356408]}, "mutation_prompt": null}
{"id": "f9ae16f5-7960-49f6-b7cb-d1eb9a1b3e71", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Slightly reduced population size for more rapid convergence\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.7  # Adjusted inertia weight for better velocity control\n        self.c1 = 1.8  # Improved cognitive coefficient for stronger individual learning\n        self.c2 = 1.5  # Slightly reduced social coefficient to balance exploration\n        self.F = 0.9  # Increased mutation factor for greater diversity\n        self.CR = 0.85  # Higher crossover rate for enhanced robustness\n        self.adapt_factor = 0.95  # Modified adaptation factor for smoother parameter evolution\n        self.diversity_prob = 0.3  # Increased probability for diversity to ensure broad search\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Continuously refine inertia weight\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A refined adaptive DEPSO hybrid optimizer that incorporates stochastic perturbations and elite diversification for enhanced exploration and faster convergence.", "configspace": "", "generation": 33, "fitness": 0.36748049090925444, "feedback": "The algorithm RefinedAdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.26.", "error": "", "parent_id": "f1de49e0-fa67-4cc6-ad1b-5acddda8b9c5", "metadata": {"aucs": [0.8340253524572258, 0.8106047007734072, 0.8147713825783952, 0.8236764417897319, 0.8186584225354478, 0.8103195331604292, 0.8343113435235432, 0.793320559923503, 0.8065020058867411, 0.5932553148633215, 0.5519126198375767, 0.5863145549940911, 0.60204333472122, 0.5693596279288844, 0.5469621721730084, 0.5767948014540345, 0.5707571311229975, 0.5527742522560005, 0.11941290703617846, 0.10829120491458288, 0.14149004153715683, 0.1037209511766718, 0.13940173613134232, 0.06957845206877467, 0.14239804273883705, 0.10686830883702658, 0.09088127797878065, 0.08754579173539712, 0.09311869358089042, 0.06789849179223839, 0.08129750396308932, 0.0925099350860552, 0.08564548752544066, 0.10593497596435353, 0.09243010411569064, 0.12662551192750093, 0.9895354225974275, 0.9862879184280969, 0.9854942734013665, 0.9873807155672926, 0.9863494066126766, 0.971829065679597, 0.9797953844086539, 0.9890447814086701, 0.9872003962449999, 0.6082557486788935, 0.579081003241865, 0.5684518410182207, 0.6585911655104728, 0.5840898282074476, 0.5547613084675602, 0.5960489685056487, 0.5994474631983973, 0.6383817341264395, 0.2235964356126523, 0.3550712069305919, 0.35715741969821724, 0.20992495057537996, 0.2599841132969938, 0.2628734452667152, 0.8097145757344425, 0.7730875336730958, 0.17539029871354883, 0.5549656534046896, 0.4109277542844755, 0.45609303470291807, 0.11125792407873925, 0.598559550420263, 0.454231076439213, 0.5583484828826655, 0.7125030263793042, 0.3868051874022279, 0.6436027188224458, 0.4788739312115744, 0.12532447066800867, 0.450850432263074, 0.4633045912376401, 0.5266779606094751, 0.556813266057166, 0.4628658989478247, 0.6818224001400839, 0.02038063455392225, 0.19656359750271957, 0.17161523260576927, 0.03584451388243137, 0.32327653500681497, 0.1510082356547302, 0.29035148548696055, 0.513032378046006, 0.41422254652736834, 0.22866467602078233, 0.3059678832446726, 0.32569236098247734, 0.635946946656621, 0.16105656550425596, 0.46832893931621056, 0.3230253123888067, 0.5529536772245638, 0.37649397030640497, 0.06971394383874596, 0.04267038423895664, 0.3176752545838468, 0.20199878070893518, 0.2752689547300017, 0.13795935206104515, 0.12745702478655896, 0.19326158908787805, 0.10891898185663218, 0.19733738983125593, 0.22306682000819655, 0.15120411477866547, 0.38341099816768476, 0.19223672237929457, 0.25135564000067123, 0.22413004018026994, 0.13602773303327975, 0.07554413935742066, 0.646361473930271, 0.5666798660025616, 0.6091262326393576, 0.7135917808753571, 0.598465910902252, 0.5565353139047898, 0.7520321846663662, 0.6355802891839802, 0.5946834663623217, 0.10132243963550192, 0.07991331114813582, 0.10516136871998516, 0.13470996016198966, 0.09475937052155003, 0.11585484674846869, 0.12804763829842292, 0.08897228297167603, 0.10665406948974199, 0.26707237235517, 0.1966400822134996, 0.21887844380994348, 0.18681883831497303, 0.4283218159608745, 0.31368730586977445, 0.2843606852240357, 0.19819853019239708, 0.1777644023379269, 0.2658193463277032, 0.35305855549569964, 0.39088535048602213, 0.30510976713624705, 0.3119425942672467, 0.37968892401093257, 0.3438409621819959, 0.3851916683707778, 0.36763023725653177, 0.19654899216191768, 0.2973359165456413, 0.3252653677321975, 0.24002998110983131, 0.29607091595043245, 0.3826921262803761, 0.24195620624400094, 0.2585370701584172, 0.26158717516936825, 0.29502109070794347, 0.1896939370996149, 0.19892079978070143, 0.22071886942381025, 0.24246783409618955, 0.18184364354951232, 0.1814364852491105, 0.24535050203506337, 0.2076655955501029, 0.19873054645477373, 0.20016866053161686, 0.22791060212908265, 0.20171746516745948, 0.190183061777649, 0.2285847537180018, 0.1969162567779078, 0.20287790441429032, 0.22019618780259353, 0.8664599682849468, 0.8402722803504833, 0.15313263678229727, 0.8073416190483724, 0.3147852737157053, 0.18389024633991558, 0.1532329410254455, 0.17274376881361098, 0.8296345023406198, 0.8238891674263188, 0.2109126131043798, 0.7598388675685562, 0.8121674973233394, 0.1677929295460202, 0.24570155521856774, 0.21236667758449845, 0.6612442975061887, 0.7521021222560332, 0.20220950846765073, 0.18145568640404586, 0.20163069270785006, 0.18777588348419016, 0.1990667286843738, 0.18610772348113103, 0.21509247827244182, 0.1980451436759636, 0.1868142766853481, 0.09731165546177833, 0.09859048583271957, 0.09180017242444172, 0.10117153145069047, 0.08233805286427742, 0.09166614324106581, 0.09163842259342658, 0.09884575001465457, 0.09719701143794279]}, "mutation_prompt": null}
{"id": "8dc3f6df-569e-4d07-a6e3-ac393284dfea", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 12 * dim  # Adjusted population size for better exploration\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.65  # Further adjusted inertia weight for control\n        self.c1 = 1.7  # Altered cognitive coefficient for enhanced local search\n        self.c2 = 1.6  # Balanced social coefficient\n        self.F = 0.85  # Fine-tuned mutation factor for diversity\n        self.CR = 0.8  # Adjusted crossover rate for explorative robustness\n        self.adapt_factor = 0.9  # Adaptation factor for dynamic control\n        self.diversity_prob = 0.25  # Increased probability for diversity manipulation\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Continuously adjust inertia weight\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "EnhancedAdaptiveDEPSOHybridOptimizer", "description": "An enhanced adaptive DEPSO hybrid optimizer tailoring dynamic control parameters and elite selection for improved exploration and convergence balance.", "configspace": "", "generation": 27, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "f1de49e0-fa67-4cc6-ad1b-5acddda8b9c5", "metadata": {"aucs": [0.8355409558076017, 0.8494426084577814, 0.8428963889796215, 0.8502852936515759, 0.8621901096656455, 0.8497248109461688, 0.8387232776935258, 0.8459284358315018, 0.8362425413873057, 0.03808480415518245, 0.6212092818697802, 0.6598724132580744, 0.6502034892458568, 0.647123652252421, 0.6890056170188226, 0.6702099755395825, 0.624013855909104, 0.6362004785053328, 0.12207907847920163, 0.17257720538319243, 0.10467972342729026, 0.11439498939861659, 0.13666043391409644, 0.10682223525172652, 0.1108679681777136, 0.14784642832704253, 0.10861616695313658, 0.10773597615856856, 0.0824763932957665, 0.10001990105948755, 0.13541818863283084, 0.09333746487170791, 0.10678260432852493, 0.11449311655902128, 0.09339932778005766, 0.11298007871445048, 0.9872029040341762, 0.9872894199974253, 0.9865901085447795, 0.9868745094722602, 0.9854832635141402, 0.9848641647636192, 0.9867568197531932, 0.9848918714150006, 0.9882765486673663, 0.5007111019665824, 0.608074550285124, 0.5247571953872642, 0.5619436341968036, 0.6399432180851307, 0.6221965875744164, 0.6395661567218133, 0.6591555597139024, 0.5472504531082588, 0.21135012282197585, 0.7800919306743392, 0.22232627742521993, 0.8516069552123506, 0.2628604510316278, 0.2073265396274221, 0.83428349495713, 0.8398019620784158, 0.22748420511413447, 0.67686311890875, 0.5329752656707352, 0.5402159077307994, 0.6893425927037747, 0.5427592297946797, 0.1294594924653657, 0.1261981341808005, 0.5992713769384455, 0.6493406999815003, 0.5938949090212955, 0.44886919828682104, 0.5929113193379214, 0.5950533802181326, 0.5036198518173242, 0.5992240615970458, 0.6958532114694396, 0.5916765446709902, 0.12516503811974422, 0.13382899773215995, 0.2634108234625794, 0.23380247273103594, 0.09074172674597991, 9.999999999998899e-05, 0.205012596259878, 0.12974233392809476, 0.12297059187754622, 0.12847894972749818, 0.3824334532518411, 0.3516044090341116, 0.22886474481398134, 0.6833061490636131, 0.22866670834320746, 0.5369431843452157, 0.5596685980822769, 0.5980103415008682, 0.5231875070604719, 0.05938342188516854, 0.06175585168723552, 0.22798890033483488, 0.15994671754544376, 0.46982615522606996, 0.08792684540425566, 0.12551751453330684, 0.10706358301053553, 0.2116052000276315, 0.27182094151942593, 0.32484617399407356, 0.3881794954252107, 0.26639554796954024, 0.210533602523456, 0.3010891192001802, 0.04802433576686849, 0.05414903593810472, 0.07739605282909601, 0.6957313505423219, 0.6430901707788463, 0.7808067168848984, 0.7527932516594305, 0.639178142675696, 0.7252789241464053, 0.7014624808729144, 0.6694388299173162, 0.6537199387033179, 0.08564285772074787, 0.11019796056272424, 0.10826888698964798, 0.1300085467135199, 0.14999965979111263, 0.13386439071945866, 0.134654412685846, 0.11098594313521026, 0.13323263062529878, 0.20969418297682252, 0.3697136335907768, 0.55423104697274, 0.21084229979461588, 0.3257358828764384, 0.18272518099560775, 0.2417761157850855, 0.45084070110867114, 0.1595061423248919, 0.31744813825732776, 0.2688181347600346, 0.38435525426927664, 0.4125385053764913, 0.317112443709631, 0.24996839494760592, 0.31129982783820487, 0.31560450501811343, 0.2755635656621499, 0.3357005687226233, 0.3154881598444341, 0.20998457100134071, 0.2903080941249575, 0.19814068641145877, 0.22203970851073607, 0.21140353217928587, 0.34463661495035336, 0.212456075483466, 0.2325205994821279, 0.22222149955173254, 0.19259614210465759, 0.2625992558743159, 0.20793472659634304, 0.20853791338893357, 0.24645002533612426, 0.3008286640816966, 0.24304667970593796, 0.1786158990898784, 0.21383636861607402, 0.17632632425439132, 0.24392101743295558, 0.1946813608955963, 0.2101187602952035, 0.20902471008492374, 0.22027433961212806, 0.20167102129658088, 0.18662391353117824, 0.16791359444098253, 0.1865747338708159, 0.8802561179962776, 0.19954127204905214, 0.7380328545019104, 0.14230489207325303, 0.16328028751245316, 0.17780482120464147, 0.854768348127194, 0.6223772766003928, 0.8225357750507345, 0.8751038443426415, 0.16645529734105713, 0.8248608861164217, 0.2009963873038746, 0.7481790167658484, 0.8521606506415751, 0.2037439086091224, 0.18512869532449905, 0.18428291000120556, 0.20053462889801676, 0.1955537548324272, 0.19159368833788915, 0.19684294339685926, 0.20180877733092228, 0.2265578817383479, 0.153786791582323, 0.15020476166341956, 0.11870998187667015, 0.09805224508387778, 0.09719166019349845, 0.07923263991057305, 0.0896549667936275, 0.08091464298075624, 0.1111398835428159]}, "mutation_prompt": null}
{"id": "5fd95bb9-18c1-4c71-b330-2e051325cf39", "solution": "import numpy as np\n\nclass NovelAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 14 * dim  # Increased population size for extensive exploration\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.7  # Adjusted inertia weight for dynamic control\n        self.c1 = 1.5  # Modified cognitive coefficient to balance exploration\n        self.c2 = 1.7  # Improved social coefficient for better information sharing\n        self.F = 0.9  # Enhanced mutation factor for increased diversity\n        self.CR = 0.85  # Fine-tuned crossover rate\n        self.adapt_factor = 0.85  # Increased adaptation factor to ensure variability\n        self.diversity_prob = 0.3  # Enhanced probability for diversity boosting\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Continuously adjust inertia weight\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "NovelAdaptiveDEPSOHybridOptimizer", "description": "A novel adaptive DEPSO hybrid optimizer with enhanced diversity mechanism and dynamic parameter adaptation for improved convergence performance.", "configspace": "", "generation": 35, "fitness": 0.35755187837033625, "feedback": "The algorithm NovelAdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.26.", "error": "", "parent_id": "f1de49e0-fa67-4cc6-ad1b-5acddda8b9c5", "metadata": {"aucs": [0.835003826369251, 0.8196488769501434, 0.8440258675843622, 0.8487415249357532, 0.8387152833526679, 0.8603922864264459, 0.8257427141687458, 0.8345090634763719, 0.8529816038230824, 9.999999999998899e-05, 0.5749362812440644, 0.6489718357022094, 0.5461532754423664, 0.5029570368702109, 0.6643413055384236, 0.6212612566561069, 0.6108622597946296, 0.5973574372572705, 0.13060007751428726, 0.11978660643014027, 0.1259660577006242, 0.09175087736274057, 0.15151835055737684, 0.11359641793315278, 0.1186460003812112, 0.1494650274235968, 0.11881633962131544, 0.07047026107152032, 0.12128339350940354, 0.10377017930734744, 0.08754315423799985, 0.10150560664136832, 0.09833314351748013, 0.10783722086888425, 0.16121765481311945, 0.10903173844081282, 0.983012691522347, 0.9859710291006535, 0.9806614892321802, 0.9740290162204346, 0.9824365718819671, 0.9833714156446173, 0.9860940627688732, 0.9836716196575479, 0.9853971057094624, 0.5803791631799109, 0.5142923812747136, 0.5554927509233774, 0.6284048041293641, 0.4436315721050158, 0.5343301983642577, 0.5185176554798727, 0.4516261357140663, 0.4748308440275779, 0.22679238433439797, 0.22359441785993006, 0.8601969794777733, 0.26712231652943397, 0.1860006562496903, 0.26360463862209904, 0.17210896996407554, 0.28204040578412126, 0.22720190623722802, 0.5180860331104735, 0.5157476698372039, 0.4880541660014973, 0.5501328114193054, 0.6051026093218157, 0.12566370622152367, 0.32135766871197524, 0.19467341384694847, 0.5497335569168021, 0.6247604650488905, 0.3215796220380568, 0.5065005924189078, 0.5304664508244923, 0.5287184309022849, 0.6107822049174498, 0.6036048302893767, 0.5612746374891343, 0.5532150071546951, 0.4674465324722106, 0.09177251388644636, 0.29095996425982573, 0.1792600363812693, 9.999999999998899e-05, 0.009734573219090326, 0.142858499256189, 0.24279388029897642, 0.19376724270546053, 0.5357370369204806, 0.4861059296109318, 0.4618546327260903, 0.31667461207272374, 0.3216174274018615, 0.45985163979380583, 0.6237577905353904, 0.5145149480594713, 0.5916071659100317, 0.08278791133336305, 0.15595153042738585, 0.13704714892499015, 0.21755336837802075, 0.11348803715302058, 0.1972700778315376, 0.365049850155846, 0.21554304515801992, 0.12187649624593577, 0.2758597737693844, 0.22658341184129005, 0.2793356424666785, 0.41599195842108516, 0.26559154903273086, 0.16346380715193987, 0.12759300357190062, 0.07724524933144461, 0.1966542318522101, 0.6571944171964171, 0.7517296128598507, 0.7256956789184464, 0.6792307939023849, 0.7339464187227018, 0.6397439262668267, 0.7499971653557974, 0.6573646722978734, 0.6872093803764905, 0.12218390405403712, 0.6402758683582956, 0.09183202655011169, 0.10961332694254322, 0.08788298009092521, 0.09418198991934545, 0.10598420527031138, 0.1089893907546775, 0.1325524207097838, 0.1943222081599938, 0.19402698886984338, 0.2630721967104359, 0.17528906115684717, 0.24830618890816025, 0.2208152527410855, 0.22728932043175853, 0.20605079677820948, 0.3568873537234213, 0.2883517942430318, 0.33638070839913037, 0.29019563042520624, 0.30276795666483236, 0.3162793191743428, 0.36860879447997785, 0.38523344928391856, 0.3280157082375219, 0.3746149057631576, 0.20026417331321755, 0.24778827012879023, 0.20970584808981407, 0.22787776608820887, 0.19543324520509486, 0.2943938570009209, 0.22707016138744907, 0.25474781939748214, 0.20087573989425878, 0.24836273442901513, 0.2299521705612103, 0.18984859827992828, 0.2249117391556501, 0.18481924373444847, 0.28688442923869206, 0.22041850828445764, 0.21484989195738524, 0.2306828874522906, 0.18081209598764458, 0.1787259416785888, 0.18503324403959687, 0.1979178598509923, 0.18129634591016053, 0.1846718758334457, 0.20653690493639165, 0.17844882318564592, 0.19647937201789478, 0.18047667648978294, 0.18685076361325637, 0.1871388097218032, 0.8601103775134502, 0.19923812008745323, 0.1646829195721683, 0.18060785747928898, 0.1915529382502551, 0.16670947514770473, 0.87171404225206, 0.2070541647651214, 0.8440777065090397, 0.1579126453119406, 0.7844183821577614, 0.15250513860320114, 0.1335498999403555, 0.8610763274474584, 0.7967774978470223, 0.19746785097424757, 0.18129801350171615, 0.20842833588855725, 0.2213541909613812, 0.18533175254506096, 0.20605467299021596, 0.18945920286347884, 0.1812479120648851, 0.18187479216660074, 0.09637610836962629, 0.08057310323477196, 0.07938259201906772, 0.09370997207073417, 0.0805184986622991, 0.08284231045432822, 0.08208739132151055, 0.08856745530510501, 0.09984505020619527]}, "mutation_prompt": null}
{"id": "9323e0a5-f168-403b-b1fa-5be4fcf78a00", "solution": "import numpy as np\n\nclass DynamicDEPSOOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Adjusted population size for dynamic adaptability\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.7  # Increased inertia weight for broader exploration\n        self.c1 = 1.8  # Enhanced cognitive coefficient for better local search\n        self.c2 = 1.5  # Adjusted social coefficient for equilibrium\n        self.F = 0.9  # Increased mutation factor for higher diversity\n        self.CR = 0.75  # Tweaked crossover rate for stability\n        self.adapt_factor = 0.88  # Slightly reduced adaptation for gradual adjustment\n        self.diversity_prob = 0.2  # Lowered diversity manipulation probability\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Continuously adjust inertia weight\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], -np.abs(self.bounds[0] - pop[i]), np.abs(self.bounds[1] - pop[i]))\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "DynamicDEPSOOptimizer", "description": "DynamicDEPSOOptimizer enhances adaptability through stochastic parameter tuning and diversified mutation strategies for superior exploration-exploitation balance.", "configspace": "", "generation": 36, "fitness": 0.35623436898847904, "feedback": "The algorithm DynamicDEPSOOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.28.", "error": "", "parent_id": "f1de49e0-fa67-4cc6-ad1b-5acddda8b9c5", "metadata": {"aucs": [0.8640529014894416, 0.863386465659693, 0.8690277526027722, 0.883485787703762, 0.8824558613317954, 0.8772637544708307, 0.8775536097458507, 0.867601065035979, 0.8838138750295069, 0.7337617704603641, 0.7232271360479652, 0.7271138849274097, 0.7230352964134521, 0.7010145633035185, 0.7348597027815125, 0.7407852911171813, 0.7431136062793797, 0.6979954339590384, 0.15089606020421475, 0.14753027220513837, 0.12929759455067813, 0.13812536342449344, 0.1348243824976022, 0.13800154566784262, 0.12786547694309103, 0.12854911461875196, 0.1484056815912913, 0.09286423590277848, 0.10602859758039962, 0.14970033394510684, 0.08073514416954153, 0.1056626230444333, 0.1060689981352585, 0.15335953449114148, 0.1083001089373341, 0.10063256769794549, 0.9894769763418466, 0.9834733082627052, 0.9854986598922096, 0.9828233564390733, 0.9817742827290553, 0.9886536950080235, 0.9788607170266245, 0.9819549690722482, 0.9872028067043168, 0.6479450850435967, 0.6576743903439306, 0.6442053571985047, 0.6451887725147692, 0.5818014969075007, 0.6720961098643856, 0.6364548309533162, 0.6871895245966878, 0.6900889681764726, 0.7060234386425785, 0.8314272252597701, 0.22511960932305253, 0.37675392797614327, 0.27630477072733717, 0.21043927774085203, 0.17785167879934327, 0.8682889402381974, 0.23688419321825105, 0.519631374305414, 0.11625939497010462, 0.7270567179180116, 0.12401744746222088, 0.36799671220125474, 0.13236396658606409, 0.6019514646026507, 0.6897509028564444, 0.12983936312480526, 0.6771321460364874, 0.5558291414270347, 0.4665414506765059, 0.6080176862531261, 0.5162139316292156, 0.6789075956494566, 0.4219400423534543, 0.5477219231674018, 0.5923821684337667, 0.06353968787080888, 0.27235828054002453, 0.06720152153407066, 0.14962612866578295, 0.11431525460081049, 0.14649584992669584, 0.1529395858767555, 0.0698867213596468, 0.04352034183507747, 0.25330593380014355, 0.2593006204274564, 0.15244669710727554, 0.32260600994750344, 0.15055562496244435, 0.32133457026982004, 0.3632253287920675, 0.18851641175252298, 0.3490432822710767, 0.06616279495141042, 0.07199573010619009, 0.1427517056492168, 0.2708032481635758, 0.14971298647482623, 0.19919598079756662, 0.1307998970338482, 0.2254879008843601, 0.11994690558560928, 0.19884164768186086, 0.15425641615780694, 0.17301318676685673, 0.33023308195498047, 0.3243783926955407, 0.12210676267476994, 0.06332312905838622, 0.0807994365180934, 0.07968537505524986, 0.7153099954672353, 0.6342067475619504, 0.6927572177779786, 0.6091149687725497, 0.6176893889024242, 0.6212436694208616, 0.687629973852234, 0.705824855239698, 0.7015525844486413, 0.10310052478775056, 0.07111947512703864, 0.10820991849291528, 0.12766542587613472, 0.09172570756912135, 0.09414425919721847, 0.14788939128203915, 0.09000533349538331, 0.09392715232340165, 0.2077662909462752, 0.22486377550912928, 0.20534830100344603, 0.260006755281337, 0.2852725708819813, 0.21823302577288417, 0.2915463566998332, 0.17032500395680727, 0.27478978036787516, 0.3104317648637335, 0.3842969967732456, 0.3208607333047542, 0.3384115392737431, 0.21557285078405908, 0.2752184198753471, 0.3943147474419758, 0.3662676790334949, 0.3687117071767555, 0.21503289562716432, 0.25894178739701934, 0.32624133699583135, 0.22449284228535893, 0.30727631162160374, 0.2229653605875117, 0.24140139101554436, 0.2812818497958809, 0.23267730985867163, 0.18366422401494997, 0.21441292863715278, 0.21226394141905836, 0.23291157287251263, 0.21671957463803715, 0.2575949018630376, 0.22459506693747067, 0.19876765187886003, 0.19849992682518947, 0.17610873456203446, 0.19930680375348775, 0.19532143119888046, 0.23647177911079298, 0.18577400381161258, 0.19496869127246763, 0.24702949450157374, 0.19656472050470264, 0.19340100986152498, 0.9320813718104398, 0.17727843824386602, 0.1861301125515762, 0.20603754770117466, 0.19777793746495798, 0.19862404090107855, 0.14946132949855107, 0.16319586873812364, 0.891122400330246, 0.8945357034624333, 0.2117325279956681, 0.20192347873843597, 0.8550738495903625, 0.16751104802251215, 0.16668092520440192, 0.21189567938076803, 0.16387968005753595, 0.1272274001500595, 0.20978627976539577, 0.18543206475105822, 0.23261902761257136, 0.1891879125643603, 0.1961279267523991, 0.1921432216922876, 0.2340700836401377, 0.2052236132096441, 0.19436245067971392, 0.0997262951324217, 0.08324258833969311, 0.09393884126438312, 0.09208156682477076, 0.09981181765503389, 0.08648081241503591, 0.08697086925187736, 0.08989804037020555, 0.08419089598825524]}, "mutation_prompt": null}
{"id": "94035a13-f857-4c4f-b8e6-363670cdc2ec", "solution": "import numpy as np\n\nclass EnhancedRefinedDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Adjusted population size to 10 times the dimension\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.7  # Increased inertia weight for better exploration\n        self.c1 = 1.5  # Reduced cognitive coefficient for balanced local search\n        self.c2 = 1.8  # Increased social coefficient to enhance convergence\n        self.F = 0.9  # Increased mutation factor for more diversity\n        self.CR = 0.7  # Reduced crossover rate to encourage stability\n        self.adapt_factor = 0.95  # Slightly adjusted adaptation factor\n        self.diversity_prob = 0.3  # Increased probability for diversity enhancement\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Continuously adjust inertia weight\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "EnhancedRefinedDEPSOHybridOptimizer", "description": "A further refined adaptive DEPSO hybrid optimizer incorporating stochastic perturbations and selective elitism for enhanced global exploration and convergence.", "configspace": "", "generation": 37, "fitness": 0.36134622409715506, "feedback": "The algorithm EnhancedRefinedDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.27.", "error": "", "parent_id": "f1de49e0-fa67-4cc6-ad1b-5acddda8b9c5", "metadata": {"aucs": [0.8143628924471044, 0.8070263582335679, 0.7614720594325453, 0.8077773461440549, 0.8222518896026934, 0.8050954855088324, 0.8241237728049771, 0.7941188979957066, 0.8123711067906524, 0.03811857309951561, 0.6152802686595626, 0.6147216067997061, 0.6169342007761198, 0.5790838734426005, 0.6121932586378152, 0.565361997693985, 0.5975443349314408, 0.5547704916209212, 0.10198050318696694, 0.09696461343581775, 0.12075516533402864, 0.137292876318569, 0.16930375064320546, 0.11438315745682248, 0.12425627233660141, 0.10733405115291639, 0.12217803459665721, 0.10769579865463852, 0.11636303832467843, 0.0889809197768553, 0.12405841459148503, 0.1271990133396974, 0.12022888855855851, 0.11799249159572245, 0.051399937467176304, 0.1394796265371675, 0.9894517920164547, 0.9863499116385654, 0.9871357845916038, 0.989976984787122, 0.9862352901356464, 0.9897880952917211, 0.9803189375009079, 0.9817013604623955, 0.9872653345738278, 0.6312101399744872, 0.5953286758343193, 0.6189031759371786, 0.6144715526328022, 0.6079797839357577, 0.5405321688306095, 0.5462972377695416, 0.5944642144439111, 0.5806755226608187, 0.7235453201932174, 0.21752332765101146, 0.3015243055740432, 0.7010070775760296, 0.20782066998383264, 0.18981698010202264, 0.8073509540362462, 0.7923194306963504, 0.7419837535363454, 0.6805303799188315, 0.3788898174876535, 0.5995644840961236, 0.11571000227541861, 0.1281753667617639, 0.6232682150357678, 0.6188948184760579, 0.6335721395495195, 0.5951730675290383, 0.5090389871860002, 0.17626010241538947, 0.11391831814057973, 0.591850203734837, 0.5861248098570744, 0.5649549249891388, 0.1256346800328958, 0.11711646901003514, 0.10884065620179995, 0.06547031444368401, 0.05436816178351889, 0.07483396269078657, 0.0006143034051078189, 0.01644336948138192, 0.15954910613276152, 0.22425052302617254, 0.1262619054025923, 0.007597459014046404, 0.3510838171228199, 0.5947908927995547, 0.4215363351924155, 0.12644087895891476, 0.4249420024034861, 0.14858086289560435, 0.2760881575137334, 0.557395090069036, 0.6062453251680289, 0.0529128389233714, 0.06050669487759619, 0.23961423698380635, 0.13074819735326615, 0.2721709889760978, 0.27220450464546053, 0.10074188332178946, 0.22241595787801038, 0.08495300069999956, 0.204896295218574, 0.22687264368545346, 0.2014590951126901, 0.32522367562030763, 0.26435705528484, 0.20061677724113847, 0.05353225153723851, 0.15279019163250507, 0.1785018451325242, 0.6815495319766539, 0.6555817145700129, 0.6568724248128288, 0.7279522185883687, 0.6925376214366232, 0.6761433721160085, 0.703571572888852, 0.7631500489252284, 0.7096095913888432, 0.09004601636878284, 0.13513383361945364, 0.11195647191955393, 0.12778061748208436, 0.1408937693216532, 0.07290148774176997, 0.07391523076179651, 0.09196197209455603, 0.07558286500517919, 0.19780254959785692, 0.3620165837332643, 0.24257861708039496, 0.308843586964042, 0.23171713940080785, 0.1720849997535302, 0.2481029916988492, 0.22188645672969554, 0.18213680060732562, 0.35318491229512283, 0.3909703846014134, 0.28831341812175515, 0.4185914601481864, 0.2429035436403133, 0.43583468871378617, 0.36271234261140906, 0.3450280447162325, 0.4350763773325188, 0.2137410101126328, 0.23761126880544647, 0.2858055975745406, 0.27834016640418824, 0.2081953265503188, 0.3013767839949414, 0.28391283496026665, 0.3076847793791374, 0.21373011738064784, 0.1880159331482152, 0.21386463869242223, 0.2023804251462824, 0.2419780729796276, 0.21451586340665074, 0.2063685843154991, 0.20882435037473168, 0.19534824584864918, 0.2627403001723967, 0.19690889978133563, 0.2207779170235037, 0.18171651333421845, 0.17958762572983122, 0.18807611964443227, 0.18706555721822615, 0.18714725332853233, 0.19087861308012155, 0.17427852880156702, 0.8805217758717662, 0.8026537495253276, 0.18639316759911706, 0.1668571649019246, 0.341632544744912, 0.2036109037158943, 0.16606327641352758, 0.8218441076158229, 0.8554600799909138, 0.8615200642178074, 0.20980385239408683, 0.1964080768930353, 0.8531574425918631, 0.7557550794301838, 0.22279379187737736, 0.20977934784965824, 0.691601868658532, 0.724458501380732, 0.19237278606121777, 0.18170412389344714, 0.18784512721321478, 0.18872485109706605, 0.18232257379606343, 0.19837075275311689, 0.18946613625648157, 0.1888008353138675, 0.200855118723542, 0.10644124100808572, 0.10709712065110799, 0.0892844463181316, 0.08417622465479602, 0.09004333000511755, 0.09168222485419375, 0.0882813472079984, 0.08600510616435664, 0.0792388827657029]}, "mutation_prompt": null}
{"id": "e50ec75e-8690-4c47-ae89-5558d8f4b6b5", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Slightly reduced population size for faster convergence\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.7  # Modified inertia weight for enhanced momentum\n        self.c1 = 1.8  # Increased cognitive coefficient for stronger local search\n        self.c2 = 1.5  # Adjusted social coefficient for better global reach\n        self.F = 0.9  # High mutation factor for increased diversity\n        self.CR = 0.7  # Lower crossover rate for stability\n        self.adapt_factor = 0.95  # Fine-tuned adaptation factor for inertia adjustment\n        self.diversity_prob = 0.3  # Increased probability for introducing diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Continuously adjust inertia weight\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A refined hybrid optimizer integrating adaptive DEPSO elements with novel mutation and diversity strategies for robust exploration-exploitation balance.", "configspace": "", "generation": 38, "fitness": 0.3482323306402986, "feedback": "The algorithm RefinedAdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.26.", "error": "", "parent_id": "f1de49e0-fa67-4cc6-ad1b-5acddda8b9c5", "metadata": {"aucs": [0.840178431824563, 0.8148942536679952, 0.8105456919260243, 0.8374988654395232, 0.826546435316577, 0.8178407871922055, 0.8282124727243199, 0.8099605598525064, 0.7990945714870731, 0.631697141290547, 0.6533515825099128, 0.5526945234446089, 0.6371407146747052, 0.5982601992086524, 0.6331888732650401, 0.6467642598039869, 0.5249952162622928, 0.6254599933694271, 0.11129795384906793, 0.14156131421429907, 0.14528114562495198, 0.1105242040925759, 0.13810766690387377, 0.12478341631151701, 0.12929619219821975, 0.13259036768635546, 0.13071154335520696, 0.1437780242212442, 0.1408443089756789, 0.11118224719847769, 0.10304520587567478, 0.1143180851946739, 0.1036737380638495, 0.1320544121895335, 0.11380649123647213, 0.1157696078373901, 0.9894806273889966, 0.9817974200801436, 0.9854942734013665, 0.9834819914594184, 0.9863064781476906, 0.9886446218460548, 0.9863584002044425, 0.9816063746569981, 0.9872003962449999, 0.6395533814366087, 0.6035702137329864, 0.5611138526180723, 0.6717623943922135, 0.6387860636165072, 0.5228382575387209, 0.6383514455811288, 0.6104133182652028, 0.56594684689811, 0.3221181335507046, 0.3561974758557285, 0.6915055303175188, 0.27085447841494437, 0.2294516786263312, 0.15913447775885703, 0.7477615771309698, 0.7767241201235414, 0.3105154919591544, 0.12758360214844666, 0.49326393003880753, 0.4987351819195356, 0.6031284544129619, 0.5531021971918388, 0.6171950257925918, 0.6352369621860476, 0.5206839318568341, 0.5280868656979035, 0.5474459131284412, 0.15218003600243246, 0.12451957216368315, 0.516860808539858, 0.5317989987895122, 0.5341295459953115, 0.12923997456738556, 0.12355182643394713, 0.5824278664501553, 0.05497528309143673, 0.2097565505866681, 0.101075654619321, 0.07149750539849575, 0.05047993598319045, 0.08614654746959727, 0.11941873098675593, 0.05887301906031661, 0.00935800627370631, 0.24733599700703313, 0.2805165285376531, 0.26208040256203124, 0.30997570006263186, 0.13165344993060046, 0.26944089538775684, 0.20244324320690188, 0.23102735672920438, 0.4974926021303254, 0.08012840098029317, 0.04642950691317671, 0.14624867918845175, 0.21168203784473605, 0.18641983316851563, 0.15773508955266313, 0.10054851959043376, 0.09934230673397271, 0.1375996957001111, 0.16556255099341943, 0.1145974873104888, 0.15259995113964864, 0.16883045146908116, 0.3648086708666862, 0.29291636459765824, 0.31526026889992076, 0.18223866610077522, 0.07623344033829493, 0.6729066312322713, 0.6475373050056967, 0.5974651167538341, 0.6022972456451281, 0.6538049901221052, 0.6188004586859772, 0.6775842269358479, 0.583830126502883, 0.6166567163818376, 0.07611666608884748, 0.11345708813044297, 0.11054323824638412, 0.09911273776283525, 0.09011030191502145, 0.13662965591845, 0.10735075511712788, 0.13176917230941942, 0.12817287906111108, 0.23185534351433446, 0.18475719246017974, 0.22844007979415326, 0.15544162452224608, 0.1769021817621511, 0.1653966100148878, 0.4045382343587337, 0.16959703954028849, 0.24651060919262036, 0.3620779319747197, 0.3636212933524008, 0.4056930634795217, 0.3075152339563666, 0.3177846711646135, 0.30362828429863953, 0.323453061706546, 0.3527519157959683, 0.2614984402225037, 0.2044681724211127, 0.3125386051580342, 0.22361105155696837, 0.26010789285355795, 0.2320801447148828, 0.28834667180917395, 0.247122188215379, 0.2561553168181978, 0.30088787226096103, 0.20742444957414952, 0.22920493104502326, 0.1974180154263172, 0.22040463830115808, 0.24513335406981562, 0.20893278110838565, 0.23555588440604736, 0.20107045704509696, 0.25331529354957805, 0.1877323096718122, 0.19094415355129568, 0.18938212252181463, 0.2044734892315231, 0.18742101097598773, 0.19318246001704475, 0.19466716785448357, 0.23826594517612898, 0.2053878830440361, 0.8706704966828998, 0.8373186565756393, 0.1851949229467249, 0.16487215495466934, 0.3213575217104315, 0.23323104899128633, 0.15341903720207628, 0.15961933966972608, 0.8198476966433785, 0.8436148306399287, 0.2111324705183809, 0.21264449211962855, 0.8105414464082148, 0.20503752029273348, 0.30788641575222353, 0.21239347963157007, 0.20894647044624604, 0.7275268352839441, 0.1986023367648464, 0.21721787105629276, 0.20356560305387816, 0.21157277198474445, 0.19636581994620705, 0.1859244877944437, 0.2020858889024918, 0.19026118473174103, 0.21505678701528197, 0.08732613207296758, 0.10526623064803386, 0.09833571183523637, 0.09547705952891816, 0.0979156372219091, 0.09323776598479361, 0.08314866376538832, 0.08308519373066425, 0.0978212072288257]}, "mutation_prompt": null}
{"id": "363fd533-be01-4c52-b878-1663f0b049a7", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Slightly reduced population size for faster convergence\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.7  # Adjusted inertia weight for control\n        self.c1 = 1.5  # Altered cognitive coefficient for enhanced local search\n        self.c2 = 1.8  # Balanced social coefficient\n        self.F = 0.9  # Fine-tuned mutation factor for diversity\n        self.CR = 0.75  # Adjusted crossover rate for explorative robustness\n        self.adapt_factor = 0.95  # Adaptation factor for dynamic control\n        self.diversity_prob = 0.3  # Increased probability for diversity manipulation\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Continuously adjust inertia weight\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A refined adaptive DEPSO hybrid optimizer with dynamic mutation and diversity enhancement for robust exploration and faster convergence.", "configspace": "", "generation": 39, "fitness": 0.36753085575035693, "feedback": "The algorithm RefinedAdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.27.", "error": "", "parent_id": "f1de49e0-fa67-4cc6-ad1b-5acddda8b9c5", "metadata": {"aucs": [0.8144970951667241, 0.8080687056221428, 0.7941559202044083, 0.8067770356188382, 0.8053099748287644, 0.7924278075164354, 0.8175444463007562, 0.8186890291019615, 0.7915407124594207, 0.6375892759763413, 0.5915685524670533, 0.6189662882433167, 0.6289619338403406, 0.6060001053465176, 0.6072650717121928, 0.5599304494034578, 0.6229860162884664, 0.5446191182777322, 0.10326164140677052, 0.13008880389504973, 0.122677699180048, 0.13247924381642406, 0.11745332491516924, 0.1374073784113502, 0.4757227732405418, 0.11722860577935534, 0.1261202533539707, 0.09085710827980331, 0.13708095053778302, 0.09180506266925004, 0.09860222096044258, 0.06652125087571181, 0.0984542159677727, 0.12038225563677007, 0.1286997541295617, 0.0970567625446338, 0.9894517920164547, 0.9863499116385654, 0.9871357845916038, 0.9899491152053262, 0.9793167381097089, 0.9898016488816852, 0.9774441411734788, 0.9817013604623955, 0.9872653345738278, 0.616037114093467, 0.6155694759379131, 0.6053324595580427, 0.5856067107361151, 0.5913142439887125, 0.5464574952401752, 0.5558545095099596, 0.6054039147293608, 0.5817375570297094, 0.8344426490823427, 0.7597620147469937, 0.35895814966254125, 0.21346693006090034, 0.21414694545239876, 0.8134822331022483, 0.12553320626796416, 0.13889860558044365, 0.7590188617996189, 0.6055680953641445, 0.42105165332911454, 0.5549073308424519, 0.0957931940446971, 0.5496544513695185, 0.5784389768135874, 0.5459299718463928, 0.6116917209634167, 0.6035667121072892, 0.686294138039572, 0.5791100313893283, 0.6239323076432883, 0.6065293063263995, 0.4535507753484439, 0.5327074866731187, 0.12549730557385996, 0.12169013378525761, 0.10786979095200333, 0.059694885710242285, 0.10749506364531358, 0.24708366409426297, 0.041725944980514074, 0.0979228925838499, 0.3883038924066964, 0.030751893106865102, 0.1118153426065075, 0.03907089481367676, 0.5796144789263454, 0.6207858411201219, 0.5599885965698966, 0.08589729401833102, 0.2107162988566239, 0.41153242031098414, 0.4151522495651496, 0.6003065827120508, 0.53944303580584, 0.0430162930215654, 0.0631589682717224, 0.2832626351988019, 0.12115247288512743, 0.1841965016088719, 0.28117396886090806, 0.11753424994441064, 0.23685331225176653, 0.10863284274779184, 0.154507491869166, 0.23625823157662407, 0.22756935504396636, 0.2731057164545275, 0.09028927082365024, 0.3276257570084433, 0.14892532989175344, 0.21538086866619943, 0.1052430528052215, 0.7128508490155343, 0.6713132015498322, 0.5861764152841811, 0.6563079970005202, 0.7244777636929183, 0.713030649927042, 0.6767513368794003, 0.6231744486711487, 0.6593329007210602, 0.13472577160449017, 0.13587544183039135, 0.08583818474833627, 0.12964917048142266, 0.12345600717884175, 0.09732486972898002, 0.1212965008446032, 0.07857621225653533, 0.08242522615510117, 0.20489283845322692, 0.23477810627504447, 0.24532895970671886, 0.25707997239718994, 0.2627002865971789, 0.17444692846932142, 0.37374572659417604, 0.1601962868414576, 0.1673668265600099, 0.3811535015120121, 0.39211242838793636, 0.3467882545109171, 0.3529422850572147, 0.43933413884107486, 0.3574676294321485, 0.35708573555266954, 0.31401317640507864, 0.25673170034491155, 0.29890494938920587, 0.23730912911761892, 0.3781851588802577, 0.3168646485469837, 0.2122564407612465, 0.19689191115105553, 0.25938032528975186, 0.2611927914756439, 0.3380343034865565, 0.25010068403241226, 0.2119291894173071, 0.18825268345148283, 0.2018126075715706, 0.1927209486150061, 0.2899745737441126, 0.25560769697232255, 0.1872088977158527, 0.22423722389458955, 0.18727709952242144, 0.2166346761264799, 0.20001371332324103, 0.2435812047460466, 0.19595551698468072, 0.17318961547117817, 0.18932289096150723, 0.18869462357395028, 0.19388513802628582, 0.8823205712478401, 0.20484826388338861, 0.18615252342624666, 0.16424890703156414, 0.34159611619776464, 0.20172594001620536, 0.19219857821797415, 0.7944463764291003, 0.8476817374833722, 0.8489196979800364, 0.20990207630621316, 0.7605757768855139, 0.8425509906709876, 0.16665492751396083, 0.23293653762973487, 0.21032483614674802, 0.15801813441385126, 0.7513722718666405, 0.18257522951545735, 0.200889786597779, 0.2050663118852447, 0.1816014573649256, 0.19135386606840565, 0.20573251190457176, 0.20418079558250857, 0.19420356413740303, 0.1894644159640544, 0.08448276870066584, 0.11073912537306985, 0.08222554406037286, 0.09691861467360419, 0.09298376382493823, 0.09320359836428938, 0.08226686588978172, 0.10151711637626282, 0.0934121503063221]}, "mutation_prompt": null}
{"id": "b97f4e93-8c5d-4b90-bf37-11cbb0e613a8", "solution": "import numpy as np\n\nclass AdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Slightly reduced population size for efficiency\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.7  # Slightly increased inertia weight\n        self.c1 = 1.8  # Enhanced cognitive coefficient for better local search\n        self.c2 = 1.4  # Reduced social coefficient for better balance\n        self.F = 0.9  # Increased mutation factor for more diversity\n        self.CR = 0.75  # Slightly reduced crossover rate\n        self.adapt_factor = 0.95  # Adjusted adaptation factor for control\n        self.diversity_prob = 0.3  # Increased diversity probability\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Continuously adjust inertia weight\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "AdaptiveHybridOptimizer", "description": "Adaptive hybrid optimizer combining DE and PSO with dynamic parameter tuning and diversity introduction for enhanced exploration-exploitation balance.", "configspace": "", "generation": 40, "fitness": 0.3591692128682712, "feedback": "The algorithm AdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.27.", "error": "", "parent_id": "f1de49e0-fa67-4cc6-ad1b-5acddda8b9c5", "metadata": {"aucs": [0.8237881749329221, 0.8116949771296662, 0.7925281855385169, 0.8255862098844278, 0.8079642330107726, 0.8161351847122451, 0.8280513057776752, 0.8359514830606568, 0.8153428222005579, 0.5801577153341, 0.6003811041627429, 0.5516536465854627, 0.6432368053738602, 0.6604711603578115, 0.6136021958732003, 0.6177259320656452, 0.6113946207468505, 0.5587867182241372, 0.09171892179686603, 0.12096134039519824, 0.09563838442292671, 0.10707330455013997, 0.13819707515780155, 0.13944815173793446, 0.11246663916623822, 0.11875611242822248, 0.13547425028633842, 0.1055831830443934, 0.09786086785921944, 0.08613824104598822, 0.10691296942555895, 0.07551322551368067, 0.1057724926686735, 0.10362850288178438, 0.10527056136330082, 0.09690087456145013, 0.9894492138752514, 0.9861987339409585, 0.9812777313077042, 0.9834752584374445, 0.9862370179531492, 0.9811027044411399, 0.9777137299180398, 0.9821216621417037, 0.9872090890534237, 0.64714229183862, 0.5680869266175949, 0.6370814782574148, 0.6692274251969814, 0.6152662889536047, 0.5809101720272976, 0.6942325074086405, 0.6508261230465602, 0.6533369584262598, 0.7714741381850718, 0.8002021756005521, 0.8206698923069533, 0.21563159493174466, 0.25921990762838054, 0.25413146037333767, 0.7346585948547606, 0.22941290575732187, 0.23362154602586038, 0.12378903242529338, 0.3324998229888828, 0.5050452765943498, 0.5615863208558929, 0.5532020231077642, 0.12601889484549755, 0.5658628775747405, 0.12448183183372052, 0.12718235811237533, 0.12841230242648594, 0.619445124882434, 0.12286684599150943, 0.6353426717801544, 0.6220896581621975, 0.492017223994075, 0.12959316488833483, 0.5498755562430417, 0.5111086254814752, 0.05884527675956419, 0.1509870254808755, 0.06112398176281475, 0.05033974047641965, 0.2193024087509109, 0.014292456470978099, 0.23985717054654898, 0.2450862610735809, 0.0649436080045529, 0.23468512610022418, 0.20103589611588002, 0.5055057295063019, 0.46453758004255186, 0.2015287549794912, 0.28181454172836606, 0.4192163035041705, 0.4381481785233595, 0.5843575538478831, 0.07797758049649406, 0.029009866703720077, 0.1601429042757847, 0.11560628662725225, 0.27384517242387474, 0.12142414211170593, 0.2616107668749952, 0.08783606149776702, 0.11092645570131465, 0.30324299567131596, 0.23992829398280724, 0.22449581208465508, 0.17991684530459662, 0.18985890418248952, 0.17970710013196167, 0.29615275418438847, 0.09895717027750739, 0.07637334586204703, 0.6183787564404379, 0.6397695055391783, 0.6311762214401283, 0.6051141810549048, 0.6293810344909871, 0.6450627303053206, 0.6874724827876733, 0.6551347298331848, 0.6317555033303126, 0.11163976826529398, 0.08299130175125524, 0.11470042001941005, 0.1265215190097837, 0.07092140814768022, 0.07501257629162106, 0.13806690178025605, 0.1193150704686946, 0.13813567386812886, 0.22940812360828455, 0.19232649539834523, 0.22698051029664845, 0.24969606715001968, 0.39101806042057874, 0.163445240235097, 0.21226778645658295, 0.17123028654270112, 0.3989372971288453, 0.31190167989941997, 0.2342437687971718, 0.38868480957612495, 0.3430922449097866, 0.3881291764789946, 0.34367563247268396, 0.39983534327935755, 0.4132567554998867, 0.40108364222691084, 0.21693264766666875, 0.2087158672625854, 0.2864662953015543, 0.23427629977694064, 0.33331523484248715, 0.3408390885543705, 0.26132932341355863, 0.38270388877248207, 0.18928850555173526, 0.2685777523661189, 0.20755085612997337, 0.2198428317053649, 0.23739997276475922, 0.20895376186288184, 0.21001198495312356, 0.22604511424497253, 0.23408293912550415, 0.23446364140749543, 0.20063397910013114, 0.19635777674913357, 0.1764548659203652, 0.21722073212951098, 0.21933548839339423, 0.20598489196774417, 0.7602922089592509, 0.2179701208930247, 0.18963820742517734, 0.8920475761924148, 0.20403950048995234, 0.15214182567338153, 0.8633004928484472, 0.3322966224016738, 0.20823798716312714, 0.1534425290077983, 0.16126710202944483, 0.8506027183867483, 0.8325665268118232, 0.20780007723829663, 0.20090505134546988, 0.8568764695771065, 0.16665084451292111, 0.820248741053283, 0.2116397407960191, 0.16647410584153954, 0.7038844711322885, 0.21034433544325037, 0.21173654274956832, 0.18872605885240756, 0.19481503423771918, 0.18813851500618106, 0.18976876594921677, 0.21656859816977636, 0.17905940170472334, 0.1760319498243672, 0.0858031665393697, 0.08016457120672016, 0.08985409927892107, 0.10011228705970565, 0.09011362449747717, 0.10039034643562628, 0.1144663673694013, 0.0959412525497686, 0.09892093168853222]}, "mutation_prompt": null}
{"id": "908194e8-7a49-44de-8c94-c72806631b2f", "solution": "import numpy as np\n\nclass OptimizedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Adjusted population size for strategic balance\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.7  # Optimized inertia weight for improved control\n        self.c1 = 1.6  # Fine-tuned cognitive coefficient for local searches\n        self.c2 = 1.8  # Enhanced social coefficient for global interaction\n        self.F = 0.9  # Optimized mutation factor for maintaining diversity\n        self.CR = 0.7  # Revised crossover rate for balance in exploration\n        self.adapt_factor = 0.95  # Adaptive factor for dynamic inertia weight adjustment\n        self.diversity_prob = 0.3  # Increased probability for diversity enhancement\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Gradual adaptation of inertia weight\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "OptimizedHybridDEPSO", "description": "Optimized inertia weight adaptation and hybrid strategy combination for enhanced exploration and exploitation balance.", "configspace": "", "generation": 41, "fitness": 0.3501501436563149, "feedback": "The algorithm OptimizedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.26.", "error": "", "parent_id": "f1de49e0-fa67-4cc6-ad1b-5acddda8b9c5", "metadata": {"aucs": [0.8038026217052243, 0.792310295261769, 0.8109129953435925, 0.7872873850556973, 0.7963538240945163, 0.8053279112621069, 0.8319086407976723, 0.7976432768687269, 0.7910744930407164, 0.6322673126878594, 0.6100200858979492, 0.5695264005876692, 0.06062224697623897, 0.603645623115447, 0.5760961968180809, 0.6547789531078528, 0.6275354035694605, 0.6079131364389823, 0.13694243979544374, 0.12732528523177933, 0.1361787851857552, 0.13747501152830865, 0.14514883356493524, 0.1409466514611757, 0.14631117342445177, 0.12272697454761472, 0.13659735477431878, 0.09064799434761373, 0.09502188285028801, 0.06485011469186885, 0.10987833779592093, 0.1000704758375448, 0.09853595771412405, 0.09195158446227669, 0.09385951937897241, 0.09581175132195818, 0.9894559253561593, 0.9863499116385654, 0.9872251488345906, 0.989976984787122, 0.986239681722499, 0.9897880952917211, 0.982552060309202, 0.9815727152292646, 0.9886015026588341, 0.5830032250058754, 0.595894211076879, 0.6120760656917065, 0.5741426232512777, 0.5730492717136686, 0.5080648318746348, 0.6302521642017542, 0.5627952231684409, 0.5491320495527265, 0.386016656255192, 0.22568907992736953, 0.7249880460464474, 0.2076127071100704, 0.2613410606846318, 0.18405564876449876, 0.2370320840849779, 0.2138759329196278, 0.2306080556733694, 0.692747014644378, 0.5092570183225316, 0.6242753378039658, 0.09692519006873246, 0.5064459620675638, 0.5527707618961175, 0.5891984104465873, 0.12034832805744011, 0.5515827270777144, 0.6453380181808215, 0.17414452221635368, 0.4829340836621119, 0.5202609124659113, 0.38604014023467503, 0.124421743346109, 0.12579431212935155, 0.12178126745201667, 0.4396158788692086, 9.999999999998899e-05, 0.05340598223274606, 0.09890462670373035, 0.0006072818551218218, 0.16870097843401977, 0.015987401903377774, 0.3724937519297694, 0.13619162837006804, 0.03292320447606745, 0.2731307852571355, 0.4203761092490469, 0.5153047146008223, 0.26773178620624827, 0.2010178209463973, 0.32605075250988724, 0.49609267819241454, 0.5614509947695322, 0.21160621021384562, 0.06551691045652697, 0.06174341850335807, 0.20808020767119273, 0.11789062850764587, 0.12086084010487652, 0.19452776047750509, 0.1136041119523985, 0.22687094241295935, 0.07468120891206875, 0.2584365218372008, 0.48167595259089646, 0.2999956644785252, 0.3712983161290617, 0.2991619989368959, 0.2684504852267878, 0.050469374944167256, 0.0779840999625887, 0.0760472971202949, 0.7669503992646509, 0.7189552455922592, 0.7205962378362052, 0.732254005129026, 0.5639638274562015, 0.6689613269351681, 0.668045833497318, 0.6521574199684569, 0.5985247738180587, 0.13727724019226584, 0.1397194335600177, 0.10849131817121194, 0.09349012573144977, 0.09532884105694173, 0.14064961302621637, 0.1309346660852403, 0.0917442989624575, 0.1430665778774115, 0.2722944526711004, 0.24448035026993997, 0.1945957888527, 0.26782595825496835, 0.2177353810043191, 0.2534751058264264, 0.3789810438697412, 0.32534477371213466, 0.19703417229788622, 0.27787232270841855, 0.371989845289886, 0.2866788759695309, 0.27933236128569383, 0.2810777851589513, 0.44714999466508354, 0.3826369996127883, 0.3862521210789187, 0.29809036307355397, 0.26387152123318747, 0.25643182040032053, 0.3095807587066538, 0.2996218244540655, 0.21695734103502995, 0.36346612128960687, 0.20390065731126528, 0.2250464502260181, 0.28722781258370744, 0.20602557650562625, 0.2042055568325173, 0.2054108353314127, 0.22495026452491362, 0.19514656939069697, 0.23943881204248596, 0.23269135141366082, 0.18032180222799765, 0.20138069525198665, 0.2159913813323694, 0.19653568341827155, 0.20060995820886907, 0.24677021913020258, 0.2031216842216419, 0.19560821437248066, 0.23146251094526782, 0.20330715569057378, 0.1756177844968292, 0.8664305626193455, 0.8200195539278522, 0.1849809899646141, 0.819566252181965, 0.3343671678202059, 0.20585432484574262, 0.15161384809283796, 0.18047541997833927, 0.8138161155630292, 0.8437801246679553, 0.21109297166157504, 0.20403507337740834, 0.8388512042589829, 0.19817929868824413, 0.1891731037026293, 0.20176218113077793, 0.7531615300881557, 0.7529777228207286, 0.18941814991871475, 0.21021796263231374, 0.18044575600854929, 0.178917424235026, 0.18918841118403507, 0.20622872170140716, 0.1833460137522459, 0.23225754949074962, 0.20586981529590342, 0.08544868010973572, 0.09428688295335907, 0.10190599951721291, 0.08334761510961619, 0.10241257675169568, 0.09522237353393737, 0.08510265826955021, 0.08293374748828175, 0.08313203368923228]}, "mutation_prompt": null}
{"id": "80e28b9a-38d3-450c-9ddd-afbb25af32c9", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 12 * dim  # Population size to balance exploration\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.7  # Slightly increased inertia weight for better momentum\n        self.c1 = 1.5  # Lowered cognitive coefficient for improved diversity\n        self.c2 = 1.8  # Enhanced social coefficient for global search\n        self.F = 0.9  # Increased mutation factor to enhance exploration\n        self.CR = 0.75  # Adjusted crossover rate for better trial vector creation\n        self.adapt_factor = 0.95  # Smaller adaptation factor for gradual control changes\n        self.diversity_prob = 0.3  # Higher probability to inject diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Gradually adjust inertia weight\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOOptimizer", "description": "A refined adaptive DEPSO hybrid optimizer with dynamic velocity control and enhanced elite mutation for improved exploration and exploitation.", "configspace": "", "generation": 42, "fitness": 0.34904946196810255, "feedback": "The algorithm RefinedAdaptiveDEPSOOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.26.", "error": "", "parent_id": "f1de49e0-fa67-4cc6-ad1b-5acddda8b9c5", "metadata": {"aucs": [0.7949539383317095, 0.7921334597836298, 0.7770247359945615, 0.7966394700851356, 0.7861091456761202, 0.7985222891304831, 0.7715803248463945, 0.7644104063330216, 0.7828684716848212, 0.47314843764132, 0.4717387903198865, 0.06545986775528512, 0.47722522665871936, 0.5452225154952528, 0.5178337512779203, 0.5816948949479066, 0.5819716676382226, 0.04788460073540812, 0.10469725709885791, 0.1340203352050514, 0.13715901149213028, 0.10432782087207537, 0.12982689462918628, 0.12514582831213306, 0.10345735081662955, 0.11048493385009783, 0.136139438901963, 0.09569805141172838, 0.07714244302827589, 0.14500485258782414, 0.10063496856536003, 0.0908846837888535, 0.10169249204107023, 0.14237937951928503, 0.09208032378171793, 0.09300316556740729, 0.9875849646134474, 0.9853425733826534, 0.9866480392698332, 0.9834566405977545, 0.9731706562933471, 0.9854585992131448, 0.9874462012911419, 0.9842600883652657, 0.9882871158906108, 0.5256741054151208, 0.5980660319163156, 0.5036189778183642, 0.5389224749035342, 0.5969269435077972, 0.5518961912828098, 0.5681436375721485, 0.5742028522534246, 0.5084950246058035, 0.22209861243959306, 0.7450030767172796, 0.21991346166665748, 0.27104853771114745, 0.1837351883845818, 0.18688798451335809, 0.21835782088698785, 0.7565319031204907, 0.7640217614902295, 0.6467132045890147, 0.4031274395951293, 0.1193723258141638, 0.12421842320443155, 0.5746002752101818, 0.5092208686546347, 0.48536512837444057, 0.12317744289500154, 0.5620513436809695, 0.612265104871826, 0.4400035814092774, 0.5816777258416221, 0.1239768768516909, 0.5281093719160214, 0.5914894506063308, 0.5202375011171962, 0.511649480733523, 0.12087515351981093, 0.05035751618244577, 0.25916752654671993, 0.05872431539549794, 0.0006326627473343116, 0.15065911881776806, 0.20796875573896578, 0.3080055004102986, 0.16273138994255698, 0.1478637420727329, 0.41283475364360933, 0.2584681523639685, 0.5828473772646887, 0.6167074787509191, 0.5905094211835982, 0.2805875883754597, 0.5837261464886763, 0.5776666202280083, 0.4924245901682711, 0.06262228907676692, 0.05009968005036958, 0.06131095233935757, 0.16331451947830333, 0.2120078944636986, 0.20282389642139642, 0.09068683415546475, 0.27394098223961105, 0.14432561293944002, 0.26206167549381687, 0.3276757088782427, 0.19006059980305845, 0.33363905331616484, 0.2635654502832112, 0.19102975161339353, 0.21943374491483747, 0.19372422798912714, 0.07690975471236616, 0.6726059722770112, 0.6362207678091727, 0.7134336959253846, 0.6188268534848027, 0.5890032145576728, 0.6380719421727323, 0.6447842206639801, 0.6060752229850332, 0.5924134686671156, 0.1301947111507823, 0.07748523352327175, 0.09047586812015995, 0.08201424021903081, 0.1269095372108746, 0.09263036284683224, 0.09426038367617895, 0.11280862368594335, 0.1218667404247602, 0.18843053651674457, 0.31756108669632466, 0.1777264128586008, 0.16186957482007125, 0.43856959464757395, 0.16219182217764117, 0.2415687705119085, 0.21751754691262692, 0.24928038667696795, 0.3307235136358265, 0.4166946006576263, 0.37456625654294307, 0.3523498589681552, 0.3437055516615396, 0.3073467837338534, 0.35333428328795, 0.3202036380250215, 0.3780333067397067, 0.31628591071168166, 0.2329132477295418, 0.24820134632107915, 0.1838807173884658, 0.2474206955943038, 0.31397899219928305, 0.247918177887681, 0.266524561669342, 0.20005877696526153, 0.25405927894116154, 0.27531550358498613, 0.20993514453190087, 0.22056957695906954, 0.21052844958956263, 0.21410436584940218, 0.2263432218489395, 0.24634148126516553, 0.22352002526254489, 0.19466174708494177, 0.23011733745354868, 0.18560711649003347, 0.20291748389466113, 0.1925430991017938, 0.18854411679902883, 0.6224478533755982, 0.20556360485122904, 0.17059400451853124, 0.1933160615997106, 0.2027528402581521, 0.758155579205285, 0.17573656097886392, 0.19775151849955852, 0.7633143145510046, 0.142495369214102, 0.16124595404650421, 0.6029896218284676, 0.8618991295800172, 0.20792665824538004, 0.7447144524060634, 0.7900935088912955, 0.16799622550277238, 0.2001364959978983, 0.2077564726644876, 0.1647915494855311, 0.7899478876693282, 0.2104081714726479, 0.19440993550711216, 0.18784942454597542, 0.18669515719758434, 0.2169827583880226, 0.18644933124389296, 0.1879212061354819, 0.19249515488953484, 0.20703735569371562, 0.12202577121120739, 0.11342435019930786, 0.08033455741628037, 0.09552979458855893, 0.08123903498364249, 0.10322989024482232, 0.11783906520512832, 0.08582118541580586, 0.10467434350274385]}, "mutation_prompt": null}
{"id": "5f4aa088-1476-4029-87a0-610663854d84", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Slightly reduced population size for efficiency\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.7  # Adjusted inertia weight for improved convergence\n        self.c1 = 1.5  # Adapted cognitive coefficient\n        self.c2 = 1.8  # Enhanced social coefficient for better global search\n        self.F = 0.9  # Modified mutation factor for increased diversity\n        self.CR = 0.7  # Adjusted crossover rate to maintain balance\n        self.adapt_factor = 0.95  # Slower adaptation for smoother control\n        self.diversity_prob = 0.3  # Increased probability for diversity manipulation\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Gradual adjustment of inertia weight\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A refined adaptive DEPSO hybrid optimizer with dynamic inertia decay and improved diversity introduction for enhanced convergence.", "configspace": "", "generation": 43, "fitness": 0.36134622409715506, "feedback": "The algorithm RefinedAdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.27.", "error": "", "parent_id": "f1de49e0-fa67-4cc6-ad1b-5acddda8b9c5", "metadata": {"aucs": [0.8143628924471044, 0.8070263582335679, 0.7614720594325453, 0.8077773461440549, 0.8222518896026934, 0.8050954855088324, 0.8241237728049771, 0.7941188979957066, 0.8123711067906524, 0.03811857309951561, 0.6152802686595626, 0.6147216067997061, 0.6169342007761198, 0.5790838734426005, 0.6121932586378152, 0.565361997693985, 0.5975443349314408, 0.5547704916209212, 0.10198050318696694, 0.09696461343581775, 0.12075516533402864, 0.137292876318569, 0.16930375064320546, 0.11438315745682248, 0.12425627233660141, 0.10733405115291639, 0.12217803459665721, 0.10769579865463852, 0.11636303832467843, 0.0889809197768553, 0.12405841459148503, 0.1271990133396974, 0.12022888855855851, 0.11799249159572245, 0.051399937467176304, 0.1394796265371675, 0.9894517920164547, 0.9863499116385654, 0.9871357845916038, 0.989976984787122, 0.9862352901356464, 0.9897880952917211, 0.9803189375009079, 0.9817013604623955, 0.9872653345738278, 0.6312101399744872, 0.5953286758343193, 0.6189031759371786, 0.6144715526328022, 0.6079797839357577, 0.5405321688306095, 0.5462972377695416, 0.5944642144439111, 0.5806755226608187, 0.7235453201932174, 0.21752332765101146, 0.3015243055740432, 0.7010070775760296, 0.20782066998383264, 0.18981698010202264, 0.8073509540362462, 0.7923194306963504, 0.7419837535363454, 0.6805303799188315, 0.3788898174876535, 0.5995644840961236, 0.11571000227541861, 0.1281753667617639, 0.6232682150357678, 0.6188948184760579, 0.6335721395495195, 0.5951730675290383, 0.5090389871860002, 0.17626010241538947, 0.11391831814057973, 0.591850203734837, 0.5861248098570744, 0.5649549249891388, 0.1256346800328958, 0.11711646901003514, 0.10884065620179995, 0.06547031444368401, 0.05436816178351889, 0.07483396269078657, 0.0006143034051078189, 0.01644336948138192, 0.15954910613276152, 0.22425052302617254, 0.1262619054025923, 0.007597459014046404, 0.3510838171228199, 0.5947908927995547, 0.4215363351924155, 0.12644087895891476, 0.4249420024034861, 0.14858086289560435, 0.2760881575137334, 0.557395090069036, 0.6062453251680289, 0.0529128389233714, 0.06050669487759619, 0.23961423698380635, 0.13074819735326615, 0.2721709889760978, 0.27220450464546053, 0.10074188332178946, 0.22241595787801038, 0.08495300069999956, 0.204896295218574, 0.22687264368545346, 0.2014590951126901, 0.32522367562030763, 0.26435705528484, 0.20061677724113847, 0.05353225153723851, 0.15279019163250507, 0.1785018451325242, 0.6815495319766539, 0.6555817145700129, 0.6568724248128288, 0.7279522185883687, 0.6925376214366232, 0.6761433721160085, 0.703571572888852, 0.7631500489252284, 0.7096095913888432, 0.09004601636878284, 0.13513383361945364, 0.11195647191955393, 0.12778061748208436, 0.1408937693216532, 0.07290148774176997, 0.07391523076179651, 0.09196197209455603, 0.07558286500517919, 0.19780254959785692, 0.3620165837332643, 0.24257861708039496, 0.308843586964042, 0.23171713940080785, 0.1720849997535302, 0.2481029916988492, 0.22188645672969554, 0.18213680060732562, 0.35318491229512283, 0.3909703846014134, 0.28831341812175515, 0.4185914601481864, 0.2429035436403133, 0.43583468871378617, 0.36271234261140906, 0.3450280447162325, 0.4350763773325188, 0.2137410101126328, 0.23761126880544647, 0.2858055975745406, 0.27834016640418824, 0.2081953265503188, 0.3013767839949414, 0.28391283496026665, 0.3076847793791374, 0.21373011738064784, 0.1880159331482152, 0.21386463869242223, 0.2023804251462824, 0.2419780729796276, 0.21451586340665074, 0.2063685843154991, 0.20882435037473168, 0.19534824584864918, 0.2627403001723967, 0.19690889978133563, 0.2207779170235037, 0.18171651333421845, 0.17958762572983122, 0.18807611964443227, 0.18706555721822615, 0.18714725332853233, 0.19087861308012155, 0.17427852880156702, 0.8805217758717662, 0.8026537495253276, 0.18639316759911706, 0.1668571649019246, 0.341632544744912, 0.2036109037158943, 0.16606327641352758, 0.8218441076158229, 0.8554600799909138, 0.8615200642178074, 0.20980385239408683, 0.1964080768930353, 0.8531574425918631, 0.7557550794301838, 0.22279379187737736, 0.20977934784965824, 0.691601868658532, 0.724458501380732, 0.19237278606121777, 0.18170412389344714, 0.18784512721321478, 0.18872485109706605, 0.18232257379606343, 0.19837075275311689, 0.18946613625648157, 0.1888008353138675, 0.200855118723542, 0.10644124100808572, 0.10709712065110799, 0.0892844463181316, 0.08417622465479602, 0.09004333000511755, 0.09168222485419375, 0.0882813472079984, 0.08600510616435664, 0.0792388827657029]}, "mutation_prompt": null}
{"id": "ed46f4e6-a0ef-41b9-9427-eb33164ce039", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 12 * dim\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.7  # Modified inertia weight for better balance\n        self.c1 = 1.5  # Slightly reduced cognitive coefficient\n        self.c2 = 1.8  # Increased social coefficient for global exploration\n        self.F = 0.9  # Adjusted mutation factor for broader search\n        self.CR = 0.75  # Slightly reduced crossover rate\n        self.adapt_factor = 0.95  # Increased adaptation factor\n        self.diversity_prob = 0.3  # Higher probability for diversity boost\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "EnhancedAdaptiveDEPSOHybridOptimizer", "description": "A dynamically adaptive differential evolution with particle swarm optimization hybrid incorporating elite learning and stochastic restart for enhanced convergence and exploration.", "configspace": "", "generation": 44, "fitness": 0.34904946196810255, "feedback": "The algorithm EnhancedAdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.26.", "error": "", "parent_id": "f1de49e0-fa67-4cc6-ad1b-5acddda8b9c5", "metadata": {"aucs": [0.7949539383317095, 0.7921334597836298, 0.7770247359945615, 0.7966394700851356, 0.7861091456761202, 0.7985222891304831, 0.7715803248463945, 0.7644104063330216, 0.7828684716848212, 0.47314843764132, 0.4717387903198865, 0.06545986775528512, 0.47722522665871936, 0.5452225154952528, 0.5178337512779203, 0.5816948949479066, 0.5819716676382226, 0.04788460073540812, 0.10469725709885791, 0.1340203352050514, 0.13715901149213028, 0.10432782087207537, 0.12982689462918628, 0.12514582831213306, 0.10345735081662955, 0.11048493385009783, 0.136139438901963, 0.09569805141172838, 0.07714244302827589, 0.14500485258782414, 0.10063496856536003, 0.0908846837888535, 0.10169249204107023, 0.14237937951928503, 0.09208032378171793, 0.09300316556740729, 0.9875849646134474, 0.9853425733826534, 0.9866480392698332, 0.9834566405977545, 0.9731706562933471, 0.9854585992131448, 0.9874462012911419, 0.9842600883652657, 0.9882871158906108, 0.5256741054151208, 0.5980660319163156, 0.5036189778183642, 0.5389224749035342, 0.5969269435077972, 0.5518961912828098, 0.5681436375721485, 0.5742028522534246, 0.5084950246058035, 0.22209861243959306, 0.7450030767172796, 0.21991346166665748, 0.27104853771114745, 0.1837351883845818, 0.18688798451335809, 0.21835782088698785, 0.7565319031204907, 0.7640217614902295, 0.6467132045890147, 0.4031274395951293, 0.1193723258141638, 0.12421842320443155, 0.5746002752101818, 0.5092208686546347, 0.48536512837444057, 0.12317744289500154, 0.5620513436809695, 0.612265104871826, 0.4400035814092774, 0.5816777258416221, 0.1239768768516909, 0.5281093719160214, 0.5914894506063308, 0.5202375011171962, 0.511649480733523, 0.12087515351981093, 0.05035751618244577, 0.25916752654671993, 0.05872431539549794, 0.0006326627473343116, 0.15065911881776806, 0.20796875573896578, 0.3080055004102986, 0.16273138994255698, 0.1478637420727329, 0.41283475364360933, 0.2584681523639685, 0.5828473772646887, 0.6167074787509191, 0.5905094211835982, 0.2805875883754597, 0.5837261464886763, 0.5776666202280083, 0.4924245901682711, 0.06262228907676692, 0.05009968005036958, 0.06131095233935757, 0.16331451947830333, 0.2120078944636986, 0.20282389642139642, 0.09068683415546475, 0.27394098223961105, 0.14432561293944002, 0.26206167549381687, 0.3276757088782427, 0.19006059980305845, 0.33363905331616484, 0.2635654502832112, 0.19102975161339353, 0.21943374491483747, 0.19372422798912714, 0.07690975471236616, 0.6726059722770112, 0.6362207678091727, 0.7134336959253846, 0.6188268534848027, 0.5890032145576728, 0.6380719421727323, 0.6447842206639801, 0.6060752229850332, 0.5924134686671156, 0.1301947111507823, 0.07748523352327175, 0.09047586812015995, 0.08201424021903081, 0.1269095372108746, 0.09263036284683224, 0.09426038367617895, 0.11280862368594335, 0.1218667404247602, 0.18843053651674457, 0.31756108669632466, 0.1777264128586008, 0.16186957482007125, 0.43856959464757395, 0.16219182217764117, 0.2415687705119085, 0.21751754691262692, 0.24928038667696795, 0.3307235136358265, 0.4166946006576263, 0.37456625654294307, 0.3523498589681552, 0.3437055516615396, 0.3073467837338534, 0.35333428328795, 0.3202036380250215, 0.3780333067397067, 0.31628591071168166, 0.2329132477295418, 0.24820134632107915, 0.1838807173884658, 0.2474206955943038, 0.31397899219928305, 0.247918177887681, 0.266524561669342, 0.20005877696526153, 0.25405927894116154, 0.27531550358498613, 0.20993514453190087, 0.22056957695906954, 0.21052844958956263, 0.21410436584940218, 0.2263432218489395, 0.24634148126516553, 0.22352002526254489, 0.19466174708494177, 0.23011733745354868, 0.18560711649003347, 0.20291748389466113, 0.1925430991017938, 0.18854411679902883, 0.6224478533755982, 0.20556360485122904, 0.17059400451853124, 0.1933160615997106, 0.2027528402581521, 0.758155579205285, 0.17573656097886392, 0.19775151849955852, 0.7633143145510046, 0.142495369214102, 0.16124595404650421, 0.6029896218284676, 0.8618991295800172, 0.20792665824538004, 0.7447144524060634, 0.7900935088912955, 0.16799622550277238, 0.2001364959978983, 0.2077564726644876, 0.1647915494855311, 0.7899478876693282, 0.2104081714726479, 0.19440993550711216, 0.18784942454597542, 0.18669515719758434, 0.2169827583880226, 0.18644933124389296, 0.1879212061354819, 0.19249515488953484, 0.20703735569371562, 0.12202577121120739, 0.11342435019930786, 0.08033455741628037, 0.09552979458855893, 0.08123903498364249, 0.10322989024482232, 0.11783906520512832, 0.08582118541580586, 0.10467434350274385]}, "mutation_prompt": null}
{"id": "63d6276a-d986-4db4-a68e-3326448e0c8a", "solution": "import numpy as np\n\nclass RefinedStochasticDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Reduced population size for focused search\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.7  # Slightly increased inertia weight\n        self.c1 = 1.5  # Balanced cognitive coefficient\n        self.c2 = 1.9  # Enhanced social coefficient for global influence\n        self.F = 0.9  # Increased mutation factor for exploration\n        self.CR = 0.7  # Slightly reduced crossover rate for better exploitation\n        self.adapt_factor = 0.95  # Less aggressive adaptation factor\n        self.diffusion_prob = 0.3  # Probability for stochastic diffusion\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Continuously adjust inertia weight\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diffusion_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedStochasticDEPSOHybridOptimizer", "description": "A refined DEPSO hybrid optimizer with stochastic local diffusion and dynamic population reshaping for robust exploration and convergence.", "configspace": "", "generation": 45, "fitness": 0.3506097695075263, "feedback": "The algorithm RefinedStochasticDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.27.", "error": "", "parent_id": "f1de49e0-fa67-4cc6-ad1b-5acddda8b9c5", "metadata": {"aucs": [0.8165168036468964, 0.7963032259081575, 0.8057455079657542, 0.8004145886258038, 0.7989244908337714, 0.7810815895929618, 0.7938303468209259, 0.7833470862688661, 0.7855129630574955, 0.5669390072116383, 0.5772941805753893, 0.5478099943301042, 0.6368901729552282, 0.5993934931602807, 0.6162802893876592, 0.4992217782969729, 0.5596094335027122, 0.6169306754479229, 0.13371818666458568, 0.1609677943828729, 0.16393696743966957, 0.14119033062072395, 0.1681504737173738, 0.13578202855429822, 0.0808658687517263, 0.15053682474968577, 0.11190592421466394, 0.12772281791994788, 0.10880422077621421, 0.10844965817201502, 0.10698894007925464, 0.09464533532479869, 0.10351949617019396, 0.10707204777339108, 0.08477954209610639, 0.07565881264297547, 0.9894485847059679, 0.9878418875143374, 0.9869533008814957, 0.9900666997074573, 0.9813007373749014, 0.989789869977392, 0.9801502766210021, 0.981724492952709, 0.9872531895759011, 0.4917067319742583, 0.5966224768112711, 0.5917738932397688, 0.5877677903096675, 0.5723900424652428, 0.5498706136913155, 0.5588780557728412, 0.47894912294616787, 0.5624945813426081, 0.8325452039770639, 0.16957276223955375, 0.27644600461503865, 0.19234731769518343, 0.8209536172491567, 0.20336186164199732, 0.812340841047305, 0.1699616154719208, 0.7226818684892454, 0.6315811907433189, 0.1111564744936806, 0.573595818180525, 0.12149903620099067, 0.41807153063257196, 0.4968218224250567, 0.47163862048679384, 0.12211944045852707, 0.5192070026218172, 0.6128957414595348, 0.3883687490172312, 0.11488591007406668, 0.6460839140740124, 0.5204965620806672, 0.129218204075374, 0.1269899180901417, 0.48680749851046645, 0.11805119504954686, 0.04592526080432435, 0.1638068672301406, 0.1976134015551173, 0.0004700597587534716, 0.0019858542934636514, 9.999999999998899e-05, 0.12823212925052774, 0.21854745664280595, 0.008243708455242582, 0.2702266768046895, 0.1595180376560933, 0.09040473047596931, 0.23239286644506962, 0.15489499095111003, 0.40137203559998, 0.5589156951499152, 0.593479344908168, 0.5904108883136342, 0.06813336615605747, 0.06125075176614991, 0.22533968099717294, 0.1248908321265062, 0.0848191143903374, 0.2084096531837577, 0.15882651611131582, 0.3046511540545661, 0.07725814821895294, 0.22114440608236652, 0.26124793865443374, 0.3726560970922863, 0.20524173863397144, 0.2986695912065178, 0.35064787255740437, 0.10072259029347241, 0.07927646072663608, 0.0740365429937836, 0.6869948120295528, 0.6734301801375229, 0.6225664316186111, 0.6071912268905033, 0.6540067948858441, 0.7077325464274893, 0.6082136650523936, 0.6832722976008659, 0.6065415477241013, 0.08318321491688363, 0.10450795324952833, 0.1118448808205208, 0.12288611087929402, 0.09695291484238044, 0.11100339814096438, 0.12996392458545503, 0.0964785151381149, 0.11204039538162214, 0.1554025456409237, 0.2527019032678818, 0.24356343043957562, 0.18693694371966108, 0.24263876449153188, 0.16984004186293955, 0.37284745612135217, 0.27885304032601843, 0.27809474882362606, 0.2969585496138598, 0.3582628223050395, 0.41350809627415963, 0.3158751865531514, 0.329016021353459, 0.21630421835296143, 0.3926932338713508, 0.3981361699315119, 0.4405303389630453, 0.20366169650418553, 0.31449374424199983, 0.25966707256211363, 0.2307078055786561, 0.20535736572938246, 0.2972471811860339, 0.18532404112808554, 0.26762185936681404, 0.2697599347345575, 0.22444986185337124, 0.2427585970085876, 0.20025057281361147, 0.2527713421478702, 0.21008350102136353, 0.24116779945949263, 0.2551595618207776, 0.20020858412657294, 0.21732423294609793, 0.19138552005410392, 0.18974639832684148, 0.20994574003640998, 0.18613531450677756, 0.6761732815124647, 0.19211680304884926, 0.18480067555981827, 0.22027631893100175, 0.19599835697042733, 0.881090347280465, 0.17449394564931697, 0.18567274087666719, 0.7970429896476753, 0.34816907704267464, 0.2198379223713618, 0.15107120539872299, 0.16155309196928191, 0.8189888620838278, 0.8772429321202854, 0.21069687892546374, 0.2094497741167598, 0.8511451625828139, 0.15243322455021846, 0.34546672125075173, 0.19658582626829335, 0.6971472457582382, 0.8064508926994394, 0.20837482108601368, 0.18122777306565763, 0.20819326414394057, 0.19347065801542718, 0.18691073446030848, 0.20589521319168302, 0.2061662446489987, 0.1999850226608333, 0.18513800275193248, 0.08789602723496992, 0.10002324502139148, 0.09298476432703595, 0.08536241351164775, 0.1050143379124675, 0.08857112592104854, 0.10119891347519605, 0.1050707677936984, 0.10493513225638706]}, "mutation_prompt": null}
{"id": "9864cccd-82bb-4547-a9c8-6ebfee90ff97", "solution": "import numpy as np\n\nclass AdvancedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 12 * dim  # Adjusted population size for better exploration\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.7  # Adjusted inertia weight for improved balance between exploration and exploitation\n        self.c1 = 1.5  # Reduced cognitive coefficient for better cooperation\n        self.c2 = 1.8  # Enhanced social coefficient for improved global search\n        self.F = 0.9  # Increased mutation factor for broader diversity\n        self.CR = 0.75  # Slightly reduced crossover rate for robustness\n        self.adapt_factor = 0.95  # Slightly increased adaptation factor for smoother adjustments\n        self.diversity_prob = 0.2  # Maintained probability for occasional diversity boosts\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))  # Adjusted velocity range\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Continuously adjust inertia weight\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "AdvancedAdaptiveDEPSOHybridOptimizer", "description": "An advanced adaptive DEPSO hybrid optimizer integrating a novel learning rate adjustment for enhanced convergence and exploration balance.", "configspace": "", "generation": 46, "fitness": 0.35539086992172386, "feedback": "The algorithm AdvancedAdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.26.", "error": "", "parent_id": "f1de49e0-fa67-4cc6-ad1b-5acddda8b9c5", "metadata": {"aucs": [0.7900073241437477, 0.7695076059171733, 0.7816215141817393, 0.8029057904137618, 0.8197122405791238, 0.7594649851106163, 0.8058948794599303, 0.7701961223536755, 0.780034117122396, 0.5768732839985655, 0.6286094978221267, 0.5619942967222892, 0.5766074958763545, 0.5542098688818065, 0.5037983577831723, 0.5510215171860178, 0.6091585294195169, 0.5980265956911486, 0.11722652568331482, 0.14086767966015212, 0.11700859704847355, 0.06467382740944616, 0.14392819552032632, 0.10819594310602965, 0.1173663838736636, 0.1477229553791165, 0.11784878387559727, 0.11352743934107967, 0.07565614913497465, 0.10803720889791835, 0.12982973259657815, 0.11498313402336502, 0.07776421524025445, 0.1069027464438812, 0.10857727675457096, 0.10841735887701265, 0.9876695004357171, 0.9846172862927801, 0.9866801897864387, 0.9834475025759469, 0.9836804739765663, 0.9854651851406041, 0.9837111371205708, 0.9842520183993327, 0.9882856530054921, 0.6356987853216511, 0.5432319788483562, 0.5287254137651793, 0.6198946320880607, 0.5305221562683735, 0.5371490606256305, 0.5945071900918377, 0.44327958241120546, 0.5752327491239094, 0.3644270713941431, 0.748792866875194, 0.7856947016009523, 0.21633102845273233, 0.8157198160778031, 0.2063656225600664, 0.2244178122665803, 0.22075886364073893, 0.7586088870988552, 0.6146309794090883, 0.4526736691260277, 0.11874514045354989, 0.13104879284306203, 0.11859935253597886, 0.5122011729587206, 0.44128539805507905, 0.5134145003672663, 0.5680950865161181, 0.5866817536807363, 0.521260784241053, 0.36652995614711914, 0.586527739016075, 0.4517540610284999, 0.5822791983296615, 0.6276595545330533, 0.43974763692208285, 0.5367557658963249, 0.1332081683030899, 0.35833808998445793, 0.09884531806407193, 0.03168019359638852, 0.208386350564022, 0.1114773267267225, 0.12966896133311678, 0.008947112668272195, 0.01959923691604981, 0.20140456293455944, 0.11755223122534031, 0.1261404628956172, 0.560804793333692, 0.42373905339906603, 0.24434111634248168, 0.29480963801335847, 0.49409260002941136, 0.47147515169657195, 0.10213018649458627, 0.048379282894888465, 0.08246312599292382, 0.18797267472010748, 0.2565950527677494, 0.25105580612496337, 0.17435773750543937, 0.10183202211718345, 0.11517252816249457, 0.26117290509396685, 0.34777641039573803, 0.25288476076661137, 0.3706528142803287, 0.2430797809790355, 0.25893766151135544, 0.23309651300781553, 0.27517511556039953, 0.07508071436521424, 0.6440502817044647, 0.6520161142961975, 0.6324988326946267, 0.753461850910272, 0.6952984984217756, 0.6952723532541917, 0.6813416105365115, 0.6502805093070088, 0.6369071807613502, 0.08415765333872083, 0.0920899042953528, 0.10634094758947887, 0.1668321628964775, 0.13160611578519643, 0.16983565786123067, 0.12695118023051744, 0.1428991857760693, 0.1267461326891196, 0.19676279155059184, 0.3098649292873582, 0.24839494164080356, 0.21705345532780118, 0.5388465360650095, 0.1465047646007679, 0.46502959284024714, 0.18008859842211966, 0.2022025578281239, 0.34662056478464454, 0.4278173410893281, 0.30933909251411584, 0.301816273715646, 0.28495449278029894, 0.3926427193946639, 0.29904837956794394, 0.295900909871597, 0.3343455746801133, 0.24979105498340037, 0.2340687032032278, 0.21910510316577902, 0.2923213255831487, 0.229645266372698, 0.3531683595497729, 0.39134616565308633, 0.2468241799457398, 0.1845938019243637, 0.21084766045987524, 0.19054880158456267, 0.2321048709925143, 0.22178725836311552, 0.20834597481258588, 0.20134106147031217, 0.2111852258803114, 0.250935116472636, 0.2811150195587565, 0.18314327961408472, 0.21510348860689454, 0.20932345378419803, 0.2034833777093753, 0.1967265323180043, 0.19760287348212635, 0.20343681273152003, 0.6443050804085764, 0.2145634850030811, 0.16057848938671448, 0.18689444915008457, 0.20745985437885706, 0.1738583685587498, 0.19810754436822609, 0.8189783593437431, 0.1418475392955012, 0.16086990395263567, 0.2025202511428702, 0.8367147438072564, 0.20936233267929694, 0.19812260362799428, 0.827150550600746, 0.167607601627922, 0.20128019035477696, 0.773328165287965, 0.1675310567724202, 0.8088318414253668, 0.19331160136489522, 0.18669789814634774, 0.2013695944124665, 0.19011221795645228, 0.19935318519082157, 0.19002108302145249, 0.1943365861373333, 0.1860399170590229, 0.23971751249107642, 0.12396555481842586, 0.08087018174881866, 0.09288841865721531, 0.09231997014661208, 0.07960344779051642, 0.08297766701305076, 0.09642548917694627, 0.09068500262927648, 0.12254436402678459]}, "mutation_prompt": null}
{"id": "5f2b0427-b491-4a06-81db-51bb41243635", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 15 * dim  # Increased population size for wider exploration\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Adjusted inertia weight for improved convergence\n        self.c1 = 1.5  # Reduced cognitive coefficient to balance global search\n        self.c2 = 1.7  # Slightly increased social coefficient for better convergence\n        self.F = 0.9  # Increased mutation factor for enhanced diversity\n        self.CR = 0.7  # Slightly reduced crossover rate for more selective exploration\n        self.adapt_factor = 0.95  # Slower adaptation to maintain control stability\n        self.diversity_prob = 0.2  # Base probability for diversity manipulation\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w = max(0.4, self.w * self.adapt_factor)  # Ensure inertia weight doesn't become too small\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "EnhancedAdaptiveDEPSOHybridOptimizer", "description": "An enhanced adaptive DEPSO hybrid optimizer using balanced dynamic control parameters, elite selection, and selective diversity introduction for improved search efficiency.", "configspace": "", "generation": 47, "fitness": 0.32534169929070883, "feedback": "The algorithm EnhancedAdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.24.", "error": "", "parent_id": "f1de49e0-fa67-4cc6-ad1b-5acddda8b9c5", "metadata": {"aucs": [0.7101237965632674, 0.7009411014013619, 0.6989992454510239, 0.7044247793729321, 0.7427630147381268, 0.7513634985176421, 0.7158250730826432, 0.7242222031101925, 0.772753722360574, 0.05103665999473983, 0.289998883952474, 0.3378862408071843, 0.2517395229370253, 0.3399378833509339, 0.32364023614647597, 0.2692554264302066, 0.3474507988247887, 0.37797116391967456, 0.09808277534383558, 0.13780975842932952, 0.15020244591961196, 0.15099174221993217, 0.1170627821688015, 0.10314613813985252, 0.12930384611123846, 0.13410090467142777, 0.12666322923336615, 0.09644804399034945, 0.0983951978789308, 0.09548068325456638, 0.09579958652128284, 0.09530851791835271, 0.10507560295702967, 0.14158474555395184, 0.10116382460164441, 0.10885147252135052, 0.9721185619004068, 0.9842074253614141, 0.9851243202054177, 0.9807671502887874, 0.9830473365286992, 0.9844094452653062, 0.9858679720228833, 0.9853681394065534, 0.985299158545057, 0.4793308785933449, 0.49105574404027585, 0.458479158633887, 0.46916551455012845, 0.5096208874405492, 0.494366569650015, 0.4289848725639549, 0.4346608935344418, 0.4386715091336243, 0.3564949514998015, 0.21678223499257432, 0.8207704834663831, 0.2146339315859387, 0.670965870174185, 0.20704124829004655, 0.7120469164979348, 0.6014438119253448, 0.7779452612226053, 0.11286820132422326, 0.4527583187691999, 0.28045926357656803, 0.30363581873939505, 0.3144289665923411, 0.46430173161984056, 0.12264529721672002, 0.5144728532783356, 0.3928500004130425, 0.30104711568627596, 0.32539846600234834, 0.3700351895395002, 0.4073443872813389, 0.12123671287871807, 0.1283818175614997, 0.13243894314971372, 0.21352347795848925, 0.4789448916228194, 0.17316167441761443, 0.12249512861800727, 0.2709563033349668, 0.014214725726392485, 0.07628269289089262, 9.999999999998899e-05, 0.21020641901060855, 0.15115347460017414, 0.09704268644435232, 0.3272769570152434, 0.34980302322326495, 0.42952678672946776, 0.2164457788427595, 0.3210002154190924, 0.36355074187658176, 0.3799910369548154, 0.36708220106601197, 0.4481839349085258, 0.03066752684435392, 0.09785152124234064, 0.09201840020178786, 0.13481393544337972, 0.1421304674054058, 0.1801077188403296, 0.21453463846018184, 0.28304447430057256, 0.13668477184427497, 0.2237913696252043, 0.15066257804181238, 0.13251736470420894, 0.1032943103452395, 0.17768541235453028, 0.22913963690822625, 0.0717383631974744, 0.04651788780846744, 0.07822276825402696, 0.5572490399088341, 0.5826541268661397, 0.5639951592392288, 0.5373733977075639, 0.5477905210818999, 0.6119759272708112, 0.5494708062423244, 0.5756438269102546, 0.5793067889676531, 0.1345156130691061, 0.08329280721132148, 0.09608652605202228, 0.091439705743951, 0.13996425281999236, 0.4910630079152679, 0.11050923389612033, 0.11175421976527034, 0.12035054476824192, 0.19896171094022752, 0.17099280520606464, 0.20452220573627689, 0.22136131818592386, 0.18104686014149596, 0.2212739186731011, 0.46000428349113265, 0.18914938073551102, 0.39992085830750546, 0.3819392941373744, 0.39607850870884753, 0.28417219720500997, 0.40491389112155507, 0.4198278267085196, 0.39642064127020926, 0.3698175501464681, 0.2559474927315689, 0.44724669008915985, 0.22820952366715652, 0.23323787135827445, 0.2500913541414137, 0.2373541935425153, 0.18497488495396486, 0.288708086173066, 0.2321485113540711, 0.27226834245462883, 0.16002394248877916, 0.2194172405529765, 0.20231441589123078, 0.21566427246011988, 0.19853681786620603, 0.19504500991529494, 0.2139402385438719, 0.25570604503872574, 0.22289899526476775, 0.18917634952694917, 0.19487575957703562, 0.2144083098913745, 0.19214132989233512, 0.20474946385732573, 0.17558802751170366, 0.1812438221294339, 0.17609027420625445, 0.22820127385309374, 0.20104133156367276, 0.1674898625396707, 0.18744254430622465, 0.8610832651903467, 0.4940115061939153, 0.19892375461866385, 0.16622060532718752, 0.7913628406435297, 0.5126722495221151, 0.7153386221953295, 0.8093299396309053, 0.750474418753515, 0.7856995595093105, 0.2070773611691641, 0.20552544728744215, 0.15055452427353444, 0.7225668361504871, 0.2103286550130854, 0.7847217966000966, 0.21945925088966, 0.18281307673142533, 0.18062977461164664, 0.21654869543561672, 0.2219959217228693, 0.21791092697033798, 0.1969585168102581, 0.20083735576099693, 0.18408956934687593, 0.08326720331754134, 0.08068254231526095, 0.09397654693747937, 0.09296339887935934, 0.07817134861303898, 0.09170169694972952, 0.07589849260444625, 0.09189577511737956, 0.08195136237981882]}, "mutation_prompt": null}
{"id": "bcf3bf76-e14b-42e4-baec-7d5f7896a283", "solution": "import numpy as np\n\nclass DiversifiedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Refined population size for better exploration\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.7  # Adjusted inertia weight for convergence control\n        self.c1 = 1.5  # Fine-tuned cognitive coefficient for local search\n        self.c2 = 1.7  # Enhanced social coefficient for global search\n        self.F = 0.9  # Mutation factor for diversity preservation\n        self.CR = 0.9  # Crossover rate for explorative robustness\n        self.adapt_factor = 0.95  # Adaptation factor for dynamic inertia adjustment\n        self.diversity_prob = 0.3  # Diversification probability for population refresh\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Continuously adjust inertia weight\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "DiversifiedAdaptiveDEPSOHybridOptimizer", "description": "A diversified DEPSO hybrid optimizer with adaptive parameter tuning, elite selection, and stochastic individual replacement for enhanced exploration and exploitation balance.", "configspace": "", "generation": 48, "fitness": 0.3707864181050619, "feedback": "The algorithm DiversifiedAdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.26.", "error": "", "parent_id": "f1de49e0-fa67-4cc6-ad1b-5acddda8b9c5", "metadata": {"aucs": [0.8053801466404673, 0.7873306001878487, 0.8104882993852968, 0.826803527395928, 0.8146248321569236, 0.8111953000309399, 0.815877009043955, 0.7969674889987394, 0.8019549664991017, 0.5007227288263436, 0.5826154095276743, 0.5722244387280409, 0.5867696767650709, 0.5910170008842011, 0.5788311579810399, 0.6349690138698971, 0.6313948443120407, 0.5901012204225404, 0.1234809532629173, 0.14156943867045158, 0.14687042342565015, 0.11792576807651478, 0.1087352398432162, 0.14016686904322828, 0.12410818680425817, 0.12369718973140387, 0.15319688286877275, 0.09245790667529852, 0.11873249869232028, 0.07242191230937822, 0.0977429449662004, 0.06639836289354806, 0.07694351320595472, 0.12287206361285119, 0.09634147994537812, 0.09993175404983334, 0.9890726951519944, 0.9900874595898923, 0.9818745914006556, 0.9883894427110138, 0.9879022793393449, 0.971807656582261, 0.9795855255935356, 0.9890842763939998, 0.9878354206439335, 0.6416749552849713, 0.5427091709384975, 0.6100883265354238, 0.6149406379914443, 0.5942938912721991, 0.6106684409702687, 0.6414123607733752, 0.5900443460091267, 0.5594184418497528, 0.7661093157967493, 0.7988784176565978, 0.7649394270635166, 0.36928895359817515, 0.2668469234411569, 0.19303064393819125, 0.7651722040143485, 0.17461380374727176, 0.26535026708093024, 0.7007825496550099, 0.44983828239171086, 0.5582435561476762, 0.09489293573005109, 0.4804408356822676, 0.6661192713004589, 0.346469944490599, 0.5325307195414845, 0.12027841492482616, 0.6638593740468226, 0.13129793938169554, 0.12124078876108046, 0.5739478078871509, 0.38804425701296363, 0.5092210343517477, 0.6065409007118677, 0.5010405201425822, 0.5891491479104969, 0.025164315022658812, 0.32471316790529725, 0.24592279865784195, 9.999999999998899e-05, 0.5394019985431768, 0.49582147361190054, 0.2280151367184049, 0.5521391866000366, 0.0042519618906546874, 0.5744376165327469, 0.39227407935238146, 0.3127028768556869, 0.5972799095470835, 0.3513303527774492, 0.49101456687569, 0.5574323524934137, 0.32115423132933385, 0.6259175281707563, 0.197582625417013, 0.09335413296517892, 0.1131320335013063, 0.25169093556579547, 0.2771837764007645, 0.09645650190611688, 0.2780597304461023, 0.46330416662345575, 0.07722900055753612, 0.3276473448706356, 0.26225199141203637, 0.2518361026905752, 0.2491825754498932, 0.20929413398641683, 0.25791084754040605, 0.34184842283419903, 0.3695413358115288, 0.15721291175403307, 0.6615958476067711, 0.7183438538540436, 0.719879971646016, 0.7793968643257688, 0.6925920064384434, 0.7120788581025477, 0.7289647732446265, 0.6134549198585291, 0.6438467362067766, 0.09451076044391338, 0.1252138802733238, 0.09443341455394716, 0.08507711711689969, 0.12572216305673156, 0.08490061562231987, 0.09806544901157888, 0.11363892344044546, 0.11927054581998964, 0.15288088719477988, 0.16861993760006844, 0.24261974727825142, 0.2512302142678614, 0.22458364961533717, 0.15385117161936268, 0.18081436480602298, 0.32664099136481195, 0.25160532469528984, 0.25451878849328935, 0.30185237720556735, 0.35545183580010065, 0.330012895998823, 0.3255560814409316, 0.4412687567404031, 0.19901023448010646, 0.38565582844952473, 0.39072336721915524, 0.2647425570739681, 0.3019311846332917, 0.2703284642020062, 0.22237053271173735, 0.19712181259474193, 0.24687728161186095, 0.28731443321087113, 0.2614354587279195, 0.28860614364649795, 0.25528883745824604, 0.24039356182262872, 0.23842523663682702, 0.19921630341665642, 0.1917974644690683, 0.2000744053801543, 0.2318849966688783, 0.2450662804197148, 0.23527335184070564, 0.19258923874058143, 0.19489535458980622, 0.20742103368114917, 0.20359332700395427, 0.19116746474006008, 0.20224505083129485, 0.1734964851569062, 0.2288479583845604, 0.19253226161725612, 0.16345281374758924, 0.16541498593813653, 0.12432872816133711, 0.16437123670230702, 0.3173949343165927, 0.7200865503453704, 0.17581912763132823, 0.14791194720266543, 0.8642821234560906, 0.8403295096801797, 0.20887941786266373, 0.30767548147210266, 0.8166556127412145, 0.11247422395976281, 0.23176014821347968, 0.20949845046716764, 0.736842466371903, 0.6692612420969886, 0.18837359930029474, 0.20981152581007823, 0.19872632808765633, 0.22979284497889152, 0.19694370377650505, 0.2009311116528809, 0.19758613251133528, 0.19242388681526468, 0.21160396369774748, 0.09195706532272963, 0.09212830769375413, 0.103545640797154, 0.0817559385328881, 0.08657912234072684, 0.08236542355997611, 0.10037756942030152, 0.09097377024589826, 0.09902041182884747]}, "mutation_prompt": null}
{"id": "6ee71ca8-a330-4c08-b302-6b3171f2cdb7", "solution": "import numpy as np\n\nclass StochasticAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Slightly reduced population size for efficiency\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.7  # Adjusted inertia weight for stability\n        self.c1 = 1.5  # Refined cognitive coefficient for local search\n        self.c2 = 1.8  # Enhanced social coefficient\n        self.F = 0.9  # Increased mutation factor for exploration\n        self.CR = 0.75  # Balanced crossover rate\n        self.adapt_factor = 0.95  # Modified adaptation factor for dynamic adjustments\n        self.elite_prob = 0.2  # Probability for elite perturbation enhancement\n    \n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Adapt inertia weight dynamically\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.elite_prob:\n                elite = personal_best[np.argmin(personal_best_values)]\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                elite_candidate = np.clip(elite + perturbation, self.bounds[0], self.bounds[1])\n                elite_value = func(elite_candidate)\n                self.current_eval += 1\n                if elite_value < global_best_value:\n                    global_best = elite_candidate\n                    global_best_value = elite_value\n\n        return global_best", "name": "StochasticAdaptiveHybridOptimizer", "description": "A stochastic adaptive hybrid optimizer blending dynamic DE and PSO strategies with elite perturbation for refined exploration and convergence.", "configspace": "", "generation": 49, "fitness": 0.3642638328492215, "feedback": "The algorithm StochasticAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.28.", "error": "", "parent_id": "f1de49e0-fa67-4cc6-ad1b-5acddda8b9c5", "metadata": {"aucs": [0.8354173931964923, 0.8327543990558507, 0.8104873634176402, 0.8342977546260142, 0.838015062967977, 0.820846781194911, 0.8528199656854973, 0.8292493890504161, 0.8322138335807848, 0.6098971932657413, 0.6363300264085445, 0.07161518184435223, 0.6261045743295108, 0.6782335604373613, 0.6638610043870419, 0.682405956862117, 0.6781537614358893, 0.7127492266759794, 0.14558326504577346, 0.1758916577239068, 0.12628404396168136, 0.15256971686229914, 0.12960097786854874, 0.12581138938399816, 0.1263249415114105, 0.11828690239470685, 0.17061617884028657, 0.11123031318553389, 0.1215003750602236, 0.16091393572524926, 0.12584173623620631, 0.11496314539397012, 0.14417957880181598, 0.13117485595257494, 0.08450530000134093, 0.11160059771930775, 0.9894517920164547, 0.9863499116385654, 0.9871357845916038, 0.9899491152053262, 0.9793167381097089, 0.9898016488816852, 0.9774441411734788, 0.9817013604623955, 0.9872653345738278, 0.64943110037984, 0.6129597877477309, 0.7030054649752987, 0.6260847963215397, 0.6491446832897676, 0.6582528134251344, 0.6307236739139597, 0.6612406414525662, 0.6480066470614018, 0.3308487243653607, 0.8406395100094786, 0.17757690822846794, 0.21727328224307108, 0.27150072498903177, 0.21000580900967925, 0.1357176864326528, 0.8397669694359895, 0.2347329933895751, 0.7604495399668226, 0.5902960710074329, 0.5700194376856583, 0.09413895565167207, 0.47582860949813865, 0.6924913841764759, 0.5664685084214863, 0.6907199772968573, 0.6387059604147017, 0.5308910059256968, 0.5808703029990907, 0.6855377936998849, 0.6173764236310264, 0.539726554794715, 0.7326424783780189, 0.48081745825244093, 0.12714888422954718, 0.11461155615114005, 0.07377864453150174, 0.06347909086614123, 0.08238544176091256, 0.03594691264374583, 0.10054587041502017, 0.01629248192954036, 0.033553934403481644, 0.10085001489620704, 0.003487253805221191, 0.3804031827462312, 0.2871943648351657, 0.38518850905802227, 0.147615181688317, 0.23979939952368445, 0.32527869822754896, 0.203918182456451, 0.365694304336029, 0.0782075760991231, 0.1367465238586486, 0.030923660072651904, 0.48232901460706856, 0.2548463494296882, 0.09857067058120561, 0.20647576982362614, 0.12532957371696596, 0.30089397644613924, 0.11239650754858488, 0.41541360251695236, 0.16042758437621396, 0.4046157375776487, 0.3152856644649986, 0.0937171732687091, 0.28889433318869295, 0.15084499115797445, 0.08888712266215737, 0.19896343275875983, 0.7093198355825217, 0.702308351430597, 0.6563833411021462, 0.6163926556023898, 0.6358485488401999, 0.7566290321942946, 0.7713013922306762, 0.7250725975655256, 0.6687667316076618, 0.10723312090380854, 0.13839119311520987, 0.09741653971951236, 0.10901231030599023, 0.09638928724007323, 0.11336385552076733, 0.15075630665109363, 0.10810116361938238, 0.11149660748281764, 0.24348143841321523, 0.2305327304347099, 0.1817260925009455, 0.2324135271862896, 0.28171139031882453, 0.18310835530554836, 0.193283232151663, 0.1983129807206182, 0.1750226416016365, 0.33890643823869404, 0.33007944671220535, 0.4118590849824121, 0.32356674120521056, 0.30679888645358067, 0.2658167987891068, 0.402224853711158, 0.3542392025057134, 0.2996678769305072, 0.23007356429198744, 0.2979986862483227, 0.2669553521201199, 0.3232807602640779, 0.19530415861015804, 0.22620237687433709, 0.24699395875120722, 0.2709820209507571, 0.28308211244754244, 0.25705690261562264, 0.19560949828143026, 0.20710406982412455, 0.21973299315552908, 0.23283376947497048, 0.1667899878831307, 0.23314020472383612, 0.1833314908366861, 0.2358758154905145, 0.20821160306489384, 0.7529322090778168, 0.1842664113731225, 0.6951826547317439, 0.2457307151724979, 0.18904660106310767, 0.18317356999094558, 0.20876717585667826, 0.19857445815513963, 0.885959655838647, 0.12509268538949492, 0.17673947025258463, 0.10494275720261992, 0.2003509637592683, 0.1965496685135073, 0.14086116824730088, 0.1621847371148749, 0.8814446697885773, 0.8575034279455894, 0.21169485206137117, 0.20260605477133986, 0.8707251674983707, 0.7721197817657243, 0.16737310039122444, 0.2109349400212709, 0.15440811404085486, 0.8504727997541244, 0.1969194685463227, 0.1884975505007157, 0.18549789765673586, 0.20354721554610966, 0.2013243417583167, 0.1898082382711962, 0.19370009903027108, 0.2041793460085216, 0.19304392682329652, 0.10562917216830359, 0.10193672804604192, 0.10274538778517384, 0.07984310922245963, 0.09654428644751967, 0.1578021503130247, 0.09711936978076174, 0.10320913948595811, 0.07692772560298022]}, "mutation_prompt": null}
{"id": "04cec9cb-98c1-43c8-9c17-f27b6c178ae0", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 12 * dim  # Adjusted population size for better exploration\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.65  # Further adjusted inertia weight for control\n        self.c1 = 1.7  # Altered cognitive coefficient for enhanced local search\n        self.c2 = 1.6  # Balanced social coefficient\n        self.F = 0.85  # Fine-tuned mutation factor for diversity\n        self.CR = 0.8  # Adjusted crossover rate for explorative robustness\n        self.adapt_factor = 0.9  # Adaptation factor for dynamic control\n        self.diversity_prob = 0.25  # Increased probability for diversity manipulation\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Continuously adjust inertia weight\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "EnhancedAdaptiveDEPSOHybridOptimizer", "description": "An enhanced adaptive DEPSO hybrid optimizer tailoring dynamic control parameters and elite selection for improved exploration and convergence balance.", "configspace": "", "generation": 27, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "f1de49e0-fa67-4cc6-ad1b-5acddda8b9c5", "metadata": {"aucs": [0.8355409558076017, 0.8494426084577814, 0.8428963889796215, 0.8502852936515759, 0.8621901096656455, 0.8497248109461688, 0.8387232776935258, 0.8459284358315018, 0.8362425413873057, 0.03808480415518245, 0.6212092818697802, 0.6598724132580744, 0.6502034892458568, 0.647123652252421, 0.6890056170188226, 0.6702099755395825, 0.624013855909104, 0.6362004785053328, 0.12207907847920163, 0.17257720538319243, 0.10467972342729026, 0.11439498939861659, 0.13666043391409644, 0.10682223525172652, 0.1108679681777136, 0.14784642832704253, 0.10861616695313658, 0.10773597615856856, 0.0824763932957665, 0.10001990105948755, 0.13541818863283084, 0.09333746487170791, 0.10678260432852493, 0.11449311655902128, 0.09339932778005766, 0.11298007871445048, 0.9872029040341762, 0.9872894199974253, 0.9865901085447795, 0.9868745094722602, 0.9854832635141402, 0.9848641647636192, 0.9867568197531932, 0.9848918714150006, 0.9882765486673663, 0.5007111019665824, 0.608074550285124, 0.5247571953872642, 0.5619436341968036, 0.6399432180851307, 0.6221965875744164, 0.6395661567218133, 0.6591555597139024, 0.5472504531082588, 0.21135012282197585, 0.7800919306743392, 0.22232627742521993, 0.8516069552123506, 0.2628604510316278, 0.2073265396274221, 0.83428349495713, 0.8398019620784158, 0.22748420511413447, 0.67686311890875, 0.5329752656707352, 0.5402159077307994, 0.6893425927037747, 0.5427592297946797, 0.1294594924653657, 0.1261981341808005, 0.5992713769384455, 0.6493406999815003, 0.5938949090212955, 0.44886919828682104, 0.5929113193379214, 0.5950533802181326, 0.5036198518173242, 0.5992240615970458, 0.6958532114694396, 0.5916765446709902, 0.12516503811974422, 0.13382899773215995, 0.2634108234625794, 0.23380247273103594, 0.09074172674597991, 9.999999999998899e-05, 0.205012596259878, 0.12974233392809476, 0.12297059187754622, 0.12847894972749818, 0.3824334532518411, 0.3516044090341116, 0.22886474481398134, 0.6833061490636131, 0.22866670834320746, 0.5369431843452157, 0.5596685980822769, 0.5980103415008682, 0.5231875070604719, 0.05938342188516854, 0.06175585168723552, 0.22798890033483488, 0.15994671754544376, 0.46982615522606996, 0.08792684540425566, 0.12551751453330684, 0.10706358301053553, 0.2116052000276315, 0.27182094151942593, 0.32484617399407356, 0.3881794954252107, 0.26639554796954024, 0.210533602523456, 0.3010891192001802, 0.04802433576686849, 0.05414903593810472, 0.07739605282909601, 0.6957313505423219, 0.6430901707788463, 0.7808067168848984, 0.7527932516594305, 0.639178142675696, 0.7252789241464053, 0.7014624808729144, 0.6694388299173162, 0.6537199387033179, 0.08564285772074787, 0.11019796056272424, 0.10826888698964798, 0.1300085467135199, 0.14999965979111263, 0.13386439071945866, 0.134654412685846, 0.11098594313521026, 0.13323263062529878, 0.20969418297682252, 0.3697136335907768, 0.55423104697274, 0.21084229979461588, 0.3257358828764384, 0.18272518099560775, 0.2417761157850855, 0.45084070110867114, 0.1595061423248919, 0.31744813825732776, 0.2688181347600346, 0.38435525426927664, 0.4125385053764913, 0.317112443709631, 0.24996839494760592, 0.31129982783820487, 0.31560450501811343, 0.2755635656621499, 0.3357005687226233, 0.3154881598444341, 0.20998457100134071, 0.2903080941249575, 0.19814068641145877, 0.22203970851073607, 0.21140353217928587, 0.34463661495035336, 0.212456075483466, 0.2325205994821279, 0.22222149955173254, 0.19259614210465759, 0.2625992558743159, 0.20793472659634304, 0.20853791338893357, 0.24645002533612426, 0.3008286640816966, 0.24304667970593796, 0.1786158990898784, 0.21383636861607402, 0.17632632425439132, 0.24392101743295558, 0.1946813608955963, 0.2101187602952035, 0.20902471008492374, 0.22027433961212806, 0.20167102129658088, 0.18662391353117824, 0.16791359444098253, 0.1865747338708159, 0.8802561179962776, 0.19954127204905214, 0.7380328545019104, 0.14230489207325303, 0.16328028751245316, 0.17780482120464147, 0.854768348127194, 0.6223772766003928, 0.8225357750507345, 0.8751038443426415, 0.16645529734105713, 0.8248608861164217, 0.2009963873038746, 0.7481790167658484, 0.8521606506415751, 0.2037439086091224, 0.18512869532449905, 0.18428291000120556, 0.20053462889801676, 0.1955537548324272, 0.19159368833788915, 0.19684294339685926, 0.20180877733092228, 0.2265578817383479, 0.153786791582323, 0.15020476166341956, 0.11870998187667015, 0.09805224508387778, 0.09719166019349845, 0.07923263991057305, 0.0896549667936275, 0.08091464298075624, 0.1111398835428159]}, "mutation_prompt": null}
{"id": "96db6ee6-f4cf-4225-b0e3-bfccc0ba0e38", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Refined population size for improved balancing\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.7  # Adjusted inertia weight for better adaptive control\n        self.c1 = 1.8  # Enhanced cognitive coefficient for intensified local search\n        self.c2 = 1.5  # Reduced social coefficient for maintained balance\n        self.F = 0.9  # Adaptive mutation factor for heightened diversity\n        self.CR = 0.7  # Reduced crossover rate for strategic exploration\n        self.adapt_factor = 0.95  # Incremented adaptation factor for gradual control\n        self.diversity_prob = 0.3  # Amplified probability for diversity enhancement\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Gradually adjust inertia weight\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A refined adaptive DEPSO hybrid optimizer integrating stochastic component adjustment and diversity amplification for enhanced global search efficacy.", "configspace": "", "generation": 51, "fitness": 0.3482323306402986, "feedback": "The algorithm RefinedAdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.26.", "error": "", "parent_id": "f1de49e0-fa67-4cc6-ad1b-5acddda8b9c5", "metadata": {"aucs": [0.840178431824563, 0.8148942536679952, 0.8105456919260243, 0.8374988654395232, 0.826546435316577, 0.8178407871922055, 0.8282124727243199, 0.8099605598525064, 0.7990945714870731, 0.631697141290547, 0.6533515825099128, 0.5526945234446089, 0.6371407146747052, 0.5982601992086524, 0.6331888732650401, 0.6467642598039869, 0.5249952162622928, 0.6254599933694271, 0.11129795384906793, 0.14156131421429907, 0.14528114562495198, 0.1105242040925759, 0.13810766690387377, 0.12478341631151701, 0.12929619219821975, 0.13259036768635546, 0.13071154335520696, 0.1437780242212442, 0.1408443089756789, 0.11118224719847769, 0.10304520587567478, 0.1143180851946739, 0.1036737380638495, 0.1320544121895335, 0.11380649123647213, 0.1157696078373901, 0.9894806273889966, 0.9817974200801436, 0.9854942734013665, 0.9834819914594184, 0.9863064781476906, 0.9886446218460548, 0.9863584002044425, 0.9816063746569981, 0.9872003962449999, 0.6395533814366087, 0.6035702137329864, 0.5611138526180723, 0.6717623943922135, 0.6387860636165072, 0.5228382575387209, 0.6383514455811288, 0.6104133182652028, 0.56594684689811, 0.3221181335507046, 0.3561974758557285, 0.6915055303175188, 0.27085447841494437, 0.2294516786263312, 0.15913447775885703, 0.7477615771309698, 0.7767241201235414, 0.3105154919591544, 0.12758360214844666, 0.49326393003880753, 0.4987351819195356, 0.6031284544129619, 0.5531021971918388, 0.6171950257925918, 0.6352369621860476, 0.5206839318568341, 0.5280868656979035, 0.5474459131284412, 0.15218003600243246, 0.12451957216368315, 0.516860808539858, 0.5317989987895122, 0.5341295459953115, 0.12923997456738556, 0.12355182643394713, 0.5824278664501553, 0.05497528309143673, 0.2097565505866681, 0.101075654619321, 0.07149750539849575, 0.05047993598319045, 0.08614654746959727, 0.11941873098675593, 0.05887301906031661, 0.00935800627370631, 0.24733599700703313, 0.2805165285376531, 0.26208040256203124, 0.30997570006263186, 0.13165344993060046, 0.26944089538775684, 0.20244324320690188, 0.23102735672920438, 0.4974926021303254, 0.08012840098029317, 0.04642950691317671, 0.14624867918845175, 0.21168203784473605, 0.18641983316851563, 0.15773508955266313, 0.10054851959043376, 0.09934230673397271, 0.1375996957001111, 0.16556255099341943, 0.1145974873104888, 0.15259995113964864, 0.16883045146908116, 0.3648086708666862, 0.29291636459765824, 0.31526026889992076, 0.18223866610077522, 0.07623344033829493, 0.6729066312322713, 0.6475373050056967, 0.5974651167538341, 0.6022972456451281, 0.6538049901221052, 0.6188004586859772, 0.6775842269358479, 0.583830126502883, 0.6166567163818376, 0.07611666608884748, 0.11345708813044297, 0.11054323824638412, 0.09911273776283525, 0.09011030191502145, 0.13662965591845, 0.10735075511712788, 0.13176917230941942, 0.12817287906111108, 0.23185534351433446, 0.18475719246017974, 0.22844007979415326, 0.15544162452224608, 0.1769021817621511, 0.1653966100148878, 0.4045382343587337, 0.16959703954028849, 0.24651060919262036, 0.3620779319747197, 0.3636212933524008, 0.4056930634795217, 0.3075152339563666, 0.3177846711646135, 0.30362828429863953, 0.323453061706546, 0.3527519157959683, 0.2614984402225037, 0.2044681724211127, 0.3125386051580342, 0.22361105155696837, 0.26010789285355795, 0.2320801447148828, 0.28834667180917395, 0.247122188215379, 0.2561553168181978, 0.30088787226096103, 0.20742444957414952, 0.22920493104502326, 0.1974180154263172, 0.22040463830115808, 0.24513335406981562, 0.20893278110838565, 0.23555588440604736, 0.20107045704509696, 0.25331529354957805, 0.1877323096718122, 0.19094415355129568, 0.18938212252181463, 0.2044734892315231, 0.18742101097598773, 0.19318246001704475, 0.19466716785448357, 0.23826594517612898, 0.2053878830440361, 0.8706704966828998, 0.8373186565756393, 0.1851949229467249, 0.16487215495466934, 0.3213575217104315, 0.23323104899128633, 0.15341903720207628, 0.15961933966972608, 0.8198476966433785, 0.8436148306399287, 0.2111324705183809, 0.21264449211962855, 0.8105414464082148, 0.20503752029273348, 0.30788641575222353, 0.21239347963157007, 0.20894647044624604, 0.7275268352839441, 0.1986023367648464, 0.21721787105629276, 0.20356560305387816, 0.21157277198474445, 0.19636581994620705, 0.1859244877944437, 0.2020858889024918, 0.19026118473174103, 0.21505678701528197, 0.08732613207296758, 0.10526623064803386, 0.09833571183523637, 0.09547705952891816, 0.0979156372219091, 0.09323776598479361, 0.08314866376538832, 0.08308519373066425, 0.0978212072288257]}, "mutation_prompt": null}
{"id": "2f8677c7-656b-40db-bc95-0aca17006c99", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Reduced population size for higher convergence speed\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.7  # Slightly increased inertia weight for better momentum\n        self.c1 = 1.6  # Reduced cognitive coefficient for broader exploration\n        self.c2 = 1.8  # Increased social coefficient for stronger convergence\n        self.F = 0.9  # Adjusted mutation factor for stability\n        self.CR = 0.75  # Slightly lower crossover rate for strategic diversification\n        self.adapt_factor = 0.95  # Modified adaptation factor for gradual inertia adjustment\n        self.diversity_prob = 0.3  # Enhanced probability for diversity injection\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            if self.current_eval >= self.budget:\n                break\n\n            self.w *= self.adapt_factor  # Continuously adjust inertia weight\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = self.w * velocities[i]\n                velocities[i] += self.c1 * r1 * (personal_best[i] - pop[i])\n                velocities[i] += self.c2 * r2 * (global_best - pop[i])\n                velocity_clamp = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n                velocities[i] = np.random.choice([velocity_clamp, velocities[i]])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A refined adaptive DEPSO hybrid optimizer employing stochastic velocity clamping and focused diversity injection for enhanced optimization performance.", "configspace": "", "generation": 52, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('a must be 1-dimensional').", "error": "ValueError('a must be 1-dimensional')", "parent_id": "f1de49e0-fa67-4cc6-ad1b-5acddda8b9c5", "metadata": {}, "mutation_prompt": null}
{"id": "174faea3-1b6c-4214-ad7c-75b035a97a35", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 12 * dim\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.7  # Slightly increased inertia weight for diverse exploration\n        self.c1 = 1.5  # Reduced cognitive coefficient to encourage broader search\n        self.c2 = 1.7  # Slightly increased social coefficient for better convergence\n        self.F = 0.9  # Increased mutation factor for enhanced diversity\n        self.CR = 0.85  # Raised crossover rate for better recombination\n        self.adapt_factor = 0.95  # Moderately adjusted adaptation factor for stability\n        self.diversity_prob = 0.3  # Further increased probability for diversity injection\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "EnhancedAdaptiveDEPSOHybridOptimizer", "description": "A probabilistically-enhanced DEPSO hybrid optimizer utilizing strategic diversity injection and parameter adaptation for robust search efficiency.", "configspace": "", "generation": 53, "fitness": 0.3673402339515331, "feedback": "The algorithm EnhancedAdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.25.", "error": "", "parent_id": "f1de49e0-fa67-4cc6-ad1b-5acddda8b9c5", "metadata": {"aucs": [0.7834237340754977, 0.7894905128836759, 0.7866235689764856, 0.8022795083278819, 0.7785067007795103, 0.8061535444479961, 0.7928970260521214, 0.7942368267562314, 0.7930117643725509, 0.46771093386795515, 0.5758236739058222, 0.5877723957770449, 0.5992649426247993, 0.5442119931891469, 0.5798843194005192, 0.37517823115448024, 0.6129662513463151, 0.5550908134407795, 0.11727184248770661, 0.10765650117125991, 0.11017766808938378, 0.13308788251916703, 0.13209098583152445, 0.16040744128236184, 0.12175342278957635, 0.1123425418720495, 0.09459087111310105, 0.08819452263235128, 0.123109566205434, 0.08965395121905584, 0.08392509839241213, 0.07500915544132825, 0.10474141018581917, 0.11100233557627559, 0.11704456434898125, 0.10354850350873934, 0.9857335460579021, 0.9872765768389853, 0.986618246922704, 0.9873884357086818, 0.9858502292078871, 0.9848705031441615, 0.9872125950765567, 0.9842881002239486, 0.9882869028958516, 0.5498505730224055, 0.5508127864210193, 0.5594315759979531, 0.4807379251302122, 0.5314528578044165, 0.6016873670623482, 0.4497261790319068, 0.6187765123554885, 0.5780291643311448, 0.16786169425030384, 0.7660076413972596, 0.23947967352875643, 0.7350807917502375, 0.2646890551142862, 0.2628751859670456, 0.7440440636250703, 0.7336970020564748, 0.8154867359613431, 0.5908891491206834, 0.5514575668923616, 0.12556158715193633, 0.5163448998352158, 0.5721695932137844, 0.45482790870310186, 0.4325369275991563, 0.5868742483931941, 0.5179197034955465, 0.6017942956984974, 0.5442222549007671, 0.607353489658619, 0.12262329211486445, 0.5145819624066892, 0.5590402076321106, 0.6098113889633883, 0.5969582182804969, 0.5164854889082181, 0.516766325448754, 0.19882039593411438, 0.474059609657293, 0.04231681717181435, 0.4557811196462799, 0.15919676515001613, 0.5748110858805169, 0.008753614449393488, 0.3348631864771019, 0.5332780952213682, 0.34441805072445053, 0.5480287835073125, 0.4350167936526391, 0.5463870248077397, 0.44609152081790526, 0.5928286411943039, 0.5685079977418805, 0.5027811470599376, 0.03340599274132805, 0.09060887696909614, 0.16025864402361745, 0.17688638123571132, 0.1992436831170593, 0.2020826353221279, 0.19733106159203417, 0.09723730061378866, 0.13005481664244667, 0.16078607760628694, 0.35997432383217143, 0.3468502746316793, 0.1890209799257011, 0.4151289235729748, 0.3014400687532106, 0.1796764199253319, 0.04687529805864399, 0.17167595915228118, 0.6926024120277599, 0.6849324123862942, 0.6994763774196178, 0.7057251207590676, 0.6818733723271118, 0.6662593919339688, 0.6945381520923234, 0.6857079291599095, 0.5819648953139513, 0.1155408969557129, 0.10610764816304619, 0.14229602739661096, 0.1465731541931009, 0.10366399144387883, 0.1116906950097325, 0.09312057830772935, 0.08729615396490431, 0.1339946269257789, 0.35497933577082486, 0.16347952368863428, 0.21268721092449638, 0.1855717047168416, 0.32336341948428593, 0.15788715089163652, 0.18589329422358747, 0.1873114540929094, 0.25087359153989897, 0.42368860502800954, 0.3738920300691885, 0.35975025985102993, 0.27161330206985046, 0.28196803307917884, 0.3519540586812181, 0.37070851427054463, 0.398212223202398, 0.42594578140637296, 0.3163992550086886, 0.23777026690666403, 0.37146168366035504, 0.26687211918468334, 0.22423946917873394, 0.2844596790372337, 0.34160133362756584, 0.22078980449878827, 0.2108423726223212, 0.20446104422033617, 0.2392620158514801, 0.21092232394662624, 0.24319398516752577, 0.20600720084866764, 0.23822583761122507, 0.1983922997963945, 0.23210810016852235, 0.22720086617627178, 0.1735393572832974, 0.20751908626675808, 0.19199755032703147, 0.21630891750180758, 0.19887677085163935, 0.18739378835770104, 0.1884428973446881, 0.19549801493574837, 0.19186531016978148, 0.19206638053281688, 0.18527802745390887, 0.18523088642247965, 0.19751842073357684, 0.1984901340796429, 0.7054227078519069, 0.1639242700004464, 0.16142887526353056, 0.18071403611646708, 0.8256192868375046, 0.1693395712414083, 0.46240526430899886, 0.7880498774055916, 0.16660755518046755, 0.20030852626130224, 0.1538800725661389, 0.2089399181833692, 0.5633855997737011, 0.19359615777908057, 0.19251206990081238, 0.20417414046763893, 0.2165134500636866, 0.21873315231506496, 0.19305530733606213, 0.2042668713148854, 0.21448132220867588, 0.22113083644031073, 0.1033094049713027, 0.09304111011770422, 0.08308036477560221, 0.09257161168167949, 0.09083754825280188, 0.08964465585911208, 0.08851294478265004, 0.09476377168442418, 0.10377792188781221]}, "mutation_prompt": null}
{"id": "2c6ec980-88d8-4084-967a-de3a084a9197", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Slightly smaller population for quicker convergence\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.7  # Adjusted inertia weight to fine-tune exploration\n        self.c1 = 1.5  # Reduced cognitive coefficient for broader search\n        self.c2 = 1.8  # Increased social coefficient for better convergence\n        self.F = 0.9  # Increased mutation factor to boost diversity\n        self.CR = 0.7  # Adjusted crossover rate for balanced exploitation\n        self.adapt_factor = 0.95  # Increased adaptation factor for inertia adjustment\n        self.diversity_prob = 0.3  # Higher probability for diversity injection\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor  # Adjust inertia weight adaptively\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "EnhancedAdaptiveDEPSOHybridOptimizer", "description": "An enhanced adaptive DEPSO hybrid optimizer with probabilistic diversity injection and adaptive crossover for balanced exploration-exploitation.", "configspace": "", "generation": 54, "fitness": 0.36134622409715506, "feedback": "The algorithm EnhancedAdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.27.", "error": "", "parent_id": "f1de49e0-fa67-4cc6-ad1b-5acddda8b9c5", "metadata": {"aucs": [0.8143628924471044, 0.8070263582335679, 0.7614720594325453, 0.8077773461440549, 0.8222518896026934, 0.8050954855088324, 0.8241237728049771, 0.7941188979957066, 0.8123711067906524, 0.03811857309951561, 0.6152802686595626, 0.6147216067997061, 0.6169342007761198, 0.5790838734426005, 0.6121932586378152, 0.565361997693985, 0.5975443349314408, 0.5547704916209212, 0.10198050318696694, 0.09696461343581775, 0.12075516533402864, 0.137292876318569, 0.16930375064320546, 0.11438315745682248, 0.12425627233660141, 0.10733405115291639, 0.12217803459665721, 0.10769579865463852, 0.11636303832467843, 0.0889809197768553, 0.12405841459148503, 0.1271990133396974, 0.12022888855855851, 0.11799249159572245, 0.051399937467176304, 0.1394796265371675, 0.9894517920164547, 0.9863499116385654, 0.9871357845916038, 0.989976984787122, 0.9862352901356464, 0.9897880952917211, 0.9803189375009079, 0.9817013604623955, 0.9872653345738278, 0.6312101399744872, 0.5953286758343193, 0.6189031759371786, 0.6144715526328022, 0.6079797839357577, 0.5405321688306095, 0.5462972377695416, 0.5944642144439111, 0.5806755226608187, 0.7235453201932174, 0.21752332765101146, 0.3015243055740432, 0.7010070775760296, 0.20782066998383264, 0.18981698010202264, 0.8073509540362462, 0.7923194306963504, 0.7419837535363454, 0.6805303799188315, 0.3788898174876535, 0.5995644840961236, 0.11571000227541861, 0.1281753667617639, 0.6232682150357678, 0.6188948184760579, 0.6335721395495195, 0.5951730675290383, 0.5090389871860002, 0.17626010241538947, 0.11391831814057973, 0.591850203734837, 0.5861248098570744, 0.5649549249891388, 0.1256346800328958, 0.11711646901003514, 0.10884065620179995, 0.06547031444368401, 0.05436816178351889, 0.07483396269078657, 0.0006143034051078189, 0.01644336948138192, 0.15954910613276152, 0.22425052302617254, 0.1262619054025923, 0.007597459014046404, 0.3510838171228199, 0.5947908927995547, 0.4215363351924155, 0.12644087895891476, 0.4249420024034861, 0.14858086289560435, 0.2760881575137334, 0.557395090069036, 0.6062453251680289, 0.0529128389233714, 0.06050669487759619, 0.23961423698380635, 0.13074819735326615, 0.2721709889760978, 0.27220450464546053, 0.10074188332178946, 0.22241595787801038, 0.08495300069999956, 0.204896295218574, 0.22687264368545346, 0.2014590951126901, 0.32522367562030763, 0.26435705528484, 0.20061677724113847, 0.05353225153723851, 0.15279019163250507, 0.1785018451325242, 0.6815495319766539, 0.6555817145700129, 0.6568724248128288, 0.7279522185883687, 0.6925376214366232, 0.6761433721160085, 0.703571572888852, 0.7631500489252284, 0.7096095913888432, 0.09004601636878284, 0.13513383361945364, 0.11195647191955393, 0.12778061748208436, 0.1408937693216532, 0.07290148774176997, 0.07391523076179651, 0.09196197209455603, 0.07558286500517919, 0.19780254959785692, 0.3620165837332643, 0.24257861708039496, 0.308843586964042, 0.23171713940080785, 0.1720849997535302, 0.2481029916988492, 0.22188645672969554, 0.18213680060732562, 0.35318491229512283, 0.3909703846014134, 0.28831341812175515, 0.4185914601481864, 0.2429035436403133, 0.43583468871378617, 0.36271234261140906, 0.3450280447162325, 0.4350763773325188, 0.2137410101126328, 0.23761126880544647, 0.2858055975745406, 0.27834016640418824, 0.2081953265503188, 0.3013767839949414, 0.28391283496026665, 0.3076847793791374, 0.21373011738064784, 0.1880159331482152, 0.21386463869242223, 0.2023804251462824, 0.2419780729796276, 0.21451586340665074, 0.2063685843154991, 0.20882435037473168, 0.19534824584864918, 0.2627403001723967, 0.19690889978133563, 0.2207779170235037, 0.18171651333421845, 0.17958762572983122, 0.18807611964443227, 0.18706555721822615, 0.18714725332853233, 0.19087861308012155, 0.17427852880156702, 0.8805217758717662, 0.8026537495253276, 0.18639316759911706, 0.1668571649019246, 0.341632544744912, 0.2036109037158943, 0.16606327641352758, 0.8218441076158229, 0.8554600799909138, 0.8615200642178074, 0.20980385239408683, 0.1964080768930353, 0.8531574425918631, 0.7557550794301838, 0.22279379187737736, 0.20977934784965824, 0.691601868658532, 0.724458501380732, 0.19237278606121777, 0.18170412389344714, 0.18784512721321478, 0.18872485109706605, 0.18232257379606343, 0.19837075275311689, 0.18946613625648157, 0.1888008353138675, 0.200855118723542, 0.10644124100808572, 0.10709712065110799, 0.0892844463181316, 0.08417622465479602, 0.09004333000511755, 0.09168222485419375, 0.0882813472079984, 0.08600510616435664, 0.0792388827657029]}, "mutation_prompt": null}
{"id": "9669ffdd-e653-4884-b075-7cd7fb6ecbb8", "solution": "import numpy as np\n\nclass AdaptiveProbabilisticDEPSOOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Slightly reduced population size\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Adjusted inertia weight\n        self.c1 = 1.5  # Modified cognitive coefficient\n        self.c2 = 1.7  # Modified social coefficient\n        self.F = 0.9  # Increased mutation factor\n        self.CR = 0.7  # Reduced crossover rate\n        self.adapt_factor = 0.95  # Adjusted adaptation factor\n        self.diversity_prob = 0.3  # Increased probability for diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            if np.random.rand() < self.adapt_factor:\n                self.w *= 1.05  # Slightly increase inertia weight occasionally\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = (np.random.rand(self.dim) < self.CR) | np.random.rand(self.dim) < 0.1\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] = np.clip(velocities[i], self.bounds[0] - pop[i], self.bounds[1] - pop[i])\n\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                challenger = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n                challenger_value = func(challenger)\n                self.current_eval += 1\n                if challenger_value < global_best_value:\n                    global_best = challenger\n                    global_best_value = challenger_value\n\n        return global_best", "name": "AdaptiveProbabilisticDEPSOOptimizer", "description": "Adaptive DEPSO optimizer with probabilistic crossover and dynamic diversification inspired by evolutionary strategies for enhanced convergence.", "configspace": "", "generation": 55, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"ufunc 'bitwise_or' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\").", "error": "TypeError(\"ufunc 'bitwise_or' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\")", "parent_id": "f1de49e0-fa67-4cc6-ad1b-5acddda8b9c5", "metadata": {}, "mutation_prompt": null}
{"id": "9f8738dc-f31b-4302-a833-7a066cd1918e", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 12 * dim\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.62  # Adjusted inertia weight for improved convergence\n        self.c1 = 1.8  # Slightly increased cognitive coefficient\n        self.c2 = 1.5  # Modified social coefficient for balance\n        self.F = 0.90  # Enhanced mutation factor\n        self.CR = 0.85  # Increased crossover rate\n        self.adapt_factor = 0.85  # Modified adaptation strategy\n        self.diversity_prob = 0.2  # Refined probability for diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -2.0, 2.0)  # Adaptive velocity clipping\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.5, 0.5, self.dim)  # Stochastic perturbation\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A refined adaptive DEPSO hybrid optimizer incorporating stochastic perturbations and adaptive velocity clipping for enhanced convergence.", "configspace": "", "generation": 56, "fitness": 0.388495867520134, "feedback": "The algorithm RefinedAdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.28.", "error": "", "parent_id": "f1de49e0-fa67-4cc6-ad1b-5acddda8b9c5", "metadata": {"aucs": [0.8884451127783082, 0.8805347476076905, 0.8785614360390426, 0.8602920108204787, 0.858985871888103, 0.8785938802448261, 0.8717916796531366, 0.8839537866142294, 0.8657838377627914, 0.6592959826021951, 0.6762330783041066, 0.6784332600848397, 0.7066710477690341, 0.706442670316197, 0.6717276677218964, 0.7021180862903345, 0.6859452652536769, 0.7378928755197247, 0.17787328470496944, 0.12960437326423457, 0.1828164502042513, 0.11425917130150343, 0.1210333330426101, 0.15684585690973307, 0.15304895266086682, 0.15396059591144073, 0.17248144121253772, 0.11488082061771687, 0.12659062537472876, 0.10232444436659627, 0.10401173904711736, 0.1123939027205193, 0.10527546089171536, 0.1080178905966721, 0.10757549327726268, 0.14754267528100007, 0.9537708327000517, 0.9295671747029737, 0.9465120369267864, 0.9403057104548471, 0.927312805818602, 0.9476983994201303, 0.9414105277724355, 0.9401415454651801, 0.9675842959184684, 0.6190433297079935, 0.6042989558677696, 0.6276617849761794, 0.674782903262183, 0.5796102106873695, 0.5829416990874944, 0.6468375117980978, 0.5969346419796526, 0.5998271423959817, 0.8427799417631235, 0.7446345517473725, 0.8891071183394846, 0.36336508804081646, 0.2754353900536438, 0.3610467601523083, 0.23212956992203337, 0.8444403165230552, 0.36144651619431456, 0.5701195760558082, 0.49351607982819556, 0.13048885841718094, 0.13100727480716923, 0.7175406726789513, 0.5831618022148143, 0.5288896161212453, 0.5902387561669997, 0.43364573768901027, 0.7997914202913585, 0.6020417659643513, 0.5737540329600961, 0.5418375950256449, 0.5306242252632992, 0.7317845398325189, 0.5382529273806129, 0.5897501891381727, 0.13067150073215905, 0.1421031461406994, 0.3827643705133491, 0.24048759723891577, 0.14702246755331194, 0.3585931031725421, 0.15132483963754617, 0.09535141475741515, 0.07683183373613667, 0.009256282293250151, 0.33312839559115337, 0.3122760224344373, 0.409669651535188, 0.18973605466855692, 0.429106132086851, 0.1359947851550436, 0.18909625526271978, 0.2600776455160463, 0.48827773944756514, 0.05455567678449169, 0.2322301542794396, 0.33752128753902566, 0.21739153993881144, 0.1497418416717312, 0.3639579196788997, 0.14231277219794614, 0.22689695952607714, 0.1901378794328452, 0.10136657778963276, 0.23160363739436352, 0.10178437485309477, 0.2982544885012244, 0.16082064822866193, 0.27187784439371876, 0.1825367478973705, 0.159032485058619, 0.08185423805839676, 0.7757048093753668, 0.6759603888464975, 0.6924114913886715, 0.6648961465175185, 0.606266554903852, 0.706316097027457, 0.6866159434003134, 0.6413756990635713, 0.7200366042366025, 0.09728904794066873, 0.11060989918408937, 0.11734699051042552, 0.15658067370515183, 0.11723123703935656, 0.13991421628739786, 0.17692975240266373, 0.1559946635228161, 0.10715900187727789, 0.1624732793703504, 0.21938620666661968, 0.2569756948279126, 0.2477258008080806, 0.2646044408925047, 0.24033536702411396, 0.20849914202995357, 0.2765327326706868, 0.33907170377011375, 0.3481804159474967, 0.31147080807625993, 0.3577702638105945, 0.27804191433409453, 0.2666682366325416, 0.5010014233990375, 0.28229603257532687, 0.4107496298361716, 0.2992798947276093, 0.23116575141394913, 0.2221978270963576, 0.24618834962272462, 0.33092636516386154, 0.24478825679944327, 0.2951038567241937, 0.20792183244702545, 0.3667945858592787, 0.17439310668485541, 0.20896985570392057, 0.25503990799275833, 0.29142879639371, 0.24551721320427256, 0.22495441133676863, 0.23425923340336552, 0.2514158981781025, 0.22402341456514618, 0.24561892890572612, 0.22362862505759062, 0.21020045462888381, 0.20846493687204315, 0.23052831957547326, 0.2502373643400816, 0.22051487896298871, 0.18626191051000984, 0.1857866120697016, 0.20170117206341054, 0.9096979110867941, 0.9110426160763689, 0.18725137033027117, 0.9227638314998469, 0.20018410558196242, 0.9231724057711042, 0.14215211138986739, 0.175135348304592, 0.15805364291605495, 0.887782671929558, 0.2119906430699966, 0.868363103103898, 0.8834717421378814, 0.16843866822928433, 0.1989974522750062, 0.8486415382800165, 0.16838608936061794, 0.8637396719313516, 0.20041088232193638, 0.19150951307872544, 0.2343049363013887, 0.19596633237667505, 0.19763672534815013, 0.21294741828874486, 0.22482267898678943, 0.1952487830135885, 0.17522692603372036, 0.10330261667846641, 0.10250990952397532, 0.09231140989975661, 0.09523809351290746, 0.09613672046850219, 0.11406104841930742, 0.08500927600930264, 0.10549191377774936, 0.1310162559628708]}, "mutation_prompt": null}
{"id": "50faecd1-d57e-4974-a47f-65ab9e7bb485", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 12 * dim\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.65  # Slightly adjusted inertia weight for enhanced exploration\n        self.c1 = 1.9  # Further increased cognitive coefficient for diversity\n        self.c2 = 1.4  # Reduced social coefficient to balance exploration\n        self.F = 0.95  # Higher mutation factor for increased diversity\n        self.CR = 0.8  # Decreased crossover rate to favor exploration\n        self.adapt_factor = 0.9  # Updated adaptation strategy for better stability\n        self.diversity_prob = 0.25  # Increased probability for enhanced diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -2.0, 2.0)  # Adaptive velocity clipping\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.6, 0.6, self.dim)  # Increased stochastic perturbation\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A refined adaptive DEPSO hybrid optimizer with enhanced perturbation diversity and dynamic coefficient adjustments for robust convergence.", "configspace": "", "generation": 57, "fitness": 0.39448917273654704, "feedback": "The algorithm RefinedAdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.28.", "error": "", "parent_id": "9f8738dc-f31b-4302-a833-7a066cd1918e", "metadata": {"aucs": [0.8559563759912958, 0.8488586529491216, 0.84722518641552, 0.8590879189201657, 0.845554907436293, 0.8510844284311991, 0.8464797361733107, 0.8411372739014482, 0.8510882543074072, 0.6441846523267722, 0.6409567097364219, 0.6718094350607613, 0.6675602130065423, 0.6813638547314091, 0.6712257080192991, 0.6608703093531265, 0.6566040393175194, 0.6732323616598137, 0.13752722597390366, 0.11855871513703953, 0.13933572104985636, 0.13505962668057714, 0.12878859480020133, 0.1386862446432251, 0.1106842638071095, 0.15337365435949868, 0.10279488997978092, 0.099063394159428, 0.10990867185712472, 0.11778528273369504, 0.14044858346630484, 0.11090610113983035, 0.12785816579632192, 0.1130333281097261, 0.13143370259028742, 0.1334110087330197, 0.9542269577014131, 0.9335307524054148, 0.9508985457934097, 0.9422521379015875, 0.9296133528775153, 0.9216703386945115, 0.9416509731699138, 0.9405083486176503, 0.9535600256765255, 0.6587051877938906, 0.639287753075108, 0.6167016284401792, 0.6639309842213368, 0.7065490746779097, 0.640763202959772, 0.6113470299067105, 0.6207473567432369, 0.6398140704598725, 0.38444613946551354, 0.8508301890652075, 0.37354873844648673, 0.2741496310057009, 0.2742306039256458, 0.2477854112938418, 0.8198672740813244, 0.8709320565684079, 0.8565064323347441, 0.5020890186774516, 0.12563009549228976, 0.5331338517339133, 0.12997795564683334, 0.5861925153869346, 0.5194664259108747, 0.6769704224164111, 0.49841195604607114, 0.5543125208203326, 0.7266600900545236, 0.13029810422954502, 0.709780524482672, 0.6445304600017032, 0.5667313374894944, 0.47417875458436287, 0.5736912170954651, 0.587018003981067, 0.4531881847451197, 0.0669552629639878, 0.06493364721232375, 0.04015513138543503, 0.04763057972815821, 0.11161611335996968, 0.10140046010427761, 0.22001724725310257, 0.008531328220485745, 0.10138656180625472, 0.31353095777728524, 0.20864529347332006, 0.40151860728851896, 0.18862395870513804, 0.3946701378679921, 0.18222819106150068, 0.4259202244058333, 0.2686338333391317, 0.40315780841959514, 0.21767809413358696, 0.13976681379801226, 0.07908570141490179, 0.18118715744896796, 0.3656802419282702, 0.13797186573482434, 0.16415661382666258, 0.14456372818163477, 0.12527348492333057, 0.15398512331830205, 0.27471929840868947, 0.270633027715555, 0.31674856193426704, 0.3088580395916428, 0.15111882217466477, 0.14405745626116717, 0.2465048103808284, 0.20447446478440545, 0.7052715562973204, 0.6767557084979149, 0.6300122088844076, 0.6969012900892679, 0.5839140206144482, 0.632454568727876, 0.6698044049653207, 0.7722150685074916, 0.6788645322898046, 0.15094553649587628, 0.10176787821171251, 0.12451800140071534, 0.15576371571399283, 0.14238934182718566, 0.11033532724873008, 0.09370761163463215, 0.11636691198535043, 0.09235069323391831, 0.30964618485080964, 0.22372049380718362, 0.2250227630627294, 0.2031802587304269, 0.19888363967665024, 0.17726652005921606, 0.3266721529207527, 0.15910423194022183, 0.2815274407610585, 0.2693320004802049, 0.3879542448604677, 0.3471813857995487, 0.43218775824607425, 0.3239711387648314, 0.36134298243612173, 0.3967678285417914, 0.3257462126867685, 0.4092697363561112, 0.1608054713221121, 0.24733410849439197, 0.3069944746517891, 0.44565703248614663, 0.24140463707029358, 0.2757775640275574, 0.2613625222112228, 0.22834380258792253, 0.22335774085579452, 0.23665312632054214, 0.24516844865454912, 0.27073817636078956, 0.22059481324858254, 0.2411257723852257, 0.2215781069608702, 0.2706313685631939, 0.23849290234089615, 0.21530997572861288, 0.1975105321621884, 0.19213591069799185, 0.17916022773833395, 0.18931923455811872, 0.24055548558004602, 0.2102892245891539, 0.21866199374148143, 0.19155003962545125, 0.17881320905693632, 0.8972933049314908, 0.7614985077109202, 0.16706593682201165, 0.9122701923440302, 0.8832759590092866, 0.8929505611208586, 0.7528564175389394, 0.163898423996089, 0.8540102548261291, 0.8938403261270016, 0.2121118566072283, 0.8753045566631372, 0.8649571325487135, 0.6686713144350627, 0.8044077048836981, 0.8050881277839708, 0.20966587935982228, 0.763252741189398, 0.22985073138797174, 0.18525052825940225, 0.21565532891698524, 0.19430850403272237, 0.18578094803800604, 0.19157397499997364, 0.18177565377277305, 0.18614844047272183, 0.19139675144346135, 0.10731541128840694, 0.13762286661884005, 0.14645542513983711, 0.10959915885391891, 0.10380999296789162, 0.09565194426354051, 0.08924202646533541, 0.09450077616514463, 0.08959091829804033]}, "mutation_prompt": null}
{"id": "36e6ed05-97b9-46e8-b5d8-10f9d3f8f391", "solution": "import numpy as np\n\nclass ImprovedHybridDEPSOOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Adjusted population size for better balance\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.7  # Adjusted inertia weight to enhance convergence speed\n        self.c1 = 2.0  # Increased cognitive coefficient for better local search\n        self.c2 = 1.2  # Reduced social coefficient to refine exploration\n        self.F = 0.85  # Adjusted mutation factor to maintain adequate diversity\n        self.CR = 0.75  # Modified crossover rate for improved exploration\n        self.adapt_factor = 0.95  # Fine-tuned adaptation strategy for stability\n        self.diversity_prob = 0.3  # Increased probability for exploratory perturbation\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.5, 1.5)  # Adjusted velocity clipping for control\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.5, 0.5, self.dim)  # Enhanced perturbation for diversity\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "ImprovedHybridDEPSOOptimizer", "description": "An improved hybrid optimizer integrating adaptive DE and PSO strategies with dynamic parameter adjustments and novel exploratory mechanisms for robust global search.", "configspace": "", "generation": 58, "fitness": 0.3884810517786703, "feedback": "The algorithm ImprovedHybridDEPSOOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.27.", "error": "", "parent_id": "50faecd1-d57e-4974-a47f-65ab9e7bb485", "metadata": {"aucs": [0.8442110048857938, 0.8218970533928388, 0.811765945787384, 0.8420599961465447, 0.8243788893328227, 0.8259109587327058, 0.8418304622963516, 0.832871244968408, 0.8091131274987792, 0.6284719633320373, 0.6836130168620593, 0.6435302671995928, 0.6554102616070951, 0.6439891502106441, 0.6041038113487209, 0.6074574742137155, 0.609422588159111, 0.6220107977577731, 0.12034383383296643, 0.12879744220331635, 0.14594800023851096, 0.12016373870816677, 0.6189737641361878, 0.15168214795194412, 0.13465930832827977, 0.15420990227495035, 0.12609925705467995, 0.10456384089219994, 0.12492332150292174, 0.08979253970717105, 0.166806366171664, 0.09952406734402153, 0.11000698245829699, 0.1108488407510313, 0.14773612105783507, 0.10815984349194441, 0.9355447948150528, 0.9120639698227768, 0.9268881263662957, 0.941078428417802, 0.9276514659447809, 0.9243833012513392, 0.9126798639337415, 0.9267247921820319, 0.9309604924401548, 0.6666026515232387, 0.6545992509189464, 0.67559441785935, 0.6312148118801963, 0.6512325456062351, 0.6571119629969249, 0.6630411773549905, 0.6853058462338238, 0.677699697585479, 0.3803490420395086, 0.85776843445446, 0.742285759385998, 0.21886437845104878, 0.8645325970589407, 0.41822477450834106, 0.22988740359389281, 0.8113621232525519, 0.8447806843668921, 0.4986542974306599, 0.5389431563203405, 0.6057480558089723, 0.1287567872064188, 0.4691946944381481, 0.48547340143668594, 0.43239001692193035, 0.5305615439858288, 0.4166478960908926, 0.25806570062385903, 0.3520404712107743, 0.48177234713555217, 0.6136732244563112, 0.5529263528898158, 0.5310168002762805, 0.4827228261268951, 0.5832282856016173, 0.12869604104851062, 0.13489145049310336, 0.19487320308019263, 0.11449756013787538, 0.1937435709243679, 0.1289324310642651, 0.11743377055174042, 0.12774945537133497, 0.04622140345055836, 0.176920456290376, 0.46265416853915653, 0.18765620281218975, 0.3992740222109019, 0.1325330571416704, 0.09102893978467363, 0.24375546938605175, 0.24505452626666424, 0.5041320667380824, 0.2291352640324319, 0.12732742243643624, 0.17367177413158075, 0.23471486404522268, 0.29566867647467, 0.0716455446184342, 0.08422037549749006, 0.08913165328153705, 0.33482921085534767, 0.1736491442781205, 0.15753872841194205, 0.10622580052916242, 0.26625948652999865, 0.16417830909894604, 0.23816241047517805, 0.25405354835578575, 0.25056600913033455, 0.1702783920667127, 0.10783357974747398, 0.6493083345363688, 0.6831314232025718, 0.6501228266524726, 0.6403363229478818, 0.614389260831021, 0.6072865359439026, 0.5903771106864016, 0.5913234604612503, 0.5982633885455726, 0.11008557085169957, 0.1454393452518088, 0.10875854746067304, 0.1357290775354828, 0.1331426753187478, 0.14226571341020844, 0.13004445656631747, 0.10400429316343218, 0.1689030849678016, 0.3601375005229759, 0.23411219176082898, 0.20339135558968058, 0.16368980680275558, 0.2137806717512476, 0.21828910453077666, 0.30423315729745537, 0.17850106634103902, 0.2574888011510793, 0.4192271038194193, 0.4783222990543281, 0.3775490872767978, 0.4197199253826791, 0.32663056168850957, 0.4381143041688963, 0.2589645438458109, 0.3953740781439289, 0.4508063624126839, 0.2949632720076032, 0.20183520316216763, 0.312343629370022, 0.2481401140983519, 0.2862452471580741, 0.35055439991684056, 0.2439749705826808, 0.2645001282808882, 0.22971919722548173, 0.24289457459381947, 0.24864284621761912, 0.2299874099354764, 0.22898351516700355, 0.22355960367806715, 0.25045208220361703, 0.2043227665070836, 0.2430856276409299, 0.20925488816039384, 0.19621404579772905, 0.20419768344109968, 0.2153618358537176, 0.21536407483804632, 0.2045393140869599, 0.2041933772875386, 0.19671378531043016, 0.5742935056061542, 0.24171480303502513, 0.8825186270590919, 0.8051921492796867, 0.20364677421022737, 0.9021388374045614, 0.19868306755090437, 0.19522222794411714, 0.8870104292402617, 0.8015962192461368, 0.7256418100963685, 0.8668718494405636, 0.35622999956789014, 0.8341820886255535, 0.8063068917713379, 0.16605738029802886, 0.8319461305856094, 0.8327651239134999, 0.15407611938467258, 0.8591405733795473, 0.1936050467153565, 0.1868295905932741, 0.18071683281135753, 0.19492775986954447, 0.20320085002218524, 0.1895427882552876, 0.21370156717682953, 0.21643321730467058, 0.20056861397905656, 0.0933214824723958, 0.09160232450419681, 0.10441712507485246, 0.08812730489470211, 0.08268850068438482, 0.08627100493064921, 0.10540352651970042, 0.09840115083209444, 0.10095297418408977]}, "mutation_prompt": null}
{"id": "56443b25-c22d-439d-b64a-a593514e2a75", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Slight reduction in population size for faster convergence\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.7  # Increased inertia weight for more exploration\n        self.c1 = 1.8  # Adjusted cognitive coefficient for better balance\n        self.c2 = 1.5  # Slightly increased social coefficient for enhanced convergence\n        self.F = 0.9  # Mutation factor reduced for more precise local search\n        self.CR = 0.85  # Increased crossover rate for better exploitation\n        self.adapt_factor = 0.95  # Slightly different adaptation strategy for stability\n        self.diversity_prob = 0.3  # Higher probability for perturbation to escape local optima\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))  # Tighter initial velocity bounds\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.5, 1.5)  # Adjusted velocity clipping for better control\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.5, 0.5, self.dim)  # Adjusted perturbation range\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "EnhancedAdaptiveDEPSOHybridOptimizer", "description": "An enhanced hybrid optimizer leveraging adaptive control parameters with strategic individual line modifications for improved global search efficiency.", "configspace": "", "generation": 59, "fitness": 0.39531318715063785, "feedback": "The algorithm EnhancedAdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.27.", "error": "", "parent_id": "50faecd1-d57e-4974-a47f-65ab9e7bb485", "metadata": {"aucs": [0.8390953892486464, 0.8245416589425913, 0.8208496163162203, 0.8169590629414033, 0.827736352339867, 0.8164789217683773, 0.83625458184033, 0.815737031774429, 0.8262397128575488, 0.6450105369521947, 0.6207426993341705, 0.6287001876801154, 0.6003822387438715, 0.6260464596668626, 0.6307257981028822, 0.5869922381212234, 0.6093282763243004, 0.599528451587118, 0.15402639901924908, 0.1377970016797384, 0.13054097838542078, 0.15497615518986185, 0.15095282594564674, 0.1544047132898504, 0.11359602437254412, 0.12168653926192396, 0.15159530090355344, 0.11439035997756941, 0.0998678948405135, 0.11997471098687185, 0.13511367396789997, 0.12950689136110727, 0.11807988041604967, 0.13039137522625244, 0.11196059929270363, 0.08686069594314738, 0.959182596923995, 0.9049053081318055, 0.9294392074442673, 0.9419181555179839, 0.9101178138996576, 0.9169467563755195, 0.8888748198613479, 0.9359074640802285, 0.9524971664475285, 0.6608249760280993, 0.650258085836801, 0.6647726644208756, 0.657164913814225, 0.6670781898772055, 0.637556640629968, 0.6136986700172482, 0.6180377069885709, 0.6558844543882651, 0.8599972617823719, 0.5117397048444856, 0.8064990158983482, 0.27659864530177236, 0.8096335366842533, 0.825012072751, 0.8236610727218825, 0.7851641262907169, 0.38761816306604835, 0.12906151229772544, 0.12835360861639944, 0.5717745198149418, 0.5326822746043662, 0.6014684752479486, 0.5682679535876833, 0.5594205787992923, 0.5463429884113125, 0.504773156487935, 0.6495603690901119, 0.6673019256909635, 0.6197758946012344, 0.6746041396720783, 0.5995069826111217, 0.569537421623082, 0.5560495271680843, 0.5817199465465512, 0.565027149660918, 0.060384561136419324, 0.11281571964460813, 0.09980291806121788, 0.032032777672861945, 0.21693907203893537, 0.06487797083682667, 0.3820462692305987, 0.2501130665080227, 0.23382617986148524, 0.27213049542246026, 0.2906062785134902, 0.1983556547579467, 0.35252719277481126, 0.18491392585308186, 0.14154723056149832, 0.25500804030272073, 0.38092621604686117, 0.21657106899805756, 0.4153284911550723, 0.044677807960255445, 0.27060065063977823, 0.23364572026475727, 0.23126218225216433, 0.2047151488221295, 0.08972995778133741, 0.184031558952787, 0.11785629685003973, 0.3754503642575514, 0.22202398302148507, 0.15227564546252015, 0.3393788317184404, 0.3776424551022214, 0.4223937781974201, 0.3956844837889072, 0.19612119766137648, 0.08638464681860025, 0.6484063235426443, 0.729919864870102, 0.7035007337840806, 0.6860061963521578, 0.5845876687766491, 0.7544903739820085, 0.7615511463153581, 0.6693301295525658, 0.65306187582158, 0.08907805896584231, 0.1151825394732452, 0.14102820132745397, 0.1532661731014321, 0.1633981798490387, 0.14930389368222952, 0.1535606210700875, 0.11871827662851431, 0.08618047178395916, 0.1857666916818015, 0.3614866896162994, 0.2560813949533932, 0.17823761572721086, 0.1853357564821566, 0.38251973682872376, 0.4008993479664157, 0.21896247866743268, 0.23932138360107824, 0.3896829117398527, 0.44877116114605753, 0.3649981733590022, 0.35195196744062796, 0.3138311198786653, 0.40013327752649597, 0.2751650571575034, 0.29683302018330404, 0.373607640395737, 0.2695961250696569, 0.25184321720797054, 0.23299105200865555, 0.36977359642821495, 0.22487959437671934, 0.24592375087392537, 0.3040056090493114, 0.28150826486315095, 0.2581136459552249, 0.23336979595818852, 0.2355113899274872, 0.23654328719978224, 0.21583576245097025, 0.24088396993091532, 0.24995439237043537, 0.24052274830366838, 0.2460403531111528, 0.24921984680422937, 0.1886352816479454, 0.202503417079682, 0.1987379905436497, 0.19881069209797764, 0.1953780573709345, 0.1806803013375582, 0.19245434407421913, 0.2180567164899323, 0.20685754858223315, 0.8880291679717007, 0.18589841298561227, 0.1463879649606713, 0.8850598352091301, 0.19840296842451022, 0.1654913554049594, 0.7922892239345372, 0.8638247904885786, 0.8751549169283828, 0.8647212291246976, 0.20975113848152438, 0.8102942833497799, 0.20949494860329754, 0.8242718220916073, 0.8642455459108862, 0.1676055623428463, 0.8294730711567769, 0.20931900508123613, 0.21387770066032108, 0.23895736615410068, 0.20673359081108833, 0.20015997984175626, 0.20562038727548093, 0.20165547274146478, 0.2308507121979516, 0.21265592937133915, 0.19656830287968274, 0.0914110450220571, 0.0985871405143669, 0.10234365122889322, 0.0861938243640219, 0.10868196441618727, 0.09503241888415337, 0.08716379906510496, 0.09913816444961687, 0.10159813977793541]}, "mutation_prompt": null}
{"id": "2622f588-6b8c-44de-bd17-a9734d6c9530", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDEPSOPlusOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 12 * dim  # Increase population size for diversity\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Lower inertia weight for quicker convergence\n        self.c1 = 1.9  # Increased cognitive coefficient for stronger local search\n        self.c2 = 1.4  # Reduced social coefficient for avoiding premature convergence\n        self.F = 0.85  # Slightly adjusted mutation factor for balance\n        self.CR = 0.8  # Reduced crossover rate for more exploration\n        self.adapt_factor = 0.98  # Slower adaptation to maintain diversity\n        self.diversity_prob = 0.25  # Adjusted probability for improved escape strategy\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))  # Expanded initial velocity range\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]) +\n                                 np.random.uniform(-0.1, 0.1, self.dim))  # Introduced small random exploration\n                \n                velocities[i] = np.clip(velocities[i], -2.0, 2.0)  # Expanded velocity clipping for greater flexibility\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.7, 0.7, self.dim)  # Increased perturbation range\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "EnhancedAdaptiveDEPSOPlusOptimizer", "description": "A novel hybrid optimizer with probabilistic adaptive parameters and enhanced exploration-exploitation balance using modified velocity updates.", "configspace": "", "generation": 60, "fitness": 0.24571541870167693, "feedback": "The algorithm EnhancedAdaptiveDEPSOPlusOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.21.", "error": "", "parent_id": "56443b25-c22d-439d-b64a-a593514e2a75", "metadata": {"aucs": [0.4150159322830479, 0.43109532379701054, 0.443631662232411, 0.4120010785576548, 0.42262280465337687, 0.43771024938837066, 0.4381956276563629, 0.42459070658110076, 0.4408496227033861, 0.004024044679100225, 0.028871171765241344, 0.048866754371030274, 0.05798597138716122, 0.0704419759797269, 0.03142709282722311, 0.03432548669351987, 0.09422516205165865, 0.027242800592016114, 0.13749226534731007, 0.11154460831489055, 0.110115860663618, 0.11438261358566992, 0.10681651682881144, 0.13108266297074456, 0.12817726243063976, 0.1172867345832459, 0.13012010990937284, 0.10019556018559228, 0.10393021860149942, 0.10169582627568963, 0.10468112093924842, 0.09187484041087335, 0.11089187746000684, 0.0987444720701307, 0.11884860972962397, 0.10098386570354667, 0.9528696239286725, 0.9395244781448184, 0.9527383058865223, 0.9419997220350129, 0.9398467389890331, 0.9355302867774538, 0.9343034439409142, 0.9290729829684405, 0.9543954466528682, 0.29025603263888455, 0.2971378057576438, 0.29329811305260023, 0.298842640499296, 0.30968942343096884, 0.30272609819388685, 0.29758385160374523, 0.2893835400297846, 0.2811825207591684, 0.7520751967860577, 0.6959389181237043, 0.3347783180600985, 0.3476160658470191, 0.5953767892473506, 0.3609058102430137, 0.35056006563011355, 0.3543146610337159, 0.4241552456337876, 0.15593170102448717, 0.13782543805992042, 0.16512215292721144, 0.11552954862772691, 0.1484752237117689, 0.14677850108847856, 0.1573370185904388, 0.17435455935662525, 0.15372178597123187, 0.16552582947742445, 0.1634541111626595, 0.17154969394221786, 0.1786456932672027, 0.1634170836983081, 0.1710320381414514, 0.18648780158191536, 0.14905053847043515, 0.14977492525659164, 0.035991630345107106, 0.03854763023395957, 0.04336994408996486, 9.999999999998899e-05, 0.03719623922732085, 9.999999999998899e-05, 0.023574550737655575, 0.031077481992745404, 9.999999999998899e-05, 0.133196793524906, 0.19323993887870605, 0.16221754190339777, 0.09615486743905732, 0.09083044755650493, 0.10158051539615787, 0.10583560818972326, 0.11225945254001768, 0.16021517810273123, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09682558496273941, 0.08069876002296439, 0.1137738402485935, 0.11000356158670088, 0.10544722761963876, 0.11618691071679388, 0.07775458003889357, 0.11041140911868297, 0.08663799137073658, 0.4128204250718326, 0.4124271046345227, 0.3966562552425421, 0.40054303456827034, 0.4239118862334361, 0.40056101651951714, 0.40502271868682105, 0.41155063561298144, 0.40174218285904095, 0.13853230322493104, 0.1705619039639803, 0.16885905979737348, 0.11887353602576944, 0.12260595256621676, 0.12762787983554247, 0.10642625851635623, 0.12956680065768145, 0.11311020859641774, 0.25539980529384276, 0.23268783841694984, 0.26717739159021625, 0.23929939223336805, 0.2373816147347908, 0.2078145048431166, 0.2642133498512719, 0.20514449200846785, 0.23585685699107561, 0.2879217977533578, 0.30095176287483405, 0.298879466076295, 0.29546601840424314, 0.28742534839215184, 0.2915726687988135, 0.29520797593168246, 0.28521864679085107, 0.2707025891994522, 0.23489092145131518, 0.2322095544144529, 0.23782253075403492, 0.2518792518050832, 0.24267457203235498, 0.22676286013999936, 0.20926324404434526, 0.24632860687353153, 0.23176495129613284, 0.19988000490388658, 0.21058997332129525, 0.18870944725327976, 0.22215485809113011, 0.224414650235092, 0.2299146223450006, 0.19535892542920164, 0.2395701981124796, 0.21843495710344152, 0.20020425188863167, 0.21808833898827917, 0.21458735891524816, 0.19770196080899127, 0.1913207514787082, 0.18791499448582927, 0.1997404195870255, 0.20932734778118034, 0.17383340670269587, 0.18415369663148995, 0.186229023003331, 0.18525595579563026, 0.6687817040860435, 0.19748833304523083, 0.6347194029365988, 0.5702986543079805, 0.623253766316739, 0.6537219789192126, 0.5950845434414325, 0.2109416595714424, 0.547158160544503, 0.5838652304918488, 0.20739139602373002, 0.6138938835252186, 0.5647852308298175, 0.5988655092466622, 0.559349634258612, 0.17665458112218402, 0.18679207166576406, 0.179790916006205, 0.19107396354984463, 0.18124513707609458, 0.1711678245288777, 0.18212565402719305, 0.17750937734973427, 0.19233742903726314, 0.09926340779856968, 0.11407705842175497, 0.08039616907371905, 0.08699386468941939, 0.08365660496479377, 0.103614843522426, 0.09003194174826534, 0.08423126419758176, 0.09693497446206367]}, "mutation_prompt": null}
{"id": "0ff9e7a4-7550-43ab-9f45-f1f6fa4d9b19", "solution": "import numpy as np\n\nclass RefinedHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.8  # Adjusted inertia weight for balanced exploration-exploitation\n        self.c1 = 2.0  # Increased cognitive coefficient for stronger local search\n        self.c2 = 1.3  # Reduced social coefficient for improved diversity\n        self.F = 0.85  # Mutation factor adjusted for adaptive search precision\n        self.CR = 0.8  # Adapted crossover rate for effective exploitation\n        self.adapt_factor = 0.9  # Dynamic adaptation for convergence speed\n        self.diversity_prob = 0.25  # Perturbation probability for escaping local minima\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.0, 1.0)  # Adjusted velocity clipping for refined control\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.4, 0.4, self.dim)  # Refined perturbation strategy\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedHybridOptimizer", "description": "A refined hybrid optimizer with dynamic adaptation of parameters and enhanced perturbation strategies for superior exploration and exploitation.", "configspace": "", "generation": 61, "fitness": 0.3828962629873758, "feedback": "The algorithm RefinedHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38 with standard deviation 0.27.", "error": "", "parent_id": "56443b25-c22d-439d-b64a-a593514e2a75", "metadata": {"aucs": [0.8644640208327956, 0.8654749957840411, 0.8741031093428868, 0.8590638354032334, 0.8499572250740758, 0.854656421992222, 0.8551873252317443, 0.8592417415434962, 0.8633529351087954, 0.6911434534341063, 0.6618610996107126, 0.6693486726546982, 0.6500395079605258, 0.6539651243774752, 0.7479418545683922, 0.7140132050798604, 0.701570619212214, 0.7073761180729112, 0.1402011899965726, 0.1483091850589714, 0.15570234375237502, 0.1392215387750514, 0.11888296214804017, 0.12999640740621277, 0.10251181670495135, 0.14933844791683437, 0.09969454745761686, 0.12525556267711235, 0.1053386356127134, 0.10738434158110777, 0.12158182280736163, 0.11805897114011044, 0.14185770371533402, 0.14834307698924643, 0.1171727649024118, 0.1019121963673344, 0.9013010195795677, 0.8919895348554308, 0.8898867714272022, 0.903660940736123, 0.8912701145928531, 0.8684946007782977, 0.9156932762766753, 0.8678392770662371, 0.9065235315938478, 0.6459325567980831, 0.6901005107102194, 0.6855922147006741, 0.7016390837486065, 0.5963713819260301, 0.6114439186101439, 0.7024255233611987, 0.6329025378950526, 0.6100681593064328, 0.22603699396010501, 0.8384892687209486, 0.22450190425622618, 0.8487061151011346, 0.19296501103937358, 0.3550253444690029, 0.1746375424593869, 0.7791720965232637, 0.2304202856919917, 0.699579227147228, 0.5499051114717481, 0.12832427700327043, 0.5797131698123072, 0.13026987913599897, 0.41580004731190356, 0.4695989679662522, 0.6554106054169074, 0.7109345304161738, 0.5490870247166422, 0.12542063431308148, 0.5145057075926462, 0.33537462682723684, 0.59051240190243, 0.5960638062327317, 0.5893353572810394, 0.48562076894584094, 0.5286700432666982, 0.1045148624680351, 0.10360264880985903, 0.16593736559440408, 0.06276282540970657, 0.23463272676855673, 0.13018791121869544, 0.1475663306706858, 0.1883112067080006, 0.10797432696382514, 0.26525844128481735, 0.3664868170663662, 0.2676553324513744, 0.11700531766675626, 0.15183045159336017, 0.2978003797065668, 0.2826276529128908, 0.42656173353204774, 0.24115226911824628, 0.3689472466026408, 0.09650748272099441, 0.20718745796885074, 0.43120108974438864, 0.19605398278724673, 0.29504947291880435, 0.10890575600457564, 0.1834108709565615, 0.13629760844786176, 0.1453382337444744, 0.5220452502142803, 0.2699454927616344, 0.13081006905339854, 0.38747355987043697, 0.20639337517504686, 0.37099925982951176, 0.07915156188439998, 0.08214395539002073, 0.7676802996030757, 0.6711394123841132, 0.6828883535529251, 0.64151364151447, 0.612394279933675, 0.6264134189396566, 0.6502925743554987, 0.62640249162175, 0.6529911554725609, 0.12715083037888997, 0.08137316554572449, 0.08611253659883955, 0.137739652342188, 0.12932157584734327, 0.13721529807376553, 0.1376531500061512, 0.17602222290458902, 0.1291494946511813, 0.2587260949273499, 0.2997587077723256, 0.17240761570311314, 0.18544413806535565, 0.22615165862935782, 0.18317295678441892, 0.33263920218400567, 0.21045618698149582, 0.25203868476244684, 0.32379732517529836, 0.33409681045946604, 0.3975682804513302, 0.413106783337274, 0.3912157678957475, 0.43631862602971805, 0.4807383425306021, 0.3894835258354099, 0.46850572077477926, 0.29948097927500883, 0.3367919818991778, 0.24101266820186273, 0.2902292290595646, 0.252811295538346, 0.2967169516699387, 0.31566200787483645, 0.2242016555881975, 0.27685983699848227, 0.255115615309365, 0.2604149150824061, 0.26125579250382724, 0.28796684642769643, 0.21969891266459285, 0.28511339535077973, 0.22997906297736959, 0.24972859634707956, 0.24007214975305513, 0.2195272275364124, 0.19707556988058939, 0.1896132629486127, 0.24959259290662628, 0.20219982382121848, 0.1894796808955702, 0.1970218627104322, 0.18661137518437598, 0.19618992987725192, 0.8978930553010499, 0.18453419021669748, 0.15540113190403027, 0.9172661149809472, 0.19772820480768127, 0.1946516537047681, 0.8862380149020324, 0.16234855165346562, 0.17570106064724877, 0.8549323977560219, 0.21066945078975519, 0.8515656204369586, 0.865282921024677, 0.19605710483923688, 0.8442528789847867, 0.8620683108868659, 0.7809013583159846, 0.7857380820072732, 0.2196189318942916, 0.20488023478330197, 0.20387475436755198, 0.1908585364072507, 0.2021214940503473, 0.1907807244380677, 0.19323662418711218, 0.2015490769322098, 0.17847558484011572, 0.1033680887356433, 0.0884317156969644, 0.09694168459102548, 0.10327675252990864, 0.09222946260437404, 0.1072300143048105, 0.09836084781591448, 0.10861300292332543, 0.08854116144580071]}, "mutation_prompt": null}
{"id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 8 * dim  # Changed population size for faster adaptation\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Adjusted inertia weight for varied exploration\n        self.c1 = 2.0  # Increased cognitive coefficient for enhanced individual focus\n        self.c2 = 1.3  # Decreased social coefficient to balance exploration\n        self.F = 0.85  # Adjusted mutation factor for a balanced search\n        self.CR = 0.9  # Further increased crossover rate to improve exploitation\n        self.adapt_factor = 0.98  # Altered adaptation strategy for fine-tuning dynamics\n        self.diversity_prob = 0.25  # Modified probability to maintain diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.pop_size, self.dim))  # Tighter initial velocity bounds\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.2, 1.2)  # Fine-tuned velocity clipping\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.4, 0.4, self.dim)  # Adjusted perturbation range\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A novel adaptive hybrid optimizer combining differential evolution and particle swarm optimization with probabilistic line refinement for improved convergence and robustness.", "configspace": "", "generation": 62, "fitness": 0.4185410959192057, "feedback": "The algorithm RefinedAdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.42 with standard deviation 0.28.", "error": "", "parent_id": "56443b25-c22d-439d-b64a-a593514e2a75", "metadata": {"aucs": [0.8422026875756686, 0.8316019688777077, 0.8519869328290357, 0.8297406844583839, 0.8252630810752194, 0.8277146988170878, 0.8068246858743604, 0.8561060802327902, 0.8368040280874159, 0.5717081710158031, 0.6229294567072469, 0.6577352366361608, 0.6097452113019179, 0.6248463092449099, 0.6480892213630982, 0.5853863526991877, 0.0512914350509458, 0.6345276944127677, 0.12661715743764002, 0.13553147013685352, 0.1165180416573206, 0.15148546967390686, 0.11833273301113134, 0.11262716667065764, 0.09118768173218983, 0.14706882869418092, 0.12165743506468629, 0.12200259360489396, 0.13034521545583178, 0.10944944258130584, 0.10633023239117789, 0.09527081094569545, 0.11958436269742212, 0.10133130517975841, 0.10989989219452312, 0.10750303865126443, 0.9584574983645874, 0.9456154497882113, 0.9248413138037459, 0.9394551060087084, 0.9178440572107031, 0.9247673511357778, 0.9144207782702397, 0.9195730061057308, 0.9376478922359291, 0.6852319709074105, 0.6780533300046745, 0.7108562413265345, 0.6930832315747306, 0.6473842756151248, 0.6668633835109659, 0.64220068456561, 0.6802151366784446, 0.698301550023128, 0.8284517086601723, 0.8319853512761421, 0.848700148364309, 0.19309996213284675, 0.8640311987671301, 0.8237765327623953, 0.7548692240966136, 0.7386572483314423, 0.8061550552153522, 0.6932523924834011, 0.6326694635926952, 0.5702079409903438, 0.504380399590584, 0.12794219324437095, 0.6326230014369127, 0.6645992326448668, 0.6458071418537177, 0.6824412135078085, 0.6043996176797476, 0.5329321711330159, 0.5621157612975026, 0.5799416763180532, 0.6787042232568141, 0.6327755902918872, 0.6245389618384289, 0.594169038943976, 0.6159025368644813, 0.2142937207523753, 0.5471077190497382, 0.34075658145661114, 0.06300005442848433, 0.32213183089088593, 0.2642637831740825, 0.5790571789927872, 0.2219122676957993, 0.30282947269926586, 0.27733961317035494, 0.3025133376612158, 0.40151213893255033, 0.22581234342655665, 0.12018211681647095, 0.16096111360077414, 0.19341753830233344, 0.4028576817096069, 0.4815084195410494, 0.0971570659457186, 0.11809561294884408, 0.14606350116883315, 0.302776137134796, 0.462988492103911, 0.34443607346144123, 0.12731332407030782, 0.1692466283912818, 0.21420574580174156, 0.25821731821921967, 0.37170899358653164, 0.3209911039463592, 0.20206573914765158, 0.15242447640139722, 0.3654460569911646, 0.0796097810397487, 0.10677503213591588, 0.3671365836218843, 0.7289913375444261, 0.7021916146005962, 0.7667444024290355, 0.6654456240892526, 0.7677149592326706, 0.774739243646891, 0.6856674927873443, 0.7484678961515467, 0.7923371581346985, 0.10519973895126877, 0.13636345543025197, 0.09069979364325631, 0.11397311546275801, 0.14986323712414085, 0.10092383413138228, 0.12178337409989903, 0.13995936282413945, 0.11625146899098693, 0.24031191767279736, 0.2831384168733655, 0.2512288845549715, 0.21349208283147814, 0.2709742534134405, 0.253204641108837, 0.3065697933836059, 0.2569032502330555, 0.21508329618225674, 0.39468858929153916, 0.44493785886825876, 0.3412214442304601, 0.4022518625501722, 0.41978764058825146, 0.34803590937855267, 0.26225525808833394, 0.3355335156396261, 0.5077708211963312, 0.3112174627536882, 0.27900801700448374, 0.21404165006284892, 0.27762550591535406, 0.28627741444079047, 0.2788592224413342, 0.2328027262841742, 0.34512107931937674, 0.2545199493596185, 0.22867202164916411, 0.2536000096249822, 0.247559824187208, 0.23364220594619622, 0.21887149137225992, 0.25138452113105114, 0.22421342801936184, 0.22082035780942944, 0.26193760881573214, 0.6917708034846162, 0.19789960153376596, 0.19597016243354393, 0.1824361653717258, 0.19096904756917732, 0.19631191947214144, 0.2174981643883065, 0.19520924804057704, 0.19598404262508584, 0.18396969015625342, 0.18612147229137166, 0.18517537599147238, 0.8856055410695953, 0.1670557324344476, 0.8368596087322189, 0.8436385097376322, 0.8912841263690393, 0.8947753156261895, 0.8588835393419383, 0.851533553040317, 0.20966216501723933, 0.15504869507750096, 0.8433294130433883, 0.8436479962982408, 0.8482683162296778, 0.8536043853808677, 0.8761218173780815, 0.18914312298110825, 0.18325469051801324, 0.1936603612190574, 0.19372859952831, 0.20479347063556275, 0.19053844456159152, 0.1943455261954916, 0.18417599204962354, 0.18891691406148725, 0.09964227729862762, 0.09408133954616915, 0.0979702773558867, 0.08852594779641498, 0.09971456269814027, 0.11477467723659951, 0.08067348385687656, 0.10256296180541413, 0.13155598340959773]}, "mutation_prompt": null}
{"id": "3c2575b1-25a3-41bc-aa19-8e03311111a0", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 8 * dim  # Changed population size for faster adaptation\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Adjusted inertia weight for varied exploration\n        self.c1 = 2.0  # Increased cognitive coefficient for enhanced individual focus\n        self.c2 = 1.3  # Decreased social coefficient to balance exploration\n        self.F = 0.85  # Adjusted mutation factor for a balanced search\n        self.CR = 0.9  # Further increased crossover rate to improve exploitation\n        self.adapt_factor = 0.98  # Altered adaptation strategy for fine-tuning dynamics\n        self.diversity_prob = 0.25  # Modified probability to maintain diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.pop_size, self.dim))  # Tighter initial velocity bounds\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.2, 1.2)  # Fine-tuned velocity clipping\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.4, 0.4, self.dim)  # Adjusted perturbation range\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A novel adaptive hybrid optimizer combining differential evolution and particle swarm optimization with probabilistic line refinement for improved convergence and robustness.", "configspace": "", "generation": 63, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.8422026875756686, 0.8316019688777077, 0.8519869328290357, 0.8297406844583839, 0.8252630810752194, 0.8277146988170878, 0.8068246858743604, 0.8561060802327902, 0.8368040280874159, 0.5717081710158031, 0.6229294567072469, 0.6577352366361608, 0.6097452113019179, 0.6248463092449099, 0.6480892213630982, 0.5853863526991877, 0.0512914350509458, 0.6345276944127677, 0.12661715743764002, 0.13553147013685352, 0.1165180416573206, 0.15148546967390686, 0.11833273301113134, 0.11262716667065764, 0.09118768173218983, 0.14706882869418092, 0.12165743506468629, 0.12200259360489396, 0.13034521545583178, 0.10944944258130584, 0.10633023239117789, 0.09527081094569545, 0.11958436269742212, 0.10133130517975841, 0.10989989219452312, 0.10750303865126443, 0.9584574983645874, 0.9456154497882113, 0.9248413138037459, 0.9394551060087084, 0.9178440572107031, 0.9247673511357778, 0.9144207782702397, 0.9195730061057308, 0.9376478922359291, 0.6852319709074105, 0.6780533300046745, 0.7108562413265345, 0.6930832315747306, 0.6473842756151248, 0.6668633835109659, 0.64220068456561, 0.6802151366784446, 0.698301550023128, 0.8284517086601723, 0.8319853512761421, 0.848700148364309, 0.19309996213284675, 0.8640311987671301, 0.8237765327623953, 0.7548692240966136, 0.7386572483314423, 0.8061550552153522, 0.6932523924834011, 0.6326694635926952, 0.5702079409903438, 0.504380399590584, 0.12794219324437095, 0.6326230014369127, 0.6645992326448668, 0.6458071418537177, 0.6824412135078085, 0.6043996176797476, 0.5329321711330159, 0.5621157612975026, 0.5799416763180532, 0.6787042232568141, 0.6327755902918872, 0.6245389618384289, 0.594169038943976, 0.6159025368644813, 0.2142937207523753, 0.5471077190497382, 0.34075658145661114, 0.06300005442848433, 0.32213183089088593, 0.2642637831740825, 0.5790571789927872, 0.2219122676957993, 0.30282947269926586, 0.27733961317035494, 0.3025133376612158, 0.40151213893255033, 0.22581234342655665, 0.12018211681647095, 0.16096111360077414, 0.19341753830233344, 0.4028576817096069, 0.4815084195410494, 0.0971570659457186, 0.11809561294884408, 0.14606350116883315, 0.302776137134796, 0.462988492103911, 0.34443607346144123, 0.12731332407030782, 0.1692466283912818, 0.21420574580174156, 0.25821731821921967, 0.37170899358653164, 0.3209911039463592, 0.20206573914765158, 0.15242447640139722, 0.3654460569911646, 0.0796097810397487, 0.10677503213591588, 0.3671365836218843, 0.7289913375444261, 0.7021916146005962, 0.7667444024290355, 0.6654456240892526, 0.7677149592326706, 0.774739243646891, 0.6856674927873443, 0.7484678961515467, 0.7923371581346985, 0.10519973895126877, 0.13636345543025197, 0.09069979364325631, 0.11397311546275801, 0.14986323712414085, 0.10092383413138228, 0.12178337409989903, 0.13995936282413945, 0.11625146899098693, 0.24031191767279736, 0.2831384168733655, 0.2512288845549715, 0.21349208283147814, 0.2709742534134405, 0.253204641108837, 0.3065697933836059, 0.2569032502330555, 0.21508329618225674, 0.39468858929153916, 0.44493785886825876, 0.3412214442304601, 0.4022518625501722, 0.41978764058825146, 0.34803590937855267, 0.26225525808833394, 0.3355335156396261, 0.5077708211963312, 0.3112174627536882, 0.27900801700448374, 0.21404165006284892, 0.27762550591535406, 0.28627741444079047, 0.2788592224413342, 0.2328027262841742, 0.34512107931937674, 0.2545199493596185, 0.22867202164916411, 0.2536000096249822, 0.247559824187208, 0.23364220594619622, 0.21887149137225992, 0.25138452113105114, 0.22421342801936184, 0.22082035780942944, 0.26193760881573214, 0.6917708034846162, 0.19789960153376596, 0.19597016243354393, 0.1824361653717258, 0.19096904756917732, 0.19631191947214144, 0.2174981643883065, 0.19520924804057704, 0.19598404262508584, 0.18396969015625342, 0.18612147229137166, 0.18517537599147238, 0.8856055410695953, 0.1670557324344476, 0.8368596087322189, 0.8436385097376322, 0.8912841263690393, 0.8947753156261895, 0.8588835393419383, 0.851533553040317, 0.20966216501723933, 0.15504869507750096, 0.8433294130433883, 0.8436479962982408, 0.8482683162296778, 0.8536043853808677, 0.8761218173780815, 0.18914312298110825, 0.18325469051801324, 0.1936603612190574, 0.19372859952831, 0.20479347063556275, 0.19053844456159152, 0.1943455261954916, 0.18417599204962354, 0.18891691406148725, 0.09964227729862762, 0.09408133954616915, 0.0979702773558867, 0.08852594779641498, 0.09971456269814027, 0.11477467723659951, 0.08067348385687656, 0.10256296180541413, 0.13155598340959773]}, "mutation_prompt": null}
{"id": "60104256-292e-466c-bfe4-f65b04234b7b", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 8 * dim  # Changed population size for faster adaptation\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Adjusted inertia weight for varied exploration\n        self.c1 = 2.0  # Increased cognitive coefficient for enhanced individual focus\n        self.c2 = 1.3  # Decreased social coefficient to balance exploration\n        self.F = 0.85  # Adjusted mutation factor for a balanced search\n        self.CR = 0.9  # Further increased crossover rate to improve exploitation\n        self.adapt_factor = 0.98  # Altered adaptation strategy for fine-tuning dynamics\n        self.diversity_prob = 0.25  # Modified probability to maintain diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.pop_size, self.dim))  # Tighter initial velocity bounds\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.2, 1.2)  # Fine-tuned velocity clipping\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.4, 0.4, self.dim)  # Adjusted perturbation range\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A novel adaptive hybrid optimizer combining differential evolution and particle swarm optimization with probabilistic line refinement for improved convergence and robustness.", "configspace": "", "generation": 63, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.8422026875756686, 0.8316019688777077, 0.8519869328290357, 0.8297406844583839, 0.8252630810752194, 0.8277146988170878, 0.8068246858743604, 0.8561060802327902, 0.8368040280874159, 0.5717081710158031, 0.6229294567072469, 0.6577352366361608, 0.6097452113019179, 0.6248463092449099, 0.6480892213630982, 0.5853863526991877, 0.0512914350509458, 0.6345276944127677, 0.12661715743764002, 0.13553147013685352, 0.1165180416573206, 0.15148546967390686, 0.11833273301113134, 0.11262716667065764, 0.09118768173218983, 0.14706882869418092, 0.12165743506468629, 0.12200259360489396, 0.13034521545583178, 0.10944944258130584, 0.10633023239117789, 0.09527081094569545, 0.11958436269742212, 0.10133130517975841, 0.10989989219452312, 0.10750303865126443, 0.9584574983645874, 0.9456154497882113, 0.9248413138037459, 0.9394551060087084, 0.9178440572107031, 0.9247673511357778, 0.9144207782702397, 0.9195730061057308, 0.9376478922359291, 0.6852319709074105, 0.6780533300046745, 0.7108562413265345, 0.6930832315747306, 0.6473842756151248, 0.6668633835109659, 0.64220068456561, 0.6802151366784446, 0.698301550023128, 0.8284517086601723, 0.8319853512761421, 0.848700148364309, 0.19309996213284675, 0.8640311987671301, 0.8237765327623953, 0.7548692240966136, 0.7386572483314423, 0.8061550552153522, 0.6932523924834011, 0.6326694635926952, 0.5702079409903438, 0.504380399590584, 0.12794219324437095, 0.6326230014369127, 0.6645992326448668, 0.6458071418537177, 0.6824412135078085, 0.6043996176797476, 0.5329321711330159, 0.5621157612975026, 0.5799416763180532, 0.6787042232568141, 0.6327755902918872, 0.6245389618384289, 0.594169038943976, 0.6159025368644813, 0.2142937207523753, 0.5471077190497382, 0.34075658145661114, 0.06300005442848433, 0.32213183089088593, 0.2642637831740825, 0.5790571789927872, 0.2219122676957993, 0.30282947269926586, 0.27733961317035494, 0.3025133376612158, 0.40151213893255033, 0.22581234342655665, 0.12018211681647095, 0.16096111360077414, 0.19341753830233344, 0.4028576817096069, 0.4815084195410494, 0.0971570659457186, 0.11809561294884408, 0.14606350116883315, 0.302776137134796, 0.462988492103911, 0.34443607346144123, 0.12731332407030782, 0.1692466283912818, 0.21420574580174156, 0.25821731821921967, 0.37170899358653164, 0.3209911039463592, 0.20206573914765158, 0.15242447640139722, 0.3654460569911646, 0.0796097810397487, 0.10677503213591588, 0.3671365836218843, 0.7289913375444261, 0.7021916146005962, 0.7667444024290355, 0.6654456240892526, 0.7677149592326706, 0.774739243646891, 0.6856674927873443, 0.7484678961515467, 0.7923371581346985, 0.10519973895126877, 0.13636345543025197, 0.09069979364325631, 0.11397311546275801, 0.14986323712414085, 0.10092383413138228, 0.12178337409989903, 0.13995936282413945, 0.11625146899098693, 0.24031191767279736, 0.2831384168733655, 0.2512288845549715, 0.21349208283147814, 0.2709742534134405, 0.253204641108837, 0.3065697933836059, 0.2569032502330555, 0.21508329618225674, 0.39468858929153916, 0.44493785886825876, 0.3412214442304601, 0.4022518625501722, 0.41978764058825146, 0.34803590937855267, 0.26225525808833394, 0.3355335156396261, 0.5077708211963312, 0.3112174627536882, 0.27900801700448374, 0.21404165006284892, 0.27762550591535406, 0.28627741444079047, 0.2788592224413342, 0.2328027262841742, 0.34512107931937674, 0.2545199493596185, 0.22867202164916411, 0.2536000096249822, 0.247559824187208, 0.23364220594619622, 0.21887149137225992, 0.25138452113105114, 0.22421342801936184, 0.22082035780942944, 0.26193760881573214, 0.6917708034846162, 0.19789960153376596, 0.19597016243354393, 0.1824361653717258, 0.19096904756917732, 0.19631191947214144, 0.2174981643883065, 0.19520924804057704, 0.19598404262508584, 0.18396969015625342, 0.18612147229137166, 0.18517537599147238, 0.8856055410695953, 0.1670557324344476, 0.8368596087322189, 0.8436385097376322, 0.8912841263690393, 0.8947753156261895, 0.8588835393419383, 0.851533553040317, 0.20966216501723933, 0.15504869507750096, 0.8433294130433883, 0.8436479962982408, 0.8482683162296778, 0.8536043853808677, 0.8761218173780815, 0.18914312298110825, 0.18325469051801324, 0.1936603612190574, 0.19372859952831, 0.20479347063556275, 0.19053844456159152, 0.1943455261954916, 0.18417599204962354, 0.18891691406148725, 0.09964227729862762, 0.09408133954616915, 0.0979702773558867, 0.08852594779641498, 0.09971456269814027, 0.11477467723659951, 0.08067348385687656, 0.10256296180541413, 0.13155598340959773]}, "mutation_prompt": null}
{"id": "8acadfe8-b3e8-48cc-b8a6-5eaddfeab2a4", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 8 * dim\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.5  # Adjusted inertia weight for more exploration\n        self.c1 = 1.9  # Tweaked cognitive coefficient for balanced personal exploration\n        self.c2 = 1.5  # Slightly increased social coefficient for better convergence\n        self.F = 0.9  # Enhanced mutation factor for diverse search\n        self.CR = 0.85  # Moderated crossover rate for sustained diversity\n        self.adapt_factor = 0.96  # Refined adaptation strategy for smoother dynamics\n        self.diversity_prob = 0.3  # Enhanced probability to maintain diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.2, 0.2, (self.pop_size, self.dim))  # Narrower initial velocity bounds\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.0, 1.0)  # Adjusted velocity clipping\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.3, 0.3, self.dim)  # Adjusted perturbation range\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "EnhancedAdaptiveDEPSO", "description": "Enhanced Adaptive DEPSO integrating stochastic learning and adaptive control for robust global exploration and exploitation.", "configspace": "", "generation": 65, "fitness": 0.40100036255418875, "feedback": "The algorithm EnhancedAdaptiveDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.28.", "error": "", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.8654405111132789, 0.8700816382784097, 0.8853340616039271, 0.8654972019284377, 0.8682285607435225, 0.8669828421206798, 0.8563314145676941, 0.8725925085463221, 0.8655395145432946, 0.6788418276511595, 0.6953840623431395, 0.6716637313604972, 0.6914857776407823, 0.6844091875449126, 0.703964192312615, 0.688121799349089, 0.6934630278973399, 0.6462295273372619, 0.13961223310535475, 0.18208805601429878, 0.14329299745168322, 0.14489185996077192, 0.11440709432330043, 0.15433714678296695, 0.0947660122142322, 0.1282826654796243, 0.11303133621164085, 0.11530690084933193, 0.08964010713544668, 0.13032197573219728, 0.15182379074115793, 0.10760167717297986, 0.0877625058618825, 0.11281780139770381, 0.07537179599290522, 0.09422774641431331, 0.9387582842066055, 0.9189416552949633, 0.8958989972635917, 0.9468403337787952, 0.9067644277409337, 0.9029842743418028, 0.942486869013275, 0.906376623515002, 0.9417315960547905, 0.5545185044174417, 0.7433603565368161, 0.6730987467113018, 0.5898741290131765, 0.6742764274543724, 0.7073915050773263, 0.6364645912706407, 0.7086201724011887, 0.7241016989832356, 0.22788928071497372, 0.13182129114135355, 0.2264489155201903, 0.19271613243237784, 0.5837101089271282, 0.20710211231932318, 0.8183630179818019, 0.2261059565720488, 0.8807129960362698, 0.6051728002088337, 0.7488202712875965, 0.6524929220919711, 0.7264413843539879, 0.1301817245320177, 0.5985848388156799, 0.7059448215676826, 0.12834374485686273, 0.5884848590505023, 0.6894082513546922, 0.6849511524952767, 0.6564388272005404, 0.6068415180143591, 0.5473409759908736, 0.6001797451951829, 0.6697491664753719, 0.6389408452316045, 0.7104328742448838, 0.1145004023784364, 0.28016655152788117, 0.17096349466461802, 0.05509301724828786, 0.2588965300189542, 0.12145547018714842, 0.23758582596059952, 0.2046171826789822, 0.31769256426958925, 0.2358334080064134, 0.30265043875390907, 0.21404863855974565, 0.11561883565260855, 0.18568386506233048, 0.17758686557057168, 0.30685131740679517, 0.3411312962969144, 0.24302485615313218, 0.2490021907282669, 0.3108069070329027, 0.18692055527679352, 0.1653270593964804, 0.20445250288465266, 0.49757207345104226, 0.2674949023144514, 0.29268284166944936, 0.09162395506965482, 0.187737409039336, 0.18016041387113801, 0.2193283538652242, 0.24371793195509484, 0.4829564348199783, 0.32837217718401657, 0.30108622741102475, 0.35832089434012915, 0.3715099771065812, 0.7036195353363189, 0.7149002034502006, 0.6436371307979789, 0.7724835415737041, 0.6909509455898739, 0.8082800985071934, 0.7679679473262432, 0.655938089520598, 0.788416691712879, 0.11475692794285619, 0.11681954463752975, 0.10907237153672433, 0.13871163261450437, 0.12325221558272714, 0.10436800674281443, 0.16856177100041458, 0.08133988564709904, 0.15345743371051945, 0.2418587788037655, 0.19548581044084945, 0.24488423478398247, 0.3172772239706453, 0.19041469870154082, 0.22673731862334223, 0.35938665618319177, 0.18793906943891892, 0.19412799194618435, 0.36303128034850995, 0.4131425757509527, 0.2170057790826565, 0.35091312818118214, 0.3083650562110726, 0.34521346462420766, 0.4428724291246139, 0.49554939973085244, 0.3937932896620786, 0.3597853365262461, 0.335763442934087, 0.23214891014626626, 0.2715530477396142, 0.23163631508590643, 0.3884206745886958, 0.19365860533369106, 0.267041098859909, 0.23558669383925168, 0.2318381069077866, 0.2724373848371975, 0.2342496296915617, 0.24045259457181622, 0.26071517260642707, 0.23188422326424485, 0.24618317816546353, 0.21619895838501224, 0.22726933243507497, 0.19037107778871354, 0.19422759292208225, 0.19693008224517006, 0.19086827877352908, 0.22197697565239172, 0.1978785101176591, 0.1780906555620948, 0.18921895799715083, 0.18388438579396127, 0.8880080979583252, 0.8921175189070885, 0.18495381777117514, 0.9141960131343226, 0.20043567808917728, 0.18169911812750594, 0.8953050688115707, 0.8795209751822586, 0.9107263832585908, 0.8678111045584782, 0.15638831036354406, 0.7978257131445604, 0.1555801333283403, 0.16646434855374992, 0.1530790654658858, 0.8524391812439598, 0.8634119587418145, 0.8883318617434919, 0.1818587048607857, 0.19641958251572011, 0.1943755965699666, 0.21857625045993367, 0.1899267837791584, 0.20386867630177152, 0.20142658126617663, 0.1999613535770678, 0.22376219776175188, 0.10525742196859245, 0.10478724038029397, 0.12374847964715519, 0.09986573953006483, 0.09602945194851786, 0.10054356821929233, 0.11867704149591995, 0.08727585960201034, 0.08886386660109369]}, "mutation_prompt": null}
{"id": "715bb787-6fae-454c-bd20-9c9f325a2955", "solution": "import numpy as np\n\nclass EvolvedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Increased population size for richer diversity\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.5  # Refined inertia weight for balanced exploration-exploitation\n        self.c1 = 1.5  # Moderated cognitive coefficient for better individual performance\n        self.c2 = 1.7  # Slightly increased social coefficient to enhance collective behavior\n        self.F = 0.9  # Higher mutation factor to encourage exploration\n        self.CR = 0.85  # Reduced crossover rate to foster thorough local search\n        self.adapt_factor = 0.99  # Subtle adaptation to maintain dynamic balance\n        self.diversity_prob = 0.3  # Increased probability to ensure diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))  # Expanded initial velocity bounds\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n\n                velocities[i] = np.clip(velocities[i], -1.5, 1.5)  # Relaxed velocity clipping for broader search space\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.5, 0.5, self.dim)  # Increased perturbation range\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "EvolvedAdaptiveDEPSOHybridOptimizer", "description": "An evolved adaptive hybrid optimizer based on differential evolution and particle swarm optimization with enhanced probabilistic refinement for superior convergence and stability.", "configspace": "", "generation": 66, "fitness": 0.3900836679557618, "feedback": "The algorithm EvolvedAdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.26.", "error": "", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.8270472068478788, 0.7864939825215531, 0.7869949365338308, 0.8170189965865504, 0.8110635468144799, 0.7863169946221117, 0.80423234851821, 0.7991289765325071, 0.7812283250979604, 0.5207393629907571, 0.572291311652652, 0.5032768966120176, 0.5970846195910235, 0.5319092173126299, 0.05703767914497837, 0.5300858072525811, 0.5262592636263246, 0.5477871946057202, 0.10974183279291916, 0.11323560935773769, 0.15123221896789818, 0.09503401407004819, 0.4343170541006047, 0.13292266796437202, 0.09534458321596684, 0.5541728827337489, 0.1320761061221758, 0.10452691655193791, 0.11086588949102139, 0.10913712542633425, 0.13155783957875866, 0.0811910315203268, 0.10503170133854223, 0.10231022564504422, 0.08903589049696803, 0.09739881370759063, 0.9589814599976542, 0.9105485754323075, 0.930136303886542, 0.9502922545025121, 0.924039898121667, 0.9133219186839998, 0.8989322201403478, 0.9276197054940601, 0.9528258290327479, 0.6271021432888055, 0.640720557033698, 0.5900657030849956, 0.5943597023194814, 0.6666872061632807, 0.615586209934313, 0.5718439541260644, 0.6253127347512966, 0.6044670545517161, 0.2215946202962904, 0.8528456940458647, 0.7561864776067824, 0.27356449816600104, 0.3657072292272685, 0.7590155674050875, 0.8607034427698443, 0.7902602701640047, 0.7912090094577797, 0.6213425080627157, 0.13267257744362437, 0.129284708518846, 0.5586163088936547, 0.5695986867562259, 0.5213671228376663, 0.5866382813187567, 0.48551519487908634, 0.5767884413818819, 0.5885410394437052, 0.5656968312695331, 0.5054812292684953, 0.630110817014814, 0.5617277525549804, 0.5289601974822504, 0.5680859898475097, 0.5073969450545983, 0.5248667667636403, 0.03740190754510053, 0.3387698241212773, 0.2824204105285726, 0.4713364795800802, 0.4396299171021819, 0.35349411015761945, 0.5209183358924139, 0.3422762549128645, 0.2768604114735467, 0.5213992066551489, 0.2882198327362486, 0.20883822629552562, 0.302402945824488, 0.3755108355640744, 0.10415672833083245, 0.44474957327254905, 0.32528640166217804, 0.34623760754216515, 0.16311249815845918, 0.20581554966198523, 0.17530251517628825, 0.13597511097503867, 0.14111983926771376, 0.0653898628940307, 0.08853070508166128, 0.23467952150889537, 0.0749097457125657, 0.18976202163936418, 0.30214161863213773, 0.10489604972186206, 0.31402986328284677, 0.3574193879158668, 0.3159340184058742, 0.04674851173170158, 0.17744159480163357, 0.44243478468255026, 0.7235699700550027, 0.7115118778695625, 0.682187772101708, 0.7074174888256626, 0.7169164488117414, 0.7198421397546202, 0.7025934545759525, 0.7110571079410613, 0.6883833198329338, 0.0880403671043043, 0.0861103759439984, 0.11464818588011583, 0.13244994023522705, 0.09258055609742244, 0.11973852996420409, 0.10985444372468833, 0.1314888926391533, 0.1019169161291289, 0.2487948583734525, 0.3367069935744731, 0.17402022800355366, 0.5979107498351321, 0.2535924096693841, 0.25181052786618496, 0.3197739041753298, 0.26772512338534293, 0.27955901037976905, 0.3403060907184693, 0.40990710931545193, 0.27051425226440085, 0.38434484509568034, 0.3483995030450152, 0.42924546224370974, 0.3615457096861264, 0.4197925801731338, 0.3149634630555628, 0.2592301536370073, 0.3985831245362107, 0.35515206748261896, 0.3465012299323528, 0.18901521561300128, 0.24881144322543813, 0.18341207441080098, 0.23701045478817062, 0.21943682106499285, 0.25437983064224157, 0.26483594267418653, 0.2376154172530972, 0.22535959353112933, 0.2547044826722179, 0.23105660005238127, 0.21789397577445668, 0.28132289460387483, 0.2527225187754054, 0.18275060553658673, 0.19659978039858694, 0.20439279006775046, 0.18761514975817906, 0.22591919502592916, 0.24217886877976225, 0.2049924990740054, 0.1881972773889662, 0.6647683817333405, 0.8742461958445211, 0.18642170544954884, 0.14650609208280763, 0.8765013814391163, 0.19667127963874242, 0.16656389418245876, 0.8605518327642958, 0.7929922226686648, 0.8717042077807428, 0.8347321617250023, 0.21088385142674115, 0.8296078146168936, 0.2088414203783281, 0.20964148858923137, 0.8173620502988201, 0.1664886377186915, 0.16664937292773574, 0.20874680131194423, 0.17939118082006167, 0.20155393996880566, 0.21020062527820593, 0.18956518943735, 0.20494927160717957, 0.19451420653200924, 0.18548288422501213, 0.18376320809687097, 0.2437699896406179, 0.09670770388446981, 0.08860174952233701, 0.11353293969664047, 0.1166971319113056, 0.09614150982017278, 0.11072537695634532, 0.13066803376112457, 0.10186872718587803, 0.09384428560702474]}, "mutation_prompt": null}
{"id": "b69f7844-415d-4ee1-98dd-5368017d8289", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Increased population size for diversity\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.7  # Increased inertia weight for exploration\n        self.c1 = 1.8  # Slightly decreased cognitive coefficient\n        self.c2 = 1.5  # Increased social coefficient for stronger collective influence\n        self.F = 0.9  # Higher mutation factor for exploration\n        self.CR = 0.85  # Reduced crossover rate to introduce randomness\n        self.adapt_factor = 0.95  # Slower adaptation for stability\n        self.diversity_prob = 0.3  # Increased probability to encourage diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))  # Broader initial velocity range\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.5, 1.5)  # Adjusted velocity clipping to accommodate broader exploration\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.5, 0.5, self.dim)  # Increased perturbation range for broader search\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A refined hybrid optimizer leveraging adaptive differential evolution and particle swarm dynamics with diversified perturbation for enhanced convergence.", "configspace": "", "generation": 67, "fitness": 0.39531318715063785, "feedback": "The algorithm RefinedAdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.27.", "error": "", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.8390953892486464, 0.8245416589425913, 0.8208496163162203, 0.8169590629414033, 0.827736352339867, 0.8164789217683773, 0.83625458184033, 0.815737031774429, 0.8262397128575488, 0.6450105369521947, 0.6207426993341705, 0.6287001876801154, 0.6003822387438715, 0.6260464596668626, 0.6307257981028822, 0.5869922381212234, 0.6093282763243004, 0.599528451587118, 0.15402639901924908, 0.1377970016797384, 0.13054097838542078, 0.15497615518986185, 0.15095282594564674, 0.1544047132898504, 0.11359602437254412, 0.12168653926192396, 0.15159530090355344, 0.11439035997756941, 0.0998678948405135, 0.11997471098687185, 0.13511367396789997, 0.12950689136110727, 0.11807988041604967, 0.13039137522625244, 0.11196059929270363, 0.08686069594314738, 0.959182596923995, 0.9049053081318055, 0.9294392074442673, 0.9419181555179839, 0.9101178138996576, 0.9169467563755195, 0.8888748198613479, 0.9359074640802285, 0.9524971664475285, 0.6608249760280993, 0.650258085836801, 0.6647726644208756, 0.657164913814225, 0.6670781898772055, 0.637556640629968, 0.6136986700172482, 0.6180377069885709, 0.6558844543882651, 0.8599972617823719, 0.5117397048444856, 0.8064990158983482, 0.27659864530177236, 0.8096335366842533, 0.825012072751, 0.8236610727218825, 0.7851641262907169, 0.38761816306604835, 0.12906151229772544, 0.12835360861639944, 0.5717745198149418, 0.5326822746043662, 0.6014684752479486, 0.5682679535876833, 0.5594205787992923, 0.5463429884113125, 0.504773156487935, 0.6495603690901119, 0.6673019256909635, 0.6197758946012344, 0.6746041396720783, 0.5995069826111217, 0.569537421623082, 0.5560495271680843, 0.5817199465465512, 0.565027149660918, 0.060384561136419324, 0.11281571964460813, 0.09980291806121788, 0.032032777672861945, 0.21693907203893537, 0.06487797083682667, 0.3820462692305987, 0.2501130665080227, 0.23382617986148524, 0.27213049542246026, 0.2906062785134902, 0.1983556547579467, 0.35252719277481126, 0.18491392585308186, 0.14154723056149832, 0.25500804030272073, 0.38092621604686117, 0.21657106899805756, 0.4153284911550723, 0.044677807960255445, 0.27060065063977823, 0.23364572026475727, 0.23126218225216433, 0.2047151488221295, 0.08972995778133741, 0.184031558952787, 0.11785629685003973, 0.3754503642575514, 0.22202398302148507, 0.15227564546252015, 0.3393788317184404, 0.3776424551022214, 0.4223937781974201, 0.3956844837889072, 0.19612119766137648, 0.08638464681860025, 0.6484063235426443, 0.729919864870102, 0.7035007337840806, 0.6860061963521578, 0.5845876687766491, 0.7544903739820085, 0.7615511463153581, 0.6693301295525658, 0.65306187582158, 0.08907805896584231, 0.1151825394732452, 0.14102820132745397, 0.1532661731014321, 0.1633981798490387, 0.14930389368222952, 0.1535606210700875, 0.11871827662851431, 0.08618047178395916, 0.1857666916818015, 0.3614866896162994, 0.2560813949533932, 0.17823761572721086, 0.1853357564821566, 0.38251973682872376, 0.4008993479664157, 0.21896247866743268, 0.23932138360107824, 0.3896829117398527, 0.44877116114605753, 0.3649981733590022, 0.35195196744062796, 0.3138311198786653, 0.40013327752649597, 0.2751650571575034, 0.29683302018330404, 0.373607640395737, 0.2695961250696569, 0.25184321720797054, 0.23299105200865555, 0.36977359642821495, 0.22487959437671934, 0.24592375087392537, 0.3040056090493114, 0.28150826486315095, 0.2581136459552249, 0.23336979595818852, 0.2355113899274872, 0.23654328719978224, 0.21583576245097025, 0.24088396993091532, 0.24995439237043537, 0.24052274830366838, 0.2460403531111528, 0.24921984680422937, 0.1886352816479454, 0.202503417079682, 0.1987379905436497, 0.19881069209797764, 0.1953780573709345, 0.1806803013375582, 0.19245434407421913, 0.2180567164899323, 0.20685754858223315, 0.8880291679717007, 0.18589841298561227, 0.1463879649606713, 0.8850598352091301, 0.19840296842451022, 0.1654913554049594, 0.7922892239345372, 0.8638247904885786, 0.8751549169283828, 0.8647212291246976, 0.20975113848152438, 0.8102942833497799, 0.20949494860329754, 0.8242718220916073, 0.8642455459108862, 0.1676055623428463, 0.8294730711567769, 0.20931900508123613, 0.21387770066032108, 0.23895736615410068, 0.20673359081108833, 0.20015997984175626, 0.20562038727548093, 0.20165547274146478, 0.2308507121979516, 0.21265592937133915, 0.19656830287968274, 0.0914110450220571, 0.0985871405143669, 0.10234365122889322, 0.0861938243640219, 0.10868196441618727, 0.09503241888415337, 0.08716379906510496, 0.09913816444961687, 0.10159813977793541]}, "mutation_prompt": null}
{"id": "ef5aa245-f258-4687-bd25-ed80c6f6bec0", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 8 * dim  # Changed population size for faster adaptation\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Adjusted inertia weight for varied exploration\n        self.c1 = 2.0  # Increased cognitive coefficient for enhanced individual focus\n        self.c2 = 1.3  # Decreased social coefficient to balance exploration\n        self.F = 0.85  # Adjusted mutation factor for a balanced search\n        self.CR = 0.9  # Further increased crossover rate to improve exploitation\n        self.adapt_factor = 0.98  # Altered adaptation strategy for fine-tuning dynamics\n        self.diversity_prob = 0.25  # Modified probability to maintain diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.pop_size, self.dim))  # Tighter initial velocity bounds\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.2, 1.2)  # Fine-tuned velocity clipping\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.4, 0.4, self.dim)  # Adjusted perturbation range\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A novel adaptive hybrid optimizer combining differential evolution and particle swarm optimization with probabilistic line refinement for improved convergence and robustness.", "configspace": "", "generation": 63, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.8422026875756686, 0.8316019688777077, 0.8519869328290357, 0.8297406844583839, 0.8252630810752194, 0.8277146988170878, 0.8068246858743604, 0.8561060802327902, 0.8368040280874159, 0.5717081710158031, 0.6229294567072469, 0.6577352366361608, 0.6097452113019179, 0.6248463092449099, 0.6480892213630982, 0.5853863526991877, 0.0512914350509458, 0.6345276944127677, 0.12661715743764002, 0.13553147013685352, 0.1165180416573206, 0.15148546967390686, 0.11833273301113134, 0.11262716667065764, 0.09118768173218983, 0.14706882869418092, 0.12165743506468629, 0.12200259360489396, 0.13034521545583178, 0.10944944258130584, 0.10633023239117789, 0.09527081094569545, 0.11958436269742212, 0.10133130517975841, 0.10989989219452312, 0.10750303865126443, 0.9584574983645874, 0.9456154497882113, 0.9248413138037459, 0.9394551060087084, 0.9178440572107031, 0.9247673511357778, 0.9144207782702397, 0.9195730061057308, 0.9376478922359291, 0.6852319709074105, 0.6780533300046745, 0.7108562413265345, 0.6930832315747306, 0.6473842756151248, 0.6668633835109659, 0.64220068456561, 0.6802151366784446, 0.698301550023128, 0.8284517086601723, 0.8319853512761421, 0.848700148364309, 0.19309996213284675, 0.8640311987671301, 0.8237765327623953, 0.7548692240966136, 0.7386572483314423, 0.8061550552153522, 0.6932523924834011, 0.6326694635926952, 0.5702079409903438, 0.504380399590584, 0.12794219324437095, 0.6326230014369127, 0.6645992326448668, 0.6458071418537177, 0.6824412135078085, 0.6043996176797476, 0.5329321711330159, 0.5621157612975026, 0.5799416763180532, 0.6787042232568141, 0.6327755902918872, 0.6245389618384289, 0.594169038943976, 0.6159025368644813, 0.2142937207523753, 0.5471077190497382, 0.34075658145661114, 0.06300005442848433, 0.32213183089088593, 0.2642637831740825, 0.5790571789927872, 0.2219122676957993, 0.30282947269926586, 0.27733961317035494, 0.3025133376612158, 0.40151213893255033, 0.22581234342655665, 0.12018211681647095, 0.16096111360077414, 0.19341753830233344, 0.4028576817096069, 0.4815084195410494, 0.0971570659457186, 0.11809561294884408, 0.14606350116883315, 0.302776137134796, 0.462988492103911, 0.34443607346144123, 0.12731332407030782, 0.1692466283912818, 0.21420574580174156, 0.25821731821921967, 0.37170899358653164, 0.3209911039463592, 0.20206573914765158, 0.15242447640139722, 0.3654460569911646, 0.0796097810397487, 0.10677503213591588, 0.3671365836218843, 0.7289913375444261, 0.7021916146005962, 0.7667444024290355, 0.6654456240892526, 0.7677149592326706, 0.774739243646891, 0.6856674927873443, 0.7484678961515467, 0.7923371581346985, 0.10519973895126877, 0.13636345543025197, 0.09069979364325631, 0.11397311546275801, 0.14986323712414085, 0.10092383413138228, 0.12178337409989903, 0.13995936282413945, 0.11625146899098693, 0.24031191767279736, 0.2831384168733655, 0.2512288845549715, 0.21349208283147814, 0.2709742534134405, 0.253204641108837, 0.3065697933836059, 0.2569032502330555, 0.21508329618225674, 0.39468858929153916, 0.44493785886825876, 0.3412214442304601, 0.4022518625501722, 0.41978764058825146, 0.34803590937855267, 0.26225525808833394, 0.3355335156396261, 0.5077708211963312, 0.3112174627536882, 0.27900801700448374, 0.21404165006284892, 0.27762550591535406, 0.28627741444079047, 0.2788592224413342, 0.2328027262841742, 0.34512107931937674, 0.2545199493596185, 0.22867202164916411, 0.2536000096249822, 0.247559824187208, 0.23364220594619622, 0.21887149137225992, 0.25138452113105114, 0.22421342801936184, 0.22082035780942944, 0.26193760881573214, 0.6917708034846162, 0.19789960153376596, 0.19597016243354393, 0.1824361653717258, 0.19096904756917732, 0.19631191947214144, 0.2174981643883065, 0.19520924804057704, 0.19598404262508584, 0.18396969015625342, 0.18612147229137166, 0.18517537599147238, 0.8856055410695953, 0.1670557324344476, 0.8368596087322189, 0.8436385097376322, 0.8912841263690393, 0.8947753156261895, 0.8588835393419383, 0.851533553040317, 0.20966216501723933, 0.15504869507750096, 0.8433294130433883, 0.8436479962982408, 0.8482683162296778, 0.8536043853808677, 0.8761218173780815, 0.18914312298110825, 0.18325469051801324, 0.1936603612190574, 0.19372859952831, 0.20479347063556275, 0.19053844456159152, 0.1943455261954916, 0.18417599204962354, 0.18891691406148725, 0.09964227729862762, 0.09408133954616915, 0.0979702773558867, 0.08852594779641498, 0.09971456269814027, 0.11477467723659951, 0.08067348385687656, 0.10256296180541413, 0.13155598340959773]}, "mutation_prompt": null}
{"id": "11431f73-ffb7-47ab-9c1f-3e8f35c43b7d", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Adjust population size for better diversity\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.5  # Slightly decreased inertia weight for better convergence\n        self.c1 = 1.9  # Slightly reduced cognitive coefficient for balanced focus\n        self.c2 = 1.5  # Increased social coefficient to enhance global convergence\n        self.F = 0.8  # Slightly reduced mutation factor for better local search\n        self.CR = 0.85  # Reduced crossover rate for enhanced exploration\n        self.adapt_factor = 0.95  # Adjusted adaptation strategy for gradual change\n        self.diversity_prob = 0.3  # Increased probability to maintain diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.4, 0.4, (self.pop_size, self.dim))  # Wider initial velocity bounds\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.5, 1.5)  # Extended velocity clipping\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.3, 0.3, self.dim)  # Reduced perturbation range\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "EnhancedAdaptiveDEPSOHybridOptimizer", "description": "EnhancedAdaptiveDEPSOHybridOptimizer: Improved adaptive hybrid optimizer that leverages differential evolution and particle swarm optimization with dynamic adaptation and perturbation strategies for superior exploration-exploitation balance.", "configspace": "", "generation": 69, "fitness": 0.39660303667088975, "feedback": "The algorithm EnhancedAdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.28.", "error": "", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.8634262297478699, 0.8541317274303107, 0.8380729873943444, 0.8663075470479563, 0.8566281983422779, 0.8355988794352063, 0.8573061953804324, 0.8482981211320867, 0.827744837725271, 0.6690448206312223, 0.619678538628182, 0.6502527535702729, 0.6760565952200479, 0.6736842707840485, 0.6685589768495783, 0.5781753159481771, 0.6027578996774712, 0.6423119843938379, 0.11027874103128121, 0.1503944455846684, 0.12254052498705426, 0.11540653132032419, 0.17109399441494622, 0.15077456383542498, 0.11305162572051286, 0.17116367239916142, 0.12205622364100577, 0.09374477708168849, 0.11447331535708183, 0.11227251448924258, 0.15509498263303245, 0.09166588859760794, 0.1314230267983315, 0.14217251518125196, 0.11843837337606022, 0.09678456843008221, 0.9574064887264482, 0.9162502173863882, 0.9311354908415925, 0.934249412201916, 0.9076555473378384, 0.9035284291978365, 0.8868928933739142, 0.925581731600032, 0.952742853170394, 0.645094269635015, 0.6851118829590697, 0.7121175444152645, 0.6691439119581134, 0.6397928922503198, 0.6354907262087752, 0.6564930084502713, 0.6795024261186016, 0.649200771616885, 0.856796426951366, 0.7689533023609315, 0.8265597262373109, 0.21497439348756608, 0.36530470312362084, 0.21388162492409102, 0.23195756103581278, 0.7685014149394707, 0.36575375166701574, 0.7226215234194496, 0.6065258254724513, 0.6290626281592662, 0.12630716205810355, 0.6393885284841075, 0.12938572824130934, 0.7330872446705448, 0.5625106629943175, 0.5171541872345694, 0.5719422618096851, 0.6002276439628405, 0.13188246835969353, 0.5654934471991657, 0.5935542101453104, 0.5067313265652202, 0.7558702173377454, 0.591328144693642, 0.6360773661252392, 0.06759329178429618, 0.2502580339055043, 0.4819007216106447, 0.3207492988768941, 0.14190729819172798, 0.3358797287266051, 0.1946082860657823, 0.18865470182849964, 0.2511115912649846, 0.4026792025217313, 0.20633463600283808, 0.4522254299679964, 0.15427301342550803, 0.315820994452261, 0.16354673445921852, 0.1926394091399395, 0.39758200256468446, 0.2425233416516579, 0.18710142551897346, 0.23011797548957746, 0.293085871365236, 0.361192560754528, 0.3182343094546579, 0.12383113911511989, 0.11246531931968895, 0.17515100241963977, 0.19465812856163855, 0.247841261720801, 0.168244379641994, 0.16990507253003817, 0.2661524391346507, 0.3195961813897068, 0.21599810625474603, 0.30570460496368845, 0.07977779039419752, 0.2566050091938843, 0.7003119127283604, 0.7287699462801279, 0.6427999460696329, 0.6558492960654881, 0.7416114376281223, 0.673539374591589, 0.6900340005142473, 0.7712754894585199, 0.7022288856088204, 0.08601793546642511, 0.11080837901061291, 0.1166092342558086, 0.09612547682909645, 0.12623498723890803, 0.1381432146486966, 0.11322935807679568, 0.15896460549454094, 0.11106446150438531, 0.23505018455786097, 0.30501367967380644, 0.2431862607264299, 0.26800454742550484, 0.17464419985934598, 0.29726887717205286, 0.3333469966417324, 0.17813166590516216, 0.19628372362715574, 0.359726766195128, 0.3677634116391437, 0.3902145806904682, 0.3148052937709205, 0.41063179768459346, 0.33728821744044357, 0.2675798129739517, 0.3926691404229139, 0.42235639668884495, 0.23497058310170238, 0.19440927294151011, 0.23867230036203335, 0.27172191516760535, 0.21765822048604488, 0.2624037391334336, 0.22437174955547856, 0.2319100521728994, 0.21293002737736766, 0.21512821686470485, 0.2239253830185044, 0.2409216040309553, 0.24523437368256562, 0.2218609724215016, 0.23346754107426537, 0.23243922880091072, 0.25403589195059006, 0.24771904569240244, 0.19846156420432315, 0.220092859107186, 0.20170961153794253, 0.25142659415686097, 0.2076141134873335, 0.18674405093674262, 0.20808969410643385, 0.1773001830522395, 0.21382189920432126, 0.9191920988165159, 0.17732602689747168, 0.20583848193694543, 0.9026027335197794, 0.1996024910111398, 0.19629618341777777, 0.9042452674004323, 0.8997504387184665, 0.8755298612911452, 0.9020221382591553, 0.851524607767405, 0.8377470730646404, 0.20935028134130385, 0.8319432966351724, 0.16735765315153328, 0.20903980136119393, 0.8352383141106673, 0.8421356789451504, 0.20281162298237632, 0.19047640591061432, 0.18244950990916364, 0.18854662154574786, 0.17384552275801035, 0.21151889282109249, 0.23044280642928483, 0.18949516255863208, 0.2003100893784059, 0.14605832216051207, 0.09557602782779828, 0.12530406255884352, 0.09932895896612193, 0.12969082225271145, 0.10313502146123987, 0.09730489327992364, 0.1045356189205402, 0.08601851236236713]}, "mutation_prompt": null}
{"id": "193613ff-5b7a-44c6-9bc9-d44d10f8d0b9", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 8 * dim  # Changed population size for faster adaptation\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Adjusted inertia weight for varied exploration\n        self.c1 = 2.0  # Increased cognitive coefficient for enhanced individual focus\n        self.c2 = 1.3  # Decreased social coefficient to balance exploration\n        self.F = 0.85  # Adjusted mutation factor for a balanced search\n        self.CR = 0.9  # Further increased crossover rate to improve exploitation\n        self.adapt_factor = 0.98  # Altered adaptation strategy for fine-tuning dynamics\n        self.diversity_prob = 0.25  # Modified probability to maintain diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.pop_size, self.dim))  # Tighter initial velocity bounds\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.2, 1.2)  # Fine-tuned velocity clipping\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.4, 0.4, self.dim)  # Adjusted perturbation range\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A novel adaptive hybrid optimizer combining differential evolution and particle swarm optimization with probabilistic line refinement for improved convergence and robustness.", "configspace": "", "generation": 63, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.8422026875756686, 0.8316019688777077, 0.8519869328290357, 0.8297406844583839, 0.8252630810752194, 0.8277146988170878, 0.8068246858743604, 0.8561060802327902, 0.8368040280874159, 0.5717081710158031, 0.6229294567072469, 0.6577352366361608, 0.6097452113019179, 0.6248463092449099, 0.6480892213630982, 0.5853863526991877, 0.0512914350509458, 0.6345276944127677, 0.12661715743764002, 0.13553147013685352, 0.1165180416573206, 0.15148546967390686, 0.11833273301113134, 0.11262716667065764, 0.09118768173218983, 0.14706882869418092, 0.12165743506468629, 0.12200259360489396, 0.13034521545583178, 0.10944944258130584, 0.10633023239117789, 0.09527081094569545, 0.11958436269742212, 0.10133130517975841, 0.10989989219452312, 0.10750303865126443, 0.9584574983645874, 0.9456154497882113, 0.9248413138037459, 0.9394551060087084, 0.9178440572107031, 0.9247673511357778, 0.9144207782702397, 0.9195730061057308, 0.9376478922359291, 0.6852319709074105, 0.6780533300046745, 0.7108562413265345, 0.6930832315747306, 0.6473842756151248, 0.6668633835109659, 0.64220068456561, 0.6802151366784446, 0.698301550023128, 0.8284517086601723, 0.8319853512761421, 0.848700148364309, 0.19309996213284675, 0.8640311987671301, 0.8237765327623953, 0.7548692240966136, 0.7386572483314423, 0.8061550552153522, 0.6932523924834011, 0.6326694635926952, 0.5702079409903438, 0.504380399590584, 0.12794219324437095, 0.6326230014369127, 0.6645992326448668, 0.6458071418537177, 0.6824412135078085, 0.6043996176797476, 0.5329321711330159, 0.5621157612975026, 0.5799416763180532, 0.6787042232568141, 0.6327755902918872, 0.6245389618384289, 0.594169038943976, 0.6159025368644813, 0.2142937207523753, 0.5471077190497382, 0.34075658145661114, 0.06300005442848433, 0.32213183089088593, 0.2642637831740825, 0.5790571789927872, 0.2219122676957993, 0.30282947269926586, 0.27733961317035494, 0.3025133376612158, 0.40151213893255033, 0.22581234342655665, 0.12018211681647095, 0.16096111360077414, 0.19341753830233344, 0.4028576817096069, 0.4815084195410494, 0.0971570659457186, 0.11809561294884408, 0.14606350116883315, 0.302776137134796, 0.462988492103911, 0.34443607346144123, 0.12731332407030782, 0.1692466283912818, 0.21420574580174156, 0.25821731821921967, 0.37170899358653164, 0.3209911039463592, 0.20206573914765158, 0.15242447640139722, 0.3654460569911646, 0.0796097810397487, 0.10677503213591588, 0.3671365836218843, 0.7289913375444261, 0.7021916146005962, 0.7667444024290355, 0.6654456240892526, 0.7677149592326706, 0.774739243646891, 0.6856674927873443, 0.7484678961515467, 0.7923371581346985, 0.10519973895126877, 0.13636345543025197, 0.09069979364325631, 0.11397311546275801, 0.14986323712414085, 0.10092383413138228, 0.12178337409989903, 0.13995936282413945, 0.11625146899098693, 0.24031191767279736, 0.2831384168733655, 0.2512288845549715, 0.21349208283147814, 0.2709742534134405, 0.253204641108837, 0.3065697933836059, 0.2569032502330555, 0.21508329618225674, 0.39468858929153916, 0.44493785886825876, 0.3412214442304601, 0.4022518625501722, 0.41978764058825146, 0.34803590937855267, 0.26225525808833394, 0.3355335156396261, 0.5077708211963312, 0.3112174627536882, 0.27900801700448374, 0.21404165006284892, 0.27762550591535406, 0.28627741444079047, 0.2788592224413342, 0.2328027262841742, 0.34512107931937674, 0.2545199493596185, 0.22867202164916411, 0.2536000096249822, 0.247559824187208, 0.23364220594619622, 0.21887149137225992, 0.25138452113105114, 0.22421342801936184, 0.22082035780942944, 0.26193760881573214, 0.6917708034846162, 0.19789960153376596, 0.19597016243354393, 0.1824361653717258, 0.19096904756917732, 0.19631191947214144, 0.2174981643883065, 0.19520924804057704, 0.19598404262508584, 0.18396969015625342, 0.18612147229137166, 0.18517537599147238, 0.8856055410695953, 0.1670557324344476, 0.8368596087322189, 0.8436385097376322, 0.8912841263690393, 0.8947753156261895, 0.8588835393419383, 0.851533553040317, 0.20966216501723933, 0.15504869507750096, 0.8433294130433883, 0.8436479962982408, 0.8482683162296778, 0.8536043853808677, 0.8761218173780815, 0.18914312298110825, 0.18325469051801324, 0.1936603612190574, 0.19372859952831, 0.20479347063556275, 0.19053844456159152, 0.1943455261954916, 0.18417599204962354, 0.18891691406148725, 0.09964227729862762, 0.09408133954616915, 0.0979702773558867, 0.08852594779641498, 0.09971456269814027, 0.11477467723659951, 0.08067348385687656, 0.10256296180541413, 0.13155598340959773]}, "mutation_prompt": null}
{"id": "3e22bbf2-13a5-4043-b2f3-1d835e09e3ff", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 8 * dim  # Changed population size for faster adaptation\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Adjusted inertia weight for varied exploration\n        self.c1 = 2.0  # Increased cognitive coefficient for enhanced individual focus\n        self.c2 = 1.3  # Decreased social coefficient to balance exploration\n        self.F = 0.85  # Adjusted mutation factor for a balanced search\n        self.CR = 0.9  # Further increased crossover rate to improve exploitation\n        self.adapt_factor = 0.98  # Altered adaptation strategy for fine-tuning dynamics\n        self.diversity_prob = 0.25  # Modified probability to maintain diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.pop_size, self.dim))  # Tighter initial velocity bounds\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.2, 1.2)  # Fine-tuned velocity clipping\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.4, 0.4, self.dim)  # Adjusted perturbation range\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A novel adaptive hybrid optimizer combining differential evolution and particle swarm optimization with probabilistic line refinement for improved convergence and robustness.", "configspace": "", "generation": 63, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.8422026875756686, 0.8316019688777077, 0.8519869328290357, 0.8297406844583839, 0.8252630810752194, 0.8277146988170878, 0.8068246858743604, 0.8561060802327902, 0.8368040280874159, 0.5717081710158031, 0.6229294567072469, 0.6577352366361608, 0.6097452113019179, 0.6248463092449099, 0.6480892213630982, 0.5853863526991877, 0.0512914350509458, 0.6345276944127677, 0.12661715743764002, 0.13553147013685352, 0.1165180416573206, 0.15148546967390686, 0.11833273301113134, 0.11262716667065764, 0.09118768173218983, 0.14706882869418092, 0.12165743506468629, 0.12200259360489396, 0.13034521545583178, 0.10944944258130584, 0.10633023239117789, 0.09527081094569545, 0.11958436269742212, 0.10133130517975841, 0.10989989219452312, 0.10750303865126443, 0.9584574983645874, 0.9456154497882113, 0.9248413138037459, 0.9394551060087084, 0.9178440572107031, 0.9247673511357778, 0.9144207782702397, 0.9195730061057308, 0.9376478922359291, 0.6852319709074105, 0.6780533300046745, 0.7108562413265345, 0.6930832315747306, 0.6473842756151248, 0.6668633835109659, 0.64220068456561, 0.6802151366784446, 0.698301550023128, 0.8284517086601723, 0.8319853512761421, 0.848700148364309, 0.19309996213284675, 0.8640311987671301, 0.8237765327623953, 0.7548692240966136, 0.7386572483314423, 0.8061550552153522, 0.6932523924834011, 0.6326694635926952, 0.5702079409903438, 0.504380399590584, 0.12794219324437095, 0.6326230014369127, 0.6645992326448668, 0.6458071418537177, 0.6824412135078085, 0.6043996176797476, 0.5329321711330159, 0.5621157612975026, 0.5799416763180532, 0.6787042232568141, 0.6327755902918872, 0.6245389618384289, 0.594169038943976, 0.6159025368644813, 0.2142937207523753, 0.5471077190497382, 0.34075658145661114, 0.06300005442848433, 0.32213183089088593, 0.2642637831740825, 0.5790571789927872, 0.2219122676957993, 0.30282947269926586, 0.27733961317035494, 0.3025133376612158, 0.40151213893255033, 0.22581234342655665, 0.12018211681647095, 0.16096111360077414, 0.19341753830233344, 0.4028576817096069, 0.4815084195410494, 0.0971570659457186, 0.11809561294884408, 0.14606350116883315, 0.302776137134796, 0.462988492103911, 0.34443607346144123, 0.12731332407030782, 0.1692466283912818, 0.21420574580174156, 0.25821731821921967, 0.37170899358653164, 0.3209911039463592, 0.20206573914765158, 0.15242447640139722, 0.3654460569911646, 0.0796097810397487, 0.10677503213591588, 0.3671365836218843, 0.7289913375444261, 0.7021916146005962, 0.7667444024290355, 0.6654456240892526, 0.7677149592326706, 0.774739243646891, 0.6856674927873443, 0.7484678961515467, 0.7923371581346985, 0.10519973895126877, 0.13636345543025197, 0.09069979364325631, 0.11397311546275801, 0.14986323712414085, 0.10092383413138228, 0.12178337409989903, 0.13995936282413945, 0.11625146899098693, 0.24031191767279736, 0.2831384168733655, 0.2512288845549715, 0.21349208283147814, 0.2709742534134405, 0.253204641108837, 0.3065697933836059, 0.2569032502330555, 0.21508329618225674, 0.39468858929153916, 0.44493785886825876, 0.3412214442304601, 0.4022518625501722, 0.41978764058825146, 0.34803590937855267, 0.26225525808833394, 0.3355335156396261, 0.5077708211963312, 0.3112174627536882, 0.27900801700448374, 0.21404165006284892, 0.27762550591535406, 0.28627741444079047, 0.2788592224413342, 0.2328027262841742, 0.34512107931937674, 0.2545199493596185, 0.22867202164916411, 0.2536000096249822, 0.247559824187208, 0.23364220594619622, 0.21887149137225992, 0.25138452113105114, 0.22421342801936184, 0.22082035780942944, 0.26193760881573214, 0.6917708034846162, 0.19789960153376596, 0.19597016243354393, 0.1824361653717258, 0.19096904756917732, 0.19631191947214144, 0.2174981643883065, 0.19520924804057704, 0.19598404262508584, 0.18396969015625342, 0.18612147229137166, 0.18517537599147238, 0.8856055410695953, 0.1670557324344476, 0.8368596087322189, 0.8436385097376322, 0.8912841263690393, 0.8947753156261895, 0.8588835393419383, 0.851533553040317, 0.20966216501723933, 0.15504869507750096, 0.8433294130433883, 0.8436479962982408, 0.8482683162296778, 0.8536043853808677, 0.8761218173780815, 0.18914312298110825, 0.18325469051801324, 0.1936603612190574, 0.19372859952831, 0.20479347063556275, 0.19053844456159152, 0.1943455261954916, 0.18417599204962354, 0.18891691406148725, 0.09964227729862762, 0.09408133954616915, 0.0979702773558867, 0.08852594779641498, 0.09971456269814027, 0.11477467723659951, 0.08067348385687656, 0.10256296180541413, 0.13155598340959773]}, "mutation_prompt": null}
{"id": "d3ff3f41-c839-4e49-9bba-e6bbba7c6812", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 8 * dim  # Changed population size for faster adaptation\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Adjusted inertia weight for varied exploration\n        self.c1 = 2.0  # Increased cognitive coefficient for enhanced individual focus\n        self.c2 = 1.3  # Decreased social coefficient to balance exploration\n        self.F = 0.85  # Adjusted mutation factor for a balanced search\n        self.CR = 0.9  # Further increased crossover rate to improve exploitation\n        self.adapt_factor = 0.98  # Altered adaptation strategy for fine-tuning dynamics\n        self.diversity_prob = 0.25  # Modified probability to maintain diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.pop_size, self.dim))  # Tighter initial velocity bounds\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.2, 1.2)  # Fine-tuned velocity clipping\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.4, 0.4, self.dim)  # Adjusted perturbation range\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A novel adaptive hybrid optimizer combining differential evolution and particle swarm optimization with probabilistic line refinement for improved convergence and robustness.", "configspace": "", "generation": 63, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.8422026875756686, 0.8316019688777077, 0.8519869328290357, 0.8297406844583839, 0.8252630810752194, 0.8277146988170878, 0.8068246858743604, 0.8561060802327902, 0.8368040280874159, 0.5717081710158031, 0.6229294567072469, 0.6577352366361608, 0.6097452113019179, 0.6248463092449099, 0.6480892213630982, 0.5853863526991877, 0.0512914350509458, 0.6345276944127677, 0.12661715743764002, 0.13553147013685352, 0.1165180416573206, 0.15148546967390686, 0.11833273301113134, 0.11262716667065764, 0.09118768173218983, 0.14706882869418092, 0.12165743506468629, 0.12200259360489396, 0.13034521545583178, 0.10944944258130584, 0.10633023239117789, 0.09527081094569545, 0.11958436269742212, 0.10133130517975841, 0.10989989219452312, 0.10750303865126443, 0.9584574983645874, 0.9456154497882113, 0.9248413138037459, 0.9394551060087084, 0.9178440572107031, 0.9247673511357778, 0.9144207782702397, 0.9195730061057308, 0.9376478922359291, 0.6852319709074105, 0.6780533300046745, 0.7108562413265345, 0.6930832315747306, 0.6473842756151248, 0.6668633835109659, 0.64220068456561, 0.6802151366784446, 0.698301550023128, 0.8284517086601723, 0.8319853512761421, 0.848700148364309, 0.19309996213284675, 0.8640311987671301, 0.8237765327623953, 0.7548692240966136, 0.7386572483314423, 0.8061550552153522, 0.6932523924834011, 0.6326694635926952, 0.5702079409903438, 0.504380399590584, 0.12794219324437095, 0.6326230014369127, 0.6645992326448668, 0.6458071418537177, 0.6824412135078085, 0.6043996176797476, 0.5329321711330159, 0.5621157612975026, 0.5799416763180532, 0.6787042232568141, 0.6327755902918872, 0.6245389618384289, 0.594169038943976, 0.6159025368644813, 0.2142937207523753, 0.5471077190497382, 0.34075658145661114, 0.06300005442848433, 0.32213183089088593, 0.2642637831740825, 0.5790571789927872, 0.2219122676957993, 0.30282947269926586, 0.27733961317035494, 0.3025133376612158, 0.40151213893255033, 0.22581234342655665, 0.12018211681647095, 0.16096111360077414, 0.19341753830233344, 0.4028576817096069, 0.4815084195410494, 0.0971570659457186, 0.11809561294884408, 0.14606350116883315, 0.302776137134796, 0.462988492103911, 0.34443607346144123, 0.12731332407030782, 0.1692466283912818, 0.21420574580174156, 0.25821731821921967, 0.37170899358653164, 0.3209911039463592, 0.20206573914765158, 0.15242447640139722, 0.3654460569911646, 0.0796097810397487, 0.10677503213591588, 0.3671365836218843, 0.7289913375444261, 0.7021916146005962, 0.7667444024290355, 0.6654456240892526, 0.7677149592326706, 0.774739243646891, 0.6856674927873443, 0.7484678961515467, 0.7923371581346985, 0.10519973895126877, 0.13636345543025197, 0.09069979364325631, 0.11397311546275801, 0.14986323712414085, 0.10092383413138228, 0.12178337409989903, 0.13995936282413945, 0.11625146899098693, 0.24031191767279736, 0.2831384168733655, 0.2512288845549715, 0.21349208283147814, 0.2709742534134405, 0.253204641108837, 0.3065697933836059, 0.2569032502330555, 0.21508329618225674, 0.39468858929153916, 0.44493785886825876, 0.3412214442304601, 0.4022518625501722, 0.41978764058825146, 0.34803590937855267, 0.26225525808833394, 0.3355335156396261, 0.5077708211963312, 0.3112174627536882, 0.27900801700448374, 0.21404165006284892, 0.27762550591535406, 0.28627741444079047, 0.2788592224413342, 0.2328027262841742, 0.34512107931937674, 0.2545199493596185, 0.22867202164916411, 0.2536000096249822, 0.247559824187208, 0.23364220594619622, 0.21887149137225992, 0.25138452113105114, 0.22421342801936184, 0.22082035780942944, 0.26193760881573214, 0.6917708034846162, 0.19789960153376596, 0.19597016243354393, 0.1824361653717258, 0.19096904756917732, 0.19631191947214144, 0.2174981643883065, 0.19520924804057704, 0.19598404262508584, 0.18396969015625342, 0.18612147229137166, 0.18517537599147238, 0.8856055410695953, 0.1670557324344476, 0.8368596087322189, 0.8436385097376322, 0.8912841263690393, 0.8947753156261895, 0.8588835393419383, 0.851533553040317, 0.20966216501723933, 0.15504869507750096, 0.8433294130433883, 0.8436479962982408, 0.8482683162296778, 0.8536043853808677, 0.8761218173780815, 0.18914312298110825, 0.18325469051801324, 0.1936603612190574, 0.19372859952831, 0.20479347063556275, 0.19053844456159152, 0.1943455261954916, 0.18417599204962354, 0.18891691406148725, 0.09964227729862762, 0.09408133954616915, 0.0979702773558867, 0.08852594779641498, 0.09971456269814027, 0.11477467723659951, 0.08067348385687656, 0.10256296180541413, 0.13155598340959773]}, "mutation_prompt": null}
{"id": "ece14086-d306-45da-b181-2f1bf218bcaf", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 8 * dim  # Changed population size for faster adaptation\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Adjusted inertia weight for varied exploration\n        self.c1 = 2.0  # Increased cognitive coefficient for enhanced individual focus\n        self.c2 = 1.3  # Decreased social coefficient to balance exploration\n        self.F = 0.85  # Adjusted mutation factor for a balanced search\n        self.CR = 0.9  # Further increased crossover rate to improve exploitation\n        self.adapt_factor = 0.98  # Altered adaptation strategy for fine-tuning dynamics\n        self.diversity_prob = 0.25  # Modified probability to maintain diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.pop_size, self.dim))  # Tighter initial velocity bounds\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.2, 1.2)  # Fine-tuned velocity clipping\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.4, 0.4, self.dim)  # Adjusted perturbation range\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A novel adaptive hybrid optimizer combining differential evolution and particle swarm optimization with probabilistic line refinement for improved convergence and robustness.", "configspace": "", "generation": 63, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.8422026875756686, 0.8316019688777077, 0.8519869328290357, 0.8297406844583839, 0.8252630810752194, 0.8277146988170878, 0.8068246858743604, 0.8561060802327902, 0.8368040280874159, 0.5717081710158031, 0.6229294567072469, 0.6577352366361608, 0.6097452113019179, 0.6248463092449099, 0.6480892213630982, 0.5853863526991877, 0.0512914350509458, 0.6345276944127677, 0.12661715743764002, 0.13553147013685352, 0.1165180416573206, 0.15148546967390686, 0.11833273301113134, 0.11262716667065764, 0.09118768173218983, 0.14706882869418092, 0.12165743506468629, 0.12200259360489396, 0.13034521545583178, 0.10944944258130584, 0.10633023239117789, 0.09527081094569545, 0.11958436269742212, 0.10133130517975841, 0.10989989219452312, 0.10750303865126443, 0.9584574983645874, 0.9456154497882113, 0.9248413138037459, 0.9394551060087084, 0.9178440572107031, 0.9247673511357778, 0.9144207782702397, 0.9195730061057308, 0.9376478922359291, 0.6852319709074105, 0.6780533300046745, 0.7108562413265345, 0.6930832315747306, 0.6473842756151248, 0.6668633835109659, 0.64220068456561, 0.6802151366784446, 0.698301550023128, 0.8284517086601723, 0.8319853512761421, 0.848700148364309, 0.19309996213284675, 0.8640311987671301, 0.8237765327623953, 0.7548692240966136, 0.7386572483314423, 0.8061550552153522, 0.6932523924834011, 0.6326694635926952, 0.5702079409903438, 0.504380399590584, 0.12794219324437095, 0.6326230014369127, 0.6645992326448668, 0.6458071418537177, 0.6824412135078085, 0.6043996176797476, 0.5329321711330159, 0.5621157612975026, 0.5799416763180532, 0.6787042232568141, 0.6327755902918872, 0.6245389618384289, 0.594169038943976, 0.6159025368644813, 0.2142937207523753, 0.5471077190497382, 0.34075658145661114, 0.06300005442848433, 0.32213183089088593, 0.2642637831740825, 0.5790571789927872, 0.2219122676957993, 0.30282947269926586, 0.27733961317035494, 0.3025133376612158, 0.40151213893255033, 0.22581234342655665, 0.12018211681647095, 0.16096111360077414, 0.19341753830233344, 0.4028576817096069, 0.4815084195410494, 0.0971570659457186, 0.11809561294884408, 0.14606350116883315, 0.302776137134796, 0.462988492103911, 0.34443607346144123, 0.12731332407030782, 0.1692466283912818, 0.21420574580174156, 0.25821731821921967, 0.37170899358653164, 0.3209911039463592, 0.20206573914765158, 0.15242447640139722, 0.3654460569911646, 0.0796097810397487, 0.10677503213591588, 0.3671365836218843, 0.7289913375444261, 0.7021916146005962, 0.7667444024290355, 0.6654456240892526, 0.7677149592326706, 0.774739243646891, 0.6856674927873443, 0.7484678961515467, 0.7923371581346985, 0.10519973895126877, 0.13636345543025197, 0.09069979364325631, 0.11397311546275801, 0.14986323712414085, 0.10092383413138228, 0.12178337409989903, 0.13995936282413945, 0.11625146899098693, 0.24031191767279736, 0.2831384168733655, 0.2512288845549715, 0.21349208283147814, 0.2709742534134405, 0.253204641108837, 0.3065697933836059, 0.2569032502330555, 0.21508329618225674, 0.39468858929153916, 0.44493785886825876, 0.3412214442304601, 0.4022518625501722, 0.41978764058825146, 0.34803590937855267, 0.26225525808833394, 0.3355335156396261, 0.5077708211963312, 0.3112174627536882, 0.27900801700448374, 0.21404165006284892, 0.27762550591535406, 0.28627741444079047, 0.2788592224413342, 0.2328027262841742, 0.34512107931937674, 0.2545199493596185, 0.22867202164916411, 0.2536000096249822, 0.247559824187208, 0.23364220594619622, 0.21887149137225992, 0.25138452113105114, 0.22421342801936184, 0.22082035780942944, 0.26193760881573214, 0.6917708034846162, 0.19789960153376596, 0.19597016243354393, 0.1824361653717258, 0.19096904756917732, 0.19631191947214144, 0.2174981643883065, 0.19520924804057704, 0.19598404262508584, 0.18396969015625342, 0.18612147229137166, 0.18517537599147238, 0.8856055410695953, 0.1670557324344476, 0.8368596087322189, 0.8436385097376322, 0.8912841263690393, 0.8947753156261895, 0.8588835393419383, 0.851533553040317, 0.20966216501723933, 0.15504869507750096, 0.8433294130433883, 0.8436479962982408, 0.8482683162296778, 0.8536043853808677, 0.8761218173780815, 0.18914312298110825, 0.18325469051801324, 0.1936603612190574, 0.19372859952831, 0.20479347063556275, 0.19053844456159152, 0.1943455261954916, 0.18417599204962354, 0.18891691406148725, 0.09964227729862762, 0.09408133954616915, 0.0979702773558867, 0.08852594779641498, 0.09971456269814027, 0.11477467723659951, 0.08067348385687656, 0.10256296180541413, 0.13155598340959773]}, "mutation_prompt": null}
{"id": "f594c560-399e-4ea9-a813-06fa6b233b42", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 8 * dim  # Changed population size for faster adaptation\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Adjusted inertia weight for varied exploration\n        self.c1 = 2.0  # Increased cognitive coefficient for enhanced individual focus\n        self.c2 = 1.3  # Decreased social coefficient to balance exploration\n        self.F = 0.85  # Adjusted mutation factor for a balanced search\n        self.CR = 0.9  # Further increased crossover rate to improve exploitation\n        self.adapt_factor = 0.98  # Altered adaptation strategy for fine-tuning dynamics\n        self.diversity_prob = 0.25  # Modified probability to maintain diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.pop_size, self.dim))  # Tighter initial velocity bounds\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.2, 1.2)  # Fine-tuned velocity clipping\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.4, 0.4, self.dim)  # Adjusted perturbation range\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A novel adaptive hybrid optimizer combining differential evolution and particle swarm optimization with probabilistic line refinement for improved convergence and robustness.", "configspace": "", "generation": 63, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.8422026875756686, 0.8316019688777077, 0.8519869328290357, 0.8297406844583839, 0.8252630810752194, 0.8277146988170878, 0.8068246858743604, 0.8561060802327902, 0.8368040280874159, 0.5717081710158031, 0.6229294567072469, 0.6577352366361608, 0.6097452113019179, 0.6248463092449099, 0.6480892213630982, 0.5853863526991877, 0.0512914350509458, 0.6345276944127677, 0.12661715743764002, 0.13553147013685352, 0.1165180416573206, 0.15148546967390686, 0.11833273301113134, 0.11262716667065764, 0.09118768173218983, 0.14706882869418092, 0.12165743506468629, 0.12200259360489396, 0.13034521545583178, 0.10944944258130584, 0.10633023239117789, 0.09527081094569545, 0.11958436269742212, 0.10133130517975841, 0.10989989219452312, 0.10750303865126443, 0.9584574983645874, 0.9456154497882113, 0.9248413138037459, 0.9394551060087084, 0.9178440572107031, 0.9247673511357778, 0.9144207782702397, 0.9195730061057308, 0.9376478922359291, 0.6852319709074105, 0.6780533300046745, 0.7108562413265345, 0.6930832315747306, 0.6473842756151248, 0.6668633835109659, 0.64220068456561, 0.6802151366784446, 0.698301550023128, 0.8284517086601723, 0.8319853512761421, 0.848700148364309, 0.19309996213284675, 0.8640311987671301, 0.8237765327623953, 0.7548692240966136, 0.7386572483314423, 0.8061550552153522, 0.6932523924834011, 0.6326694635926952, 0.5702079409903438, 0.504380399590584, 0.12794219324437095, 0.6326230014369127, 0.6645992326448668, 0.6458071418537177, 0.6824412135078085, 0.6043996176797476, 0.5329321711330159, 0.5621157612975026, 0.5799416763180532, 0.6787042232568141, 0.6327755902918872, 0.6245389618384289, 0.594169038943976, 0.6159025368644813, 0.2142937207523753, 0.5471077190497382, 0.34075658145661114, 0.06300005442848433, 0.32213183089088593, 0.2642637831740825, 0.5790571789927872, 0.2219122676957993, 0.30282947269926586, 0.27733961317035494, 0.3025133376612158, 0.40151213893255033, 0.22581234342655665, 0.12018211681647095, 0.16096111360077414, 0.19341753830233344, 0.4028576817096069, 0.4815084195410494, 0.0971570659457186, 0.11809561294884408, 0.14606350116883315, 0.302776137134796, 0.462988492103911, 0.34443607346144123, 0.12731332407030782, 0.1692466283912818, 0.21420574580174156, 0.25821731821921967, 0.37170899358653164, 0.3209911039463592, 0.20206573914765158, 0.15242447640139722, 0.3654460569911646, 0.0796097810397487, 0.10677503213591588, 0.3671365836218843, 0.7289913375444261, 0.7021916146005962, 0.7667444024290355, 0.6654456240892526, 0.7677149592326706, 0.774739243646891, 0.6856674927873443, 0.7484678961515467, 0.7923371581346985, 0.10519973895126877, 0.13636345543025197, 0.09069979364325631, 0.11397311546275801, 0.14986323712414085, 0.10092383413138228, 0.12178337409989903, 0.13995936282413945, 0.11625146899098693, 0.24031191767279736, 0.2831384168733655, 0.2512288845549715, 0.21349208283147814, 0.2709742534134405, 0.253204641108837, 0.3065697933836059, 0.2569032502330555, 0.21508329618225674, 0.39468858929153916, 0.44493785886825876, 0.3412214442304601, 0.4022518625501722, 0.41978764058825146, 0.34803590937855267, 0.26225525808833394, 0.3355335156396261, 0.5077708211963312, 0.3112174627536882, 0.27900801700448374, 0.21404165006284892, 0.27762550591535406, 0.28627741444079047, 0.2788592224413342, 0.2328027262841742, 0.34512107931937674, 0.2545199493596185, 0.22867202164916411, 0.2536000096249822, 0.247559824187208, 0.23364220594619622, 0.21887149137225992, 0.25138452113105114, 0.22421342801936184, 0.22082035780942944, 0.26193760881573214, 0.6917708034846162, 0.19789960153376596, 0.19597016243354393, 0.1824361653717258, 0.19096904756917732, 0.19631191947214144, 0.2174981643883065, 0.19520924804057704, 0.19598404262508584, 0.18396969015625342, 0.18612147229137166, 0.18517537599147238, 0.8856055410695953, 0.1670557324344476, 0.8368596087322189, 0.8436385097376322, 0.8912841263690393, 0.8947753156261895, 0.8588835393419383, 0.851533553040317, 0.20966216501723933, 0.15504869507750096, 0.8433294130433883, 0.8436479962982408, 0.8482683162296778, 0.8536043853808677, 0.8761218173780815, 0.18914312298110825, 0.18325469051801324, 0.1936603612190574, 0.19372859952831, 0.20479347063556275, 0.19053844456159152, 0.1943455261954916, 0.18417599204962354, 0.18891691406148725, 0.09964227729862762, 0.09408133954616915, 0.0979702773558867, 0.08852594779641498, 0.09971456269814027, 0.11477467723659951, 0.08067348385687656, 0.10256296180541413, 0.13155598340959773]}, "mutation_prompt": null}
{"id": "403be74d-a00d-444e-b8ec-9e52470b6d36", "solution": "import numpy as np\n\nclass NeuralAdaptiveDEPSOOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 8 * dim\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.7  # Slightly increased inertia weight for broader exploration\n        self.c1 = 1.9  # Reduced cognitive coefficient to avoid premature convergence\n        self.c2 = 1.5  # Balanced social coefficient for cooperative behavior\n        self.F = 0.9  # Enhanced mutation factor for extensive search capability\n        self.CR = 0.85  # Slightly reduced crossover rate for more diverse solutions\n        self.adapt_factor = 0.95  # Modified adaptation strategy for dynamic learning\n        self.diversity_prob = 0.3  # Increased probability to maintain diversity through exploration\n        self.neural_factor = 0.1  # New factor to introduce stochastic neural learning\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]) +\n                                 self.neural_factor * np.random.normal(0, 1, self.dim))  # Neural-inspired perturbation\n                \n                velocities[i] = np.clip(velocities[i], -1.2, 1.2)\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.5, 0.5, self.dim)\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "NeuralAdaptiveDEPSOOptimizer", "description": "A refined adaptive hybrid optimizer that enhances the DE-PSO framework with stochastic neural learning for dynamic exploration-exploitation balance.", "configspace": "", "generation": 75, "fitness": 0.2318422655551743, "feedback": "The algorithm NeuralAdaptiveDEPSOOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.4028009470450794, 0.4176038128858983, 0.4362552066217872, 0.42618873317801964, 0.4404499103521631, 0.4118549851201948, 0.4372521501407144, 0.4312885113369761, 0.42156820443014587, 0.05078790891532914, 0.04719816601076676, 0.10477093100186341, 9.999999999998899e-05, 0.07187856782835589, 9.999999999998899e-05, 0.04279224242972757, 0.015040830543084138, 9.999999999998899e-05, 0.14180515210850497, 0.12026349419966609, 0.1145829382926109, 0.1010358069219548, 0.13370302437163117, 0.10293744719188636, 0.09841119792687425, 0.13284900372848518, 0.12867917269840967, 0.09401478531274043, 0.09556075612231418, 0.0988687924451711, 0.1144575904704963, 0.09818675887028949, 0.101920198540988, 0.09984313591018068, 0.10569475817525076, 0.10262292621980118, 0.9349745197632222, 0.9381603071905797, 0.9337983265215608, 0.9123805654880264, 0.9170480724888794, 0.9018172029139695, 0.9475032029584844, 0.9617790719531008, 0.9212807824440344, 0.2810781786426185, 0.29991026160324397, 0.2650937711391781, 0.26677367945778374, 0.30262414164050333, 0.28618959745949146, 0.29300071485619805, 0.33408543175809546, 0.3054119426273394, 0.3158733054301186, 0.4665401607667583, 0.6977917607916642, 0.3050007584551948, 0.28176558435587185, 0.35830832289002124, 0.2950611885418999, 0.32540236576067705, 0.3247566474634769, 0.2024771172669534, 0.14258098133462116, 0.1726939556875835, 0.12154691628802139, 0.16605442372740997, 0.1737610062670496, 0.16366575877131295, 0.14256429234497514, 0.13405144531864222, 0.17301940248753378, 0.1513349623727036, 0.15150985404741546, 0.1600100797486692, 0.15834455393634106, 0.16190066821512994, 0.1819832817008914, 0.18092656923782835, 0.16742318531835676, 0.0563682769219207, 0.02289306811207592, 9.999999999998899e-05, 0.04226100016489287, 9.999999999998899e-05, 9.999999999998899e-05, 0.05235201180231941, 0.05220451936474435, 0.0163085015350376, 0.16273724974419912, 0.10452873940338436, 0.15931670092338213, 0.09041609123836647, 0.08922712656900933, 0.05276716237133516, 0.12090990849344596, 0.1677535413372041, 0.13610543983590273, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0942048353388858, 0.09519896905693404, 0.06683034493844009, 0.10786722125037962, 0.09683216256684246, 0.11120061628141342, 0.0936756476006202, 0.0908047437100804, 0.10004827260882121, 0.3945610005669026, 0.41711874332001186, 0.3997385718119306, 0.3975805310066618, 0.38181210090426954, 0.39508600269672967, 0.3900940279793055, 0.3981411884073067, 0.38840966900593044, 0.12254811958382106, 0.12716623926008763, 0.0901566858780889, 0.10572787655413418, 0.14000643411752967, 0.0950838186615045, 0.1133762591079378, 0.12603397961656249, 0.11560642606822458, 0.20341663556605494, 0.2209530825647842, 0.186273128183984, 0.23871667533948393, 0.18849786855036155, 0.21409872902788152, 0.23790069079079212, 0.277557734754143, 0.16494741625820697, 0.27985410480557216, 0.3126242886794861, 0.28197393946153504, 0.27933882670874777, 0.2800880741237618, 0.2841784166231992, 0.28096302693954267, 0.2844226993239012, 0.2814311003351426, 0.2256199692182631, 0.23903470043826625, 0.21764060170098798, 0.22281667025465013, 0.1852789677914335, 0.2278428494363317, 0.19702338576213663, 0.23737684823631244, 0.18710469086753345, 0.23430511854186464, 0.2263415627963674, 0.24939834521323379, 0.20504780851091986, 0.25458054904104854, 0.25188461204127977, 0.21068725022939438, 0.23248119324182948, 0.21991684795868105, 0.19966910468037535, 0.2074428220317589, 0.19778871592174785, 0.2136139088374921, 0.18953446454226663, 0.21932627121699766, 0.17645012764803336, 0.17361979742883127, 0.19037325092562718, 0.18223356309153316, 0.5647921108637662, 0.17585701752802452, 0.6031351680994199, 0.19758312859583416, 0.6077918338037099, 0.1735843797735246, 0.6180451479336229, 0.5987443607752818, 0.6435288398366089, 0.20841843682484373, 0.3842885060062804, 0.5114953407001341, 0.20997480225770437, 0.1526934901381357, 0.4758956334046196, 0.5903350106901915, 0.16532943293552693, 0.17591889279637762, 0.18667182801294957, 0.1807082128876114, 0.19606380819642444, 0.19252381614294745, 0.19483318110087267, 0.1913094041899377, 0.1845585266047507, 0.18472759944243555, 0.09512582174803608, 0.08813244166808398, 0.09323927259027165, 0.09627261122737818, 0.08312287729424317, 0.11246017376005579, 0.08929242562271722, 0.08408356304367881, 0.09073563528249473]}, "mutation_prompt": null}
{"id": "f5a02b2e-d392-4c00-85b7-5b4da35e4826", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 8 * dim  # Changed population size for faster adaptation\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Adjusted inertia weight for varied exploration\n        self.c1 = 2.0  # Increased cognitive coefficient for enhanced individual focus\n        self.c2 = 1.3  # Decreased social coefficient to balance exploration\n        self.F = 0.85  # Adjusted mutation factor for a balanced search\n        self.CR = 0.9  # Further increased crossover rate to improve exploitation\n        self.adapt_factor = 0.98  # Altered adaptation strategy for fine-tuning dynamics\n        self.diversity_prob = 0.25  # Modified probability to maintain diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.pop_size, self.dim))  # Tighter initial velocity bounds\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.2, 1.2)  # Fine-tuned velocity clipping\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.4, 0.4, self.dim)  # Adjusted perturbation range\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A novel adaptive hybrid optimizer combining differential evolution and particle swarm optimization with probabilistic line refinement for improved convergence and robustness.", "configspace": "", "generation": 63, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.8422026875756686, 0.8316019688777077, 0.8519869328290357, 0.8297406844583839, 0.8252630810752194, 0.8277146988170878, 0.8068246858743604, 0.8561060802327902, 0.8368040280874159, 0.5717081710158031, 0.6229294567072469, 0.6577352366361608, 0.6097452113019179, 0.6248463092449099, 0.6480892213630982, 0.5853863526991877, 0.0512914350509458, 0.6345276944127677, 0.12661715743764002, 0.13553147013685352, 0.1165180416573206, 0.15148546967390686, 0.11833273301113134, 0.11262716667065764, 0.09118768173218983, 0.14706882869418092, 0.12165743506468629, 0.12200259360489396, 0.13034521545583178, 0.10944944258130584, 0.10633023239117789, 0.09527081094569545, 0.11958436269742212, 0.10133130517975841, 0.10989989219452312, 0.10750303865126443, 0.9584574983645874, 0.9456154497882113, 0.9248413138037459, 0.9394551060087084, 0.9178440572107031, 0.9247673511357778, 0.9144207782702397, 0.9195730061057308, 0.9376478922359291, 0.6852319709074105, 0.6780533300046745, 0.7108562413265345, 0.6930832315747306, 0.6473842756151248, 0.6668633835109659, 0.64220068456561, 0.6802151366784446, 0.698301550023128, 0.8284517086601723, 0.8319853512761421, 0.848700148364309, 0.19309996213284675, 0.8640311987671301, 0.8237765327623953, 0.7548692240966136, 0.7386572483314423, 0.8061550552153522, 0.6932523924834011, 0.6326694635926952, 0.5702079409903438, 0.504380399590584, 0.12794219324437095, 0.6326230014369127, 0.6645992326448668, 0.6458071418537177, 0.6824412135078085, 0.6043996176797476, 0.5329321711330159, 0.5621157612975026, 0.5799416763180532, 0.6787042232568141, 0.6327755902918872, 0.6245389618384289, 0.594169038943976, 0.6159025368644813, 0.2142937207523753, 0.5471077190497382, 0.34075658145661114, 0.06300005442848433, 0.32213183089088593, 0.2642637831740825, 0.5790571789927872, 0.2219122676957993, 0.30282947269926586, 0.27733961317035494, 0.3025133376612158, 0.40151213893255033, 0.22581234342655665, 0.12018211681647095, 0.16096111360077414, 0.19341753830233344, 0.4028576817096069, 0.4815084195410494, 0.0971570659457186, 0.11809561294884408, 0.14606350116883315, 0.302776137134796, 0.462988492103911, 0.34443607346144123, 0.12731332407030782, 0.1692466283912818, 0.21420574580174156, 0.25821731821921967, 0.37170899358653164, 0.3209911039463592, 0.20206573914765158, 0.15242447640139722, 0.3654460569911646, 0.0796097810397487, 0.10677503213591588, 0.3671365836218843, 0.7289913375444261, 0.7021916146005962, 0.7667444024290355, 0.6654456240892526, 0.7677149592326706, 0.774739243646891, 0.6856674927873443, 0.7484678961515467, 0.7923371581346985, 0.10519973895126877, 0.13636345543025197, 0.09069979364325631, 0.11397311546275801, 0.14986323712414085, 0.10092383413138228, 0.12178337409989903, 0.13995936282413945, 0.11625146899098693, 0.24031191767279736, 0.2831384168733655, 0.2512288845549715, 0.21349208283147814, 0.2709742534134405, 0.253204641108837, 0.3065697933836059, 0.2569032502330555, 0.21508329618225674, 0.39468858929153916, 0.44493785886825876, 0.3412214442304601, 0.4022518625501722, 0.41978764058825146, 0.34803590937855267, 0.26225525808833394, 0.3355335156396261, 0.5077708211963312, 0.3112174627536882, 0.27900801700448374, 0.21404165006284892, 0.27762550591535406, 0.28627741444079047, 0.2788592224413342, 0.2328027262841742, 0.34512107931937674, 0.2545199493596185, 0.22867202164916411, 0.2536000096249822, 0.247559824187208, 0.23364220594619622, 0.21887149137225992, 0.25138452113105114, 0.22421342801936184, 0.22082035780942944, 0.26193760881573214, 0.6917708034846162, 0.19789960153376596, 0.19597016243354393, 0.1824361653717258, 0.19096904756917732, 0.19631191947214144, 0.2174981643883065, 0.19520924804057704, 0.19598404262508584, 0.18396969015625342, 0.18612147229137166, 0.18517537599147238, 0.8856055410695953, 0.1670557324344476, 0.8368596087322189, 0.8436385097376322, 0.8912841263690393, 0.8947753156261895, 0.8588835393419383, 0.851533553040317, 0.20966216501723933, 0.15504869507750096, 0.8433294130433883, 0.8436479962982408, 0.8482683162296778, 0.8536043853808677, 0.8761218173780815, 0.18914312298110825, 0.18325469051801324, 0.1936603612190574, 0.19372859952831, 0.20479347063556275, 0.19053844456159152, 0.1943455261954916, 0.18417599204962354, 0.18891691406148725, 0.09964227729862762, 0.09408133954616915, 0.0979702773558867, 0.08852594779641498, 0.09971456269814027, 0.11477467723659951, 0.08067348385687656, 0.10256296180541413, 0.13155598340959773]}, "mutation_prompt": null}
{"id": "84315b70-33e1-4a4c-bc50-41f311b9b96e", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 8 * dim  # Changed population size for faster adaptation\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Adjusted inertia weight for varied exploration\n        self.c1 = 2.0  # Increased cognitive coefficient for enhanced individual focus\n        self.c2 = 1.3  # Decreased social coefficient to balance exploration\n        self.F = 0.85  # Adjusted mutation factor for a balanced search\n        self.CR = 0.9  # Further increased crossover rate to improve exploitation\n        self.adapt_factor = 0.98  # Altered adaptation strategy for fine-tuning dynamics\n        self.diversity_prob = 0.25  # Modified probability to maintain diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.pop_size, self.dim))  # Tighter initial velocity bounds\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.2, 1.2)  # Fine-tuned velocity clipping\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.4, 0.4, self.dim)  # Adjusted perturbation range\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A novel adaptive hybrid optimizer combining differential evolution and particle swarm optimization with probabilistic line refinement for improved convergence and robustness.", "configspace": "", "generation": 63, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.8422026875756686, 0.8316019688777077, 0.8519869328290357, 0.8297406844583839, 0.8252630810752194, 0.8277146988170878, 0.8068246858743604, 0.8561060802327902, 0.8368040280874159, 0.5717081710158031, 0.6229294567072469, 0.6577352366361608, 0.6097452113019179, 0.6248463092449099, 0.6480892213630982, 0.5853863526991877, 0.0512914350509458, 0.6345276944127677, 0.12661715743764002, 0.13553147013685352, 0.1165180416573206, 0.15148546967390686, 0.11833273301113134, 0.11262716667065764, 0.09118768173218983, 0.14706882869418092, 0.12165743506468629, 0.12200259360489396, 0.13034521545583178, 0.10944944258130584, 0.10633023239117789, 0.09527081094569545, 0.11958436269742212, 0.10133130517975841, 0.10989989219452312, 0.10750303865126443, 0.9584574983645874, 0.9456154497882113, 0.9248413138037459, 0.9394551060087084, 0.9178440572107031, 0.9247673511357778, 0.9144207782702397, 0.9195730061057308, 0.9376478922359291, 0.6852319709074105, 0.6780533300046745, 0.7108562413265345, 0.6930832315747306, 0.6473842756151248, 0.6668633835109659, 0.64220068456561, 0.6802151366784446, 0.698301550023128, 0.8284517086601723, 0.8319853512761421, 0.848700148364309, 0.19309996213284675, 0.8640311987671301, 0.8237765327623953, 0.7548692240966136, 0.7386572483314423, 0.8061550552153522, 0.6932523924834011, 0.6326694635926952, 0.5702079409903438, 0.504380399590584, 0.12794219324437095, 0.6326230014369127, 0.6645992326448668, 0.6458071418537177, 0.6824412135078085, 0.6043996176797476, 0.5329321711330159, 0.5621157612975026, 0.5799416763180532, 0.6787042232568141, 0.6327755902918872, 0.6245389618384289, 0.594169038943976, 0.6159025368644813, 0.2142937207523753, 0.5471077190497382, 0.34075658145661114, 0.06300005442848433, 0.32213183089088593, 0.2642637831740825, 0.5790571789927872, 0.2219122676957993, 0.30282947269926586, 0.27733961317035494, 0.3025133376612158, 0.40151213893255033, 0.22581234342655665, 0.12018211681647095, 0.16096111360077414, 0.19341753830233344, 0.4028576817096069, 0.4815084195410494, 0.0971570659457186, 0.11809561294884408, 0.14606350116883315, 0.302776137134796, 0.462988492103911, 0.34443607346144123, 0.12731332407030782, 0.1692466283912818, 0.21420574580174156, 0.25821731821921967, 0.37170899358653164, 0.3209911039463592, 0.20206573914765158, 0.15242447640139722, 0.3654460569911646, 0.0796097810397487, 0.10677503213591588, 0.3671365836218843, 0.7289913375444261, 0.7021916146005962, 0.7667444024290355, 0.6654456240892526, 0.7677149592326706, 0.774739243646891, 0.6856674927873443, 0.7484678961515467, 0.7923371581346985, 0.10519973895126877, 0.13636345543025197, 0.09069979364325631, 0.11397311546275801, 0.14986323712414085, 0.10092383413138228, 0.12178337409989903, 0.13995936282413945, 0.11625146899098693, 0.24031191767279736, 0.2831384168733655, 0.2512288845549715, 0.21349208283147814, 0.2709742534134405, 0.253204641108837, 0.3065697933836059, 0.2569032502330555, 0.21508329618225674, 0.39468858929153916, 0.44493785886825876, 0.3412214442304601, 0.4022518625501722, 0.41978764058825146, 0.34803590937855267, 0.26225525808833394, 0.3355335156396261, 0.5077708211963312, 0.3112174627536882, 0.27900801700448374, 0.21404165006284892, 0.27762550591535406, 0.28627741444079047, 0.2788592224413342, 0.2328027262841742, 0.34512107931937674, 0.2545199493596185, 0.22867202164916411, 0.2536000096249822, 0.247559824187208, 0.23364220594619622, 0.21887149137225992, 0.25138452113105114, 0.22421342801936184, 0.22082035780942944, 0.26193760881573214, 0.6917708034846162, 0.19789960153376596, 0.19597016243354393, 0.1824361653717258, 0.19096904756917732, 0.19631191947214144, 0.2174981643883065, 0.19520924804057704, 0.19598404262508584, 0.18396969015625342, 0.18612147229137166, 0.18517537599147238, 0.8856055410695953, 0.1670557324344476, 0.8368596087322189, 0.8436385097376322, 0.8912841263690393, 0.8947753156261895, 0.8588835393419383, 0.851533553040317, 0.20966216501723933, 0.15504869507750096, 0.8433294130433883, 0.8436479962982408, 0.8482683162296778, 0.8536043853808677, 0.8761218173780815, 0.18914312298110825, 0.18325469051801324, 0.1936603612190574, 0.19372859952831, 0.20479347063556275, 0.19053844456159152, 0.1943455261954916, 0.18417599204962354, 0.18891691406148725, 0.09964227729862762, 0.09408133954616915, 0.0979702773558867, 0.08852594779641498, 0.09971456269814027, 0.11477467723659951, 0.08067348385687656, 0.10256296180541413, 0.13155598340959773]}, "mutation_prompt": null}
{"id": "bc6e0b22-dd40-4f93-8305-7f2b4ca8ab9e", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 8 * dim  # Changed population size for faster adaptation\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Adjusted inertia weight for varied exploration\n        self.c1 = 2.0  # Increased cognitive coefficient for enhanced individual focus\n        self.c2 = 1.3  # Decreased social coefficient to balance exploration\n        self.F = 0.85  # Adjusted mutation factor for a balanced search\n        self.CR = 0.9  # Further increased crossover rate to improve exploitation\n        self.adapt_factor = 0.98  # Altered adaptation strategy for fine-tuning dynamics\n        self.diversity_prob = 0.25  # Modified probability to maintain diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.pop_size, self.dim))  # Tighter initial velocity bounds\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.2, 1.2)  # Fine-tuned velocity clipping\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.4, 0.4, self.dim)  # Adjusted perturbation range\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A novel adaptive hybrid optimizer combining differential evolution and particle swarm optimization with probabilistic line refinement for improved convergence and robustness.", "configspace": "", "generation": 63, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.8422026875756686, 0.8316019688777077, 0.8519869328290357, 0.8297406844583839, 0.8252630810752194, 0.8277146988170878, 0.8068246858743604, 0.8561060802327902, 0.8368040280874159, 0.5717081710158031, 0.6229294567072469, 0.6577352366361608, 0.6097452113019179, 0.6248463092449099, 0.6480892213630982, 0.5853863526991877, 0.0512914350509458, 0.6345276944127677, 0.12661715743764002, 0.13553147013685352, 0.1165180416573206, 0.15148546967390686, 0.11833273301113134, 0.11262716667065764, 0.09118768173218983, 0.14706882869418092, 0.12165743506468629, 0.12200259360489396, 0.13034521545583178, 0.10944944258130584, 0.10633023239117789, 0.09527081094569545, 0.11958436269742212, 0.10133130517975841, 0.10989989219452312, 0.10750303865126443, 0.9584574983645874, 0.9456154497882113, 0.9248413138037459, 0.9394551060087084, 0.9178440572107031, 0.9247673511357778, 0.9144207782702397, 0.9195730061057308, 0.9376478922359291, 0.6852319709074105, 0.6780533300046745, 0.7108562413265345, 0.6930832315747306, 0.6473842756151248, 0.6668633835109659, 0.64220068456561, 0.6802151366784446, 0.698301550023128, 0.8284517086601723, 0.8319853512761421, 0.848700148364309, 0.19309996213284675, 0.8640311987671301, 0.8237765327623953, 0.7548692240966136, 0.7386572483314423, 0.8061550552153522, 0.6932523924834011, 0.6326694635926952, 0.5702079409903438, 0.504380399590584, 0.12794219324437095, 0.6326230014369127, 0.6645992326448668, 0.6458071418537177, 0.6824412135078085, 0.6043996176797476, 0.5329321711330159, 0.5621157612975026, 0.5799416763180532, 0.6787042232568141, 0.6327755902918872, 0.6245389618384289, 0.594169038943976, 0.6159025368644813, 0.2142937207523753, 0.5471077190497382, 0.34075658145661114, 0.06300005442848433, 0.32213183089088593, 0.2642637831740825, 0.5790571789927872, 0.2219122676957993, 0.30282947269926586, 0.27733961317035494, 0.3025133376612158, 0.40151213893255033, 0.22581234342655665, 0.12018211681647095, 0.16096111360077414, 0.19341753830233344, 0.4028576817096069, 0.4815084195410494, 0.0971570659457186, 0.11809561294884408, 0.14606350116883315, 0.302776137134796, 0.462988492103911, 0.34443607346144123, 0.12731332407030782, 0.1692466283912818, 0.21420574580174156, 0.25821731821921967, 0.37170899358653164, 0.3209911039463592, 0.20206573914765158, 0.15242447640139722, 0.3654460569911646, 0.0796097810397487, 0.10677503213591588, 0.3671365836218843, 0.7289913375444261, 0.7021916146005962, 0.7667444024290355, 0.6654456240892526, 0.7677149592326706, 0.774739243646891, 0.6856674927873443, 0.7484678961515467, 0.7923371581346985, 0.10519973895126877, 0.13636345543025197, 0.09069979364325631, 0.11397311546275801, 0.14986323712414085, 0.10092383413138228, 0.12178337409989903, 0.13995936282413945, 0.11625146899098693, 0.24031191767279736, 0.2831384168733655, 0.2512288845549715, 0.21349208283147814, 0.2709742534134405, 0.253204641108837, 0.3065697933836059, 0.2569032502330555, 0.21508329618225674, 0.39468858929153916, 0.44493785886825876, 0.3412214442304601, 0.4022518625501722, 0.41978764058825146, 0.34803590937855267, 0.26225525808833394, 0.3355335156396261, 0.5077708211963312, 0.3112174627536882, 0.27900801700448374, 0.21404165006284892, 0.27762550591535406, 0.28627741444079047, 0.2788592224413342, 0.2328027262841742, 0.34512107931937674, 0.2545199493596185, 0.22867202164916411, 0.2536000096249822, 0.247559824187208, 0.23364220594619622, 0.21887149137225992, 0.25138452113105114, 0.22421342801936184, 0.22082035780942944, 0.26193760881573214, 0.6917708034846162, 0.19789960153376596, 0.19597016243354393, 0.1824361653717258, 0.19096904756917732, 0.19631191947214144, 0.2174981643883065, 0.19520924804057704, 0.19598404262508584, 0.18396969015625342, 0.18612147229137166, 0.18517537599147238, 0.8856055410695953, 0.1670557324344476, 0.8368596087322189, 0.8436385097376322, 0.8912841263690393, 0.8947753156261895, 0.8588835393419383, 0.851533553040317, 0.20966216501723933, 0.15504869507750096, 0.8433294130433883, 0.8436479962982408, 0.8482683162296778, 0.8536043853808677, 0.8761218173780815, 0.18914312298110825, 0.18325469051801324, 0.1936603612190574, 0.19372859952831, 0.20479347063556275, 0.19053844456159152, 0.1943455261954916, 0.18417599204962354, 0.18891691406148725, 0.09964227729862762, 0.09408133954616915, 0.0979702773558867, 0.08852594779641498, 0.09971456269814027, 0.11477467723659951, 0.08067348385687656, 0.10256296180541413, 0.13155598340959773]}, "mutation_prompt": null}
{"id": "b248cbb5-ec4e-49da-aa0e-6f61e12b9ed3", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 8 * dim  # Changed population size for faster adaptation\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Adjusted inertia weight for varied exploration\n        self.c1 = 2.0  # Increased cognitive coefficient for enhanced individual focus\n        self.c2 = 1.3  # Decreased social coefficient to balance exploration\n        self.F = 0.85  # Adjusted mutation factor for a balanced search\n        self.CR = 0.9  # Further increased crossover rate to improve exploitation\n        self.adapt_factor = 0.98  # Altered adaptation strategy for fine-tuning dynamics\n        self.diversity_prob = 0.25  # Modified probability to maintain diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.pop_size, self.dim))  # Tighter initial velocity bounds\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.2, 1.2)  # Fine-tuned velocity clipping\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.4, 0.4, self.dim)  # Adjusted perturbation range\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A novel adaptive hybrid optimizer combining differential evolution and particle swarm optimization with probabilistic line refinement for improved convergence and robustness.", "configspace": "", "generation": 63, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.8422026875756686, 0.8316019688777077, 0.8519869328290357, 0.8297406844583839, 0.8252630810752194, 0.8277146988170878, 0.8068246858743604, 0.8561060802327902, 0.8368040280874159, 0.5717081710158031, 0.6229294567072469, 0.6577352366361608, 0.6097452113019179, 0.6248463092449099, 0.6480892213630982, 0.5853863526991877, 0.0512914350509458, 0.6345276944127677, 0.12661715743764002, 0.13553147013685352, 0.1165180416573206, 0.15148546967390686, 0.11833273301113134, 0.11262716667065764, 0.09118768173218983, 0.14706882869418092, 0.12165743506468629, 0.12200259360489396, 0.13034521545583178, 0.10944944258130584, 0.10633023239117789, 0.09527081094569545, 0.11958436269742212, 0.10133130517975841, 0.10989989219452312, 0.10750303865126443, 0.9584574983645874, 0.9456154497882113, 0.9248413138037459, 0.9394551060087084, 0.9178440572107031, 0.9247673511357778, 0.9144207782702397, 0.9195730061057308, 0.9376478922359291, 0.6852319709074105, 0.6780533300046745, 0.7108562413265345, 0.6930832315747306, 0.6473842756151248, 0.6668633835109659, 0.64220068456561, 0.6802151366784446, 0.698301550023128, 0.8284517086601723, 0.8319853512761421, 0.848700148364309, 0.19309996213284675, 0.8640311987671301, 0.8237765327623953, 0.7548692240966136, 0.7386572483314423, 0.8061550552153522, 0.6932523924834011, 0.6326694635926952, 0.5702079409903438, 0.504380399590584, 0.12794219324437095, 0.6326230014369127, 0.6645992326448668, 0.6458071418537177, 0.6824412135078085, 0.6043996176797476, 0.5329321711330159, 0.5621157612975026, 0.5799416763180532, 0.6787042232568141, 0.6327755902918872, 0.6245389618384289, 0.594169038943976, 0.6159025368644813, 0.2142937207523753, 0.5471077190497382, 0.34075658145661114, 0.06300005442848433, 0.32213183089088593, 0.2642637831740825, 0.5790571789927872, 0.2219122676957993, 0.30282947269926586, 0.27733961317035494, 0.3025133376612158, 0.40151213893255033, 0.22581234342655665, 0.12018211681647095, 0.16096111360077414, 0.19341753830233344, 0.4028576817096069, 0.4815084195410494, 0.0971570659457186, 0.11809561294884408, 0.14606350116883315, 0.302776137134796, 0.462988492103911, 0.34443607346144123, 0.12731332407030782, 0.1692466283912818, 0.21420574580174156, 0.25821731821921967, 0.37170899358653164, 0.3209911039463592, 0.20206573914765158, 0.15242447640139722, 0.3654460569911646, 0.0796097810397487, 0.10677503213591588, 0.3671365836218843, 0.7289913375444261, 0.7021916146005962, 0.7667444024290355, 0.6654456240892526, 0.7677149592326706, 0.774739243646891, 0.6856674927873443, 0.7484678961515467, 0.7923371581346985, 0.10519973895126877, 0.13636345543025197, 0.09069979364325631, 0.11397311546275801, 0.14986323712414085, 0.10092383413138228, 0.12178337409989903, 0.13995936282413945, 0.11625146899098693, 0.24031191767279736, 0.2831384168733655, 0.2512288845549715, 0.21349208283147814, 0.2709742534134405, 0.253204641108837, 0.3065697933836059, 0.2569032502330555, 0.21508329618225674, 0.39468858929153916, 0.44493785886825876, 0.3412214442304601, 0.4022518625501722, 0.41978764058825146, 0.34803590937855267, 0.26225525808833394, 0.3355335156396261, 0.5077708211963312, 0.3112174627536882, 0.27900801700448374, 0.21404165006284892, 0.27762550591535406, 0.28627741444079047, 0.2788592224413342, 0.2328027262841742, 0.34512107931937674, 0.2545199493596185, 0.22867202164916411, 0.2536000096249822, 0.247559824187208, 0.23364220594619622, 0.21887149137225992, 0.25138452113105114, 0.22421342801936184, 0.22082035780942944, 0.26193760881573214, 0.6917708034846162, 0.19789960153376596, 0.19597016243354393, 0.1824361653717258, 0.19096904756917732, 0.19631191947214144, 0.2174981643883065, 0.19520924804057704, 0.19598404262508584, 0.18396969015625342, 0.18612147229137166, 0.18517537599147238, 0.8856055410695953, 0.1670557324344476, 0.8368596087322189, 0.8436385097376322, 0.8912841263690393, 0.8947753156261895, 0.8588835393419383, 0.851533553040317, 0.20966216501723933, 0.15504869507750096, 0.8433294130433883, 0.8436479962982408, 0.8482683162296778, 0.8536043853808677, 0.8761218173780815, 0.18914312298110825, 0.18325469051801324, 0.1936603612190574, 0.19372859952831, 0.20479347063556275, 0.19053844456159152, 0.1943455261954916, 0.18417599204962354, 0.18891691406148725, 0.09964227729862762, 0.09408133954616915, 0.0979702773558867, 0.08852594779641498, 0.09971456269814027, 0.11477467723659951, 0.08067348385687656, 0.10256296180541413, 0.13155598340959773]}, "mutation_prompt": null}
{"id": "22e41dc3-386e-45b7-a396-44b9738da7ea", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 8 * dim  # Changed population size for faster adaptation\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Adjusted inertia weight for varied exploration\n        self.c1 = 2.0  # Increased cognitive coefficient for enhanced individual focus\n        self.c2 = 1.3  # Decreased social coefficient to balance exploration\n        self.F = 0.85  # Adjusted mutation factor for a balanced search\n        self.CR = 0.9  # Further increased crossover rate to improve exploitation\n        self.adapt_factor = 0.98  # Altered adaptation strategy for fine-tuning dynamics\n        self.diversity_prob = 0.25  # Modified probability to maintain diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.pop_size, self.dim))  # Tighter initial velocity bounds\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.2, 1.2)  # Fine-tuned velocity clipping\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.4, 0.4, self.dim)  # Adjusted perturbation range\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A novel adaptive hybrid optimizer combining differential evolution and particle swarm optimization with probabilistic line refinement for improved convergence and robustness.", "configspace": "", "generation": 63, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.8422026875756686, 0.8316019688777077, 0.8519869328290357, 0.8297406844583839, 0.8252630810752194, 0.8277146988170878, 0.8068246858743604, 0.8561060802327902, 0.8368040280874159, 0.5717081710158031, 0.6229294567072469, 0.6577352366361608, 0.6097452113019179, 0.6248463092449099, 0.6480892213630982, 0.5853863526991877, 0.0512914350509458, 0.6345276944127677, 0.12661715743764002, 0.13553147013685352, 0.1165180416573206, 0.15148546967390686, 0.11833273301113134, 0.11262716667065764, 0.09118768173218983, 0.14706882869418092, 0.12165743506468629, 0.12200259360489396, 0.13034521545583178, 0.10944944258130584, 0.10633023239117789, 0.09527081094569545, 0.11958436269742212, 0.10133130517975841, 0.10989989219452312, 0.10750303865126443, 0.9584574983645874, 0.9456154497882113, 0.9248413138037459, 0.9394551060087084, 0.9178440572107031, 0.9247673511357778, 0.9144207782702397, 0.9195730061057308, 0.9376478922359291, 0.6852319709074105, 0.6780533300046745, 0.7108562413265345, 0.6930832315747306, 0.6473842756151248, 0.6668633835109659, 0.64220068456561, 0.6802151366784446, 0.698301550023128, 0.8284517086601723, 0.8319853512761421, 0.848700148364309, 0.19309996213284675, 0.8640311987671301, 0.8237765327623953, 0.7548692240966136, 0.7386572483314423, 0.8061550552153522, 0.6932523924834011, 0.6326694635926952, 0.5702079409903438, 0.504380399590584, 0.12794219324437095, 0.6326230014369127, 0.6645992326448668, 0.6458071418537177, 0.6824412135078085, 0.6043996176797476, 0.5329321711330159, 0.5621157612975026, 0.5799416763180532, 0.6787042232568141, 0.6327755902918872, 0.6245389618384289, 0.594169038943976, 0.6159025368644813, 0.2142937207523753, 0.5471077190497382, 0.34075658145661114, 0.06300005442848433, 0.32213183089088593, 0.2642637831740825, 0.5790571789927872, 0.2219122676957993, 0.30282947269926586, 0.27733961317035494, 0.3025133376612158, 0.40151213893255033, 0.22581234342655665, 0.12018211681647095, 0.16096111360077414, 0.19341753830233344, 0.4028576817096069, 0.4815084195410494, 0.0971570659457186, 0.11809561294884408, 0.14606350116883315, 0.302776137134796, 0.462988492103911, 0.34443607346144123, 0.12731332407030782, 0.1692466283912818, 0.21420574580174156, 0.25821731821921967, 0.37170899358653164, 0.3209911039463592, 0.20206573914765158, 0.15242447640139722, 0.3654460569911646, 0.0796097810397487, 0.10677503213591588, 0.3671365836218843, 0.7289913375444261, 0.7021916146005962, 0.7667444024290355, 0.6654456240892526, 0.7677149592326706, 0.774739243646891, 0.6856674927873443, 0.7484678961515467, 0.7923371581346985, 0.10519973895126877, 0.13636345543025197, 0.09069979364325631, 0.11397311546275801, 0.14986323712414085, 0.10092383413138228, 0.12178337409989903, 0.13995936282413945, 0.11625146899098693, 0.24031191767279736, 0.2831384168733655, 0.2512288845549715, 0.21349208283147814, 0.2709742534134405, 0.253204641108837, 0.3065697933836059, 0.2569032502330555, 0.21508329618225674, 0.39468858929153916, 0.44493785886825876, 0.3412214442304601, 0.4022518625501722, 0.41978764058825146, 0.34803590937855267, 0.26225525808833394, 0.3355335156396261, 0.5077708211963312, 0.3112174627536882, 0.27900801700448374, 0.21404165006284892, 0.27762550591535406, 0.28627741444079047, 0.2788592224413342, 0.2328027262841742, 0.34512107931937674, 0.2545199493596185, 0.22867202164916411, 0.2536000096249822, 0.247559824187208, 0.23364220594619622, 0.21887149137225992, 0.25138452113105114, 0.22421342801936184, 0.22082035780942944, 0.26193760881573214, 0.6917708034846162, 0.19789960153376596, 0.19597016243354393, 0.1824361653717258, 0.19096904756917732, 0.19631191947214144, 0.2174981643883065, 0.19520924804057704, 0.19598404262508584, 0.18396969015625342, 0.18612147229137166, 0.18517537599147238, 0.8856055410695953, 0.1670557324344476, 0.8368596087322189, 0.8436385097376322, 0.8912841263690393, 0.8947753156261895, 0.8588835393419383, 0.851533553040317, 0.20966216501723933, 0.15504869507750096, 0.8433294130433883, 0.8436479962982408, 0.8482683162296778, 0.8536043853808677, 0.8761218173780815, 0.18914312298110825, 0.18325469051801324, 0.1936603612190574, 0.19372859952831, 0.20479347063556275, 0.19053844456159152, 0.1943455261954916, 0.18417599204962354, 0.18891691406148725, 0.09964227729862762, 0.09408133954616915, 0.0979702773558867, 0.08852594779641498, 0.09971456269814027, 0.11477467723659951, 0.08067348385687656, 0.10256296180541413, 0.13155598340959773]}, "mutation_prompt": null}
{"id": "38db1f74-da43-41c0-b3c4-dd0ef7e6faf4", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 9 * dim  # Adjusted population size for better exploration\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.7  # Increased inertia weight for better exploration\n        self.c1 = 1.8  # Modified cognitive coefficient for balanced focus\n        self.c2 = 1.5  # Modified social coefficient for better social influence\n        self.F = 0.9  # Adjusted mutation factor for diverse search\n        self.CR = 0.85  # Revised crossover rate for exploration/exploitation balance\n        self.adapt_factor = 0.95  # Updated adaptation strategy for parameter dynamics\n        self.diversity_prob = 0.3  # Increased probability to maintain diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.4, 0.4, (self.pop_size, self.dim))  # Modified initial velocity bounds\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.5, 1.5)  # Extended velocity clipping\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.5, 0.5, self.dim)  # Broader perturbation range\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A refined hybrid optimizer integrating differential evolution with particle swarm optimization, leveraging adaptive parameter tuning and random elite replacement for enhanced global exploration and convergence.", "configspace": "", "generation": 81, "fitness": 0.3979895056645063, "feedback": "The algorithm RefinedAdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.27.", "error": "", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.8366875745528369, 0.8524843922113756, 0.8572418033545093, 0.8286028881107401, 0.8413085939506187, 0.8595434081904751, 0.8287187730620963, 0.8306762887838015, 0.847057018926825, 0.61356155398069, 0.626651721716156, 0.6330768552496306, 0.6364430327463418, 0.6789913982234388, 0.7008289564918404, 0.6237838494912784, 0.6559552482381128, 0.6540950343119896, 0.09340905113356346, 0.14817137220857024, 0.13615902764510268, 0.11071802834714928, 0.12269390960075088, 0.17351075435982255, 0.09380836646289081, 0.15563511974526012, 0.1253101315527867, 0.10440680716771311, 0.13582311748329157, 0.08883039453852948, 0.12940582657138167, 0.10673595878866526, 0.15032719620636303, 0.10164669422425121, 0.11345688407421839, 0.10521323700417617, 0.9404097938130264, 0.9349966805477382, 0.9287621813154956, 0.9521746324853849, 0.9309700913376601, 0.9371911085811105, 0.9553960715288246, 0.9191838031231665, 0.9348660312737643, 0.6714288623863167, 0.7029532431876668, 0.6756226396508482, 0.6370610197478338, 0.6762329551736139, 0.6841869426559604, 0.6376992678647166, 0.6613816327012847, 0.6848942353947611, 0.7912582165743661, 0.35078487461539054, 0.22664632519647554, 0.2698866697477631, 0.8707542741100165, 0.20946674367104157, 0.2278380061651798, 0.2278842279957125, 0.8615858355430982, 0.5698370306953975, 0.7503014173034062, 0.6020970364116904, 0.12751969418275422, 0.7340264098565754, 0.6700432532787071, 0.5806667102660592, 0.5302171974058438, 0.6293557459768142, 0.6182832702748207, 0.6509940446001086, 0.5373441533669074, 0.6023224009719916, 0.7290640578853855, 0.6015667904397521, 0.7094079444703212, 0.6851510592906432, 0.5911206940794527, 0.2602789481904322, 0.08409585126109143, 0.42280640674199543, 0.060660311643027987, 0.16466884755595834, 0.452726010597544, 0.1837158680363331, 0.1984864019603143, 0.37813297344214125, 0.2597771393490249, 0.1911675391839116, 0.2943028204469995, 0.21343348747842106, 0.2842650378604511, 0.19900856259730404, 0.378473343964001, 0.31525087451151046, 0.5023124904719016, 0.28713815878127336, 0.1390228761933, 0.22015176826749727, 0.1565247843821449, 0.07226664176393827, 0.49629104477778363, 0.21601423251497187, 0.3515077057892464, 0.16630353109863405, 0.2682842411979306, 0.47576706968056737, 0.2251147164989219, 0.3359912383216179, 0.2094044084217772, 0.2195301140682403, 0.2046860508095053, 0.38840446661495875, 0.37640990554121767, 0.7740526392080043, 0.6827018114222363, 0.6863455403874765, 0.6677949596315056, 0.7041623876785426, 0.678855272842174, 0.6566182349133427, 0.6011365366729489, 0.643074781281135, 0.17012793046809405, 0.15050582338279328, 0.0918893718889745, 0.11834353629814154, 0.0941532861555564, 0.150369060960018, 0.15201336765461404, 0.15592182804643384, 0.13503210783873965, 0.20404897527444477, 0.22570404625412221, 0.17908468866267102, 0.4354968355126796, 0.34551384934713414, 0.3187892569068965, 0.304816052095361, 0.3053520870082501, 0.21647306236223374, 0.32818127597562896, 0.39390810431815537, 0.36306751149061256, 0.4643742989744778, 0.3230327180022471, 0.3371869186120203, 0.410846729777265, 0.3662209265672438, 0.4581453670597695, 0.28966425300529963, 0.2553276593155439, 0.23560670509509984, 0.2535680022931104, 0.2787724086772809, 0.4468076826320042, 0.278309274666826, 0.3411385588304655, 0.33866661217446103, 0.2743413468836078, 0.22269287690053896, 0.2371726447833592, 0.25672903525026447, 0.2788863213866668, 0.2362426121319785, 0.21772497328656604, 0.28059654545444224, 0.24371480498000342, 0.1891717276640198, 0.20041512110450632, 0.19231581960140998, 0.20639162776144304, 0.1908832720641016, 0.2012437008737934, 0.18409886683696663, 0.2031963193281049, 0.203235360600449, 0.15738642704043648, 0.17019933367472517, 0.1516459978345478, 0.1783225301742637, 0.1990997540231474, 0.9041977716293585, 0.8816937099158622, 0.8944924555498421, 0.16711775257823414, 0.878683545761698, 0.8427176713508374, 0.8411825862402453, 0.862562643750312, 0.21073117063620217, 0.15226806388480185, 0.1667355789905618, 0.10392345588427976, 0.8560555861239743, 0.19482429992225725, 0.18603401199161185, 0.1955135095649756, 0.20231381067516252, 0.204381988734877, 0.1798485499257687, 0.21651273301844054, 0.1806624596741867, 0.21933278343757434, 0.09403877099970048, 0.10292292392731384, 0.0993345059419436, 0.09082729015593627, 0.09473054337126141, 0.08560175510137125, 0.09021437682831057, 0.09590457130133767, 0.1092815735357533]}, "mutation_prompt": null}
{"id": "8efe0a6b-d359-424b-942b-e3e01595147c", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 8 * dim  # Changed population size for faster adaptation\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Adjusted inertia weight for varied exploration\n        self.c1 = 2.0  # Increased cognitive coefficient for enhanced individual focus\n        self.c2 = 1.3  # Decreased social coefficient to balance exploration\n        self.F = 0.85  # Adjusted mutation factor for a balanced search\n        self.CR = 0.9  # Further increased crossover rate to improve exploitation\n        self.adapt_factor = 0.98  # Altered adaptation strategy for fine-tuning dynamics\n        self.diversity_prob = 0.25  # Modified probability to maintain diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.pop_size, self.dim))  # Tighter initial velocity bounds\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.2, 1.2)  # Fine-tuned velocity clipping\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.4, 0.4, self.dim)  # Adjusted perturbation range\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A novel adaptive hybrid optimizer combining differential evolution and particle swarm optimization with probabilistic line refinement for improved convergence and robustness.", "configspace": "", "generation": 63, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.8422026875756686, 0.8316019688777077, 0.8519869328290357, 0.8297406844583839, 0.8252630810752194, 0.8277146988170878, 0.8068246858743604, 0.8561060802327902, 0.8368040280874159, 0.5717081710158031, 0.6229294567072469, 0.6577352366361608, 0.6097452113019179, 0.6248463092449099, 0.6480892213630982, 0.5853863526991877, 0.0512914350509458, 0.6345276944127677, 0.12661715743764002, 0.13553147013685352, 0.1165180416573206, 0.15148546967390686, 0.11833273301113134, 0.11262716667065764, 0.09118768173218983, 0.14706882869418092, 0.12165743506468629, 0.12200259360489396, 0.13034521545583178, 0.10944944258130584, 0.10633023239117789, 0.09527081094569545, 0.11958436269742212, 0.10133130517975841, 0.10989989219452312, 0.10750303865126443, 0.9584574983645874, 0.9456154497882113, 0.9248413138037459, 0.9394551060087084, 0.9178440572107031, 0.9247673511357778, 0.9144207782702397, 0.9195730061057308, 0.9376478922359291, 0.6852319709074105, 0.6780533300046745, 0.7108562413265345, 0.6930832315747306, 0.6473842756151248, 0.6668633835109659, 0.64220068456561, 0.6802151366784446, 0.698301550023128, 0.8284517086601723, 0.8319853512761421, 0.848700148364309, 0.19309996213284675, 0.8640311987671301, 0.8237765327623953, 0.7548692240966136, 0.7386572483314423, 0.8061550552153522, 0.6932523924834011, 0.6326694635926952, 0.5702079409903438, 0.504380399590584, 0.12794219324437095, 0.6326230014369127, 0.6645992326448668, 0.6458071418537177, 0.6824412135078085, 0.6043996176797476, 0.5329321711330159, 0.5621157612975026, 0.5799416763180532, 0.6787042232568141, 0.6327755902918872, 0.6245389618384289, 0.594169038943976, 0.6159025368644813, 0.2142937207523753, 0.5471077190497382, 0.34075658145661114, 0.06300005442848433, 0.32213183089088593, 0.2642637831740825, 0.5790571789927872, 0.2219122676957993, 0.30282947269926586, 0.27733961317035494, 0.3025133376612158, 0.40151213893255033, 0.22581234342655665, 0.12018211681647095, 0.16096111360077414, 0.19341753830233344, 0.4028576817096069, 0.4815084195410494, 0.0971570659457186, 0.11809561294884408, 0.14606350116883315, 0.302776137134796, 0.462988492103911, 0.34443607346144123, 0.12731332407030782, 0.1692466283912818, 0.21420574580174156, 0.25821731821921967, 0.37170899358653164, 0.3209911039463592, 0.20206573914765158, 0.15242447640139722, 0.3654460569911646, 0.0796097810397487, 0.10677503213591588, 0.3671365836218843, 0.7289913375444261, 0.7021916146005962, 0.7667444024290355, 0.6654456240892526, 0.7677149592326706, 0.774739243646891, 0.6856674927873443, 0.7484678961515467, 0.7923371581346985, 0.10519973895126877, 0.13636345543025197, 0.09069979364325631, 0.11397311546275801, 0.14986323712414085, 0.10092383413138228, 0.12178337409989903, 0.13995936282413945, 0.11625146899098693, 0.24031191767279736, 0.2831384168733655, 0.2512288845549715, 0.21349208283147814, 0.2709742534134405, 0.253204641108837, 0.3065697933836059, 0.2569032502330555, 0.21508329618225674, 0.39468858929153916, 0.44493785886825876, 0.3412214442304601, 0.4022518625501722, 0.41978764058825146, 0.34803590937855267, 0.26225525808833394, 0.3355335156396261, 0.5077708211963312, 0.3112174627536882, 0.27900801700448374, 0.21404165006284892, 0.27762550591535406, 0.28627741444079047, 0.2788592224413342, 0.2328027262841742, 0.34512107931937674, 0.2545199493596185, 0.22867202164916411, 0.2536000096249822, 0.247559824187208, 0.23364220594619622, 0.21887149137225992, 0.25138452113105114, 0.22421342801936184, 0.22082035780942944, 0.26193760881573214, 0.6917708034846162, 0.19789960153376596, 0.19597016243354393, 0.1824361653717258, 0.19096904756917732, 0.19631191947214144, 0.2174981643883065, 0.19520924804057704, 0.19598404262508584, 0.18396969015625342, 0.18612147229137166, 0.18517537599147238, 0.8856055410695953, 0.1670557324344476, 0.8368596087322189, 0.8436385097376322, 0.8912841263690393, 0.8947753156261895, 0.8588835393419383, 0.851533553040317, 0.20966216501723933, 0.15504869507750096, 0.8433294130433883, 0.8436479962982408, 0.8482683162296778, 0.8536043853808677, 0.8761218173780815, 0.18914312298110825, 0.18325469051801324, 0.1936603612190574, 0.19372859952831, 0.20479347063556275, 0.19053844456159152, 0.1943455261954916, 0.18417599204962354, 0.18891691406148725, 0.09964227729862762, 0.09408133954616915, 0.0979702773558867, 0.08852594779641498, 0.09971456269814027, 0.11477467723659951, 0.08067348385687656, 0.10256296180541413, 0.13155598340959773]}, "mutation_prompt": null}
{"id": "481e0b42-626b-4aee-897a-e3936db530bf", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 8 * dim  # Changed population size for faster adaptation\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Adjusted inertia weight for varied exploration\n        self.c1 = 2.0  # Increased cognitive coefficient for enhanced individual focus\n        self.c2 = 1.3  # Decreased social coefficient to balance exploration\n        self.F = 0.85  # Adjusted mutation factor for a balanced search\n        self.CR = 0.9  # Further increased crossover rate to improve exploitation\n        self.adapt_factor = 0.98  # Altered adaptation strategy for fine-tuning dynamics\n        self.diversity_prob = 0.25  # Modified probability to maintain diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.pop_size, self.dim))  # Tighter initial velocity bounds\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.2, 1.2)  # Fine-tuned velocity clipping\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.4, 0.4, self.dim)  # Adjusted perturbation range\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A novel adaptive hybrid optimizer combining differential evolution and particle swarm optimization with probabilistic line refinement for improved convergence and robustness.", "configspace": "", "generation": 63, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.8422026875756686, 0.8316019688777077, 0.8519869328290357, 0.8297406844583839, 0.8252630810752194, 0.8277146988170878, 0.8068246858743604, 0.8561060802327902, 0.8368040280874159, 0.5717081710158031, 0.6229294567072469, 0.6577352366361608, 0.6097452113019179, 0.6248463092449099, 0.6480892213630982, 0.5853863526991877, 0.0512914350509458, 0.6345276944127677, 0.12661715743764002, 0.13553147013685352, 0.1165180416573206, 0.15148546967390686, 0.11833273301113134, 0.11262716667065764, 0.09118768173218983, 0.14706882869418092, 0.12165743506468629, 0.12200259360489396, 0.13034521545583178, 0.10944944258130584, 0.10633023239117789, 0.09527081094569545, 0.11958436269742212, 0.10133130517975841, 0.10989989219452312, 0.10750303865126443, 0.9584574983645874, 0.9456154497882113, 0.9248413138037459, 0.9394551060087084, 0.9178440572107031, 0.9247673511357778, 0.9144207782702397, 0.9195730061057308, 0.9376478922359291, 0.6852319709074105, 0.6780533300046745, 0.7108562413265345, 0.6930832315747306, 0.6473842756151248, 0.6668633835109659, 0.64220068456561, 0.6802151366784446, 0.698301550023128, 0.8284517086601723, 0.8319853512761421, 0.848700148364309, 0.19309996213284675, 0.8640311987671301, 0.8237765327623953, 0.7548692240966136, 0.7386572483314423, 0.8061550552153522, 0.6932523924834011, 0.6326694635926952, 0.5702079409903438, 0.504380399590584, 0.12794219324437095, 0.6326230014369127, 0.6645992326448668, 0.6458071418537177, 0.6824412135078085, 0.6043996176797476, 0.5329321711330159, 0.5621157612975026, 0.5799416763180532, 0.6787042232568141, 0.6327755902918872, 0.6245389618384289, 0.594169038943976, 0.6159025368644813, 0.2142937207523753, 0.5471077190497382, 0.34075658145661114, 0.06300005442848433, 0.32213183089088593, 0.2642637831740825, 0.5790571789927872, 0.2219122676957993, 0.30282947269926586, 0.27733961317035494, 0.3025133376612158, 0.40151213893255033, 0.22581234342655665, 0.12018211681647095, 0.16096111360077414, 0.19341753830233344, 0.4028576817096069, 0.4815084195410494, 0.0971570659457186, 0.11809561294884408, 0.14606350116883315, 0.302776137134796, 0.462988492103911, 0.34443607346144123, 0.12731332407030782, 0.1692466283912818, 0.21420574580174156, 0.25821731821921967, 0.37170899358653164, 0.3209911039463592, 0.20206573914765158, 0.15242447640139722, 0.3654460569911646, 0.0796097810397487, 0.10677503213591588, 0.3671365836218843, 0.7289913375444261, 0.7021916146005962, 0.7667444024290355, 0.6654456240892526, 0.7677149592326706, 0.774739243646891, 0.6856674927873443, 0.7484678961515467, 0.7923371581346985, 0.10519973895126877, 0.13636345543025197, 0.09069979364325631, 0.11397311546275801, 0.14986323712414085, 0.10092383413138228, 0.12178337409989903, 0.13995936282413945, 0.11625146899098693, 0.24031191767279736, 0.2831384168733655, 0.2512288845549715, 0.21349208283147814, 0.2709742534134405, 0.253204641108837, 0.3065697933836059, 0.2569032502330555, 0.21508329618225674, 0.39468858929153916, 0.44493785886825876, 0.3412214442304601, 0.4022518625501722, 0.41978764058825146, 0.34803590937855267, 0.26225525808833394, 0.3355335156396261, 0.5077708211963312, 0.3112174627536882, 0.27900801700448374, 0.21404165006284892, 0.27762550591535406, 0.28627741444079047, 0.2788592224413342, 0.2328027262841742, 0.34512107931937674, 0.2545199493596185, 0.22867202164916411, 0.2536000096249822, 0.247559824187208, 0.23364220594619622, 0.21887149137225992, 0.25138452113105114, 0.22421342801936184, 0.22082035780942944, 0.26193760881573214, 0.6917708034846162, 0.19789960153376596, 0.19597016243354393, 0.1824361653717258, 0.19096904756917732, 0.19631191947214144, 0.2174981643883065, 0.19520924804057704, 0.19598404262508584, 0.18396969015625342, 0.18612147229137166, 0.18517537599147238, 0.8856055410695953, 0.1670557324344476, 0.8368596087322189, 0.8436385097376322, 0.8912841263690393, 0.8947753156261895, 0.8588835393419383, 0.851533553040317, 0.20966216501723933, 0.15504869507750096, 0.8433294130433883, 0.8436479962982408, 0.8482683162296778, 0.8536043853808677, 0.8761218173780815, 0.18914312298110825, 0.18325469051801324, 0.1936603612190574, 0.19372859952831, 0.20479347063556275, 0.19053844456159152, 0.1943455261954916, 0.18417599204962354, 0.18891691406148725, 0.09964227729862762, 0.09408133954616915, 0.0979702773558867, 0.08852594779641498, 0.09971456269814027, 0.11477467723659951, 0.08067348385687656, 0.10256296180541413, 0.13155598340959773]}, "mutation_prompt": null}
{"id": "82587790-481d-4215-aaf5-9007e061308a", "solution": "import numpy as np\n\nclass EnhancedChaoticDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 8 * dim\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.65  # Slightly increased inertia weight for exploration\n        self.c1 = 1.8  # Balanced cognitive coefficient\n        self.c2 = 1.5  # Balanced social coefficient\n        self.F = 0.9  # Enhanced mutation factor for diversity\n        self.CR = 0.85  # High crossover rate for exploitation\n        self.adapt_factor = 0.95  # Adjusted adaptation strategy\n        self.diversity_prob = 0.2  # Probabilistic diversity maintenance\n        self.chaos_factor = 0.7  # Introduced chaos factor for perturbations\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.4, 0.4, (self.pop_size, self.dim))  # Broader initial velocity range\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n\n                velocities[i] = np.clip(velocities[i], -1.0, 1.0)  # Modified velocity clipping\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.5, 0.5, self.dim) * self.chaos_factor  # Introduced chaotic perturbation\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "EnhancedChaoticDEPSOHybridOptimizer", "description": "An enhanced adaptive hybrid optimizer integrating differential evolution, particle swarm optimization, and chaotic perturbations for improved global and local search efficiency.", "configspace": "", "generation": 84, "fitness": 0.38311164078442494, "feedback": "The algorithm EnhancedChaoticDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38 with standard deviation 0.28.", "error": "", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.8750823404944366, 0.8385760254353575, 0.8676565661432691, 0.8560906082036157, 0.8508301219400312, 0.8550861102055847, 0.8673510902286076, 0.8599521693498686, 0.8457397267459671, 0.6809842146150313, 0.6496661349415511, 0.6949399619915135, 0.6846801048001275, 0.716937165087344, 0.6947038861572044, 0.6675132470128282, 0.6200708049290767, 0.5519689431389395, 0.09570397205323466, 0.1390869033979819, 0.14315754959712046, 0.10558024392480225, 0.15319429793600015, 0.13674274909802697, 0.11684380122325744, 0.14860885206559815, 0.11344376749695062, 0.10000021303737994, 0.1087906244227228, 0.09641659822523874, 0.13933608726324254, 0.09322506148902121, 0.09143070752002025, 0.11005738543855459, 0.10764240386776469, 0.11441004448264358, 0.9459808194634897, 0.9217107904348751, 0.8924124072938906, 0.9404122034446295, 0.8830597767733296, 0.9237409099267655, 0.9410945698722148, 0.9169543314388906, 0.9392894920922559, 0.6640086411093107, 0.728269154412177, 0.7249571547586572, 0.6976771526841588, 0.6859036976571686, 0.7478488919505779, 0.7114858390036539, 0.6201019211233394, 0.7460493466446755, 0.8401946600106212, 0.21874224750140814, 0.2258744872989985, 0.8630810314672938, 0.8544152014835041, 0.2077765839607182, 0.7799944292776809, 0.8421947270067571, 0.24395716655233424, 0.7166075115551782, 0.6492530388749062, 0.6812096348011245, 0.7267885049464544, 0.13023942721089732, 0.1275334260107065, 0.6668241739115436, 0.12622730243068203, 0.6181548294441254, 0.6160005739516998, 0.572546783273258, 0.12678271440882016, 0.7152046775810217, 0.6423971955839781, 0.13366623752560025, 0.6781186776906932, 0.6912533110971767, 0.6686827070488197, 0.11075925450663748, 0.1082848715705752, 0.19821207669189944, 0.1871570204666455, 0.1579550668215044, 0.0152512196571164, 0.25233757706174686, 0.06510739699514412, 0.2033286471504565, 0.1787388896899682, 0.17138219481212413, 0.22721542235509873, 0.1798808634720428, 0.24408999958095812, 0.1644753998656785, 0.15584004808844698, 0.40808378151230584, 0.24731189071964443, 0.12102829311872687, 0.18971798660771788, 0.3220684032245493, 0.21155594168159164, 0.24075887104195748, 0.24603339312736938, 0.1520073528558007, 0.31761091911866657, 0.2419696697275926, 0.2352200696771214, 0.16546597551299214, 0.17253488076932677, 0.3543906456437905, 0.42428186245454047, 0.3660177330302553, 0.23825023965752412, 0.3849251126811707, 0.08131831257571898, 0.7158119628116169, 0.7042850635323326, 0.6242892716848503, 0.5792853312830339, 0.6286393072152838, 0.60525648350853, 0.7686681726231568, 0.6919529641389999, 0.6792486106588376, 0.12782125834348423, 0.07750161234232744, 0.13893086744847172, 0.1084620839482533, 0.15463637349199344, 0.14217686609717306, 0.13593098157994044, 0.118426003566789, 0.11140957138340168, 0.2520330753188933, 0.29021874341854514, 0.2553587503799861, 0.18680692537010657, 0.3010797525995277, 0.2281169897968418, 0.22230341354071403, 0.24105830414619567, 0.18842132410630863, 0.4286202293597663, 0.3537893993765887, 0.352340928607354, 0.4022416096673004, 0.3715521892785384, 0.3804070531449275, 0.23772909152513755, 0.2806261632567564, 0.3062656524421796, 0.31375022265914176, 0.3488486567962632, 0.23576844894510418, 0.3524194494211411, 0.2384535588829233, 0.28952491818144943, 0.22398034116028742, 0.26739707915735655, 0.19777675880122425, 0.2474843899002247, 0.2290403177244672, 0.24006139070640942, 0.2021554389563468, 0.238696326569098, 0.23660188413221295, 0.23739495123500132, 0.2469147332049091, 0.2526779566112607, 0.19481299454606227, 0.19504007805894352, 0.1821145447424244, 0.24256685066762185, 0.19737530220129307, 0.18433221588993542, 0.20320564281056608, 0.19171190417194162, 0.17240145949667296, 0.18474941783620658, 0.8840590563931978, 0.1513759171130883, 0.9136727203678174, 0.20007928715334822, 0.18337143537965062, 0.8878085380733103, 0.1667636247204195, 0.9041926433000546, 0.8754984548278302, 0.1567423685652426, 0.21043135229534404, 0.15607586965207343, 0.16645216864569978, 0.15333305520884133, 0.8519592885438516, 0.8555389363570768, 0.8706592789350929, 0.18805992794460658, 0.18712298100300784, 0.2094937502007349, 0.19901479465849092, 0.2110616455010751, 0.20227128624036217, 0.21038310712414077, 0.21811033587262119, 0.18706169088177493, 0.08548920836687135, 0.10265208468445375, 0.1222334538760873, 0.1079076738309781, 0.09593517551571329, 0.08336528361836482, 0.09996675705508207, 0.10496434602605043, 0.08330116756841466]}, "mutation_prompt": null}
{"id": "268f4494-f248-4600-a46f-7df2f2b78751", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 8 * dim  # Changed population size for faster adaptation\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Adjusted inertia weight for varied exploration\n        self.c1 = 2.0  # Increased cognitive coefficient for enhanced individual focus\n        self.c2 = 1.3  # Decreased social coefficient to balance exploration\n        self.F = 0.85  # Adjusted mutation factor for a balanced search\n        self.CR = 0.9  # Further increased crossover rate to improve exploitation\n        self.adapt_factor = 0.98  # Altered adaptation strategy for fine-tuning dynamics\n        self.diversity_prob = 0.25  # Modified probability to maintain diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.pop_size, self.dim))  # Tighter initial velocity bounds\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.2, 1.2)  # Fine-tuned velocity clipping\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.4, 0.4, self.dim)  # Adjusted perturbation range\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A novel adaptive hybrid optimizer combining differential evolution and particle swarm optimization with probabilistic line refinement for improved convergence and robustness.", "configspace": "", "generation": 63, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.8422026875756686, 0.8316019688777077, 0.8519869328290357, 0.8297406844583839, 0.8252630810752194, 0.8277146988170878, 0.8068246858743604, 0.8561060802327902, 0.8368040280874159, 0.5717081710158031, 0.6229294567072469, 0.6577352366361608, 0.6097452113019179, 0.6248463092449099, 0.6480892213630982, 0.5853863526991877, 0.0512914350509458, 0.6345276944127677, 0.12661715743764002, 0.13553147013685352, 0.1165180416573206, 0.15148546967390686, 0.11833273301113134, 0.11262716667065764, 0.09118768173218983, 0.14706882869418092, 0.12165743506468629, 0.12200259360489396, 0.13034521545583178, 0.10944944258130584, 0.10633023239117789, 0.09527081094569545, 0.11958436269742212, 0.10133130517975841, 0.10989989219452312, 0.10750303865126443, 0.9584574983645874, 0.9456154497882113, 0.9248413138037459, 0.9394551060087084, 0.9178440572107031, 0.9247673511357778, 0.9144207782702397, 0.9195730061057308, 0.9376478922359291, 0.6852319709074105, 0.6780533300046745, 0.7108562413265345, 0.6930832315747306, 0.6473842756151248, 0.6668633835109659, 0.64220068456561, 0.6802151366784446, 0.698301550023128, 0.8284517086601723, 0.8319853512761421, 0.848700148364309, 0.19309996213284675, 0.8640311987671301, 0.8237765327623953, 0.7548692240966136, 0.7386572483314423, 0.8061550552153522, 0.6932523924834011, 0.6326694635926952, 0.5702079409903438, 0.504380399590584, 0.12794219324437095, 0.6326230014369127, 0.6645992326448668, 0.6458071418537177, 0.6824412135078085, 0.6043996176797476, 0.5329321711330159, 0.5621157612975026, 0.5799416763180532, 0.6787042232568141, 0.6327755902918872, 0.6245389618384289, 0.594169038943976, 0.6159025368644813, 0.2142937207523753, 0.5471077190497382, 0.34075658145661114, 0.06300005442848433, 0.32213183089088593, 0.2642637831740825, 0.5790571789927872, 0.2219122676957993, 0.30282947269926586, 0.27733961317035494, 0.3025133376612158, 0.40151213893255033, 0.22581234342655665, 0.12018211681647095, 0.16096111360077414, 0.19341753830233344, 0.4028576817096069, 0.4815084195410494, 0.0971570659457186, 0.11809561294884408, 0.14606350116883315, 0.302776137134796, 0.462988492103911, 0.34443607346144123, 0.12731332407030782, 0.1692466283912818, 0.21420574580174156, 0.25821731821921967, 0.37170899358653164, 0.3209911039463592, 0.20206573914765158, 0.15242447640139722, 0.3654460569911646, 0.0796097810397487, 0.10677503213591588, 0.3671365836218843, 0.7289913375444261, 0.7021916146005962, 0.7667444024290355, 0.6654456240892526, 0.7677149592326706, 0.774739243646891, 0.6856674927873443, 0.7484678961515467, 0.7923371581346985, 0.10519973895126877, 0.13636345543025197, 0.09069979364325631, 0.11397311546275801, 0.14986323712414085, 0.10092383413138228, 0.12178337409989903, 0.13995936282413945, 0.11625146899098693, 0.24031191767279736, 0.2831384168733655, 0.2512288845549715, 0.21349208283147814, 0.2709742534134405, 0.253204641108837, 0.3065697933836059, 0.2569032502330555, 0.21508329618225674, 0.39468858929153916, 0.44493785886825876, 0.3412214442304601, 0.4022518625501722, 0.41978764058825146, 0.34803590937855267, 0.26225525808833394, 0.3355335156396261, 0.5077708211963312, 0.3112174627536882, 0.27900801700448374, 0.21404165006284892, 0.27762550591535406, 0.28627741444079047, 0.2788592224413342, 0.2328027262841742, 0.34512107931937674, 0.2545199493596185, 0.22867202164916411, 0.2536000096249822, 0.247559824187208, 0.23364220594619622, 0.21887149137225992, 0.25138452113105114, 0.22421342801936184, 0.22082035780942944, 0.26193760881573214, 0.6917708034846162, 0.19789960153376596, 0.19597016243354393, 0.1824361653717258, 0.19096904756917732, 0.19631191947214144, 0.2174981643883065, 0.19520924804057704, 0.19598404262508584, 0.18396969015625342, 0.18612147229137166, 0.18517537599147238, 0.8856055410695953, 0.1670557324344476, 0.8368596087322189, 0.8436385097376322, 0.8912841263690393, 0.8947753156261895, 0.8588835393419383, 0.851533553040317, 0.20966216501723933, 0.15504869507750096, 0.8433294130433883, 0.8436479962982408, 0.8482683162296778, 0.8536043853808677, 0.8761218173780815, 0.18914312298110825, 0.18325469051801324, 0.1936603612190574, 0.19372859952831, 0.20479347063556275, 0.19053844456159152, 0.1943455261954916, 0.18417599204962354, 0.18891691406148725, 0.09964227729862762, 0.09408133954616915, 0.0979702773558867, 0.08852594779641498, 0.09971456269814027, 0.11477467723659951, 0.08067348385687656, 0.10256296180541413, 0.13155598340959773]}, "mutation_prompt": null}
{"id": "bacbe838-0e5f-46e9-8aae-075fa226c35c", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 8 * dim  # Changed population size for faster adaptation\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Adjusted inertia weight for varied exploration\n        self.c1 = 2.0  # Increased cognitive coefficient for enhanced individual focus\n        self.c2 = 1.3  # Decreased social coefficient to balance exploration\n        self.F = 0.85  # Adjusted mutation factor for a balanced search\n        self.CR = 0.9  # Further increased crossover rate to improve exploitation\n        self.adapt_factor = 0.98  # Altered adaptation strategy for fine-tuning dynamics\n        self.diversity_prob = 0.25  # Modified probability to maintain diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.pop_size, self.dim))  # Tighter initial velocity bounds\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.2, 1.2)  # Fine-tuned velocity clipping\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.4, 0.4, self.dim)  # Adjusted perturbation range\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A novel adaptive hybrid optimizer combining differential evolution and particle swarm optimization with probabilistic line refinement for improved convergence and robustness.", "configspace": "", "generation": 63, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.8422026875756686, 0.8316019688777077, 0.8519869328290357, 0.8297406844583839, 0.8252630810752194, 0.8277146988170878, 0.8068246858743604, 0.8561060802327902, 0.8368040280874159, 0.5717081710158031, 0.6229294567072469, 0.6577352366361608, 0.6097452113019179, 0.6248463092449099, 0.6480892213630982, 0.5853863526991877, 0.0512914350509458, 0.6345276944127677, 0.12661715743764002, 0.13553147013685352, 0.1165180416573206, 0.15148546967390686, 0.11833273301113134, 0.11262716667065764, 0.09118768173218983, 0.14706882869418092, 0.12165743506468629, 0.12200259360489396, 0.13034521545583178, 0.10944944258130584, 0.10633023239117789, 0.09527081094569545, 0.11958436269742212, 0.10133130517975841, 0.10989989219452312, 0.10750303865126443, 0.9584574983645874, 0.9456154497882113, 0.9248413138037459, 0.9394551060087084, 0.9178440572107031, 0.9247673511357778, 0.9144207782702397, 0.9195730061057308, 0.9376478922359291, 0.6852319709074105, 0.6780533300046745, 0.7108562413265345, 0.6930832315747306, 0.6473842756151248, 0.6668633835109659, 0.64220068456561, 0.6802151366784446, 0.698301550023128, 0.8284517086601723, 0.8319853512761421, 0.848700148364309, 0.19309996213284675, 0.8640311987671301, 0.8237765327623953, 0.7548692240966136, 0.7386572483314423, 0.8061550552153522, 0.6932523924834011, 0.6326694635926952, 0.5702079409903438, 0.504380399590584, 0.12794219324437095, 0.6326230014369127, 0.6645992326448668, 0.6458071418537177, 0.6824412135078085, 0.6043996176797476, 0.5329321711330159, 0.5621157612975026, 0.5799416763180532, 0.6787042232568141, 0.6327755902918872, 0.6245389618384289, 0.594169038943976, 0.6159025368644813, 0.2142937207523753, 0.5471077190497382, 0.34075658145661114, 0.06300005442848433, 0.32213183089088593, 0.2642637831740825, 0.5790571789927872, 0.2219122676957993, 0.30282947269926586, 0.27733961317035494, 0.3025133376612158, 0.40151213893255033, 0.22581234342655665, 0.12018211681647095, 0.16096111360077414, 0.19341753830233344, 0.4028576817096069, 0.4815084195410494, 0.0971570659457186, 0.11809561294884408, 0.14606350116883315, 0.302776137134796, 0.462988492103911, 0.34443607346144123, 0.12731332407030782, 0.1692466283912818, 0.21420574580174156, 0.25821731821921967, 0.37170899358653164, 0.3209911039463592, 0.20206573914765158, 0.15242447640139722, 0.3654460569911646, 0.0796097810397487, 0.10677503213591588, 0.3671365836218843, 0.7289913375444261, 0.7021916146005962, 0.7667444024290355, 0.6654456240892526, 0.7677149592326706, 0.774739243646891, 0.6856674927873443, 0.7484678961515467, 0.7923371581346985, 0.10519973895126877, 0.13636345543025197, 0.09069979364325631, 0.11397311546275801, 0.14986323712414085, 0.10092383413138228, 0.12178337409989903, 0.13995936282413945, 0.11625146899098693, 0.24031191767279736, 0.2831384168733655, 0.2512288845549715, 0.21349208283147814, 0.2709742534134405, 0.253204641108837, 0.3065697933836059, 0.2569032502330555, 0.21508329618225674, 0.39468858929153916, 0.44493785886825876, 0.3412214442304601, 0.4022518625501722, 0.41978764058825146, 0.34803590937855267, 0.26225525808833394, 0.3355335156396261, 0.5077708211963312, 0.3112174627536882, 0.27900801700448374, 0.21404165006284892, 0.27762550591535406, 0.28627741444079047, 0.2788592224413342, 0.2328027262841742, 0.34512107931937674, 0.2545199493596185, 0.22867202164916411, 0.2536000096249822, 0.247559824187208, 0.23364220594619622, 0.21887149137225992, 0.25138452113105114, 0.22421342801936184, 0.22082035780942944, 0.26193760881573214, 0.6917708034846162, 0.19789960153376596, 0.19597016243354393, 0.1824361653717258, 0.19096904756917732, 0.19631191947214144, 0.2174981643883065, 0.19520924804057704, 0.19598404262508584, 0.18396969015625342, 0.18612147229137166, 0.18517537599147238, 0.8856055410695953, 0.1670557324344476, 0.8368596087322189, 0.8436385097376322, 0.8912841263690393, 0.8947753156261895, 0.8588835393419383, 0.851533553040317, 0.20966216501723933, 0.15504869507750096, 0.8433294130433883, 0.8436479962982408, 0.8482683162296778, 0.8536043853808677, 0.8761218173780815, 0.18914312298110825, 0.18325469051801324, 0.1936603612190574, 0.19372859952831, 0.20479347063556275, 0.19053844456159152, 0.1943455261954916, 0.18417599204962354, 0.18891691406148725, 0.09964227729862762, 0.09408133954616915, 0.0979702773558867, 0.08852594779641498, 0.09971456269814027, 0.11477467723659951, 0.08067348385687656, 0.10256296180541413, 0.13155598340959773]}, "mutation_prompt": null}
{"id": "0e8e29cc-df4a-4c11-8768-1d8433ea1c17", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 8 * dim  # Changed population size for faster adaptation\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Adjusted inertia weight for varied exploration\n        self.c1 = 2.0  # Increased cognitive coefficient for enhanced individual focus\n        self.c2 = 1.3  # Decreased social coefficient to balance exploration\n        self.F = 0.85  # Adjusted mutation factor for a balanced search\n        self.CR = 0.9  # Further increased crossover rate to improve exploitation\n        self.adapt_factor = 0.98  # Altered adaptation strategy for fine-tuning dynamics\n        self.diversity_prob = 0.25  # Modified probability to maintain diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.pop_size, self.dim))  # Tighter initial velocity bounds\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.2, 1.2)  # Fine-tuned velocity clipping\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.4, 0.4, self.dim)  # Adjusted perturbation range\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A novel adaptive hybrid optimizer combining differential evolution and particle swarm optimization with probabilistic line refinement for improved convergence and robustness.", "configspace": "", "generation": 63, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.8422026875756686, 0.8316019688777077, 0.8519869328290357, 0.8297406844583839, 0.8252630810752194, 0.8277146988170878, 0.8068246858743604, 0.8561060802327902, 0.8368040280874159, 0.5717081710158031, 0.6229294567072469, 0.6577352366361608, 0.6097452113019179, 0.6248463092449099, 0.6480892213630982, 0.5853863526991877, 0.0512914350509458, 0.6345276944127677, 0.12661715743764002, 0.13553147013685352, 0.1165180416573206, 0.15148546967390686, 0.11833273301113134, 0.11262716667065764, 0.09118768173218983, 0.14706882869418092, 0.12165743506468629, 0.12200259360489396, 0.13034521545583178, 0.10944944258130584, 0.10633023239117789, 0.09527081094569545, 0.11958436269742212, 0.10133130517975841, 0.10989989219452312, 0.10750303865126443, 0.9584574983645874, 0.9456154497882113, 0.9248413138037459, 0.9394551060087084, 0.9178440572107031, 0.9247673511357778, 0.9144207782702397, 0.9195730061057308, 0.9376478922359291, 0.6852319709074105, 0.6780533300046745, 0.7108562413265345, 0.6930832315747306, 0.6473842756151248, 0.6668633835109659, 0.64220068456561, 0.6802151366784446, 0.698301550023128, 0.8284517086601723, 0.8319853512761421, 0.848700148364309, 0.19309996213284675, 0.8640311987671301, 0.8237765327623953, 0.7548692240966136, 0.7386572483314423, 0.8061550552153522, 0.6932523924834011, 0.6326694635926952, 0.5702079409903438, 0.504380399590584, 0.12794219324437095, 0.6326230014369127, 0.6645992326448668, 0.6458071418537177, 0.6824412135078085, 0.6043996176797476, 0.5329321711330159, 0.5621157612975026, 0.5799416763180532, 0.6787042232568141, 0.6327755902918872, 0.6245389618384289, 0.594169038943976, 0.6159025368644813, 0.2142937207523753, 0.5471077190497382, 0.34075658145661114, 0.06300005442848433, 0.32213183089088593, 0.2642637831740825, 0.5790571789927872, 0.2219122676957993, 0.30282947269926586, 0.27733961317035494, 0.3025133376612158, 0.40151213893255033, 0.22581234342655665, 0.12018211681647095, 0.16096111360077414, 0.19341753830233344, 0.4028576817096069, 0.4815084195410494, 0.0971570659457186, 0.11809561294884408, 0.14606350116883315, 0.302776137134796, 0.462988492103911, 0.34443607346144123, 0.12731332407030782, 0.1692466283912818, 0.21420574580174156, 0.25821731821921967, 0.37170899358653164, 0.3209911039463592, 0.20206573914765158, 0.15242447640139722, 0.3654460569911646, 0.0796097810397487, 0.10677503213591588, 0.3671365836218843, 0.7289913375444261, 0.7021916146005962, 0.7667444024290355, 0.6654456240892526, 0.7677149592326706, 0.774739243646891, 0.6856674927873443, 0.7484678961515467, 0.7923371581346985, 0.10519973895126877, 0.13636345543025197, 0.09069979364325631, 0.11397311546275801, 0.14986323712414085, 0.10092383413138228, 0.12178337409989903, 0.13995936282413945, 0.11625146899098693, 0.24031191767279736, 0.2831384168733655, 0.2512288845549715, 0.21349208283147814, 0.2709742534134405, 0.253204641108837, 0.3065697933836059, 0.2569032502330555, 0.21508329618225674, 0.39468858929153916, 0.44493785886825876, 0.3412214442304601, 0.4022518625501722, 0.41978764058825146, 0.34803590937855267, 0.26225525808833394, 0.3355335156396261, 0.5077708211963312, 0.3112174627536882, 0.27900801700448374, 0.21404165006284892, 0.27762550591535406, 0.28627741444079047, 0.2788592224413342, 0.2328027262841742, 0.34512107931937674, 0.2545199493596185, 0.22867202164916411, 0.2536000096249822, 0.247559824187208, 0.23364220594619622, 0.21887149137225992, 0.25138452113105114, 0.22421342801936184, 0.22082035780942944, 0.26193760881573214, 0.6917708034846162, 0.19789960153376596, 0.19597016243354393, 0.1824361653717258, 0.19096904756917732, 0.19631191947214144, 0.2174981643883065, 0.19520924804057704, 0.19598404262508584, 0.18396969015625342, 0.18612147229137166, 0.18517537599147238, 0.8856055410695953, 0.1670557324344476, 0.8368596087322189, 0.8436385097376322, 0.8912841263690393, 0.8947753156261895, 0.8588835393419383, 0.851533553040317, 0.20966216501723933, 0.15504869507750096, 0.8433294130433883, 0.8436479962982408, 0.8482683162296778, 0.8536043853808677, 0.8761218173780815, 0.18914312298110825, 0.18325469051801324, 0.1936603612190574, 0.19372859952831, 0.20479347063556275, 0.19053844456159152, 0.1943455261954916, 0.18417599204962354, 0.18891691406148725, 0.09964227729862762, 0.09408133954616915, 0.0979702773558867, 0.08852594779641498, 0.09971456269814027, 0.11477467723659951, 0.08067348385687656, 0.10256296180541413, 0.13155598340959773]}, "mutation_prompt": null}
{"id": "7c60549e-9c7d-45ad-8b93-74957c5d5482", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDEPSOChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 8 * dim\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.7  # Slightly increased inertia weight for better exploration\n        self.c1 = 1.8  # Reduced cognitive coefficient to avoid premature convergence\n        self.c2 = 1.5  # Adjusted social coefficient for improved balance between exploration and exploitation\n        self.F = 0.9  # Increased mutation factor for more aggressive search\n        self.CR = 0.85  # Slightly reduced crossover rate to maintain diversity\n        self.adapt_factor = 0.99  # Minor adaptation strategy adjustment for smoother inertia weight decay\n        self.diversity_prob = 0.2  # Lowered probability to maintain diversity but with chaotic perturbation\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.2, 1.2)\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.4, 0.4, self.dim) * (np.sin(j) + 1)  # Chaotic perturbation\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "EnhancedAdaptiveDEPSOChaoticOptimizer", "description": "An enhanced adaptive hybrid optimizer blending differential evolution, particle swarm optimization, and chaotic perturbation for improved exploration and convergence.", "configspace": "", "generation": 88, "fitness": 0.38059868109783374, "feedback": "The algorithm EnhancedAdaptiveDEPSOChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38 with standard deviation 0.25.", "error": "", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.759726825154729, 0.7198718150888785, 0.7604129870985216, 0.770619391068578, 0.7521746537891005, 0.7657552202540125, 0.7521256806629274, 0.7485530637671944, 0.7576656602214755, 0.4537191034109749, 0.528730193728526, 0.5261001272030678, 0.4514076968506081, 0.4668569628504945, 0.47534093013084067, 0.4932998476524556, 0.38179146094678873, 0.49940016764827644, 0.1471835171824155, 0.10057117279858063, 0.09719288127201076, 0.1639544816040741, 0.1210096119872649, 0.15307109108857242, 0.1340989907573763, 0.13104652006302708, 0.15116433443189448, 0.10060976216364947, 0.13086387561258872, 0.12305940944414817, 0.11431886808523972, 0.1039235578050195, 0.12313712018725487, 0.0922529395915117, 0.1036980295306823, 0.12164196723882947, 0.9574336681166807, 0.9220307626365103, 0.9373815064711459, 0.949707675480964, 0.9222655454769975, 0.9084377227279631, 0.9514713301907969, 0.9434842556322308, 0.9449423487626115, 0.5072695864363824, 0.5897694069821819, 0.586413872332757, 0.6263088230321819, 0.5663759707761475, 0.6227525413384807, 0.5948622290990809, 0.5423226848016285, 0.5607485731046419, 0.7761813062933101, 0.7577286416777791, 0.7685044240798071, 0.2509882916006644, 0.26692504951074114, 0.8369720255931618, 0.7535418797022602, 0.22725410213093078, 0.7194886460064895, 0.5048340143239972, 0.5248521132134928, 0.12748295534837706, 0.5032989899737061, 0.5279690802004315, 0.12530677384695643, 0.5569168900762279, 0.4219084465401821, 0.5602152302683645, 0.5042419741564674, 0.45619783173932815, 0.12854438723772377, 0.5540383455908204, 0.4984498721017514, 0.5032450746647354, 0.5076014565137379, 0.5231845441061352, 0.556785227971152, 0.05523601032570202, 0.4374318954314368, 0.4084222863683351, 0.13616656573868768, 0.3092521800790943, 0.017899808590454813, 0.3840720315768591, 0.3486802366194752, 0.3255569410378678, 0.4736499286569761, 0.24773586036740747, 0.19897580318499508, 0.20717253387355117, 0.09166411109602979, 0.2745096479056899, 0.2717199036404686, 0.45491744829250436, 0.3830488198537553, 0.07269197942283956, 0.2354116048212621, 0.3481719941023782, 0.19480356781588037, 0.1488771038603176, 0.17009979798509667, 0.0636730159774519, 0.14605784043723402, 0.2947285877022011, 0.32285889016714453, 0.14182195581598478, 0.20929769286604405, 0.33918846135186465, 0.19459097442307283, 0.3955803332241832, 0.25181537548341193, 0.21137043399053845, 0.18067523029655874, 0.6981955702921934, 0.6253415195678704, 0.6156873945018599, 0.6896149010533178, 0.6547471089254135, 0.6550347326209228, 0.672969833733282, 0.5867811687585427, 0.7119445578931017, 0.12995946323511776, 0.5424753828439375, 0.15941114191063466, 0.14768269260016476, 0.13308349995158386, 0.17063686397969546, 0.14584835452536404, 0.1408566337221766, 0.4293283048616108, 0.285606221689891, 0.29057614414825406, 0.17717146910924353, 0.6572748217497115, 0.22386178048328909, 0.19630183046440974, 0.37822576673327835, 0.17173457551893423, 0.24330811087839943, 0.3229540976723865, 0.4434573421674688, 0.4187682480964734, 0.4055800189165333, 0.45052750061616675, 0.41235866441176694, 0.4245188078395833, 0.44097012942257585, 0.24649275684063876, 0.23004146800729208, 0.2993686345855413, 0.2990959365568616, 0.27643711936824855, 0.27753691249057033, 0.35482473761801925, 0.18718201801705203, 0.32804343173998385, 0.2515976052194908, 0.2659164328314989, 0.22356159500316375, 0.2163218597708153, 0.5239755135315436, 0.22517394731714324, 0.19348631996032595, 0.24098328792380863, 0.25789625232197255, 0.22711528331491926, 0.20022687419667307, 0.21043160620885826, 0.18310824468670028, 0.24407865549614716, 0.18978790083545483, 0.21712860389523037, 0.21393732146970967, 0.19484568490871346, 0.21486298141503424, 0.17619196081422783, 0.18680712066643168, 0.1518918543823906, 0.8404921543829484, 0.19273855244020355, 0.18465970466018022, 0.8295129594849115, 0.8439229507594679, 0.8450884158312906, 0.8465905313288544, 0.7049307682747209, 0.20930822712232755, 0.7239483548336375, 0.7715839991995984, 0.15347972777912333, 0.10424770074353651, 0.788210024748777, 0.7331306523204197, 0.1882068858713687, 0.19486696009284976, 0.22850655272559228, 0.24857979851034295, 0.19855946547719727, 0.22451907317165543, 0.1869080357594457, 0.20428676531457468, 0.2145826801288956, 0.0993085091582161, 0.09164074670977151, 0.09541119342020432, 0.0992942952149446, 0.0911173309626776, 0.13015145600193412, 0.08904351254251264, 0.09602079184121703, 0.09450891540662343]}, "mutation_prompt": null}
{"id": "6ac8c080-cf69-4650-a369-9922b504dffe", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 8 * dim  # Changed population size for faster adaptation\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Adjusted inertia weight for varied exploration\n        self.c1 = 2.0  # Increased cognitive coefficient for enhanced individual focus\n        self.c2 = 1.3  # Decreased social coefficient to balance exploration\n        self.F = 0.85  # Adjusted mutation factor for a balanced search\n        self.CR = 0.9  # Further increased crossover rate to improve exploitation\n        self.adapt_factor = 0.98  # Altered adaptation strategy for fine-tuning dynamics\n        self.diversity_prob = 0.25  # Modified probability to maintain diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.pop_size, self.dim))  # Tighter initial velocity bounds\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.2, 1.2)  # Fine-tuned velocity clipping\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.4, 0.4, self.dim)  # Adjusted perturbation range\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A novel adaptive hybrid optimizer combining differential evolution and particle swarm optimization with probabilistic line refinement for improved convergence and robustness.", "configspace": "", "generation": 63, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.8422026875756686, 0.8316019688777077, 0.8519869328290357, 0.8297406844583839, 0.8252630810752194, 0.8277146988170878, 0.8068246858743604, 0.8561060802327902, 0.8368040280874159, 0.5717081710158031, 0.6229294567072469, 0.6577352366361608, 0.6097452113019179, 0.6248463092449099, 0.6480892213630982, 0.5853863526991877, 0.0512914350509458, 0.6345276944127677, 0.12661715743764002, 0.13553147013685352, 0.1165180416573206, 0.15148546967390686, 0.11833273301113134, 0.11262716667065764, 0.09118768173218983, 0.14706882869418092, 0.12165743506468629, 0.12200259360489396, 0.13034521545583178, 0.10944944258130584, 0.10633023239117789, 0.09527081094569545, 0.11958436269742212, 0.10133130517975841, 0.10989989219452312, 0.10750303865126443, 0.9584574983645874, 0.9456154497882113, 0.9248413138037459, 0.9394551060087084, 0.9178440572107031, 0.9247673511357778, 0.9144207782702397, 0.9195730061057308, 0.9376478922359291, 0.6852319709074105, 0.6780533300046745, 0.7108562413265345, 0.6930832315747306, 0.6473842756151248, 0.6668633835109659, 0.64220068456561, 0.6802151366784446, 0.698301550023128, 0.8284517086601723, 0.8319853512761421, 0.848700148364309, 0.19309996213284675, 0.8640311987671301, 0.8237765327623953, 0.7548692240966136, 0.7386572483314423, 0.8061550552153522, 0.6932523924834011, 0.6326694635926952, 0.5702079409903438, 0.504380399590584, 0.12794219324437095, 0.6326230014369127, 0.6645992326448668, 0.6458071418537177, 0.6824412135078085, 0.6043996176797476, 0.5329321711330159, 0.5621157612975026, 0.5799416763180532, 0.6787042232568141, 0.6327755902918872, 0.6245389618384289, 0.594169038943976, 0.6159025368644813, 0.2142937207523753, 0.5471077190497382, 0.34075658145661114, 0.06300005442848433, 0.32213183089088593, 0.2642637831740825, 0.5790571789927872, 0.2219122676957993, 0.30282947269926586, 0.27733961317035494, 0.3025133376612158, 0.40151213893255033, 0.22581234342655665, 0.12018211681647095, 0.16096111360077414, 0.19341753830233344, 0.4028576817096069, 0.4815084195410494, 0.0971570659457186, 0.11809561294884408, 0.14606350116883315, 0.302776137134796, 0.462988492103911, 0.34443607346144123, 0.12731332407030782, 0.1692466283912818, 0.21420574580174156, 0.25821731821921967, 0.37170899358653164, 0.3209911039463592, 0.20206573914765158, 0.15242447640139722, 0.3654460569911646, 0.0796097810397487, 0.10677503213591588, 0.3671365836218843, 0.7289913375444261, 0.7021916146005962, 0.7667444024290355, 0.6654456240892526, 0.7677149592326706, 0.774739243646891, 0.6856674927873443, 0.7484678961515467, 0.7923371581346985, 0.10519973895126877, 0.13636345543025197, 0.09069979364325631, 0.11397311546275801, 0.14986323712414085, 0.10092383413138228, 0.12178337409989903, 0.13995936282413945, 0.11625146899098693, 0.24031191767279736, 0.2831384168733655, 0.2512288845549715, 0.21349208283147814, 0.2709742534134405, 0.253204641108837, 0.3065697933836059, 0.2569032502330555, 0.21508329618225674, 0.39468858929153916, 0.44493785886825876, 0.3412214442304601, 0.4022518625501722, 0.41978764058825146, 0.34803590937855267, 0.26225525808833394, 0.3355335156396261, 0.5077708211963312, 0.3112174627536882, 0.27900801700448374, 0.21404165006284892, 0.27762550591535406, 0.28627741444079047, 0.2788592224413342, 0.2328027262841742, 0.34512107931937674, 0.2545199493596185, 0.22867202164916411, 0.2536000096249822, 0.247559824187208, 0.23364220594619622, 0.21887149137225992, 0.25138452113105114, 0.22421342801936184, 0.22082035780942944, 0.26193760881573214, 0.6917708034846162, 0.19789960153376596, 0.19597016243354393, 0.1824361653717258, 0.19096904756917732, 0.19631191947214144, 0.2174981643883065, 0.19520924804057704, 0.19598404262508584, 0.18396969015625342, 0.18612147229137166, 0.18517537599147238, 0.8856055410695953, 0.1670557324344476, 0.8368596087322189, 0.8436385097376322, 0.8912841263690393, 0.8947753156261895, 0.8588835393419383, 0.851533553040317, 0.20966216501723933, 0.15504869507750096, 0.8433294130433883, 0.8436479962982408, 0.8482683162296778, 0.8536043853808677, 0.8761218173780815, 0.18914312298110825, 0.18325469051801324, 0.1936603612190574, 0.19372859952831, 0.20479347063556275, 0.19053844456159152, 0.1943455261954916, 0.18417599204962354, 0.18891691406148725, 0.09964227729862762, 0.09408133954616915, 0.0979702773558867, 0.08852594779641498, 0.09971456269814027, 0.11477467723659951, 0.08067348385687656, 0.10256296180541413, 0.13155598340959773]}, "mutation_prompt": null}
{"id": "2ff5b969-5b11-49a7-88c2-b4bab7e39a21", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Increased population size for diverse initial exploration\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.5  # Lowered inertia weight for quicker convergence\n        self.c1 = 1.8  # Slightly reduced cognitive coefficient for better global search\n        self.c2 = 1.5  # Increased social coefficient to enhance cooperation\n        self.F = 0.9  # Higher mutation factor for aggressive exploration\n        self.CR = 0.85  # Balanced crossover rate to maintain exploration-exploitation trade-off\n        self.adapt_factor = 0.99  # Slower adaptation for steady progression\n        self.diversity_prob = 0.3  # Increased probability to enhance diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.2, 0.2, (self.pop_size, self.dim))  # Reduced initial velocity bounds\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.0, 1.0)  # Adjusted velocity clipping for smoother updates\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.3, 0.3, self.dim)  # Adjusted perturbation for better exploration\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "EnhancedAdaptiveDEPSOHybridOptimizer", "description": "An enhanced adaptive hybrid optimizer combining differential evolution and particle swarm optimization with dynamic strategy adaptation for superior convergence and robustness.", "configspace": "", "generation": 90, "fitness": 0.39225872534026146, "feedback": "The algorithm EnhancedAdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.27.", "error": "", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.8167871256316938, 0.7832952586201561, 0.7889596568430245, 0.7993846415603428, 0.8016262688509233, 0.7808061146167863, 0.8071386869241565, 0.8000566185104708, 0.7891718183679205, 0.5232497705438379, 0.5031178137682832, 0.5631748528560674, 0.5420065751942831, 0.548087923545052, 0.5265669231773584, 0.5812826139414851, 0.5652228697334718, 0.5389558693275672, 0.1764380748267973, 0.1792737186158836, 0.10864046683932915, 0.13780006693634694, 0.11489099240118594, 0.17769723938789994, 0.12308216328173782, 0.13371474266308725, 0.11079852138663027, 0.06918199319426599, 0.10552044562012053, 0.09966754368464603, 0.10749466416374742, 0.10499834554354925, 0.08745641935580173, 0.12759428805605544, 0.10204253777977934, 0.08061206865231729, 0.910227502887726, 0.8757727995793488, 0.9168672559561845, 0.9121673383314512, 0.9027484226889595, 0.9021782110302301, 0.8808618969706705, 0.9090924361908865, 0.9327342748816722, 0.6608461147430866, 0.641275086628182, 0.616911695165461, 0.5924340318702783, 0.6170634661039355, 0.5974987261442289, 0.6424450800834439, 0.5834397052052052, 0.6351737385195693, 0.7810802159937988, 0.8256524469814881, 0.22566870806337924, 0.27510931875429456, 0.8511596723265134, 0.27147724382816096, 0.7823110584109388, 0.7495376043139639, 0.8186974456697341, 0.5408078277847359, 0.5296034549123998, 0.5840468333723556, 0.12455477356243139, 0.1290430005735661, 0.5207509795050842, 0.13017741375807468, 0.6271467499167703, 0.5782109207236338, 0.5648389862594372, 0.6041879523907384, 0.5606847510134867, 0.5320593681614674, 0.5118880673377888, 0.5722011151958185, 0.63323423591479, 0.5862514390461901, 0.47795558735797916, 0.1053852266620603, 0.24701874211002306, 0.21004186942313463, 0.24496182507432718, 0.23091189114672428, 0.12883052360378655, 0.24864531258574885, 0.4190563794101304, 0.5099545486569572, 0.26397875264820536, 0.2776624402340374, 0.45222275222373653, 0.28481947616540204, 0.20635591553702237, 0.24933454110433917, 0.3614360612761529, 0.30323391047579873, 0.22504693516572927, 0.22585292391956724, 0.1342586166704377, 0.12665622524122577, 0.2182628935981914, 0.12785369290759863, 0.2116561783151556, 0.11179646157219392, 0.1583200550811793, 0.17726914576385921, 0.1832810482420496, 0.1930172114267783, 0.26946603445501915, 0.23318477780350144, 0.20565916220708902, 0.4015246709083903, 0.10580494040428401, 0.11960358178898456, 0.24260657947049347, 0.7178908101038708, 0.7018420818935366, 0.7022398104280316, 0.6987130100453686, 0.6695994791173026, 0.6928548886214284, 0.7014845753928493, 0.7212465710174318, 0.6978154089245354, 0.10263753351377514, 0.11647066959782282, 0.08648231734416345, 0.17147406481833805, 0.1459191742832452, 0.10408670545537169, 0.11184171130446996, 0.13569915277592048, 0.09857921685551774, 0.29733843659826353, 0.30444670526330675, 0.24006716663799677, 0.37460350541526954, 0.19362569741820057, 0.3091273143927963, 0.23230699064221227, 0.27331855903380786, 0.18333440515753885, 0.430586187587055, 0.3989847100773576, 0.3332728120669056, 0.3297687048589153, 0.45944512162216455, 0.3918304812355389, 0.40253315051716176, 0.4518106860908109, 0.4672458675556841, 0.27043540129826904, 0.31411327431325886, 0.34613232985475484, 0.3076595818156965, 0.24840690564512924, 0.31028344509500816, 0.19987491194825546, 0.3271472503371491, 0.19936238139528117, 0.20947877182645902, 0.20603505401214572, 0.22657997656865714, 0.2571018340734432, 0.2798016258253836, 0.23466032743281962, 0.24184432347966478, 0.2547526704573705, 0.2209115088077509, 0.18152788726599867, 0.20592448931612872, 0.1911298715461821, 0.1912541213962916, 0.19176567369067665, 0.2446974157255688, 0.21724140974182826, 0.20444222578166338, 0.18660563897546611, 0.8661868911452765, 0.8490192644501275, 0.173367083279928, 0.8791789524510979, 0.1995657746752998, 0.8873345813642496, 0.8858944974577652, 0.1651481012991397, 0.8780051542410221, 0.8825494771711377, 0.2103595728315495, 0.8043143564486328, 0.20465863110610116, 0.1511415388071924, 0.8475182391636544, 0.8379436494956217, 0.8343042416379114, 0.8044907453498319, 0.19326305654314924, 0.2007219749096012, 0.19014412602327657, 0.1838073754595263, 0.18948689004039831, 0.19588533109160344, 0.1879722230920282, 0.18520261281078754, 0.2155264071775186, 0.08978603939508778, 0.12931386936235212, 0.13218073414012654, 0.10691605764137146, 0.08520872707804705, 0.10202466739855387, 0.12652943836272246, 0.09557246296212651, 0.09882598455148439]}, "mutation_prompt": null}
{"id": "68bc32a3-8215-4d54-a771-9312ea6aaf16", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 8 * dim  # Population size for rapid convergence\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.5  # Reduced inertia weight for tighter convergence\n        self.c1 = 1.8  # Slightly decreased cognitive coefficient\n        self.c2 = 1.5  # Increased social coefficient for better global search\n        self.F = 0.9  # Increased mutation factor for exploration\n        self.CR = 0.95  # High crossover rate for exploitation\n        self.adapt_factor = 0.99  # Slower adaptation to maintain balance\n        self.diversity_prob = 0.2  # Probability to employ diversity mechanisms\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.4, 0.4, (self.pop_size, self.dim))  # Expanded initial velocity range\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.0, 1.0)  # Adjusted velocity clipping\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.5, 0.5, self.dim)  # Increased perturbation range\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "EnhancedAdaptiveDEPSOHybridOptimizer", "description": "An enhanced adaptive hybrid optimizer blending differential evolution and particle swarm optimization with a novel dynamic exploration-exploitation balance and probabilistic diversity preservation.", "configspace": "", "generation": 91, "fitness": 0.4117271216510469, "feedback": "The algorithm EnhancedAdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41 with standard deviation 0.28.", "error": "", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.8339386695187623, 0.8296316015794575, 0.8536169761647948, 0.8281685664535905, 0.8082200956592015, 0.832128136548118, 0.8356192733385928, 0.8260609082125188, 0.844022694197108, 0.651887224632129, 0.5845638136678185, 0.6531071905872716, 0.6329191316036764, 0.5812043316434373, 0.6229299764179871, 0.6181066812160305, 0.6155914709808675, 0.6166293303757826, 0.11107899390116927, 0.12421680626200415, 0.11614458227876145, 0.15304105852728223, 0.09826380167674775, 0.09456798854601534, 0.09255028726003256, 0.11701841537907987, 0.12267230320840339, 0.1479492512124414, 0.11787194171297855, 0.13842014864073549, 0.13480979179360053, 0.11723992229005653, 0.0749013047531415, 0.09292534499560812, 0.10797699236118019, 0.09099105148567965, 0.936894556911552, 0.9454101679562067, 0.9160675375171546, 0.9219757497815075, 0.882512408160584, 0.9240325708565913, 0.934605271872856, 0.9165480968348706, 0.9251538347709405, 0.6884393426986699, 0.6415060124346035, 0.612717486541745, 0.6600085332539739, 0.6430740682972116, 0.6719245558127218, 0.6641904006013302, 0.64816740606505, 0.670920968392041, 0.22897604445917152, 0.16897204803552723, 0.22607811546246726, 0.27543065146731216, 0.27403738048619997, 0.8678028450748319, 0.8761418487660552, 0.7678777342283312, 0.22919437305620538, 0.5674860305480576, 0.6205717105262204, 0.12851074762644277, 0.591847037317809, 0.5844740155650493, 0.5314314090369986, 0.5545335744293116, 0.12960204444856394, 0.5726475739270527, 0.6263491597024984, 0.13108897219320859, 0.5574949463105712, 0.6420314467061168, 0.5479319439894216, 0.6719510616662974, 0.6595860297536824, 0.5856761275393458, 0.6733943215727605, 0.33113307150095683, 0.4671242133876794, 0.5612511508274487, 0.13384025710822223, 0.4319269571796973, 0.23984624096708007, 0.4810581337320856, 0.3982061391593553, 0.536492724962432, 0.3553554443860275, 0.4416107359898255, 0.21280864444231484, 0.15208899776811013, 0.11840323839029221, 0.10826790813313913, 0.5182036262580211, 0.48176099179376475, 0.33829003397240887, 0.2582155162287614, 0.269856341494378, 0.1370903542047779, 0.2794140461815495, 0.10077277116117911, 0.26473931787433136, 0.1227170117473303, 0.327002411601894, 0.15669653283055507, 0.19126031530857512, 0.3586399346090199, 0.45511472377428186, 0.4812948787518222, 0.33932710586901016, 0.3697824093762415, 0.21311397203328952, 0.37108443404397307, 0.08104654420452206, 0.7854897497174934, 0.7358479901404089, 0.7290805837991723, 0.7429060465470001, 0.7587453543227652, 0.7403319763160006, 0.7592360192957317, 0.7026193322482581, 0.7607842861976124, 0.1348763242213199, 0.12611766568374783, 0.13308573888795638, 0.07676446258926439, 0.14689545100651524, 0.12496711243865288, 0.1053886683204509, 0.09155062912343948, 0.08740518880265968, 0.29871690108671967, 0.23328364592551365, 0.17977564019578862, 0.17716645769579464, 0.20654778647127647, 0.26419791853239105, 0.3368268354829266, 0.171630499883755, 0.19389420086742026, 0.385645577034603, 0.35419728647187143, 0.3894108434565847, 0.38318173435150016, 0.39030092335724054, 0.47259362793324433, 0.4989729657503217, 0.44241269596738897, 0.2503198873516158, 0.22628614937904412, 0.27979712706865334, 0.21549073797717133, 0.27858786441125416, 0.28113813245850217, 0.34145351916241906, 0.223898863040369, 0.2729024439092327, 0.18713172924133326, 0.22604057723933513, 0.3440615113628923, 0.23829605017337985, 0.21358595244783563, 0.2568631139583001, 0.2609953321224583, 0.2418805743064122, 0.23978594864840475, 0.23857934483926302, 0.1975368986817534, 0.2089068215970623, 0.2003681215847769, 0.21012067884562502, 0.1883755946967851, 0.18123801360736957, 0.1831881178785194, 0.19923512066552407, 0.1864034546254527, 0.12546209441173828, 0.8725206132165458, 0.18507278313393594, 0.8943412510696543, 0.1996432472054459, 0.840963853972352, 0.8796617640882717, 0.8715850834130611, 0.915098509229946, 0.8896250768085193, 0.8637395502602094, 0.8507741623032443, 0.8510588045362104, 0.1660507461018622, 0.8214668573879607, 0.8340141293645885, 0.8325161244911998, 0.842556272110247, 0.18950529990960752, 0.20320368335551198, 0.20291719699563238, 0.20464767732158107, 0.19519504538119126, 0.19786525686937406, 0.19883723229999306, 0.19884074286102038, 0.19857230422931393, 0.10289531130213125, 0.1009969102463012, 0.1199871418566052, 0.1004642991051945, 0.10399555520035153, 0.13572070200985142, 0.11149250109517528, 0.14115212242859887, 0.09621121665862753]}, "mutation_prompt": null}
{"id": "5a2e241a-f065-4f73-87f3-25c2ff39502b", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 8 * dim  # Changed population size for faster adaptation\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Adjusted inertia weight for varied exploration\n        self.c1 = 2.0  # Increased cognitive coefficient for enhanced individual focus\n        self.c2 = 1.3  # Decreased social coefficient to balance exploration\n        self.F = 0.85  # Adjusted mutation factor for a balanced search\n        self.CR = 0.9  # Further increased crossover rate to improve exploitation\n        self.adapt_factor = 0.98  # Altered adaptation strategy for fine-tuning dynamics\n        self.diversity_prob = 0.25  # Modified probability to maintain diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.pop_size, self.dim))  # Tighter initial velocity bounds\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.2, 1.2)  # Fine-tuned velocity clipping\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.4, 0.4, self.dim)  # Adjusted perturbation range\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A novel adaptive hybrid optimizer combining differential evolution and particle swarm optimization with probabilistic line refinement for improved convergence and robustness.", "configspace": "", "generation": 63, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.8422026875756686, 0.8316019688777077, 0.8519869328290357, 0.8297406844583839, 0.8252630810752194, 0.8277146988170878, 0.8068246858743604, 0.8561060802327902, 0.8368040280874159, 0.5717081710158031, 0.6229294567072469, 0.6577352366361608, 0.6097452113019179, 0.6248463092449099, 0.6480892213630982, 0.5853863526991877, 0.0512914350509458, 0.6345276944127677, 0.12661715743764002, 0.13553147013685352, 0.1165180416573206, 0.15148546967390686, 0.11833273301113134, 0.11262716667065764, 0.09118768173218983, 0.14706882869418092, 0.12165743506468629, 0.12200259360489396, 0.13034521545583178, 0.10944944258130584, 0.10633023239117789, 0.09527081094569545, 0.11958436269742212, 0.10133130517975841, 0.10989989219452312, 0.10750303865126443, 0.9584574983645874, 0.9456154497882113, 0.9248413138037459, 0.9394551060087084, 0.9178440572107031, 0.9247673511357778, 0.9144207782702397, 0.9195730061057308, 0.9376478922359291, 0.6852319709074105, 0.6780533300046745, 0.7108562413265345, 0.6930832315747306, 0.6473842756151248, 0.6668633835109659, 0.64220068456561, 0.6802151366784446, 0.698301550023128, 0.8284517086601723, 0.8319853512761421, 0.848700148364309, 0.19309996213284675, 0.8640311987671301, 0.8237765327623953, 0.7548692240966136, 0.7386572483314423, 0.8061550552153522, 0.6932523924834011, 0.6326694635926952, 0.5702079409903438, 0.504380399590584, 0.12794219324437095, 0.6326230014369127, 0.6645992326448668, 0.6458071418537177, 0.6824412135078085, 0.6043996176797476, 0.5329321711330159, 0.5621157612975026, 0.5799416763180532, 0.6787042232568141, 0.6327755902918872, 0.6245389618384289, 0.594169038943976, 0.6159025368644813, 0.2142937207523753, 0.5471077190497382, 0.34075658145661114, 0.06300005442848433, 0.32213183089088593, 0.2642637831740825, 0.5790571789927872, 0.2219122676957993, 0.30282947269926586, 0.27733961317035494, 0.3025133376612158, 0.40151213893255033, 0.22581234342655665, 0.12018211681647095, 0.16096111360077414, 0.19341753830233344, 0.4028576817096069, 0.4815084195410494, 0.0971570659457186, 0.11809561294884408, 0.14606350116883315, 0.302776137134796, 0.462988492103911, 0.34443607346144123, 0.12731332407030782, 0.1692466283912818, 0.21420574580174156, 0.25821731821921967, 0.37170899358653164, 0.3209911039463592, 0.20206573914765158, 0.15242447640139722, 0.3654460569911646, 0.0796097810397487, 0.10677503213591588, 0.3671365836218843, 0.7289913375444261, 0.7021916146005962, 0.7667444024290355, 0.6654456240892526, 0.7677149592326706, 0.774739243646891, 0.6856674927873443, 0.7484678961515467, 0.7923371581346985, 0.10519973895126877, 0.13636345543025197, 0.09069979364325631, 0.11397311546275801, 0.14986323712414085, 0.10092383413138228, 0.12178337409989903, 0.13995936282413945, 0.11625146899098693, 0.24031191767279736, 0.2831384168733655, 0.2512288845549715, 0.21349208283147814, 0.2709742534134405, 0.253204641108837, 0.3065697933836059, 0.2569032502330555, 0.21508329618225674, 0.39468858929153916, 0.44493785886825876, 0.3412214442304601, 0.4022518625501722, 0.41978764058825146, 0.34803590937855267, 0.26225525808833394, 0.3355335156396261, 0.5077708211963312, 0.3112174627536882, 0.27900801700448374, 0.21404165006284892, 0.27762550591535406, 0.28627741444079047, 0.2788592224413342, 0.2328027262841742, 0.34512107931937674, 0.2545199493596185, 0.22867202164916411, 0.2536000096249822, 0.247559824187208, 0.23364220594619622, 0.21887149137225992, 0.25138452113105114, 0.22421342801936184, 0.22082035780942944, 0.26193760881573214, 0.6917708034846162, 0.19789960153376596, 0.19597016243354393, 0.1824361653717258, 0.19096904756917732, 0.19631191947214144, 0.2174981643883065, 0.19520924804057704, 0.19598404262508584, 0.18396969015625342, 0.18612147229137166, 0.18517537599147238, 0.8856055410695953, 0.1670557324344476, 0.8368596087322189, 0.8436385097376322, 0.8912841263690393, 0.8947753156261895, 0.8588835393419383, 0.851533553040317, 0.20966216501723933, 0.15504869507750096, 0.8433294130433883, 0.8436479962982408, 0.8482683162296778, 0.8536043853808677, 0.8761218173780815, 0.18914312298110825, 0.18325469051801324, 0.1936603612190574, 0.19372859952831, 0.20479347063556275, 0.19053844456159152, 0.1943455261954916, 0.18417599204962354, 0.18891691406148725, 0.09964227729862762, 0.09408133954616915, 0.0979702773558867, 0.08852594779641498, 0.09971456269814027, 0.11477467723659951, 0.08067348385687656, 0.10256296180541413, 0.13155598340959773]}, "mutation_prompt": null}
{"id": "595cd2a4-73ce-4d01-af47-975b79fda728", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 8 * dim  # Changed population size for faster adaptation\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Adjusted inertia weight for varied exploration\n        self.c1 = 2.0  # Increased cognitive coefficient for enhanced individual focus\n        self.c2 = 1.3  # Decreased social coefficient to balance exploration\n        self.F = 0.85  # Adjusted mutation factor for a balanced search\n        self.CR = 0.9  # Further increased crossover rate to improve exploitation\n        self.adapt_factor = 0.98  # Altered adaptation strategy for fine-tuning dynamics\n        self.diversity_prob = 0.25  # Modified probability to maintain diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.pop_size, self.dim))  # Tighter initial velocity bounds\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.2, 1.2)  # Fine-tuned velocity clipping\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.4, 0.4, self.dim)  # Adjusted perturbation range\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A novel adaptive hybrid optimizer combining differential evolution and particle swarm optimization with probabilistic line refinement for improved convergence and robustness.", "configspace": "", "generation": 63, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.8422026875756686, 0.8316019688777077, 0.8519869328290357, 0.8297406844583839, 0.8252630810752194, 0.8277146988170878, 0.8068246858743604, 0.8561060802327902, 0.8368040280874159, 0.5717081710158031, 0.6229294567072469, 0.6577352366361608, 0.6097452113019179, 0.6248463092449099, 0.6480892213630982, 0.5853863526991877, 0.0512914350509458, 0.6345276944127677, 0.12661715743764002, 0.13553147013685352, 0.1165180416573206, 0.15148546967390686, 0.11833273301113134, 0.11262716667065764, 0.09118768173218983, 0.14706882869418092, 0.12165743506468629, 0.12200259360489396, 0.13034521545583178, 0.10944944258130584, 0.10633023239117789, 0.09527081094569545, 0.11958436269742212, 0.10133130517975841, 0.10989989219452312, 0.10750303865126443, 0.9584574983645874, 0.9456154497882113, 0.9248413138037459, 0.9394551060087084, 0.9178440572107031, 0.9247673511357778, 0.9144207782702397, 0.9195730061057308, 0.9376478922359291, 0.6852319709074105, 0.6780533300046745, 0.7108562413265345, 0.6930832315747306, 0.6473842756151248, 0.6668633835109659, 0.64220068456561, 0.6802151366784446, 0.698301550023128, 0.8284517086601723, 0.8319853512761421, 0.848700148364309, 0.19309996213284675, 0.8640311987671301, 0.8237765327623953, 0.7548692240966136, 0.7386572483314423, 0.8061550552153522, 0.6932523924834011, 0.6326694635926952, 0.5702079409903438, 0.504380399590584, 0.12794219324437095, 0.6326230014369127, 0.6645992326448668, 0.6458071418537177, 0.6824412135078085, 0.6043996176797476, 0.5329321711330159, 0.5621157612975026, 0.5799416763180532, 0.6787042232568141, 0.6327755902918872, 0.6245389618384289, 0.594169038943976, 0.6159025368644813, 0.2142937207523753, 0.5471077190497382, 0.34075658145661114, 0.06300005442848433, 0.32213183089088593, 0.2642637831740825, 0.5790571789927872, 0.2219122676957993, 0.30282947269926586, 0.27733961317035494, 0.3025133376612158, 0.40151213893255033, 0.22581234342655665, 0.12018211681647095, 0.16096111360077414, 0.19341753830233344, 0.4028576817096069, 0.4815084195410494, 0.0971570659457186, 0.11809561294884408, 0.14606350116883315, 0.302776137134796, 0.462988492103911, 0.34443607346144123, 0.12731332407030782, 0.1692466283912818, 0.21420574580174156, 0.25821731821921967, 0.37170899358653164, 0.3209911039463592, 0.20206573914765158, 0.15242447640139722, 0.3654460569911646, 0.0796097810397487, 0.10677503213591588, 0.3671365836218843, 0.7289913375444261, 0.7021916146005962, 0.7667444024290355, 0.6654456240892526, 0.7677149592326706, 0.774739243646891, 0.6856674927873443, 0.7484678961515467, 0.7923371581346985, 0.10519973895126877, 0.13636345543025197, 0.09069979364325631, 0.11397311546275801, 0.14986323712414085, 0.10092383413138228, 0.12178337409989903, 0.13995936282413945, 0.11625146899098693, 0.24031191767279736, 0.2831384168733655, 0.2512288845549715, 0.21349208283147814, 0.2709742534134405, 0.253204641108837, 0.3065697933836059, 0.2569032502330555, 0.21508329618225674, 0.39468858929153916, 0.44493785886825876, 0.3412214442304601, 0.4022518625501722, 0.41978764058825146, 0.34803590937855267, 0.26225525808833394, 0.3355335156396261, 0.5077708211963312, 0.3112174627536882, 0.27900801700448374, 0.21404165006284892, 0.27762550591535406, 0.28627741444079047, 0.2788592224413342, 0.2328027262841742, 0.34512107931937674, 0.2545199493596185, 0.22867202164916411, 0.2536000096249822, 0.247559824187208, 0.23364220594619622, 0.21887149137225992, 0.25138452113105114, 0.22421342801936184, 0.22082035780942944, 0.26193760881573214, 0.6917708034846162, 0.19789960153376596, 0.19597016243354393, 0.1824361653717258, 0.19096904756917732, 0.19631191947214144, 0.2174981643883065, 0.19520924804057704, 0.19598404262508584, 0.18396969015625342, 0.18612147229137166, 0.18517537599147238, 0.8856055410695953, 0.1670557324344476, 0.8368596087322189, 0.8436385097376322, 0.8912841263690393, 0.8947753156261895, 0.8588835393419383, 0.851533553040317, 0.20966216501723933, 0.15504869507750096, 0.8433294130433883, 0.8436479962982408, 0.8482683162296778, 0.8536043853808677, 0.8761218173780815, 0.18914312298110825, 0.18325469051801324, 0.1936603612190574, 0.19372859952831, 0.20479347063556275, 0.19053844456159152, 0.1943455261954916, 0.18417599204962354, 0.18891691406148725, 0.09964227729862762, 0.09408133954616915, 0.0979702773558867, 0.08852594779641498, 0.09971456269814027, 0.11477467723659951, 0.08067348385687656, 0.10256296180541413, 0.13155598340959773]}, "mutation_prompt": null}
{"id": "3c64cee2-6f92-4a98-bd00-28cad95615b0", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 8 * dim  # Changed population size for faster adaptation\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Adjusted inertia weight for varied exploration\n        self.c1 = 2.0  # Increased cognitive coefficient for enhanced individual focus\n        self.c2 = 1.3  # Decreased social coefficient to balance exploration\n        self.F = 0.85  # Adjusted mutation factor for a balanced search\n        self.CR = 0.9  # Further increased crossover rate to improve exploitation\n        self.adapt_factor = 0.98  # Altered adaptation strategy for fine-tuning dynamics\n        self.diversity_prob = 0.25  # Modified probability to maintain diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.pop_size, self.dim))  # Tighter initial velocity bounds\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.2, 1.2)  # Fine-tuned velocity clipping\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.4, 0.4, self.dim)  # Adjusted perturbation range\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A novel adaptive hybrid optimizer combining differential evolution and particle swarm optimization with probabilistic line refinement for improved convergence and robustness.", "configspace": "", "generation": 63, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.8422026875756686, 0.8316019688777077, 0.8519869328290357, 0.8297406844583839, 0.8252630810752194, 0.8277146988170878, 0.8068246858743604, 0.8561060802327902, 0.8368040280874159, 0.5717081710158031, 0.6229294567072469, 0.6577352366361608, 0.6097452113019179, 0.6248463092449099, 0.6480892213630982, 0.5853863526991877, 0.0512914350509458, 0.6345276944127677, 0.12661715743764002, 0.13553147013685352, 0.1165180416573206, 0.15148546967390686, 0.11833273301113134, 0.11262716667065764, 0.09118768173218983, 0.14706882869418092, 0.12165743506468629, 0.12200259360489396, 0.13034521545583178, 0.10944944258130584, 0.10633023239117789, 0.09527081094569545, 0.11958436269742212, 0.10133130517975841, 0.10989989219452312, 0.10750303865126443, 0.9584574983645874, 0.9456154497882113, 0.9248413138037459, 0.9394551060087084, 0.9178440572107031, 0.9247673511357778, 0.9144207782702397, 0.9195730061057308, 0.9376478922359291, 0.6852319709074105, 0.6780533300046745, 0.7108562413265345, 0.6930832315747306, 0.6473842756151248, 0.6668633835109659, 0.64220068456561, 0.6802151366784446, 0.698301550023128, 0.8284517086601723, 0.8319853512761421, 0.848700148364309, 0.19309996213284675, 0.8640311987671301, 0.8237765327623953, 0.7548692240966136, 0.7386572483314423, 0.8061550552153522, 0.6932523924834011, 0.6326694635926952, 0.5702079409903438, 0.504380399590584, 0.12794219324437095, 0.6326230014369127, 0.6645992326448668, 0.6458071418537177, 0.6824412135078085, 0.6043996176797476, 0.5329321711330159, 0.5621157612975026, 0.5799416763180532, 0.6787042232568141, 0.6327755902918872, 0.6245389618384289, 0.594169038943976, 0.6159025368644813, 0.2142937207523753, 0.5471077190497382, 0.34075658145661114, 0.06300005442848433, 0.32213183089088593, 0.2642637831740825, 0.5790571789927872, 0.2219122676957993, 0.30282947269926586, 0.27733961317035494, 0.3025133376612158, 0.40151213893255033, 0.22581234342655665, 0.12018211681647095, 0.16096111360077414, 0.19341753830233344, 0.4028576817096069, 0.4815084195410494, 0.0971570659457186, 0.11809561294884408, 0.14606350116883315, 0.302776137134796, 0.462988492103911, 0.34443607346144123, 0.12731332407030782, 0.1692466283912818, 0.21420574580174156, 0.25821731821921967, 0.37170899358653164, 0.3209911039463592, 0.20206573914765158, 0.15242447640139722, 0.3654460569911646, 0.0796097810397487, 0.10677503213591588, 0.3671365836218843, 0.7289913375444261, 0.7021916146005962, 0.7667444024290355, 0.6654456240892526, 0.7677149592326706, 0.774739243646891, 0.6856674927873443, 0.7484678961515467, 0.7923371581346985, 0.10519973895126877, 0.13636345543025197, 0.09069979364325631, 0.11397311546275801, 0.14986323712414085, 0.10092383413138228, 0.12178337409989903, 0.13995936282413945, 0.11625146899098693, 0.24031191767279736, 0.2831384168733655, 0.2512288845549715, 0.21349208283147814, 0.2709742534134405, 0.253204641108837, 0.3065697933836059, 0.2569032502330555, 0.21508329618225674, 0.39468858929153916, 0.44493785886825876, 0.3412214442304601, 0.4022518625501722, 0.41978764058825146, 0.34803590937855267, 0.26225525808833394, 0.3355335156396261, 0.5077708211963312, 0.3112174627536882, 0.27900801700448374, 0.21404165006284892, 0.27762550591535406, 0.28627741444079047, 0.2788592224413342, 0.2328027262841742, 0.34512107931937674, 0.2545199493596185, 0.22867202164916411, 0.2536000096249822, 0.247559824187208, 0.23364220594619622, 0.21887149137225992, 0.25138452113105114, 0.22421342801936184, 0.22082035780942944, 0.26193760881573214, 0.6917708034846162, 0.19789960153376596, 0.19597016243354393, 0.1824361653717258, 0.19096904756917732, 0.19631191947214144, 0.2174981643883065, 0.19520924804057704, 0.19598404262508584, 0.18396969015625342, 0.18612147229137166, 0.18517537599147238, 0.8856055410695953, 0.1670557324344476, 0.8368596087322189, 0.8436385097376322, 0.8912841263690393, 0.8947753156261895, 0.8588835393419383, 0.851533553040317, 0.20966216501723933, 0.15504869507750096, 0.8433294130433883, 0.8436479962982408, 0.8482683162296778, 0.8536043853808677, 0.8761218173780815, 0.18914312298110825, 0.18325469051801324, 0.1936603612190574, 0.19372859952831, 0.20479347063556275, 0.19053844456159152, 0.1943455261954916, 0.18417599204962354, 0.18891691406148725, 0.09964227729862762, 0.09408133954616915, 0.0979702773558867, 0.08852594779641498, 0.09971456269814027, 0.11477467723659951, 0.08067348385687656, 0.10256296180541413, 0.13155598340959773]}, "mutation_prompt": null}
{"id": "4da45d91-475e-495e-b211-9c052419cfb9", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 8 * dim  # Changed population size for faster adaptation\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Adjusted inertia weight for varied exploration\n        self.c1 = 2.0  # Increased cognitive coefficient for enhanced individual focus\n        self.c2 = 1.3  # Decreased social coefficient to balance exploration\n        self.F = 0.85  # Adjusted mutation factor for a balanced search\n        self.CR = 0.9  # Further increased crossover rate to improve exploitation\n        self.adapt_factor = 0.98  # Altered adaptation strategy for fine-tuning dynamics\n        self.diversity_prob = 0.25  # Modified probability to maintain diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.pop_size, self.dim))  # Tighter initial velocity bounds\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.2, 1.2)  # Fine-tuned velocity clipping\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.4, 0.4, self.dim)  # Adjusted perturbation range\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A novel adaptive hybrid optimizer combining differential evolution and particle swarm optimization with probabilistic line refinement for improved convergence and robustness.", "configspace": "", "generation": 63, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.8422026875756686, 0.8316019688777077, 0.8519869328290357, 0.8297406844583839, 0.8252630810752194, 0.8277146988170878, 0.8068246858743604, 0.8561060802327902, 0.8368040280874159, 0.5717081710158031, 0.6229294567072469, 0.6577352366361608, 0.6097452113019179, 0.6248463092449099, 0.6480892213630982, 0.5853863526991877, 0.0512914350509458, 0.6345276944127677, 0.12661715743764002, 0.13553147013685352, 0.1165180416573206, 0.15148546967390686, 0.11833273301113134, 0.11262716667065764, 0.09118768173218983, 0.14706882869418092, 0.12165743506468629, 0.12200259360489396, 0.13034521545583178, 0.10944944258130584, 0.10633023239117789, 0.09527081094569545, 0.11958436269742212, 0.10133130517975841, 0.10989989219452312, 0.10750303865126443, 0.9584574983645874, 0.9456154497882113, 0.9248413138037459, 0.9394551060087084, 0.9178440572107031, 0.9247673511357778, 0.9144207782702397, 0.9195730061057308, 0.9376478922359291, 0.6852319709074105, 0.6780533300046745, 0.7108562413265345, 0.6930832315747306, 0.6473842756151248, 0.6668633835109659, 0.64220068456561, 0.6802151366784446, 0.698301550023128, 0.8284517086601723, 0.8319853512761421, 0.848700148364309, 0.19309996213284675, 0.8640311987671301, 0.8237765327623953, 0.7548692240966136, 0.7386572483314423, 0.8061550552153522, 0.6932523924834011, 0.6326694635926952, 0.5702079409903438, 0.504380399590584, 0.12794219324437095, 0.6326230014369127, 0.6645992326448668, 0.6458071418537177, 0.6824412135078085, 0.6043996176797476, 0.5329321711330159, 0.5621157612975026, 0.5799416763180532, 0.6787042232568141, 0.6327755902918872, 0.6245389618384289, 0.594169038943976, 0.6159025368644813, 0.2142937207523753, 0.5471077190497382, 0.34075658145661114, 0.06300005442848433, 0.32213183089088593, 0.2642637831740825, 0.5790571789927872, 0.2219122676957993, 0.30282947269926586, 0.27733961317035494, 0.3025133376612158, 0.40151213893255033, 0.22581234342655665, 0.12018211681647095, 0.16096111360077414, 0.19341753830233344, 0.4028576817096069, 0.4815084195410494, 0.0971570659457186, 0.11809561294884408, 0.14606350116883315, 0.302776137134796, 0.462988492103911, 0.34443607346144123, 0.12731332407030782, 0.1692466283912818, 0.21420574580174156, 0.25821731821921967, 0.37170899358653164, 0.3209911039463592, 0.20206573914765158, 0.15242447640139722, 0.3654460569911646, 0.0796097810397487, 0.10677503213591588, 0.3671365836218843, 0.7289913375444261, 0.7021916146005962, 0.7667444024290355, 0.6654456240892526, 0.7677149592326706, 0.774739243646891, 0.6856674927873443, 0.7484678961515467, 0.7923371581346985, 0.10519973895126877, 0.13636345543025197, 0.09069979364325631, 0.11397311546275801, 0.14986323712414085, 0.10092383413138228, 0.12178337409989903, 0.13995936282413945, 0.11625146899098693, 0.24031191767279736, 0.2831384168733655, 0.2512288845549715, 0.21349208283147814, 0.2709742534134405, 0.253204641108837, 0.3065697933836059, 0.2569032502330555, 0.21508329618225674, 0.39468858929153916, 0.44493785886825876, 0.3412214442304601, 0.4022518625501722, 0.41978764058825146, 0.34803590937855267, 0.26225525808833394, 0.3355335156396261, 0.5077708211963312, 0.3112174627536882, 0.27900801700448374, 0.21404165006284892, 0.27762550591535406, 0.28627741444079047, 0.2788592224413342, 0.2328027262841742, 0.34512107931937674, 0.2545199493596185, 0.22867202164916411, 0.2536000096249822, 0.247559824187208, 0.23364220594619622, 0.21887149137225992, 0.25138452113105114, 0.22421342801936184, 0.22082035780942944, 0.26193760881573214, 0.6917708034846162, 0.19789960153376596, 0.19597016243354393, 0.1824361653717258, 0.19096904756917732, 0.19631191947214144, 0.2174981643883065, 0.19520924804057704, 0.19598404262508584, 0.18396969015625342, 0.18612147229137166, 0.18517537599147238, 0.8856055410695953, 0.1670557324344476, 0.8368596087322189, 0.8436385097376322, 0.8912841263690393, 0.8947753156261895, 0.8588835393419383, 0.851533553040317, 0.20966216501723933, 0.15504869507750096, 0.8433294130433883, 0.8436479962982408, 0.8482683162296778, 0.8536043853808677, 0.8761218173780815, 0.18914312298110825, 0.18325469051801324, 0.1936603612190574, 0.19372859952831, 0.20479347063556275, 0.19053844456159152, 0.1943455261954916, 0.18417599204962354, 0.18891691406148725, 0.09964227729862762, 0.09408133954616915, 0.0979702773558867, 0.08852594779641498, 0.09971456269814027, 0.11477467723659951, 0.08067348385687656, 0.10256296180541413, 0.13155598340959773]}, "mutation_prompt": null}
{"id": "ff027dc7-0ffd-4b0a-ae56-bf794d055fc7", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 8 * dim  # Changed population size for faster adaptation\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Adjusted inertia weight for varied exploration\n        self.c1 = 2.0  # Increased cognitive coefficient for enhanced individual focus\n        self.c2 = 1.3  # Decreased social coefficient to balance exploration\n        self.F = 0.85  # Adjusted mutation factor for a balanced search\n        self.CR = 0.9  # Further increased crossover rate to improve exploitation\n        self.adapt_factor = 0.98  # Altered adaptation strategy for fine-tuning dynamics\n        self.diversity_prob = 0.25  # Modified probability to maintain diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.pop_size, self.dim))  # Tighter initial velocity bounds\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.2, 1.2)  # Fine-tuned velocity clipping\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.4, 0.4, self.dim)  # Adjusted perturbation range\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A novel adaptive hybrid optimizer combining differential evolution and particle swarm optimization with probabilistic line refinement for improved convergence and robustness.", "configspace": "", "generation": 63, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.8422026875756686, 0.8316019688777077, 0.8519869328290357, 0.8297406844583839, 0.8252630810752194, 0.8277146988170878, 0.8068246858743604, 0.8561060802327902, 0.8368040280874159, 0.5717081710158031, 0.6229294567072469, 0.6577352366361608, 0.6097452113019179, 0.6248463092449099, 0.6480892213630982, 0.5853863526991877, 0.0512914350509458, 0.6345276944127677, 0.12661715743764002, 0.13553147013685352, 0.1165180416573206, 0.15148546967390686, 0.11833273301113134, 0.11262716667065764, 0.09118768173218983, 0.14706882869418092, 0.12165743506468629, 0.12200259360489396, 0.13034521545583178, 0.10944944258130584, 0.10633023239117789, 0.09527081094569545, 0.11958436269742212, 0.10133130517975841, 0.10989989219452312, 0.10750303865126443, 0.9584574983645874, 0.9456154497882113, 0.9248413138037459, 0.9394551060087084, 0.9178440572107031, 0.9247673511357778, 0.9144207782702397, 0.9195730061057308, 0.9376478922359291, 0.6852319709074105, 0.6780533300046745, 0.7108562413265345, 0.6930832315747306, 0.6473842756151248, 0.6668633835109659, 0.64220068456561, 0.6802151366784446, 0.698301550023128, 0.8284517086601723, 0.8319853512761421, 0.848700148364309, 0.19309996213284675, 0.8640311987671301, 0.8237765327623953, 0.7548692240966136, 0.7386572483314423, 0.8061550552153522, 0.6932523924834011, 0.6326694635926952, 0.5702079409903438, 0.504380399590584, 0.12794219324437095, 0.6326230014369127, 0.6645992326448668, 0.6458071418537177, 0.6824412135078085, 0.6043996176797476, 0.5329321711330159, 0.5621157612975026, 0.5799416763180532, 0.6787042232568141, 0.6327755902918872, 0.6245389618384289, 0.594169038943976, 0.6159025368644813, 0.2142937207523753, 0.5471077190497382, 0.34075658145661114, 0.06300005442848433, 0.32213183089088593, 0.2642637831740825, 0.5790571789927872, 0.2219122676957993, 0.30282947269926586, 0.27733961317035494, 0.3025133376612158, 0.40151213893255033, 0.22581234342655665, 0.12018211681647095, 0.16096111360077414, 0.19341753830233344, 0.4028576817096069, 0.4815084195410494, 0.0971570659457186, 0.11809561294884408, 0.14606350116883315, 0.302776137134796, 0.462988492103911, 0.34443607346144123, 0.12731332407030782, 0.1692466283912818, 0.21420574580174156, 0.25821731821921967, 0.37170899358653164, 0.3209911039463592, 0.20206573914765158, 0.15242447640139722, 0.3654460569911646, 0.0796097810397487, 0.10677503213591588, 0.3671365836218843, 0.7289913375444261, 0.7021916146005962, 0.7667444024290355, 0.6654456240892526, 0.7677149592326706, 0.774739243646891, 0.6856674927873443, 0.7484678961515467, 0.7923371581346985, 0.10519973895126877, 0.13636345543025197, 0.09069979364325631, 0.11397311546275801, 0.14986323712414085, 0.10092383413138228, 0.12178337409989903, 0.13995936282413945, 0.11625146899098693, 0.24031191767279736, 0.2831384168733655, 0.2512288845549715, 0.21349208283147814, 0.2709742534134405, 0.253204641108837, 0.3065697933836059, 0.2569032502330555, 0.21508329618225674, 0.39468858929153916, 0.44493785886825876, 0.3412214442304601, 0.4022518625501722, 0.41978764058825146, 0.34803590937855267, 0.26225525808833394, 0.3355335156396261, 0.5077708211963312, 0.3112174627536882, 0.27900801700448374, 0.21404165006284892, 0.27762550591535406, 0.28627741444079047, 0.2788592224413342, 0.2328027262841742, 0.34512107931937674, 0.2545199493596185, 0.22867202164916411, 0.2536000096249822, 0.247559824187208, 0.23364220594619622, 0.21887149137225992, 0.25138452113105114, 0.22421342801936184, 0.22082035780942944, 0.26193760881573214, 0.6917708034846162, 0.19789960153376596, 0.19597016243354393, 0.1824361653717258, 0.19096904756917732, 0.19631191947214144, 0.2174981643883065, 0.19520924804057704, 0.19598404262508584, 0.18396969015625342, 0.18612147229137166, 0.18517537599147238, 0.8856055410695953, 0.1670557324344476, 0.8368596087322189, 0.8436385097376322, 0.8912841263690393, 0.8947753156261895, 0.8588835393419383, 0.851533553040317, 0.20966216501723933, 0.15504869507750096, 0.8433294130433883, 0.8436479962982408, 0.8482683162296778, 0.8536043853808677, 0.8761218173780815, 0.18914312298110825, 0.18325469051801324, 0.1936603612190574, 0.19372859952831, 0.20479347063556275, 0.19053844456159152, 0.1943455261954916, 0.18417599204962354, 0.18891691406148725, 0.09964227729862762, 0.09408133954616915, 0.0979702773558867, 0.08852594779641498, 0.09971456269814027, 0.11477467723659951, 0.08067348385687656, 0.10256296180541413, 0.13155598340959773]}, "mutation_prompt": null}
{"id": "4d1771f4-c960-4353-be61-f3aac53dd1fe", "solution": "import numpy as np\n\nclass RefinedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 8 * dim  # Changed population size for faster adaptation\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.6  # Adjusted inertia weight for varied exploration\n        self.c1 = 2.0  # Increased cognitive coefficient for enhanced individual focus\n        self.c2 = 1.3  # Decreased social coefficient to balance exploration\n        self.F = 0.85  # Adjusted mutation factor for a balanced search\n        self.CR = 0.9  # Further increased crossover rate to improve exploitation\n        self.adapt_factor = 0.98  # Altered adaptation strategy for fine-tuning dynamics\n        self.diversity_prob = 0.25  # Modified probability to maintain diversity\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.pop_size, self.dim))  # Tighter initial velocity bounds\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.2, 1.2)  # Fine-tuned velocity clipping\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.4, 0.4, self.dim)  # Adjusted perturbation range\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "RefinedAdaptiveDEPSOHybridOptimizer", "description": "A novel adaptive hybrid optimizer combining differential evolution and particle swarm optimization with probabilistic line refinement for improved convergence and robustness.", "configspace": "", "generation": 63, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.8422026875756686, 0.8316019688777077, 0.8519869328290357, 0.8297406844583839, 0.8252630810752194, 0.8277146988170878, 0.8068246858743604, 0.8561060802327902, 0.8368040280874159, 0.5717081710158031, 0.6229294567072469, 0.6577352366361608, 0.6097452113019179, 0.6248463092449099, 0.6480892213630982, 0.5853863526991877, 0.0512914350509458, 0.6345276944127677, 0.12661715743764002, 0.13553147013685352, 0.1165180416573206, 0.15148546967390686, 0.11833273301113134, 0.11262716667065764, 0.09118768173218983, 0.14706882869418092, 0.12165743506468629, 0.12200259360489396, 0.13034521545583178, 0.10944944258130584, 0.10633023239117789, 0.09527081094569545, 0.11958436269742212, 0.10133130517975841, 0.10989989219452312, 0.10750303865126443, 0.9584574983645874, 0.9456154497882113, 0.9248413138037459, 0.9394551060087084, 0.9178440572107031, 0.9247673511357778, 0.9144207782702397, 0.9195730061057308, 0.9376478922359291, 0.6852319709074105, 0.6780533300046745, 0.7108562413265345, 0.6930832315747306, 0.6473842756151248, 0.6668633835109659, 0.64220068456561, 0.6802151366784446, 0.698301550023128, 0.8284517086601723, 0.8319853512761421, 0.848700148364309, 0.19309996213284675, 0.8640311987671301, 0.8237765327623953, 0.7548692240966136, 0.7386572483314423, 0.8061550552153522, 0.6932523924834011, 0.6326694635926952, 0.5702079409903438, 0.504380399590584, 0.12794219324437095, 0.6326230014369127, 0.6645992326448668, 0.6458071418537177, 0.6824412135078085, 0.6043996176797476, 0.5329321711330159, 0.5621157612975026, 0.5799416763180532, 0.6787042232568141, 0.6327755902918872, 0.6245389618384289, 0.594169038943976, 0.6159025368644813, 0.2142937207523753, 0.5471077190497382, 0.34075658145661114, 0.06300005442848433, 0.32213183089088593, 0.2642637831740825, 0.5790571789927872, 0.2219122676957993, 0.30282947269926586, 0.27733961317035494, 0.3025133376612158, 0.40151213893255033, 0.22581234342655665, 0.12018211681647095, 0.16096111360077414, 0.19341753830233344, 0.4028576817096069, 0.4815084195410494, 0.0971570659457186, 0.11809561294884408, 0.14606350116883315, 0.302776137134796, 0.462988492103911, 0.34443607346144123, 0.12731332407030782, 0.1692466283912818, 0.21420574580174156, 0.25821731821921967, 0.37170899358653164, 0.3209911039463592, 0.20206573914765158, 0.15242447640139722, 0.3654460569911646, 0.0796097810397487, 0.10677503213591588, 0.3671365836218843, 0.7289913375444261, 0.7021916146005962, 0.7667444024290355, 0.6654456240892526, 0.7677149592326706, 0.774739243646891, 0.6856674927873443, 0.7484678961515467, 0.7923371581346985, 0.10519973895126877, 0.13636345543025197, 0.09069979364325631, 0.11397311546275801, 0.14986323712414085, 0.10092383413138228, 0.12178337409989903, 0.13995936282413945, 0.11625146899098693, 0.24031191767279736, 0.2831384168733655, 0.2512288845549715, 0.21349208283147814, 0.2709742534134405, 0.253204641108837, 0.3065697933836059, 0.2569032502330555, 0.21508329618225674, 0.39468858929153916, 0.44493785886825876, 0.3412214442304601, 0.4022518625501722, 0.41978764058825146, 0.34803590937855267, 0.26225525808833394, 0.3355335156396261, 0.5077708211963312, 0.3112174627536882, 0.27900801700448374, 0.21404165006284892, 0.27762550591535406, 0.28627741444079047, 0.2788592224413342, 0.2328027262841742, 0.34512107931937674, 0.2545199493596185, 0.22867202164916411, 0.2536000096249822, 0.247559824187208, 0.23364220594619622, 0.21887149137225992, 0.25138452113105114, 0.22421342801936184, 0.22082035780942944, 0.26193760881573214, 0.6917708034846162, 0.19789960153376596, 0.19597016243354393, 0.1824361653717258, 0.19096904756917732, 0.19631191947214144, 0.2174981643883065, 0.19520924804057704, 0.19598404262508584, 0.18396969015625342, 0.18612147229137166, 0.18517537599147238, 0.8856055410695953, 0.1670557324344476, 0.8368596087322189, 0.8436385097376322, 0.8912841263690393, 0.8947753156261895, 0.8588835393419383, 0.851533553040317, 0.20966216501723933, 0.15504869507750096, 0.8433294130433883, 0.8436479962982408, 0.8482683162296778, 0.8536043853808677, 0.8761218173780815, 0.18914312298110825, 0.18325469051801324, 0.1936603612190574, 0.19372859952831, 0.20479347063556275, 0.19053844456159152, 0.1943455261954916, 0.18417599204962354, 0.18891691406148725, 0.09964227729862762, 0.09408133954616915, 0.0979702773558867, 0.08852594779641498, 0.09971456269814027, 0.11477467723659951, 0.08067348385687656, 0.10256296180541413, 0.13155598340959773]}, "mutation_prompt": null}
{"id": "59d401fe-bfe5-42f4-84af-9c85f85f3f77", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Increased population size for enhanced diversity\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.5  # Further adjusted inertia weight for more exploration\n        self.c1 = 1.8  # Slightly reduced cognitive coefficient for smoother individual changes\n        self.c2 = 1.5  # Increased social coefficient to strengthen global learning\n        self.F = 0.9  # Enhanced mutation factor for aggressive search\n        self.CR = 0.85  # Reduced crossover rate to maintain diversity\n        self.adapt_factor = 0.95  # More gradual adaptation strategy for stability\n        self.diversity_prob = 0.3  # Increased diversity maintenance probability\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))  # Broadened initial velocity range\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i], -1.5, 1.5)  # Extended velocity clipping\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.3, 0.3, self.dim)  # Smaller perturbation range for subtle refinements\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "EnhancedAdaptiveDEPSOHybridOptimizer", "description": "A modified adaptive hybrid optimizer using differential evolution and particle swarm strategies with dynamic parameter adaptation for improved exploration-exploitation balance.", "configspace": "", "generation": 98, "fitness": 0.3947266759146545, "feedback": "The algorithm EnhancedAdaptiveDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.28.", "error": "", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.8718453382325185, 0.8612171233616972, 0.854716095788709, 0.8505940605513628, 0.8489415277881005, 0.8567801047898748, 0.8613343131869198, 0.8604783307997578, 0.8427773349469309, 0.6960305861810584, 0.6690068084021197, 0.6771287097370815, 0.6904838542797276, 0.6622030184660235, 0.6643814293960895, 0.702753452668453, 0.635021397057566, 0.6261641171836936, 0.1560572697424213, 0.15732558241118244, 0.1568194358906756, 0.12092684685303123, 0.1099464705221842, 0.11370966941366534, 0.11883425602766406, 0.14132960220524715, 0.1638695862123415, 0.12046412509121529, 0.13864837600948798, 0.15641473014829155, 0.1288025499394354, 0.1120705722459332, 0.12092267711428795, 0.1158110853349017, 0.11936977270919347, 0.1062163148624572, 0.9590922049228966, 0.9222457764136756, 0.9256846364274741, 0.9420589472834564, 0.9226524509056571, 0.9174422781189944, 0.8946908465413238, 0.927300557780455, 0.9523821665604006, 0.6966610575903359, 0.7089140039981985, 0.6490587825978695, 0.6372498179717268, 0.6908305961664812, 0.6537040314865825, 0.6211443958383878, 0.6511609070884496, 0.6435781807653791, 0.9053398769184263, 0.7113425257318688, 0.2267347087222683, 0.7584315252846658, 0.8589807644260301, 0.37166921496034444, 0.23005051814743194, 0.24095828206870762, 0.8542252415571153, 0.5739745130143143, 0.1305194780872283, 0.503638159787674, 0.6355657152017571, 0.6727443942560412, 0.6139007863471823, 0.665937340271225, 0.6497757200756547, 0.43816399190827304, 0.6016242706910095, 0.40088308805681294, 0.5694336004142259, 0.5503918972333166, 0.5541349171929564, 0.6809864457286154, 0.1321768528236047, 0.6465314814902021, 0.536282462460333, 0.06400352535139353, 0.21509234594015436, 0.3259347257965164, 0.04692498212931018, 0.43637598050563153, 0.10218530635521916, 0.137204726826735, 0.203708350583778, 0.12485044247047772, 0.6158663615841442, 0.12030940574969395, 0.4041481456011218, 0.10173919081141425, 0.12435816408644518, 0.23842937995472924, 0.24290961350923546, 0.2344893436839003, 0.356888362404849, 0.11185768244810024, 0.2909193993126157, 0.3028346236680294, 0.29280423703713554, 0.19231889688731663, 0.1185859601174497, 0.09264214888617206, 0.19057920186005317, 0.10729775962499044, 0.2583836504685455, 0.3489903995248155, 0.17842399996099834, 0.3034691396689825, 0.20105659684452437, 0.19569700553906633, 0.08486779588591875, 0.24212002790103682, 0.08133266283799145, 0.6862009208682724, 0.754972511189964, 0.7616710528192916, 0.68388707721152, 0.7431613763125231, 0.6710351301946589, 0.7497591771374971, 0.7679900034800324, 0.6701258589499814, 0.08964421385193311, 0.13788604019009543, 0.13646211638814387, 0.10969768007690106, 0.15469283960289582, 0.12143900669528707, 0.1092074144108709, 0.11371600425499218, 0.11352153834430012, 0.3374498382136196, 0.20949456222040252, 0.17639944417532405, 0.25678858429049, 0.24217070047633116, 0.3223558936142904, 0.23209234516209098, 0.2822161800965921, 0.16582403824707204, 0.35400302101868286, 0.3888234400717976, 0.4135652585354389, 0.39788243001995705, 0.4117080453930043, 0.42310931385295925, 0.28445973378939593, 0.32138473734378337, 0.37648016100749104, 0.31379694031875915, 0.1976535433444837, 0.2392163881531606, 0.2731919383728235, 0.25019959248066925, 0.245733772695789, 0.24548966258201665, 0.26727488179276093, 0.26513289654129635, 0.2777837755792745, 0.20329330213543984, 0.21153807641678035, 0.31792971717373, 0.2293050311748167, 0.23462313762613374, 0.28068838249565775, 0.24996436159132607, 0.24991307186537937, 0.21655659088671342, 0.20103531261612928, 0.21701739698828915, 0.1965321453937332, 0.21567875273748893, 0.1837883680763699, 0.1826666272490408, 0.18801102265594205, 0.18318277898910262, 0.9193909442673247, 0.18531901810264118, 0.17776518150082432, 0.9148668257844085, 0.19916175930751, 0.16569004280404986, 0.9049321825927265, 0.16563449825560272, 0.9002469630469294, 0.8890240508208074, 0.21227920568468595, 0.8382265622340266, 0.20919068432983723, 0.8680501644388762, 0.8083834411821523, 0.786603887675285, 0.820288041352974, 0.20937565617574205, 0.2158148931285615, 0.18796647638120567, 0.196808231491563, 0.2088241277845394, 0.22722527524755065, 0.1957252669687103, 0.20203166868135136, 0.19534342180643982, 0.18656247118609603, 0.09888046246061455, 0.10303033416554697, 0.09451559435667756, 0.0797911780259628, 0.08858711784797435, 0.15092267083882094, 0.14961978070901039, 0.0826622027630538, 0.10450107803947506]}, "mutation_prompt": null}
{"id": "ff1bc483-9016-40b8-9e7b-4058c31c056e", "solution": "import numpy as np\n\nclass EnhancedChaoticDEPSOHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 8 * dim\n        self.current_eval = 0\n        self.bounds = (-5.0, 5.0)\n        self.w = 0.7\n        self.c1 = 1.8\n        self.c2 = 1.5\n        self.F = 0.9\n        self.CR = 0.85\n        self.adapt_factor = 0.99\n        self.diversity_prob = 0.3\n\n    def chaotic_sequence(self, n):\n        x = np.random.rand()\n        sequence = []\n        for _ in range(n):\n            x = 3.9 * x * (1 - x)\n            sequence.append(x)\n        return np.array(sequence)\n\n    def __call__(self, func):\n        pop = np.random.uniform(self.bounds[0], self.bounds[1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.4, 0.4, (self.pop_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        while self.current_eval < self.budget:\n            self.w *= self.adapt_factor\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.bounds[0], self.bounds[1])\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_value = func(trial)\n                self.current_eval += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            chaotic_factor = self.chaotic_sequence(self.pop_size)\n\n            for i in range(self.pop_size):\n                if self.current_eval >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                \n                velocities[i] = np.clip(velocities[i] * chaotic_factor[i], -1.5, 1.5)\n                pop[i] = np.clip(pop[i] + velocities[i], self.bounds[0], self.bounds[1])\n                value = func(pop[i])\n                self.current_eval += 1\n\n                if value < personal_best_values[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_values[i] = value\n                    if value < global_best_value:\n                        global_best = pop[i]\n                        global_best_value = value\n\n            if self.current_eval >= self.budget:\n                break\n\n            if np.random.rand() < self.diversity_prob:\n                for j in range(self.pop_size):\n                    perturbation = np.random.uniform(-0.5, 0.5, self.dim)\n                    challenger = np.clip(personal_best[j] + perturbation, self.bounds[0], self.bounds[1])\n                    challenger_value = func(challenger)\n                    self.current_eval += 1\n                    if challenger_value < personal_best_values[j]:\n                        personal_best[j] = challenger\n                        personal_best_values[j] = challenger_value\n                        if challenger_value < global_best_value:\n                            global_best = challenger\n                            global_best_value = challenger_value\n\n        return global_best", "name": "EnhancedChaoticDEPSOHybridOptimizer", "description": "An enhanced adaptive hybrid optimizer integrating differential evolution, particle swarm optimization, and chaotic perturbations for improved exploration and convergence.", "configspace": "", "generation": 99, "fitness": 0.38722086896636865, "feedback": "The algorithm EnhancedChaoticDEPSOHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.27.", "error": "", "parent_id": "ba4a0ecb-9e78-4120-a3bd-1ca218bef303", "metadata": {"aucs": [0.8644173139150133, 0.8328456018846988, 0.8610763077267642, 0.8477179151718326, 0.8564433089001897, 0.8481516790183837, 0.8510051093211517, 0.8551877533909504, 0.8390536708193701, 0.6416549569397587, 0.6390757876512594, 0.6291170639936834, 0.6611235112033789, 0.7125742703298765, 0.6547400512833026, 0.6931712231986134, 0.5971202437030948, 0.6440756186467269, 0.15861226324379119, 0.14252786703105247, 0.09391218679348456, 0.11444215569038207, 0.1411656859800915, 0.13630312887187668, 0.12756696541246437, 0.13991034655190593, 0.10912315659347682, 0.0793934305619477, 0.10418051578043519, 0.10686428798977288, 0.11517084171599012, 0.11599572494340227, 0.09121617997142728, 0.09957037099081523, 0.10908004903968127, 0.11842989564754913, 0.9404707083877448, 0.935908724930157, 0.9438367307737568, 0.9322892762232649, 0.9144643132924419, 0.908419069212183, 0.9539785026028689, 0.938551636276905, 0.9423532784915357, 0.722339369173178, 0.7094181237043304, 0.6286217714074294, 0.7143271641700213, 0.6693853163942787, 0.6952683201504546, 0.7243140283372329, 0.6624323287517209, 0.7203760620530573, 0.8532572492854129, 0.8570768149836894, 0.22604847003881146, 0.8057211491674449, 0.8967006683935672, 0.3715696551570997, 0.23171630657166764, 0.17625627045946368, 0.23163078916591429, 0.5272372672115928, 0.5657912048042347, 0.46765035232218244, 0.34161473812131093, 0.12536179517114088, 0.41462157246811093, 0.536947612281923, 0.7057332909286755, 0.13325684970668494, 0.4330421607013917, 0.5149719875475568, 0.4419713085786342, 0.6582817041612785, 0.5848926212215139, 0.533695139492223, 0.5847209455556808, 0.630176812524194, 0.6767037812349949, 0.15454704648691842, 0.1063322310371494, 0.12976328616776878, 0.09265470252864305, 0.2696603802100812, 0.2574320894668878, 0.11005900713141292, 0.25172008746078334, 0.20551729600091406, 0.21539394108470755, 0.31060558923750325, 0.3607188254838788, 0.3196557434668541, 0.21303998702530058, 0.32533138414139595, 0.3883724141563847, 0.5142664726803191, 0.24621981249019587, 0.2073704799843029, 0.1213307277332093, 0.14084219257959563, 0.21380595863258245, 0.263389933237676, 0.2271454022869328, 0.37011829964488874, 0.19063041555251825, 0.07037497368993262, 0.22444030712046525, 0.31920794939505526, 0.24930165053212727, 0.3070847662046122, 0.255783489893078, 0.35409674735456265, 0.30181175982186326, 0.18714271015025008, 0.1062858001687278, 0.6757976933197718, 0.7369781253648842, 0.6775523800138987, 0.7084769530708548, 0.7113238945591693, 0.7417390066482477, 0.6650559353666016, 0.6665992278913457, 0.6895562215611113, 0.06353190882238902, 0.14602940020723765, 0.07142852292486279, 0.1279145450962904, 0.14150312283020172, 0.11569616160528096, 0.135634584755007, 0.1381696644092264, 0.08481942746169391, 0.1509214928027428, 0.2744162019585036, 0.27549203101009245, 0.300475934519555, 0.1956268789572625, 0.20358857397942576, 0.37733768398881573, 0.19473146806292296, 0.4095003040000824, 0.45527912405836546, 0.3849798493435036, 0.28150001961674953, 0.36586629545881366, 0.5240376294162574, 0.4365117189717952, 0.23715686385061174, 0.3708909291874739, 0.25646995003197315, 0.3108399722950548, 0.3057954413605789, 0.2633053270704927, 0.3716423208038391, 0.21380740147193122, 0.27701795444208954, 0.33570566680543734, 0.27490703017174833, 0.23914240552216892, 0.25075497285928006, 0.2047051870298816, 0.2389644696578993, 0.24060933807252582, 0.25430409309293367, 0.2113452720891521, 0.22152749766104707, 0.23032960680763426, 0.20661913517693442, 0.19332180617785066, 0.18475847085490837, 0.16687762430942643, 0.18194753970893573, 0.20718936186198267, 0.17221706251190372, 0.18083152602650676, 0.19064344875407646, 0.19367587005492837, 0.16896910228717466, 0.8491220636557832, 0.18511275424045626, 0.9063660277642264, 0.1994650153638048, 0.18614823864090035, 0.8600664847806389, 0.8962636290653441, 0.8909289288656357, 0.8823237149192413, 0.21087663560966796, 0.8763771484048364, 0.15627067451203913, 0.2060048375156487, 0.6816452001581582, 0.12548509870082614, 0.8661582378076743, 0.16512183933924773, 0.19526710217646093, 0.20010137111198778, 0.18205380105796054, 0.20017643691653253, 0.19541378110644447, 0.18930391715051953, 0.20994252705611627, 0.19796302187246784, 0.18821229935854544, 0.10364669488855127, 0.09284322321069116, 0.1015057132556143, 0.09739935395438237, 0.09371012182903526, 0.07939457760301716, 0.08907350778004852, 0.10059078657325193, 0.09815475869249679]}, "mutation_prompt": null}

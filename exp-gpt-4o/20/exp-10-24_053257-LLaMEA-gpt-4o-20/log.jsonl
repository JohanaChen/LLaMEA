{"id": "cccc43a6-41b3-4e1d-95eb-59d99e3dd60f", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // (dim * 5))\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            # Evaluate current population\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            # Update velocities and positions (PSO)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            # Apply Differential Evolution mutation\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + self.F * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "HybridPSODE", "description": "A hybrid metaheuristic combining Particle Swarm Optimization and Differential Evolution to adaptively balance exploration and exploitation.", "configspace": "", "generation": 0, "fitness": 0.22406527398612686, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.21.", "error": "", "parent_id": null, "metadata": {"aucs": [0.5091733627763539, 0.43365156368514746, 0.49519814976718657, 0.44923230852523544, 0.5343955837634107, 0.4849490892835535, 0.43546039445799456, 0.48071192833030585, 0.48200825425574534, 0.13146159816872405, 0.0992432444586906, 0.011081246494431984, 0.07614932253916706, 0.07361199646914629, 0.018444650292263387, 0.0036586689405719852, 0.09446714310337956, 0.0055018617300937045, 0.1434447972403574, 0.14083498299602704, 0.10570964862156451, 0.13555841833048288, 0.10006122025820607, 0.08884803754411041, 0.09866536120998948, 0.1170199983910496, 0.11334500164491823, 0.08283950280129515, 0.07581024945972381, 0.11268988520938494, 0.10274191660700982, 0.08285591638601764, 0.08046199490505446, 0.08969781538563926, 0.11391575449393587, 0.08839975616875129, 0.9788049714528467, 0.9674923884100938, 0.9861190644478779, 0.9316323666662025, 0.9683668408288333, 0.9681696890680042, 0.9863439170220196, 0.9765554127406889, 0.9731198906222748, 0.21778517803303343, 0.2614495570138301, 0.22554801853332018, 0.14044396155126493, 0.14301251377367885, 0.26370588217988444, 0.08036764440917976, 0.08724720567494149, 0.29832669232979847, 0.5359865971175565, 0.21029516759304456, 0.5844260632554794, 0.21329921477962788, 0.546886759854168, 0.186742268493574, 0.1220200889135965, 0.38319273593945957, 0.5132485834683189, 0.2399131467203547, 0.10892418206512378, 0.14383381803366524, 0.079547202605878, 0.14856528162114968, 0.19319261805939925, 0.11444515341751904, 0.27187101876345443, 0.1785245911543838, 0.09480656058530879, 0.12998044751310767, 0.12288857832105948, 0.12579693377868884, 0.11644097226565753, 0.1416353726004823, 0.14996849623457853, 0.12475275809021291, 0.20671410614169916, 9.999999999998899e-05, 0.0400945981648565, 0.04756016682892927, 0.012590526727159324, 0.06722900082668914, 0.011088343291504543, 0.023359957294164846, 0.03080437286464588, 0.061251680237181416, 0.11279065183356085, 0.07576341293056976, 0.12639741843690266, 0.08435211210638538, 0.05804200574396723, 0.05873108334028421, 0.0720466371175098, 0.1477097175763218, 0.11858696050093964, 0.00848609391683075, 0.016704287926477046, 0.011639411822705892, 0.03017409022679307, 0.00597335679691946, 0.026056461099723816, 0.022501523313907312, 0.03262630738087191, 0.00795790780235861, 0.12311262014443236, 0.11915772751591758, 0.08047486669850223, 0.14335716827352352, 0.11173328668952576, 0.08947762828133488, 0.049029568345897445, 0.06699451689783587, 0.07126378602651073, 0.4675675102620508, 0.41972385930101797, 0.4216144438741982, 0.4806729736105345, 0.4309098123975562, 0.4557022194483672, 0.5029057536106432, 0.39045901820995144, 0.38124759251719065, 0.08900621403149722, 0.09506790553180144, 0.0776124173916225, 0.09577410583849488, 0.10117119500036698, 0.09761093094171391, 0.08212681536745081, 0.10308201062665445, 0.11054051824663114, 0.19534686282043978, 0.2031863713748414, 0.15938156540283777, 0.1863637861766957, 0.22475804177348724, 0.1810237110670525, 0.22471278653333615, 0.21669410961561075, 0.2113389790691108, 0.27289461263196824, 0.2647832608650944, 0.28741688721952396, 0.20937075989815346, 0.2753165410327202, 0.2811528387502341, 0.30101373950925714, 0.31092733282704743, 0.2777891384520873, 0.20372517984230487, 0.19966006962211835, 0.2168312740246181, 0.1964727752847324, 0.15695161464294938, 0.20750884328235697, 0.1824009644942588, 0.2061329378646718, 0.22323078772524219, 0.23137199344411574, 0.20752691448725724, 0.19971612928054294, 0.20535765529490746, 0.2086148335619762, 0.21794381836674515, 0.2247172898820139, 0.2199725505172797, 0.20218401695803379, 0.19234623735614864, 0.18381136638974127, 0.20074256923088452, 0.20386845917927898, 0.28457068401185726, 0.21268355821617957, 0.1737013147099944, 0.1860519467624384, 0.18118718396749034, 0.7040118245116402, 0.16746325183977384, 0.15170192244955927, 0.7434256966475394, 0.19713042402213776, 0.1942704959685485, 0.14145875878164627, 0.5352355660406707, 0.6460930470740724, 0.6332655776076628, 0.2088392410814882, 0.16319025689895794, 0.19844032567853653, 0.5655258340687549, 0.15298683844961347, 0.19673139051384436, 0.20279450623859685, 0.20444298160565755, 0.19045535247092116, 0.19414205039181365, 0.19297426112633798, 0.20111145983238732, 0.19360538948225425, 0.2098204362456776, 0.17593488770595633, 0.18109612403402908, 0.18755170974686175, 0.0700495306544926, 0.08426910814258903, 0.0800099717077355, 0.09568118298030348, 0.08855960294285492, 0.07585546249189357, 0.07806646632164815, 0.08657263281898564, 0.09087623097968967]}, "mutation_prompt": null}
{"id": "9d0f4e6d-37b6-4389-b296-a18853a1b048", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // (dim * 5))\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.5\n        self.CR_max = 0.9\n        self.CR_min = 0.1\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            # Update inertia weight and crossover rate adaptively\n            w = self.w_max - (self.w_max - self.w_min) * (self.evaluations / self.budget)\n            CR = self.CR_min + (self.CR_max - self.CR_min) * (self.evaluations / self.budget)\n\n            # Evaluate current population\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            # Update velocities and positions (PSO)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            # Apply Differential Evolution mutation\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + self.F * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSODE", "description": "An enhanced hybrid metaheuristic combining Particle Swarm Optimization and Differential Evolution with adaptive inertia weight and crossover rate for improved exploration-exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.2129541035743576, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.20.", "error": "", "parent_id": "cccc43a6-41b3-4e1d-95eb-59d99e3dd60f", "metadata": {"aucs": [0.45937014494645934, 0.5030175401361745, 0.5119532066921801, 0.4642878682256867, 0.4358944738336975, 0.3921361974839288, 0.46949990615971315, 0.47810145074448385, 0.47067691893189767, 0.09624854137112293, 0.10055338924341195, 0.12179555104030948, 0.03837641248940349, 0.13225192594208401, 0.14599878480904283, 0.1039699573307944, 0.030215258848578008, 0.1327988827973151, 0.11003756846276991, 0.11092828277771727, 0.10138218815063194, 0.09855410230808426, 0.1235822956425745, 0.0808294416973182, 0.17215687359469978, 0.1013786249186649, 0.10834551673763948, 0.0741274651683228, 0.069811096486458, 0.08077151926684056, 0.08012174230599634, 0.09529433744818161, 0.09443860202006471, 0.0857260957645305, 0.10214395612366589, 0.08661661758900596, 0.9781702561667922, 0.9524129802156749, 0.9861452126787049, 0.9769023678470163, 0.968103250150248, 0.9743773338439645, 0.9858627510409684, 0.9685164506233744, 0.9685295641786139, 0.2532243881352352, 0.28503447528330106, 0.05456212603557464, 0.2629469925945096, 0.1398757028481843, 0.29772173158715476, 0.11476038512237974, 0.08511490943530986, 0.2313985398801507, 0.208940616314638, 0.2015054609795549, 0.4708656232846802, 0.20794768978747602, 0.44476848552929327, 0.1832450511357513, 0.1835028670987202, 0.12346081777779605, 0.46964416713230484, 0.18418616739122184, 0.059157911532484286, 0.1764679184463277, 0.06788084315971465, 0.1481407926309588, 0.130112679645762, 0.21013135834642394, 0.18084958045911004, 0.16094830356220646, 0.1872245516204849, 0.039045336674356945, 0.09550139125087076, 0.198357156236303, 0.13939860353311306, 0.11692286754446946, 0.11070597401590676, 0.07835430065775817, 0.1297917599225149, 0.03112554203474205, 0.0376910386882493, 0.03531816565939028, 9.999999999998899e-05, 0.009050472833306955, 0.008935968765192759, 0.022461028570447517, 0.08112341387400734, 0.07451683836496936, 0.10818233484022566, 0.05966705572764108, 0.10201383540860642, 0.05141601813955876, 0.04121428390693982, 0.0507990619651002, 0.030837997387850202, 0.13454846737256088, 0.03255791583823686, 0.015867736290057333, 0.015562556125877536, 0.010542598344047804, 0.02660676345871038, 0.029071579522144342, 0.01912466205077723, 0.033116732601359944, 0.03875888847988229, 0.026743052092608965, 0.10402915485579722, 0.07217556018836235, 0.07466417984869878, 0.0741169657506211, 0.10666579813910082, 0.12052199085469162, 0.05590099066369203, 0.05935808540692056, 0.05745553909254686, 0.40734485398472153, 0.37189312798743424, 0.40425342997250346, 0.4175719330766857, 0.42246524439068645, 0.4391648068331302, 0.4041285773512836, 0.43238581470846427, 0.42313775679011445, 0.07620800695915264, 0.10297761737693778, 0.06828877128309974, 0.15411714021583378, 0.09210440833976896, 0.15996857768548856, 0.07814473945964129, 0.0963846769280452, 0.11182525003072474, 0.14879186325721727, 0.21207817002670704, 0.18769587383939856, 0.21950915663779835, 0.24476062737073379, 0.3120007918746849, 0.29987846836097476, 0.20869296415483485, 0.19921932523114683, 0.2283315927539601, 0.27220754292650007, 0.31179737132289187, 0.2900092807341095, 0.25595573541037997, 0.23603217729136206, 0.2629343146158215, 0.25060219323880195, 0.3210422167141571, 0.1863401274399339, 0.19775043404366133, 0.15880918205161065, 0.1315517376469797, 0.21789915614764455, 0.15025644719584907, 0.1595314062267449, 0.237355697187009, 0.18848794452610562, 0.19535104957941396, 0.2112962449542125, 0.2380505597292094, 0.19772737852199762, 0.2028250663349238, 0.2128615473814831, 0.18627623266712212, 0.2190773701410751, 0.2010782924368495, 0.18285348158192516, 0.18664632604365394, 0.2031601201040074, 0.20404032483862888, 0.1707867778104415, 0.19770797012946717, 0.19028157549449964, 0.17307080380285567, 0.19293468373787126, 0.5572300272452616, 0.16230103337578095, 0.15169978111150828, 0.6189448860787787, 0.19252507795826845, 0.19121556128826223, 0.1419654285543649, 0.1590557082284042, 0.6064987171756002, 0.5798780939103227, 0.20796401336861958, 0.17361634824888317, 0.1847377158357285, 0.1673808266093092, 0.13084061313045714, 0.19542161018948545, 0.18990491668584863, 0.5790700522771589, 0.19887421076578649, 0.18941476466096852, 0.1935049112641546, 0.18887937276443068, 0.17305632389468906, 0.18343933125979828, 0.19026216476123448, 0.1838947319475942, 0.18732744581654948, 0.07064175887966972, 0.07993656779444513, 0.08466207929432279, 0.06843121042847411, 0.08530398012918083, 0.07054101454065909, 0.09096350411968301, 0.07283116936499845, 0.07200637824245115]}, "mutation_prompt": null}
{"id": "e607e351-75bd-4732-ad0c-c6f8c7286e3e", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // (dim * 5))\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            # Evaluate current population\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            # Update velocities and positions (PSO)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            # Apply Differential Evolution mutation\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + self.F * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "HybridPSODE", "description": "A hybrid metaheuristic combining Particle Swarm Optimization and Differential Evolution to adaptively balance exploration and exploitation.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "cccc43a6-41b3-4e1d-95eb-59d99e3dd60f", "metadata": {"aucs": [0.5091733627763539, 0.43365156368514746, 0.49519814976718657, 0.44923230852523544, 0.5343955837634107, 0.4849490892835535, 0.43546039445799456, 0.48071192833030585, 0.48200825425574534, 0.13146159816872405, 0.0992432444586906, 0.011081246494431984, 0.07614932253916706, 0.07361199646914629, 0.018444650292263387, 0.0036586689405719852, 0.09446714310337956, 0.0055018617300937045, 0.1434447972403574, 0.14083498299602704, 0.10570964862156451, 0.13555841833048288, 0.10006122025820607, 0.08884803754411041, 0.09866536120998948, 0.1170199983910496, 0.11334500164491823, 0.08283950280129515, 0.07581024945972381, 0.11268988520938494, 0.10274191660700982, 0.08285591638601764, 0.08046199490505446, 0.08969781538563926, 0.11391575449393587, 0.08839975616875129, 0.9788049714528467, 0.9674923884100938, 0.9861190644478779, 0.9316323666662025, 0.9683668408288333, 0.9681696890680042, 0.9863439170220196, 0.9765554127406889, 0.9731198906222748, 0.21778517803303343, 0.2614495570138301, 0.22554801853332018, 0.14044396155126493, 0.14301251377367885, 0.26370588217988444, 0.08036764440917976, 0.08724720567494149, 0.29832669232979847, 0.5359865971175565, 0.21029516759304456, 0.5844260632554794, 0.21329921477962788, 0.546886759854168, 0.186742268493574, 0.1220200889135965, 0.38319273593945957, 0.5132485834683189, 0.2399131467203547, 0.10892418206512378, 0.14383381803366524, 0.079547202605878, 0.14856528162114968, 0.19319261805939925, 0.11444515341751904, 0.27187101876345443, 0.1785245911543838, 0.09480656058530879, 0.12998044751310767, 0.12288857832105948, 0.12579693377868884, 0.11644097226565753, 0.1416353726004823, 0.14996849623457853, 0.12475275809021291, 0.20671410614169916, 9.999999999998899e-05, 0.0400945981648565, 0.04756016682892927, 0.012590526727159324, 0.06722900082668914, 0.011088343291504543, 0.023359957294164846, 0.03080437286464588, 0.061251680237181416, 0.11279065183356085, 0.07576341293056976, 0.12639741843690266, 0.08435211210638538, 0.05804200574396723, 0.05873108334028421, 0.0720466371175098, 0.1477097175763218, 0.11858696050093964, 0.00848609391683075, 0.016704287926477046, 0.011639411822705892, 0.03017409022679307, 0.00597335679691946, 0.026056461099723816, 0.022501523313907312, 0.03262630738087191, 0.00795790780235861, 0.12311262014443236, 0.11915772751591758, 0.08047486669850223, 0.14335716827352352, 0.11173328668952576, 0.08947762828133488, 0.049029568345897445, 0.06699451689783587, 0.07126378602651073, 0.4675675102620508, 0.41972385930101797, 0.4216144438741982, 0.4806729736105345, 0.4309098123975562, 0.4557022194483672, 0.5029057536106432, 0.39045901820995144, 0.38124759251719065, 0.08900621403149722, 0.09506790553180144, 0.0776124173916225, 0.09577410583849488, 0.10117119500036698, 0.09761093094171391, 0.08212681536745081, 0.10308201062665445, 0.11054051824663114, 0.19534686282043978, 0.2031863713748414, 0.15938156540283777, 0.1863637861766957, 0.22475804177348724, 0.1810237110670525, 0.22471278653333615, 0.21669410961561075, 0.2113389790691108, 0.27289461263196824, 0.2647832608650944, 0.28741688721952396, 0.20937075989815346, 0.2753165410327202, 0.2811528387502341, 0.30101373950925714, 0.31092733282704743, 0.2777891384520873, 0.20372517984230487, 0.19966006962211835, 0.2168312740246181, 0.1964727752847324, 0.15695161464294938, 0.20750884328235697, 0.1824009644942588, 0.2061329378646718, 0.22323078772524219, 0.23137199344411574, 0.20752691448725724, 0.19971612928054294, 0.20535765529490746, 0.2086148335619762, 0.21794381836674515, 0.2247172898820139, 0.2199725505172797, 0.20218401695803379, 0.19234623735614864, 0.18381136638974127, 0.20074256923088452, 0.20386845917927898, 0.28457068401185726, 0.21268355821617957, 0.1737013147099944, 0.1860519467624384, 0.18118718396749034, 0.7040118245116402, 0.16746325183977384, 0.15170192244955927, 0.7434256966475394, 0.19713042402213776, 0.1942704959685485, 0.14145875878164627, 0.5352355660406707, 0.6460930470740724, 0.6332655776076628, 0.2088392410814882, 0.16319025689895794, 0.19844032567853653, 0.5655258340687549, 0.15298683844961347, 0.19673139051384436, 0.20279450623859685, 0.20444298160565755, 0.19045535247092116, 0.19414205039181365, 0.19297426112633798, 0.20111145983238732, 0.19360538948225425, 0.2098204362456776, 0.17593488770595633, 0.18109612403402908, 0.18755170974686175, 0.0700495306544926, 0.08426910814258903, 0.0800099717077355, 0.09568118298030348, 0.08855960294285492, 0.07585546249189357, 0.07806646632164815, 0.08657263281898564, 0.09087623097968967]}, "mutation_prompt": null}
{"id": "068f7dee-9d76-45fc-a181-cace0201fd08", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // (dim * 5))\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2 = 1.3\n        self.F = 0.6\n        self.CR = 0.8\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            # Evaluate current population\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            w = self.w_max - ((self.w_max - self.w_min) * (self.evaluations / self.budget))\n\n            # Update velocities and positions (PSO)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            # Apply Differential Evolution mutation\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + self.F * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSODE", "description": "An enhanced hybrid algorithm integrating Particle Swarm Optimization, Differential Evolution, and adaptive inertia weights to optimize exploration and exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.21785508838885814, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.20.", "error": "", "parent_id": "cccc43a6-41b3-4e1d-95eb-59d99e3dd60f", "metadata": {"aucs": [0.42918518463708144, 0.46158449164991844, 0.44536641318270453, 0.4464415674284592, 0.388001218519197, 0.4602835921632028, 0.49678444286350043, 0.4387022183454051, 0.45090962993682493, 0.10785351800934984, 0.07049489382809149, 0.026909065663278442, 0.07317843603396468, 0.06572256366167606, 0.07417116791989742, 0.02334656772159982, 0.09867850775190656, 0.03474388870018452, 0.09345741086416404, 0.08741422450374936, 0.0670661619807068, 0.10024812092719781, 0.1121471824544833, 0.1046696231412263, 0.13561369267724932, 0.10584620913558351, 0.09051866013600252, 0.09229166669623678, 0.0859122487756444, 0.06254815352510668, 0.07551856635840193, 0.09396207430446157, 0.12281608510728181, 0.08876757014783976, 0.08550092411824406, 0.10043058083425804, 0.9783609404843092, 0.9765710471658539, 0.9860539573112814, 0.9500688464445707, 0.9753205071543611, 0.9684242502604463, 0.9770385819514683, 0.9765145921365316, 0.976662042577811, 0.31585388367721623, 0.25276103693198704, 0.1875763165585328, 0.19988351680403205, 0.2458444437270093, 0.24425899849407084, 0.10761053005537558, 0.2347420569137908, 0.30460751666828323, 0.3429736775655008, 0.2660516863345451, 0.43161292868426204, 0.20848004369563022, 0.45815047858193014, 0.18713533692177076, 0.4826783648469988, 0.4452269584924893, 0.457169335175994, 0.11327934963848818, 0.15605035679692303, 0.1727902584244836, 0.0700271543772486, 0.12133562087231398, 0.1664925709201217, 0.104431659689737, 0.09440078030294041, 0.14009120946305942, 0.13838707329924949, 0.10830751417910922, 0.13035953482570717, 0.11241910046293435, 0.13827476696845042, 0.11925656945909757, 0.15469706304245046, 0.10198233870037487, 0.0940484735766689, 9.999999999998899e-05, 0.023468961335366134, 0.03733391370289152, 0.02008516797552018, 9.999999999998899e-05, 0.010898359557807491, 0.0293256894977012, 0.006213899509310394, 0.03135996925096329, 0.06931383303758065, 0.1167181973093877, 0.13890744666268728, 0.186781596857032, 0.019311427245831014, 0.13999371927369686, 0.14542910568278056, 0.18810332288856046, 0.09664311415495996, 0.027954681485025112, 0.03180811136480244, 0.023736883875526082, 0.09166317941662949, 0.01884278850827703, 0.019938334092578724, 0.032698937327875544, 0.026016512937104386, 0.031622135540506524, 0.14012408472275673, 0.027799271207320064, 0.10957180424933743, 0.12108642097204991, 0.103848958173127, 0.10329492411761165, 0.04018274713001335, 0.08577891546655647, 0.0629751240897809, 0.37709219229607216, 0.34423452735738735, 0.3586585042669005, 0.36199755595453087, 0.40472621836713596, 0.3823357559199503, 0.36655408328683314, 0.37429693102634065, 0.35763004937223686, 0.07282839116967921, 0.08946161706392364, 0.07799632271897683, 0.10029336014098211, 0.10328917509042734, 0.09425162536457865, 0.09530250876169244, 0.0802538610114627, 0.10654366920823066, 0.1537284546989618, 0.21979305277545813, 0.17463221116818317, 0.23752098932181587, 0.2325195296998812, 0.14251758229934786, 0.18233330486680677, 0.1653657417711909, 0.18300318933037607, 0.2989247154327437, 0.2781167336049968, 0.2651679703394577, 0.2831376647061514, 0.2621861192671354, 0.28987078558428225, 0.29488512000232114, 0.2865898686267534, 0.29445600347013956, 0.19308147319962377, 0.19934451800531927, 0.17309066902704273, 0.18962243487377628, 0.22151697996639574, 0.1825046765322571, 0.22433700041256643, 0.22302969727806754, 0.2242594823324785, 0.20978848606084, 0.21061979161331323, 0.200183752805828, 0.1910527917752496, 0.19813550863505425, 0.18146151484732198, 0.200736358424091, 0.2019095676225099, 0.1944221166160378, 0.2466627225538599, 0.1717614993834381, 0.20065551766976053, 0.19723302217019767, 0.16238248226660668, 0.18193530296674243, 0.19486189196922943, 0.18051008554613523, 0.19687784181791002, 0.6339240388374909, 0.5420323280229157, 0.1528475643790722, 0.5797004417586784, 0.1957938375748125, 0.18237217926574034, 0.1410422898457182, 0.4945921832199037, 0.5586403990566831, 0.5251299642664973, 0.19340754042752928, 0.3509967698137121, 0.20022152602964105, 0.16593642486281313, 0.15644387821327432, 0.1982813967050131, 0.15145031614231685, 0.47458781503718017, 0.17876344089652552, 0.18301276952994805, 0.18488595552867926, 0.18798184934670703, 0.1935522145532832, 0.1810045192459353, 0.18358577540309007, 0.18641083617860255, 0.19034211964215064, 0.09374730922734431, 0.0671377265570211, 0.07452650236935165, 0.07745992532893875, 0.08237044095696788, 0.0826131874139453, 0.08179867505692251, 0.07619608168119285, 0.07905496496431574]}, "mutation_prompt": null}
{"id": "48600216-f531-4933-928f-4d0b012960cd", "solution": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // (dim * 5))\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            # Evaluate current population\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            # Update velocities and positions (PSO) with adaptive inertia weight\n            w = self.w_max - ((self.w_max - self.w_min) * (self.evaluations / self.budget))\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            # Apply Differential Evolution mutation\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = np.delete(np.arange(self.population_size), i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + self.F * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "RefinedHybridPSODE", "description": "A refined hybrid metaheuristic combining Particle Swarm Optimization, Differential Evolution, and adaptive inertia weight to dynamically balance exploration and exploitation based on convergence progress.", "configspace": "", "generation": 4, "fitness": 0.21285100508642554, "feedback": "The algorithm RefinedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.21.", "error": "", "parent_id": "cccc43a6-41b3-4e1d-95eb-59d99e3dd60f", "metadata": {"aucs": [0.4748215477560217, 0.44637558675355793, 0.4529520063158732, 0.46905963974811526, 0.46635411733237264, 0.5008345062829184, 0.48544505328799137, 0.45271102476757796, 0.3871450068956659, 0.09179429014326956, 0.07419361192180329, 0.07917241307602962, 0.011600194436967803, 0.10333776399771577, 0.03915250980292262, 0.07741918642159218, 0.05709893472935201, 0.09831336398173696, 0.09762530155965266, 0.10601083781513332, 0.07922617645715657, 0.09478433355008875, 0.09901055370414047, 0.09131439898269722, 0.10992700879236905, 0.09414492591127621, 0.10815570865149837, 0.09047236732402597, 0.07215923477661601, 0.0776154567433438, 0.08659477948596106, 0.08991950513896774, 0.0725308810968005, 0.08590322722480526, 0.07994753649564446, 0.07361891244500807, 0.9786991891045403, 0.974577797094573, 0.9863591315332205, 0.9245047606064367, 0.9740623252758347, 0.9683930594000705, 0.9863207918165674, 0.9765435682373929, 0.9752047551690084, 0.3009938978257576, 0.25557416046621295, 0.2702692067523239, 0.25953008900723795, 0.13566717374926374, 0.14304626196060566, 0.08033202762957803, 0.08682915914551537, 0.27421613171346815, 0.1673461963976135, 0.21268143603631362, 0.20801812926079644, 0.1937962995872181, 0.5248438318923927, 0.1933101195100242, 0.4099985869471545, 0.4061726602341347, 0.21761363444014192, 0.14592048802446766, 0.07695600389596402, 0.18371305396193938, 0.08069895059601839, 0.0975660543047745, 0.09277238995328552, 0.1684009945537951, 0.15560025180922787, 0.16658863650628009, 0.11005684874082622, 0.09072336269179782, 0.19495309035818376, 0.10007497270165167, 0.1303135942107594, 0.12901363243693287, 0.24653190659643875, 0.08051729507496608, 0.1319728409750316, 9.999999999998899e-05, 9.999999999998899e-05, 0.023590231018443042, 9.999999999998899e-05, 9.999999999998899e-05, 0.006974263665169067, 0.001433177984944578, 0.04810818438114017, 0.02926018313465739, 0.059991052654515986, 0.20722985379062697, 0.15581197900035637, 0.11342305315354517, 0.16663267035191387, 0.03962060854870919, 0.015638170166695442, 0.13801964025062485, 0.024396559246540384, 9.999999999998899e-05, 0.010318591103614771, 0.010926102922749648, 0.02427952204038697, 0.02889182357880693, 0.01113463255034186, 0.06038784408117481, 0.029939584288161458, 0.03488529178897892, 0.09886762610172295, 0.04613664370380921, 0.09698701294439538, 0.11262341397024689, 9.999999999998899e-05, 0.11883773227186956, 0.040638665451048994, 0.13499118870161653, 0.048851578846438315, 0.3906972037281302, 0.3826936167652608, 0.40205489923673043, 0.4083791379318972, 0.41644400550031624, 0.3895476727821763, 0.39351436125926775, 0.35567655561196054, 0.3789044807767308, 0.07906863704814238, 0.08922270342895477, 0.09657172919018486, 0.10186877106731496, 0.11097524228222388, 0.10939236334440705, 0.09181275263200062, 0.11459765077375672, 0.09331799237235805, 0.19169076943016738, 0.3648509332852241, 0.17358429015286492, 0.16621917952864007, 0.2001645162309904, 0.16355626195024875, 0.2300335971667994, 0.20036351427898846, 0.18780963812869955, 0.27212226260845684, 0.27726855027772446, 0.2774414333052643, 0.28914439253571955, 0.26882344645233847, 0.2575133313400867, 0.2572209180090941, 0.24967594943991667, 0.24361906993438542, 0.2087984070637251, 0.19403855164600758, 0.1754558225037245, 0.1978218712350286, 0.19888830065796848, 0.22388625193106826, 0.20332110813880422, 0.22716004466387463, 0.2033952395516756, 0.20097612891098593, 0.21411906614987242, 0.17829454478491769, 0.204405887553056, 0.18178767957722064, 0.18784189988191813, 0.21234931563366322, 0.1834848809369708, 0.1952759459669181, 0.19155780375448994, 0.2162406089432195, 0.23513610771859395, 0.18382414214946474, 0.1844877814124366, 0.19204618091678216, 0.19075287590023204, 0.1984620799825597, 0.16970936037201534, 0.5680101429405677, 0.16675572551838325, 0.1522118084032028, 0.5955159312841867, 0.18710449165616083, 0.18574997699166385, 0.13742507917068347, 0.39401307724788537, 0.6194433876833061, 0.5579458786398228, 0.2048267347273689, 0.19022768417921798, 0.5197937057714583, 0.15978706491747052, 0.1441143870383299, 0.1982646137865609, 0.19016711900456562, 0.5616673438745412, 0.1896494519157026, 0.18177022217979033, 0.18610518712036705, 0.1909070840541227, 0.18788353154796777, 0.2050210270981676, 0.2065814400157473, 0.20861845488777075, 0.18575502674322075, 0.07091575615845724, 0.07846618600301192, 0.07666685664871731, 0.06914320886074454, 0.0798950886451032, 0.07176302439035831, 0.07158851615970996, 0.08123785865653377, 0.08801777333677596]}, "mutation_prompt": null}
{"id": "849c7b63-8aca-4146-85bd-a070baaee65b", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // (dim * 5))\n        self.w = 0.6 + 0.1 * np.random.rand()  # Slightly varying inertia weight\n        self.c1 = 1.4 + 0.1 * np.random.rand()  # Slightly varying cognitive coefficient\n        self.c2 = 1.6 + 0.1 * np.random.rand()  # Slightly varying social coefficient\n        self.F = 0.5 + 0.1 * np.random.rand()  # Adaptive mutation factor\n        self.CR = 0.9\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            # Evaluate current population\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            # Update velocities and positions (PSO)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            # Apply Differential Evolution mutation with adaptive mutation strategy\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + (self.F + np.random.uniform(-0.1, 0.1)) * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSODE", "description": "A novel hybrid metaheuristic that combines Particle Swarm Optimization, Differential Evolution, and adaptive mutation strategies to balance exploration and exploitation dynamically.", "configspace": "", "generation": 5, "fitness": 0.24358256358956776, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.22.", "error": "", "parent_id": "cccc43a6-41b3-4e1d-95eb-59d99e3dd60f", "metadata": {"aucs": [0.44841607368763337, 0.547790966916554, 0.527401468669612, 0.5906753670422049, 0.5850997109247956, 0.5382628203051285, 0.48387226597940547, 0.5065070328235036, 0.6145157607183769, 0.1065248802361195, 0.06061886617393464, 0.04612659616004766, 0.06889671250288187, 9.999999999998899e-05, 0.14715900544503113, 0.027451936000197574, 0.006252175874653543, 0.18645194457280767, 0.08537027159145694, 0.13106364406810767, 0.13438031258840621, 0.09282562692972351, 0.14302062877506072, 0.1650570350430438, 0.11488728526328684, 0.13901957929176711, 0.11168601543770096, 0.11559327729515301, 0.10312787951600699, 0.08979823291772959, 0.10489890519607503, 0.09137922476519611, 0.10587608200501386, 0.09960247175779657, 0.12225044319872735, 0.10420705952643294, 0.977179819660313, 0.9792350592658948, 0.9860388481617137, 0.9853636596368439, 0.9761965153628566, 0.9639298852224569, 0.9810022813153767, 0.9852174275481163, 0.9733806357246094, 0.3462375975900934, 0.341630755218839, 0.37627455117645014, 0.2784524398526095, 0.24345631376314225, 0.2902131122633699, 0.29239069572690934, 0.08820945073163988, 0.31385381175736715, 0.7362250810836433, 0.21911430860168868, 0.2146262178167052, 0.18638182100672862, 0.26811572432135256, 0.19696508277728353, 0.2351292892761132, 0.46894773002840096, 0.5410898648692933, 0.14497335353018792, 0.1193405718079521, 0.11371351290993226, 0.18201961858961857, 0.08664724430875503, 0.12763024428516323, 0.1543094795536365, 0.10329032394220161, 0.17829807031377443, 0.18630713351526496, 0.22866738523260877, 0.21812356613369477, 0.144995992422971, 0.15785489663569474, 0.16292256064050326, 0.11885907764283943, 0.18839017397441415, 0.14685800852208708, 0.00234090905946871, 0.058785463474609556, 0.056428624734207955, 0.06366354947040231, 0.060721002073151786, 0.0690712305508554, 0.004511790490320022, 0.04931407846427993, 0.10184557165306818, 0.11033623744775156, 0.12264767836476642, 0.14370862167311294, 0.07771013347685218, 0.08637776651655482, 0.060987769855976315, 0.09094030360356442, 0.16976276850804006, 0.06660832617461487, 0.05561042079727818, 0.10609707944650604, 0.06482919875651239, 0.0374286864604233, 0.03818888829390854, 0.038997208746080814, 0.11152413053913968, 0.03493232090442455, 0.055877468707248634, 0.009258101204180802, 0.12070279224023905, 0.15448917545209462, 0.11968858489037215, 0.14401113669421628, 0.13077952852584307, 0.11957883328319274, 0.05107001142710155, 0.14441640069376915, 0.44825878277568965, 0.46715667857204246, 0.5008334340812192, 0.40241213968245715, 0.45737579847122556, 0.46474080262824613, 0.39565088626493794, 0.4257960436952323, 0.45412670345552064, 0.09410223539659746, 0.12479753829600726, 0.12734090808695997, 0.1419696081028009, 0.14294237677614907, 0.11706687413132988, 0.14319196630470565, 0.12660010077590578, 0.10336561111644627, 0.23300316812354704, 0.19320499698951454, 0.17752623158341452, 0.21682968294885008, 0.1558533541860142, 0.176730056935249, 0.1911849775964759, 0.3523916242352717, 0.21836233481125722, 0.23436860041020136, 0.30710935918408055, 0.34724993384879477, 0.31486979958916117, 0.36213309958484274, 0.31088300784466993, 0.33101658469390693, 0.34872918645664386, 0.2900777043786139, 0.23930805778831432, 0.1808845212993253, 0.22733832102845908, 0.2161758293280227, 0.2521645911719702, 0.2855474896178979, 0.2294984957704559, 0.2773784289373705, 0.22737387082991156, 0.2034141305172541, 0.2091420485898723, 0.21153006641166072, 0.21340488615645015, 0.199949421116984, 0.25306407324978564, 0.21562249048504067, 0.22328519472139063, 0.19659719953315347, 0.26542950279979105, 0.22132295583708428, 0.2336369073432374, 0.20999031354178554, 0.21195285228494032, 0.18374725068980535, 0.18016119383519602, 0.21611335324487724, 0.19835878101867388, 0.1896168716313953, 0.1623260406197733, 0.1640557854713497, 0.19534684992483675, 0.7755145843304052, 0.7196966246623802, 0.19937505460206317, 0.15740195604357743, 0.72955635460605, 0.19905319569425706, 0.6802000069830934, 0.7182946052272308, 0.20705012646498722, 0.7244948973465664, 0.16372925950374195, 0.20738152922713093, 0.19913785654466531, 0.15571995710406228, 0.19004100822584946, 0.1758777151559371, 0.1939165220336746, 0.181203170535589, 0.1948651831474777, 0.19388467930728093, 0.19640288006120743, 0.1828162198974418, 0.1974568200250203, 0.08851698487395021, 0.09143701667855753, 0.08523101425785662, 0.10139692372856002, 0.07597497951104637, 0.08713093725182974, 0.08855448060518045, 0.0889697649102702, 0.08309291441483835]}, "mutation_prompt": null}
{"id": "65249ebd-4446-475c-8e23-6f3d30bebc3e", "solution": "import numpy as np\n\nclass AdvancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 4))  # Slightly increased population size\n        self.w = 0.5 + 0.2 * np.random.rand()  # More variation in inertia weight\n        self.c1 = 1.3 + 0.2 * np.random.rand()  # Increased variation in cognitive coefficient\n        self.c2 = 1.7 + 0.1 * np.random.rand()  # Adjusted social coefficient\n        self.F = 0.5 + 0.2 * np.random.rand()  # More adaptive mutation factor\n        self.CR = 0.8 + 0.1 * np.random.rand()  # Slightly adaptive crossover rate\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            # Evaluate current population\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            # Update velocities and positions (PSO)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            # Apply Differential Evolution mutation with adaptive mutation strategy\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + (self.F + np.random.uniform(-0.15, 0.15)) * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "AdvancedHybridPSODE", "description": "An advanced hybrid metaheuristic integrating Particle Swarm Optimization, Differential Evolution, and dynamic mutation strategies with adaptive crossover to enhance convergence and diversity.", "configspace": "", "generation": 6, "fitness": 0.25527530807393267, "feedback": "The algorithm AdvancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.22.", "error": "", "parent_id": "849c7b63-8aca-4146-85bd-a070baaee65b", "metadata": {"aucs": [0.5350591568215478, 0.5731464963567614, 0.6169349780047105, 0.6311134486581699, 0.5897846861918971, 0.5754934165809087, 0.512469744917072, 0.6690360314800943, 0.5776894005686477, 0.016062439674475848, 0.08651957801456811, 9.999999999998899e-05, 0.03287382416742057, 0.1748172356223311, 0.04937408166496138, 0.13260031530867722, 0.21614816847156515, 0.17954132427205916, 0.1065080796118405, 0.09639312306951464, 0.10676128272039465, 0.08733383448546228, 0.10905578336607269, 0.10689230276278416, 0.12441497062239137, 0.12371327653293773, 0.11548633156624943, 0.08814547137867812, 0.09726412800808992, 0.11799850663288669, 0.08974448135993895, 0.11044191088157529, 0.08644470326354547, 0.11887910785918188, 0.12070002419631642, 0.10681112109773039, 0.9737073912706383, 0.9595806434476776, 0.9838301125287819, 0.9720610090930242, 0.9634332895881066, 0.9627576173087048, 0.9809249237762477, 0.9818244373788175, 0.9735852185908977, 0.30252075846703674, 0.3844567981508883, 0.3000431869766075, 0.3183946637299654, 0.2530438545188811, 0.386371038251886, 0.28709930433978814, 0.08766836806406753, 0.37341351441381243, 0.5792098019994318, 0.5546701628332397, 0.21301931007402253, 0.1903071816877181, 0.2652302218579664, 0.1895403089987593, 0.22729928542753464, 0.6067012694815828, 0.6875408179602049, 0.2786800867970516, 0.11572331516067536, 0.23604137159540206, 0.13480144841825348, 0.17325315462186375, 9.999999999998899e-05, 0.15775648888997873, 0.2036561019040415, 0.24948537975029883, 0.23383184615570185, 0.19716233469519973, 0.2738864718516406, 0.2160240717006614, 0.19909236613403858, 0.19805651464938223, 0.20039130264781546, 0.20209432621193524, 0.16436820072750158, 0.04477762843836375, 0.12916204684654153, 0.044657028514218156, 9.999999999998899e-05, 9.999999999998899e-05, 0.011116059780698961, 0.14962912545939866, 0.03894730858077655, 0.11364268815667378, 0.0715431274445808, 0.02819034543559884, 0.2679578193077211, 0.051458922340544055, 0.13233846087452128, 0.058362819490676676, 0.13867666881370677, 0.22032311622407208, 0.21546400859617731, 0.009425415904143808, 0.06834395077028876, 0.0809332962842726, 0.06269689086961172, 0.029801855172166714, 0.06329311372190072, 0.06950174962385736, 0.058655346507832884, 0.0593401204521975, 0.10150532205158413, 0.09751272878635375, 0.1965271177406699, 0.10461759671891491, 0.17592916472758535, 0.1332597862186603, 0.06751263928621754, 0.03357832707850428, 0.13616846894485768, 0.46431856056786114, 0.4526919064082232, 0.501664094643808, 0.43347136125117935, 0.4445757935357749, 0.4623074407656652, 0.4575201302074424, 0.455654683879815, 0.46516676845421934, 0.14748970140660533, 0.08685512701420062, 0.10932322762224544, 0.1365056561811292, 0.12145586350593962, 0.14990851576044317, 0.1214448227575694, 0.10668192059025261, 0.10958455266073197, 0.18200427116764006, 0.17665550336912872, 0.16285203497296208, 0.2203983188721601, 0.2084230581785037, 0.31274042606001196, 0.24286361884948504, 0.1758418345347551, 0.4003824887460331, 0.35679039789628186, 0.23008046683794614, 0.3081316432224612, 0.26766499166636604, 0.38385323595157095, 0.2701907202033843, 0.33006557136784476, 0.3409428082370669, 0.32973099134357586, 0.17940411538693135, 0.1724456273260737, 0.2596057403422274, 0.19806728289145892, 0.25744978771792826, 0.24703349779420813, 0.2418067776009165, 0.27571931305554953, 0.15258366339611074, 0.22211122589396493, 0.2192801662893883, 0.20804300603426562, 0.27109256429409134, 0.2074899583480062, 0.24170506007923553, 0.18157138407030815, 0.21234578721499586, 0.21299527689408448, 0.1711843956973631, 0.20817774867500816, 0.1982223438902565, 0.28070200262159606, 0.20865922486521682, 0.2007174662367197, 0.2238813087324637, 0.20578740951107843, 0.18398823523601426, 0.7669573874556027, 0.18482309888404924, 0.18378034686810152, 0.5655916551543121, 0.197333701825394, 0.1994139964888102, 0.14161913632233658, 0.7149182363973321, 0.7741822359416055, 0.646662773109977, 0.20608517728089537, 0.602254897013758, 0.1108027862556068, 0.16550486618227855, 0.5594335794118581, 0.18926864789418973, 0.20171421342551998, 0.49491738578108413, 0.18392390807628967, 0.18222750280033773, 0.19511863242380556, 0.19941860066067807, 0.19201914137131337, 0.18886959062553155, 0.17152146520259126, 0.19134636799533145, 0.18926965374334326, 0.11363814972785147, 0.0829814564519511, 0.10058050971228771, 0.08652345466465072, 0.09077697580606436, 0.07899510502085505, 0.09032063465031337, 0.09400639642874775, 0.09491989464597461]}, "mutation_prompt": null}
{"id": "1769af42-c3f3-421d-94fd-a3dd3b49faea", "solution": "import numpy as np\n\nclass AdvancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 4))  # Slightly increased population size\n        self.w = 0.5 + 0.2 * np.random.rand()  # More variation in inertia weight\n        self.c1 = 1.3 + 0.2 * np.random.rand()  # Increased variation in cognitive coefficient\n        self.c2 = 1.7 + 0.1 * np.random.rand()  # Adjusted social coefficient\n        self.F = 0.5 + 0.2 * np.random.rand()  # More adaptive mutation factor\n        self.CR = 0.8 + 0.1 * np.random.rand()  # Slightly adaptive crossover rate\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            # Evaluate current population\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            # Update velocities and positions (PSO)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            # Apply Differential Evolution mutation with adaptive mutation strategy\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + (self.F + np.random.uniform(-0.15, 0.15)) * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "AdvancedHybridPSODE", "description": "An advanced hybrid metaheuristic integrating Particle Swarm Optimization, Differential Evolution, and dynamic mutation strategies with adaptive crossover to enhance convergence and diversity.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "65249ebd-4446-475c-8e23-6f3d30bebc3e", "metadata": {"aucs": [0.5350591568215478, 0.5731464963567614, 0.6169349780047105, 0.6311134486581699, 0.5897846861918971, 0.5754934165809087, 0.512469744917072, 0.6690360314800943, 0.5776894005686477, 0.016062439674475848, 0.08651957801456811, 9.999999999998899e-05, 0.03287382416742057, 0.1748172356223311, 0.04937408166496138, 0.13260031530867722, 0.21614816847156515, 0.17954132427205916, 0.1065080796118405, 0.09639312306951464, 0.10676128272039465, 0.08733383448546228, 0.10905578336607269, 0.10689230276278416, 0.12441497062239137, 0.12371327653293773, 0.11548633156624943, 0.08814547137867812, 0.09726412800808992, 0.11799850663288669, 0.08974448135993895, 0.11044191088157529, 0.08644470326354547, 0.11887910785918188, 0.12070002419631642, 0.10681112109773039, 0.9737073912706383, 0.9595806434476776, 0.9838301125287819, 0.9720610090930242, 0.9634332895881066, 0.9627576173087048, 0.9809249237762477, 0.9818244373788175, 0.9735852185908977, 0.30252075846703674, 0.3844567981508883, 0.3000431869766075, 0.3183946637299654, 0.2530438545188811, 0.386371038251886, 0.28709930433978814, 0.08766836806406753, 0.37341351441381243, 0.5792098019994318, 0.5546701628332397, 0.21301931007402253, 0.1903071816877181, 0.2652302218579664, 0.1895403089987593, 0.22729928542753464, 0.6067012694815828, 0.6875408179602049, 0.2786800867970516, 0.11572331516067536, 0.23604137159540206, 0.13480144841825348, 0.17325315462186375, 9.999999999998899e-05, 0.15775648888997873, 0.2036561019040415, 0.24948537975029883, 0.23383184615570185, 0.19716233469519973, 0.2738864718516406, 0.2160240717006614, 0.19909236613403858, 0.19805651464938223, 0.20039130264781546, 0.20209432621193524, 0.16436820072750158, 0.04477762843836375, 0.12916204684654153, 0.044657028514218156, 9.999999999998899e-05, 9.999999999998899e-05, 0.011116059780698961, 0.14962912545939866, 0.03894730858077655, 0.11364268815667378, 0.0715431274445808, 0.02819034543559884, 0.2679578193077211, 0.051458922340544055, 0.13233846087452128, 0.058362819490676676, 0.13867666881370677, 0.22032311622407208, 0.21546400859617731, 0.009425415904143808, 0.06834395077028876, 0.0809332962842726, 0.06269689086961172, 0.029801855172166714, 0.06329311372190072, 0.06950174962385736, 0.058655346507832884, 0.0593401204521975, 0.10150532205158413, 0.09751272878635375, 0.1965271177406699, 0.10461759671891491, 0.17592916472758535, 0.1332597862186603, 0.06751263928621754, 0.03357832707850428, 0.13616846894485768, 0.46431856056786114, 0.4526919064082232, 0.501664094643808, 0.43347136125117935, 0.4445757935357749, 0.4623074407656652, 0.4575201302074424, 0.455654683879815, 0.46516676845421934, 0.14748970140660533, 0.08685512701420062, 0.10932322762224544, 0.1365056561811292, 0.12145586350593962, 0.14990851576044317, 0.1214448227575694, 0.10668192059025261, 0.10958455266073197, 0.18200427116764006, 0.17665550336912872, 0.16285203497296208, 0.2203983188721601, 0.2084230581785037, 0.31274042606001196, 0.24286361884948504, 0.1758418345347551, 0.4003824887460331, 0.35679039789628186, 0.23008046683794614, 0.3081316432224612, 0.26766499166636604, 0.38385323595157095, 0.2701907202033843, 0.33006557136784476, 0.3409428082370669, 0.32973099134357586, 0.17940411538693135, 0.1724456273260737, 0.2596057403422274, 0.19806728289145892, 0.25744978771792826, 0.24703349779420813, 0.2418067776009165, 0.27571931305554953, 0.15258366339611074, 0.22211122589396493, 0.2192801662893883, 0.20804300603426562, 0.27109256429409134, 0.2074899583480062, 0.24170506007923553, 0.18157138407030815, 0.21234578721499586, 0.21299527689408448, 0.1711843956973631, 0.20817774867500816, 0.1982223438902565, 0.28070200262159606, 0.20865922486521682, 0.2007174662367197, 0.2238813087324637, 0.20578740951107843, 0.18398823523601426, 0.7669573874556027, 0.18482309888404924, 0.18378034686810152, 0.5655916551543121, 0.197333701825394, 0.1994139964888102, 0.14161913632233658, 0.7149182363973321, 0.7741822359416055, 0.646662773109977, 0.20608517728089537, 0.602254897013758, 0.1108027862556068, 0.16550486618227855, 0.5594335794118581, 0.18926864789418973, 0.20171421342551998, 0.49491738578108413, 0.18392390807628967, 0.18222750280033773, 0.19511863242380556, 0.19941860066067807, 0.19201914137131337, 0.18886959062553155, 0.17152146520259126, 0.19134636799533145, 0.18926965374334326, 0.11363814972785147, 0.0829814564519511, 0.10058050971228771, 0.08652345466465072, 0.09077697580606436, 0.07899510502085505, 0.09032063465031337, 0.09400639642874775, 0.09491989464597461]}, "mutation_prompt": null}
{"id": "f633626e-5b87-4936-9808-388b671481b5", "solution": "import numpy as np\n\nclass StochasticAdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 4))\n        self.w = 0.5 + 0.3 * np.random.rand()  # Increased randomness in inertia weight\n        self.c1 = 1.5 + 0.25 * np.random.rand()  # Further variation in cognitive coefficient\n        self.c2 = 1.5 + 0.15 * np.random.rand()  # More balanced social coefficient\n        self.F = 0.6 + 0.1 * np.random.rand()  # Slightly different adaptive mutation factor\n        self.CR = 0.7 + 0.15 * np.random.rand()  # Adaptive crossover rate with more variance\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            # Evaluate current population\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            # Update velocities and positions (PSO)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            # Apply Differential Evolution mutation with adaptive mutation strategy\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + (self.F + np.random.uniform(-0.1, 0.1)) * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "StochasticAdaptiveHybridPSODE", "description": "A stochastic adaptive hybrid algorithm combining enhanced Particle Swarm Optimization and Differential Evolution with dynamic parameter tuning for improved global search and convergence.", "configspace": "", "generation": 8, "fitness": 0.23142562636431233, "feedback": "The algorithm StochasticAdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.21.", "error": "", "parent_id": "65249ebd-4446-475c-8e23-6f3d30bebc3e", "metadata": {"aucs": [0.4914406229279352, 0.47761083000402993, 0.46496441176709513, 0.42009844469298885, 0.6015826773471751, 0.4373583500755748, 0.5171066676145089, 0.49298097120573026, 0.5125915212670122, 0.04964172984990567, 0.0848455041480074, 0.0688543769295249, 0.0020627394110115382, 0.08438434030773223, 0.1366413051296973, 0.11904051846113284, 0.10353190492316877, 0.12190705505995814, 0.08532688753869955, 0.10375124647457545, 0.10295044920934582, 0.10988342218092673, 0.13644226461682607, 0.10517164539965596, 0.09564781101901898, 0.10716738054791453, 0.1167684028538466, 0.09109595425981154, 0.08354281944670816, 0.08775662438614185, 0.11556720215223049, 0.10208445533370447, 0.09098544848406676, 0.08543462185641315, 0.0935273623141939, 0.09339154665515181, 0.9749632850579373, 0.9695838230049028, 0.9832868535239864, 0.9719691099319393, 0.972169055408517, 0.9620005461365578, 0.9719367069976408, 0.9797372940430029, 0.972144488750649, 0.28860003344441365, 0.28410630721661856, 0.2657878348623054, 0.1766509527596789, 0.2182175219016972, 0.2350040285193281, 0.11280341431240615, 0.08681912768508027, 0.32281293942413236, 0.4629502187961745, 0.21979989187660154, 0.5970782125491507, 0.2497243614093585, 0.20733483080661508, 0.19597769083973926, 0.3514092141546191, 0.46809042357661146, 0.7020825565233121, 0.18561997932239538, 0.18671004159245763, 0.083415209842166, 0.10604302212248728, 0.16877104469811788, 9.999999999998899e-05, 0.15755618794681192, 0.12349992928524356, 0.15939554192158778, 0.23966380990393865, 0.19161753366183898, 0.17564723930506643, 0.2155491231088471, 0.15576104678395586, 0.14293223093612306, 0.15915516526256157, 0.2265938956709801, 0.22304104038080608, 0.04366078224555181, 0.13105756827036874, 0.04582709933392648, 0.015612303800710436, 9.999999999998899e-05, 0.01340026202875888, 0.03097383791627928, 0.0203327553481919, 0.033257458537539586, 0.11935833250042793, 0.115278700474019, 0.10680158751984725, 0.007427893282733966, 0.10250354492891789, 0.11141349454677707, 0.10957672976177002, 0.2071425565144439, 0.14232071709844496, 0.01683833150185765, 0.022425855619503055, 0.07157045333454426, 0.07094611545878737, 0.037714938668636955, 0.03666134339408822, 0.015490925416267731, 0.08119517266541243, 0.024503621920560548, 0.12779385470207194, 0.14231348920207054, 0.03896097060005754, 0.09942758142172492, 0.13385781235014182, 0.10005647835699327, 0.04023730347139631, 0.06589475900889086, 0.10896766446495187, 0.3922004614199853, 0.45000765265016973, 0.45835312650959437, 0.39954496338907197, 0.46161077845536647, 0.3956663654258882, 0.33135706543574817, 0.3894878762868561, 0.43801858965416285, 0.11321342242113075, 0.07894650761337907, 0.0999408450953142, 0.08722529220849229, 0.12056166336913998, 0.10971969248990432, 0.12493496804836834, 0.10234929737684284, 0.11478255815416838, 0.21267526200967035, 0.3044517713181861, 0.19398355329520156, 0.22921395717322546, 0.3125838500814452, 0.1805412804607971, 0.28383864213177534, 0.1773237190419401, 0.20058527440323992, 0.2944940440965691, 0.28703981394400124, 0.3090438553112057, 0.27852859444635114, 0.31728367492568055, 0.24534876689786655, 0.279491510819043, 0.3537637292177219, 0.23733403134083597, 0.19406586768784506, 0.2238824801439222, 0.2223389774404333, 0.2136285462130476, 0.2230932383246893, 0.24511469543733566, 0.15843877666025563, 0.2340323489996251, 0.15245983884544367, 0.193643233883542, 0.1969554110997428, 0.210463266156368, 0.21849183000192673, 0.1916022056568223, 0.21756599865175763, 0.1777618647935244, 0.20859452641727083, 0.20890122379237275, 0.1914606557719981, 0.19346818912181285, 0.1836708215014885, 0.18418038596398623, 0.2172738481268386, 0.19314713993830124, 0.18096291903789075, 0.1833688986112767, 0.20197466508956763, 0.6018495687796682, 0.18512592229263736, 0.18510017197743578, 0.6120636657662577, 0.1935369428010112, 0.19937624082590755, 0.14171045763483558, 0.1606141789216795, 0.6417721368179687, 0.5538378181656537, 0.2034018816948363, 0.6285634608319628, 0.589788719364859, 0.16496386580386446, 0.1661279158934984, 0.2013253259449862, 0.10468542440030904, 0.44491031261132963, 0.1875195721553784, 0.1834308709326966, 0.20573013846104937, 0.18118414084753187, 0.19435037945815392, 0.1725040425855061, 0.19549310419067045, 0.24598656327952573, 0.20245321321430299, 0.07741631309534946, 0.07922441051033768, 0.08471781339696316, 0.09854325607663683, 0.09219061327344358, 0.07705412029940839, 0.0783965072524061, 0.08463328212181553, 0.09421005594770904]}, "mutation_prompt": null}
{"id": "0a277c6a-4e4a-42e4-801a-44869da27104", "solution": "import numpy as np\n\nclass AdvancedHybridPSODERefined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 5))  # Adjusted population size for balance\n        self.w = 0.4 + 0.3 * np.random.rand()  # Increased variation in inertia weight\n        self.c1 = 1.4 + 0.2 * np.random.rand()  # Slightly increased cognitive coefficient\n        self.c2 = 1.6 + 0.2 * np.random.rand()  # Increased variation in social coefficient\n        self.F = 0.4 + 0.3 * np.random.rand()  # More adaptive mutation factor\n        self.CR = 0.7 + 0.2 * np.random.rand()  # Wider range for adaptive crossover rate\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            # Evaluate current population\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            # Update velocities and positions (PSO)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            # Apply Differential Evolution mutation with adaptive mutation strategy\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + (self.F + np.random.uniform(-0.2, 0.2)) * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "AdvancedHybridPSODERefined", "description": "A refined hybrid metaheuristic combining Particle Swarm Optimization, Differential Evolution, and adaptive mutation strategies with enhanced cognitive and social dynamics for diverse and efficient convergence.", "configspace": "", "generation": 9, "fitness": 0.2870076063883971, "feedback": "The algorithm AdvancedHybridPSODERefined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.23.", "error": "", "parent_id": "65249ebd-4446-475c-8e23-6f3d30bebc3e", "metadata": {"aucs": [0.5685679177177311, 0.6715086413489841, 0.646833742980927, 0.6606310895844512, 0.7185476271722102, 0.6699540072372421, 0.6561000961939656, 0.6417838056194742, 0.6751155603939545, 0.1909415417738466, 0.17699316511137475, 0.2454724308324283, 0.18188239920047866, 0.25298732928436096, 0.2809716716122491, 0.10381191692572578, 0.2629213163947308, 0.34215661095558547, 0.13904190924701876, 0.13324752622777325, 0.10548664928805063, 0.12426945542190393, 0.1102667108223222, 0.11444732186349227, 0.0965079679805142, 0.10624479290113975, 0.13016517840465736, 0.0975630847858927, 0.11502458591586195, 0.11948298760986942, 0.10242439478715804, 0.09906408296873592, 0.0849634642568966, 0.12270653239974949, 0.08655933684234218, 0.10989743908708427, 0.9735129598993544, 0.9609052379558407, 0.9836590288338956, 0.96881845335264, 0.9508526357770687, 0.9625142705492655, 0.9775369809657876, 0.9830432061120665, 0.9733022240217131, 0.41993780586232343, 0.40626396398037956, 0.4439398722237805, 0.2813156402867344, 0.3891846545179556, 0.4153305262711259, 0.08641733484356517, 0.26509217520419426, 0.40801290860502626, 0.7523857319772267, 0.2275613813523999, 0.2181813738452565, 0.21255022945010904, 0.7282576259213125, 0.19450160368987401, 0.615380366865855, 0.22699008605283166, 0.7034846024917881, 0.4133804000283716, 0.18775175271126499, 0.11618676992047117, 0.10151141723536161, 0.12683065105648006, 0.2725445265184723, 0.21432913610866766, 0.35314463460998524, 0.2534788431220546, 0.3290957434722064, 0.4349823464836522, 0.3063057425936788, 0.20962381437418298, 0.3693607486368671, 0.327513311192826, 0.2629571328819226, 0.1239272296987246, 0.24857515072132186, 0.12068735707249356, 0.19606026091903062, 0.056800275503568476, 9.999999999998899e-05, 0.028085468971055683, 0.03578395265395862, 0.035838540401388674, 0.10016371135471713, 0.003115476502511094, 0.06875411836423995, 0.08609999552058156, 0.3596459502113297, 0.05859227079858176, 0.14588332216524746, 0.15944555539426442, 0.2816489679372698, 0.18515835623218269, 0.21187035282594746, 0.03032474315990008, 0.11459216611342948, 0.10589462339995426, 0.09540568669849059, 0.05985660194065201, 0.07351663778278505, 0.05852077441189907, 0.16103923585987867, 0.12997028523964127, 0.14991497784013286, 0.18127841384983445, 0.17349362889752606, 0.18060299894704823, 0.24631768237658913, 0.20161402938863415, 0.045374976906246034, 0.17079782361144136, 0.07694443699507425, 0.496626499094727, 0.5706279275302657, 0.5584054925165365, 0.500929506151012, 0.5227826875438459, 0.5403469835347945, 0.46752757440030723, 0.5351606624512387, 0.5412105793269983, 0.10479100637151151, 0.060188294645370455, 0.0914232718770992, 0.10756066879554005, 0.12432157955638523, 0.1260049226249228, 0.07055825203599908, 0.11873382558930812, 0.13969833753074123, 0.27870077692562567, 0.39052960574827444, 0.22104481255866393, 0.221572344564403, 0.3040322451622124, 0.26329556361089557, 0.18659279832386677, 0.18660361299463435, 0.1975847412760432, 0.25789685222960645, 0.39188789856888906, 0.4004431625981588, 0.24853815170886673, 0.3504473231528471, 0.38520154359383263, 0.3392486307692072, 0.40329237153755837, 0.26304790727831706, 0.24840947931496293, 0.16001937931204102, 0.2544706455469201, 0.24652432408013092, 0.19622343579692803, 0.21804716935621637, 0.1760887108362824, 0.28305973752100655, 0.19651395359580703, 0.22212711084114123, 0.25570625940894753, 0.1971792825262767, 0.21636038462760465, 0.22688226701500724, 0.2237687049704934, 0.19272807587050522, 0.20722108196264943, 0.21745157686536598, 0.1790683971306133, 0.19927733137635595, 0.21340865776407358, 0.29720751831059533, 0.21537640668626723, 0.19899256429453238, 0.1921432499855893, 0.42589839881502844, 0.18195908168986874, 0.8178018428778189, 0.6858655210787383, 0.18703281496448176, 0.7957835709627559, 0.1973330641158869, 0.19950769798620538, 0.14130460202164885, 0.1616672628996586, 0.821772764878203, 0.7720552024643572, 0.21116414197940725, 0.7119206741402908, 0.19830496542558707, 0.16748839486054334, 0.6580457558868594, 0.1031828592799584, 0.10389061515908271, 0.7915103946812269, 0.19275625899360282, 0.18544853231470648, 0.20592086916943597, 0.19990372373233256, 0.1810904575419956, 0.22462784326527008, 0.1837607459353361, 0.1864678800167039, 0.1905273195849181, 0.08498077227300815, 0.08924102872079076, 0.07434587415750649, 0.08485458430976944, 0.09901648455198431, 0.08931075857917292, 0.1116354397821342, 0.07642374608965963, 0.08455673585944312]}, "mutation_prompt": null}
{"id": "7ab3da92-bc8d-43d1-9144-369e0c79d818", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 5))\n        self.w = 0.5 + 0.2 * np.random.rand()  # Adaptive inertia weight\n        self.c1 = 1.5 + 0.1 * np.random.rand()  # Fine-tuned cognitive coefficient\n        self.c2 = 1.7 + 0.1 * np.random.rand()  # Fine-tuned social coefficient\n        self.F = 0.5 + 0.2 * np.random.rand()  # Adaptive mutation factor\n        self.CR = 0.8 + 0.1 * np.random.rand()  # Adaptive crossover rate\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + (self.F + np.random.uniform(-0.1, 0.1)) * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSODE", "description": "An enhanced hybrid optimization strategy integrating Particle Swarm Optimization and Differential Evolution with adaptive inertia and cognitive components for improved exploration-exploitation balance.", "configspace": "", "generation": 10, "fitness": 0.25173338640815524, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.23.", "error": "", "parent_id": "0a277c6a-4e4a-42e4-801a-44869da27104", "metadata": {"aucs": [0.4980302255289979, 0.5244251834558105, 0.4692755367244653, 0.5399601673957974, 0.572254444922103, 0.5637916662962704, 0.5428067151994773, 0.588064404515614, 0.5569943255621028, 0.14125754113265798, 0.08257964158311493, 0.016454677222189074, 0.09954532678581329, 0.18121974789127282, 0.05243532492779124, 0.03221482887792626, 0.16603525299434418, 0.03813336139475321, 0.12073512589861823, 0.10543518337209701, 0.13149273872308054, 0.10637783790786359, 0.12547297235652732, 0.10724990623724684, 0.09136795333412573, 0.11145195794218321, 0.12017573109524893, 0.09924633152914508, 0.11269533875270932, 0.09360547898173588, 0.12001777978534789, 0.10233946655726234, 0.09411863972248269, 0.08432893008996156, 0.10594579704176921, 0.10631841384051566, 0.9745613107356453, 0.9596694712476761, 0.9835304865272536, 0.9720593834164838, 0.9702065256187219, 0.9705586307424854, 0.9809068404275375, 0.9818420146807438, 0.9735606623202525, 0.25928395367567014, 0.36051905744443224, 0.26503970364360563, 0.3621523317233909, 0.31420736479210787, 0.14708394011275827, 0.3677117816369251, 0.08739557746253923, 0.33732275762609043, 0.5170248558874562, 0.6239471973645854, 0.22103431351310288, 0.2538912200452401, 0.6337841606029536, 0.18946049754237815, 0.5280980202440861, 0.6048902792480798, 0.6724823391457999, 0.11865414782249828, 0.08625239569768983, 0.14073448723978088, 0.16457888992131797, 0.11213159045071519, 9.999999999998899e-05, 0.12477455145062832, 0.09434037853653265, 0.12329802471691143, 0.2313181345368962, 0.11063275724516919, 0.2460342294394786, 0.144636587626933, 0.18959383320150747, 0.21596839669557522, 0.1589122169513355, 0.2931447571006117, 0.12141546535260839, 9.999999999998899e-05, 0.04483085407790388, 0.06694061830092035, 0.0001234649007033628, 9.999999999998899e-05, 0.012889855827275087, 0.08297048715501187, 0.006338781965661622, 0.020487413297342938, 0.13581087401808067, 0.06134076985572734, 0.13114541458605722, 0.1454887194350546, 0.08336620459728106, 0.050068098885162726, 0.10304831058733621, 0.10370116824308029, 0.05171870677469537, 0.03288404404698264, 0.06864928350486366, 0.06123264775541415, 0.07251913826846612, 0.03582900410148737, 0.043875370239349065, 0.03435324246081384, 0.08020147685653867, 0.09650133415391882, 0.08917849012110346, 0.16073126719478037, 0.15069049582613347, 0.1256334982755174, 9.999999999998899e-05, 0.13857902414423484, 0.04260426829081021, 9.999999999998899e-05, 0.165996553940283, 0.4535997657535705, 0.48972569165956525, 0.5166527858890648, 0.4541001546038992, 0.4527754681161581, 0.5058809242909654, 0.4711042117094021, 0.43527903237632015, 0.4505814672969345, 0.11040764470664766, 0.09236736159756931, 0.07235892539850086, 0.11200613356242084, 0.09978866010262155, 0.13142487721967444, 0.09624564888664622, 0.09933582665789487, 0.10114254832052882, 0.1823988536579384, 0.2904845735984669, 0.18584136541470453, 0.2971800139248124, 0.3361766455090117, 0.3130034976404986, 0.2879894765480897, 0.2415766405157468, 0.19857994178017202, 0.2930034260525818, 0.2917271676348623, 0.31550443188165933, 0.232649466256035, 0.27621167000796953, 0.2755328842714889, 0.33687755806356157, 0.3743600116656972, 0.31899593571143015, 0.19024364380814862, 0.19391233440556188, 0.19829188168550438, 0.18004560039769824, 0.1432809062344058, 0.22906014878745595, 0.23580730387219606, 0.21165801922767813, 0.16284322483464786, 0.2182619141059854, 0.1946317782250654, 0.1896796777507318, 0.25795219143374193, 0.20174107438393307, 0.2404064522797147, 0.2021284940832656, 0.25865477286130134, 0.20969655973472057, 0.19620412951727528, 0.19169393919119848, 0.1836823453847264, 0.37159598439523356, 0.18944353495709843, 0.29674702085970817, 0.19103111663290617, 0.19354978335178652, 0.18060700474371083, 0.7250994768838652, 0.45266512476108123, 0.6008006805112103, 0.5963484736151808, 0.19837492102262955, 0.19919603342291492, 0.14087701107604356, 0.6434199752463883, 0.786742508335011, 0.7002776370687678, 0.20884915302116824, 0.723045679301044, 0.6035187893304007, 0.166068807096737, 0.3960658164486257, 0.1949022489167529, 0.10434816220022403, 0.31390858911013464, 0.1780852216016099, 0.19026435127050112, 0.1676127403574148, 0.19441063197227804, 0.18379682652177576, 0.18099926835003777, 0.18750915184283423, 0.18131449292347712, 0.18675949959257154, 0.0791194856294185, 0.08305786865343068, 0.07929670358345287, 0.08008232596983522, 0.08495503273281557, 0.08639857641461635, 0.08695428144413275, 0.11143946666110183, 0.07939656716292975]}, "mutation_prompt": null}
{"id": "60209ae5-3ba1-4a3c-840b-6fe4023c3df7", "solution": "import numpy as np\n\nclass AdvancedHybridPSODEEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 5))\n        self.w = 0.5 + 0.4 * np.random.rand()  # Broader range for inertia weight\n        self.c1 = 1.5 + 0.3 * np.random.rand()  # Further increased cognitive coefficient variation\n        self.c2 = 1.5 + 0.3 * np.random.rand()  # Further increased social coefficient variation\n        self.F = 0.5 + 0.4 * np.random.rand()  # More adaptive mutation factor with wider range\n        self.CR = 0.6 + 0.3 * np.random.rand()  # Broader range for crossover rate\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            # Dynamic inertia weight adjustment\n            self.w = 0.7 - (0.5 * (self.evaluations / self.budget))  # Linearly decreasing inertia weight\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + np.random.uniform(-0.3, 0.3)  # Adjusted mutation factor range\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "AdvancedHybridPSODEEnhanced", "description": "An enhanced hybrid metaheuristic incorporating dynamic inertia weight adjustment and adaptive learning rates for improved exploration and exploitation balance in diverse optimization landscapes.", "configspace": "", "generation": 11, "fitness": 0.27557528659315966, "feedback": "The algorithm AdvancedHybridPSODEEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.23.", "error": "", "parent_id": "0a277c6a-4e4a-42e4-801a-44869da27104", "metadata": {"aucs": [0.5767015603326919, 0.676553023397138, 0.6195515364940705, 0.6032834864304976, 0.6224993625795128, 0.618029417092573, 0.594518512447999, 0.6374375964653383, 0.6329171478411715, 0.2760604476798386, 0.2716736825013073, 0.34178383548890434, 0.16763478151517097, 0.30272950459994363, 0.27644508813182755, 0.22594489423529274, 0.3234193030570949, 0.04402749559743935, 0.08875171554880523, 0.33939569672082603, 0.06875567175948127, 0.1311169025271165, 0.12473010406833107, 0.09488382892484681, 0.1339099111252453, 0.1363736189503688, 0.10313903636466837, 0.08038339955350837, 0.09509924117798996, 0.10518376584042433, 0.12532030264790084, 0.1123810279000711, 0.10610810121296177, 0.09208954469572295, 0.09420624281647905, 0.10868282413855301, 0.9726960957379244, 0.9697749458198222, 0.9834026052491868, 0.9651209932708946, 0.9707910181962054, 0.9629419570314272, 0.9813656488112505, 0.9797283996140829, 0.9831285554524212, 0.37807732083266443, 0.40185215657561557, 0.4156617495727657, 0.3678671325255817, 0.37820310667188306, 0.4499318259523126, 0.30859054002611186, 0.3794893008211673, 0.461264029582636, 0.35070150975335446, 0.211249719155722, 0.607148517296477, 0.7311873873582455, 0.2586973517263277, 0.1835083291084758, 0.591485575447613, 0.6234253637677175, 0.6621617818078387, 0.11569292664659936, 0.14778797815552103, 0.1750052365136444, 0.104906606991361, 0.24881669840200837, 0.1959986661948534, 0.20076147198124905, 0.0911353581579184, 0.30173737428845837, 0.2901755993394285, 0.27700255330314616, 0.19149836487155902, 0.26509827405045017, 0.3363230223752972, 0.22283255031295357, 0.20247209263297705, 0.1128941650672678, 0.10919859361525852, 0.05266536507198438, 0.09145299711777066, 0.06739931886803185, 0.028198379641318883, 9.999999999998899e-05, 0.011991473210089532, 0.06086253771657135, 0.058702323065283, 0.0433210621721597, 0.13089759740841622, 0.05837482226121882, 0.19400272969764099, 0.0699669586442313, 0.15399657829545976, 0.022435606894325222, 0.22711207568810565, 0.23634158905812486, 0.17353862365141903, 0.06471232660649062, 0.048187678404539525, 0.07533105580655064, 0.16404822524272167, 0.049366579224688234, 0.08059386409353719, 0.05580253626094034, 0.08411817393049825, 0.042461099885060305, 0.16457677714845254, 0.20120452731272587, 0.19035159847976724, 0.17699020696770673, 0.1251914433117125, 0.09992060437942041, 0.043993491283772945, 0.15601038987694194, 0.14387920456260328, 0.48904776289917984, 0.500483381739797, 0.5083936209508328, 0.4261993229996768, 0.49909676994621455, 0.5261900124828836, 0.49282196066644235, 0.5085551203341218, 0.514741229223108, 0.12778558102055215, 0.12261524380362221, 0.079045813984015, 0.11153581607112428, 0.0887970602086483, 0.114068053834392, 0.10116218214442307, 0.11166274557128342, 0.11917076901090151, 0.16897324227760624, 0.37047885247602486, 0.23788976586289978, 0.28193801474244573, 0.21539183980069543, 0.28478120776052307, 0.3219150389669565, 0.17108667102223407, 0.19687644976068464, 0.32182063035107256, 0.3156235365541553, 0.3584456125878943, 0.3459483654875094, 0.3738083925454494, 0.33666667372487713, 0.30761752677787824, 0.3406624325359887, 0.3858136314718441, 0.2695280832260083, 0.205309943975309, 0.22128665310210183, 0.2224732090357754, 0.2240294498592219, 0.2344398258699183, 0.2490322606030001, 0.24476134711042918, 0.1524935743772634, 0.17996826809588873, 0.21119658668578634, 0.19011777784838912, 0.20553246143639448, 0.21911516881802262, 0.19199440678141866, 0.21176862998189638, 0.25014150745812636, 0.2025962792269459, 0.18486094916303142, 0.18498586310316933, 0.18316260877757617, 0.20663133091474395, 0.21309994312225422, 0.20384966375021984, 0.20243845517058812, 0.18784052184604783, 0.19048726504078795, 0.71508886710851, 0.18474719430071862, 0.18519944206895944, 0.7556465843681219, 0.19147152898118058, 0.19884373981226744, 0.14107034386380912, 0.15962794856527218, 0.7544333086800685, 0.6960227819990764, 0.2041319047812321, 0.6043133491678468, 0.6020516355883255, 0.16607788757167763, 0.1488676156792118, 0.20039457551633166, 0.20687584512635682, 0.7311930499778587, 0.1795116657628678, 0.19046620434061767, 0.20434251347666466, 0.19969765205943946, 0.17745408045529454, 0.21959022510844495, 0.2011914303258392, 0.21394935668138237, 0.173239583771982, 0.0784515439911605, 0.09084113986319953, 0.09371946523453989, 0.08089505942740294, 0.09082388358928761, 0.07895492610824917, 0.07746289213744983, 0.08896160900848316, 0.0997868204780108]}, "mutation_prompt": null}
{"id": "a2056c52-07dd-44f6-8524-4c1b9755b65a", "solution": "import numpy as np\n\nclass EnhancedHybridPSODEStochastic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 4))  # Adjusted population size for more adaptability\n        self.w = 0.5 + 0.2 * np.random.rand()  # Randomized inertia weight for dynamic adaptation\n        self.c1 = 1.5 + 0.1 * np.random.rand()  # Balanced cognitive coefficient\n        self.c2 = 1.5 + 0.1 * np.random.rand()  # Balanced social coefficient\n        self.F = 0.5 + 0.2 * np.random.rand()  # Smoothed adaptive mutation factor\n        self.CR = 0.6 + 0.2 * np.random.rand()  # Adaptive crossover rate with wide range\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            # Evaluate current population\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            # Update velocities and positions (PSO)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                inertia_component = self.w * self.velocities[i] + np.random.normal(0, 0.1, self.dim)  # Added stochastic influence\n                self.velocities[i] = inertia_component + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            # Apply Differential Evolution mutation with adaptive mutation strategy\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + (self.F + np.random.uniform(-0.1, 0.1)) * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSODEStochastic", "description": "An enhanced hybrid algorithm integrating PSO, DE, and adaptive mutation with stochastic influence mechanisms for balanced exploration and exploitation.", "configspace": "", "generation": 12, "fitness": 0.20182913430098728, "feedback": "The algorithm EnhancedHybridPSODEStochastic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.20.", "error": "", "parent_id": "0a277c6a-4e4a-42e4-801a-44869da27104", "metadata": {"aucs": [0.3553585984988683, 0.3621728669025157, 0.40964519913672004, 0.3800565903814527, 0.3869972829518393, 0.4010373259901281, 0.38213047382003906, 0.3568553216573167, 0.3897412004016858, 0.004431674379381745, 0.007662874077865145, 0.014944157762327492, 9.999999999998899e-05, 0.01805291473959114, 0.02984864664459197, 0.023901235112696817, 0.00516402065136623, 9.999999999998899e-05, 0.07216131755401145, 0.08708448895696874, 0.09802105170530317, 0.09062907921051977, 0.09978372097250776, 0.08937980966166592, 0.10718559099430802, 0.12075418172831287, 0.08777555097398726, 0.06941270124130083, 0.11088432094584877, 0.09745289300541904, 0.09676531129110322, 0.07899050759832993, 0.08410187059687702, 0.08847173904860428, 0.09610297960219683, 0.07917834025855897, 0.9795786621608475, 0.9635145532507507, 0.9819666662858979, 0.9716540023416741, 0.9513845134104431, 0.961685008831181, 0.9728502549858672, 0.9835221543230933, 0.9737514703844081, 0.21132725133817654, 0.251506708134444, 0.22232761173147209, 0.22666532016458996, 0.23228553189772772, 0.24171952175797162, 0.21608530646906787, 0.25556016220251254, 0.269780323165398, 0.3031123350348942, 0.23693732669309442, 0.30172115667715094, 0.29785172438532126, 0.5684862257326979, 0.23812788368324278, 0.2828839445807071, 0.21790719232487266, 0.2943112700135909, 0.14223473983332346, 0.08883148008271946, 0.1260654657333231, 0.113940977159948, 0.1394695109772801, 0.11890582615874068, 0.1321762931599123, 0.1698375905368299, 0.15607709305464956, 0.1309413829830841, 0.09158630002043688, 0.1378727663467565, 0.17946954581510965, 0.16183790647247442, 0.15090937766151435, 0.11768430301580957, 0.14447020015371215, 0.1322127387482973, 0.0017817611724756377, 9.999999999998899e-05, 0.020072836978244912, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01821107386201437, 0.06190743313449021, 0.09410969374785871, 0.08451461723953102, 0.11004992601414709, 0.08265257141267102, 0.003902230293148179, 0.06663579495218341, 0.08608428223401765, 0.10509735323384828, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06432275359473183, 0.06294952025812706, 0.0786514222336433, 0.0716718410815762, 0.08161921295092545, 0.06486897929238944, 0.0425214470815124, 0.053225488912750585, 0.059052505070830374, 0.35069356291672127, 0.3532611225201957, 0.3511736062212306, 0.33650942079305335, 0.37054643682526656, 0.3358762160567539, 0.3451947118416756, 0.3770209598704388, 0.3586039779963297, 0.109513345210557, 0.08649559249961036, 0.09336503296949827, 0.1035820380558411, 0.11020068121255078, 0.11197044942657053, 0.08970608034188776, 0.10719616130376486, 0.09409449629954703, 0.17229235316663394, 0.14954906925717515, 0.1672587135122483, 0.1846496268364265, 0.19416147946035833, 0.22397160033429364, 0.22098536894539866, 0.20677091740610942, 0.1894871118680922, 0.25681992518706953, 0.26743633855802507, 0.2569300132085168, 0.26200627631487095, 0.2596449138464858, 0.2473162586286355, 0.2603926100822851, 0.27073729559428517, 0.26493371173186975, 0.1712033096894895, 0.1655540898209361, 0.20764991513975062, 0.1535496935938383, 0.181876876096433, 0.19313207338098748, 0.2109932327740649, 0.1974421385298467, 0.21229105623393174, 0.2300455873266526, 0.20935227844726334, 0.2340605637866845, 0.19237801913491137, 0.20754685905022308, 0.21905094399283964, 0.1934807260536371, 0.19911826191681592, 0.2172788628319795, 0.19514606868448825, 0.18430007840990115, 0.17884876616848655, 0.18509707123579155, 0.2098253587198332, 0.20425209530028543, 0.19842778664293825, 0.1997469625238486, 0.19089499905457108, 0.4186440251253428, 0.18348246089838405, 0.16610245962816572, 0.5546956440880854, 0.19448492655233385, 0.19644152935520132, 0.14083932148322242, 0.16014298317662123, 0.5220996621356733, 0.49779230055624313, 0.2065555502749089, 0.4230635021971497, 0.2031368087623795, 0.4280597023249395, 0.14774090524947092, 0.1040235032135659, 0.18608409079185917, 0.4355494551877944, 0.19247002336862362, 0.17680201827220332, 0.17894843020814555, 0.17378413217289712, 0.1769787877742458, 0.17317927854887805, 0.17770612718426637, 0.18132282897641938, 0.19996308476676528, 0.09296749430070572, 0.09202977520341227, 0.0859568781921376, 0.07814613808820281, 0.08067437857701532, 0.09022486616424907, 0.08166102461896663, 0.07797812445451602, 0.09170347321921768]}, "mutation_prompt": null}
{"id": "fc4bb8e2-5e2b-4e14-bc22-1124ab10b206", "solution": "import numpy as np\n\nclass AdvancedHybridPSODERefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 6))  # Adjusted population size for greater exploration\n        self.w = 0.5 + 0.2 * np.random.rand()  # Updated inertia weight for balance\n        self.c1 = 1.5 + 0.1 * np.random.rand()  # Refined cognitive coefficient\n        self.c2 = 1.5 + 0.1 * np.random.rand()  # Refined social coefficient\n        self.F = 0.5 + 0.2 * np.random.rand()  # Streamlined mutation factor\n        self.CR = 0.8 + 0.1 * np.random.rand()  # Narrowed range for adaptive crossover rate\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, dim))  # Reduced initial velocity range\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            # Evaluate current population\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            # Update velocities and positions (PSO)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            # Apply Differential Evolution mutation with adaptive mutation strategy\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + (self.F + np.random.uniform(-0.1, 0.1)) * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "AdvancedHybridPSODERefinedV2", "description": "Enhanced hybrid metaheuristic combining Particle Swarm Optimization and Differential Evolution with adaptive acceleration strategies and diversity preservation for robust convergence.", "configspace": "", "generation": 13, "fitness": 0.26266531723001313, "feedback": "The algorithm AdvancedHybridPSODERefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.22.", "error": "", "parent_id": "0a277c6a-4e4a-42e4-801a-44869da27104", "metadata": {"aucs": [0.5570895573292733, 0.5817393701633626, 0.6452822650851886, 0.6189357568729098, 0.6019846843826709, 0.5580302592244237, 0.6224019476590468, 0.5891522296746249, 0.6361843027683887, 0.1014970857610239, 0.12760146191237487, 0.1783247900146565, 0.18609748403216375, 0.19291439526095355, 0.17806187267619078, 0.10752137776640425, 0.17349407439772913, 0.03690710262209629, 0.10760555347173284, 0.12866362999675784, 0.10729798657229273, 0.11753101700733637, 0.10811034087165772, 0.10898648779107245, 0.1175321444798334, 0.11462186854672796, 0.1135022202209488, 0.10158182721018727, 0.09210842421530929, 0.08705841964674277, 0.13308798339637418, 0.08637305126136985, 0.0848695937725461, 0.10312111319545347, 0.11615497690866161, 0.15306110491461444, 0.9751300227890847, 0.9594541283871119, 0.9830249656931156, 0.9641570107815481, 0.9612728901613539, 0.9620117294548212, 0.9732289533541166, 0.9817706329380689, 0.9707589267003898, 0.29694472864337806, 0.31249879586145657, 0.32488175097883676, 0.2952709557851877, 0.3271061027128389, 0.14371948023956016, 0.23266256049886236, 0.36707383202482524, 0.40508267841453793, 0.5378922595425901, 0.22198374647809282, 0.5856087490968317, 0.6948017272032787, 0.188027462175838, 0.1900717781890986, 0.6994311462030608, 0.6922744919272275, 0.7249730850140623, 0.2633455560676494, 0.09899543934131272, 0.16801611279594764, 0.18361982479251449, 0.12401762450050269, 0.08797060674100488, 0.24533935501199455, 0.30094951759325794, 0.2537635236386758, 0.15342798020565585, 0.12381488466431001, 0.11928071435883958, 0.18238468206131708, 0.23551418454596262, 0.18414060650107833, 0.18266205589688944, 0.11500643486457085, 0.2218202097641938, 9.999999999998899e-05, 0.11897128695771386, 0.04450646397546121, 0.02191446353663673, 0.07153543611656932, 0.04591368088407943, 0.05430570672031332, 0.13800207140392917, 0.06536622119630642, 0.16992326249109224, 0.11417918633582014, 0.2090878772603112, 0.08083316483363145, 0.22911777968405644, 0.17509908662805085, 0.065237928539852, 0.06599638291165899, 0.18558478613867724, 0.027058473517645454, 0.020685045120940604, 0.09237364209505972, 0.11354064329911673, 0.04426170861035639, 0.06007087959463275, 0.06270686291455618, 0.0363421488293898, 0.0432368134775577, 0.10658542085288081, 0.13214312204717715, 0.22586033389235882, 0.14242368990765575, 0.15537623883584561, 0.1204578068633737, 0.14009314482105106, 0.07610693816273983, 0.07000839475974918, 0.4400853887148589, 0.4975507860764805, 0.5301467140061921, 0.450934120605036, 0.4790946545737538, 0.4733193486872147, 0.4880624278251907, 0.3902461500522669, 0.4739007970201171, 0.08747435142852267, 0.10458413146217704, 0.08429411977876078, 0.13873617144273398, 0.12568176236542417, 0.11280112823430588, 0.09841695249412263, 0.10257619429616893, 0.11748771785269896, 0.24230246159870228, 0.20212634671657048, 0.35743450965810886, 0.33971586758441685, 0.4092712284708947, 0.19814722160217335, 0.1720359624228025, 0.2614593460788809, 0.3973249837910955, 0.29951547038775406, 0.32499906377689014, 0.3737734124823109, 0.27941723849601363, 0.3512444878246096, 0.27430244413272964, 0.3390630128111417, 0.38003882847181425, 0.31344798283143427, 0.296685306900735, 0.16555139237647454, 0.2840044965727392, 0.23209893722106034, 0.2355294825865918, 0.21324633581100805, 0.21765839827000977, 0.33370386554061837, 0.1546713308916824, 0.1890180029452352, 0.19856007679581145, 0.20624266191061447, 0.22637694073748527, 0.20786848986288664, 0.2208533776513627, 0.19063505596973884, 0.2110429373977366, 0.21338225376475572, 0.17954911654349182, 0.19195333906656487, 0.2231491436468812, 0.19895712127907972, 0.185621674329412, 0.1896249658193898, 0.20942726922976507, 0.18395352028751366, 0.20873958178578744, 0.7713921693987724, 0.18715085306590307, 0.16779746521155248, 0.7491334694974481, 0.19611953189730158, 0.19725630370698743, 0.5690543374333978, 0.16000617803245754, 0.7536818111051529, 0.7821092228629808, 0.2081458015447497, 0.19423509020652896, 0.4678222583143371, 0.1660728180222999, 0.16631954041534414, 0.19632511235222394, 0.20551834739157293, 0.22522558029675266, 0.1882545598454266, 0.19111528619543994, 0.1840464396821624, 0.19334065673667455, 0.18154814853106427, 0.18225557296395167, 0.1963407079320313, 0.18045313275067787, 0.18823061337352665, 0.08554067520074149, 0.0873233176676953, 0.08943262750252912, 0.09077453400228064, 0.08507741498919585, 0.09025676926688464, 0.08882931600941846, 0.09103388728091955, 0.08469335085345153]}, "mutation_prompt": null}
{"id": "478c27b4-9b94-4e26-a359-35b71640c86b", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE_Chaotic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 5))\n        self.w = 0.5 + 0.2 * np.random.rand()\n        self.c1 = 1.5 + 0.1 * np.random.rand()\n        self.c2 = 1.7 + 0.1 * np.random.rand()\n        self.F = 0.5 + 0.2 * np.random.rand()\n        self.CR = 0.8 + 0.1 * np.random.rand()\n        self.population = self.initialize_population()\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def initialize_population(self):\n        # Using a chaotic map for initial population\n        x0 = np.random.rand(self.population_size, self.dim)\n        population = self.lower_bound + (self.upper_bound - self.lower_bound) * np.sin(np.pi * x0)\n        return population\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + (self.F + np.random.uniform(-0.15, 0.15)) * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE_Chaotic", "description": "An enhanced hybrid metaheuristic with diversified exploration and exploitation phases, incorporating chaotic maps for initialization and adaptive parameter tuning to improve convergence and robustness.", "configspace": "", "generation": 14, "fitness": 0.23805969522476217, "feedback": "The algorithm EnhancedHybridPSO_DE_Chaotic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.22.", "error": "", "parent_id": "0a277c6a-4e4a-42e4-801a-44869da27104", "metadata": {"aucs": [0.5045007506062136, 0.47893891172711756, 0.5373400397052446, 0.18723870499596929, 0.6294894182983893, 0.6141950741301927, 0.48819976671701903, 0.5111827918990886, 0.5640260975501897, 0.11141936623478998, 0.13942985492329985, 0.07341394536460633, 0.040501638337475, 9.999999999998899e-05, 0.12146651549630882, 0.10280091806817437, 0.03798529722685673, 0.04158772996121329, 0.12776229938626127, 0.11367935755679193, 0.11805947184301113, 0.06617096479277007, 0.10676030638802836, 0.10160140186753797, 0.08765416302412199, 0.13002893704386187, 0.10538639976593989, 0.07159604125813734, 0.08979112331026684, 0.08949853417804932, 0.08516759428969001, 0.09913719384605324, 0.10245158012096778, 0.07387297070097609, 0.10307292432429549, 0.08297711458320589, 0.9750010309711793, 0.9931964116322443, 0.9843201991184802, 0.9842482532311442, 0.9840347410736381, 0.9663362319148491, 0.9723251088233963, 0.9619160437045162, 0.9598719313381079, 0.298054951361424, 0.36459272153852673, 0.2896863681786285, 0.18173396337752123, 0.35280696828221125, 0.29849889206353786, 0.24477441329743577, 0.3088075497474193, 0.33608196631489695, 0.5901489358103578, 0.21377201622834063, 0.5401615483922781, 0.5451444198871209, 0.5388226318027687, 0.2565994216920432, 0.1997560620619463, 0.4633388669035978, 0.5862297198432365, 0.13269160710805206, 0.22914166852925655, 0.1994225423224799, 0.10674092182400963, 0.23538667762649357, 0.2272318225502944, 0.24342011322496837, 0.09722205870727452, 0.11650695777155273, 0.19224897620702674, 0.3758609014323193, 0.19729747236172812, 0.09423647624426246, 0.11562414120539288, 0.24920282171233676, 0.08327086447533016, 0.154589343478174, 0.2532938014828524, 0.032420694447231835, 0.05762773555709044, 0.0468936387042147, 9.999999999998899e-05, 9.999999999998899e-05, 0.02708795096254757, 0.07528304429135535, 0.004171058098360492, 9.999999999998899e-05, 0.029059056746332135, 0.14805074558153597, 0.03236100978740453, 0.21482154032817835, 0.0998893692554278, 0.10093779187709173, 0.15521542822441248, 0.08342727012217821, 0.1304988218633112, 0.0019272963593531811, 0.09162348716106317, 0.02028705525180108, 0.025198390971064466, 0.08100619507969054, 0.06293746400510625, 0.032682077551014155, 0.09234812729601616, 0.04592664016108772, 0.13453078853815736, 0.008027923876674503, 0.1615144256764255, 0.004903066753492058, 0.18386513196070442, 0.16989061315581444, 0.06696740576791649, 0.04890628238539119, 0.04478198007144474, 0.3839258714907, 0.4317762855985091, 0.4326543177204416, 0.39967146222449623, 0.46273275696669947, 0.5396276433405711, 0.44520819159083336, 0.46052998225568476, 0.4486183206621104, 0.13228806652393066, 0.09523342645125954, 0.11644579015661438, 0.099650042412611, 0.08929615007692648, 0.08014932227812699, 0.11200007189629901, 0.13918389629286831, 0.08437008286526182, 0.15635117726965075, 0.1474009098819935, 0.39524312446073895, 0.2472303811167066, 0.1691401339171873, 0.19217584715546832, 0.20611017085464844, 0.19659911361682425, 0.2369717302922506, 0.272886368293487, 0.24011488955286964, 0.30676086018620685, 0.2900435431607158, 0.29645975594038443, 0.2788514735855201, 0.33548579709553317, 0.29457748823583807, 0.2664076090772678, 0.18547046441183723, 0.18327269453868444, 0.2637266174537064, 0.20253855924192532, 0.2662614592433614, 0.25730280262420846, 0.22461045860566342, 0.19078827265210552, 0.21838335185739333, 0.17467220458685295, 0.1882408290619575, 0.21711396617909218, 0.18563897120598216, 0.19522615042778535, 0.23758103861761637, 0.20780159934212705, 0.2248814441348005, 0.21759653536375145, 0.2198843571917498, 0.19204854490826406, 0.19258529824654202, 0.18956969202849983, 0.19698084478710498, 0.19247505521257025, 0.18652898302103893, 0.19262552303014047, 0.192051192563224, 0.1622623500401672, 0.1260348712645638, 0.5964320182724877, 0.16449781816667242, 0.7590866126973795, 0.1677709508548576, 0.16646060323449197, 0.1854254882425751, 0.1874320430108105, 0.5802432425332764, 0.12439690595880837, 0.6948097470280665, 0.5875722936100118, 0.15261718985924166, 0.08134005686521106, 0.12437941163961752, 0.20810712035669743, 0.6087110137232443, 0.2043668303742413, 0.18706775749712423, 0.18919535550130817, 0.19094283117990196, 0.18771154614911523, 0.18518132999438008, 0.22335241287250296, 0.1925207686144751, 0.18671156012490442, 0.07396847745431334, 0.08982184143289429, 0.09021830283359955, 0.08365430269371898, 0.08386301490397252, 0.09346495348503281, 0.09186647592440544, 0.0782117872358774, 0.08566067363780039]}, "mutation_prompt": null}
{"id": "ff7af5a8-939f-4cc5-801c-33e33e6874ee", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 5))\n        self.w = 0.5 + 0.2 * np.random.rand()  # Slightly adjusted inertia weight\n        self.c1 = 1.4 + 0.3 * np.random.rand()  # Wider range for cognitive coefficient\n        self.c2 = 1.6 + 0.3 * np.random.rand()  # Wider range for social coefficient\n        self.F = 0.6 + 0.3 * np.random.rand()  # Increased adaptation in mutation factor\n        self.CR = 0.6 + 0.3 * np.random.rand()  # Adjusted crossover rate\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.elite_positions = np.copy(self.population)\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            # Evaluate current population\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            # Randomly select elite individuals\n            elite_indices = np.random.choice(self.population_size, size=max(1, self.population_size // 5), replace=False)\n            self.elite_positions = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                elite_component = 0.5 * np.random.rand() * (self.elite_positions[np.random.choice(len(self.elite_positions))] - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component + elite_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            # Apply Differential Evolution mutation with adaptive mutation strategy\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + (self.F + np.random.uniform(-0.1, 0.1)) * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSODE", "description": "A novel hybrid metaheuristic combining Particle Swarm Optimization with adaptive mutation and crossover strategies, enhanced by a random elite selection mechanism for improved exploration and exploitation.", "configspace": "", "generation": 15, "fitness": 0.1856133150702702, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.19.", "error": "", "parent_id": "0a277c6a-4e4a-42e4-801a-44869da27104", "metadata": {"aucs": [0.2920855166928995, 0.36260318438573513, 0.33132313537278446, 0.32399311484356097, 0.4160859843716733, 0.35758332004902227, 0.32515952422672545, 0.3912587148680411, 0.3559933156479559, 9.999999999998899e-05, 0.01242887403202042, 0.009624215615480214, 9.999999999998899e-05, 0.005056908007967986, 0.020391257901625437, 9.999999999998899e-05, 0.0053761642633944895, 0.014303663807246125, 0.07759869568747435, 0.0824841866337167, 0.09376989339680253, 0.07723056124689465, 0.0823100244923578, 0.12000228851855521, 0.09051160294384464, 0.11917142942863268, 0.09684304734347404, 0.08572587298245438, 0.08705157487401283, 0.09057121397884571, 0.0713449400238263, 0.09293457916260162, 0.07513842376442204, 0.07466065321383553, 0.08103022541823268, 0.07669762588016327, 0.9738869362524943, 0.9711131866822936, 0.9832328101175185, 0.9706966398549469, 0.9739359781044966, 0.9513278706393584, 0.9725419677553269, 0.9825574891695191, 0.9824499345695235, 0.168205180047849, 0.16534229022497327, 0.182125690755237, 0.18137931136996, 0.206714331746377, 0.1531467124118553, 0.16638159229985283, 0.20262837168938075, 0.18724197728183845, 0.2147160155574559, 0.1929047122401124, 0.2700039725481511, 0.2059745650118393, 0.23759888905624726, 0.19869982820848053, 0.17925200948804754, 0.2250851702281692, 0.25164359131263514, 0.09697133249624335, 0.0690307981960332, 0.05701476873265843, 0.08872203615936558, 0.12412424993581539, 0.07529405757192875, 0.10703891722820957, 0.1153737140656318, 0.11580791273047164, 0.0922898024830685, 0.08886103450460525, 0.11862061759191589, 0.07700750214953511, 0.12037378718657032, 0.10650936517596132, 0.06095616437258555, 0.10011967043365566, 0.07116437317123414, 9.999999999998899e-05, 0.008136182117107427, 0.02582504339107672, 0.01767863138532977, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00011475893777745938, 0.08826899071545136, 0.03025406680912801, 0.11381977406172261, 0.04623497157519307, 0.0880798730033393, 0.12096246965783597, 0.0638167419207506, 0.06765101938125118, 0.10337694894407445, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.045758968819638146, 0.08627385414155819, 0.09629353420532805, 0.07356281012254562, 0.09690040086103124, 0.06969018070879629, 0.051249178782586946, 0.09494751377707777, 0.04419853506480509, 0.28483093557860795, 0.3300505941895797, 0.35780270522520297, 0.3310791330490269, 0.377199277076566, 0.361165951760961, 0.31878076783565845, 0.3367614183655775, 0.31685646346311447, 0.09631096511389059, 0.07061300201562348, 0.09749340306083454, 0.09205001055444062, 0.10344185332719558, 0.09066573346844975, 0.07511000337464335, 0.10423295590144699, 0.058547713517628885, 0.14899245822536045, 0.13139031724161176, 0.18975435768979398, 0.14626250677566843, 0.12684737723834516, 0.14713762784726347, 0.1952760960957759, 0.14778216618365736, 0.18531420933563192, 0.2123606498706323, 0.24697412547435027, 0.25001044459549837, 0.21850450136370136, 0.26850564817271194, 0.2277614482400412, 0.22407427295652171, 0.24066190119874487, 0.21959322913692625, 0.1728335764360316, 0.16855349379448703, 0.17296095841853143, 0.15320637524749947, 0.17865038400669075, 0.17363395814997618, 0.16640921077849258, 0.21013917755677225, 0.18572967938787444, 0.1850720612675193, 0.2120283821769703, 0.19007828498153834, 0.18092438853117976, 0.21205202165810166, 0.19460418391617862, 0.19883730038407277, 0.18621445855469565, 0.18777126448041248, 0.16837927168242584, 0.1669054902346626, 0.17558372127638322, 0.18052301488450062, 0.17948083489804756, 0.177797309616884, 0.17042343045861308, 0.17153930908208315, 0.17668922630570583, 0.4668657987144428, 0.4757080241658379, 0.1794239654916091, 0.3443726061829968, 0.19271023539377452, 0.16296760585414616, 0.3257403926739172, 0.22634320335924718, 0.556323725789259, 0.35374135802303597, 0.20372166450297724, 0.183637982555924, 0.19461783024939083, 0.3183437268736756, 0.16231318170264764, 0.2797836952000362, 0.31804354025526216, 0.2872733277121433, 0.18843314801916822, 0.18345506156213964, 0.1943663103154537, 0.21023480873766343, 0.18312884409206598, 0.17438722458504685, 0.17126944577940084, 0.18805128507397773, 0.18377991053248177, 0.061860386247453825, 0.08518881538897571, 0.08913435924620972, 0.07179355471501692, 0.08607000910596363, 0.08145405703516395, 0.0630368406604066, 0.06660384373655037, 0.0818739826887801]}, "mutation_prompt": null}
{"id": "481245a2-700d-408d-b0f3-b2ac7101b338", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // (dim * 6))  # Adjusted population size for balance\n        self.w = 0.5 + 0.2 * np.random.rand()  # Adjusted inertia weight for more exploration\n        self.c1 = 1.5 + 0.1 * np.random.rand()  # Slightly adjusted cognitive coefficient\n        self.c2 = 1.7 + 0.1 * np.random.rand()  # Adjusted social coefficient for more influence\n        self.F = 0.5 + 0.2 * np.random.rand()  # Adaptive mutation adjusted\n        self.CR = 0.8 + 0.1 * np.random.rand()  # Narrower range for crossover rate\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            # Evaluate current population\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            # Update velocities and positions (PSO)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            # Apply Differential Evolution mutation with adaptive mutation strategy\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + (self.F + np.random.uniform(-0.1, 0.1)) * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSODE", "description": "An enhanced hybrid metaheuristic integrating Particle Swarm Optimization, Differential Evolution, and dynamic adaptation strategies for improved exploration and exploitation balance.", "configspace": "", "generation": 16, "fitness": 0.25847592073608205, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.23.", "error": "", "parent_id": "0a277c6a-4e4a-42e4-801a-44869da27104", "metadata": {"aucs": [0.5446015071751288, 0.5928478806496262, 0.6613990001924881, 0.5905281551031502, 0.6474346151809112, 0.5981875745441105, 0.5773422749888963, 0.6379367879345995, 0.5997853165137743, 0.16028753315970423, 9.999999999998899e-05, 0.18816215425749505, 0.06266220016433677, 0.20903231538467593, 0.09487164366347112, 0.023593250348154293, 0.2992765808189546, 0.09439220912334967, 0.10383678747219471, 0.10066172657150674, 0.13707478259341022, 0.11777810830974089, 0.12450585997864672, 0.11063785164242868, 0.19300515230278326, 0.15889615376361055, 0.11896183017308304, 0.092926192182474, 0.1154976747338533, 0.09808977528513663, 0.08830927720411452, 0.11501304373670806, 0.10883016086572861, 0.13085695544532305, 0.10384895533194372, 0.1158788986708672, 0.9765144075790557, 0.9836521752466663, 0.9851579732270025, 0.9582358822981709, 0.9849111344947923, 0.9743953941615577, 0.9768916972767974, 0.97722604697246, 0.9775636400178517, 0.32449313793609647, 0.13036498024245446, 0.4100705624423556, 0.35629717486632284, 0.2805849195434368, 0.14987015996741315, 0.11648595634896886, 0.28735580698053964, 0.08795945641253344, 0.6276361718528466, 0.646721976154975, 0.7266614373588126, 0.5983823634364329, 0.20975769291874646, 0.20121568153660618, 0.11324159496063857, 0.13735687773223038, 0.5761633338761339, 0.23109262879106396, 0.0880002401194584, 0.25940816478779216, 0.08346808504106318, 0.28745496340721377, 0.10888571198893537, 0.12239487855852382, 0.22214622332818257, 0.23259796902196417, 0.22707354944582803, 0.05001597145410619, 0.1491273474126068, 0.12214254874495123, 0.11817049517342149, 0.30847261458915776, 0.18628930635443997, 0.17720743238186765, 0.17347719316425014, 0.013898540788363056, 0.0619833835507545, 0.045382584256515646, 9.999999999998899e-05, 9.999999999998899e-05, 0.01643977756150239, 0.00173064229493336, 0.09699599446180895, 0.1592750393960718, 0.1450136401831572, 0.09539461794914583, 0.2434916373378796, 0.04852304151551967, 0.1168239337571032, 0.04340296287031464, 0.13940035349164503, 0.08604645249273157, 0.06960818690272685, 0.018329651310715067, 0.0472401745923664, 0.05427181628367961, 0.08198144953140563, 0.06855995583098118, 0.09503398653356165, 0.04782829728151594, 0.06633801436068865, 0.09417580003776949, 0.12580897970142157, 0.08724607243820248, 0.17457330012907657, 0.14736508896114997, 0.17206302119407335, 0.11813981519589978, 0.041973409631712144, 0.03999127759273302, 0.07226973669258241, 0.44581601841430285, 0.5134834941362453, 0.4678703328930074, 0.4463779105222405, 0.5174633729080724, 0.4230531573439069, 0.4917998717205013, 0.509505630001184, 0.43303853420223815, 0.10207773852943736, 0.10423952747430154, 0.08711756132104675, 0.11722153965247195, 0.11741687321214067, 0.10053421962659437, 0.08808706875350492, 0.10287993099117976, 0.13545390596941376, 0.20895809437698742, 0.23206021084194983, 0.22051623141302357, 0.23000473457269632, 0.24620374614161245, 0.3131500674986468, 0.34395380011221, 0.23147481165305384, 0.21589611302206924, 0.32200337942984647, 0.3836485819680602, 0.3861327544990305, 0.3650325034810139, 0.30339089288347876, 0.2833985752153907, 0.3024903401935862, 0.347087173490089, 0.3194939817543675, 0.25622888201296923, 0.23957284769007436, 0.24252564435494628, 0.2540281790631248, 0.2154064653331189, 0.2513869417212753, 0.29841305769746274, 0.24445993468774285, 0.31071928565964246, 0.21576532948984783, 0.25489759546744595, 0.21219673974685138, 0.20468475475605596, 0.22105309066754175, 0.18353984368573195, 0.1898710169714144, 0.17763064442150023, 0.21318657453519396, 0.19711371466847383, 0.21746058191544593, 0.20280996884194902, 0.20495125203165487, 0.4708644228880743, 0.2045026235699815, 0.1856464240985768, 0.2131317657097478, 0.22657070777842125, 0.8008175197616149, 0.16577705058617398, 0.16726041397611513, 0.6989587213557893, 0.19980221674580578, 0.19640820253284685, 0.14003492463472156, 0.17634952554787908, 0.21163395852359534, 0.6022218314659709, 0.21191235114024254, 0.666694727321436, 0.7183286669688533, 0.7284105866578483, 0.1501890165565044, 0.19303083409615207, 0.20890691804319184, 0.7112481328661862, 0.19067020288927117, 0.18708172724040573, 0.20013892160189228, 0.19564129597107682, 0.19088976405226543, 0.18760551897105093, 0.1830253140414162, 0.18159299839414667, 0.20296734820973372, 0.08943782118822818, 0.07395177027138666, 0.09619420900459752, 0.09120211773173159, 0.09559731414310935, 0.10355725636874924, 0.08611801332271352, 0.10051840700717585, 0.08322852893786481]}, "mutation_prompt": null}
{"id": "a43be774-a147-4cdd-8d7b-92c0d34803f1", "solution": "import numpy as np\n\nclass AdvancedHybridPSODERefined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // (dim * 4))  # Adjusted population size for balance\n        self.w = 0.5 + 0.2 * np.random.rand()  # Increased variation in inertia weight\n        self.c1 = 1.5 + 0.1 * np.random.rand()  # Slightly increased cognitive coefficient\n        self.c2 = 1.5 + 0.1 * np.random.rand()  # Increased variation in social coefficient\n        self.F = 0.5 + 0.2 * np.random.rand()  # More adaptive mutation factor\n        self.CR = 0.6 + 0.3 * np.random.rand()  # Wider range for adaptive crossover rate\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust'])\n        \n        while self.evaluations < self.budget:\n            # Evaluate current population\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            # Update velocities and positions (PSO)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            # Dynamic adjustment strategy\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.4, self.c1 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c1 + 0.05)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.4, self.c2 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c2 + 0.05)\n\n            # Apply Differential Evolution mutation with adaptive mutation strategy\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + (self.F + np.random.uniform(-0.1, 0.1)) * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "AdvancedHybridPSODERefined", "description": "A refined hybrid algorithm blending Particle Swarm Optimization, Differential Evolution, and dynamic learning strategies for enhanced exploration and exploitation balance.", "configspace": "", "generation": 17, "fitness": 0.30391848094387763, "feedback": "The algorithm AdvancedHybridPSODERefined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.25.", "error": "", "parent_id": "0a277c6a-4e4a-42e4-801a-44869da27104", "metadata": {"aucs": [0.63315677056284, 0.7553202442793351, 0.7401399887411061, 0.6625646571537755, 0.7494094488098588, 0.7359083400638655, 0.5766131362314191, 0.7405966054082476, 0.7479496418971727, 0.2223524217475985, 0.44055095805623745, 0.4624557796195171, 0.2907565957314636, 0.44733784725308356, 0.2894403649256454, 0.06793537916132864, 0.417498522912081, 0.4420524740768431, 0.14607248942018614, 0.12034885810982565, 0.1462303205686043, 0.09932300652693771, 0.13605764093199346, 0.1138213769143438, 0.10531034203309808, 0.1549680739327829, 0.10828856894185646, 0.10520608029535394, 0.10389350267548814, 0.11015611223924937, 0.07639946681360943, 0.13469613836956684, 0.09906127324626901, 0.10247860386725349, 0.13197866974900185, 0.09921927998747282, 0.9762668752589546, 0.9749418390354508, 0.9857861471845687, 0.9483048903579786, 0.9738529579719323, 0.9770813700346264, 0.9766698336963292, 0.9687993492052808, 0.9762753620393598, 0.48726136618428095, 0.5502439463399033, 0.46167872425214374, 0.15015726572386978, 0.5036988468196795, 0.5384239524982242, 0.12076832217473932, 0.17233708884369792, 0.5792205190545667, 0.3722840636472087, 0.8217846095716284, 0.827482940282417, 0.19406885734255908, 0.26833982791479405, 0.1897862764164766, 0.6433189712255256, 0.4895880019218958, 0.7663300812519079, 0.39676562017519423, 0.15307955374613025, 0.19545595020100348, 0.08910570997805045, 0.3442972785740517, 0.12261915216394792, 0.20865154730633317, 0.5183909088306968, 0.18336262355037403, 0.2761086647472939, 0.12491070302203822, 0.18192683771015172, 0.12951070943411358, 0.21414306115547566, 0.23530057005203975, 0.12683019449368949, 0.3939169506414091, 0.12164904092166706, 0.010618496940164368, 0.07982340814987787, 0.11478733565417099, 0.010674600409438462, 0.05650979367141884, 0.008536053662827503, 0.056061281236991056, 0.27357335694925367, 0.10098617891152895, 0.05136240217603372, 0.24772620838893622, 0.21452710829591115, 0.23891098027036028, 0.062151136109617644, 0.07049244275743949, 0.1652385814328563, 0.3086929117380597, 0.1144570037497682, 0.0321014132756704, 0.06570233690701954, 0.04109659293269574, 0.05294284056005871, 0.12836485694558863, 0.06147322474673256, 0.07372185479311011, 0.0721943514090575, 0.20237720771305934, 0.11967881844660166, 0.13468225203301953, 0.11196587212677589, 0.10947901761513434, 0.13626482569945442, 0.20262153474242994, 0.12253227439872116, 0.13098682511255577, 0.07809298504316298, 0.5149967883834852, 0.5177662724543655, 0.6353642780995419, 0.5238560476291032, 0.6289250620540232, 0.5868691032818868, 0.4962992210711784, 0.5787132874505603, 0.6330511858607819, 0.1288075750085924, 0.09730687746868849, 0.11678207405350882, 0.11502151086081236, 0.1245313364020294, 0.1180908802229449, 0.13790787624003586, 0.12666755212795233, 0.13432727494093888, 0.23815288662876777, 0.23988847277515823, 0.2176697771977153, 0.25787000209635036, 0.397704775496738, 0.2476983703273279, 0.21595678553130648, 0.21833047397522998, 0.15469014904876077, 0.3584433216436895, 0.3138175417536969, 0.4112441563397764, 0.3370524870844912, 0.3326514874690556, 0.27538362245915227, 0.3367703630277624, 0.4508760518136353, 0.39833337417827275, 0.2699795110567743, 0.23008184318438074, 0.33496344442637993, 0.32879593667552454, 0.3079815059327964, 0.3616910331781926, 0.32503480631240533, 0.29108308668757576, 0.2778950926220157, 0.27827942932932515, 0.17589864980624148, 0.19995021319630957, 0.21247525507996223, 0.22910225059333666, 0.23709490485440188, 0.22053123690238763, 0.19447679658331396, 0.23588060010692025, 0.17784129635979973, 0.24173929223218804, 0.2122134969338919, 0.2225681657847326, 0.18513457469252204, 0.1954389909807206, 0.18942840588285703, 0.21203621090871128, 0.19689319208063571, 0.7908029956878249, 0.17708246215649748, 0.1981707205697929, 0.7201413924752096, 0.1989126875528, 0.19824969385098112, 0.1418757434453477, 0.8027639839011396, 0.83768502184625, 0.7944131110288711, 0.20839853666125696, 0.7125247260467988, 0.7740969857097957, 0.6569960160042452, 0.1542706831439482, 0.10371228659222964, 0.20626994080537886, 0.775977526589956, 0.2068224414636698, 0.19281337225383555, 0.19156319132734645, 0.19483284405928736, 0.18266662258093325, 0.1966484273384541, 0.21374241423382068, 0.1962163736132273, 0.17707001197327588, 0.07980279003600677, 0.09033731367966702, 0.08616220133712671, 0.0867665360024994, 0.08910706716345596, 0.07328395403489862, 0.09960424871170903, 0.09625193477654281, 0.09031339116839132]}, "mutation_prompt": null}
{"id": "361f0266-d6bb-4dde-8dfc-49b89a0ea99e", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 4))  # Slightly increased population size for diversity\n        self.w = 0.3 + 0.4 * np.random.rand()  # Broadened range for inertia weight\n        self.c1 = 1.4 + 0.2 * np.random.rand()  # More adaptive cognitive coefficient\n        self.c2 = 1.4 + 0.2 * np.random.rand()  # More adaptive social coefficient\n        self.F = 0.6 + 0.1 * np.random.rand()  # Slight adjustment in mutation factor\n        self.CR = 0.5 + 0.4 * np.random.rand()  # Wider range for adaptive crossover rate\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c1 + 0.05)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c2 + 0.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + (self.F + np.random.uniform(-0.05, 0.05)) * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSODE", "description": "An enhanced hybrid algorithm combining Particle Swarm Optimization, Differential Evolution, and adaptive dynamic learning strategies with probabilistic adjustments for improved convergence.", "configspace": "", "generation": 18, "fitness": 0.30064774617656564, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.25.", "error": "", "parent_id": "a43be774-a147-4cdd-8d7b-92c0d34803f1", "metadata": {"aucs": [0.7353299458372784, 0.7420632360120929, 0.7045457073143969, 0.6823580853249882, 0.7511991432557464, 0.7651497148827652, 0.7370163896883428, 0.7863005832297051, 0.7398213408303542, 0.3633215794187349, 0.3726309501978484, 0.38270729356838096, 0.2686430102653953, 0.3052581361508111, 0.38403886041819757, 0.03956297908584694, 0.44629007481236427, 0.37427782288885114, 0.12220438737183559, 0.135893442033732, 0.10648019868583791, 0.14518077917588523, 0.17120383744415035, 0.13000818034182793, 0.09408688253185793, 0.12572950159873852, 0.16215652222224874, 0.1480479004037406, 0.12443051725458154, 0.11609432981636858, 0.08761931700679249, 0.08602735537386874, 0.09625548853095789, 0.10518528264027938, 0.08688557682363063, 0.11559878560631787, 0.9713089831415607, 0.9506708621682719, 0.9805924204783442, 0.9767013292759903, 0.9811300249577273, 0.963121517922006, 0.9728364599051765, 0.9841912200816564, 0.9734755794825053, 0.5666615965215513, 0.5777826339417966, 0.27480015618489617, 0.4973413011670196, 0.6252998561840695, 0.5421568158777508, 0.4517793719157671, 0.5852939449746362, 0.12665334072899115, 0.7621162604056382, 0.2395591152093801, 0.801616280122067, 0.2085061121489934, 0.19383325741656632, 0.8177266852125065, 0.769203426442724, 0.2160738705667209, 0.8295863462348425, 0.3126742305548239, 0.16984899288210253, 0.12101171507723485, 0.09632135396087482, 0.2680359049677836, 0.252997490532488, 0.13611981147622298, 0.15453658547361593, 0.17891643905638777, 0.33400684291493676, 0.11751138410861517, 0.17083194618354647, 0.38380356303444063, 0.17737493269501303, 0.1984200429211176, 0.20038444284900347, 0.2640154318890652, 0.16188479952219026, 0.09417842104506613, 0.00012531584805419715, 0.16553547182141393, 0.03627448151004464, 9.999999999998899e-05, 9.999999999998899e-05, 0.10816374375192861, 0.04575621055104362, 0.003713610593038763, 0.16284048384529493, 0.14120970283452605, 0.17364841265981634, 0.08561311341819966, 0.24012120229519185, 0.18233402016970068, 0.1387651325651419, 0.11121636168466609, 0.20971064355584357, 0.09253305245868049, 0.09225911852787849, 0.15515792564548558, 0.09727699722483707, 0.07883365225125838, 0.08353893138687729, 0.11631558817136811, 0.060052998809219216, 0.08324596449833066, 0.1633649582848482, 0.09825141180320773, 0.2611629387517044, 0.2177082247677533, 0.03662122735979734, 0.20118004205130513, 0.05080957655133056, 0.046690918556704264, 0.25308583976386045, 0.49016161410834613, 0.5581915431095968, 0.6195457781782114, 0.5794392705543078, 0.5215002247055791, 0.5766191681244053, 0.5591818697515647, 0.5661746536251506, 0.5742347454355736, 0.08828401156866128, 0.1254010205955981, 0.1503664703052232, 0.08537881233835964, 0.16815173363877434, 0.09313146254582316, 0.07010842228927794, 0.13368318102013932, 0.10091077881651145, 0.24975879694480152, 0.2578130512740828, 0.17762709727136738, 0.214812174627666, 0.2738529006451549, 0.24741717876747582, 0.18175858502903208, 0.4263745838809001, 0.21286986575933686, 0.37374769605207336, 0.24408555327134618, 0.37805296150733203, 0.39782843887164276, 0.3467184950506277, 0.33641343910827615, 0.289213653770232, 0.4359291143804126, 0.4225076112247973, 0.25600033945095224, 0.1571620105196544, 0.26258345625626367, 0.17495857813935722, 0.20363827843001414, 0.24037369085948335, 0.22412054299639483, 0.34323472055873894, 0.3590057106390384, 0.22205263963980904, 0.2790872951254406, 0.2016741227518689, 0.19719126501695916, 0.21435537191625398, 0.19977554960982324, 0.18919069389869325, 0.22210334436680412, 0.20968840230271557, 0.18168744334671305, 0.19460727923216337, 0.22204577979652074, 0.20887739502093328, 0.21774688218549332, 0.19552003058595002, 0.1987779651980649, 0.20076606037783595, 0.19961865564263603, 0.8437612459082698, 0.18744472697537973, 0.16771459474462114, 0.8414413317818398, 0.19924336557133548, 0.19915292356962033, 0.1417344128793866, 0.16083872443889502, 0.8671134579315087, 0.7755353207038713, 0.20921521536373344, 0.7187463683355528, 0.20385670362166652, 0.7111646524826345, 0.15071997219822575, 0.19897179020617584, 0.1043703582918859, 0.7797249912159342, 0.19417115333642354, 0.18325535466392773, 0.1837412269883968, 0.2103173615752295, 0.20246228369438646, 0.18548031060709713, 0.18206392856793474, 0.21843313440019496, 0.2018999650443687, 0.0897338986368299, 0.09675282280435116, 0.08807182251626322, 0.08974394838380118, 0.10215063989575479, 0.1025412816739405, 0.09711569109188734, 0.08137997941720909, 0.10094524078062872]}, "mutation_prompt": null}
{"id": "e8bacfa7-0416-44b7-aafb-f8fa371d00e3", "solution": "import numpy as np\n\nclass EnhancedEvoPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))  # Slightly larger population size\n        self.w = 0.4 + 0.3 * np.random.rand()  # Greater variability in inertia weight\n        self.c1 = 1.4 + 0.2 * np.random.rand()  # Altered cognitive component\n        self.c2 = 1.6 + 0.2 * np.random.rand()  # Adjusted social coefficient\n        self.F = 0.6 + 0.3 * np.random.rand()  # Modified adaptive mutation factor\n        self.CR = 0.7 + 0.2 * np.random.rand()  # Narrowed range for crossover rate\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'adaptive_w'])\n        \n        while self.evaluations < self.budget:\n            # Evaluate current population\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            # Update velocities and positions (PSO)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            # Feedback-driven adjustment strategy\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.05) if self.global_best_score < np.mean(self.personal_best_scores) else min(2.1, self.c1 + 0.05)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.05) if self.global_best_score < np.mean(self.personal_best_scores) else min(2.1, self.c2 + 0.05)\n            elif learning_strategy == 'adaptive_w':\n                self.w = 0.4 + (0.6 * (1 - self.evaluations / self.budget))  # Adaptive inertia weight\n\n            # Apply Differential Evolution mutation with adaptive mutation strategy\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + (self.F + np.random.uniform(-0.1, 0.1)) * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedEvoPSO_DE", "description": "An enhanced evolutionary algorithm combining Particle Swarm Optimization with adaptive Differential Evolution mechanisms and feedback-driven learning strategies for robust performance across diverse optimization landscapes.", "configspace": "", "generation": 19, "fitness": 0.17170628281316602, "feedback": "The algorithm EnhancedEvoPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.19.", "error": "", "parent_id": "a43be774-a147-4cdd-8d7b-92c0d34803f1", "metadata": {"aucs": [0.33625445720124625, 0.3321344307630263, 0.3340787468347124, 0.2991364842604932, 0.3264485912115018, 0.3691898447968497, 0.340404844091981, 0.3392159826739196, 0.31922760960511953, 0.006262884997569884, 0.0077798836472040556, 0.018894199927149802, 0.017595755428846727, 0.029976602513768325, 0.02141565552876712, 0.018742449544609574, 0.03771326224978855, 9.999999999998899e-05, 0.07898567732002881, 0.075495560638972, 0.08356065998835094, 0.08014198245450155, 0.0750443910934786, 0.08288290069950421, 0.07416878400563509, 0.10556549104019741, 0.0718786731695995, 0.0544658173539585, 0.07064301118313654, 0.05785330473694483, 0.05886601645732481, 0.0679528129247241, 0.06187121331727152, 0.07622606905513896, 0.061392709450587946, 0.07486356539461103, 0.9756507856748678, 0.9617313029306819, 0.9832050053778728, 0.9785433054604852, 0.9746213252556, 0.9622219168974135, 0.9813278571353066, 0.9942894587038288, 0.980356375444074, 0.21246153447624405, 0.17404493932520781, 0.17608943320079795, 0.12616536139070245, 0.21746927120096682, 0.11044339255979363, 0.08266265797225802, 0.08489347558996818, 0.17931764329666688, 0.34707175755664765, 0.29124565947968417, 0.21690786034158627, 0.35930967954396986, 0.18082716683196942, 0.1765367993434922, 0.18446166865115554, 0.19435221536732028, 0.33863740486875216, 0.08420915062004075, 0.03894463452299968, 0.07190097255160166, 0.03608424813285749, 0.07214451049073867, 9.999999999998899e-05, 0.06750276104675468, 0.07955510384713094, 0.08115965462739771, 0.07608462830937168, 0.049287834768159344, 0.08262438267942873, 0.08659518875200733, 0.05134408818588343, 0.13406167694004711, 0.08815513138173514, 0.10579525632741682, 0.042996232220761654, 0.00817509045746212, 0.016425628066405573, 9.999999999998899e-05, 9.999999999998899e-05, 0.0001300686496377157, 0.007864296142727434, 0.030077165758312208, 0.012984155638159023, 0.0012418958354651899, 0.04558245628838398, 0.04996911632094203, 0.07735246650221761, 0.015430452458984445, 0.07074462293491213, 0.0543610101450156, 0.037481386190041155, 0.05138066899992433, 0.057618409006521376, 0.007668010230688527, 0.0024281835595658663, 0.007455919568528979, 0.00917110182062808, 0.0029341712803446773, 0.004155658210655777, 0.02888217838303464, 0.00258790782419549, 0.003206404142120145, 0.048059306982921934, 0.07036869964659109, 9.999999999998899e-05, 0.05146311960581407, 0.042016116856308905, 0.046102142030394644, 0.021104256669630894, 0.02489406956761664, 0.05437571275277353, 0.2797889480632867, 0.2970946740165793, 0.3233013045412636, 0.19886390732072123, 0.34209120012742245, 0.2812293936135024, 0.3215315938023896, 0.31743278677105413, 0.322919672973876, 0.0801076692790813, 0.06457323820741478, 0.09665880502787927, 0.0880757872727812, 0.08628795603173789, 0.07354927122448607, 0.07258037227132574, 0.07447950778383261, 0.0807366437588275, 0.15204934971506812, 0.14155075463423183, 0.1495268546112939, 0.1918883344081057, 0.19119289235113124, 0.16992520912862952, 0.19347937277614746, 0.20237881522068846, 0.1360696091440634, 0.2220742519968999, 0.21003353900162702, 0.22829156195393452, 0.22811504494048773, 0.22601523299946535, 0.23519418362799982, 0.2309672388746825, 0.23714581261249568, 0.2466258360878837, 0.18461957769929616, 0.14139329791015187, 0.17480818944641197, 0.15537692776859258, 0.1358463235281513, 0.17964398509080803, 0.21018074196598513, 0.1967539076443191, 0.15477252661013463, 0.19334102311277634, 0.1801988463016574, 0.1807087478773417, 0.18347949795832896, 0.17743964692353242, 0.17002648314037583, 0.18925923494316954, 0.16900840630669678, 0.1811346178078268, 0.17502344475428055, 0.17050834191146513, 0.1740411579092721, 0.17572131490631815, 0.17660399970058493, 0.16717483372899478, 0.1827384591423704, 0.17548852777547186, 0.18650389486278518, 0.21533812421654275, 0.18010072776363795, 0.17090400641557313, 0.3760112552006335, 0.18546993960518798, 0.17737134760193607, 0.15254693817542686, 0.1506536478192151, 0.41811632524175835, 0.31070164161175684, 0.18787792047026164, 0.15086954811722242, 0.16554458285484108, 0.2598860412368065, 0.14486541956198284, 0.19353358143672617, 0.18906858687533357, 0.3434757744711987, 0.18543113091519103, 0.18629032860452222, 0.18679647296990398, 0.17801764117750407, 0.18249577963967534, 0.1737520992500471, 0.1778076945832694, 0.18959055090302868, 0.17584297830548312, 0.06268551601283057, 0.06507136297530047, 0.06985123827409212, 0.05812403116690179, 0.07420942781831108, 0.08073957085723815, 0.07674661426730056, 0.06997867322201223, 0.06335510175671788]}, "mutation_prompt": null}
{"id": "dbbe0881-c4d9-48b6-b4e7-d557f7c7e78a", "solution": "import numpy as np\n\nclass AdvancedHybridPSODERefined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 4))  # Adjusted population size for balance\n        self.w = 0.4 + 0.3 * np.random.rand()  # Increased variation in inertia weight\n        self.c1 = 1.4 + 0.2 * np.random.rand()  # Slightly increased cognitive coefficient\n        self.c2 = 1.6 + 0.1 * np.random.rand()  # Increased variation in social coefficient\n        self.F = 0.6 + 0.2 * np.random.rand()  # More adaptive mutation factor\n        self.CR = 0.5 + 0.4 * np.random.rand()  # Wider range for adaptive crossover rate\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'both_adjust'])\n        \n        while self.evaluations < self.budget:\n            # Evaluate current population\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            # Update velocities and positions (PSO)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            # Dynamic adjustment strategy\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c1 + 0.05)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c2 + 0.05)\n            elif learning_strategy == 'both_adjust':\n                self.c1 = max(0.5, self.c1 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c1 + 0.05)\n                self.c2 = max(0.5, self.c2 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c2 + 0.05)\n\n            # Apply Differential Evolution mutation with adaptive mutation strategy\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + (self.F + np.random.uniform(-0.1, 0.1)) * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "AdvancedHybridPSODERefined", "description": "A refined hybrid optimization algorithm leveraging dynamic PSO-DE with adaptive parameter tuning and strategic variation for better exploration and exploitation.", "configspace": "", "generation": 20, "fitness": 0.2818605384127028, "feedback": "The algorithm AdvancedHybridPSODERefined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.26.", "error": "", "parent_id": "a43be774-a147-4cdd-8d7b-92c0d34803f1", "metadata": {"aucs": [0.7341361788999461, 0.7918843974796159, 0.7800374246085369, 0.7474887736411353, 0.7285185397490371, 0.7814328190308517, 0.6704219772454967, 0.7619203993240709, 0.7339455960246977, 0.12536627537107448, 0.034290009605755456, 0.2205258885972794, 0.26668238421585, 0.10704015030498704, 0.12174179726953194, 0.012725196402656347, 0.07225089448181643, 9.999999999998899e-05, 0.10266612808115916, 0.1365231766883881, 0.10417256949736708, 0.1719375679559555, 0.10967584963532151, 0.10045210011330274, 0.11132178013856897, 0.13878397550118748, 0.14902858990357615, 0.09675920024147511, 0.08572055373514065, 0.10573258608519176, 0.12277124896990277, 0.10545679213476411, 0.07808508637209288, 0.09092170916309172, 0.09673322532215456, 0.14807835900603128, 0.9758079534609415, 0.9007938743548445, 0.9823532719949284, 0.9768344917151391, 0.9812477921049646, 0.9718789864369759, 0.9730011175192977, 0.9847138209713936, 0.9728193228675238, 0.5955660906037231, 0.6134920014691523, 0.05871637222391968, 0.19669788057317938, 0.17118465223885704, 0.6113465002609786, 0.12122562542873494, 0.3919508872790689, 0.23289492837447778, 0.7778910920366673, 0.7733835902417763, 0.21504173210330868, 0.26634378877189846, 0.8491406090726845, 0.8153813420575333, 0.22801337778412567, 0.767107988375846, 0.8373009345076545, 0.18493148734016152, 0.11461609802619754, 0.15524480712801647, 0.09024227191225143, 0.1829598732796801, 0.1379477901465085, 0.15122090781788233, 0.15113176954083662, 0.12261141741394554, 0.09955297133326291, 0.27354704413427444, 0.11240953557370337, 0.14280219673154881, 0.13574627158548902, 0.2688391977482062, 0.164253407741503, 0.2636352891183411, 0.1002798374207794, 9.999999999998899e-05, 9.999999999998899e-05, 0.10798668527531574, 0.042570998818019734, 9.999999999998899e-05, 0.00418814281201485, 0.06960892562210608, 0.021481120241020668, 9.999999999998899e-05, 0.10383742831653486, 0.19951348583816364, 0.08441083462608057, 0.06905381055773252, 0.0712638062972536, 0.05207851446128464, 0.09225468537416348, 0.07954657866896708, 0.3355804500845989, 0.1948470490803953, 0.028720968041837325, 0.1391627973551085, 0.3054472900018116, 0.06399979216644147, 0.06948640052047561, 0.14287792539432176, 0.1307764954268421, 0.2153271365410292, 0.17573953856131752, 0.13398650321146865, 0.13756078609959987, 0.10923331363423061, 0.11018150303573016, 0.06797095880407344, 0.044330306817507825, 0.26779488049380407, 0.07705029874167735, 0.48239490784255634, 0.5961437019142686, 0.49951051719820916, 0.4867606979593636, 0.4897920866227493, 0.527035244648381, 0.53244133608925, 0.5228792197672996, 0.5202540210281517, 0.09590682093587255, 0.1340706589934385, 0.10793774741842499, 0.14278767708191664, 0.14245867862808503, 0.09361236546729779, 0.14956258099033948, 0.12187525389738163, 0.10349596421230833, 0.19181603731650498, 0.35873044403395526, 0.21945930655036316, 0.2550202947829806, 0.48891301645001106, 0.2618405173011904, 0.2546509137806958, 0.2585000674680308, 0.2005253641741379, 0.3903788510003324, 0.4261821059826213, 0.3470218066370533, 0.4371822703036713, 0.242535349636661, 0.39346930393950574, 0.44209977090620045, 0.4021087636186568, 0.2784583102301422, 0.22696119098873913, 0.23820532929275684, 0.227066338343189, 0.21676089713722269, 0.24494116736483384, 0.23232278018006214, 0.3344393176089101, 0.24438166151995488, 0.2054439143939062, 0.20483670257491127, 0.27116373617694245, 0.1952813733904767, 0.24233359061749427, 0.17741409183559076, 0.18732030803978705, 0.19526152599379454, 0.25137783152440074, 0.26856534479433225, 0.20079789827567962, 0.19026788419795437, 0.6032445284221002, 0.20010237819658627, 0.20845412444030154, 0.1874404970224126, 0.5802634748087883, 0.19546988317596736, 0.18361068892316856, 0.8126547963627392, 0.187111951031114, 0.16746014897305217, 0.8336277689911532, 0.19903818813834795, 0.19717623031780052, 0.16684827636762567, 0.16057411682752842, 0.8241465081453581, 0.735527622723078, 0.2083462007250777, 0.07349632503325754, 0.19985926787262998, 0.44656319022939484, 0.12254913521276745, 0.2083917966467046, 0.1046284924300942, 0.8023494806132603, 0.1823013132935103, 0.1977844272529895, 0.1875957197864213, 0.19198467323615676, 0.18351943643105373, 0.185597802898682, 0.190784872618445, 0.19906213091380665, 0.20311319682869633, 0.08585698033615952, 0.09326891626894485, 0.09312737907604673, 0.09996726590161198, 0.08831356515483546, 0.08511116141843011, 0.08403605531511094, 0.08640186264862637, 0.09445879653490008]}, "mutation_prompt": null}
{"id": "118f7844-f816-4366-9fc9-e2325247a813", "solution": "import numpy as np\n\nclass AdvancedHybridPSODERefined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // (dim * 4))  # Adjusted population size for balance\n        self.w = 0.5 + 0.2 * np.random.rand()  # Increased variation in inertia weight\n        self.c1 = 1.5 + 0.1 * np.random.rand()  # Slightly increased cognitive coefficient\n        self.c2 = 1.5 + 0.1 * np.random.rand()  # Increased variation in social coefficient\n        self.F = 0.5 + 0.2 * np.random.rand()  # More adaptive mutation factor\n        self.CR = 0.6 + 0.3 * np.random.rand()  # Wider range for adaptive crossover rate\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust'])\n        \n        while self.evaluations < self.budget:\n            # Evaluate current population\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            # Update velocities and positions (PSO)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            # Dynamic adjustment strategy\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.4, self.c1 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c1 + 0.05)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.4, self.c2 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c2 + 0.05)\n\n            # Apply Differential Evolution mutation with adaptive mutation strategy\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + (self.F + np.random.uniform(-0.1, 0.1)) * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "AdvancedHybridPSODERefined", "description": "A refined hybrid algorithm blending Particle Swarm Optimization, Differential Evolution, and dynamic learning strategies for enhanced exploration and exploitation balance.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a43be774-a147-4cdd-8d7b-92c0d34803f1", "metadata": {"aucs": [0.63315677056284, 0.7553202442793351, 0.7401399887411061, 0.6625646571537755, 0.7494094488098588, 0.7359083400638655, 0.5766131362314191, 0.7405966054082476, 0.7479496418971727, 0.2223524217475985, 0.44055095805623745, 0.4624557796195171, 0.2907565957314636, 0.44733784725308356, 0.2894403649256454, 0.06793537916132864, 0.417498522912081, 0.4420524740768431, 0.14607248942018614, 0.12034885810982565, 0.1462303205686043, 0.09932300652693771, 0.13605764093199346, 0.1138213769143438, 0.10531034203309808, 0.1549680739327829, 0.10828856894185646, 0.10520608029535394, 0.10389350267548814, 0.11015611223924937, 0.07639946681360943, 0.13469613836956684, 0.09906127324626901, 0.10247860386725349, 0.13197866974900185, 0.09921927998747282, 0.9762668752589546, 0.9749418390354508, 0.9857861471845687, 0.9483048903579786, 0.9738529579719323, 0.9770813700346264, 0.9766698336963292, 0.9687993492052808, 0.9762753620393598, 0.48726136618428095, 0.5502439463399033, 0.46167872425214374, 0.15015726572386978, 0.5036988468196795, 0.5384239524982242, 0.12076832217473932, 0.17233708884369792, 0.5792205190545667, 0.3722840636472087, 0.8217846095716284, 0.827482940282417, 0.19406885734255908, 0.26833982791479405, 0.1897862764164766, 0.6433189712255256, 0.4895880019218958, 0.7663300812519079, 0.39676562017519423, 0.15307955374613025, 0.19545595020100348, 0.08910570997805045, 0.3442972785740517, 0.12261915216394792, 0.20865154730633317, 0.5183909088306968, 0.18336262355037403, 0.2761086647472939, 0.12491070302203822, 0.18192683771015172, 0.12951070943411358, 0.21414306115547566, 0.23530057005203975, 0.12683019449368949, 0.3939169506414091, 0.12164904092166706, 0.010618496940164368, 0.07982340814987787, 0.11478733565417099, 0.010674600409438462, 0.05650979367141884, 0.008536053662827503, 0.056061281236991056, 0.27357335694925367, 0.10098617891152895, 0.05136240217603372, 0.24772620838893622, 0.21452710829591115, 0.23891098027036028, 0.062151136109617644, 0.07049244275743949, 0.1652385814328563, 0.3086929117380597, 0.1144570037497682, 0.0321014132756704, 0.06570233690701954, 0.04109659293269574, 0.05294284056005871, 0.12836485694558863, 0.06147322474673256, 0.07372185479311011, 0.0721943514090575, 0.20237720771305934, 0.11967881844660166, 0.13468225203301953, 0.11196587212677589, 0.10947901761513434, 0.13626482569945442, 0.20262153474242994, 0.12253227439872116, 0.13098682511255577, 0.07809298504316298, 0.5149967883834852, 0.5177662724543655, 0.6353642780995419, 0.5238560476291032, 0.6289250620540232, 0.5868691032818868, 0.4962992210711784, 0.5787132874505603, 0.6330511858607819, 0.1288075750085924, 0.09730687746868849, 0.11678207405350882, 0.11502151086081236, 0.1245313364020294, 0.1180908802229449, 0.13790787624003586, 0.12666755212795233, 0.13432727494093888, 0.23815288662876777, 0.23988847277515823, 0.2176697771977153, 0.25787000209635036, 0.397704775496738, 0.2476983703273279, 0.21595678553130648, 0.21833047397522998, 0.15469014904876077, 0.3584433216436895, 0.3138175417536969, 0.4112441563397764, 0.3370524870844912, 0.3326514874690556, 0.27538362245915227, 0.3367703630277624, 0.4508760518136353, 0.39833337417827275, 0.2699795110567743, 0.23008184318438074, 0.33496344442637993, 0.32879593667552454, 0.3079815059327964, 0.3616910331781926, 0.32503480631240533, 0.29108308668757576, 0.2778950926220157, 0.27827942932932515, 0.17589864980624148, 0.19995021319630957, 0.21247525507996223, 0.22910225059333666, 0.23709490485440188, 0.22053123690238763, 0.19447679658331396, 0.23588060010692025, 0.17784129635979973, 0.24173929223218804, 0.2122134969338919, 0.2225681657847326, 0.18513457469252204, 0.1954389909807206, 0.18942840588285703, 0.21203621090871128, 0.19689319208063571, 0.7908029956878249, 0.17708246215649748, 0.1981707205697929, 0.7201413924752096, 0.1989126875528, 0.19824969385098112, 0.1418757434453477, 0.8027639839011396, 0.83768502184625, 0.7944131110288711, 0.20839853666125696, 0.7125247260467988, 0.7740969857097957, 0.6569960160042452, 0.1542706831439482, 0.10371228659222964, 0.20626994080537886, 0.775977526589956, 0.2068224414636698, 0.19281337225383555, 0.19156319132734645, 0.19483284405928736, 0.18266662258093325, 0.1966484273384541, 0.21374241423382068, 0.1962163736132273, 0.17707001197327588, 0.07980279003600677, 0.09033731367966702, 0.08616220133712671, 0.0867665360024994, 0.08910706716345596, 0.07328395403489862, 0.09960424871170903, 0.09625193477654281, 0.09031339116839132]}, "mutation_prompt": null}
{"id": "f7edf7b1-2914-456a-a620-1b190dd57078", "solution": "import numpy as np\n\nclass AdvancedHybridPSODERefined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // (dim * 4))  # Adjusted population size for balance\n        self.w = 0.5 + 0.2 * np.random.rand()  # Increased variation in inertia weight\n        self.c1 = 1.5 + 0.1 * np.random.rand()  # Slightly increased cognitive coefficient\n        self.c2 = 1.5 + 0.1 * np.random.rand()  # Increased variation in social coefficient\n        self.F = 0.5 + 0.2 * np.random.rand()  # More adaptive mutation factor\n        self.CR = 0.6 + 0.3 * np.random.rand()  # Wider range for adaptive crossover rate\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust'])\n        \n        while self.evaluations < self.budget:\n            # Evaluate current population\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            # Update velocities and positions (PSO)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            # Dynamic adjustment strategy\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.4, self.c1 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c1 + 0.05)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.4, self.c2 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c2 + 0.05)\n\n            # Apply Differential Evolution mutation with adaptive mutation strategy\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + (self.F + np.random.uniform(-0.1, 0.1)) * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "AdvancedHybridPSODERefined", "description": "A refined hybrid algorithm blending Particle Swarm Optimization, Differential Evolution, and dynamic learning strategies for enhanced exploration and exploitation balance.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a43be774-a147-4cdd-8d7b-92c0d34803f1", "metadata": {"aucs": [0.63315677056284, 0.7553202442793351, 0.7401399887411061, 0.6625646571537755, 0.7494094488098588, 0.7359083400638655, 0.5766131362314191, 0.7405966054082476, 0.7479496418971727, 0.2223524217475985, 0.44055095805623745, 0.4624557796195171, 0.2907565957314636, 0.44733784725308356, 0.2894403649256454, 0.06793537916132864, 0.417498522912081, 0.4420524740768431, 0.14607248942018614, 0.12034885810982565, 0.1462303205686043, 0.09932300652693771, 0.13605764093199346, 0.1138213769143438, 0.10531034203309808, 0.1549680739327829, 0.10828856894185646, 0.10520608029535394, 0.10389350267548814, 0.11015611223924937, 0.07639946681360943, 0.13469613836956684, 0.09906127324626901, 0.10247860386725349, 0.13197866974900185, 0.09921927998747282, 0.9762668752589546, 0.9749418390354508, 0.9857861471845687, 0.9483048903579786, 0.9738529579719323, 0.9770813700346264, 0.9766698336963292, 0.9687993492052808, 0.9762753620393598, 0.48726136618428095, 0.5502439463399033, 0.46167872425214374, 0.15015726572386978, 0.5036988468196795, 0.5384239524982242, 0.12076832217473932, 0.17233708884369792, 0.5792205190545667, 0.3722840636472087, 0.8217846095716284, 0.827482940282417, 0.19406885734255908, 0.26833982791479405, 0.1897862764164766, 0.6433189712255256, 0.4895880019218958, 0.7663300812519079, 0.39676562017519423, 0.15307955374613025, 0.19545595020100348, 0.08910570997805045, 0.3442972785740517, 0.12261915216394792, 0.20865154730633317, 0.5183909088306968, 0.18336262355037403, 0.2761086647472939, 0.12491070302203822, 0.18192683771015172, 0.12951070943411358, 0.21414306115547566, 0.23530057005203975, 0.12683019449368949, 0.3939169506414091, 0.12164904092166706, 0.010618496940164368, 0.07982340814987787, 0.11478733565417099, 0.010674600409438462, 0.05650979367141884, 0.008536053662827503, 0.056061281236991056, 0.27357335694925367, 0.10098617891152895, 0.05136240217603372, 0.24772620838893622, 0.21452710829591115, 0.23891098027036028, 0.062151136109617644, 0.07049244275743949, 0.1652385814328563, 0.3086929117380597, 0.1144570037497682, 0.0321014132756704, 0.06570233690701954, 0.04109659293269574, 0.05294284056005871, 0.12836485694558863, 0.06147322474673256, 0.07372185479311011, 0.0721943514090575, 0.20237720771305934, 0.11967881844660166, 0.13468225203301953, 0.11196587212677589, 0.10947901761513434, 0.13626482569945442, 0.20262153474242994, 0.12253227439872116, 0.13098682511255577, 0.07809298504316298, 0.5149967883834852, 0.5177662724543655, 0.6353642780995419, 0.5238560476291032, 0.6289250620540232, 0.5868691032818868, 0.4962992210711784, 0.5787132874505603, 0.6330511858607819, 0.1288075750085924, 0.09730687746868849, 0.11678207405350882, 0.11502151086081236, 0.1245313364020294, 0.1180908802229449, 0.13790787624003586, 0.12666755212795233, 0.13432727494093888, 0.23815288662876777, 0.23988847277515823, 0.2176697771977153, 0.25787000209635036, 0.397704775496738, 0.2476983703273279, 0.21595678553130648, 0.21833047397522998, 0.15469014904876077, 0.3584433216436895, 0.3138175417536969, 0.4112441563397764, 0.3370524870844912, 0.3326514874690556, 0.27538362245915227, 0.3367703630277624, 0.4508760518136353, 0.39833337417827275, 0.2699795110567743, 0.23008184318438074, 0.33496344442637993, 0.32879593667552454, 0.3079815059327964, 0.3616910331781926, 0.32503480631240533, 0.29108308668757576, 0.2778950926220157, 0.27827942932932515, 0.17589864980624148, 0.19995021319630957, 0.21247525507996223, 0.22910225059333666, 0.23709490485440188, 0.22053123690238763, 0.19447679658331396, 0.23588060010692025, 0.17784129635979973, 0.24173929223218804, 0.2122134969338919, 0.2225681657847326, 0.18513457469252204, 0.1954389909807206, 0.18942840588285703, 0.21203621090871128, 0.19689319208063571, 0.7908029956878249, 0.17708246215649748, 0.1981707205697929, 0.7201413924752096, 0.1989126875528, 0.19824969385098112, 0.1418757434453477, 0.8027639839011396, 0.83768502184625, 0.7944131110288711, 0.20839853666125696, 0.7125247260467988, 0.7740969857097957, 0.6569960160042452, 0.1542706831439482, 0.10371228659222964, 0.20626994080537886, 0.775977526589956, 0.2068224414636698, 0.19281337225383555, 0.19156319132734645, 0.19483284405928736, 0.18266662258093325, 0.1966484273384541, 0.21374241423382068, 0.1962163736132273, 0.17707001197327588, 0.07980279003600677, 0.09033731367966702, 0.08616220133712671, 0.0867665360024994, 0.08910706716345596, 0.07328395403489862, 0.09960424871170903, 0.09625193477654281, 0.09031339116839132]}, "mutation_prompt": null}
{"id": "ceff8875-a730-413f-9a61-23b65b1e95d6", "solution": "import numpy as np\n\nclass AdvancedHybridPSODERefined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // (dim * 4))  # Adjusted population size for balance\n        self.w = 0.5 + 0.2 * np.random.rand()  # Increased variation in inertia weight\n        self.c1 = 1.5 + 0.1 * np.random.rand()  # Slightly increased cognitive coefficient\n        self.c2 = 1.5 + 0.1 * np.random.rand()  # Increased variation in social coefficient\n        self.F = 0.5 + 0.2 * np.random.rand()  # More adaptive mutation factor\n        self.CR = 0.6 + 0.3 * np.random.rand()  # Wider range for adaptive crossover rate\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust'])\n        \n        while self.evaluations < self.budget:\n            # Evaluate current population\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            # Update velocities and positions (PSO)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            # Dynamic adjustment strategy\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.4, self.c1 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c1 + 0.05)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.4, self.c2 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c2 + 0.05)\n\n            # Apply Differential Evolution mutation with adaptive mutation strategy\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + (self.F + np.random.uniform(-0.1, 0.1)) * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "AdvancedHybridPSODERefined", "description": "A refined hybrid algorithm blending Particle Swarm Optimization, Differential Evolution, and dynamic learning strategies for enhanced exploration and exploitation balance.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a43be774-a147-4cdd-8d7b-92c0d34803f1", "metadata": {"aucs": [0.63315677056284, 0.7553202442793351, 0.7401399887411061, 0.6625646571537755, 0.7494094488098588, 0.7359083400638655, 0.5766131362314191, 0.7405966054082476, 0.7479496418971727, 0.2223524217475985, 0.44055095805623745, 0.4624557796195171, 0.2907565957314636, 0.44733784725308356, 0.2894403649256454, 0.06793537916132864, 0.417498522912081, 0.4420524740768431, 0.14607248942018614, 0.12034885810982565, 0.1462303205686043, 0.09932300652693771, 0.13605764093199346, 0.1138213769143438, 0.10531034203309808, 0.1549680739327829, 0.10828856894185646, 0.10520608029535394, 0.10389350267548814, 0.11015611223924937, 0.07639946681360943, 0.13469613836956684, 0.09906127324626901, 0.10247860386725349, 0.13197866974900185, 0.09921927998747282, 0.9762668752589546, 0.9749418390354508, 0.9857861471845687, 0.9483048903579786, 0.9738529579719323, 0.9770813700346264, 0.9766698336963292, 0.9687993492052808, 0.9762753620393598, 0.48726136618428095, 0.5502439463399033, 0.46167872425214374, 0.15015726572386978, 0.5036988468196795, 0.5384239524982242, 0.12076832217473932, 0.17233708884369792, 0.5792205190545667, 0.3722840636472087, 0.8217846095716284, 0.827482940282417, 0.19406885734255908, 0.26833982791479405, 0.1897862764164766, 0.6433189712255256, 0.4895880019218958, 0.7663300812519079, 0.39676562017519423, 0.15307955374613025, 0.19545595020100348, 0.08910570997805045, 0.3442972785740517, 0.12261915216394792, 0.20865154730633317, 0.5183909088306968, 0.18336262355037403, 0.2761086647472939, 0.12491070302203822, 0.18192683771015172, 0.12951070943411358, 0.21414306115547566, 0.23530057005203975, 0.12683019449368949, 0.3939169506414091, 0.12164904092166706, 0.010618496940164368, 0.07982340814987787, 0.11478733565417099, 0.010674600409438462, 0.05650979367141884, 0.008536053662827503, 0.056061281236991056, 0.27357335694925367, 0.10098617891152895, 0.05136240217603372, 0.24772620838893622, 0.21452710829591115, 0.23891098027036028, 0.062151136109617644, 0.07049244275743949, 0.1652385814328563, 0.3086929117380597, 0.1144570037497682, 0.0321014132756704, 0.06570233690701954, 0.04109659293269574, 0.05294284056005871, 0.12836485694558863, 0.06147322474673256, 0.07372185479311011, 0.0721943514090575, 0.20237720771305934, 0.11967881844660166, 0.13468225203301953, 0.11196587212677589, 0.10947901761513434, 0.13626482569945442, 0.20262153474242994, 0.12253227439872116, 0.13098682511255577, 0.07809298504316298, 0.5149967883834852, 0.5177662724543655, 0.6353642780995419, 0.5238560476291032, 0.6289250620540232, 0.5868691032818868, 0.4962992210711784, 0.5787132874505603, 0.6330511858607819, 0.1288075750085924, 0.09730687746868849, 0.11678207405350882, 0.11502151086081236, 0.1245313364020294, 0.1180908802229449, 0.13790787624003586, 0.12666755212795233, 0.13432727494093888, 0.23815288662876777, 0.23988847277515823, 0.2176697771977153, 0.25787000209635036, 0.397704775496738, 0.2476983703273279, 0.21595678553130648, 0.21833047397522998, 0.15469014904876077, 0.3584433216436895, 0.3138175417536969, 0.4112441563397764, 0.3370524870844912, 0.3326514874690556, 0.27538362245915227, 0.3367703630277624, 0.4508760518136353, 0.39833337417827275, 0.2699795110567743, 0.23008184318438074, 0.33496344442637993, 0.32879593667552454, 0.3079815059327964, 0.3616910331781926, 0.32503480631240533, 0.29108308668757576, 0.2778950926220157, 0.27827942932932515, 0.17589864980624148, 0.19995021319630957, 0.21247525507996223, 0.22910225059333666, 0.23709490485440188, 0.22053123690238763, 0.19447679658331396, 0.23588060010692025, 0.17784129635979973, 0.24173929223218804, 0.2122134969338919, 0.2225681657847326, 0.18513457469252204, 0.1954389909807206, 0.18942840588285703, 0.21203621090871128, 0.19689319208063571, 0.7908029956878249, 0.17708246215649748, 0.1981707205697929, 0.7201413924752096, 0.1989126875528, 0.19824969385098112, 0.1418757434453477, 0.8027639839011396, 0.83768502184625, 0.7944131110288711, 0.20839853666125696, 0.7125247260467988, 0.7740969857097957, 0.6569960160042452, 0.1542706831439482, 0.10371228659222964, 0.20626994080537886, 0.775977526589956, 0.2068224414636698, 0.19281337225383555, 0.19156319132734645, 0.19483284405928736, 0.18266662258093325, 0.1966484273384541, 0.21374241423382068, 0.1962163736132273, 0.17707001197327588, 0.07980279003600677, 0.09033731367966702, 0.08616220133712671, 0.0867665360024994, 0.08910706716345596, 0.07328395403489862, 0.09960424871170903, 0.09625193477654281, 0.09031339116839132]}, "mutation_prompt": null}
{"id": "5e66e78e-cc78-468f-b4f9-719f2db24ebb", "solution": "import numpy as np\n\nclass AdvancedHybridPSODERefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))  # Adjusted population size for balance\n        self.w = 0.5 + 0.2 * np.random.rand()  # Increased variation in inertia weight\n        self.c1 = 1.4 + 0.1 * np.random.rand()  # Slightly decreased cognitive coefficient\n        self.c2 = 1.6 + 0.1 * np.random.rand()  # Increased variation in social coefficient\n        self.F = 0.6 + 0.3 * np.random.rand()  # More adaptive mutation factor\n        self.CR = 0.5 + 0.3 * np.random.rand()  # Adjusted crossover rate\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'mix'])\n\n        while self.evaluations < self.budget:\n            # Evaluate current population\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            # Update velocities and positions (PSO)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            # Dynamic adjustment strategy\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c1 + 0.05)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c2 + 0.05)\n            elif learning_strategy == 'mix':\n                self.c1, self.c2 = (self.c1 + self.c2) / 2, (self.c1 + self.c2) / 2\n\n            # Apply Differential Evolution mutation with adaptive mutation strategy\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + (self.F + np.random.uniform(-0.1, 0.1)) * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "AdvancedHybridPSODERefinedV2", "description": "A refined hybrid algorithm blending Particle Swarm Optimization, Differential Evolution, and adaptive dynamic strategies for improved global search efficiency.", "configspace": "", "generation": 24, "fitness": 0.2592353367366043, "feedback": "The algorithm AdvancedHybridPSODERefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.22.", "error": "", "parent_id": "a43be774-a147-4cdd-8d7b-92c0d34803f1", "metadata": {"aucs": [0.49816332285457143, 0.5725280958338095, 0.6416531446750882, 0.49977218664252765, 0.623520446392074, 0.5851233121435124, 0.5639285920607413, 0.6365593584592584, 0.5805758526192226, 0.05917027494309712, 0.15082670703327672, 0.10137888445867571, 0.06909214190198432, 0.17522293094893115, 0.24731312370568148, 0.15272515923917984, 0.21241709916858387, 0.18622279587440016, 0.10961442579050051, 0.10028817826307346, 0.11236194510789732, 0.12263925396183417, 0.12186553252864818, 0.12580628476000189, 0.19250726907835902, 0.14226777456887052, 0.14492190570866492, 0.11233928732116716, 0.1279504292255328, 0.11978149731878496, 0.12001442909689686, 0.11016879567155125, 0.10084924812979612, 0.11137144899986173, 0.13484378507613926, 0.1307585793447743, 0.9720156696959752, 0.9404089677641885, 0.9816915069547938, 0.9791779629548337, 0.981289629142435, 0.9718962738219484, 0.9731786046440202, 0.9847300130843455, 0.9736672093522497, 0.3159996418485357, 0.40345517672631115, 0.31210066353635435, 0.35829580299947106, 0.3776224064628836, 0.3976261542490812, 0.21632650945976706, 0.08585084864247838, 0.3460518995511771, 0.6226083539806817, 0.2248829936974437, 0.5719963911885626, 0.19043313923617522, 0.6700196300826335, 0.1875245647843896, 0.5506835863868483, 0.14953165158038995, 0.6257507436060987, 0.1896759137946632, 0.09434377583415476, 0.15185581549479832, 0.14735897729991887, 0.11976044048553536, 0.21661352587700566, 0.11957771228396086, 0.14670789272090956, 0.264908113354941, 0.17534740837650575, 0.31745675464718737, 0.1093380980960772, 0.18543459318473, 0.19991146748178334, 0.11937891839942061, 0.11433035994614094, 0.1541295592167935, 0.16489539071510628, 0.05343113389598242, 0.0547500415330926, 0.14471448783392238, 0.003774516591774968, 0.08612154388766557, 0.016025285179779525, 0.026945799608712906, 0.15299467613348916, 0.001992752946920917, 0.11391778077408632, 0.12253381070253311, 0.20195604808866274, 0.03654130508073228, 0.22998302546680793, 0.036474653525868095, 0.1440176064614891, 0.05820651690153722, 0.20227540995256366, 0.024189752244806573, 9.999999999998899e-05, 0.0930520624078468, 0.10108153617263582, 0.13883291785074892, 0.04658871327380443, 0.04765542580058013, 0.05483199999629318, 0.06282173899952614, 0.09204614549420476, 0.1720106751141408, 0.19309278181409595, 0.16556927247706021, 0.15697316438267284, 0.07569832799214837, 0.04673037638608879, 0.04558395286654593, 0.06650469065505027, 0.45780552654909756, 0.4956887322430388, 0.5134563330589286, 0.4512405056275476, 0.457178466981943, 0.47079251102188857, 0.46565382584387505, 0.4884011004126383, 0.5153870819619211, 0.08817660996417231, 0.1135647946087216, 0.09957160651583397, 0.1479519442980649, 0.10438586567122021, 0.1303605252145471, 0.09968745608675067, 0.120818716890563, 0.08042241405003259, 0.19460412740951494, 0.13936579108160696, 0.20091697541371611, 0.2994365947496205, 0.30031132999008925, 0.23270822614394948, 0.23693475692569177, 0.22933883051140636, 0.33748903718524426, 0.32136260441114006, 0.35144209008348015, 0.3539328373806103, 0.32096451119366143, 0.3115737079046851, 0.300269083542701, 0.3072355593939763, 0.3142755803563998, 0.3393098805032493, 0.23033617868125822, 0.20542069257695128, 0.26579114133104687, 0.2079149419400903, 0.2229484657114852, 0.24883441144837992, 0.22901443442465153, 0.29241600448515503, 0.284151914923916, 0.2272466290885431, 0.18290580167586235, 0.18498718461942354, 0.2041799038435309, 0.24335243869834644, 0.2314997648982915, 0.17815605526258682, 0.2360137400112885, 0.2038876520335754, 0.21193061210234287, 0.18930955019886075, 0.19816704822036668, 0.1982033355816296, 0.23105424892968152, 0.23909716208429788, 0.1968925502558585, 0.20271544103200478, 0.3388760255498693, 0.1629546012607218, 0.18636367833540313, 0.16576661554266536, 0.691917288915566, 0.19859511100722582, 0.19848535277602886, 0.1409939435052351, 0.16201236007840958, 0.7620599349166172, 0.6916121253243814, 0.20632525703834892, 0.6157941415496353, 0.62947280414803, 0.6323111047864935, 0.15216139560636455, 0.10271001508416389, 0.10436971828923414, 0.664778683342022, 0.17732413847360873, 0.24465946184049148, 0.21578071674669186, 0.21782240114831863, 0.1961022114137756, 0.17662860916333523, 0.20120474418382095, 0.18390045104005548, 0.2101065740191813, 0.08575331454431323, 0.09683709813544139, 0.07819771283939259, 0.07865332688047888, 0.0865810925290823, 0.09534711096482718, 0.08106894440389101, 0.08657304630636609, 0.11388463813153882]}, "mutation_prompt": null}
{"id": "be28ca39-fe57-4375-802c-40f54c423e23", "solution": "import numpy as np\n\nclass AdvancedHybridPSODERefined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // (dim * 4))\n        self.w = 0.4 + 0.3 * np.random.rand()  # Increased variability in inertia weight\n        self.c1 = 1.7 + 0.1 * np.random.rand()  # Slightly increased cognitive coefficient\n        self.c2 = 1.4 + 0.1 * np.random.rand()  # Slightly decreased social coefficient\n        self.F = 0.5 + 0.25 * np.random.rand()  # Even more adaptive mutation factor\n        self.CR = 0.5 + 0.4 * np.random.rand()  # Wider range for adaptive crossover rate\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'adaptive_w_adjust'])\n        \n        while self.evaluations < self.budget:\n            # Evaluate current population\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            # Update velocities and positions (PSO)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            # Dynamic adjustment strategy\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.4, self.c1 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c1 + 0.05)\n            elif learning_strategy == 'adaptive_w_adjust':\n                self.w = 0.5 + 0.3 * np.random.rand() if self.global_best_score < np.median(self.personal_best_scores) else 0.4 + 0.3 * np.random.rand()\n\n            # Apply Differential Evolution mutation with stochastic perturbations\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + (self.F + np.random.uniform(-0.15, 0.15)) * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "AdvancedHybridPSODERefined", "description": "A refined hybrid algorithm blending Particle Swarm Optimization, Differential Evolution, and dynamic learning with stochastic perturbations for improved exploration-exploitation balance.", "configspace": "", "generation": 25, "fitness": 0.26229527083551224, "feedback": "The algorithm AdvancedHybridPSODERefined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.22.", "error": "", "parent_id": "a43be774-a147-4cdd-8d7b-92c0d34803f1", "metadata": {"aucs": [0.689274283162518, 0.5877711981176164, 0.6068898893588213, 0.6706581241531251, 0.5667416699040724, 0.5431993714079537, 0.7028256021210975, 0.5220274570164052, 0.5798068069217696, 0.23119613050274856, 0.17762092958189546, 0.12943120715308232, 0.07674914363823371, 0.04241415590289799, 0.1394188034202274, 0.035029009448149684, 0.15018420285159628, 0.1950492251199929, 0.09392856268143446, 0.09812294140231748, 0.11755507933554632, 0.12241153952185924, 0.1272647882607425, 0.10417314520570775, 0.09164942941725152, 0.1286779028410645, 0.1258908238753409, 0.12811480512654394, 0.09893659098656404, 0.10797822146594493, 0.09153393631018403, 0.09320785139824495, 0.09602210797429944, 0.13249116200702282, 0.1205091920224991, 0.12073045095020918, 0.9756224575555809, 0.9754619584767882, 0.985569000724412, 0.9583499715851712, 0.9739886494614238, 0.968326838882648, 0.9686105752348082, 0.968448397204389, 0.9760862764070715, 0.48348381289790365, 0.3014410731440711, 0.2759435084076356, 0.4884852549304829, 0.3283736121202805, 0.30431077934850737, 0.5586985407397267, 0.3613571178317493, 0.2593761278768434, 0.4414626389275925, 0.5911736197652102, 0.5660068987026468, 0.21395126700463862, 0.2308032045549655, 0.20238686655202387, 0.7497395066869865, 0.14756621890822186, 0.5654531564024379, 0.4148573187974569, 0.1567659069518218, 0.14252280022820596, 0.09534955904550357, 0.2414874976149567, 0.15922840284723228, 0.12447355649091574, 0.28866672897504864, 0.15362114279058825, 0.29856844405120453, 0.17352950506244436, 0.18659884467499976, 0.28455856913457345, 0.2286703215939141, 0.2446826980045873, 0.3123862943886646, 0.14156076661937533, 0.13570257570243283, 0.03508580012691165, 0.034469976274973724, 0.03400855606412967, 0.0005108260176495127, 9.999999999998899e-05, 0.00806950286766317, 0.08226019108530158, 0.02051081941716859, 0.11146991523368888, 0.15522477319985428, 0.12894412495876328, 0.15871048847093316, 0.057187406065145496, 0.0056255284972616115, 0.06534457530891746, 0.22970170226346354, 0.15027828303375224, 0.06100766689092019, 0.029153990125556306, 0.021837825432522218, 0.06781070597932193, 0.05612453860473254, 0.04446528462327082, 0.024842359037008488, 0.07769941131107005, 0.050310118607201026, 0.07870237395332313, 0.1919136379294304, 0.08129447422762259, 0.17212754555737197, 0.16037639348536137, 0.1422763188119054, 0.10648103955723542, 0.2876001087542862, 0.14193690389009028, 0.06804445697936967, 0.5601836531549171, 0.45550643859802864, 0.4146694123359539, 0.4925768606098465, 0.41391101953374876, 0.4399148558880692, 0.4979285409960412, 0.4733481123041211, 0.44139765096451666, 0.13104065741330906, 0.08595166185917857, 0.0929323329481071, 0.08998888369545877, 0.14070214609356624, 0.10794645458670327, 0.14097011663622905, 0.16910829700493468, 0.14456917855715856, 0.19233790372332127, 0.16727026587590899, 0.21177334968384953, 0.19369518900543392, 0.4140587727825701, 0.24234292359265974, 0.24099582321225876, 0.14993539886853502, 0.189654674082521, 0.44102922924021193, 0.3250000147163792, 0.3780031388202788, 0.3475917710181968, 0.2817949337664215, 0.3189108909578803, 0.30448881914408754, 0.272085828960243, 0.3384479395934016, 0.2740952389756036, 0.20887393424702516, 0.25963974898926667, 0.27881206753727983, 0.24470453453961116, 0.29819781930450795, 0.2459222058859546, 0.23587273459278557, 0.21261573065462658, 0.22736092426432009, 0.19794519537964472, 0.23771065198043118, 0.23028342675554725, 0.1977324713376497, 0.2049987107812603, 0.23986800804109998, 0.18517487939563182, 0.20156913528420017, 0.2396273289233376, 0.20347339198120717, 0.19117422558574448, 0.20770042929521892, 0.18747521671710987, 0.19053140090513465, 0.1949024263798489, 0.19190280234756196, 0.18678949519558086, 0.8320715773246311, 0.17053992062040946, 0.16747436670346927, 0.8146816764664243, 0.19599126775238285, 0.1991023503978986, 0.14184907138319158, 0.16577082279366318, 0.7231208208814472, 0.762348118645999, 0.2067164894170742, 0.19398453688947515, 0.20663340704006883, 0.5108084250984689, 0.14976940055172616, 0.20912440009817856, 0.20889644601359592, 0.5237842840657756, 0.18852333920446185, 0.19437106859654874, 0.17488366344864303, 0.23933243157599537, 0.18616009525050137, 0.20153116849861707, 0.1837411379834777, 0.18971574287755266, 0.19451229324451347, 0.08829962509297207, 0.08765652184812867, 0.08077454679647433, 0.1075603120202906, 0.10135311467507924, 0.083377599390549, 0.13202955876009004, 0.08517158363458677, 0.08639841341074406]}, "mutation_prompt": null}
{"id": "6de16359-48dd-4482-91bb-d74ed43ebf45", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))  # Adjusted for increased exploration\n        self.w = 0.4 + 0.3 * np.random.rand()  # Increased range for inertia weight\n        self.c1 = 1.4 + 0.15 * np.random.rand()  # More adaptive cognitive coefficient\n        self.c2 = 1.6 + 0.15 * np.random.rand()  # More adaptive social coefficient\n        self.F = 0.6 + 0.25 * np.random.rand()  # Adaptive mutation factor with increased range\n        self.CR = 0.5 + 0.4 * np.random.rand()  # Increased crossover rate range\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust'])\n        \n        while self.evaluations < self.budget:\n            # Evaluate current population\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            # Update velocities and positions (PSO)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            # Dynamic adjustment strategy\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.3, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.3, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.2, self.w - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.w + 0.05)\n\n            # Apply Differential Evolution mutation with adaptive mutation strategy\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + (self.F + np.random.uniform(-0.1, 0.1)) * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSODE", "description": "An adaptive hybrid algorithm integrating enhanced Particle Swarm Optimization, Differential Evolution, and stochastic learning strategies for optimal balance between exploration and exploitation.", "configspace": "", "generation": 26, "fitness": 0.3314184594446668, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.27.", "error": "", "parent_id": "a43be774-a147-4cdd-8d7b-92c0d34803f1", "metadata": {"aucs": [0.8219681162464489, 0.8365414828388387, 0.8171096371719522, 0.8330597812789174, 0.8319081305240762, 0.8401394694651152, 0.8363323693845419, 0.818011422981909, 0.8443490901512088, 0.5569671591267868, 0.6618768046725072, 0.6100274753006161, 0.6238392478721059, 0.629537095551006, 0.6470604084647275, 0.63419981177373, 0.6354546598773055, 0.6296320233147632, 0.12771722856073087, 0.089054526128171, 0.13294980380441102, 0.13105589988078192, 0.12539312249864176, 0.14918125029096974, 0.12490735847619439, 0.1296069074463172, 0.14987404365986656, 0.09363567684981977, 0.0971999258309525, 0.1008420669746729, 0.11947738968350585, 0.11974226469348637, 0.10432294314190071, 0.10513967467547103, 0.14169287393380015, 0.14821154051575447, 0.9721816938888576, 0.9501584463166606, 0.9825081068667245, 0.9792399681092324, 0.9813102592503796, 0.9719068907588194, 0.9732455972671211, 0.9847270345436789, 0.973539101094716, 0.6508095614066157, 0.6572297362704798, 0.519437146734465, 0.6385075839559085, 0.5416584698040068, 0.6724592279093431, 0.6267398208387805, 0.5924141718204043, 0.6557574119830021, 0.31603960541439824, 0.5664401203309742, 0.22189528144277093, 0.21470352747241772, 0.7781670993890415, 0.2796091186063572, 0.22790882863643702, 0.330412288968863, 0.8871522403011004, 0.43884816529143345, 0.1516127134611821, 0.24369110085027224, 0.09593390718316097, 0.12395045800670412, 0.12172345165334919, 0.5902523885776723, 0.19804892768494553, 0.38889047197919757, 0.294473773200838, 0.6332915999697615, 0.11839075597282556, 0.35572627712307625, 0.3252152984990133, 0.3349128835289388, 0.2753138940451264, 0.30930408324168, 0.2156673791642154, 0.01100726464855939, 0.005445656306237501, 0.030833077714007007, 0.038230551247215194, 0.00841896247611762, 9.999999999998899e-05, 0.07265795458101343, 0.16083430439368473, 0.08968353550270658, 0.33532748336402995, 0.11163951547430606, 0.10372775189544026, 0.07379403666798079, 0.17567173334046615, 0.12433557452440125, 0.15415430662074525, 0.10588169619047294, 0.16020981141699853, 0.20606631966813505, 0.03578404268621249, 0.288437218360982, 0.11346896708907184, 0.15345960812804837, 0.09112617717480265, 0.09309609371967997, 0.09291719765083817, 0.10298702331231124, 0.2782520747479378, 0.12614455733495344, 0.22612272891362617, 0.2006768711616903, 0.11614820451756436, 0.2411300643285592, 0.09136897504571628, 0.11118871233730643, 0.13658905963400703, 0.5987308124244533, 0.6902057689732586, 0.5418304780707641, 0.6666420264375108, 0.5767147078161634, 0.569050362111643, 0.677907047876021, 0.7096916379361653, 0.6617964203772673, 0.11980017194697279, 0.07081951674164577, 0.08177062973163807, 0.12428081958773907, 0.13878950809833646, 0.1399987921952427, 0.1534836539410791, 0.10800496099198731, 0.11681376953022793, 0.31968379163114047, 0.2859462701674086, 0.1705314563578495, 0.20881249840709915, 0.3038295788437584, 0.1645746757414841, 0.1997000525839323, 0.4704894935234504, 0.22008101677017866, 0.481573721725868, 0.3671880641490831, 0.38168584993459875, 0.35786353115083047, 0.2870727231054806, 0.24390652003127122, 0.5122714705208022, 0.49841562571970777, 0.3560490867047571, 0.21494074222261106, 0.21208378218094026, 0.21658305527348798, 0.17468655203623984, 0.17769021125578477, 0.32692187337302026, 0.19531164246162114, 0.262530230467629, 0.21714568331943274, 0.2485406167655232, 0.24817529953548934, 0.21605156874077225, 0.22672516808766519, 0.2089851531892294, 0.2086024128480365, 0.19900521785138203, 0.26306841758037103, 0.22894511554514652, 0.21082200686019814, 0.18235275566508746, 0.24051330888236822, 0.2037714479354572, 0.1984299434798239, 0.17262639573266936, 0.1911818449678062, 0.22044164951331147, 0.18378589767087228, 0.8599082350727898, 0.187394781874188, 0.16654488624606145, 0.8990540399676188, 0.1996217586142669, 0.1995848431635775, 0.14227251745422032, 0.16205242613175197, 0.8828932478487983, 0.8745697395635168, 0.2095913013164793, 0.20704865236541858, 0.20850559982184524, 0.6473471073381685, 0.1640250035853913, 0.20536476334546339, 0.10464396112908703, 0.8840443362439413, 0.23475088769889385, 0.19538896271415074, 0.25167092449990747, 0.2121559916310457, 0.1984621332373524, 0.19191166351854694, 0.22044993960587778, 0.19597359320347785, 0.20706956411343536, 0.1098835210650172, 0.10435109253932584, 0.1025567731460949, 0.08317648321140225, 0.11193690621382468, 0.10459781608441632, 0.09247052246851051, 0.11421975986103805, 0.0986273348215494]}, "mutation_prompt": null}
{"id": "1bab49b8-d53d-41ab-8d6c-b85454ec6f8d", "solution": "import numpy as np\n\nclass RefinedEnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.4 + 0.3 * np.random.rand()\n        self.c1 = 1.4 + 0.15 * np.random.rand()\n        self.c2 = 1.6 + 0.15 * np.random.rand()\n        self.F = 0.6 + 0.25 * np.random.rand()\n        self.CR = 0.5 + 0.4 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.3, self.c1 - 0.08) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c1 + 0.12)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.3, self.c2 - 0.08) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c2 + 0.12)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.2, self.w - 0.04) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.w + 0.06)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + (self.F + np.random.uniform(-0.1, 0.1)) * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "RefinedEnhancedHybridPSODE", "description": "A refined adaptive hybrid algorithm integrating PSO, DE, and stochastic learning with enhanced dynamic adjustment for robust exploration-exploitation balance.", "configspace": "", "generation": 27, "fitness": 0.32570011679603705, "feedback": "The algorithm RefinedEnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.26.", "error": "", "parent_id": "6de16359-48dd-4482-91bb-d74ed43ebf45", "metadata": {"aucs": [0.8339771994057301, 0.8272690176547162, 0.8252268827267131, 0.8167916584397362, 0.8194180017485553, 0.8393926192141985, 0.8396729362646026, 0.8288799826204429, 0.8371823185997218, 0.558445645826428, 0.6296472047355861, 0.6672891218893311, 0.5432515848966182, 0.5132197318452665, 0.6293615553224164, 0.6103764685267867, 0.6378934707635175, 0.5885609894554316, 0.11632156949665984, 0.1340944044781558, 0.10318340226402889, 0.13938399188986383, 0.1234992516721688, 0.10990684156621267, 0.17142005917286607, 0.17705795825814474, 0.17317883457607763, 0.16458817693446293, 0.13331200990869452, 0.10277949816346521, 0.13721635865311688, 0.1377108129012895, 0.12392362724753914, 0.13299865294532554, 0.10747947984179973, 0.11098853682130427, 0.9722548772589197, 0.9494936141109546, 0.9825070362205865, 0.9792369062032993, 0.9813073180180876, 0.9719046133396448, 0.9732640588283668, 0.9847270345436789, 0.9736197097300892, 0.6611205750292124, 0.6269392345695863, 0.4981481650562656, 0.14843456409880817, 0.5766523408860738, 0.6117063616603274, 0.49260012278353116, 0.17548041617521415, 0.5936414169016494, 0.2236613399075007, 0.8890034632173035, 0.36396286281102697, 0.20176324570649518, 0.6689647460361696, 0.8396576291445887, 0.22388751007588825, 0.2388276529340032, 0.733023218880328, 0.3571324698348797, 0.11950416871523362, 0.2802356491116963, 0.10979298194397447, 0.2505337973057974, 0.12673423243718485, 0.40734646589410306, 0.15668043073837412, 0.29116877017873055, 0.3122892353621721, 0.5073953368518913, 0.23932034737873542, 0.4420085833905012, 0.15917829131077366, 0.4341328446532593, 0.1256838828149559, 0.36627399343916756, 0.6045811800300489, 0.09780166769830922, 9.999999999998899e-05, 0.0990537379368488, 0.0005575123472328913, 0.02084230106544349, 0.019241451322402625, 0.11216148823958194, 0.031518204329389454, 0.08949356037017009, 0.1334657957307407, 0.10062407943037943, 0.27442194057265157, 0.050246115031830074, 0.15146046854603668, 0.2083149490152144, 0.16579787503128407, 0.13745124720477764, 0.11835310540776445, 0.1543976826815513, 0.03451589978783631, 0.4680359019172087, 0.13699772813298694, 0.1601712188585538, 0.14445228663102205, 0.09242811874679469, 0.09385266824784444, 0.12009069428329167, 0.15193041673559415, 0.1874736263986646, 0.16915090193648175, 0.22747550272300643, 0.16011800169290036, 0.20126920642731794, 0.046146287705004174, 0.14078585749817174, 0.10888634161112876, 0.5634590528589662, 0.7010614592819626, 0.6768413933171813, 0.6886895136912061, 0.6219576932730823, 0.20822500868742522, 0.6327338756859591, 0.6398457529737647, 0.6239807704625311, 0.12254123174321407, 0.10018597963552545, 0.10603703541870169, 0.1269446613151347, 0.11046231875769574, 0.11266635617952492, 0.11616612873185317, 0.11231669155487511, 0.1365113471181325, 0.24630038053833125, 0.2082110796358747, 0.21450031246511791, 0.3402939994778479, 0.2524565373924075, 0.1855577210537671, 0.26111439401445957, 0.23019278042071067, 0.18501621762239773, 0.234122642166382, 0.25726252925491466, 0.39566296773018916, 0.332897554351124, 0.3033883620225488, 0.2637817423521307, 0.3037382549752722, 0.4933158659632675, 0.4184784514302049, 0.3688423730589909, 0.19171007593697575, 0.28061158217369764, 0.2565458122274473, 0.1995941640471367, 0.2573349544380136, 0.3545951948925704, 0.2849641066541799, 0.19435316246970835, 0.21476449629671268, 0.25697788602030947, 0.2236562770379883, 0.23471535974772795, 0.21377527595653678, 0.23385432642673343, 0.23357778222102765, 0.23294516502272444, 0.23689510415693538, 0.1869378646383809, 0.20450665724391914, 0.20779740839836602, 0.2180533484041074, 0.22666790408698212, 0.19314062257737563, 0.19583353205316578, 0.20353970369922547, 0.19638794498407908, 0.8076359070460282, 0.18725783602883617, 0.16674610794315536, 0.8932125359198428, 0.19969930714773054, 0.19925252309059305, 0.14233381415472846, 0.16237641937174718, 0.8853515281096243, 0.8547280209392621, 0.20917515929374586, 0.20704854998418443, 0.20792302114494388, 0.6993447613909534, 0.16594350012715364, 0.2061854155152406, 0.10461485754159183, 0.8391906457313714, 0.17905136870695837, 0.18789762901849494, 0.19137327943641236, 0.18337952526475298, 0.18980942730981942, 0.2163218377084175, 0.20149825565498702, 0.2503148370398247, 0.2592359507555638, 0.0890940714416627, 0.09628441061009885, 0.09940066006217729, 0.09689157149725747, 0.09732031796497942, 0.09949655168437743, 0.09191123509857335, 0.08793831053887369, 0.08672353570385838]}, "mutation_prompt": null}
{"id": "92d9ad42-a2b0-4388-98ac-d0ed9d70c20b", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.5 + 0.2 * np.random.rand()  # Adjusted inertia weight range\n        self.c1 = 1.5 + 0.1 * np.random.rand()  # Slightly refined cognitive coefficient\n        self.c2 = 1.7 + 0.1 * np.random.rand()  # Slightly refined social coefficient\n        self.F = 0.7 + 0.2 * np.random.rand()  # Refined mutation factor\n        self.CR = 0.6 + 0.3 * np.random.rand()  # Adjusted crossover rate range\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.3, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.3, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.2, self.w - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.w + 0.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + (self.F + np.random.uniform(-0.1, 0.1)) * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSODE", "description": "A multi-strategy optimizationalgorithm with dynamic adaptive learning and boundary-aware mechanisms for enhanced exploration and exploitation.", "configspace": "", "generation": 28, "fitness": 0.3228174414599803, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.26.", "error": "", "parent_id": "6de16359-48dd-4482-91bb-d74ed43ebf45", "metadata": {"aucs": [0.8250179999803173, 0.8013897750950665, 0.8098570814755026, 0.8143359906339163, 0.8045659616663308, 0.8405302412697783, 0.820390486062912, 0.8200997793401298, 0.7985892921216788, 0.5935041987641533, 0.6253010526715859, 0.5690981964277806, 0.6606507769924749, 0.6022873412588263, 0.6235732600471554, 0.5539551181895483, 0.6777735703575287, 0.6285588583990263, 0.13603086891979188, 0.1625063677286318, 0.11062709487511035, 0.10437297949973712, 0.10175005987247043, 0.10167297823993304, 0.10633008347903483, 0.14439035694380853, 0.13734968560342298, 0.08595531669718603, 0.0902779046099147, 0.07866428647277168, 0.10481681028238676, 0.09092759251805616, 0.07768650071414818, 0.10734708976405416, 0.1302546282028677, 0.09610247907884584, 0.9791775063527357, 0.9703150847975478, 0.9828711257490579, 0.9788449953809237, 0.9814322465275865, 0.9719995793716806, 0.9792098863491381, 0.984739766145111, 0.9790548307826891, 0.5759691263583117, 0.5972925544971576, 0.5751886890517254, 0.31138238043849975, 0.5509059412693524, 0.6102950627356776, 0.12187926061268539, 0.5965838182562375, 0.6241583521006204, 0.22466011000241237, 0.8701072844844026, 0.7581687824584328, 0.19048533812062185, 0.20588391588535615, 0.2079516655561241, 0.21226832958347686, 0.22913193032019985, 0.22635148889105683, 0.12496437470304589, 0.1654502088677947, 0.361222296456417, 0.11812125982474042, 0.12190713053924906, 0.12381859196190903, 0.259149240971686, 0.418789110780881, 0.30634440040370015, 0.508208433591625, 0.6868878134330677, 0.23633782842030127, 0.5365946355056859, 0.4782134156477248, 0.34478331632153636, 0.3615560986231986, 0.42739008157976766, 0.11852854571024041, 0.05744485128371457, 0.08974398164019115, 0.21128216406674094, 0.05281383257605232, 9.999999999998899e-05, 9.999999999998899e-05, 0.07898399612248197, 0.05191004316869474, 0.008742726605046158, 0.3314120123815938, 0.20256531178732573, 0.3196875909263336, 0.13523036042043624, 0.2085075908063453, 0.1448624904561715, 0.1466660321281903, 0.527035428096388, 0.07644233869746753, 0.17224399836151383, 0.0404321603594181, 0.2302855697996289, 0.11197341319800613, 0.2785757304388542, 0.09760830577816382, 0.16852503752306225, 0.09137719063752725, 0.14528903463933251, 0.3715896361582145, 0.18148399706927132, 0.11026880960384133, 0.22546510359202343, 0.1302861768907997, 0.16659992862169803, 0.04747587409556131, 0.05366294217390111, 0.10820518681705793, 0.5590929733229069, 0.598016634807053, 0.6709696519889937, 0.713450750550569, 0.6331135787825646, 0.5592425949794637, 0.5646047416222056, 0.6261901753240271, 0.6056162098342865, 0.0776734737514414, 0.05887930523043816, 0.11417518679876193, 0.09238064421193593, 0.1329069257802279, 0.10665967958380662, 0.07922276805574946, 0.1255577430726198, 0.14818247494722925, 0.25261459053709, 0.20119664638087253, 0.17778224454488156, 0.1733134923973233, 0.20245950135486623, 0.2716515195435989, 0.2592393109423804, 0.2163092728571191, 0.19464968385594006, 0.30012054748680506, 0.24100491341664243, 0.2999798290799932, 0.3744474539744169, 0.4517401901801671, 0.36740713690623406, 0.2721905274873312, 0.5004619787503912, 0.4242982518052103, 0.2133158010342251, 0.1912595762551188, 0.26932131655952674, 0.34147035017331295, 0.34551879053087364, 0.2579787992745328, 0.3100676867376415, 0.4275097338115733, 0.20285551563533832, 0.24753966603747235, 0.2143400560000076, 0.18531486341781633, 0.26737575601190344, 0.24384262842740756, 0.2136022505694235, 0.204765639155283, 0.24039080267500568, 0.23207370397024807, 0.18662718040216075, 0.21675832165524, 0.20001811551716786, 0.19257867235894088, 0.20954754431422795, 0.2501870316360463, 0.2080027894650478, 0.19829131536885625, 0.17403565235229967, 0.16357712687105974, 0.18732784179600692, 0.16562451070173867, 0.871186432534423, 0.19873040661000396, 0.19860509892306133, 0.14217027594767073, 0.15978535019739082, 0.8539276218815312, 0.8439432492026884, 0.20944311424527318, 0.19945261997736674, 0.20601801915013507, 0.7230955577630518, 0.15090480352008162, 0.20952512096212006, 0.20655442414971958, 0.8137412913072921, 0.1921891989064013, 0.2127092807958635, 0.1998620552408995, 0.21297391143624234, 0.2052781674341465, 0.22079293819676138, 0.2047660424968606, 0.2046822358004735, 0.2296995039067814, 0.0981046656347706, 0.09396031635442781, 0.07423957121310742, 0.1333789959070042, 0.07327337959406865, 0.08213425712018929, 0.08992785369628742, 0.11115513709766056, 0.08843806869261917]}, "mutation_prompt": null}
{"id": "9f1ae52c-ce10-400e-b083-382c63ab0dda", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.5 + 0.25 * np.random.rand()\n        self.c1 = 1.5 + 0.1 * np.random.rand()\n        self.c2 = 1.7 + 0.1 * np.random.rand()\n        self.F = 0.7 + 0.2 * np.random.rand()\n        self.CR = 0.5 + 0.3 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            # Evaluate current population\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            # Update velocities and positions (PSO)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            # Dynamic adjustment strategy\n            strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust'])\n            if strategy == 'c1_adjust':\n                self.c1 = max(0.4, self.c1 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c1 + 0.05)\n            elif strategy == 'c2_adjust':\n                self.c2 = max(0.4, self.c2 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c2 + 0.05)\n            elif strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.8, self.w + 0.05)\n\n            # Apply Differential Evolution mutation with adaptive mutation strategy\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + (self.F + np.random.uniform(-0.1, 0.1)) * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedAdaptiveHybridPSODE", "description": "An enhanced adaptive hybrid combining PSO, DE, and dynamic strategy selection to optimize exploration and exploitation balance effectively.", "configspace": "", "generation": 29, "fitness": 0.3030626063140604, "feedback": "The algorithm EnhancedAdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.26.", "error": "", "parent_id": "6de16359-48dd-4482-91bb-d74ed43ebf45", "metadata": {"aucs": [0.7758648127332586, 0.8031733281865794, 0.8067422332322081, 0.7825600789645373, 0.7966528101077084, 0.8035244480856756, 0.791170525613877, 0.7921811993139553, 0.7880030563673096, 0.036112314455482686, 0.5772052172699971, 9.999999999998899e-05, 0.5306057730888749, 0.5302696355580392, 0.5408935187757917, 0.043342012587259116, 0.5350069846905937, 0.5587729238714395, 0.09518732490293547, 0.08705312621670969, 0.17328792610466603, 0.10521769316586338, 0.16326948471442193, 0.11706641113078109, 0.12765496658623832, 0.13941819583238446, 0.16278931100900096, 0.09694184942096928, 0.13035654641997518, 0.10488878715730243, 0.11643737273687838, 0.088197396365995, 0.10707267383074681, 0.1267412700014876, 0.12331245781777089, 0.10472583727156448, 0.9797967380682477, 0.9728928081203825, 0.9838342949523423, 0.9295555923172871, 0.9783610246446761, 0.9720514388465482, 0.9834173977101633, 0.9834910209760656, 0.9831033603252752, 0.6561123772430241, 0.5382574176287376, 0.5935219603018491, 0.14742539185269865, 0.6131703193723337, 0.5980207937772221, 0.08465025844411533, 0.24107299060012488, 0.5787342917211127, 0.814684677553488, 0.22562350300972545, 0.8140329952872118, 0.19159980458551595, 0.269637718642018, 0.19120483806564237, 0.7858642830992294, 0.8224415106078233, 0.7655442217970334, 0.27219767446766274, 0.1312993185755369, 0.1700592104508416, 0.11155813627580868, 0.22414090759815586, 9.999999999998899e-05, 0.13210558780855153, 0.1699449820432425, 0.12619682520201947, 0.2236880392797298, 0.12272484188732902, 0.24889837670744375, 0.19102285515992712, 0.2513705467730376, 0.1467551526839097, 0.12401362222692736, 0.23695817389256812, 0.15746961818379912, 0.027874125337338462, 0.06072648611430409, 9.999999999998899e-05, 0.03653683411609421, 9.999999999998899e-05, 0.01723928732658009, 0.012059492323410304, 0.04478264840026769, 0.006717544525714603, 0.14017338879149743, 0.10656869686338799, 0.09902319703063733, 0.09128090783513909, 0.17794883341607437, 0.0910036287564775, 0.1038836981393233, 0.31212999643860995, 0.14272659309352997, 0.0413577071903557, 0.10334934836982235, 0.1951844644314228, 0.10120625139683614, 0.148472489066512, 0.10877866466983943, 0.0890175371237939, 0.1877826344121919, 0.06921256679975996, 0.09266323095223106, 0.04894220872926258, 0.11646711314851876, 0.13441979668566395, 0.18803035587132255, 0.18870903102949776, 0.04586411060446227, 0.048260950828708515, 0.07795568252695628, 0.5596855328092235, 0.5793008591878284, 0.5732840481421099, 0.49120046592059696, 0.5194063559793725, 0.2078769989555206, 0.5360652080893245, 0.5906633889581849, 0.6657847457559384, 0.0692802541322548, 0.11725781135487523, 0.08009834760736811, 0.1419998096274805, 0.08805680083249012, 0.0881215290818802, 0.10947551906288921, 0.12855740006527394, 0.11493360783542139, 0.28265880703709023, 0.23699110714421345, 0.16730373436648893, 0.6258746911535744, 0.3714037386313467, 0.2034109643199552, 0.3191595621674961, 0.2111076514404875, 0.23586974810194272, 0.3623567075295314, 0.4497453862703804, 0.46263968212331774, 0.35050191503027295, 0.2919754920783182, 0.44725432505298757, 0.45136857945365816, 0.4231172754545629, 0.3584820511920329, 0.23978335859733668, 0.1921898105840837, 0.31345450827582444, 0.28228866410313525, 0.2356234893627034, 0.2728318078088886, 0.36081342400358984, 0.33145861856150116, 0.19864380035560447, 0.22415975842642732, 0.24114531930095873, 0.2063182431324465, 0.25552428671690675, 0.2126584560479785, 0.2152570282637094, 0.18542647305884308, 0.2330360895978565, 0.28317353890684227, 0.2394142459829387, 0.17693875924666824, 0.2045184372153851, 0.19545554699977197, 0.21773723814226154, 0.1930043105852267, 0.19916488346264738, 0.1880123257866414, 0.18660067829456406, 0.7869499316799886, 0.17783416111843275, 0.1678285873980131, 0.8589188068960061, 0.19927636612508126, 0.19944022886357737, 0.17500089155654475, 0.16056803489380977, 0.8689997476157142, 0.7896524978746127, 0.20912824583176803, 0.731206555247194, 0.3453277377585935, 0.16588386111598752, 0.7014143111780282, 0.1966459831681121, 0.20739860523532094, 0.8049277834730988, 0.19016334012243374, 0.2132405282296309, 0.20136288394402813, 0.19140503712294854, 0.2199901924958475, 0.19645308377573512, 0.1908342775065759, 0.22229402738130732, 0.20283722018443073, 0.08639953601197414, 0.09928940073247816, 0.09434456191147944, 0.09453265499940211, 0.09314364087128091, 0.09296911628004711, 0.10088716186326874, 0.08496709177944972, 0.08614776412819825]}, "mutation_prompt": null}
{"id": "0e4a43f2-0018-484c-b072-1f64bc6e740b", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))  # Maintained exploration efficiency\n        self.w = 0.5 + 0.2 * np.random.rand()  # Adjusted inertia weight for better balance\n        self.c1 = 1.8 + 0.1 * np.random.rand()  # Refined cognitive coefficient\n        self.c2 = 1.5 + 0.1 * np.random.rand()  # Refined social coefficient\n        self.F = 0.7 + 0.2 * np.random.rand()  # Modified mutation factor range\n        self.CR = 0.6 + 0.3 * np.random.rand()  # Modified crossover rate for diversity\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.3, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.3, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.2, self.w - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.w + 0.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + (self.F + np.random.uniform(-0.1, 0.1)) * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSODE", "description": "A dynamically adaptive hybrid algorithm enhancing PSO with DE and stochastic adjustments to balance exploration and exploitation more effectively.", "configspace": "", "generation": 30, "fitness": 0.31969287609544184, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.26.", "error": "", "parent_id": "6de16359-48dd-4482-91bb-d74ed43ebf45", "metadata": {"aucs": [0.8127242583955314, 0.82825992975129, 0.822367750637764, 0.8371083321712384, 0.8193494662578339, 0.8270257989167792, 0.8363906975743423, 0.8305608004501828, 0.808109967277272, 0.5666184589100298, 0.510073603484022, 0.6033255695687558, 0.5498153167404135, 0.5545698488273022, 0.6531340979865079, 0.655972546213035, 0.5156145987111489, 0.5561293109045093, 0.11263886566798897, 0.17252466844237002, 0.14192086975148555, 0.13330177166500146, 0.12389411760242697, 0.09366748512637568, 0.12126331648627042, 0.11214849124222015, 0.17740785078639087, 0.10959276338223023, 0.10896491878253001, 0.13063330056731626, 0.11501045358075679, 0.12992420819034944, 0.1021817437279251, 0.12903990298555068, 0.08599699906334424, 0.10722820389947718, 0.9714133899910535, 0.9705355657068062, 0.9818782696677608, 0.9765107985973769, 0.9812883581979752, 0.9720564868890892, 0.9732286533459626, 0.984720436313677, 0.9731649947589058, 0.5934960874072428, 0.5879685622767459, 0.05692031977659462, 0.5434468539776407, 0.686704501097641, 0.548588767904991, 0.5414522297056888, 0.5716074801960123, 0.5420821155830235, 0.24343343406129314, 0.22627091623408535, 0.22389303861710208, 0.21585702089352354, 0.3578201223456984, 0.8281430652406758, 0.6504978898688827, 0.12666790131348915, 0.8118226489239371, 0.6335500423975053, 0.2915894375256295, 0.2499648062853438, 0.0968844602441824, 0.12699476910412744, 0.22297091452740259, 0.33894123564607714, 0.1166480763833071, 0.38840316560852317, 0.1282469028844867, 0.23309692259472625, 0.12200145825607656, 0.24978872989215728, 0.3655971742318629, 0.23944592669634202, 0.3810378500036803, 0.1276666126010454, 0.1272189331517768, 0.06523783959584595, 0.027120016614535003, 0.09328625610434627, 0.0006331350964728921, 0.03887059537802995, 0.005571399060781745, 0.09643388096985073, 0.007968034460164253, 0.039347396386399835, 0.20112018646854424, 0.17226211227325217, 0.18999371232499473, 0.07716535443398675, 0.09491334507312954, 0.14650341803076994, 0.33295986223095464, 0.32738986034902084, 0.17650838137613822, 0.06376291082757413, 0.09476754779472196, 0.11581672072773164, 0.0982090916065006, 0.18390913231617212, 0.1147279294984872, 0.09458708361992396, 0.09474775758756715, 0.08895431509078422, 0.1464368884804801, 0.12082828913597365, 0.2172194305788374, 0.03514260888745413, 0.18658298974949017, 0.18474273675942554, 0.04490296430383478, 0.04602505143812652, 0.0785380600857516, 0.5832393657578557, 0.6052030665598704, 0.6725094386849982, 0.6241061532842946, 0.6138435476717901, 0.5316487289853566, 0.6508239537414291, 0.6544495901462014, 0.6109248752510692, 0.0849505969452955, 0.11539003426984529, 0.14406277957821767, 0.1758905376393468, 0.06536639458661797, 0.1426244870283655, 0.0898802327449919, 0.13523818738595128, 0.11204062546155091, 0.16184941971736844, 0.2456204617408333, 0.3152153492358628, 0.2878980459041204, 0.4573135778185259, 0.16913939055722294, 0.2725952043926735, 0.2485331688740503, 0.19655315759011915, 0.2855792151464831, 0.25402264979722644, 0.43662959162943293, 0.42503171676339935, 0.2590854561643723, 0.42061481892651287, 0.34742457153087947, 0.43568708906073694, 0.30050920015024807, 0.3101875934869859, 0.2975118138901468, 0.25480245686769953, 0.26332483671104, 0.27956769761885714, 0.3794729461819495, 0.21507313291698715, 0.2560094502521101, 0.193264390936982, 0.21790557570203894, 0.2332294834675055, 0.21906126037609563, 0.2697839877189656, 0.22824834239857383, 0.25215148960791034, 0.24820894091656143, 0.2388748011208931, 0.2167242039270959, 0.21553192559366585, 0.17464826556114166, 0.2181949172378147, 0.2199410406229072, 0.24478134923758665, 0.1991174442349185, 0.23796887685752088, 0.21847134048599082, 0.20462554626716112, 0.782245755914588, 0.8779696339642815, 0.2073481047050817, 0.8837042730254281, 0.19913187700332768, 0.20001680554937018, 0.14191083417192418, 0.16167275150281935, 0.8837510604931927, 0.8207094685892122, 0.2100846377612814, 0.20241061217556455, 0.20615099282383864, 0.16827290763659308, 0.15066692575876228, 0.10423716830694285, 0.21048818242527212, 0.8500231070076818, 0.19078318942459205, 0.19270938340703514, 0.2228299589457048, 0.1907440295255194, 0.20603698182636687, 0.18775178832209538, 0.2582178655354561, 0.19600069754590954, 0.20118853204175113, 0.13482269775309963, 0.08031568945811218, 0.082258661029326, 0.08061741923286991, 0.08747317580910985, 0.08560655876075907, 0.09994744217684914, 0.09233633901962457, 0.08585403169472028]}, "mutation_prompt": null}
{"id": "7d4d03a2-db97-465d-9937-082ba01af378", "solution": "import numpy as np\n\nclass DynamicHybridOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 4))  # Slightly more conservative population size\n        self.w = 0.3 + 0.4 * np.random.rand()  # Increased inertia weight range for adaptability\n        self.c1 = 1.5 + 0.2 * np.random.rand()  # More flexible cognitive coefficient\n        self.c2 = 1.5 + 0.2 * np.random.rand()  # More flexible social coefficient\n        self.F = 0.5 + 0.3 * np.random.rand()  # Adaptive mutation factor enhanced for variance\n        self.CR = 0.4 + 0.5 * np.random.rand()  # Wider crossover range for diversity\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust'])\n        \n        while self.evaluations < self.budget:\n            # Evaluate current population\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            # Update velocities and positions (PSO)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            # Dynamic adjustment strategy\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.3, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.3, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.2, self.w - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.w + 0.05)\n\n            # Apply Differential Evolution mutation with adaptive mutation strategy\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + (self.F + np.random.uniform(-0.1, 0.1)) * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "DynamicHybridOptimization", "description": "Dynamic Hybrid Optimization (DHO) integrates adaptive PSO and DE with strategy learning and environmental feedback for enhanced convergence.", "configspace": "", "generation": 31, "fitness": 0.32570266346699933, "feedback": "The algorithm DynamicHybridOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.26.", "error": "", "parent_id": "6de16359-48dd-4482-91bb-d74ed43ebf45", "metadata": {"aucs": [0.8407533807012447, 0.845464203428426, 0.8635360798348887, 0.8496394667249056, 0.8428653702289881, 0.8561137682749516, 0.8207907676585775, 0.8435312699090408, 0.8331389162107281, 0.6239309573940326, 0.6382731461282336, 0.5526600425219131, 0.6096695939318676, 0.6756971397092688, 0.6327256646958287, 0.6174392905198174, 0.6504780074087705, 0.6389667213347389, 0.12902751569873383, 0.13733591759765662, 0.1482452965634875, 0.15146389189272136, 0.14197851705575593, 0.13885041299680634, 0.11271169137731829, 0.1080727976913175, 0.15090162408820929, 0.10367234566697003, 0.08279305044476315, 0.10205950696327759, 0.13790875204932385, 0.09673818311222837, 0.1066787250269845, 0.14992213077489336, 0.08972567364420592, 0.1202884532791626, 0.9712834937872508, 0.9369033471745354, 0.9807773070179205, 0.9791965273050774, 0.9811971135583022, 0.9621149180280546, 0.9729728614256432, 0.984232291024721, 0.9735926344959106, 0.664291075162235, 0.6253324415940777, 0.6221537523024362, 0.5843615958388224, 0.5642940875477034, 0.6236911290608422, 0.6399880152388343, 0.6280011281420059, 0.6001967559763601, 0.8364725381120431, 0.22814986063875453, 0.69847901872076, 0.21328651009413724, 0.218296360510551, 0.20289941277041257, 0.5445194279646899, 0.19780522485271934, 0.8256357751516434, 0.323735052540956, 0.10487676440303717, 0.15388446724875726, 0.09581187913012368, 0.12784635247170373, 0.22347237315773028, 0.421988989820697, 0.3533214081086148, 0.3057955645914301, 0.35319968795603696, 0.112952522207869, 0.12408576977262853, 0.30564403005377294, 0.2788424484343287, 0.38665979050713284, 0.18198782449541018, 0.23077434151774068, 0.19459645090540179, 0.08865447797049453, 0.1318125639022104, 0.09443702219705685, 0.0005548614744442792, 9.999999999998899e-05, 9.999999999998899e-05, 0.0868916861121305, 0.07031413896131922, 0.042579609929845885, 0.19107155549510513, 0.06970450320195454, 0.35438191014712994, 0.16932122938387895, 0.13753201185485375, 0.05867665000366451, 0.13811488584243892, 0.19870334649893717, 0.14245775437299968, 0.12541966342816246, 0.12563122314870745, 0.1614163366518162, 0.29721038639220365, 0.15733577482867533, 0.20534026695293983, 0.09171580353847497, 0.1398126565456358, 0.21732234765754987, 0.16924458062866488, 0.14307839980178194, 0.14299786269251946, 0.1876479112405922, 0.12865539698906414, 0.19448741584180262, 0.05574495423831782, 0.1675878132761196, 0.2203976996944228, 0.6368513855874995, 0.5889574996110769, 0.6558188285411037, 0.6500542479854513, 0.5876051972288845, 0.557823681213597, 0.6155462675280152, 0.6000507922908058, 0.6547155821406622, 0.1312916836967375, 0.09384771132334702, 0.14583269229525153, 0.09032423076782237, 0.10313350788849418, 0.0950535738893955, 0.12894623490032886, 0.09084637444297261, 0.10081843071299079, 0.2959178033034373, 0.23512092064876067, 0.22554606284051948, 0.3427740064846342, 0.2701837817136409, 0.17857819231308025, 0.15797213302560287, 0.27253583757971356, 0.2542132177345223, 0.3266214533202544, 0.3306154587674631, 0.3368073310182125, 0.31545769656993483, 0.3440528895414491, 0.4424732975828859, 0.36364615470556716, 0.46796169732333215, 0.4358016343189134, 0.2887596877002978, 0.15997726611797913, 0.23561151734235475, 0.20910400112377137, 0.13943386224580268, 0.22415684225729837, 0.2694683996025875, 0.27376866245619735, 0.21557382994892982, 0.254884304335559, 0.248132168200075, 0.24497802179235895, 0.22178810902890156, 0.21361113797623654, 0.2001851293542274, 0.19940297034649845, 0.247055113755008, 0.21005891970477553, 0.18534173305189816, 0.2070038604562937, 0.19202909069515628, 0.19843729393218212, 0.228455213629717, 0.19087038663443756, 0.24644116487263767, 0.19710943814761683, 0.19224774000109734, 0.8568142120375604, 0.18702638599080168, 0.16781062731894947, 0.8743634699709171, 0.199891034706573, 0.19993232830692254, 0.1422612355105093, 0.16158505976299853, 0.8852548602175446, 0.8646620581030082, 0.2111771929248103, 0.2069922158387001, 0.20565290288535032, 0.4282021216885792, 0.15193868537612032, 0.10387529739056989, 0.1043760559448288, 0.8315025089792076, 0.23211348452131775, 0.18612061931102653, 0.22264882430650745, 0.19345822466358786, 0.20074830453988235, 0.20368631357756017, 0.21519427793910983, 0.20034236167985053, 0.19188323527813478, 0.08604209002614605, 0.09043643299727178, 0.07988847537704591, 0.09442968175826882, 0.08841086688965716, 0.10195294223837281, 0.08898819955540915, 0.09893478205285389, 0.08539128940388052]}, "mutation_prompt": null}
{"id": "86e08cd9-9e9e-4e06-b768-661b01c0240c", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))  # Adjusted for increased exploration\n        self.w = 0.4 + 0.35 * np.random.rand()  # Slightly increased range for inertia weight\n        self.c1 = 1.4 + 0.1 * np.random.rand()  # More adaptive cognitive coefficient\n        self.c2 = 1.6 + 0.2 * np.random.rand()  # Slightly increased adaptive social coefficient range\n        self.F = 0.6 + 0.3 * np.random.rand()  # Further adaptive mutation factor with increased range\n        self.CR = 0.5 + 0.35 * np.random.rand()  # Increased crossover rate range\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust'])\n\n        while self.evaluations < self.budget:\n            # Evaluate current population\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            # Update velocities and positions (PSO)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            # Dynamic adjustment strategy\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.4, self.c1 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c1 + 0.05)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.02) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.w + 0.02)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.F + 0.05)\n\n            # Apply Differential Evolution mutation with adaptive mutation strategy\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + (self.F + np.random.uniform(-0.05, 0.1)) * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSODE", "description": "A probabilistically refined adaptive hybrid algorithm enhancing Particle Swarm Optimization and Differential Evolution with stochastic learning and mutation strategies.", "configspace": "", "generation": 32, "fitness": 0.3288697932105424, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.26.", "error": "", "parent_id": "6de16359-48dd-4482-91bb-d74ed43ebf45", "metadata": {"aucs": [0.7984531006277666, 0.808744463355225, 0.7665949980374139, 0.7946317750134558, 0.7716802301218249, 0.8193187261459705, 0.7722530468816672, 0.8011317758353262, 0.7742567161715264, 0.5060472590158857, 0.5839646499395104, 0.5390667835030778, 0.5407300217971064, 0.5976888532191263, 0.5462914219316239, 0.587304091471553, 0.5436014912895477, 0.534851818865543, 0.13940657855298177, 0.11863393148984924, 0.10976287489092795, 0.10607365414680137, 0.12331348069172599, 0.1465101531950055, 0.10524345600429008, 0.1407269291559622, 0.13302588196810305, 0.11621507245020635, 0.12897310903955872, 0.12242934119916138, 0.07779521793197641, 0.13165778671149986, 0.09844164285008794, 0.12199749497682455, 0.09014022494386897, 0.0867518476849578, 0.9757404616592427, 0.9400854646227293, 0.9826037635001529, 0.9793164373706812, 0.9813151165721594, 0.9719299472716758, 0.9790201394714315, 0.9847280986895627, 0.9789972014351733, 0.5660319879099315, 0.6128659470744924, 0.5621511112296314, 0.4965637522865909, 0.5963141658242521, 0.5863319549009577, 0.08014297113999258, 0.5853201650545805, 0.4857830829054486, 0.7385320176116783, 0.2262687631954372, 0.5475716456492787, 0.2635210494992677, 0.2667564767225805, 0.21548815629638218, 0.68700915791519, 0.7557877025764943, 0.6417182986942929, 0.26667052919290857, 0.10403742729181775, 0.2717661129615744, 0.09081756305413036, 0.12612649466492454, 0.10829911150911209, 0.24485308916323478, 0.34809335191046675, 0.41745798023458214, 0.5199493268348563, 0.40437723360559386, 0.11787571654518392, 0.34201982498362216, 0.30401260784823037, 0.2720569445633849, 0.4135744778788344, 0.3046982831625423, 0.10434478050880303, 0.053062989788008386, 0.07686397363821018, 0.1524522857593803, 0.20701842629645273, 9.999999999998899e-05, 0.014812623075105558, 0.04964360285815217, 0.04625335551420706, 0.21505628311225722, 0.11028907955677092, 0.19155470831551835, 0.33698356125235296, 0.0682011236471306, 0.29084148098345575, 0.14929859287015879, 0.09693380562848908, 0.2524406288867862, 0.4261780392122969, 0.06491750493131188, 0.03274680206545999, 0.0661877422307725, 0.12138137649601344, 0.141745366313221, 0.16150978482913647, 0.16251237827923504, 0.3836023389703026, 0.12857409571650003, 0.10695537858449533, 0.3350860417066015, 0.2116182252624561, 0.14687040304214316, 0.31606050455267454, 0.27684832336942866, 0.04534367283209173, 0.2448776560163688, 0.08362195629028524, 0.6189202712891128, 0.6344049916922991, 0.6805964146015087, 0.6077805198010258, 0.6235514674181659, 0.2078894834074836, 0.6361157761394757, 0.6228237688799946, 0.596772029354932, 0.10393046711256337, 0.08191643570572138, 0.08422471097222262, 0.11443892519796484, 0.14952166116977628, 0.11902109521137971, 0.08530165959968383, 0.0838362135634938, 0.0705970877028056, 0.1832078082903964, 0.24131473011586257, 0.2286675775981516, 0.2211340087859225, 0.2864881265994601, 0.2677726540108729, 0.1949406015147076, 0.2781547179002458, 0.17522324765908492, 0.23078288290469695, 0.3355631849549061, 0.4697179824620792, 0.513297492449343, 0.32515417409611014, 0.4841084779326066, 0.26687971971879365, 0.2609975953963217, 0.45972872620431104, 0.2700542457376438, 0.2623781530311766, 0.25199740052084685, 0.1932058246856736, 0.26753920395535247, 0.3097215916209073, 0.22712061642934311, 0.32074527554446264, 0.21174852102372943, 0.22863181084531803, 0.27300410766123484, 0.2780667294405679, 0.2452624829915595, 0.22987967642629015, 0.24445293665942458, 0.2515244455936412, 0.251928817733747, 0.25431876376106743, 0.1921692380763964, 0.2164599941885944, 0.19964084435206086, 0.2095485006236879, 0.2080699648091252, 0.21125133732517598, 0.22532033457926282, 0.18998993973405187, 0.18565511948404434, 0.8243401924093682, 0.1870539110892665, 0.16740987188859413, 0.8671384907726323, 0.1988547824794782, 0.19801250510732593, 0.14184461233111056, 0.15987729507912118, 0.8630962112106826, 0.7918572614441729, 0.20715329076055455, 0.20504069373950784, 0.20081701546729092, 0.8172551239486594, 0.15229327876198417, 0.2092405258804877, 0.8191287517209269, 0.8002176923964548, 0.19717827791486775, 0.21296192043779905, 0.250423654094859, 0.2175568936318718, 0.2319739385913535, 0.2137448081864659, 0.2012035694708615, 0.2005360482467028, 0.23529630554924474, 0.09947329619824508, 0.0933028453229604, 0.09964324045504125, 0.07427647871026688, 0.09942334798157026, 0.10693940033094151, 0.14318298809815566, 0.09170490639731266, 0.10087943713987912]}, "mutation_prompt": null}
{"id": "0e2e08ed-62ec-40dd-9293-dabf8f30e9bc", "solution": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.4 * np.random.rand()\n        self.c1 = 1.5 + 0.1 * np.random.rand()\n        self.c2 = 1.7 + 0.1 * np.random.rand()\n        self.F = 0.5 + 0.3 * np.random.rand()\n        self.CR = 0.6 + 0.3 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.3, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.1, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.3, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.1, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.2, self.w - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.w + 0.05)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.F + 0.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + (self.F + np.random.uniform(-0.1, 0.1)) * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveHybridPSODE", "description": "A self-adaptive hybrid metaheuristic combining Particle Swarm Optimization with Differential Evolution and dynamic parameter tuning for enhanced exploration and exploitation balance.", "configspace": "", "generation": 33, "fitness": 0.33456990142249954, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.27.", "error": "", "parent_id": "6de16359-48dd-4482-91bb-d74ed43ebf45", "metadata": {"aucs": [0.825141622776838, 0.8120693277462817, 0.8501530083740372, 0.8363022406330953, 0.8336657123516347, 0.8239481322970122, 0.8362003044353954, 0.8296392953842565, 0.8514751909387689, 0.4296731325830522, 0.6443300329361493, 0.523070693809043, 0.6103168846727539, 0.6016538812291198, 0.5793577699337508, 0.5847602226496261, 0.598764283422311, 0.055046743225962036, 0.5405355240874355, 0.09133631626306737, 0.15471301895866163, 0.13375163082765407, 0.10819228845014828, 0.09488841903913703, 0.11233442919449277, 0.11093314911075591, 0.10732132716175746, 0.10925939511176708, 0.0989937665844014, 0.09578457751621938, 0.13015552458307922, 0.12139575928975332, 0.13337819625906266, 0.10311813058426456, 0.10778973208458975, 0.12442038574039449, 0.972220025547068, 0.9614389952101992, 0.9823125850947719, 0.9766430789598309, 0.9813326098271022, 0.9718802496489429, 0.9732033593650766, 0.984733714867437, 0.9732427834814551, 0.676594358200103, 0.6546894252815755, 0.6398731686348615, 0.5449825692655899, 0.6603012266180183, 0.637839187292507, 0.0863029367861835, 0.466224173836423, 0.6459803598621269, 0.7530509205705529, 0.2985554183714586, 0.24525214908974702, 0.21203090677582537, 0.8787990856303358, 0.5113074943537325, 0.5901447903229731, 0.330455194235894, 0.6688590727848529, 0.4575864596816348, 0.11854863208277167, 0.40690092946824175, 0.11820897707918632, 0.6405068610853691, 0.47183605180869037, 0.29635015413561416, 0.16118626452698737, 0.4616158635442057, 0.5213949016003943, 0.12249200548056383, 0.5191431310747969, 0.40190829945846585, 0.1248902774746048, 0.22446754264450963, 0.2374032925379974, 0.43308249291165557, 0.12019313347018379, 0.06432332679699115, 0.04246188400058615, 0.0673954788712674, 0.0658161964455547, 9.999999999998899e-05, 0.010362112892801867, 0.05651239034603173, 0.08777002057238736, 0.2241260960771151, 0.20946738278016963, 0.09689850614586104, 0.6354490810201769, 0.08046909382312495, 0.15285902735395995, 0.1716971904975899, 0.25109825514178497, 0.24735677922411814, 0.09045387581746855, 0.20417744606471966, 0.02570123079379083, 0.2504210024104768, 0.12341603588939465, 0.3148029351281503, 0.0932378594894473, 0.09160228922029579, 0.06827752758898264, 0.09704120717120168, 0.12521371652468039, 0.1920370344184993, 0.1793794559908667, 0.29014444250396176, 0.17696365609309272, 0.2712292788252557, 0.047847950575011566, 0.05504668916023314, 0.0801127949207543, 0.6214901852055023, 0.6056548931223997, 0.6174476336968586, 0.6390139785474849, 0.6465227145013246, 0.6380802580211248, 0.6657994005262944, 0.6668528159397854, 0.58672407794648, 0.11877793753860277, 0.07227657792737696, 0.09540894484387263, 0.13557015259811012, 0.08363642820582595, 0.18098512804450695, 0.11305513592808125, 0.10159908034191667, 0.09340957881660283, 0.21564682981578043, 0.23337705145033272, 0.3105153784957737, 0.27489611883782916, 0.3379031978712276, 0.26878792821051867, 0.3103427756817426, 0.13573669202813832, 0.209256986199006, 0.312829784270525, 0.24334628103154965, 0.3442934159857608, 0.3309407160655743, 0.2990812493972185, 0.20257845916079265, 0.5308228292237176, 0.4669375022421727, 0.4648813621834931, 0.2576168967738627, 0.1723598472848138, 0.4032296700951725, 0.24002359527307804, 0.1753776068166797, 0.20398053901422641, 0.28700223310534, 0.20086865347381333, 0.21841069083744935, 0.20936268176547124, 0.2088249567245788, 0.19613042995958108, 0.20258276731514646, 0.23983913145267377, 0.23099057111462684, 0.20134488169078424, 0.2404970539148943, 0.23584876849151448, 0.676694484306926, 0.20341884823507406, 0.19407400142073006, 0.18739680163371475, 0.21040562400373064, 0.19077503271430607, 0.201544130621379, 0.20687929069725253, 0.1704409569210127, 0.16363260279278713, 0.18772401421256857, 0.16786395854308322, 0.8977222891276675, 0.1996739552682939, 0.19865997390253753, 0.14261855716983096, 0.16168512672579927, 0.8836962044971286, 0.8527857176176817, 0.20939174454924403, 0.0733828669044797, 0.8087409699505768, 0.16673631224162944, 0.1453015328602596, 0.8440621927212109, 0.1946981164049002, 0.789605549755048, 0.19930177930795256, 0.20681401416925427, 0.2193459307132256, 0.22142824298048558, 0.20017724471191056, 0.19841700669245255, 0.21150907133587427, 0.1927579985954796, 0.22722489036021498, 0.09574606993209178, 0.09229398907112352, 0.09556356032026092, 0.08251999767518503, 0.08450731898885966, 0.09224443378001701, 0.08203387151995789, 0.08094938264794582, 0.09477818284969508]}, "mutation_prompt": null}
{"id": "17c45e83-d08a-40c5-ba6d-04300c71b8ce", "solution": "import numpy as np\n\nclass QuantumInspiredAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.4 * np.random.rand()\n        self.c1 = 1.5 + 0.1 * np.random.rand()\n        self.c2 = 1.7 + 0.1 * np.random.rand()\n        self.F = 0.5 + 0.3 * np.random.rand()\n        self.CR = 0.6 + 0.3 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust'])\n        \n        while self.evaluations < self.budget:\n            quantum_potential = np.random.rand(self.population_size)\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i] + quantum_potential[i], \n                                             self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.3, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.1, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.3, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.1, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.2, self.w - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.w + 0.05)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.F + 0.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + (self.F + np.random.uniform(-0.1, 0.1)) * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "QuantumInspiredAdaptivePSODE", "description": "Quantum-Inspired Adaptive Metaheuristic combines Particle Swarm Optimization with Differential Evolution using quantum-based dynamic parameter tuning for robust exploration-exploitation balance.", "configspace": "", "generation": 34, "fitness": 0.19498545581176824, "feedback": "The algorithm QuantumInspiredAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.20.", "error": "", "parent_id": "0e2e08ed-62ec-40dd-9293-dabf8f30e9bc", "metadata": {"aucs": [0.3926519216887919, 0.4387542828070753, 0.3877456915665477, 0.1895188877748093, 0.44260270618092545, 0.41574767197584184, 0.4259092449139079, 0.39923744660988636, 0.4230932474791209, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00016426986932560617, 9.999999999998899e-05, 0.003769029806762414, 0.003848132729922349, 0.027667536377886992, 9.999999999998899e-05, 0.09390814078750032, 0.07436540660062363, 0.12631128209271392, 0.08961276651173722, 0.06422466257749238, 0.09300637983219129, 0.11122678434741029, 0.09075528535913857, 0.08842100246963713, 0.07867661493166234, 0.11395864950653356, 0.0798416281252885, 0.08750660604080784, 0.10444339584736195, 0.08111292792232472, 0.1221507494208407, 0.0819826825261063, 0.07821907100628611, 0.9803636678382749, 0.9707233898733453, 0.9928746386034278, 0.9703152101096382, 0.9717047186867459, 0.9744060072132188, 0.9793266386740512, 0.9837129533263623, 0.9693180560600195, 0.24844834800267024, 0.16977199077328065, 0.2223505586535679, 0.18111282134728113, 0.22090649127296536, 0.2720835221234468, 0.11759581262830365, 0.19065679320900608, 0.08747860269352081, 0.18120106886932863, 0.3003784743162211, 0.220401992042766, 0.19077950518135356, 0.2873825234400378, 0.1900403560152536, 0.0680040464236299, 0.18061369150091655, 0.2842103715493489, 0.25549497434786095, 0.09717715996216136, 0.13173649412056254, 0.09152214030842809, 0.16435555007663405, 0.22737441814649706, 0.19528558001027818, 0.12275826344907725, 0.21373722425591746, 0.171107510332564, 0.04307269508173395, 0.16861918893153283, 0.12134588594776852, 0.12426386149146962, 0.13184591472941887, 0.14170403181124835, 0.13560821992392158, 0.12786347059472103, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11070091223439027, 0.05417860436323951, 0.09477059682806865, 0.041658572618578416, 0.05394864680034295, 0.031177750154325223, 0.08034114554077787, 0.04535307288053392, 0.07845917886767984, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.000643672652447691, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08896350011354315, 0.07483182870918048, 0.02795193587672351, 0.025360755063160823, 0.029978708426784628, 0.058734529966687266, 0.0461494421287012, 0.04798374329660382, 0.08385457015294506, 0.37024165335367265, 0.3886296781602009, 0.3966186197107372, 0.38551274184648676, 0.3675931053364998, 0.20540106872812902, 0.35329607279610487, 0.363676661975581, 0.35229672901553266, 0.08778295910785239, 0.11983108858400615, 0.08050273492585924, 0.10752411137657969, 0.11459368808963877, 0.0894099062378314, 0.08992552357449513, 0.1178886524243522, 0.11207635615719935, 0.18235704348398052, 0.1551332473311171, 0.2495322367661893, 0.1757672195763622, 0.17683794156916188, 0.15656029062628296, 0.19471805569807354, 0.15784563961441622, 0.17315557862565711, 0.21847507349264228, 0.21601487584189305, 0.22524153761867272, 0.25962743025141877, 0.2461843841535739, 0.2585169698646872, 0.24483812938644922, 0.25496056339572815, 0.25268151823680085, 0.2003784049313645, 0.15145420703286872, 0.19486485303909107, 0.162728396541849, 0.23104706368263828, 0.19092682865877442, 0.17661918253287767, 0.20069360336018371, 0.1699701330568978, 0.232172341755974, 0.16747658696450074, 0.18681688730491963, 0.19875091288473512, 0.1942675659238594, 0.18134136915962495, 0.1902402086085827, 0.21317520123874223, 0.20074767013089967, 0.17642975474835343, 0.1755723347330822, 0.18609371289737797, 0.17870168317798762, 0.18468333847488783, 0.17190370914093855, 0.19424970784831197, 0.18690538134769874, 0.19564560652505747, 0.16481798638561873, 0.1855641517885276, 0.18605696275618389, 0.5432795551230511, 0.1960043073763018, 0.19684356775604905, 0.13983755292530586, 0.17312388641088727, 0.5750891126853411, 0.4005553527118957, 0.2020602243677525, 0.552991474120103, 0.5332380176042542, 0.15070097596050835, 0.15363956270955348, 0.2001936196172912, 0.6082249970550944, 0.23368031233659792, 0.18946957134391462, 0.17922523464886475, 0.17450075721573544, 0.17526636426151077, 0.19426729193488468, 0.17594690045879835, 0.19118707016427738, 0.1856483795109679, 0.18278733628983757, 0.09491366092450826, 0.08354287872059463, 0.0677006430596584, 0.08275176614907764, 0.07822810753950382, 0.09301661504819181, 0.07716447280121297, 0.07026320020964283, 0.07126074642354574]}, "mutation_prompt": null}
{"id": "01cb8ca2-6428-485a-91e6-ec9058a97724", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.4 + 0.3 * np.random.rand()\n        self.c1 = 1.4 + 0.1 * np.random.rand()\n        self.c2 = 1.8 + 0.1 * np.random.rand()\n        self.F = 0.5 + 0.25 * np.random.rand()\n        self.CR = 0.65 + 0.25 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust'], p=[0.25, 0.25, 0.25, 0.25])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.w + 0.05)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.8, self.F + 0.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + (self.F + np.random.uniform(-0.1, 0.1)) * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedAdaptiveHybridPSODE", "description": "A self-adaptive hybrid metaheuristic integrating Particle Swarm Optimization with Differential Evolution and adaptive dynamic parameter strategy for improved global and local search balance.", "configspace": "", "generation": 35, "fitness": 0.29534448198408275, "feedback": "The algorithm EnhancedAdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.24.", "error": "", "parent_id": "0e2e08ed-62ec-40dd-9293-dabf8f30e9bc", "metadata": {"aucs": [0.7384933260245943, 0.6368015926885899, 0.7433681108489887, 0.7243045250120048, 0.66347157742866, 0.7480123740208038, 0.7295981238632265, 0.6686768577169664, 0.7506185989820952, 0.2822497265101458, 0.3179355239441981, 0.44567249186476876, 0.4446562759800726, 0.22935900570388623, 0.32052682441906954, 0.3278427652392426, 0.290269293073553, 0.42747695437748734, 0.14215232081312357, 0.1383923634158164, 0.12971759921944126, 0.13385526452543384, 0.11678406785841744, 0.1280497499409433, 0.10448926033009864, 0.11242895541793363, 0.14516178680408642, 0.10699748526474617, 0.11195487908727264, 0.10539214618477621, 0.13259990083493378, 0.1239818505261936, 0.11684066026082252, 0.10721354590335885, 0.10065248764252466, 0.12760214982114337, 0.9795086171868485, 0.9718306724977966, 0.9818819615434, 0.9609885560764171, 0.9720608181144327, 0.9613069884721217, 0.9788237491315627, 0.9825588195642729, 0.977552291372172, 0.5154069045377472, 0.36646283396933177, 0.47894220117726793, 0.47817326596487186, 0.14767965084916035, 0.57091087560671, 0.26894513535541276, 0.3377171670349901, 0.41857591968572994, 0.22093857645596027, 0.7060142743659649, 0.2189573133097208, 0.2176218018068844, 0.7708422847161233, 0.20338881850049817, 0.5654794021992869, 0.2281736088660693, 0.751499623469083, 0.45793026999182607, 0.10527391089916005, 0.09108078062168501, 0.12165323158983776, 0.3082037009114391, 0.09874926833816644, 0.1973006152682898, 0.1647569694234, 0.22712045476080966, 0.1732915707991326, 0.2841791002833024, 0.4195504315240668, 0.1909013928508685, 0.2303566693213529, 0.1707764376212001, 0.23650808171741633, 0.28450059002414063, 0.09944551187558137, 0.05800426418364679, 0.113956069641161, 0.15769865338027833, 0.11824615213949241, 0.044982842213637575, 0.015554874070659364, 0.06538018080716479, 0.030647766001584698, 0.003475516097857123, 0.14014853505550895, 0.23401269083320742, 0.18190701723273017, 0.08860007282370752, 0.2725524798730994, 0.1010476399564133, 0.14506975168098635, 0.21122499710649523, 0.20433709653144194, 0.15448632583568578, 0.07870926381124865, 0.1792862281722155, 0.1332031624939406, 0.05432126629056433, 0.07631208507870957, 0.07822258490428668, 0.12352785017519508, 0.08561976885379485, 0.23600454438786955, 0.22554647216732449, 0.09657552227993782, 0.1575836152186323, 0.17966159206050902, 0.28243617204755866, 0.051431971714889, 0.052535722992798406, 0.07461430908269162, 0.6013365985224539, 0.5487104292031988, 0.603396871191564, 0.5571801417578346, 0.5230378653733219, 0.5981148960233276, 0.6024809866714209, 0.5011492461982818, 0.6495708724858209, 0.13528275425782454, 0.11445364661499458, 0.06350179481712459, 0.11711435020616068, 0.11869798322981329, 0.1301900103364414, 0.10804082639738644, 0.0759304057018173, 0.10925965329258014, 0.33906722511388343, 0.41457716118772914, 0.1965098698972435, 0.44769687559499416, 0.4066690469195823, 0.2209519986797629, 0.3691670781656248, 0.19554562013155652, 0.2621661523388944, 0.4033812253480118, 0.3087598876013743, 0.4380530394165053, 0.3567960051629865, 0.3355489589006343, 0.40960008099292133, 0.39643989882775554, 0.3666111777720209, 0.35108828301783146, 0.24082265496035993, 0.257608931411779, 0.2759574220881965, 0.2849563091091438, 0.2528938837598781, 0.19619134293384033, 0.24668981538181933, 0.26725477553640054, 0.19968806018554763, 0.20190497320559364, 0.17947768862447522, 0.1936446462591347, 0.20769160286614796, 0.19146499413737805, 0.20013378059281672, 0.16564394199978838, 0.2316668569374375, 0.23756924620979103, 0.19459667482362641, 0.23642105847339434, 0.19533941156643386, 0.22745665679928895, 0.2395613948853702, 0.23750832546628153, 0.21695035983521693, 0.2243374382211506, 0.18538416465619, 0.8305026765464607, 0.18590687332889633, 0.1681080897597409, 0.8539989332299843, 0.1988123495642159, 0.1969813066175663, 0.1729626724047275, 0.16488465099698646, 0.8162938355447071, 0.7467885320997674, 0.2083888646573706, 0.07320692742966328, 0.20575290499929666, 0.1637654731965651, 0.1659267704603462, 0.20396860074191492, 0.7336592157736732, 0.5156841430553976, 0.19185715327445274, 0.19502287510346794, 0.20533652882534936, 0.20355284948350605, 0.18276455469603803, 0.18448608490222917, 0.1896592231189329, 0.18122979808028972, 0.19195952802635963, 0.09439649670364447, 0.10021725541556092, 0.08863383525282698, 0.0895078249242024, 0.09782936256256303, 0.08313555371856673, 0.09174450193975936, 0.09468605829601862, 0.08355387715581397]}, "mutation_prompt": null}
{"id": "3d9ad192-8849-45e9-9bb8-6bb3eab965c1", "solution": "import numpy as np\n\nclass StochasticAdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.4 * np.random.rand()\n        self.c1 = 1.5 + 0.1 * np.random.rand()\n        self.c2 = 1.7 + 0.1 * np.random.rand()\n        self.F = 0.5 + 0.3 * np.random.rand()\n        self.CR = 0.6 + 0.3 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'F_adjust', 'CR_adjust', 'w_adjust'])\n\n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.3, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.1, self.c1 + 0.1)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.F + 0.05)\n            elif learning_strategy == 'CR_adjust':\n                self.CR = max(0.1, self.CR - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.CR + 0.05)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.2, self.w - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.w + 0.05)\n\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + self.F * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "StochasticAdaptiveHybridPSODE", "description": "A self-adaptive metaheuristic blending Particle Swarm Optimization and Differential Evolution with stochastic selection of evolutionary strategies for dynamic optimization.", "configspace": "", "generation": 36, "fitness": 0.29393596574616765, "feedback": "The algorithm StochasticAdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.24.", "error": "", "parent_id": "0e2e08ed-62ec-40dd-9293-dabf8f30e9bc", "metadata": {"aucs": [0.6913427300570489, 0.7266253009829974, 0.7266510504598841, 0.7015895434777388, 0.741979543742091, 0.7903750690445162, 0.6960327082611286, 0.78409255091162, 0.7430033788311661, 0.34834462404270816, 0.35803800695964005, 0.4273855844941995, 0.29518343234091515, 0.4749719272585371, 0.46096006724970273, 0.3266102460786201, 0.4820762325646628, 0.04852776125746039, 0.1287278425490035, 0.12380807248036796, 0.1568772929640112, 0.13177919678128414, 0.09590921065946911, 0.06214397181829301, 0.15624981798883142, 0.16372800650462882, 0.13142364530619033, 0.08525546402687123, 0.1306064053714021, 0.13411279001765908, 0.10040612154021478, 0.10619966528990987, 0.1044777270159577, 0.15859013544271605, 0.1292642783518113, 0.10563442543453716, 0.9737181557802407, 0.9729573972488521, 0.9830420661575913, 0.959883616229556, 0.9523055305249585, 0.9553106719071329, 0.9816004979473868, 0.9822846372787173, 0.9802030531487306, 0.46395835538942476, 0.4236547619915352, 0.05869530614042573, 0.43183159901074863, 0.4974010746004729, 0.4524471815049518, 0.08204228654865597, 0.45624983572585365, 0.4644183886493768, 0.22263740747991256, 0.8437285286965558, 0.804251404070229, 0.21063927492229317, 0.21536834225714874, 0.18952059357535855, 0.13439611355225412, 0.13881096735666854, 0.7930994212652901, 0.26600324776866213, 0.3837728265589154, 0.30861441232328135, 0.09281127455813643, 0.4079304913384485, 9.999999999998899e-05, 0.3277342784616043, 0.10622786176331633, 0.40732339401351514, 0.47017254737844083, 0.2801375439289139, 0.11334002468300786, 0.24722806311293477, 0.44269401433694044, 0.33353927980747244, 0.11012713550831721, 0.32206292515399715, 0.09436522802827929, 0.007468244132930679, 0.08071541811792138, 0.02864496587232812, 0.023473131209182374, 0.06864299129538609, 9.999999999998899e-05, 0.008356037360726432, 0.06615948759885304, 0.2564256279611603, 0.2862113382724284, 0.1191687168148432, 0.17061071035939368, 0.07014196367677827, 0.19892683261320498, 0.07321707530989718, 0.32373545885400823, 0.23062057032037098, 0.0961949356160321, 0.10952196706149353, 0.030100998316159755, 0.1232491379270847, 0.08812248056145855, 0.06931452887404865, 0.07194863737059154, 0.07768634508560812, 0.1942481852399054, 0.15141739647340569, 0.18289164687604986, 0.12238887746307259, 0.18979045866021793, 0.14653994350833977, 0.256258826321368, 0.2588183629144033, 0.047204332070418076, 0.07693191860648507, 0.09881829843021461, 0.519070744743842, 0.6253533428953602, 0.6459302809997545, 0.5523703273737492, 0.588129171382444, 0.5499603666960201, 0.5702768126985198, 0.545508975108548, 0.594327917945698, 0.16049316362839272, 0.0655198264945529, 0.07967050576837242, 0.17891578074237313, 0.11874920092581798, 0.11674599707752009, 0.10283570594052216, 0.13070798010810358, 0.09987035953004031, 0.20600191495007625, 0.43943531353800425, 0.31527504390249705, 0.2486585731594182, 0.2982615593691479, 0.20427334511535644, 0.14482677414767275, 0.2142250291692649, 0.22477244001026342, 0.3257197831588745, 0.24772371446396124, 0.32362979613296705, 0.29794614650487805, 0.3008418514325608, 0.27329101533637123, 0.3687564443738095, 0.37003364144387274, 0.4211559739464713, 0.22935764591937535, 0.20112611965651228, 0.2280893444027875, 0.19404332512886424, 0.30707955589161673, 0.278023091807182, 0.2318999733885938, 0.2782371921388297, 0.23275647886321438, 0.22460621596141916, 0.22701200150932987, 0.22196485344678207, 0.22034344797611816, 0.1866607827895015, 0.24100962016410366, 0.21403097167689178, 0.22158304005899376, 0.2569939567030286, 0.1992490513200561, 0.18436488943224083, 0.235120567988633, 0.20734618589474563, 0.20604442075402318, 0.21326787322269636, 0.20456913470752303, 0.19584143928549003, 0.180270804033961, 0.17115456025434872, 0.18742309719537187, 0.16789629116952398, 0.7905392932015467, 0.19846618684789763, 0.19645010558448073, 0.14191858017877745, 0.1595902280022774, 0.8745871278792722, 0.8064138047110574, 0.2104111183994014, 0.1602067218122103, 0.20349053038186993, 0.46560282945857856, 0.6688958290270746, 0.20353350111990365, 0.20820074677791545, 0.814633601170078, 0.20809768860026834, 0.1858751321906602, 0.18583918654372755, 0.21218750791370966, 0.22673815306871792, 0.18989769503467147, 0.18475083033178608, 0.22919510954194533, 0.17911779486513624, 0.09171741719011539, 0.09560352550617901, 0.0974962613402417, 0.09419414846338459, 0.08498807777830386, 0.08233753293068768, 0.0912395989486533, 0.08707546044200865, 0.07255583058474857]}, "mutation_prompt": null}
{"id": "0417c305-d286-4995-b105-d0514e2bc6e8", "solution": "import numpy as np\n\nclass RefinedAdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // (dim * 3))  # Slightly reduced population size\n        self.w = 0.3 + 0.6 * np.random.rand()  # Adjusted inertia weight range\n        self.c1 = 1.3 + 0.2 * np.random.rand()  # Slightly altered cognitive component range\n        self.c2 = 1.5 + 0.2 * np.random.rand()  # Slightly altered social component range\n        self.F = 0.4 + 0.3 * np.random.rand()  # Adjusted differential weight range\n        self.CR = 0.5 + 0.4 * np.random.rand()  # Broadened crossover rate range\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust', 'CR_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.2, self.c1 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c1 + 0.05)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.2, self.c2 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c2 + 0.05)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.1, self.w - 0.03) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.w + 0.03)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.3, self.F - 0.03) if self.global_best_score < np.median(self.personal_best_scores) else min(0.8, self.F + 0.03)\n            elif learning_strategy == 'CR_adjust':\n                self.CR = max(0.1, self.CR - 0.02) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.CR + 0.02)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + (self.F + np.random.uniform(-0.05, 0.05)) * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "RefinedAdaptiveHybridPSODE", "description": "A refined adaptive hybrid algorithm integrating PSO, DE, and mutation strategies with probabilistic parameter adjustments for robust optimization across diverse landscapes.", "configspace": "", "generation": 37, "fitness": 0.27660339180693255, "feedback": "The algorithm RefinedAdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.23.", "error": "", "parent_id": "0e2e08ed-62ec-40dd-9293-dabf8f30e9bc", "metadata": {"aucs": [0.5276535389348682, 0.7469408383623388, 0.6538107267579247, 0.6170498075381897, 0.7507469211082078, 0.7067157852549311, 0.5338032229599001, 0.7676301486130321, 0.7250693265644521, 0.1940146718213699, 0.4270348194436484, 0.27298886891651586, 0.134977960181351, 0.4959202849528541, 0.32806662655580343, 0.02559479339772619, 0.4492057337711681, 0.351006647818901, 0.14772889734750516, 0.13137405190954543, 0.16243522030160606, 0.15804098177614545, 0.13841925319693038, 0.14546067155796505, 0.11301103727757167, 0.15494932469962408, 0.11142504074116477, 0.0906670428899119, 0.1201549081256853, 0.10157830825086545, 0.06883434259068943, 0.10333702049090332, 0.08766512571214247, 0.12701705906099336, 0.13364283477011285, 0.10095036171045269, 0.9770263928561532, 0.9771982237529259, 0.9856367445399646, 0.9509552557131176, 0.9672256188517149, 0.9763974784634055, 0.9773581062177763, 0.9669698329073068, 0.9759982256150235, 0.47857383244714335, 0.5404226959752843, 0.45808059199849993, 0.3873485179982459, 0.3049912166806603, 0.5085164552181736, 0.380385603664522, 0.08738602448806154, 0.5164032944976498, 0.6915680433152295, 0.2186355372157207, 0.23918859931434444, 0.20316144856747154, 0.27347708796708925, 0.20296300151426827, 0.12408611240416267, 0.17541275748317897, 0.6474252416951454, 0.19868233460872575, 0.15673540150132725, 0.26970930768056456, 0.15330990066458694, 0.128796314550936, 0.3508620112476214, 0.19878867859325267, 0.19088493913686555, 0.2890333939051204, 0.143746003214841, 0.1596676682549294, 0.31340942700667296, 0.25724408871623095, 0.2276921698119, 0.22662909163463008, 0.1692980395528677, 0.14548673114729682, 0.12626821455183002, 9.999999999998899e-05, 0.0013688346647915406, 0.12772464352073765, 0.07516879170238977, 9.999999999998899e-05, 9.999999999998899e-05, 0.006941126283584675, 9.999999999998899e-05, 0.023087632006658865, 0.07110372417332456, 0.05784966830083793, 0.22216401386128726, 0.02074694422135126, 0.033973176478595435, 0.19635990511806223, 0.09466242182817208, 0.1362267394250839, 0.2866496247846798, 0.02766812970225052, 0.16134138082830762, 0.1596815046697293, 0.07290901814417916, 0.29831100971102953, 0.05446024264672511, 0.06849848436381856, 0.07737050085097197, 0.06861700261277126, 0.14234821235888662, 0.22390845041140484, 0.18476571126804942, 0.14472321160082846, 0.15901620598436472, 0.22397920605110044, 0.06821115204095163, 0.1120603770584323, 0.0784387425214218, 0.43939686204684514, 0.6016495182994586, 0.5724614617119268, 0.4700910793813923, 0.4984721846997685, 0.20770554563174926, 0.5722922295529972, 0.5649971370029425, 0.5355106961343552, 0.1004985038827223, 0.1574126378041668, 0.07934981688031917, 0.13829308792173756, 0.10456130731592805, 0.12044580350915568, 0.1285047181433201, 0.13228057865871234, 0.14591145970331287, 0.19963213966775384, 0.23599291299446734, 0.18255269609918212, 0.16228081687340856, 0.268175381485932, 0.24488126652754127, 0.32535257636530346, 0.25450283291501474, 0.25899184241774176, 0.285599791357805, 0.36219963381818165, 0.38557804228220516, 0.3783001211765955, 0.4214599724263933, 0.23178655080572452, 0.27903784872079285, 0.38809205071724395, 0.39162601253536067, 0.19854813845978014, 0.22304918613425773, 0.3018147693475015, 0.3031488453465465, 0.24130255106988407, 0.31589555450867524, 0.20064477208893827, 0.2678358000825213, 0.1450853532459141, 0.21690385233878995, 0.16517742901403487, 0.19598039217142116, 0.2244662911369104, 0.2179870977817101, 0.20979156872058424, 0.23274942232029638, 0.20991050753697205, 0.2526944182403935, 0.1952968042290104, 0.20419025958838255, 0.21646258582327038, 0.18997877726329193, 0.3945482190050339, 0.2048404849237765, 0.17860505999639298, 0.20163345099909602, 0.2021117225749437, 0.16254158111599504, 0.17725421333285518, 0.16827750859995172, 0.7491275071877768, 0.20035523244063191, 0.19875792024642236, 0.14007059760391372, 0.1629997306657086, 0.8557810324744677, 0.7988550440382908, 0.21287591066959655, 0.12160626468018021, 0.7631814665909987, 0.8215474812335263, 0.1501151919543119, 0.10377312701017238, 0.20966711105066393, 0.7130134128427811, 0.19563296371160666, 0.19232922740145164, 0.19720606778441807, 0.19732909706526336, 0.2031433244081784, 0.195709019513996, 0.21177840690505345, 0.1861724107744167, 0.20605121131486326, 0.08462970182922525, 0.08977681037209184, 0.10091966813454711, 0.09089683244667723, 0.0934524191251086, 0.09243651438099731, 0.08637288816389299, 0.1068906115328715, 0.08458103857851784]}, "mutation_prompt": null}
{"id": "baa2e225-33d2-498b-8352-a3d628ea5077", "solution": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.4 * np.random.rand()\n        self.c1 = 1.5 + 0.1 * np.random.rand()\n        self.c2 = 1.7 + 0.1 * np.random.rand()\n        self.F = 0.5 + 0.3 * np.random.rand()\n        self.CR = 0.6 + 0.3 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.3, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.1, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.3, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.1, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.2, self.w - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.w + 0.05)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.F + 0.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + (self.F + np.random.uniform(-0.1, 0.1)) * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveHybridPSODE", "description": "A self-adaptive hybrid metaheuristic combining Particle Swarm Optimization with Differential Evolution and dynamic parameter tuning for enhanced exploration and exploitation balance.", "configspace": "", "generation": 34, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0e2e08ed-62ec-40dd-9293-dabf8f30e9bc", "metadata": {"aucs": [0.825141622776838, 0.8120693277462817, 0.8501530083740372, 0.8363022406330953, 0.8336657123516347, 0.8239481322970122, 0.8362003044353954, 0.8296392953842565, 0.8514751909387689, 0.4296731325830522, 0.6443300329361493, 0.523070693809043, 0.6103168846727539, 0.6016538812291198, 0.5793577699337508, 0.5847602226496261, 0.598764283422311, 0.055046743225962036, 0.5405355240874355, 0.09133631626306737, 0.15471301895866163, 0.13375163082765407, 0.10819228845014828, 0.09488841903913703, 0.11233442919449277, 0.11093314911075591, 0.10732132716175746, 0.10925939511176708, 0.0989937665844014, 0.09578457751621938, 0.13015552458307922, 0.12139575928975332, 0.13337819625906266, 0.10311813058426456, 0.10778973208458975, 0.12442038574039449, 0.972220025547068, 0.9614389952101992, 0.9823125850947719, 0.9766430789598309, 0.9813326098271022, 0.9718802496489429, 0.9732033593650766, 0.984733714867437, 0.9732427834814551, 0.676594358200103, 0.6546894252815755, 0.6398731686348615, 0.5449825692655899, 0.6603012266180183, 0.637839187292507, 0.0863029367861835, 0.466224173836423, 0.6459803598621269, 0.7530509205705529, 0.2985554183714586, 0.24525214908974702, 0.21203090677582537, 0.8787990856303358, 0.5113074943537325, 0.5901447903229731, 0.330455194235894, 0.6688590727848529, 0.4575864596816348, 0.11854863208277167, 0.40690092946824175, 0.11820897707918632, 0.6405068610853691, 0.47183605180869037, 0.29635015413561416, 0.16118626452698737, 0.4616158635442057, 0.5213949016003943, 0.12249200548056383, 0.5191431310747969, 0.40190829945846585, 0.1248902774746048, 0.22446754264450963, 0.2374032925379974, 0.43308249291165557, 0.12019313347018379, 0.06432332679699115, 0.04246188400058615, 0.0673954788712674, 0.0658161964455547, 9.999999999998899e-05, 0.010362112892801867, 0.05651239034603173, 0.08777002057238736, 0.2241260960771151, 0.20946738278016963, 0.09689850614586104, 0.6354490810201769, 0.08046909382312495, 0.15285902735395995, 0.1716971904975899, 0.25109825514178497, 0.24735677922411814, 0.09045387581746855, 0.20417744606471966, 0.02570123079379083, 0.2504210024104768, 0.12341603588939465, 0.3148029351281503, 0.0932378594894473, 0.09160228922029579, 0.06827752758898264, 0.09704120717120168, 0.12521371652468039, 0.1920370344184993, 0.1793794559908667, 0.29014444250396176, 0.17696365609309272, 0.2712292788252557, 0.047847950575011566, 0.05504668916023314, 0.0801127949207543, 0.6214901852055023, 0.6056548931223997, 0.6174476336968586, 0.6390139785474849, 0.6465227145013246, 0.6380802580211248, 0.6657994005262944, 0.6668528159397854, 0.58672407794648, 0.11877793753860277, 0.07227657792737696, 0.09540894484387263, 0.13557015259811012, 0.08363642820582595, 0.18098512804450695, 0.11305513592808125, 0.10159908034191667, 0.09340957881660283, 0.21564682981578043, 0.23337705145033272, 0.3105153784957737, 0.27489611883782916, 0.3379031978712276, 0.26878792821051867, 0.3103427756817426, 0.13573669202813832, 0.209256986199006, 0.312829784270525, 0.24334628103154965, 0.3442934159857608, 0.3309407160655743, 0.2990812493972185, 0.20257845916079265, 0.5308228292237176, 0.4669375022421727, 0.4648813621834931, 0.2576168967738627, 0.1723598472848138, 0.4032296700951725, 0.24002359527307804, 0.1753776068166797, 0.20398053901422641, 0.28700223310534, 0.20086865347381333, 0.21841069083744935, 0.20936268176547124, 0.2088249567245788, 0.19613042995958108, 0.20258276731514646, 0.23983913145267377, 0.23099057111462684, 0.20134488169078424, 0.2404970539148943, 0.23584876849151448, 0.676694484306926, 0.20341884823507406, 0.19407400142073006, 0.18739680163371475, 0.21040562400373064, 0.19077503271430607, 0.201544130621379, 0.20687929069725253, 0.1704409569210127, 0.16363260279278713, 0.18772401421256857, 0.16786395854308322, 0.8977222891276675, 0.1996739552682939, 0.19865997390253753, 0.14261855716983096, 0.16168512672579927, 0.8836962044971286, 0.8527857176176817, 0.20939174454924403, 0.0733828669044797, 0.8087409699505768, 0.16673631224162944, 0.1453015328602596, 0.8440621927212109, 0.1946981164049002, 0.789605549755048, 0.19930177930795256, 0.20681401416925427, 0.2193459307132256, 0.22142824298048558, 0.20017724471191056, 0.19841700669245255, 0.21150907133587427, 0.1927579985954796, 0.22722489036021498, 0.09574606993209178, 0.09229398907112352, 0.09556356032026092, 0.08251999767518503, 0.08450731898885966, 0.09224443378001701, 0.08203387151995789, 0.08094938264794582, 0.09477818284969508]}, "mutation_prompt": null}
{"id": "938ae7e2-1ce9-48e9-a94f-7d0b4a48859e", "solution": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.4 * np.random.rand()\n        self.c1 = 1.5 + 0.1 * np.random.rand()\n        self.c2 = 1.7 + 0.1 * np.random.rand()\n        self.F = 0.5 + 0.3 * np.random.rand()\n        self.CR = 0.6 + 0.3 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.3, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.1, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.3, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.1, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.2, self.w - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.w + 0.05)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.F + 0.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + (self.F + np.random.uniform(-0.1, 0.1)) * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveHybridPSODE", "description": "A self-adaptive hybrid metaheuristic combining Particle Swarm Optimization with Differential Evolution and dynamic parameter tuning for enhanced exploration and exploitation balance.", "configspace": "", "generation": 34, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0e2e08ed-62ec-40dd-9293-dabf8f30e9bc", "metadata": {"aucs": [0.825141622776838, 0.8120693277462817, 0.8501530083740372, 0.8363022406330953, 0.8336657123516347, 0.8239481322970122, 0.8362003044353954, 0.8296392953842565, 0.8514751909387689, 0.4296731325830522, 0.6443300329361493, 0.523070693809043, 0.6103168846727539, 0.6016538812291198, 0.5793577699337508, 0.5847602226496261, 0.598764283422311, 0.055046743225962036, 0.5405355240874355, 0.09133631626306737, 0.15471301895866163, 0.13375163082765407, 0.10819228845014828, 0.09488841903913703, 0.11233442919449277, 0.11093314911075591, 0.10732132716175746, 0.10925939511176708, 0.0989937665844014, 0.09578457751621938, 0.13015552458307922, 0.12139575928975332, 0.13337819625906266, 0.10311813058426456, 0.10778973208458975, 0.12442038574039449, 0.972220025547068, 0.9614389952101992, 0.9823125850947719, 0.9766430789598309, 0.9813326098271022, 0.9718802496489429, 0.9732033593650766, 0.984733714867437, 0.9732427834814551, 0.676594358200103, 0.6546894252815755, 0.6398731686348615, 0.5449825692655899, 0.6603012266180183, 0.637839187292507, 0.0863029367861835, 0.466224173836423, 0.6459803598621269, 0.7530509205705529, 0.2985554183714586, 0.24525214908974702, 0.21203090677582537, 0.8787990856303358, 0.5113074943537325, 0.5901447903229731, 0.330455194235894, 0.6688590727848529, 0.4575864596816348, 0.11854863208277167, 0.40690092946824175, 0.11820897707918632, 0.6405068610853691, 0.47183605180869037, 0.29635015413561416, 0.16118626452698737, 0.4616158635442057, 0.5213949016003943, 0.12249200548056383, 0.5191431310747969, 0.40190829945846585, 0.1248902774746048, 0.22446754264450963, 0.2374032925379974, 0.43308249291165557, 0.12019313347018379, 0.06432332679699115, 0.04246188400058615, 0.0673954788712674, 0.0658161964455547, 9.999999999998899e-05, 0.010362112892801867, 0.05651239034603173, 0.08777002057238736, 0.2241260960771151, 0.20946738278016963, 0.09689850614586104, 0.6354490810201769, 0.08046909382312495, 0.15285902735395995, 0.1716971904975899, 0.25109825514178497, 0.24735677922411814, 0.09045387581746855, 0.20417744606471966, 0.02570123079379083, 0.2504210024104768, 0.12341603588939465, 0.3148029351281503, 0.0932378594894473, 0.09160228922029579, 0.06827752758898264, 0.09704120717120168, 0.12521371652468039, 0.1920370344184993, 0.1793794559908667, 0.29014444250396176, 0.17696365609309272, 0.2712292788252557, 0.047847950575011566, 0.05504668916023314, 0.0801127949207543, 0.6214901852055023, 0.6056548931223997, 0.6174476336968586, 0.6390139785474849, 0.6465227145013246, 0.6380802580211248, 0.6657994005262944, 0.6668528159397854, 0.58672407794648, 0.11877793753860277, 0.07227657792737696, 0.09540894484387263, 0.13557015259811012, 0.08363642820582595, 0.18098512804450695, 0.11305513592808125, 0.10159908034191667, 0.09340957881660283, 0.21564682981578043, 0.23337705145033272, 0.3105153784957737, 0.27489611883782916, 0.3379031978712276, 0.26878792821051867, 0.3103427756817426, 0.13573669202813832, 0.209256986199006, 0.312829784270525, 0.24334628103154965, 0.3442934159857608, 0.3309407160655743, 0.2990812493972185, 0.20257845916079265, 0.5308228292237176, 0.4669375022421727, 0.4648813621834931, 0.2576168967738627, 0.1723598472848138, 0.4032296700951725, 0.24002359527307804, 0.1753776068166797, 0.20398053901422641, 0.28700223310534, 0.20086865347381333, 0.21841069083744935, 0.20936268176547124, 0.2088249567245788, 0.19613042995958108, 0.20258276731514646, 0.23983913145267377, 0.23099057111462684, 0.20134488169078424, 0.2404970539148943, 0.23584876849151448, 0.676694484306926, 0.20341884823507406, 0.19407400142073006, 0.18739680163371475, 0.21040562400373064, 0.19077503271430607, 0.201544130621379, 0.20687929069725253, 0.1704409569210127, 0.16363260279278713, 0.18772401421256857, 0.16786395854308322, 0.8977222891276675, 0.1996739552682939, 0.19865997390253753, 0.14261855716983096, 0.16168512672579927, 0.8836962044971286, 0.8527857176176817, 0.20939174454924403, 0.0733828669044797, 0.8087409699505768, 0.16673631224162944, 0.1453015328602596, 0.8440621927212109, 0.1946981164049002, 0.789605549755048, 0.19930177930795256, 0.20681401416925427, 0.2193459307132256, 0.22142824298048558, 0.20017724471191056, 0.19841700669245255, 0.21150907133587427, 0.1927579985954796, 0.22722489036021498, 0.09574606993209178, 0.09229398907112352, 0.09556356032026092, 0.08251999767518503, 0.08450731898885966, 0.09224443378001701, 0.08203387151995789, 0.08094938264794582, 0.09477818284969508]}, "mutation_prompt": null}
{"id": "173f671e-c203-4d82-a85e-959bc7fc95e9", "solution": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.4 * np.random.rand()\n        self.c1 = 1.5 + 0.1 * np.random.rand()\n        self.c2 = 1.7 + 0.1 * np.random.rand()\n        self.F = 0.5 + 0.3 * np.random.rand()\n        self.CR = 0.6 + 0.3 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.3, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.1, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.3, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.1, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.2, self.w - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.w + 0.05)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.F + 0.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + (self.F + np.random.uniform(-0.1, 0.1)) * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveHybridPSODE", "description": "A self-adaptive hybrid metaheuristic combining Particle Swarm Optimization with Differential Evolution and dynamic parameter tuning for enhanced exploration and exploitation balance.", "configspace": "", "generation": 34, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0e2e08ed-62ec-40dd-9293-dabf8f30e9bc", "metadata": {"aucs": [0.825141622776838, 0.8120693277462817, 0.8501530083740372, 0.8363022406330953, 0.8336657123516347, 0.8239481322970122, 0.8362003044353954, 0.8296392953842565, 0.8514751909387689, 0.4296731325830522, 0.6443300329361493, 0.523070693809043, 0.6103168846727539, 0.6016538812291198, 0.5793577699337508, 0.5847602226496261, 0.598764283422311, 0.055046743225962036, 0.5405355240874355, 0.09133631626306737, 0.15471301895866163, 0.13375163082765407, 0.10819228845014828, 0.09488841903913703, 0.11233442919449277, 0.11093314911075591, 0.10732132716175746, 0.10925939511176708, 0.0989937665844014, 0.09578457751621938, 0.13015552458307922, 0.12139575928975332, 0.13337819625906266, 0.10311813058426456, 0.10778973208458975, 0.12442038574039449, 0.972220025547068, 0.9614389952101992, 0.9823125850947719, 0.9766430789598309, 0.9813326098271022, 0.9718802496489429, 0.9732033593650766, 0.984733714867437, 0.9732427834814551, 0.676594358200103, 0.6546894252815755, 0.6398731686348615, 0.5449825692655899, 0.6603012266180183, 0.637839187292507, 0.0863029367861835, 0.466224173836423, 0.6459803598621269, 0.7530509205705529, 0.2985554183714586, 0.24525214908974702, 0.21203090677582537, 0.8787990856303358, 0.5113074943537325, 0.5901447903229731, 0.330455194235894, 0.6688590727848529, 0.4575864596816348, 0.11854863208277167, 0.40690092946824175, 0.11820897707918632, 0.6405068610853691, 0.47183605180869037, 0.29635015413561416, 0.16118626452698737, 0.4616158635442057, 0.5213949016003943, 0.12249200548056383, 0.5191431310747969, 0.40190829945846585, 0.1248902774746048, 0.22446754264450963, 0.2374032925379974, 0.43308249291165557, 0.12019313347018379, 0.06432332679699115, 0.04246188400058615, 0.0673954788712674, 0.0658161964455547, 9.999999999998899e-05, 0.010362112892801867, 0.05651239034603173, 0.08777002057238736, 0.2241260960771151, 0.20946738278016963, 0.09689850614586104, 0.6354490810201769, 0.08046909382312495, 0.15285902735395995, 0.1716971904975899, 0.25109825514178497, 0.24735677922411814, 0.09045387581746855, 0.20417744606471966, 0.02570123079379083, 0.2504210024104768, 0.12341603588939465, 0.3148029351281503, 0.0932378594894473, 0.09160228922029579, 0.06827752758898264, 0.09704120717120168, 0.12521371652468039, 0.1920370344184993, 0.1793794559908667, 0.29014444250396176, 0.17696365609309272, 0.2712292788252557, 0.047847950575011566, 0.05504668916023314, 0.0801127949207543, 0.6214901852055023, 0.6056548931223997, 0.6174476336968586, 0.6390139785474849, 0.6465227145013246, 0.6380802580211248, 0.6657994005262944, 0.6668528159397854, 0.58672407794648, 0.11877793753860277, 0.07227657792737696, 0.09540894484387263, 0.13557015259811012, 0.08363642820582595, 0.18098512804450695, 0.11305513592808125, 0.10159908034191667, 0.09340957881660283, 0.21564682981578043, 0.23337705145033272, 0.3105153784957737, 0.27489611883782916, 0.3379031978712276, 0.26878792821051867, 0.3103427756817426, 0.13573669202813832, 0.209256986199006, 0.312829784270525, 0.24334628103154965, 0.3442934159857608, 0.3309407160655743, 0.2990812493972185, 0.20257845916079265, 0.5308228292237176, 0.4669375022421727, 0.4648813621834931, 0.2576168967738627, 0.1723598472848138, 0.4032296700951725, 0.24002359527307804, 0.1753776068166797, 0.20398053901422641, 0.28700223310534, 0.20086865347381333, 0.21841069083744935, 0.20936268176547124, 0.2088249567245788, 0.19613042995958108, 0.20258276731514646, 0.23983913145267377, 0.23099057111462684, 0.20134488169078424, 0.2404970539148943, 0.23584876849151448, 0.676694484306926, 0.20341884823507406, 0.19407400142073006, 0.18739680163371475, 0.21040562400373064, 0.19077503271430607, 0.201544130621379, 0.20687929069725253, 0.1704409569210127, 0.16363260279278713, 0.18772401421256857, 0.16786395854308322, 0.8977222891276675, 0.1996739552682939, 0.19865997390253753, 0.14261855716983096, 0.16168512672579927, 0.8836962044971286, 0.8527857176176817, 0.20939174454924403, 0.0733828669044797, 0.8087409699505768, 0.16673631224162944, 0.1453015328602596, 0.8440621927212109, 0.1946981164049002, 0.789605549755048, 0.19930177930795256, 0.20681401416925427, 0.2193459307132256, 0.22142824298048558, 0.20017724471191056, 0.19841700669245255, 0.21150907133587427, 0.1927579985954796, 0.22722489036021498, 0.09574606993209178, 0.09229398907112352, 0.09556356032026092, 0.08251999767518503, 0.08450731898885966, 0.09224443378001701, 0.08203387151995789, 0.08094938264794582, 0.09477818284969508]}, "mutation_prompt": null}
{"id": "345ed29e-19f0-40ff-acf4-cf917973bf2b", "solution": "import numpy as np\n\nclass DynamicHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.4 * np.random.rand()\n        self.c1 = 1.5 + 0.2 * np.random.rand()\n        self.c2 = 1.7 + 0.2 * np.random.rand()\n        self.F = 0.5 + 0.25 * np.random.rand()\n        self.CR = 0.6 + 0.35 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.3, self.c1 - 0.1) if self.global_best_score < np.percentile(self.personal_best_scores, 75) else min(2.1, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.3, self.c2 - 0.1) if self.global_best_score < np.percentile(self.personal_best_scores, 75) else min(2.1, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.2, self.w - 0.05) if self.global_best_score < np.percentile(self.personal_best_scores, 75) else min(1.0, self.w + 0.05)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.05) if self.global_best_score < np.percentile(self.personal_best_scores, 75) else min(0.9, self.F + 0.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + (self.F + np.random.uniform(-0.05, 0.05)) * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "DynamicHybridPSODE", "description": "A dynamic self-adaptive hybrid metaheuristic leveraging Particle Swarm Optimization and Differential Evolution with stochastic parameter adjustments to enhance search efficiency.", "configspace": "", "generation": 41, "fitness": 0.32937918865438853, "feedback": "The algorithm DynamicHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.27.", "error": "", "parent_id": "0e2e08ed-62ec-40dd-9293-dabf8f30e9bc", "metadata": {"aucs": [0.8198808379353653, 0.8216835039110917, 0.8365988339671073, 0.8245752835348523, 0.8320588290339439, 0.813081244568061, 0.8246207042873884, 0.8345928592400362, 0.8373768311520098, 0.5000513161519784, 0.039676090855986335, 0.5616457286080226, 0.5808462332182338, 0.6205597008201507, 0.6471639305890591, 0.5391373773829993, 0.6663181944265972, 0.590536733272382, 0.11110544421320645, 0.10960516792812192, 0.12598690515904998, 0.14279964038404813, 0.14279602031259875, 0.12031806282791713, 0.17701765824839932, 0.15325240930041129, 0.15551159012915106, 0.12730083974855078, 0.09976583664038607, 0.12276800437726432, 0.11304087420354059, 0.1111917424258696, 0.05447989353306126, 0.1508097879713991, 0.08825845131631671, 0.10639968694030666, 0.9791923217745354, 0.9614567605152226, 0.9822433252993409, 0.9767127043237888, 0.9813060036039548, 0.9718632354764463, 0.9734525407173928, 0.9847337159804879, 0.9734751919899145, 0.5967655239397145, 0.6563703434169522, 0.5900555820974636, 0.5852082300149135, 0.6170928540329316, 0.6372723975410257, 0.5860201697452039, 0.6370908886136691, 0.6150494552114849, 0.21945625854503248, 0.23683643477393868, 0.818749410664128, 0.21668832070398736, 0.21116231071791491, 0.8723849759145219, 0.31692624149985327, 0.8025771752938748, 0.8644292888631331, 0.12644096832554863, 0.11148467887385793, 0.4541228965939843, 0.23203632060906976, 0.18291951443572074, 9.999999999998899e-05, 0.1279684696686565, 0.24279087609135364, 0.6076353213776685, 0.42599949522715186, 0.11687307154860427, 0.5176841545636454, 0.4841679710224467, 0.12530044247834016, 0.30961966257483686, 0.2945747211506736, 0.12667996782784718, 0.11394190578723506, 0.03628718387878527, 0.055250134486746316, 0.0674559006771227, 0.0005921238198739465, 0.13582072594233996, 9.999999999998899e-05, 0.20191263811687776, 0.06937127224054007, 0.0047424683205690155, 0.24814824857073658, 0.1703994952109682, 0.1299986181440803, 0.11680926854427776, 0.20899889867172694, 0.16109707349669844, 0.2690413994047731, 0.324671612636957, 0.14103747653973953, 0.19621865217213263, 0.04851205537235115, 0.27017352683337803, 0.12479604111622578, 0.17482474767948641, 0.09226973012310624, 0.09308925794217526, 0.06823478153278062, 0.23549194229784465, 0.19719565621327384, 0.21023723033561537, 0.2723162564555378, 0.201113290001809, 0.21886757177598715, 0.20360073141930402, 0.053202278122278956, 0.15502586627980652, 0.08348724698533383, 0.590504084557339, 0.6252650803135793, 0.7683011251596399, 0.6311381821635186, 0.590378626993509, 0.5392874004737498, 0.6831462940535937, 0.6399498638682932, 0.7222019273812307, 0.10538218241248165, 0.07157502023959583, 0.13817037456565917, 0.10088225708848508, 0.07403735898485209, 0.121450260709843, 0.12484168357794101, 0.11161413249343421, 0.11329620823405129, 0.23335310261618025, 0.2621425209272126, 0.17776254614651976, 0.21391283687813833, 0.3636681341549969, 0.2768290536991713, 0.22345358942842974, 0.3008762169871928, 0.18730040817935678, 0.40678419295463686, 0.26593381982261277, 0.3270804369870326, 0.37725641445355795, 0.26455778205630087, 0.37627243885806594, 0.484045442523246, 0.5845454527657885, 0.3286462018543108, 0.25572124888323366, 0.2767143974942332, 0.3374673657693793, 0.17389703591587535, 0.18692225360198256, 0.20790254334656988, 0.14981315299999898, 0.23504938701702527, 0.18043953850190664, 0.23913144203172998, 0.22423306512742225, 0.2116741649743087, 0.20848148511659415, 0.23776416754557994, 0.20019449497915276, 0.1936750052355063, 0.2389709171127482, 0.2211268417641561, 0.18619012995350648, 0.18444672458943445, 0.18562882085444543, 0.2087851388127846, 0.1941513143690239, 0.18812933761211392, 0.22030433870584232, 0.19548535322723826, 0.22144745379881658, 0.814680193405317, 0.18779238926587827, 0.1677326473781432, 0.8992541480874432, 0.1996042920362715, 0.19822857902282898, 0.14212598694044154, 0.16026969523629198, 0.9074406454756332, 0.8429372129904813, 0.21029529109505385, 0.0734193576807205, 0.7845052461967348, 0.16721719429644943, 0.15230916469124733, 0.20821186332233788, 0.20767642182659052, 0.8389638455028801, 0.2123722988316067, 0.19161801143566903, 0.20397833996603743, 0.196153457675611, 0.1880432918078665, 0.1971888981045592, 0.202064053109953, 0.19980227320343613, 0.2468787201052821, 0.09780154978431344, 0.09249436952482304, 0.10525815520746507, 0.0965171464312311, 0.10258971408990036, 0.10188321315158189, 0.09356470502761627, 0.08760161125288946, 0.08972524287961403]}, "mutation_prompt": null}
{"id": "ccf610db-aae4-46f8-b358-27eb710f33ed", "solution": "import numpy as np\n\nclass EvoIntegratedPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.4 + 0.3 * np.random.rand()\n        self.c1 = 1.4 + 0.2 * np.random.rand()\n        self.c2 = 1.6 + 0.2 * np.random.rand()\n        self.F = 0.6 + 0.2 * np.random.rand()\n        self.CR = 0.7 + 0.2 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        strategy_pool = ['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust', 'CR_adjust']\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            learning_strategy = np.random.choice(strategy_pool)\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.3, self.c1 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(2.4, self.c1 + 0.05)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.3, self.c2 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(2.4, self.c2 + 0.05)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.2, self.w - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.w + 0.05)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.F + 0.05)\n            elif learning_strategy == 'CR_adjust':\n                self.CR = max(0.5, self.CR - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.CR + 0.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.population[a] + (self.F + np.random.uniform(-0.1, 0.1)) * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EvoIntegratedPSODE", "description": "An Evolutionary Integrated Metaheuristic combining Particle Swarm Optimization and Differential Evolution with adaptive strategies for improved convergence and diversity.", "configspace": "", "generation": 42, "fitness": 0.30989590705766856, "feedback": "The algorithm EvoIntegratedPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.26.", "error": "", "parent_id": "0e2e08ed-62ec-40dd-9293-dabf8f30e9bc", "metadata": {"aucs": [0.7573484095248768, 0.8314296057397395, 0.7888278853511843, 0.7737324297682088, 0.842188225290847, 0.800731295536495, 0.7805410404502603, 0.8351194611403973, 0.8020760112971868, 0.5843506168432127, 0.2069128993829964, 0.45613041517992303, 0.555320158471388, 0.669189012412988, 0.6185918870977277, 0.14223437176164555, 0.6058312520097742, 0.6392483631329611, 0.164979874715261, 0.08970505196664358, 0.17466317819129618, 0.13234105384226647, 0.12372214056081432, 0.16339603578321826, 0.1174403536699512, 0.12406774384545427, 0.10573796623638243, 0.10712090486153192, 0.07579493702388318, 0.1025014548761416, 0.10808303128663921, 0.10387010288036069, 0.09769047088264038, 0.13896790001678783, 0.10206115274381877, 0.1405942201646545, 0.9736638706759555, 0.9609978017472245, 0.9836291464191081, 0.9690289447163719, 0.9608204531078488, 0.9719667110824945, 0.9796867211967741, 0.9830448763304475, 0.9734086155753946, 0.6303226315004333, 0.6752330120465821, 0.5012486600555077, 0.17770680526680316, 0.5845353111677964, 0.14979675087729338, 0.5486788778064042, 0.08752926992982102, 0.5366002854265575, 0.7509818491059892, 0.8515546772233393, 0.5036743307487404, 0.7519337957741893, 0.27493598784370643, 0.18987137167501544, 0.22900649441453935, 0.1745940567561194, 0.237807020602943, 0.19192734973761139, 0.14535584230169207, 0.1604370196653877, 0.1747519575670875, 0.1274387927990014, 0.10277486788082857, 0.18243128520982888, 0.12177645978662532, 0.2628860460179657, 0.4419323116425853, 0.15997639823599563, 0.235187773180637, 0.1863547565001955, 0.17004492501420787, 0.17008039952150844, 0.17394326030592255, 0.20922112117963743, 0.23050321832318654, 0.06937882037173182, 0.07257013984809568, 0.05765170583285939, 0.01740011264304664, 0.11200089690313164, 9.999999999998899e-05, 0.08072245214912055, 9.999999999998899e-05, 0.005185214583144027, 0.07095611659295842, 0.1578977776268815, 0.16770318872072187, 0.01643320630209677, 0.2088165900177028, 0.10805746271152095, 0.09350624693105969, 0.09157689230412858, 0.34420978338879904, 0.1250707902634185, 0.07519686673909365, 0.2600815274342614, 0.1171931601108196, 0.07032907422817569, 0.20620532952979087, 0.0829602014914288, 0.1564208244741876, 0.0641349146476361, 0.14733436284041457, 0.13500698213548656, 0.2512778191598667, 0.1085598554949998, 0.07961867146714885, 0.1352198292609179, 0.044889941711031445, 0.07870311580627609, 0.2537452524035614, 0.5726986494601052, 0.5647151909707134, 0.6241757942257536, 0.6274138992747669, 0.6192454054348322, 0.4843489056567297, 0.5621181719677033, 0.641386438930529, 0.5496370950393521, 0.10174613294548818, 0.09255977752644562, 0.0811840246583242, 0.13522420161790594, 0.08891271488195873, 0.10762100569535882, 0.14483523751391636, 0.09256290851825566, 0.06102495113737749, 0.15209606606004877, 0.22396522462704438, 0.22151949487400946, 0.3121737271743178, 0.4236979747966265, 0.27926298269808436, 0.27043991178594096, 0.16458299333896198, 0.20075187996136357, 0.2510229253323307, 0.437437799285902, 0.3976245536123889, 0.4346716528052951, 0.3980428360067062, 0.32436325083002593, 0.4803346625523274, 0.49873648553290295, 0.4527296670743717, 0.3272987613385836, 0.16690211270197974, 0.2542445982710284, 0.2574899733570366, 0.2422919343644988, 0.35474757016060854, 0.37813983463562995, 0.26232405634677236, 0.16455396815299228, 0.20454506238615489, 0.18141216961777784, 0.203122803550022, 0.26835293010006234, 0.2326871151844544, 0.24962640818739779, 0.2039096311671027, 0.2370292771757696, 0.24682996766977916, 0.18134563865769038, 0.2060184668956665, 0.18316433997035142, 0.23993195283920332, 0.20719083479058642, 0.20342874964932312, 0.6392946126644456, 0.19256213851112858, 0.18068400382054028, 0.8380485539716764, 0.1778388074537004, 0.16859026140021105, 0.870521337915475, 0.19864125734542493, 0.19945077261646071, 0.14111714501390182, 0.16170039745323506, 0.8557967974733725, 0.787507827993849, 0.21101036498984882, 0.7322066665427749, 0.7332954504832693, 0.1688027810545909, 0.16888961838346872, 0.10415961603355894, 0.20819637379394873, 0.790036804514241, 0.1914768346244281, 0.18625322824117352, 0.2136376410397396, 0.21525350377305108, 0.24253141512870302, 0.2136491697567452, 0.19432234525934167, 0.19436847748121155, 0.1840179097291238, 0.10236067203348265, 0.09235716417843287, 0.09907644584823616, 0.07342610523269177, 0.10764226234130714, 0.08550349260746681, 0.11836431709042827, 0.08655564682094119, 0.08887679885776667]}, "mutation_prompt": null}
{"id": "762f5696-d9c4-42fa-a919-63e374281f63", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.4 * np.random.rand()\n        self.c1 = 1.5 + 0.1 * np.random.rand()\n        self.c2 = 1.7 + 0.1 * np.random.rand()\n        self.F = 0.5 + 0.3 * np.random.rand()\n        self.CR = 0.6 + 0.3 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.4, self.c1 - 0.15) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c1 + 0.15)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.4, self.c2 - 0.15) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c2 + 0.15)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.w + 0.05)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.8, self.F + 0.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.1 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSODE", "description": "An enhanced adaptive hybrid algorithm boosting exploration-exploitation synergy through probabilistic mutation and learning strategy refinement.", "configspace": "", "generation": 43, "fitness": 0.3423217560864937, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.27.", "error": "", "parent_id": "0e2e08ed-62ec-40dd-9293-dabf8f30e9bc", "metadata": {"aucs": [0.7937168869588807, 0.8110840460577314, 0.8223124258026252, 0.8292334793015026, 0.8202705373520015, 0.8163661673418464, 0.8125309463706353, 0.8309340298974761, 0.8318134620986362, 0.036271978157934925, 0.46769062766129077, 0.5854499515612912, 0.5525228887733391, 0.5697050933427381, 0.5473268294949041, 0.5839843212732078, 0.6177205973473041, 9.999999999998899e-05, 0.12046799966568378, 0.16685181919533443, 0.10382292111213842, 0.10306651137265543, 0.13060423493780926, 0.11787659941018358, 0.16593100662388538, 0.11508489260969013, 0.15362971774268974, 0.11381256998177491, 0.09494188715498386, 0.10635529559181756, 0.11056971988888653, 0.09083774396250643, 0.09117902356562047, 0.1487032844981857, 0.11281600612383358, 0.1047879141675585, 0.9727413678611416, 0.973462333782434, 0.9823807152134303, 0.97212130492818, 0.9588214033568259, 0.9717012003398684, 0.9728032530485617, 0.9834415278744697, 0.9811084073632, 0.6628685524451319, 0.5681053144632513, 0.5422737438709716, 0.5942201542085449, 0.633610524854258, 0.6004661811128736, 0.33095606518960663, 0.3149925718092669, 0.6140301114910006, 0.8290993198872817, 0.8352112260909277, 0.8110082684827069, 0.7608394579074562, 0.8048905052753774, 0.20363178346083133, 0.22771431275162046, 0.3059496122529396, 0.22094501969105818, 0.5562267333066422, 0.3725033692671391, 0.3136266048580676, 0.39765302298934735, 0.4398677045717372, 0.5808912232133165, 0.5045040804178315, 0.10969954793521042, 0.594336088869361, 0.535023621134219, 0.6691158926418432, 0.3259352004876469, 0.4475758196173597, 0.5671066435302291, 0.3861037538629155, 0.12679663200607816, 0.1259309216885236, 0.10744003794828316, 0.32757085991373114, 0.0939710552344275, 0.0796292981005865, 0.033968083948810124, 9.999999999998899e-05, 0.015520763292286022, 0.14011933683978894, 0.03334598454370041, 0.0032050583749565487, 0.27934937775688096, 0.17840647383260477, 0.16566370211452142, 0.10481805951806622, 0.28126126774015237, 0.06438669344891257, 0.06166599363804637, 0.5184285182868864, 0.43074307515230315, 0.055007788817744596, 0.05523225041881763, 0.18047033926296774, 0.1666570483965777, 0.1378715816978764, 0.08949287971976738, 0.08817317885916331, 0.13393789020303848, 0.3054265060526712, 0.1724323559659422, 0.22333745406108862, 0.2415717942129716, 0.2053186686855084, 0.2751569820065869, 0.17042075019231384, 0.05548258795862948, 0.34159923125308034, 0.24456826933972942, 0.6342176691063348, 0.7032744151802033, 0.6106561828785786, 0.696520496597643, 0.6122866220021006, 0.5867647802698883, 0.6671952706634485, 0.6937692983422221, 0.680991756935079, 0.09938716255489122, 0.13309207329995787, 0.14400728764393567, 0.1576245682365236, 0.10916533130952433, 0.14211515140614195, 0.10744747627600537, 0.17457994960276368, 0.09153246401914328, 0.4029633132440851, 0.21501979602252252, 0.1933997728207577, 0.21070312167466032, 0.15057286944809256, 0.20082930294380397, 0.1858007061855591, 0.20510082708258293, 0.17104660655426174, 0.24187068583536186, 0.2961653233389204, 0.31787273767918967, 0.42512373789847724, 0.25441679365720027, 0.28944809209488254, 0.29980672326650015, 0.4431278070040966, 0.43099715795167404, 0.3509096698651262, 0.19844657678328437, 0.2045611077229761, 0.26424814599703184, 0.298522046985763, 0.2325508656742007, 0.30780587841920437, 0.3537301092033054, 0.19451288748463635, 0.2367667290676273, 0.2698169581915112, 0.208466949072324, 0.2382615065585585, 0.20774315105788177, 0.21339017074841748, 0.2617982842990728, 0.20988612704259357, 0.2410527965596846, 0.18442745762114643, 0.21522927652552692, 0.20371607536939285, 0.21140161634612686, 0.24552325006583897, 0.19016198959451291, 0.1885774030280103, 0.21405944466071214, 0.17917418426783338, 0.8820038072216912, 0.18797273496638411, 0.16775676508227844, 0.8551008508181219, 0.19972180879725387, 0.16867762807422404, 0.14248315156447666, 0.1621351354534869, 0.890645140568866, 0.8686579739592029, 0.2110889064736431, 0.758366565441014, 0.8484040220975784, 0.1664007729139515, 0.15402910839378325, 0.20750218566508327, 0.10462921953600013, 0.7653158807106272, 0.19978979028414035, 0.21048991323522304, 0.1855109215264482, 0.1926534584098475, 0.20620448975996963, 0.19014272102240914, 0.21025539616067868, 0.24337046206653123, 0.19629103913591084, 0.13999637572775936, 0.08244721186777226, 0.07742380334609755, 0.10172689656667677, 0.08781925034764804, 0.08828881755806361, 0.09029180992402219, 0.0883695230650079, 0.08148607510276074]}, "mutation_prompt": null}
{"id": "8e6d0b50-85c7-4566-8c6b-72bba29ec497", "solution": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // (dim * 2))\n        self.w = 0.4 + 0.3 * np.random.rand()\n        self.c1 = 1.4 + 0.2 * np.random.rand()\n        self.c2 = 1.8 + 0.2 * np.random.rand()\n        self.F = 0.6 + 0.2 * np.random.rand()\n        self.CR = 0.7 + 0.2 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if np.random.rand() < 0.2:\n                adjust_parameter = np.random.choice(['c1', 'c2', 'w', 'F'])\n                if adjust_parameter == 'c1':\n                    self.c1 = max(0.5, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c1 + 0.1)\n                elif adjust_parameter == 'c2':\n                    self.c2 = max(0.5, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c2 + 0.1)\n                elif adjust_parameter == 'w':\n                    self.w = max(0.2, self.w - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.w + 0.1)\n                elif adjust_parameter == 'F':\n                    self.F = max(0.3, self.F - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.F + 0.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.05 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveHybridPSODE", "description": "Adaptive Particle Swarm and Differential Evolution hybrid optimizing exploration-exploitation balance through stochastic parameter tuning.", "configspace": "", "generation": 44, "fitness": 0.29426081437923163, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.25.", "error": "", "parent_id": "762f5696-d9c4-42fa-a919-63e374281f63", "metadata": {"aucs": [0.6776840721420363, 0.7064166349851131, 0.8276299207020972, 0.7287131911154933, 0.741103915940289, 0.7984959917864668, 0.6911397226174532, 0.7274399868799358, 0.8230065516259462, 0.3390371959350079, 0.43909407877093276, 0.5531816277206498, 0.365647981963534, 0.45547807738209256, 0.5270472443758332, 0.05115902198535727, 0.05008115372579525, 0.051683810736463554, 0.16742118515728632, 0.11110255195682162, 0.13713639418053536, 0.1182299973395704, 0.12681950640701323, 0.12764714747439043, 0.12284528330551747, 0.1348370888023741, 0.10842265837446408, 0.10491148685229623, 0.10714200766683402, 0.14488410423331988, 0.11630727774740168, 0.10140267724320406, 0.09211454450316892, 0.08555553877058697, 0.08955141834061009, 0.12597572771264642, 0.9777256902230379, 0.9753850947705945, 0.9862472143223898, 0.09937052445665118, 0.9769894638474282, 0.9697507479183679, 0.9776285300358045, 0.9772155129688695, 0.9858952626357406, 0.5506037856647813, 0.565829803573197, 0.6572394866276152, 0.5249585262812121, 0.1453876754594181, 0.6684340229845875, 0.08768780411066002, 0.5542114475540565, 0.6676193085871891, 0.1724929775478269, 0.34452175802042595, 0.7976985767550793, 0.26463931532488993, 0.38901737402554903, 0.18734488618089773, 0.068042507003922, 0.7893052639673535, 0.17558956382127888, 0.21755466950828517, 0.09958426600229109, 0.35884932599644104, 0.100579351429537, 0.16102934979154582, 0.12883708595469978, 0.247063907143537, 0.28333715447676056, 0.23772983637724998, 0.11904390084138627, 0.4227505509362002, 0.1255743918498119, 0.2024635013345989, 0.24307599398916968, 0.4575104225521194, 0.42751947273785107, 0.4470679379102247, 0.26323666392873346, 0.00012817320342406457, 0.03421112760041012, 0.059854537329330215, 0.009200386288299556, 0.023708157062463986, 0.043807884414093334, 0.1165649985879027, 0.007921991127301076, 0.07308989035238278, 0.18981871504571168, 0.14145814545304491, 0.15776447169028018, 0.08047551892750182, 0.04797216250304481, 0.17825473939646386, 0.07472445049402832, 0.10628742286423276, 0.1256902049977301, 0.03810670486838985, 0.04239572471416919, 0.11426495295839068, 0.10180150015912626, 0.0565296705999534, 0.23237868181485632, 0.07546236069847723, 0.08896123413140866, 0.08658928521301534, 0.20758817144608432, 0.1791742737128994, 0.20864242218636986, 0.1423051394884033, 0.18584421220511893, 0.3714335739228213, 0.05076243977688644, 0.04359095418902148, 0.07669716446265662, 0.5552213961470713, 0.5639740253829832, 0.6234758792973698, 0.5547377542923766, 0.5676436555736952, 0.5777977896885977, 0.6243100664297536, 0.5698039510934012, 0.6271437174339549, 0.08164749409957639, 0.08486590128619942, 0.09270930307576108, 0.12940500506467378, 0.10786704899120492, 0.12623967609555653, 0.15292512636735778, 0.13011210338323909, 0.08862153992401833, 0.1592713573058291, 0.3793164272770182, 0.17937063200364556, 0.18568486716084243, 0.4267344241947624, 0.25016271753655983, 0.2213628852634224, 0.41789041917035263, 0.2476264208975596, 0.3795999243445043, 0.269390819790278, 0.3784421181950486, 0.3370965842072404, 0.3223849321923581, 0.35376340946364637, 0.327589484912421, 0.5064053128618231, 0.3687461949842885, 0.2525975858619859, 0.2515641427233599, 0.3361040800808057, 0.31584741186512066, 0.22914667704216207, 0.2916352162671363, 0.3072637920035386, 0.37614932374108334, 0.27368232879003407, 0.20928651976494717, 0.16593858527349947, 0.19294023842206087, 0.24557737985276085, 0.1957896575300997, 0.19797270260549693, 0.20311285590378902, 0.1988744982909414, 0.2330446180881669, 0.21128526022424288, 0.603650564174329, 0.21554139681631046, 0.19234712711816337, 0.20470327508517727, 0.19141598998427756, 0.18516984918960588, 0.17542137789628598, 0.20445652669402103, 0.8146408788448289, 0.1831201794584455, 0.16628912192520273, 0.7769977244410917, 0.1985968863794646, 0.19858309963722887, 0.1410474499864658, 0.165801142019948, 0.8702978376926533, 0.6995284413484959, 0.2100824145917407, 0.07350527626340186, 0.7727762353609546, 0.7649885438727799, 0.15381060672708502, 0.20185491425451563, 0.10406575547962094, 0.2029308198509907, 0.19704802396672372, 0.20721435918949382, 0.20532885850590832, 0.2022778149708846, 0.2093299177350515, 0.21101523985811232, 0.19148388767857671, 0.22374031375776693, 0.2305797298989778, 0.09051910593959123, 0.08719413175562352, 0.08798506859197242, 0.08559583886811473, 0.09441783238833978, 0.10216241352906585, 0.09559205574925744, 0.08364733179823614, 0.0969791791461232]}, "mutation_prompt": null}
{"id": "c11a5b6c-2cb6-4175-8c81-659888f15dbd", "solution": "import numpy as np\n\nclass DynamicHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.5 + 0.3 * np.random.rand()  # shifted slightly for diversity\n        self.c1 = 1.6 + 0.2 * np.random.rand() # stronger cognitive component\n        self.c2 = 1.5 + 0.2 * np.random.rand() # balanced social component\n        self.F = 0.6 + 0.2 * np.random.rand()  # adjusted mutation factor\n        self.CR = 0.7 + 0.2 * np.random.rand() # increased crossover rate\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                inertia_adjustment = self.w * (1 - 0.5 * (self.evaluations/self.budget))  # adaptive inertia\n                self.velocities[i] = inertia_adjustment * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.2, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.2, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.4, self.w - 0.04) if self.global_best_score < np.median(self.personal_best_scores) else min(0.8, self.w + 0.04)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.5, self.F - 0.04) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.F + 0.04)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.12 * np.random.randn())  # increased mutation variability\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "DynamicHybridOptimizer", "description": "A dynamic hybrid algorithm integrating adaptive mutation, velocity strategies, and self-tuning components for enhanced exploration and exploitation balance.", "configspace": "", "generation": 45, "fitness": 0.32979139680889746, "feedback": "The algorithm DynamicHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.26.", "error": "", "parent_id": "762f5696-d9c4-42fa-a919-63e374281f63", "metadata": {"aucs": [0.7551301202844919, 0.7906081041973001, 0.7860764469500774, 0.7903570974352694, 0.7755065205526586, 0.7854317148217178, 0.766095681766273, 0.7719384817058401, 0.7703264413510186, 0.4800921406754599, 0.48370860213258426, 0.5079695077450734, 0.4561335125742778, 0.5653019557921495, 0.5520372206441628, 0.5282845168604473, 0.4660491704960674, 0.04458290010628585, 0.1184249741153246, 0.13979062796762864, 0.1014827094926859, 0.10428306588388592, 0.14114378482419487, 0.17367664024418172, 0.11009185104934227, 0.1353278521255744, 0.13560928755989077, 0.13029747060683017, 0.10166834764674426, 0.12780634492210463, 0.09395283849674285, 0.1490846753144478, 0.09296863170847447, 0.13128606277965993, 0.11019809656010715, 0.13757523437349428, 0.9728976687377331, 0.9779719302199578, 0.9823113441544442, 0.9725291799481302, 0.9726101843661941, 0.9618880029026803, 0.9730712226012954, 0.9836198932432602, 0.9788922572731454, 0.5897469134368982, 0.5589923021829115, 0.5217769641235048, 0.5307455719688169, 0.5875553142921055, 0.6344125804882634, 0.11474108411950579, 0.2036232330408957, 0.5605099053750711, 0.8210564059548693, 0.8546511224363447, 0.8543643760732558, 0.21680481289334563, 0.2751557701582834, 0.20078012653306343, 0.17117440685192176, 0.8321056120336531, 0.8267831031248347, 0.42706665104909847, 0.10945766368107912, 0.2138805200331334, 0.16427862880895228, 0.12096569418228242, 0.3732877416075797, 0.48157665402009575, 0.23029855983384362, 0.1307065170695152, 0.3466841634705652, 0.5805551064127635, 0.32816291151732135, 0.5657990383101326, 0.44349292292271125, 0.12440320432039009, 0.1232659147003804, 0.2187150701297884, 0.12492736395538517, 0.06338992651340847, 0.06530307690592163, 0.13318038756520123, 9.999999999998899e-05, 9.999999999998899e-05, 0.18331757225292544, 0.03118901418820319, 0.07384408831259848, 0.17074958372957283, 0.3595070276920398, 0.08871336388593132, 0.2566654771277431, 0.14071229887094583, 0.2927147390207473, 0.11511430180444637, 0.1016217958583342, 0.5465769894642607, 0.36412466843833247, 0.08376764628066646, 0.05694850172912391, 0.19223501373479546, 0.13151815370917852, 0.13506798374937867, 0.09420737506670662, 0.09119366097500536, 0.2597970445266241, 0.14925848884953574, 0.3366233199832295, 0.20776263620989388, 0.1105497338650131, 0.15142388119158334, 0.27484800903232753, 0.3434161914371928, 0.053119167037705695, 0.08178720573251597, 0.15525800223067676, 0.5911923418534015, 0.6497863511037818, 0.6990397394130704, 0.6474106764004905, 0.6083401485282189, 0.5958765579343521, 0.6209114639370168, 0.6667771607266523, 0.5944775997900583, 0.11802134746276605, 0.11051367134034917, 0.1331137269278041, 0.14409312800748053, 0.14467046693799024, 0.16858917332485257, 0.133959079335348, 0.10305486887898574, 0.07695337608535391, 0.3140601544244508, 0.20365966758241016, 0.17579551392606807, 0.22313347628488944, 0.26345616008987005, 0.23758087768598535, 0.2582541759974112, 0.2031624142162447, 0.18465807364323283, 0.36015865074297915, 0.2780957554222281, 0.4398769479279451, 0.29448565559357776, 0.3573760808840636, 0.41146912275670333, 0.30767255820009476, 0.4873343098430334, 0.4941953669388578, 0.2248276972646447, 0.1916416874238447, 0.1856087447450806, 0.2260066993507055, 0.16260631783098145, 0.24639145505973825, 0.3950636937125117, 0.20601818905880265, 0.3014996232705104, 0.23775960312627786, 0.18378158340666895, 0.211793224442284, 0.20476299458383074, 0.23839042139702704, 0.24867199263407924, 0.24467845434741353, 0.2827923467947234, 0.2465137180864494, 0.18741670301225044, 0.21431796345940224, 0.19402782123978746, 0.21565734898720468, 0.2049512577582917, 0.19667999435059957, 0.23885227080857152, 0.18523727148655045, 0.18089802777150754, 0.825819582102135, 0.18532735837347714, 0.16800530996759155, 0.8602972573622509, 0.19850587150812338, 0.862025499855305, 0.14138426946359994, 0.15961244600096158, 0.8717106456602185, 0.8342999781571843, 0.21154356898671245, 0.1756028599417121, 0.7133962133288935, 0.16801112232798254, 0.15438080251329322, 0.1879268725554789, 0.2021311547675485, 0.8328702439825962, 0.1934044198815441, 0.24309716222717426, 0.1948989106649397, 0.1912739202863044, 0.18363936143485093, 0.2003789251733945, 0.18993039333606154, 0.17726029250183928, 0.19974657557674236, 0.1230410123481106, 0.09852627183458407, 0.08051944743628014, 0.08699752584347531, 0.10319379419270203, 0.12065355866616301, 0.09417387415862122, 0.1028241224272537, 0.09617756702534885]}, "mutation_prompt": null}
{"id": "dcfcce44-d0d3-4f40-a959-ad7636449939", "solution": "import numpy as np\n\nclass QuantumInspiredHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 2))\n        self.w = 0.2 + 0.5 * np.random.rand()\n        self.c1 = 1.4 + 0.2 * np.random.rand()\n        self.c2 = 1.8 + 0.2 * np.random.rand()\n        self.F = 0.45 + 0.25 * np.random.rand()\n        self.CR = 0.65 + 0.25 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'CR_adjust', 'F_adjust', 'quantum_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 += 0.1 * (1 - 2 * np.random.rand())\n            elif learning_strategy == 'CR_adjust':\n                self.CR = max(0.3, self.CR - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.CR + 0.05)\n            elif learning_strategy == 'F_adjust':\n                self.F += 0.05 * (1 - 2 * np.random.rand())\n            elif learning_strategy == 'quantum_adjust':\n                theta = np.pi * np.random.rand(self.population_size, self.dim)\n                quantum_positions = self.lower_bound + (self.upper_bound - self.lower_bound) * (np.sin(theta) ** 2)\n                self.population = np.clip(quantum_positions, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.05 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "QuantumInspiredHybrid", "description": "Adaptive Quantum-Inspired Hybrid Algorithm utilizes quantum superposition states for exploration and dynamic learning for enhanced convergence.", "configspace": "", "generation": 46, "fitness": 0.29896979477199603, "feedback": "The algorithm QuantumInspiredHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.24.", "error": "", "parent_id": "762f5696-d9c4-42fa-a919-63e374281f63", "metadata": {"aucs": [0.6930351450235579, 0.7499275167727264, 0.7782440482431647, 0.697618627263354, 0.7765240040691274, 0.7382990594819494, 0.686758775776169, 0.7256415086724035, 0.7201812183727792, 0.19180723326120086, 0.2922661562818465, 0.051477961249577264, 0.2940606433933285, 0.3577051089534281, 0.37301376357853966, 0.2302076860525062, 0.30509075354431414, 0.38109278846287764, 0.12643016894955128, 0.08802067864688035, 0.12724179304779337, 0.1320271930391851, 0.11356941705860668, 0.1351323117411486, 0.12454420361322083, 0.14713460833378944, 0.1124837195764703, 0.10626828407675859, 0.09662854116978092, 0.10439698958449117, 0.10042152490371004, 0.13120763375771372, 0.13676052786319592, 0.13138243319302234, 0.1115983184151893, 0.11677435417895654, 0.9778709501263273, 0.9724916114142876, 0.9824362628916212, 0.9684564679051679, 0.9622685423001544, 0.9627484360178256, 0.9736758791520921, 0.9837551671204373, 0.9811266462182522, 0.42224945245877465, 0.4914465430493672, 0.4615310970584475, 0.4718980655180056, 0.5344567797501077, 0.4044464625877041, 0.1140996745829973, 0.44848226968829263, 0.49870386929902377, 0.43841251006967585, 0.7994905826127856, 0.7018565318642894, 0.2598719945696655, 0.1935630973527671, 0.2076404420896073, 0.6834284364894224, 0.7895009689534193, 0.762768070655811, 0.237952632137305, 0.3373550738594402, 0.39255073618608527, 0.09951743270389068, 0.12569750074255448, 0.12381229180594777, 0.32026730112905966, 0.11344792754579791, 0.37500074207266043, 0.25600459304447054, 0.16730505823129938, 0.32027688753647876, 0.293565399763695, 0.3012001304438804, 0.12703702194175892, 0.2195485114125202, 0.428206410478699, 0.3496809885992589, 0.04112262039442849, 0.03460645489781733, 0.15813966665389667, 0.04305200274827581, 9.999999999998899e-05, 0.017002727924878114, 0.2615308990088312, 0.20753515921560173, 0.06981622251682218, 0.2641541852295989, 0.18115684545459654, 0.3407791057105719, 0.06790077307033193, 0.29579550891104855, 0.0948595811937546, 0.1989435633631711, 0.0753024003789955, 0.4311740062027134, 0.11548635090464543, 0.03515249361059014, 0.18859121298833836, 0.07912612820274645, 0.13028323373487494, 0.07434656685665653, 0.08257983882303255, 0.08703316809816841, 0.06895097802137318, 0.17166652928158999, 0.1256403648012845, 0.18727433773524504, 0.034510711557899976, 0.31111816396379277, 0.19671159114591363, 0.23485151199683418, 0.05267833787375753, 0.07701765673155803, 0.5788538004428921, 0.6163929938163717, 0.6101293500783214, 0.5224631846357928, 0.6177319694302443, 0.20630007522601745, 0.5843077337856395, 0.5760602712851609, 0.6128527052060726, 0.07678061491227639, 0.10286455435868014, 0.10396721556870325, 0.11631327050353635, 0.12480195012042516, 0.1487403555555431, 0.12013444326624412, 0.14003290691573533, 0.0823137748549625, 0.17282010974977546, 0.37219864156871996, 0.20003765590630318, 0.18873631053474804, 0.2955614180447895, 0.26579662358766387, 0.2576668232491759, 0.2130394827506672, 0.20351993411693692, 0.26898358154048607, 0.35971391820494925, 0.40118645606152936, 0.36696613063143946, 0.26828828594657494, 0.34586598886940445, 0.27351441635122775, 0.42166471395600014, 0.29295080163778753, 0.2619934979988787, 0.3358178706691479, 0.3081388287842215, 0.23201149346008543, 0.21201535013667683, 0.2423826193872144, 0.3120450586818496, 0.3436777444091279, 0.20224343645074483, 0.19523536422556753, 0.21115454183972304, 0.23541377457109258, 0.2333738906348667, 0.22748745731705056, 0.18906912941256537, 0.19357118011025531, 0.26040481867718657, 0.27145277172888826, 0.20446268885140795, 0.2226924468340279, 0.20262659252267423, 0.1779451396165096, 0.2142168613923544, 0.19483105609543772, 0.20241001836858763, 0.19719275737226505, 0.19166655653893727, 0.8470142967105219, 0.18747118780287364, 0.1675327164087348, 0.7527494576762837, 0.19950964467319665, 0.19201465124184947, 0.14172588225885285, 0.1755951635282521, 0.8643832336438038, 0.8041521548039936, 0.20947280363537002, 0.1610593602915158, 0.20452935679169637, 0.1631112795371853, 0.1535893886537606, 0.1037533846937162, 0.16331426523957193, 0.8078516018761213, 0.18434971309173365, 0.22345156713112713, 0.19937054662771658, 0.18714839886770185, 0.19672864087236064, 0.2204070714848998, 0.18700794690828992, 0.22537007643234797, 0.20881849145100673, 0.07519616096859749, 0.08607205009275987, 0.08878737794993319, 0.11227354443490367, 0.07407522435618907, 0.0755909122307048, 0.08678075463198653, 0.10006060485023394, 0.10400229990611787]}, "mutation_prompt": null}
{"id": "1afae1ee-065d-4d1c-a110-7fe75bfd4178", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.4 + 0.4 * np.random.rand()  # Modified range\n        self.c1 = 1.4 + 0.2 * np.random.rand()  # Modified range\n        self.c2 = 1.7 + 0.2 * np.random.rand()  # Modified range\n        self.F = 0.5 + 0.2 * np.random.rand()  # Modified range\n        self.CR = 0.5 + 0.4 * np.random.rand()  # Modified range\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'CR_adjust', 'F_adjust'])  # Changed strategy\n\n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.4, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.4, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c2 + 0.1)\n            elif learning_strategy == 'CR_adjust':\n                self.CR = max(0.2, self.CR - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.CR + 0.1)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.2, self.F - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.F + 0.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.1 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSODE", "description": "A probabilistically mutated hybrid PSO-DE algorithm enhancing exploration and dynamic parameter adaptation for improved convergence.", "configspace": "", "generation": 47, "fitness": 0.25502962604046586, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.22.", "error": "", "parent_id": "762f5696-d9c4-42fa-a919-63e374281f63", "metadata": {"aucs": [0.5651013050024676, 0.651377984489737, 0.5042071241063475, 0.545712421509873, 0.6750480881012513, 0.6939945098748803, 0.5318860176127298, 0.6615430559017519, 0.6475850411357176, 0.15197481166299698, 0.1465788373697502, 0.17742547824788546, 0.09410264154166015, 0.22447529944499744, 0.2885332331041721, 0.1540307688420679, 0.19202390921152868, 0.16398029369614653, 0.08922394272192324, 0.0955928452678203, 0.11539178933440375, 0.12417991850800414, 0.11905085121976955, 0.13916178640610066, 0.09606408507122544, 0.12675308268898078, 0.1348272824518304, 0.094343101719353, 0.11878405850585949, 0.09608343468236014, 0.1084486542358547, 0.12926614635831157, 0.1024352982996346, 0.13592482981695175, 0.09263509675569326, 0.10101087444015744, 0.9823379247677042, 0.9734843062641008, 0.9828731000862846, 0.951146976099653, 0.9625596337013059, 0.9624373508706741, 0.9833957737342275, 0.9836829702286626, 0.981400409491147, 0.32062836021937935, 0.3279001902267088, 0.2587809490033708, 0.3240034301404193, 0.3440793205833197, 0.39989009024954303, 0.3500691552292686, 0.30198615417247543, 0.2562979536577883, 0.6929076431708616, 0.22833720072998265, 0.2202390983273017, 0.7143083934503798, 0.5539006995945635, 0.18861852615225305, 0.12748873680445072, 0.13694307679811624, 0.6929932638591096, 0.14161690906998192, 0.09502656286597744, 0.2844130905313027, 0.11149997370850251, 0.11885739976855147, 0.07969181264182046, 0.16412858999043434, 0.2185807545029178, 0.3108357852866893, 0.22040209410489897, 0.20641718636162465, 0.10541929273029604, 0.17232720488456887, 0.12747331680997231, 0.1598281052967364, 0.12057894321929075, 0.25323940756612096, 0.10490320575647671, 0.04553315212952724, 0.11541379804761454, 0.0502281779745023, 0.010260193225123504, 9.999999999998899e-05, 0.029639119728859242, 0.05793803475410508, 0.04523424027571177, 0.16303246534566096, 0.08813416134098206, 0.09401299481414249, 0.15064564148479875, 0.04827079591114858, 0.24761862539152468, 0.08177701828438078, 0.0702290392556042, 0.30352739361926173, 0.1110059761793476, 0.10315090540849159, 0.020285716056284042, 0.08729180529639469, 0.04160737775656964, 0.1237151590510468, 0.06715098297354982, 0.06033583432894318, 0.04471357723733904, 0.08840450985899007, 0.1664483577750434, 0.12638771756646838, 0.09021003609531342, 0.034237024909491764, 0.1927835987974632, 0.15454143509659957, 0.07364287889412247, 9.999999999998899e-05, 0.14355708252193322, 0.43483485765718355, 0.4569648131524242, 0.5206301619743045, 0.4552534514157195, 0.4698308692455906, 0.41659711031678803, 0.47458804304519275, 0.5033121421498576, 0.4748792927918657, 0.06754800724883114, 0.06327757360567465, 0.07270870466548551, 0.10201438559790754, 0.15039998044121927, 0.1244769430614373, 0.08404469085178279, 0.10438178779264984, 0.07531616848720246, 0.18949923974028238, 0.20492581189287762, 0.20049265196772348, 0.18933189127820393, 0.38450856592490523, 0.24813565325971376, 0.22231225462071846, 0.22174503750311647, 0.27799815942994255, 0.24655493706600584, 0.3655297366190021, 0.26813292324881566, 0.3437150424462234, 0.3195634035990982, 0.3020915155782046, 0.3343597785608937, 0.2804916034317294, 0.37697546657567105, 0.2139353649432344, 0.1732051265278709, 0.24397483142878118, 0.27620764491644767, 0.22336218086627802, 0.2042935328354588, 0.23171249437124752, 0.27874019638512815, 0.18553937117122554, 0.2249880201112956, 0.1991078188881391, 0.20587962743638688, 0.2107358574012731, 0.1963665076050497, 0.20058301253057398, 0.1869796353346883, 0.22674960914916598, 0.2250695127615674, 0.2093277279688771, 0.38986568314276215, 0.23525466974425502, 0.18448146743656157, 0.21349919300536435, 0.19165547607579736, 0.21306195401160877, 0.20486741551647603, 0.1957005948302144, 0.16067763250984646, 0.18521509846630713, 0.16757518556816098, 0.7450718299772253, 0.19791373172893223, 0.1873220688291517, 0.14083568168875904, 0.1570550148312293, 0.8008154998503608, 0.6956289270037084, 0.20924273457450437, 0.07328648927045056, 0.614264883100589, 0.5271604506049082, 0.1488447240128311, 0.18431846005911667, 0.1985364431032598, 0.6378453775917046, 0.1913819461807188, 0.18933052241524584, 0.19965352458270158, 0.17486119539858413, 0.18718311297127288, 0.22106871591526212, 0.18444384706597783, 0.19439983883793677, 0.19827225139493654, 0.07301273097798089, 0.08938706244642802, 0.08058054198048559, 0.07667111976849961, 0.0861503034668214, 0.0910639512320276, 0.06898696734360221, 0.08312715145215022, 0.07479397646322328]}, "mutation_prompt": null}
{"id": "6ff96e49-2bcc-4a97-a51f-f392f149a304", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.4 * np.random.rand()\n        self.c1 = 1.5 + 0.1 * np.random.rand()\n        self.c2 = 1.7 + 0.1 * np.random.rand()\n        self.F = 0.5 + 0.3 * np.random.rand()\n        self.CR = 0.6 + 0.3 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.4, self.c1 - 0.15) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c1 + 0.15)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.4, self.c2 - 0.15) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c2 + 0.15)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.w + 0.05)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.8, self.F + 0.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.1 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSODE", "description": "An enhanced adaptive hybrid algorithm boosting exploration-exploitation synergy through probabilistic mutation and learning strategy refinement.", "configspace": "", "generation": 44, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "762f5696-d9c4-42fa-a919-63e374281f63", "metadata": {"aucs": [0.7937168869588807, 0.8110840460577314, 0.8223124258026252, 0.8292334793015026, 0.8202705373520015, 0.8163661673418464, 0.8125309463706353, 0.8309340298974761, 0.8318134620986362, 0.036271978157934925, 0.46769062766129077, 0.5854499515612912, 0.5525228887733391, 0.5697050933427381, 0.5473268294949041, 0.5839843212732078, 0.6177205973473041, 9.999999999998899e-05, 0.12046799966568378, 0.16685181919533443, 0.10382292111213842, 0.10306651137265543, 0.13060423493780926, 0.11787659941018358, 0.16593100662388538, 0.11508489260969013, 0.15362971774268974, 0.11381256998177491, 0.09494188715498386, 0.10635529559181756, 0.11056971988888653, 0.09083774396250643, 0.09117902356562047, 0.1487032844981857, 0.11281600612383358, 0.1047879141675585, 0.9727413678611416, 0.973462333782434, 0.9823807152134303, 0.97212130492818, 0.9588214033568259, 0.9717012003398684, 0.9728032530485617, 0.9834415278744697, 0.9811084073632, 0.6628685524451319, 0.5681053144632513, 0.5422737438709716, 0.5942201542085449, 0.633610524854258, 0.6004661811128736, 0.33095606518960663, 0.3149925718092669, 0.6140301114910006, 0.8290993198872817, 0.8352112260909277, 0.8110082684827069, 0.7608394579074562, 0.8048905052753774, 0.20363178346083133, 0.22771431275162046, 0.3059496122529396, 0.22094501969105818, 0.5562267333066422, 0.3725033692671391, 0.3136266048580676, 0.39765302298934735, 0.4398677045717372, 0.5808912232133165, 0.5045040804178315, 0.10969954793521042, 0.594336088869361, 0.535023621134219, 0.6691158926418432, 0.3259352004876469, 0.4475758196173597, 0.5671066435302291, 0.3861037538629155, 0.12679663200607816, 0.1259309216885236, 0.10744003794828316, 0.32757085991373114, 0.0939710552344275, 0.0796292981005865, 0.033968083948810124, 9.999999999998899e-05, 0.015520763292286022, 0.14011933683978894, 0.03334598454370041, 0.0032050583749565487, 0.27934937775688096, 0.17840647383260477, 0.16566370211452142, 0.10481805951806622, 0.28126126774015237, 0.06438669344891257, 0.06166599363804637, 0.5184285182868864, 0.43074307515230315, 0.055007788817744596, 0.05523225041881763, 0.18047033926296774, 0.1666570483965777, 0.1378715816978764, 0.08949287971976738, 0.08817317885916331, 0.13393789020303848, 0.3054265060526712, 0.1724323559659422, 0.22333745406108862, 0.2415717942129716, 0.2053186686855084, 0.2751569820065869, 0.17042075019231384, 0.05548258795862948, 0.34159923125308034, 0.24456826933972942, 0.6342176691063348, 0.7032744151802033, 0.6106561828785786, 0.696520496597643, 0.6122866220021006, 0.5867647802698883, 0.6671952706634485, 0.6937692983422221, 0.680991756935079, 0.09938716255489122, 0.13309207329995787, 0.14400728764393567, 0.1576245682365236, 0.10916533130952433, 0.14211515140614195, 0.10744747627600537, 0.17457994960276368, 0.09153246401914328, 0.4029633132440851, 0.21501979602252252, 0.1933997728207577, 0.21070312167466032, 0.15057286944809256, 0.20082930294380397, 0.1858007061855591, 0.20510082708258293, 0.17104660655426174, 0.24187068583536186, 0.2961653233389204, 0.31787273767918967, 0.42512373789847724, 0.25441679365720027, 0.28944809209488254, 0.29980672326650015, 0.4431278070040966, 0.43099715795167404, 0.3509096698651262, 0.19844657678328437, 0.2045611077229761, 0.26424814599703184, 0.298522046985763, 0.2325508656742007, 0.30780587841920437, 0.3537301092033054, 0.19451288748463635, 0.2367667290676273, 0.2698169581915112, 0.208466949072324, 0.2382615065585585, 0.20774315105788177, 0.21339017074841748, 0.2617982842990728, 0.20988612704259357, 0.2410527965596846, 0.18442745762114643, 0.21522927652552692, 0.20371607536939285, 0.21140161634612686, 0.24552325006583897, 0.19016198959451291, 0.1885774030280103, 0.21405944466071214, 0.17917418426783338, 0.8820038072216912, 0.18797273496638411, 0.16775676508227844, 0.8551008508181219, 0.19972180879725387, 0.16867762807422404, 0.14248315156447666, 0.1621351354534869, 0.890645140568866, 0.8686579739592029, 0.2110889064736431, 0.758366565441014, 0.8484040220975784, 0.1664007729139515, 0.15402910839378325, 0.20750218566508327, 0.10462921953600013, 0.7653158807106272, 0.19978979028414035, 0.21048991323522304, 0.1855109215264482, 0.1926534584098475, 0.20620448975996963, 0.19014272102240914, 0.21025539616067868, 0.24337046206653123, 0.19629103913591084, 0.13999637572775936, 0.08244721186777226, 0.07742380334609755, 0.10172689656667677, 0.08781925034764804, 0.08828881755806361, 0.09029180992402219, 0.0883695230650079, 0.08148607510276074]}, "mutation_prompt": null}
{"id": "0086b5ff-675d-47fc-8745-5941fbc320db", "solution": "import numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.4 * np.random.rand()\n        self.c1 = 1.5 + 0.1 * np.random.rand()\n        self.c2 = 1.7 + 0.1 * np.random.rand()\n        self.F = 0.5 + 0.3 * np.random.rand()\n        self.CR = 0.6 + 0.3 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust', 'dynamic_leader'])\n\n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.4, self.c1 - 0.1) if self.global_best_score < np.percentile(self.personal_best_scores, 50) else min(2.0, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.4, self.c2 - 0.1) if self.global_best_score < np.percentile(self.personal_best_scores, 50) else min(2.0, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.05) if self.global_best_score < np.percentile(self.personal_best_scores, 50) else min(0.9, self.w + 0.05)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.05) if self.global_best_score < np.percentile(self.personal_best_scores, 50) else min(0.8, self.F + 0.05)\n            elif learning_strategy == 'dynamic_leader':\n                leader_index = np.random.choice(np.arange(self.population_size), p=self.personal_best_scores / np.sum(self.personal_best_scores))\n                self.global_best_position = self.personal_best_positions[leader_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.1 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedAdaptivePSODE", "description": "A robust adaptive hybrid algorithm that incorporates dynamic probability-based leader selection and adaptive parameter fine-tuning to enhance exploration-exploitation balance.", "configspace": "", "generation": 49, "fitness": 0.3210465509172477, "feedback": "The algorithm EnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.26.", "error": "", "parent_id": "762f5696-d9c4-42fa-a919-63e374281f63", "metadata": {"aucs": [0.6261820617590799, 0.8110840460577314, 0.8223124258026252, 0.6938432443193826, 0.8202705373520015, 0.8163661673418464, 0.6245973529863057, 0.8309340298974761, 0.8318134620986362, 0.2314980273983086, 0.46769062766129077, 0.5854499515612912, 0.20514707692911838, 0.5697050933427381, 0.5473268294949041, 0.1547879039635056, 0.6177205973473041, 9.999999999998899e-05, 0.09649299886969187, 0.16685181919533443, 0.10382292111213842, 0.11075785501400293, 0.13060423493780926, 0.11787659941018358, 0.09933260103128994, 0.11508489260969013, 0.15362971774268974, 0.06325987911588582, 0.09494188715498386, 0.10635529559181756, 0.1034558933970422, 0.09083774396250643, 0.09117902356562047, 0.1284797624020817, 0.11281600612383358, 0.1047879141675585, 0.9831400398601191, 0.973462333782434, 0.9823807152134303, 0.9490869282743878, 0.9588214033568259, 0.9717012003398684, 0.9728326167510005, 0.9834415278744697, 0.9811084073632, 0.4540187927710728, 0.5681053144632513, 0.5422737438709716, 0.39530914833357733, 0.633610524854258, 0.6004661811128736, 0.40883029165031326, 0.3149925718092669, 0.6140301114910006, 0.575209072728249, 0.8352112260909277, 0.8110082684827069, 0.2570101149079047, 0.8048905052753774, 0.20363178346083133, 0.6523074822099344, 0.3059496122529396, 0.22094501969105818, 0.11912854368750869, 0.3725033692671391, 0.3136266048580676, 0.30822204210331783, 0.4398677045717372, 0.5808912232133165, 0.28155551268831647, 0.10969954793521042, 0.594336088869361, 0.1406272845873291, 0.6691158926418432, 0.3259352004876469, 0.26459536676139483, 0.5671066435302291, 0.3861037538629155, 0.23348685454195361, 0.1259309216885236, 0.10744003794828316, 0.12671106797295817, 0.0939710552344275, 0.0796292981005865, 0.0314525465439659, 9.999999999998899e-05, 0.015520763292286022, 0.09250736123174541, 0.03334598454370041, 0.0032050583749565487, 0.19085341446288961, 0.17840647383260477, 0.16566370211452142, 0.12635536096232702, 0.28126126774015237, 0.06438669344891257, 0.06689563256678999, 0.5184285182868864, 0.43074307515230315, 0.04015310136704975, 0.05523225041881763, 0.18047033926296774, 0.09547488182214636, 0.1378715816978764, 0.08949287971976738, 0.07983446855665477, 0.13393789020303848, 0.3054265060526712, 0.15388551226071923, 0.22333745406108862, 0.2415717942129716, 0.21658360967258616, 0.2751569820065869, 0.17042075019231384, 0.04555791238781892, 0.34159923125308034, 0.24456826933972942, 0.5267610392795463, 0.7032744151802033, 0.6106561828785786, 0.5193607033999905, 0.6122866220021006, 0.5867647802698883, 0.5146251045990841, 0.6937692983422221, 0.680991756935079, 0.10483229205881794, 0.13309207329995787, 0.14400728764393567, 0.1183362368697819, 0.10916533130952433, 0.14211515140614195, 0.09205251719978258, 0.17457994960276368, 0.09153246401914328, 0.1705128572405169, 0.21501979602252252, 0.1933997728207577, 0.19581929512899943, 0.15057286944809256, 0.20082930294380397, 0.2331585106041455, 0.20510082708258293, 0.17104660655426174, 0.3544543803893817, 0.2961653233389204, 0.31787273767918967, 0.42257829967678684, 0.25441679365720027, 0.28944809209488254, 0.3593066482949667, 0.4431278070040966, 0.43099715795167404, 0.18687564711933824, 0.19844657678328437, 0.2045611077229761, 0.31099573636377686, 0.298522046985763, 0.2325508656742007, 0.2347006544087461, 0.3537301092033054, 0.19451288748463635, 0.20908140337597447, 0.2698169581915112, 0.208466949072324, 0.23846914420240706, 0.20774315105788177, 0.21339017074841748, 0.19940827285461404, 0.20988612704259357, 0.2410527965596846, 0.20347510066804286, 0.21522927652552692, 0.20371607536939285, 0.18921689067295788, 0.24552325006583897, 0.19016198959451291, 0.22316734534073668, 0.21405944466071214, 0.17917418426783338, 0.8274234087823444, 0.18797273496638411, 0.16775676508227844, 0.8536415741026845, 0.19972180879725387, 0.16867762807422404, 0.8132425709470859, 0.1621351354534869, 0.890645140568866, 0.827141591982546, 0.2110889064736431, 0.758366565441014, 0.20295664199965413, 0.1664007729139515, 0.15402910839378325, 0.10367325833761476, 0.10462921953600013, 0.7653158807106272, 0.1916408526547384, 0.21048991323522304, 0.1855109215264482, 0.17745266790465608, 0.20620448975996963, 0.19014272102240914, 0.21496344908398413, 0.24337046206653123, 0.19629103913591084, 0.0816303183732322, 0.08244721186777226, 0.07742380334609755, 0.09227825559800162, 0.08781925034764804, 0.08828881755806361, 0.07610536708334881, 0.0883695230650079, 0.08148607510276074]}, "mutation_prompt": null}
{"id": "bcc3be14-57f0-4a72-9c50-9367a10de194", "solution": "import numpy as np\n\nclass DynamicLearningPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.4 + 0.3 * np.random.rand()\n        self.c1 = 1.6 + 0.1 * np.random.rand()\n        self.c2 = 1.8 + 0.1 * np.random.rand()\n        self.F = 0.6 + 0.2 * np.random.rand()\n        self.CR = 0.5 + 0.4 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'CR_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.1, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.1, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.04) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.w + 0.04)\n            elif learning_strategy == 'CR_adjust':\n                self.CR = max(0.4, self.CR - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.CR + 0.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.1 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "DynamicLearningPSODE", "description": "Introducing dynamic learning adaptation and diversity-driven exploration in Metaheuristic Evolution.", "configspace": "", "generation": 50, "fitness": 0.33109341985401647, "feedback": "The algorithm DynamicLearningPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.26.", "error": "", "parent_id": "762f5696-d9c4-42fa-a919-63e374281f63", "metadata": {"aucs": [0.7980746461094823, 0.7812459125270905, 0.7949431921443423, 0.7977874842793127, 0.8292765472693948, 0.8030536867076308, 0.7625936743980678, 0.8161624394772365, 0.7865685653020691, 0.46164026780100453, 0.5508761548068518, 0.5039138977756619, 0.46035315033213897, 0.5945245606260077, 0.22135393454282182, 0.4982886303265257, 0.5549351083501743, 0.5798736099436388, 0.12121604825408228, 0.14119339775945117, 0.11970584201066359, 0.1492250913364973, 0.1448131880156145, 0.12685055401721024, 0.13364428196614075, 0.11459953285913904, 0.1380664545466861, 0.09635798696885489, 0.08253990394810151, 0.1335145952083061, 0.09084801288029354, 0.12181292658241305, 0.11028504068503264, 0.13150202790473853, 0.10950014870030134, 0.10613112326564966, 0.983198915074658, 0.973582939223261, 0.9837055712705216, 0.97226376519479, 0.960389513635349, 0.9624686210995183, 0.9740630299120153, 0.983593618560195, 0.9812585775190542, 0.5547774735076654, 0.5266103411197991, 0.5674572420605554, 0.469160359190241, 0.5370898979839166, 0.5153004885743471, 0.5104002550830431, 0.5558715444921705, 0.5516084863613858, 0.25283468976428736, 0.21546264967236195, 0.35861288804451175, 0.2733062021409641, 0.8090998762292212, 0.18873020200529023, 0.7640002922924205, 0.22702760180403592, 0.2437416127574895, 0.4476472632766205, 0.31188494915649234, 0.5367316353178428, 0.12085122263944781, 0.131729408351008, 0.30291058549604377, 0.4744656800790453, 0.34409699206531874, 0.481490295616552, 0.5020121082218332, 0.11733557809443063, 0.12376852350031387, 0.426547658062302, 0.5859826784931217, 0.1285301988801495, 0.37711436748768246, 0.3829914514355359, 0.2538088235821594, 0.1791677035658773, 9.999999999998899e-05, 0.05345983782841235, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.2137361638540567, 0.0689585470076376, 0.0032959408122716916, 0.09254109258623266, 0.40254435769928254, 0.1891712395080034, 0.33772838158342533, 0.37627123423380093, 0.12700552065831672, 0.2652659818759546, 0.2517892398019943, 0.051454289295536526, 0.08433080807145821, 0.03840565813889385, 0.045598064764296065, 0.16370217271853982, 0.083190635761343, 0.20070451098693687, 0.08265865165437625, 0.1314906674937214, 0.1402228475837366, 0.3109528993607581, 0.04247369378946664, 0.24632086656112007, 0.2063242138957252, 0.2372198634120859, 0.16756617677563967, 0.04666853598747367, 0.14048910338442344, 0.224970458252563, 0.6636184336523363, 0.6211826824933026, 0.68335449387429, 0.5587270922365799, 0.585153143275768, 0.5891181044331455, 0.7088850926644414, 0.6646935188636038, 0.6590636019411651, 0.11036657974327369, 0.05912181750089718, 0.09936597961106686, 0.1326987153928505, 0.1325121277361, 0.1380083355176226, 0.09659917624598002, 0.14091204054074147, 0.13791332426785208, 0.25824295756395077, 0.1945144506084977, 0.16927012444292144, 0.25859443018063755, 0.2836277798275628, 0.2831553431888332, 0.2616734339818031, 0.2918040217515945, 0.31851394268549726, 0.3604196044642538, 0.286337481435363, 0.46469255568314316, 0.49088558978876395, 0.33866915032809064, 0.303121093795626, 0.5044498452639168, 0.5333291163391095, 0.3827439513372749, 0.2833042971214661, 0.18564446146221325, 0.34654643991759193, 0.3513165588344338, 0.22783566600107308, 0.39848628458862867, 0.363196224675678, 0.3324563511633183, 0.25374471757777495, 0.20857193124080808, 0.2157183565133618, 0.20396777451601045, 0.2112312850706295, 0.23396465130995148, 0.23321727358094657, 0.22874599675870144, 0.21767683391470005, 0.24969660394181048, 0.2028325783804924, 0.17918191269922867, 0.19090707345270963, 0.20128472661623698, 0.22081760991385468, 0.18317565427852034, 0.19515298065964093, 0.2015488656823602, 0.17862181241343078, 0.862945711339766, 0.18752763690894658, 0.16625014763821977, 0.8477010357244459, 0.19873938670997982, 0.1958211902322956, 0.7282468237382194, 0.16152276128065257, 0.8542320483345748, 0.8498357875793592, 0.20929608683295264, 0.0734555027200322, 0.7973478470250495, 0.16571024968195558, 0.1520051168661466, 0.20900886899328253, 0.10448250601902886, 0.8394401609849959, 0.20468555687794465, 0.23004462042950502, 0.20966006245777125, 0.19142773443907368, 0.20983686987251626, 0.19603036565426069, 0.1983243904167633, 0.21881213558452217, 0.22303306394176803, 0.08680391945851029, 0.09121736626245114, 0.08944125267151626, 0.10299885594085356, 0.09803701767026307, 0.09563579749680506, 0.07948697860411069, 0.10756862553674551, 0.09651409873789796]}, "mutation_prompt": null}
{"id": "6e288b3b-c6e4-44bf-be68-585b5563ba1f", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.4 * np.random.rand()\n        self.c1 = 1.5 + 0.1 * np.random.rand()\n        self.c2 = 1.7 + 0.1 * np.random.rand()\n        self.F = 0.5 + 0.3 * np.random.rand()\n        self.CR = 0.6 + 0.3 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.4, self.c1 - 0.15) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c1 + 0.15)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.4, self.c2 - 0.15) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c2 + 0.15)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.w + 0.05)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.8, self.F + 0.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.1 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSODE", "description": "An enhanced adaptive hybrid algorithm boosting exploration-exploitation synergy through probabilistic mutation and learning strategy refinement.", "configspace": "", "generation": 44, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "762f5696-d9c4-42fa-a919-63e374281f63", "metadata": {"aucs": [0.7937168869588807, 0.8110840460577314, 0.8223124258026252, 0.8292334793015026, 0.8202705373520015, 0.8163661673418464, 0.8125309463706353, 0.8309340298974761, 0.8318134620986362, 0.036271978157934925, 0.46769062766129077, 0.5854499515612912, 0.5525228887733391, 0.5697050933427381, 0.5473268294949041, 0.5839843212732078, 0.6177205973473041, 9.999999999998899e-05, 0.12046799966568378, 0.16685181919533443, 0.10382292111213842, 0.10306651137265543, 0.13060423493780926, 0.11787659941018358, 0.16593100662388538, 0.11508489260969013, 0.15362971774268974, 0.11381256998177491, 0.09494188715498386, 0.10635529559181756, 0.11056971988888653, 0.09083774396250643, 0.09117902356562047, 0.1487032844981857, 0.11281600612383358, 0.1047879141675585, 0.9727413678611416, 0.973462333782434, 0.9823807152134303, 0.97212130492818, 0.9588214033568259, 0.9717012003398684, 0.9728032530485617, 0.9834415278744697, 0.9811084073632, 0.6628685524451319, 0.5681053144632513, 0.5422737438709716, 0.5942201542085449, 0.633610524854258, 0.6004661811128736, 0.33095606518960663, 0.3149925718092669, 0.6140301114910006, 0.8290993198872817, 0.8352112260909277, 0.8110082684827069, 0.7608394579074562, 0.8048905052753774, 0.20363178346083133, 0.22771431275162046, 0.3059496122529396, 0.22094501969105818, 0.5562267333066422, 0.3725033692671391, 0.3136266048580676, 0.39765302298934735, 0.4398677045717372, 0.5808912232133165, 0.5045040804178315, 0.10969954793521042, 0.594336088869361, 0.535023621134219, 0.6691158926418432, 0.3259352004876469, 0.4475758196173597, 0.5671066435302291, 0.3861037538629155, 0.12679663200607816, 0.1259309216885236, 0.10744003794828316, 0.32757085991373114, 0.0939710552344275, 0.0796292981005865, 0.033968083948810124, 9.999999999998899e-05, 0.015520763292286022, 0.14011933683978894, 0.03334598454370041, 0.0032050583749565487, 0.27934937775688096, 0.17840647383260477, 0.16566370211452142, 0.10481805951806622, 0.28126126774015237, 0.06438669344891257, 0.06166599363804637, 0.5184285182868864, 0.43074307515230315, 0.055007788817744596, 0.05523225041881763, 0.18047033926296774, 0.1666570483965777, 0.1378715816978764, 0.08949287971976738, 0.08817317885916331, 0.13393789020303848, 0.3054265060526712, 0.1724323559659422, 0.22333745406108862, 0.2415717942129716, 0.2053186686855084, 0.2751569820065869, 0.17042075019231384, 0.05548258795862948, 0.34159923125308034, 0.24456826933972942, 0.6342176691063348, 0.7032744151802033, 0.6106561828785786, 0.696520496597643, 0.6122866220021006, 0.5867647802698883, 0.6671952706634485, 0.6937692983422221, 0.680991756935079, 0.09938716255489122, 0.13309207329995787, 0.14400728764393567, 0.1576245682365236, 0.10916533130952433, 0.14211515140614195, 0.10744747627600537, 0.17457994960276368, 0.09153246401914328, 0.4029633132440851, 0.21501979602252252, 0.1933997728207577, 0.21070312167466032, 0.15057286944809256, 0.20082930294380397, 0.1858007061855591, 0.20510082708258293, 0.17104660655426174, 0.24187068583536186, 0.2961653233389204, 0.31787273767918967, 0.42512373789847724, 0.25441679365720027, 0.28944809209488254, 0.29980672326650015, 0.4431278070040966, 0.43099715795167404, 0.3509096698651262, 0.19844657678328437, 0.2045611077229761, 0.26424814599703184, 0.298522046985763, 0.2325508656742007, 0.30780587841920437, 0.3537301092033054, 0.19451288748463635, 0.2367667290676273, 0.2698169581915112, 0.208466949072324, 0.2382615065585585, 0.20774315105788177, 0.21339017074841748, 0.2617982842990728, 0.20988612704259357, 0.2410527965596846, 0.18442745762114643, 0.21522927652552692, 0.20371607536939285, 0.21140161634612686, 0.24552325006583897, 0.19016198959451291, 0.1885774030280103, 0.21405944466071214, 0.17917418426783338, 0.8820038072216912, 0.18797273496638411, 0.16775676508227844, 0.8551008508181219, 0.19972180879725387, 0.16867762807422404, 0.14248315156447666, 0.1621351354534869, 0.890645140568866, 0.8686579739592029, 0.2110889064736431, 0.758366565441014, 0.8484040220975784, 0.1664007729139515, 0.15402910839378325, 0.20750218566508327, 0.10462921953600013, 0.7653158807106272, 0.19978979028414035, 0.21048991323522304, 0.1855109215264482, 0.1926534584098475, 0.20620448975996963, 0.19014272102240914, 0.21025539616067868, 0.24337046206653123, 0.19629103913591084, 0.13999637572775936, 0.08244721186777226, 0.07742380334609755, 0.10172689656667677, 0.08781925034764804, 0.08828881755806361, 0.09029180992402219, 0.0883695230650079, 0.08148607510276074]}, "mutation_prompt": null}
{"id": "98a9d263-d481-4689-81c2-2fc1733005d8", "solution": "import numpy as np\n\nclass NovelHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.6 * np.random.rand()\n        self.c1 = 1.5 + 0.2 * np.random.rand()\n        self.c2 = 1.7 + 0.2 * np.random.rand()\n        self.F = 0.5 + 0.5 * np.random.rand()\n        self.CR = 0.6 + 0.4 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust', 'CR_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.4, self.c1 * 0.9) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c1 * 1.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.4, self.c2 * 0.9) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c2 * 1.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w * 0.95) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.w * 1.05)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.F + 0.05)\n            elif learning_strategy == 'CR_adjust':\n                self.CR = max(0.4, self.CR * 0.95) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.CR * 1.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.05 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "NovelHybridPSODE", "description": "A novel hybrid PSO-DE with adaptive parameter adjustment and memory-based mutation strategies for improved exploration-exploitation balance.", "configspace": "", "generation": 52, "fitness": 0.28700508286208, "feedback": "The algorithm NovelHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.24.", "error": "", "parent_id": "762f5696-d9c4-42fa-a919-63e374281f63", "metadata": {"aucs": [0.43662332423186767, 0.7930848000833772, 0.8009132766943029, 0.4353358500419978, 0.8057794493972781, 0.7730883227988667, 0.5127604113389161, 0.7968261425272364, 0.7860494237904753, 0.11767049182244804, 0.5356944658456098, 0.34019823641352176, 0.06658953161640802, 0.5730076958880812, 0.5893539352798931, 0.07329601186661461, 0.5222555053971192, 0.04766717099387807, 0.10139187631732316, 0.13164403247961687, 0.12339479714204626, 0.08459451433613974, 0.1236548142622299, 0.12550657822286337, 0.11057398240220062, 0.1325633274077943, 0.13625350913960887, 0.0927292498704646, 0.09042229030642135, 0.10811800896979096, 0.08668768139281469, 0.13596976732704935, 0.11623962320822756, 0.11014445911776038, 0.11637695326179909, 0.09921891495261936, 0.9831638940828483, 0.9737478852828315, 0.9837551214479514, 0.9615143905410254, 0.9603712875974546, 0.9717526299729414, 0.9733157931476132, 0.9834955749773483, 0.9814025170256165, 0.2676096417593705, 0.5506328028143358, 0.42997770772798016, 0.2913065575471695, 0.5576641020318267, 0.5801469708433855, 0.2599191783552063, 0.5354155702200687, 0.4949959019624658, 0.23998784260128592, 0.2266416505756531, 0.7819269054109855, 0.42226591396849467, 0.28012052657741227, 0.18868145331742137, 0.20205626384766862, 0.8094702692938573, 0.22370027022800265, 0.12845075746658507, 0.10919736237511823, 0.3364764292926241, 0.1364312419492042, 0.449466288474765, 0.11900020576340353, 0.1483785144429961, 0.5001039518933676, 0.4511640360564789, 0.121447546455561, 0.28270866112719606, 0.12121144381318716, 0.13995359612892277, 0.4405375143629211, 0.12327142998990892, 0.1379115195768501, 0.3808230889979338, 0.11339879399815678, 0.08015716641904869, 0.015891010560889263, 0.14628606688786527, 0.006904124460872518, 0.010613023721220305, 0.13054607778889926, 0.002591647947463027, 0.16094632192183178, 0.16483143679626078, 0.10722975166024484, 0.16503773170975145, 0.1531157601194223, 0.07589420486291643, 0.2674195789851862, 0.04938518541929682, 0.05008303226148525, 0.3426907570931277, 0.21183401868977325, 0.006598536439831659, 0.06020608548931616, 0.043169366918783814, 0.037647340594005985, 0.0874443088829947, 0.19959894770375985, 0.0004066834001430486, 0.21308892723261375, 0.17148395138124706, 0.10014231472363322, 0.2066306944315638, 0.14729258360767306, 0.11197662421828825, 0.29021762679404395, 0.2512522614020415, 0.05994490727463453, 0.14566321802256155, 0.07672520972027086, 0.4183361621703797, 0.6284196885746391, 0.7022538389653461, 0.4083811164000808, 0.6238875730905434, 0.624985786172406, 0.4412143708767875, 0.6358806340230911, 0.596618051205253, 0.11585215132808002, 0.10434128371216644, 0.11072561240312828, 0.10028626353404235, 0.12597341039606003, 0.1559152748711221, 0.12029889686099027, 0.1485547436530804, 0.10937268917960885, 0.18653898657302048, 0.44734236955963624, 0.19358289340088009, 0.17448295147781023, 0.252128954236013, 0.19388679092488315, 0.24910465043259988, 0.22573295806953952, 0.18836453926432106, 0.2854972972210438, 0.22067817034027393, 0.2929505013565531, 0.3078439976609111, 0.2472729032426806, 0.42109550898021153, 0.28702862127908346, 0.34132874394529544, 0.3697949739042601, 0.20080107950133153, 0.23007428142033648, 0.31417514205455377, 0.2681856130596133, 0.33711510439325443, 0.311737242046495, 0.25795075193683115, 0.28919555182855305, 0.2599427837807927, 0.20710620853096218, 0.20025120807295094, 0.23527766833748187, 0.19818504182950614, 0.21234708297343385, 0.22165757323689173, 0.20682278497233075, 0.25235673690046456, 0.23836932282331458, 0.17685595545999544, 0.20295711486856105, 0.19544747627078574, 0.22396818053879042, 0.20886253879867467, 0.18844522326509328, 0.2032882474237171, 0.2103644738434144, 0.181295124709979, 0.6404504896642764, 0.1865019503605142, 0.166362170584074, 0.6319552542702637, 0.19877500154759287, 0.1951111101047831, 0.5849026498617741, 0.16026943948062722, 0.8644550746083491, 0.5693408428951493, 0.20924190928728326, 0.07328803420091623, 0.40867144146438417, 0.1663136096029677, 0.14959020867283757, 0.20762600847337176, 0.10461628657741584, 0.7894511462129409, 0.20405060897720173, 0.2023384497505576, 0.18338020240684816, 0.20778154033736196, 0.2177300101973807, 0.2108825002241721, 0.20805303817849286, 0.18926819769996128, 0.2353978682718395, 0.08537167943174062, 0.07954701397620778, 0.0962009371695054, 0.08845554666831756, 0.09645586943713602, 0.08724631102029945, 0.07426352229874844, 0.0984575626275066, 0.09470962249151726]}, "mutation_prompt": null}
{"id": "12597bd3-2ad7-4449-82ef-f0d2a0f2c8fb", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.4 * np.random.rand()\n        self.c1 = 1.5 + 0.1 * np.random.rand()\n        self.c2 = 1.7 + 0.1 * np.random.rand()\n        self.F = 0.5 + 0.3 * np.random.rand()\n        self.CR = 0.6 + 0.3 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.4, self.c1 * 0.85) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c1 * 1.15)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.4, self.c2 * 0.85) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c2 * 1.15)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w * 0.95) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.w * 1.05)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F * 0.95) if self.global_best_score < np.median(self.personal_best_scores) else min(0.8, self.F * 1.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.1 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSODE", "description": "Enhanced hybrid PSO-DE with adaptive learning strategies and probabilistic mutation for robust optimization across diverse problem landscapes.", "configspace": "", "generation": 53, "fitness": 0.3269719294156574, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.26.", "error": "", "parent_id": "762f5696-d9c4-42fa-a919-63e374281f63", "metadata": {"aucs": [0.791544766969509, 0.8144928181038612, 0.8189023447621642, 0.8152603245117203, 0.8071246020348598, 0.8033180804607389, 0.7869884171123368, 0.8282556991164988, 0.7696088053167761, 0.493479345361845, 0.5379135487747333, 0.5420079550106913, 0.4958755101427831, 0.5774878683840696, 0.5493180324532552, 0.5623833368482076, 0.6089283620971, 0.4522518368083909, 0.11136942080102796, 0.11236051174140538, 0.6046198000827729, 0.1082669086085305, 0.10410746367958523, 0.14569978891400093, 0.14039922323687037, 0.12821797688826286, 0.14962805040900895, 0.10910601196062797, 0.105726769379203, 0.10236627447976065, 0.12635131073852046, 0.1001923394365467, 0.06986789668053495, 0.10277945144513922, 0.10300043682890558, 0.10053390075889779, 0.9728072191568019, 0.9734917443098166, 0.982344718996429, 0.9720940933556218, 0.9581394642746003, 0.9623751669566684, 0.972850381366094, 0.9834420695729356, 0.9811152369814943, 0.5467534680542716, 0.5519516845659311, 0.5510140925687186, 0.5417785276104795, 0.5973447500427768, 0.5414211846545494, 0.08469002353829913, 0.2349373533311243, 0.5922574905495581, 0.8415627160572311, 0.22639629477432854, 0.20800930740071, 0.21283892112578529, 0.3767848997978841, 0.18995343029671963, 0.8194346645143299, 0.13807516951788168, 0.23329418922131784, 0.4947872620112307, 0.10715296274613995, 0.12167238733382035, 0.1228489988607151, 0.5965668733356514, 0.3321117638357175, 0.4315940539645299, 0.11780555153142525, 0.520047278688822, 0.5273054113218446, 0.38288100897496546, 0.3962013825616494, 0.3554645577651676, 0.46553209300451714, 0.23119040981386452, 0.48313839871474695, 0.6019069477602927, 0.09826156402324282, 0.2264041440204373, 9.999999999998899e-05, 0.18286430869512815, 0.03389070789621096, 9.999999999998899e-05, 9.999999999998899e-05, 0.09686642407103174, 0.05436720373462067, 0.0030013950108884746, 0.09549057955088902, 0.3247152320100064, 0.19109891463355266, 0.12603916856513298, 0.11720546369414697, 0.13592809506160897, 0.25561536660269324, 0.1338812005186628, 0.5161267661811761, 0.06976263111721781, 0.061848898235239314, 0.11875833709563544, 0.2312359694852555, 0.1397394950249593, 0.08255894247371565, 0.08713745028347164, 0.06126986260688949, 0.12611679317673985, 0.13162107406289492, 0.34275434008059136, 0.26940840856435366, 0.3776181506013446, 0.4053686519846422, 0.11559044510232364, 0.05224501490854805, 0.21791254574077545, 0.08582923274281729, 0.6967514823035652, 0.6410250195522159, 0.6723391623717565, 0.6139459628532289, 0.5939084062956074, 0.6204355318157935, 0.6171692755724145, 0.6681375136309144, 0.6294613596938134, 0.07787118791523484, 0.15231934040982686, 0.10094053039715034, 0.14073659800825555, 0.10666455154862686, 0.1732630677779664, 0.0782799543221252, 0.17256385563240362, 0.0816463204109037, 0.21548861207728864, 0.24428576642536415, 0.19500724407332093, 0.2688679663716188, 0.1519170112260152, 0.23009858797197424, 0.2924290304004943, 0.1956790814157544, 0.16683074415606203, 0.28952833767882813, 0.2807251415909492, 0.2456115439258022, 0.4456453908811875, 0.2606812635196818, 0.30381575474867195, 0.48658227028441947, 0.4650300902291977, 0.38235628502409913, 0.23740021357572072, 0.3591400991195811, 0.2465038628824876, 0.335161150811507, 0.1870722824165154, 0.2789965407903393, 0.26848625811629967, 0.29234443891960327, 0.19571853070856415, 0.2408599152969767, 0.21139411680281261, 0.21431705289607383, 0.23762978654148315, 0.2281296050593088, 0.2335129248616038, 0.22067358059070508, 0.3063344028635755, 0.21495490015322283, 0.20393866448175813, 0.18627010200751115, 0.2116236757171418, 0.20230096114934448, 0.207145188326741, 0.207985896686545, 0.21537498473470862, 0.205840646938815, 0.20129142555340462, 0.8577710209388305, 0.18771143008606406, 0.16675765181000202, 0.1722278819468538, 0.19956944585936132, 0.168731698114571, 0.1422049018058298, 0.15781810020400766, 0.8610402483128033, 0.8709976979320256, 0.2107049394340903, 0.7743996710687877, 0.7974842417158681, 0.16528519235303663, 0.1510978517313495, 0.2054360509755616, 0.10456014921178014, 0.8339300000051532, 0.19160712059724372, 0.20188441549560443, 0.18746171907215992, 0.18850908021622748, 0.1850209414094115, 0.18693606519248873, 0.22456782634766392, 0.21279448144204705, 0.19607271033565543, 0.10273027605932894, 0.07654629422394466, 0.09500845466406593, 0.09154508719791243, 0.09056864751054805, 0.06997711104088777, 0.09853812266507356, 0.10927987527157967, 0.09678632830585032]}, "mutation_prompt": null}
{"id": "cfffe809-dbf9-407a-87b8-d7311a76ddaa", "solution": "import numpy as np\n\nclass EnhancedAdaptiveMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.4 * np.random.rand()\n        self.c1 = 1.5 + 0.1 * np.random.rand()\n        self.c2 = 1.7 + 0.1 * np.random.rand()\n        self.F = 0.5 + 0.3 * np.random.rand()\n        self.CR = 0.6 + 0.3 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'CR_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.4, self.c1 - 0.15) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c1 + 0.15)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.4, self.c2 - 0.15) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c2 + 0.15)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.w + 0.05)\n            elif learning_strategy == 'CR_adjust':\n                self.CR = max(0.5, self.CR - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.CR + 0.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.1 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedAdaptiveMetaheuristic", "description": "A self-adjusting metaheuristic leveraging adaptive learning strategies and dynamic parameter tuning to enhance convergence efficiency.", "configspace": "", "generation": 54, "fitness": 0.3423217560864937, "feedback": "The algorithm EnhancedAdaptiveMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.27.", "error": "", "parent_id": "762f5696-d9c4-42fa-a919-63e374281f63", "metadata": {"aucs": [0.7937168869588807, 0.8110840460577314, 0.8223124258026252, 0.8292334793015026, 0.8202705373520015, 0.8163661673418464, 0.8125309463706353, 0.8309340298974761, 0.8318134620986362, 0.036271978157934925, 0.46769062766129077, 0.5854499515612912, 0.5525228887733391, 0.5697050933427381, 0.5473268294949041, 0.5839843212732078, 0.6177205973473041, 9.999999999998899e-05, 0.12046799966568378, 0.16685181919533443, 0.10382292111213842, 0.10306651137265543, 0.13060423493780926, 0.11787659941018358, 0.16593100662388538, 0.11508489260969013, 0.15362971774268974, 0.11381256998177491, 0.09494188715498386, 0.10635529559181756, 0.11056971988888653, 0.09083774396250643, 0.09117902356562047, 0.1487032844981857, 0.11281600612383358, 0.1047879141675585, 0.9727413678611416, 0.973462333782434, 0.9823807152134303, 0.97212130492818, 0.9588214033568259, 0.9717012003398684, 0.9728032530485617, 0.9834415278744697, 0.9811084073632, 0.6628685524451319, 0.5681053144632513, 0.5422737438709716, 0.5942201542085449, 0.633610524854258, 0.6004661811128736, 0.33095606518960663, 0.3149925718092669, 0.6140301114910006, 0.8290993198872817, 0.8352112260909277, 0.8110082684827069, 0.7608394579074562, 0.8048905052753774, 0.20363178346083133, 0.22771431275162046, 0.3059496122529396, 0.22094501969105818, 0.5562267333066422, 0.3725033692671391, 0.3136266048580676, 0.39765302298934735, 0.4398677045717372, 0.5808912232133165, 0.5045040804178315, 0.10969954793521042, 0.594336088869361, 0.535023621134219, 0.6691158926418432, 0.3259352004876469, 0.4475758196173597, 0.5671066435302291, 0.3861037538629155, 0.12679663200607816, 0.1259309216885236, 0.10744003794828316, 0.32757085991373114, 0.0939710552344275, 0.0796292981005865, 0.033968083948810124, 9.999999999998899e-05, 0.015520763292286022, 0.14011933683978894, 0.03334598454370041, 0.0032050583749565487, 0.27934937775688096, 0.17840647383260477, 0.16566370211452142, 0.10481805951806622, 0.28126126774015237, 0.06438669344891257, 0.06166599363804637, 0.5184285182868864, 0.43074307515230315, 0.055007788817744596, 0.05523225041881763, 0.18047033926296774, 0.1666570483965777, 0.1378715816978764, 0.08949287971976738, 0.08817317885916331, 0.13393789020303848, 0.3054265060526712, 0.1724323559659422, 0.22333745406108862, 0.2415717942129716, 0.2053186686855084, 0.2751569820065869, 0.17042075019231384, 0.05548258795862948, 0.34159923125308034, 0.24456826933972942, 0.6342176691063348, 0.7032744151802033, 0.6106561828785786, 0.696520496597643, 0.6122866220021006, 0.5867647802698883, 0.6671952706634485, 0.6937692983422221, 0.680991756935079, 0.09938716255489122, 0.13309207329995787, 0.14400728764393567, 0.1576245682365236, 0.10916533130952433, 0.14211515140614195, 0.10744747627600537, 0.17457994960276368, 0.09153246401914328, 0.4029633132440851, 0.21501979602252252, 0.1933997728207577, 0.21070312167466032, 0.15057286944809256, 0.20082930294380397, 0.1858007061855591, 0.20510082708258293, 0.17104660655426174, 0.24187068583536186, 0.2961653233389204, 0.31787273767918967, 0.42512373789847724, 0.25441679365720027, 0.28944809209488254, 0.29980672326650015, 0.4431278070040966, 0.43099715795167404, 0.3509096698651262, 0.19844657678328437, 0.2045611077229761, 0.26424814599703184, 0.298522046985763, 0.2325508656742007, 0.30780587841920437, 0.3537301092033054, 0.19451288748463635, 0.2367667290676273, 0.2698169581915112, 0.208466949072324, 0.2382615065585585, 0.20774315105788177, 0.21339017074841748, 0.2617982842990728, 0.20988612704259357, 0.2410527965596846, 0.18442745762114643, 0.21522927652552692, 0.20371607536939285, 0.21140161634612686, 0.24552325006583897, 0.19016198959451291, 0.1885774030280103, 0.21405944466071214, 0.17917418426783338, 0.8820038072216912, 0.18797273496638411, 0.16775676508227844, 0.8551008508181219, 0.19972180879725387, 0.16867762807422404, 0.14248315156447666, 0.1621351354534869, 0.890645140568866, 0.8686579739592029, 0.2110889064736431, 0.758366565441014, 0.8484040220975784, 0.1664007729139515, 0.15402910839378325, 0.20750218566508327, 0.10462921953600013, 0.7653158807106272, 0.19978979028414035, 0.21048991323522304, 0.1855109215264482, 0.1926534584098475, 0.20620448975996963, 0.19014272102240914, 0.21025539616067868, 0.24337046206653123, 0.19629103913591084, 0.13999637572775936, 0.08244721186777226, 0.07742380334609755, 0.10172689656667677, 0.08781925034764804, 0.08828881755806361, 0.09029180992402219, 0.0883695230650079, 0.08148607510276074]}, "mutation_prompt": null}
{"id": "ddaaa671-a954-4832-97b1-36a72a452470", "solution": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.5 * np.random.rand()\n        self.c1 = 1.5 + 0.2 * np.random.rand()\n        self.c2 = 1.7 + 0.2 * np.random.rand()\n        self.F = 0.5 + 0.25 * np.random.rand()  # Adjusted range\n        self.CR = 0.6 + 0.2 * np.random.rand()  # Adjusted range\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'CR_adjust'])  # Updated strategy\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.03) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.w + 0.03)\n            elif learning_strategy == 'CR_adjust':  # Introduced CR adjustment\n                self.CR = max(0.5, self.CR - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.CR + 0.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.1 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "RefinedHybridPSODE", "description": "A refined hybrid adaptive algorithm integrating progressive parameter adjustment and selective mutation for enhanced convergence efficiency.", "configspace": "", "generation": 55, "fitness": 0.33534031759858024, "feedback": "The algorithm RefinedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.26.", "error": "", "parent_id": "762f5696-d9c4-42fa-a919-63e374281f63", "metadata": {"aucs": [0.8033498853642476, 0.8059659293979877, 0.8058066923604432, 0.7412549967070616, 0.8249192230640092, 0.7968723445247559, 0.7785157586601622, 0.8098140518142642, 0.7883778132883251, 0.416858282658917, 0.627464504414704, 0.4902044406174797, 0.4990847069742097, 0.6584345109558928, 0.4829260096619963, 0.049857786034556706, 0.5330119425049786, 0.37529820646242107, 0.15269565772566307, 0.10992218991003466, 0.10973826366689887, 0.1108383073216459, 0.13541873271466798, 0.11188685381245778, 0.11237394485145347, 0.1180892495132595, 0.14652433029293555, 0.09591638972605199, 0.11513509898110497, 0.09710573566785974, 0.09046821963063723, 0.10158915918482869, 0.08776557084716075, 0.13331405821415232, 0.09175438010023695, 0.11937878982128747, 0.9803440507199105, 0.9735538259908065, 0.9834895576845771, 0.9722634482547374, 0.9602729611766608, 0.9625084545736264, 0.9738384403159451, 0.9834413616688483, 0.9811966925778757, 0.543136009588338, 0.5632685006479619, 0.5649582522896347, 0.5354438688548315, 0.47716419312742075, 0.634865972860754, 0.42886621107028966, 0.5311991962345297, 0.5825417686109385, 0.7667014313438857, 0.7941779087704172, 0.7846596828313616, 0.27118114063886756, 0.28166626302343, 0.19392344893442104, 0.7219256721959146, 0.1506036285143456, 0.21983444316148826, 0.3805874923696574, 0.44598424918724133, 0.36556149741380173, 0.10979327025299157, 0.47793659050577475, 0.12374982555887526, 0.4128618991048024, 0.1494429514088773, 0.3907604682894148, 0.5074686293879562, 0.3840710561818761, 0.11742993860101891, 0.43441260489306766, 0.24327172308523537, 0.12849625275827514, 0.43581743191695355, 0.5175408508780066, 0.24483518969880436, 0.056508091912046754, 0.0923468061832109, 0.118871054495297, 0.05084036869937958, 0.1148209322340259, 0.08503590156209906, 0.16000131142484697, 0.014331178631719177, 0.04637693608278037, 0.35546254071881955, 0.14285833182020158, 0.19934370695412185, 0.17155127792464664, 0.19014102572011937, 0.1692871083400379, 0.4033592410746455, 0.16912161626740219, 0.24089548441786202, 0.23572218651945276, 0.04796597471565689, 0.05708931923449834, 0.14209884455461685, 0.4377476343525716, 0.14015189327414956, 0.25538414640924423, 0.13545186576381618, 0.10958763248820791, 0.13725969934564908, 0.24998178101631774, 0.19723749990946438, 0.24995692209406106, 0.20484848543464906, 0.24667688294680779, 0.17628106056001014, 0.20071233998440696, 0.07784066854437077, 0.6423873141971219, 0.588950408262068, 0.5591347978997889, 0.615652311868338, 0.686461202278231, 0.6873375525410497, 0.6620924635598004, 0.6735199064976539, 0.5913223936118457, 0.1330639590125331, 0.132314168523893, 0.08919887302239149, 0.13987267051275798, 0.1358699873082262, 0.11284746320936279, 0.09388803507275056, 0.10440957869720913, 0.09061864106209128, 0.21983785887472418, 0.23159435127165995, 0.2098723215683589, 0.43838880576601846, 0.34188990981541467, 0.2470311441956512, 0.19787612839680335, 0.23114606324886167, 0.17302326188937567, 0.3408021383286661, 0.25674467020113634, 0.29041739146441037, 0.4499633815271352, 0.2847750554643802, 0.33533312871646725, 0.2834241589997186, 0.3820058463270303, 0.4908706401171148, 0.19629588814839383, 0.17153763915481435, 0.3363958428942124, 0.26269296354132654, 0.22061495315843727, 0.24014662771490902, 0.29568294885978763, 0.31425310985233046, 0.2304915774889762, 0.26773857328087647, 0.26160965643797607, 0.26398483868027256, 0.2083220661959806, 0.1858474711302467, 0.24177812420864164, 0.21175147222734136, 0.21172352550735163, 0.21887056278387862, 0.20363065211133058, 0.23394628183765964, 0.2114677623715503, 0.17242417274248323, 0.20286404636276734, 0.19887386371253202, 0.21406007588453935, 0.19421162064277497, 0.1958084254375868, 0.8517661272142959, 0.18759990592764442, 0.16748828590318265, 0.8309453501953983, 0.19972753113457953, 0.16869856641564818, 0.17575692123853026, 0.1560579048403521, 0.8744857064792462, 0.8544621125867083, 0.21037252663065054, 0.7102527164863397, 0.8309040645900323, 0.7943726850128401, 0.16656552846595463, 0.2092923126812719, 0.10453153375291735, 0.8262310410046274, 0.18450741035778762, 0.1886235870373646, 0.21427054262524003, 0.18787004742548263, 0.22446813000992116, 0.21555612530709534, 0.196980231055077, 0.23486828369063417, 0.20909019225310932, 0.09233525523777675, 0.10123423802960407, 0.1055837038382006, 0.09561637893487729, 0.0824974034092536, 0.10523021518219411, 0.0838193352794726, 0.09777572286377867, 0.08458017630280412]}, "mutation_prompt": null}
{"id": "2d77da3c-99dd-40fa-bd9f-4af8b377f418", "solution": "import numpy as np\n\nclass DynamicAdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.4 + 0.3 * np.random.rand()\n        self.c1 = 1.4 + 0.2 * np.random.rand()\n        self.c2 = 1.8 + 0.2 * np.random.rand()\n        self.F = 0.6 + 0.2 * np.random.rand()\n        self.CR = 0.7 + 0.2 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.1, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.1, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.35, self.w - 0.04) if self.global_best_score < np.median(self.personal_best_scores) else min(0.95, self.w + 0.04)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.5, self.F - 0.04) if self.global_best_score < np.median(self.personal_best_scores) else min(0.85, self.F + 0.04)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.1 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "DynamicAdaptiveHybridPSODE", "description": "DynamicAdaptiveHybridPSODE introduces a dynamic adjustment mechanism to adaptively tune parameters and enhance convergence in diverse problem landscapes.", "configspace": "", "generation": 56, "fitness": 0.3295102883449324, "feedback": "The algorithm DynamicAdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.26.", "error": "", "parent_id": "762f5696-d9c4-42fa-a919-63e374281f63", "metadata": {"aucs": [0.7550153909289669, 0.7589319132879875, 0.7745765765151538, 0.7739025190133619, 0.782026391177416, 0.8054287323768867, 0.7769537470227321, 0.7824064586815319, 0.7716896224984979, 0.3901157680713141, 0.4546556107469589, 0.5013298825238562, 0.3969322121266252, 0.47908868765106405, 0.5238227277117031, 0.40439431417249705, 0.49425985419512486, 0.04621114057534892, 0.1223402873568592, 0.12222836180594909, 0.12256818759878718, 0.12866736565151748, 0.07005678532340076, 0.3501947225729597, 0.14310883010173525, 0.17048021038053063, 0.11493719299328298, 0.10948393228650843, 0.08605631274814585, 0.10459992696602383, 0.11018149216464213, 0.10710340212414071, 0.1661560536479192, 0.11944823676439043, 0.12877581514967118, 0.14632659432487094, 0.9804037967650511, 0.9734952339507322, 0.9838152783244185, 0.9728934552634754, 0.9764298942039558, 0.9717582264086059, 0.9742940539312696, 0.9845324347588745, 0.9814427624713631, 0.49152375572006823, 0.5035867724568537, 0.5497262347466829, 0.4441290129928036, 0.5168666478726822, 0.5659218858493131, 0.08169335821095414, 0.4233654500917716, 0.4321431973969312, 0.22256489309799476, 0.2273861762179239, 0.7716591069598853, 0.33185013277104614, 0.7890582723024547, 0.20353998061992407, 0.8067895691822128, 0.7239598120711281, 0.23812581422070656, 0.39863960440999147, 0.11019284812516084, 0.36083847592388585, 0.32570915910218423, 0.12576580510819946, 0.11382288280585617, 0.12445368131441215, 0.2801524339980228, 0.4581470576747927, 0.410257380169597, 0.4064962061264855, 0.1205948372449619, 0.460405923484017, 0.2423551668854681, 0.4182955842504559, 0.5055356851085784, 0.5277174645152255, 0.1142989895502442, 0.14181442092753693, 0.06564265170950057, 0.22516577157567552, 0.0005368418774680528, 9.999999999998899e-05, 0.11410791701470646, 0.07778816189024529, 0.24593081529541838, 0.17703527260146912, 0.10889609856614457, 0.05522222667006249, 0.2445199096577071, 0.12470020649567926, 0.13124912076311213, 0.15810080532812576, 0.28173794509963423, 0.5311707140209048, 0.27845999290737, 0.2196339047000906, 0.04127995014270891, 0.04933163821646669, 0.1495895375267774, 0.08179210933811587, 0.11405649491570602, 0.08237896809531464, 0.08569222698708567, 0.12608574038085285, 0.11123504436682674, 0.041764196189434055, 0.2693553380581196, 0.27536948126610206, 0.23929349948278977, 0.2421901271755521, 0.04517187105350473, 0.32575447779073186, 0.30487024349035763, 0.655119749106287, 0.6589959269462846, 0.6696941690736218, 0.599752587341984, 0.6221862270190941, 0.611034136467105, 0.6707147086339857, 0.6043784234939901, 0.638736527207187, 0.1051081337881351, 0.06541895929623698, 0.08472773642535503, 0.09163164810644753, 0.09032861187645036, 0.1252992916075618, 0.15419988431616816, 0.09893956124607395, 0.16839152728253326, 0.32647004922679446, 0.22999441702541223, 0.2503555248387591, 0.19237003439780775, 0.23677237818687413, 0.2579689727869703, 0.20387716081513274, 0.31037323839753983, 0.22058711913880102, 0.3524059343692362, 0.4090160189112313, 0.48489381326041525, 0.421947099388412, 0.41237423892733993, 0.24860513094093362, 0.4339562937279918, 0.4614939555120061, 0.4541662078808947, 0.2677249531979762, 0.22363325997733885, 0.21200070052961206, 0.24992910656859202, 0.22538546858321473, 0.25834079777306884, 0.2503915817776605, 0.29501477537229015, 0.19098662733649951, 0.2280296170000824, 0.2137809543956497, 0.23186807844996615, 0.23283618388175875, 0.25769148850503465, 0.2522962602065699, 0.2295808582135781, 0.20918258046279548, 0.2349571940032098, 0.19415332093517057, 0.23627719938520153, 0.18167805547375826, 0.21545563382708643, 0.5733988934958694, 0.17898547622366134, 0.33367717047583323, 0.19725097702318695, 0.20047418922326943, 0.8687559889342805, 0.18750232607016926, 0.16714992399620077, 0.8587020797538377, 0.1995379490377771, 0.860907094599915, 0.14137097891227368, 0.16149682013499422, 0.845488471565284, 0.8214458284502469, 0.20742793545453697, 0.20612865865951635, 0.7991987240525943, 0.16666224079427006, 0.1476632037013189, 0.20394419509366157, 0.1044927125717744, 0.8154555280706066, 0.2247306593594789, 0.1878859411154028, 0.18881721225846826, 0.18163044356660252, 0.20745603964009962, 0.19850248406569015, 0.20827179691088638, 0.203017039363091, 0.23207617315432927, 0.10588746585080755, 0.09229671726728916, 0.10035928244290937, 0.09253181025720991, 0.1010472742035674, 0.0870664330209715, 0.11442080989550363, 0.0981838085369533, 0.10133005700561426]}, "mutation_prompt": null}
{"id": "a632c32e-ea77-45ea-a0b6-725429275264", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.4 + 0.3 * np.random.rand()\n        self.c1 = 1.4 + 0.2 * np.random.rand()\n        self.c2 = 1.8 + 0.1 * np.random.rand()\n        self.F = 0.6 + 0.2 * np.random.rand()\n        self.CR = 0.7 + 0.2 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.1, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.1, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.4, self.w - 0.04) if self.global_best_score < np.median(self.personal_best_scores) else min(0.85, self.w + 0.04)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.5, self.F - 0.04) if self.global_best_score < np.median(self.personal_best_scores) else min(0.85, self.F + 0.04)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.05 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedAdaptiveHybridPSODE", "description": "A dynamically adaptive hybrid algorithm enhancing exploration through stochastic position adjustments and diversified mutation strategies.", "configspace": "", "generation": 57, "fitness": 0.3149310840353568, "feedback": "The algorithm EnhancedAdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.25.", "error": "", "parent_id": "762f5696-d9c4-42fa-a919-63e374281f63", "metadata": {"aucs": [0.6951621933013832, 0.7462587435209019, 0.7662173993409358, 0.7577362134835938, 0.7426401992419345, 0.735466073137754, 0.7616697000433788, 0.7209080165453422, 0.7496600999993936, 0.44034855558360864, 0.4183738066310495, 0.3975137671012886, 0.321576777800357, 0.4617385634081457, 0.5013299924827842, 0.38273697637021686, 0.362440515158303, 0.08320625425252726, 0.07101387804051285, 0.13684782726560718, 0.1002705492948266, 0.14022942343960454, 0.10574233870385019, 0.06869623799580604, 0.1180779232310486, 0.14429887786641227, 0.10111832305395552, 0.08264091497309634, 0.12010018533748623, 0.08442817425209137, 0.07729692829179491, 0.0917638831878268, 0.1069639114099451, 0.09534868827471876, 0.12335712311414138, 0.10038756822673167, 0.9803366037903182, 0.9734732397076463, 0.9837251357379545, 0.9727931680509991, 0.9764505874321072, 0.9650607387971527, 0.9736165680378293, 0.9845451189375624, 0.981169457241953, 0.5424963818236713, 0.5244543320776965, 0.4618065359663628, 0.46829991506202295, 0.5530008320131556, 0.5644238225025084, 0.4633376733036795, 0.08433718792334988, 0.44332129145226695, 0.6371377053175489, 0.2238644450663484, 0.7748160413005621, 0.19412075492844583, 0.26997994622964416, 0.19981774594867985, 0.7360270969348086, 0.5997040178590873, 0.7938234499657636, 0.4210892899473577, 0.3243613842485984, 0.4255248632032611, 0.38916226689993416, 0.3472284460062345, 0.36480507971614173, 0.24886708320860773, 0.4774337745123155, 0.4331713337765727, 0.4224321127781352, 0.2682054495644288, 0.12329401828361974, 0.2360525814445834, 0.4712587935505823, 0.12147077541694185, 0.4579348712278697, 0.4356754401986992, 0.1040613304301713, 0.17443245254505368, 0.05689167681008911, 0.058806330509092564, 0.0006111129214534383, 9.999999999998899e-05, 0.42527147573107127, 0.18587283822578504, 0.04568651508639854, 0.10414220925399986, 0.38396266462918915, 0.4303445502563452, 0.2049107940243, 0.06147895088546107, 0.19974100709569687, 0.18974806697598423, 0.12874391122269024, 0.4232398637561894, 0.4408309999489698, 0.08477850965221756, 0.03708640983510614, 0.059766408721377395, 0.10741021484615665, 0.09524785495942001, 0.25886517524088426, 0.08430271787556598, 0.08260407231986577, 0.138547535279835, 0.1510544478430209, 0.04059959764959442, 0.2894108093129395, 0.2223653953846847, 0.2646723637282824, 0.2837618429833053, 0.04641317861299288, 0.04590578502501741, 0.11317904274651758, 0.6374336706818455, 0.6181938897781121, 0.6047157261465244, 0.5577800219720175, 0.6372185504637107, 0.5578444311399156, 0.6159987526693886, 0.5928943182386026, 0.6315673899509484, 0.08359106106840974, 0.09360103371473083, 0.08041525229575786, 0.09902850305540922, 0.06905567330440099, 0.10670608957925964, 0.13094515139928842, 0.11113348658085176, 0.1106635186713405, 0.2570079952267793, 0.23246870443998746, 0.21408048454200956, 0.199286839932025, 0.6277636734857073, 0.26651057850074744, 0.1553197075521393, 0.21062957381414138, 0.36493692849334625, 0.36523322179346684, 0.34283123171526175, 0.4086937143236218, 0.35659648439692837, 0.24991384838997055, 0.41358375999948727, 0.28420843914242655, 0.44743805335367137, 0.4418047658118823, 0.2648802000077919, 0.3039651084164885, 0.24443949347728933, 0.2635647215911564, 0.20952856586569069, 0.24660322240189803, 0.3715371433509357, 0.3291540371834818, 0.21773442222613382, 0.2575787185432651, 0.1932368682853507, 0.1956249659473437, 0.22644747372651342, 0.20458376685205326, 0.1973148340633516, 0.2051083243502244, 0.2060595786180036, 0.2054386068295645, 0.2154829702068961, 0.18373109176900604, 0.1870868222284836, 0.21334886660139674, 0.19674836750143998, 0.21434582425189608, 0.5435422232095799, 0.21728317384367501, 0.1824044189647488, 0.1635708215637124, 0.18751953560172552, 0.16621088697684394, 0.8137626725380636, 0.19825375786502897, 0.19668776141434774, 0.1423329077562434, 0.16115937391583646, 0.8939046797333431, 0.8000303423766486, 0.206136359214381, 0.07343440365528953, 0.16424368812342294, 0.16646831984630495, 0.14736859386644008, 0.20517555091881678, 0.10441491776908352, 0.6809636008118521, 0.2033019509483015, 0.20775960384502357, 0.19296776471246668, 0.205377010264142, 0.18652134544330123, 0.19656895214943593, 0.1900898631710235, 0.18068963408682936, 0.22589387437345787, 0.10531720127904609, 0.08549309123376914, 0.09841249935550056, 0.09746525303454856, 0.08670527678957929, 0.09008280375328637, 0.10305458456764971, 0.09201910919375955, 0.09956575047070726]}, "mutation_prompt": null}
{"id": "1caf9c38-2b94-4082-aece-8f9979593d6c", "solution": "import numpy as np\n\nclass SynergisticHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.4 * np.random.rand()\n        self.c1 = 1.5 + 0.1 * np.random.rand()\n        self.c2 = 1.7 + 0.1 * np.random.rand()\n        self.F = 0.5 + 0.3 * np.random.rand()\n        self.CR = 0.6 + 0.3 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.0, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.07) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.w + 0.07)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.08) if self.global_best_score < np.median(self.personal_best_scores) else min(0.8, self.F + 0.08)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.15 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "SynergisticHybridOptimizer", "description": "Synergistic Hybrid Strategy Optimizer leveraging adaptive learning rates and probabilistic dynamic adjustments to enhance global exploration and local exploitation.", "configspace": "", "generation": 58, "fitness": 0.339453790843758, "feedback": "The algorithm SynergisticHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.27.", "error": "", "parent_id": "762f5696-d9c4-42fa-a919-63e374281f63", "metadata": {"aucs": [0.8304505553216162, 0.7977288405188784, 0.8351767706102411, 0.8007382936917922, 0.811308095348598, 0.7989377731809374, 0.8231740829938164, 0.8230292442576808, 0.8207118525019078, 0.36147319562860025, 0.5276286245421502, 0.5712889271287138, 0.5014857273404095, 0.5218760599228704, 0.5584273444797203, 0.6156684797405936, 0.5376788589593279, 0.04705634538047021, 0.09353757299620868, 0.10254210209774939, 0.12045194536345682, 0.12466753874681746, 0.11304182499140747, 0.11304742555920289, 0.1271839650987313, 0.5238738347949211, 0.14072533185006453, 0.08555365865643072, 0.0950399854077979, 0.07544864140254925, 0.09776787190747149, 0.12194793614997268, 0.10140851187484079, 0.13345543045140473, 0.08359394950557475, 0.07818223724371931, 0.9726873996748765, 0.9734209981272905, 0.9823666114053974, 0.9725101588369134, 0.9601548333357889, 0.9636456768518028, 0.9727480069204699, 0.9834347892715397, 0.9811006308997143, 0.6496479752639944, 0.6657292038503516, 0.6129866094822978, 0.5468935865344836, 0.6229046402417566, 0.5914431182717417, 0.49225873060128056, 0.5275333290814077, 0.6224344850098928, 0.8825867445020918, 0.22831825365691805, 0.2396147733829298, 0.27626180612726825, 0.28155048818795025, 0.2705400426461362, 0.8040170575029997, 0.8194062239274456, 0.25257447794037724, 0.4942071815532283, 0.3965207675207898, 0.6560545554881885, 0.12626060243646242, 0.6258858752230356, 0.2681755797740458, 0.4695874988497464, 0.19993280015224468, 0.6932682616232608, 0.34680052606835965, 0.12940564193623416, 0.12163173386799886, 0.5504677051447822, 0.129527757886032, 0.4708438228913726, 0.25213769323010315, 0.513709044656139, 0.11763400020009773, 0.08783188964845268, 9.999999999998899e-05, 0.19606086156752245, 0.03663820244767135, 9.999999999998899e-05, 0.005717593644593899, 0.3307799139071703, 0.06170219688920775, 0.008701720843051541, 0.2132067299751873, 0.18818096731509293, 0.36121169988139634, 0.2740885818599784, 0.13823137677335895, 0.4228782756526085, 0.1675347028650167, 0.629552718281619, 0.370615633088737, 0.045070256580611257, 0.03865529326129058, 0.15124528621981104, 0.15897676233491675, 0.22311529295871269, 0.12414961449905237, 0.10232479244835158, 0.11869846474778856, 0.130429845482682, 0.17590037454912977, 0.2041710294528737, 0.1958121939299623, 0.33655372600945377, 0.27206198142508586, 0.31562762916529397, 0.04780689664273485, 0.11524601904650555, 0.16154896185210732, 0.6870339346514824, 0.6719842476958608, 0.6718873012915777, 0.626924238535419, 0.618411911720199, 0.6476081393750743, 0.7250691182430322, 0.6593225673334604, 0.7117856641865317, 0.08935091579191667, 0.06850222059447975, 0.08897697816473826, 0.17993722522595146, 0.08890232235677487, 0.09489123390448018, 0.08687858785588431, 0.13584661977568357, 0.11035801879749874, 0.17742267835584502, 0.23893996515611293, 0.3504659555196772, 0.6225356694501192, 0.27088367880363573, 0.19976332383723683, 0.38513113961975487, 0.17780875464743218, 0.18711116669321914, 0.2636203312590988, 0.1822854861488915, 0.3278931234720517, 0.46292411812525447, 0.2623416853517462, 0.3212149903549236, 0.35382845922240047, 0.3454994219516905, 0.35086903189076013, 0.27326382767814794, 0.287680878914656, 0.16764250608814368, 0.5040298684464319, 0.1705791908936144, 0.23542275913569133, 0.2464955832630107, 0.24114401916437456, 0.2177672063772459, 0.22373692859171146, 0.20197877133445208, 0.1976475646961523, 0.24861151534575565, 0.23223121469451158, 0.20696810943055244, 0.22348884785573087, 0.22917766192089917, 0.24280680371637864, 0.19259924341603196, 0.20278535883003168, 0.1961724013653976, 0.20381081358516262, 0.2084906107836022, 0.20639119501415393, 0.19527680679123605, 0.22226314512840206, 0.18296510234297625, 0.8677278685545015, 0.18782989009206563, 0.1678171935291033, 0.7865126309823604, 0.19928508741093276, 0.19854559632732538, 0.1425032891217184, 0.15975840937335795, 0.900310392148851, 0.849510996995214, 0.21085707256429476, 0.7994136645478056, 0.16053397059906926, 0.16653025680373013, 0.15804275743212715, 0.2067894113408374, 0.10460245973798776, 0.7310879909557924, 0.1888637367834577, 0.19586020007038318, 0.18698657687240638, 0.2044440316511138, 0.21540361237394212, 0.22929620295221553, 0.1946890028664111, 0.22697484608641938, 0.20651059331514243, 0.09324228983884297, 0.10059230358763993, 0.09549414506717147, 0.09304481590707292, 0.08073639232579777, 0.08489438562537366, 0.10525639605831838, 0.08922786875206168, 0.0905463025056108]}, "mutation_prompt": null}
{"id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "solution": "import numpy as np\n\nclass RefinedAdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.4 * np.random.rand()\n        self.c1 = 1.5 + 0.1 * np.random.rand()\n        self.c2 = 1.7 + 0.1 * np.random.rand()\n        self.F = 0.5 + 0.3 * np.random.rand()\n        self.CR = 0.6 + 0.3 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.07) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.w + 0.07)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.07) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.F + 0.07)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.05 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "RefinedAdaptiveHybridPSODE", "description": "A refined adaptive hybrid algorithm enhancing parameter tuning through dynamic probabilistic mutation and synergy optimization.", "configspace": "", "generation": 59, "fitness": 0.35943593658261375, "feedback": "The algorithm RefinedAdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.28.", "error": "", "parent_id": "762f5696-d9c4-42fa-a919-63e374281f63", "metadata": {"aucs": [0.798386629940598, 0.8140038684614535, 0.8022257739253773, 0.8023115510660797, 0.8324033018839588, 0.8184184473952807, 0.8120566341802481, 0.7993198247980557, 0.830823275729308, 0.5795948532511028, 0.5184018813252469, 0.5279612888639034, 0.5918061856791046, 0.5572764850684835, 0.5971402525569998, 0.593117346688006, 0.6036054724537274, 0.5777604494417663, 0.11669860609931693, 0.16069576018193965, 0.10515671117543535, 0.11115510671037987, 0.09192719214687983, 0.1425447726839265, 0.1365145635804731, 0.17729713437732175, 0.17310659748063395, 0.10916456457730006, 0.09501007898284675, 0.11556753927066055, 0.09644785178445947, 0.11992227730625749, 0.06977562895438627, 0.11030940298197511, 0.10642740296674769, 0.10583141808703855, 0.972702869562636, 0.9734682035510478, 0.9831630328586503, 0.9724673614502476, 0.9601656476954725, 0.971776196486502, 0.9727960929662032, 0.983443976067325, 0.9811028069051303, 0.5860061461203013, 0.614958936450563, 0.4824813399814424, 0.5749243798309396, 0.5183423735427716, 0.5346874091244398, 0.3716568559129897, 0.5316056605031527, 0.6198740205272831, 0.818639586866515, 0.8557464882562138, 0.8446962081234877, 0.27693110622212247, 0.2810286150847312, 0.1913246094761576, 0.8667912388366211, 0.6776111362077089, 0.8719809217760112, 0.599760598012501, 0.31279641905649236, 0.47363532809451603, 0.35226551766115766, 0.539224002824372, 0.12711836465863946, 0.47142995242107355, 0.11781103706516582, 0.6525585029934937, 0.4706256080094052, 0.3660624169126805, 0.1188628285326302, 0.49851313964255883, 0.12933944798105035, 0.48349381480266684, 0.29951325546678376, 0.5541865179356009, 0.11907540124143434, 0.2015574593469862, 0.024079189879376628, 0.09212644549063753, 0.0005574733377475827, 9.999999999998899e-05, 0.005024103388300505, 0.15193662754138826, 0.007373356997960934, 0.0026853220055943483, 0.3862069038256317, 0.1308639359296876, 0.46188650429223466, 0.12692314380824532, 0.5982511478303985, 0.03206544678347767, 0.2231360977079263, 0.5997715183888047, 0.11162797799787183, 0.10523905600657457, 0.044269065988996936, 0.15943434761834907, 0.12992025203384017, 0.14205801688972008, 0.12922879311079782, 0.12137543076735224, 0.18127337626507045, 0.1794162716723957, 0.25041847638226267, 0.2321537829251844, 0.29425573727289767, 0.17064967965043287, 0.3423943177781099, 0.23154344838536112, 0.046791120164487277, 0.18065191530753177, 0.08151877538681807, 0.5793939088875715, 0.6132230275235317, 0.6669008482285673, 0.6433204586689387, 0.733932648379362, 0.6294404296832777, 0.6046570252268915, 0.7230082514781024, 0.6984237425627087, 0.0834325671990438, 0.08881094588975247, 0.07489263512343991, 0.12051603056305504, 0.08836200734603095, 0.12225722795775129, 0.08952770070009008, 0.17460663486795802, 0.08859689389089775, 0.1793335277069451, 0.7083661646768167, 0.679394607007183, 0.3713108550957366, 0.2734692359524077, 0.19337794445184608, 0.1525060408860438, 0.20849869612062322, 0.2734010044148508, 0.38168214527176425, 0.2043214517281865, 0.32112002384333416, 0.4312323109182896, 0.2688027628787678, 0.4527012119688615, 0.4444453649758131, 0.5569097490227879, 0.39121527241146914, 0.2836925656132451, 0.22356063774126156, 0.2424773204892876, 0.23477681174202092, 0.3161752085456172, 0.23883091560840775, 0.2394719535817702, 0.28942986971381335, 0.20623173049025045, 0.23152612979570453, 0.24251611653712013, 0.18695497620300017, 0.2335159925363629, 0.20977652042202155, 0.20193733614336074, 0.1931739391248376, 0.2552777578669372, 0.23321653550495047, 0.6127476312977345, 0.18592830997678622, 0.20312396905309782, 0.20062409426033934, 0.20386937699080754, 0.19629315268625358, 0.1830167088267054, 0.19555692176465977, 0.1787509790462729, 0.8597395584629448, 0.18808835825677095, 0.16785018580905475, 0.8328258435261078, 0.19930799163486668, 0.1690720345305654, 0.14249792249253768, 0.16210971051557066, 0.8983968451429901, 0.8497218458816995, 0.21101552451555516, 0.843832488821923, 0.8091987430182941, 0.8290098761366081, 0.15490699558431276, 0.20750644503642646, 0.10464825917080611, 0.8008128264896168, 0.19096637595505028, 0.227402232500599, 0.17840106690919433, 0.18234499013754357, 0.18753698498046445, 0.20520523876643992, 0.20259513208954738, 0.18463251153125004, 0.25451715914969175, 0.11865327581684937, 0.09584212818905946, 0.09172850776109787, 0.09895666545773152, 0.10068981796032461, 0.0958334016062592, 0.12800964299275142, 0.08053439922157068, 0.09035047680715236]}, "mutation_prompt": null}
{"id": "46e56ed3-4775-42de-82be-83ccd2d5057d", "solution": "import numpy as np\n\nclass AdaptiveQuantumInspiredPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 4))\n        self.w = 0.4 + 0.3 * np.random.rand()\n        self.c1 = 1.5 + 0.2 * np.random.rand()\n        self.c2 = 1.8 + 0.2 * np.random.rand()\n        self.F = 0.55 + 0.25 * np.random.rand()\n        self.CR = 0.65 + 0.25 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-2, 2, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['w_adjust', 'F_adjust', 'CR_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(1.1, self.w + 0.05)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.95, self.F + 0.05)\n            elif learning_strategy == 'CR_adjust':\n                self.CR = max(0.3, self.CR - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.95, self.CR + 0.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.1 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumInspiredPSODE", "description": "Adaptive Quantum-Inspired PSO with Dynamic Differential Evolution Mutations using Heterogeneous Velocities and Feedback-driven Parameter Tuning.", "configspace": "", "generation": 60, "fitness": 0.27586690648531714, "feedback": "The algorithm AdaptiveQuantumInspiredPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.23.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.49202417280189803, 0.697007897867262, 0.5591281929128745, 0.6068286855861014, 0.7028756400482877, 0.6226114763764401, 0.5318363292523149, 0.6046216358423593, 0.6021669092464332, 0.12528861796365176, 0.22198383376222663, 0.25562380864329093, 0.279977316349331, 0.27162707878920733, 0.25125348069103404, 0.15439773909309806, 0.20408015195854368, 0.22334467343586895, 0.17352587153217924, 0.1485018552340307, 0.13392429365820702, 0.12172855494464196, 0.13718011139518627, 0.10614396921546798, 0.10698691479582834, 0.11668701567245299, 0.18797964050316374, 0.11650261940503948, 0.10525856826222879, 0.09802920216377953, 0.11557720726129606, 0.1157578137164732, 0.08057329462097118, 0.1120210508428543, 0.13066303878169205, 0.12565726953613632, 0.9830927428025503, 0.9787060531257714, 0.9831924442472195, 0.9723944449679846, 0.9712529006104266, 0.9705349243888207, 0.9830866842157088, 0.9843343788349963, 0.9815394521716957, 0.3097086912635083, 0.3666406907165095, 0.4095709220273017, 0.27277621216355685, 0.42328563180413525, 0.41274931662435954, 0.11703711945873896, 0.4302333732191098, 0.4812961893809624, 0.16764569440186172, 0.22225579479022806, 0.5307582251450551, 0.21975452386738348, 0.7651336881097617, 0.19013851236920587, 0.6912530298691834, 0.6901722945037381, 0.6590489608402726, 0.20098668093638794, 0.19010666727815562, 0.30867780610711393, 0.11662802061690969, 0.19814288559257442, 0.34520010195309236, 0.1599414076324781, 0.18020168250603474, 0.18824218292806882, 0.2923098290614724, 0.13839755893053574, 0.1979347057933294, 0.16831734939745113, 0.17508189768970062, 0.3392460145704945, 0.23162120893848281, 0.25214328600246017, 0.1686731058745774, 0.06388579566836905, 0.02861241454038521, 0.09983925801401916, 9.999999999998899e-05, 9.999999999998899e-05, 0.007879828956393609, 0.030427375581636662, 0.12475925494903295, 0.12104118852905288, 0.18367152610680115, 0.08525260569501314, 0.08346625975489641, 0.06481683356430845, 0.19327091036706123, 0.08180322572196497, 0.16835478661081504, 0.24631391144112003, 0.14662885873275078, 0.0359232557441681, 0.07322191913412701, 0.05611409245225518, 0.09411229392065323, 0.08819089823317483, 0.10047535371193994, 0.056282721303213434, 0.08208578543584577, 0.05201761313843467, 0.08878709111928929, 0.03960098660520284, 0.2122893740095767, 0.15716545630938872, 0.18815773680672632, 0.18422805672424103, 0.04994413607902748, 0.1351072777027681, 0.1516719694469466, 0.45812540849606687, 0.5801683103504771, 0.5785186839422636, 0.45746908241402584, 0.5370765485608788, 0.5434326115073952, 0.5298336857493642, 0.47499194986725135, 0.5296018547332979, 0.0891970314644821, 0.06822953237316653, 0.10808707695087838, 0.12099412464004677, 0.13147022380903906, 0.10442615667353583, 0.1275575975746267, 0.14242558292946128, 0.11579651104582078, 0.20244587440030049, 0.14913883684625762, 0.33547896342512706, 0.2471313862561948, 0.3345602712009237, 0.3663397715843866, 0.1912783332421789, 0.2780477384021709, 0.195171166213718, 0.2786878413929855, 0.2785919834783278, 0.24023830786491185, 0.3444078509207469, 0.3103250187992552, 0.3133712668698816, 0.34001640518019227, 0.36116562037094346, 0.3732875069322381, 0.23227966770660446, 0.16981354532525306, 0.25394277793806896, 0.19925722227374532, 0.18161414959415367, 0.27679307350015514, 0.2683055660821403, 0.2794112436020104, 0.2510502517009282, 0.2073763943994157, 0.21971299097345398, 0.23019873646236189, 0.2346727874390444, 0.1970118544718804, 0.24464400472970949, 0.17010714232158974, 0.21606601060812325, 0.19459388854052695, 0.19269101014515722, 0.21666802162755416, 0.21140265998015673, 0.2198108040376442, 0.203494917325712, 0.19768193786523602, 0.33358931274972015, 0.20885352597328966, 0.19907469820367008, 0.13118315084844057, 0.18640180621011437, 0.18493501443697247, 0.7703194656900715, 0.19675701969887338, 0.7547423216049849, 0.14088145681067255, 0.16204613197400486, 0.8185691481934048, 0.7793902826530733, 0.20623620531406295, 0.6540264459315139, 0.5554622609560853, 0.16550778520897202, 0.16423163324394485, 0.2056823846761724, 0.20857982414345255, 0.7371556224143865, 0.19356267725280962, 0.18382229238776004, 0.20516838050677222, 0.18316609252712446, 0.19113797893606144, 0.18338697074733867, 0.19236481192533972, 0.1933002778438605, 0.18755584234812583, 0.08307591360095534, 0.10366318404849117, 0.08992432826846308, 0.08648269370343264, 0.09234334332327399, 0.07450992330790174, 0.07310182744267513, 0.08089640572901646, 0.08605531287794]}, "mutation_prompt": null}
{"id": "9a8aa7dd-d1b9-4e78-8f6e-ac04a5a5bae3", "solution": "import numpy as np\n\nclass RefinedAdaptiveHybridPSODEPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.4 * np.random.rand()\n        self.c1 = 1.5 + 0.2 * np.random.rand()\n        self.c2 = 1.7 + 0.2 * np.random.rand()\n        self.F = 0.5 + 0.35 * np.random.rand()\n        self.CR = 0.65 + 0.25 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.15) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c1 + 0.15)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.15) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c2 + 0.15)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.w + 0.05)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.F + 0.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.05 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "RefinedAdaptiveHybridPSODEPlus", "description": "A refined adaptive hybrid algorithm incorporating stochastic learning strategies with probabilistic mutation for enhanced global exploration.", "configspace": "", "generation": 61, "fitness": 0.34041893919806543, "feedback": "The algorithm RefinedAdaptiveHybridPSODEPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.26.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.7727699768166323, 0.8131511807539106, 0.8049602361975452, 0.7686149207403543, 0.8204088266384733, 0.7919185255897758, 0.7825019874578604, 0.7869369503378965, 0.7968332474650046, 0.47107490743484637, 0.5727493912283321, 9.999999999998899e-05, 0.5561580384950667, 0.4197762340961937, 0.5267415325229798, 0.01628079604298127, 0.6321313496886138, 0.5185567083193456, 0.13426213747118876, 0.14380971193519831, 0.11138826300367677, 0.14909790717009963, 0.10919027479562704, 0.132342732748436, 0.145788800003667, 0.1286627928058287, 0.14839976135274768, 0.1061517611825018, 0.11221151025771958, 0.10957909466493676, 0.12607556437446965, 0.12124989670492325, 0.07421284118200222, 0.12462219714856981, 0.13915013991937053, 0.11320641302637413, 0.9801765768086639, 0.9735097628434798, 0.9825240148874954, 0.9726450708970316, 0.9721584826975294, 0.9717912616473793, 0.9729211824043159, 0.9835484494494842, 0.981058781218957, 0.6096011906061467, 0.6130781527253404, 0.4746290825876549, 0.4963662284242566, 0.6064698912545987, 0.548014726960953, 0.10845509804916076, 0.5300016735383354, 0.5513850852832687, 0.22616099394248623, 0.7942611197101694, 0.7608674385363227, 0.21933825214773606, 0.8211374448772443, 0.20360154240743522, 0.8377452491004455, 0.437397793785147, 0.4068560779106025, 0.6108456318807782, 0.34053823594269317, 0.5279273547044456, 0.43841327857872026, 0.5066428936238757, 0.5934336586302145, 0.5956056867045221, 0.1071686913495572, 0.4657349820812897, 0.475860365064944, 0.5056001011870496, 0.124040116412934, 0.5163347305269368, 0.6338716879456955, 0.11796551932318666, 0.48606690614518455, 0.4548609875805182, 0.0933359488162403, 0.34058653848300624, 0.04644142721643674, 0.07444303657628715, 9.999999999998899e-05, 0.03585566980227051, 0.009008103555672053, 0.15153656767164925, 0.1980881194706391, 0.17384934999094603, 0.20622275724848982, 0.16346276070940946, 0.1618679299064233, 0.18828594533299825, 0.2653632094521192, 0.13113376785333553, 0.3775166726566864, 0.489297188709619, 0.6130340457193801, 0.07474818975488584, 0.07035088366862385, 0.24232878138328295, 0.11842071720089753, 0.07003335336969774, 0.08090661069529992, 0.0877742019955775, 0.10203277782909204, 0.14140476814880132, 0.18368314377278006, 0.23343972574323557, 0.22319311883240267, 0.3021775590262077, 0.2990672295607557, 0.2783032793454865, 0.06564953105331828, 0.18942459187581562, 0.11964057974240927, 0.6881695844453382, 0.6531996419660566, 0.6224065173528296, 0.5683256651360185, 0.6762456467516307, 0.20717221607698844, 0.6439500012863124, 0.7000246580608983, 0.6631310536057113, 0.09341868973692458, 0.07307770949834136, 0.15016801703550298, 0.08868199062072313, 0.12024473298115501, 0.1059840008984132, 0.09447513892386195, 0.09838757030877254, 0.10055114814700827, 0.14845023370469168, 0.19826916920459603, 0.17291933117013902, 0.2514147188608089, 0.20870395079537163, 0.16520276180652782, 0.3031445884143691, 0.19660596385228668, 0.19519321577448467, 0.24222955133234159, 0.36558607518053776, 0.33677204557481333, 0.42514670596323245, 0.29958093693248833, 0.38326844115798275, 0.38326123427324255, 0.5361013268055164, 0.29350586116218114, 0.2632044003798455, 0.23430963088994616, 0.2432498395541205, 0.30365879804848706, 0.31661646145258626, 0.2378749225888881, 0.4578747479088713, 0.2947319688948433, 0.23503967755002264, 0.24261535920281163, 0.18829085527757894, 0.2024946614979123, 0.23776839658810145, 0.19998893286554098, 0.23519294611819497, 0.18240893015397652, 0.24592510824865965, 0.29683094215056194, 0.23854555425958668, 0.1990608222781901, 0.19743007608600305, 0.2202338906357827, 0.24263516692443432, 0.1939939787573447, 0.18844135658936656, 0.20818103836256663, 0.201615150025509, 0.848932826965072, 0.1877682041762243, 0.16724635532968024, 0.8544868398348354, 0.19979438203859468, 0.1684217621201618, 0.14216623318432353, 0.1603011662866013, 0.8856027714613617, 0.8620952378165425, 0.2063160621796999, 0.7406136222057657, 0.2046792962737488, 0.8026424893200443, 0.1501099039830911, 0.10339251739372479, 0.10473481013770836, 0.8135682455015578, 0.19111828792041918, 0.2099777992578319, 0.19398606935587048, 0.2324522083485404, 0.22835951879302563, 0.2045092538597555, 0.2288381410671757, 0.20973563914239723, 0.21909755416447185, 0.10182232199148289, 0.0927036003190429, 0.10973762799907671, 0.09562773922447454, 0.08931449114610512, 0.10202976273968856, 0.06975068426713116, 0.08744690254259091, 0.0802406862189724]}, "mutation_prompt": null}
{"id": "1773ef73-21f1-4fe0-8637-0ebbcc8ea8f0", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.6 * np.random.rand()\n        self.c1 = 1.2 + 0.8 * np.random.rand()\n        self.c2 = 1.2 + 0.8 * np.random.rand()\n        self.F = 0.4 + 0.5 * np.random.rand()\n        self.CR = 0.5 + 0.4 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n        \n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust', 'CR_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.1) if self.global_best_score < np.mean(self.personal_best_scores) else min(2.5, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.1) if self.global_best_score < np.mean(self.personal_best_scores) else min(2.5, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.07) if self.global_best_score < np.mean(self.personal_best_scores) else min(1.0, self.w + 0.07)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.1) if self.global_best_score < np.mean(self.personal_best_scores) else min(0.9, self.F + 0.1)\n            elif learning_strategy == 'CR_adjust':\n                self.CR = max(0.2, self.CR - 0.1) if self.global_best_score < np.mean(self.personal_best_scores) else min(1.0, self.CR + 0.1)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.05 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedAdaptiveHybridPSODE", "description": "An enhanced adaptive hybrid PSO-DE algorithm featuring dynamic parameter adaptation and synergistic exploratory-exploitative balance.", "configspace": "", "generation": 62, "fitness": 0.3014168773642851, "feedback": "The algorithm EnhancedAdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.26.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.5169618767804044, 0.8410662467176796, 0.835634758303637, 0.4798509660070134, 0.8372988334673941, 0.8384533250916308, 0.49429087206976463, 0.8488470842267415, 0.8242067148929894, 0.057670148228584406, 0.6045017455852821, 0.5988307593872282, 0.1752879463871031, 0.6458809648408194, 0.6131289970399108, 0.10260582991338929, 0.6469488519785893, 0.3165523433366658, 0.10561263274383215, 0.13746710850242472, 0.134080771366471, 0.09408768917550736, 0.11465124851204145, 0.10688670175243764, 0.10635330135671628, 0.09801284764440044, 0.13442601837570745, 0.09068386101946635, 0.10481382075649859, 0.09128249930921906, 0.08598025330758008, 0.1660029555684196, 0.10819465622795599, 0.0920797263593166, 0.08714882293307868, 0.05794129471771792, 0.9830743076767943, 0.9725296918439585, 0.9801465836384641, 0.9510953877793038, 0.9615797756527714, 0.9621608764074092, 0.9730098384862405, 0.981398440915746, 0.9811150576825837, 0.24379788048460116, 0.6684045235630043, 0.6408694443052629, 0.24778707440223302, 0.6039393257069072, 0.6657978158343645, 0.27755182382365307, 0.6366390883852441, 0.5575374408699015, 0.5572057657519126, 0.38753121475238694, 0.22390083139836758, 0.5019649005390796, 0.8985391064148138, 0.20416360258989752, 0.42878151698976663, 0.1758305032554841, 0.8278556453901069, 0.15714020623427316, 0.15624274852712916, 0.16861334725176125, 0.08957912606775009, 0.2293571363092024, 0.3522447012520874, 0.14941531628176585, 0.17017000703379148, 0.5567418981607664, 0.11468409726061868, 0.1184438471895004, 0.2912785682669726, 0.20871019783705702, 0.21869452831056602, 0.5403185477733946, 0.16498621645643285, 0.23225626829324408, 0.24820566870959704, 0.036228483721524984, 0.0031143891683909075, 0.09523598100800879, 0.02371650555692173, 0.005952113406718862, 0.03175070859145346, 0.0019090027361884365, 0.08918952577473971, 0.007251039787211311, 0.05620237958743746, 0.06168515937863739, 0.09170411248085952, 0.026921251964647452, 0.11843709127713775, 0.09811907914166773, 0.09311249836859659, 0.45180364192146705, 0.1743161649801681, 0.017729360777810177, 0.10419939808115886, 0.04606694656249988, 0.05788921836699956, 0.12161117751734873, 0.16177136372945733, 0.05965233288473426, 0.17055854197639875, 0.2001422230410288, 0.14147563032864996, 0.11590089779665302, 0.20171103148674796, 0.14562421369014877, 0.26458753851743955, 0.20757075113854617, 0.04329473866715583, 0.18820174288150993, 0.18751013299848884, 0.3423901862160955, 0.6420275543012364, 0.7263608685125229, 0.38797588969890284, 0.619464738522739, 0.5387144142335878, 0.4203940369948882, 0.6633358564117127, 0.6135187737612489, 0.12211878940813203, 0.07058994242579242, 0.11247608446134216, 0.11892541212280083, 0.13649531207274068, 0.08193970776519055, 0.07194495657587208, 0.13780426582728345, 0.13989495198630808, 0.3265054459817025, 0.23993262686520256, 0.2149657064215844, 0.19603935813402107, 0.2645059251815065, 0.38946415577459015, 0.22575335449981682, 0.3897370925296757, 0.4477771972222585, 0.2646332980261862, 0.35195176060548383, 0.21847120426924171, 0.2949014237924307, 0.5152812586137108, 0.2847501756209597, 0.2547656652394523, 0.4756637024075929, 0.45934568208014726, 0.2173140900380418, 0.18112650859384682, 0.2847770585719531, 0.2314320689029643, 0.18503131272124218, 0.2712933857498121, 0.24188386180109178, 0.2328086954009998, 0.21852376299205567, 0.24010444286792298, 0.19088451100571746, 0.191954416575428, 0.26642856393743364, 0.20850978102348827, 0.17896388516183992, 0.19816052347973878, 0.2507438530464414, 0.21345319065323531, 0.21532928071879454, 0.1937595009585159, 0.2041152634721719, 0.19385624115104994, 0.18847911891245406, 0.2191437786476248, 0.3077279213159062, 0.20765205022567312, 0.2035955029534935, 0.7003268336923267, 0.18809377411166284, 0.16780470587956275, 0.6282584604427853, 0.1999008168801487, 0.1698845681277087, 0.1404803531530151, 0.163880048667699, 0.8780021146873841, 0.47590160361002687, 0.21099541355566076, 0.823522433503308, 0.19627946388048279, 0.8031255309512427, 0.14994135929081243, 0.2039814804850193, 0.10450530084693, 0.7703169356050569, 0.18412433795861083, 0.21860173692606744, 0.20138668006240146, 0.18960652442200632, 0.18220117664626423, 0.22613388884379815, 0.18859815793253742, 0.20316389534966361, 0.2501434970854429, 0.07897750343767507, 0.09809304653941253, 0.09010057261515025, 0.08245150685765479, 0.10751119662542674, 0.08346645410054532, 0.09739709521853346, 0.09598322171202422, 0.09787374060429355]}, "mutation_prompt": null}
{"id": "2304daa2-023a-4401-85ae-8b5edbde6199", "solution": "import numpy as np\n\nclass AdaptiveQuantumHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.4 * np.random.rand()\n        self.c1 = 1.5 + 0.1 * np.random.rand()\n        self.c2 = 1.7 + 0.1 * np.random.rand()\n        self.F = 0.5 + 0.3 * np.random.rand()\n        self.CR = 0.6 + 0.3 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def quantum_rotation(self, vector):\n        angle = np.pi * (np.random.rand() - 0.5)\n        rotation_matrix = np.array([[np.cos(angle), -np.sin(angle)], [np.sin(angle), np.cos(angle)]])\n        return np.dot(vector, rotation_matrix.T)\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust'])\n\n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.07) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.w + 0.07)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.07) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.F + 0.07)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.05 * np.random.randn())\n                mutant_vector = self.quantum_rotation(self.population[a] + mutation_factor * (self.population[b] - self.population[c]))\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumHybridPSODE", "description": "Adaptive Quantum Hybrid PSODE: Integrates quantum-inspired rotation gates for enhanced exploration with adaptive particle dynamics for optimal synergy.", "configspace": "", "generation": 63, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('shapes (5,) and (2,2) not aligned: 5 (dim 0) != 2 (dim 0)').", "error": "ValueError('shapes (5,) and (2,2) not aligned: 5 (dim 0) != 2 (dim 0)')", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {}, "mutation_prompt": null}
{"id": "fc69e261-de74-46c2-848f-ed7d759bd199", "solution": "import numpy as np\n\nclass AdaptiveQuantumInspiredHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 4))\n        self.w = 0.5 + 0.3 * np.random.rand()\n        self.c1 = 1.4 + 0.2 * np.random.rand()\n        self.c2 = 1.6 + 0.2 * np.random.rand()\n        self.F = 0.6 + 0.2 * np.random.rand()\n        self.CR = 0.7 + 0.2 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust', 'quantum_jump'])\n\n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.07) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.w + 0.07)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.07) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.F + 0.07)\n            elif learning_strategy == 'quantum_jump':\n                for j in range(self.population_size):\n                    if np.random.rand() < 0.05:\n                        self.population[j] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.05 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumInspiredHybridPSODE", "description": "Adaptive Quantum-Inspired Hybrid PSODE enhancing convergence with quantum superposition and adaptive learning heuristics.", "configspace": "", "generation": 64, "fitness": 0.3014164220317447, "feedback": "The algorithm AdaptiveQuantumInspiredHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.26.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.4461319682011513, 0.8035140158521261, 0.8275934074791418, 0.5479547990378821, 0.8288282365429492, 0.8072389404501543, 0.4828496757983145, 0.832120189651654, 0.8121272492753862, 0.038910454385371884, 0.5742496115465057, 0.578310868302933, 0.09199117686253044, 0.6417778823119948, 0.5641344356708842, 0.032238790093461867, 0.5738081291044884, 0.5378793309253505, 0.10246531774063727, 0.12708800515835428, 0.11985635143560591, 0.129779455093873, 0.13750936279449255, 0.13677028034733607, 0.12084195094066597, 0.17097876942047618, 0.13010186569555915, 0.09957043076617611, 0.06263198409052695, 0.11291541410718509, 0.09361973999346207, 0.11207356705878102, 0.10412110925172946, 0.09405439446422448, 0.11191315503433019, 0.11095530469671355, 0.9805682034768941, 0.9739585414798265, 0.9824925984760674, 0.9611148599532835, 0.9762959355695244, 0.9717390752953399, 0.9727994562107651, 0.9836770085600643, 0.9790353359395638, 0.2007400897087439, 0.5960373880808858, 0.632959443706991, 0.2559916874731544, 0.5489162581023073, 0.5935720345389357, 0.14914661148868724, 0.08753418067940255, 0.674811772414915, 0.30231503519459346, 0.8190009783682749, 0.2238505448787379, 0.5628759095939941, 0.8473257477122524, 0.20990758661725484, 0.12213443993164563, 0.7692249219442653, 0.8095635145260562, 0.12120079279711338, 0.3272436436165401, 0.6671258035934833, 0.1773597109270555, 0.6636207184822709, 0.13001521887926393, 0.14095010729277058, 0.11995890218339755, 0.4143944590582842, 0.19086224457497825, 0.4927739448831828, 0.4163173364505973, 0.12570265615031517, 0.23809968147162863, 0.3764855141258696, 0.13654142359156507, 0.40728248579890547, 0.12056835343040351, 0.028464264021521357, 0.07335088855087302, 0.03583930476960229, 9.999999999998899e-05, 0.0002753288352296268, 0.03457717250984149, 0.007891335510648467, 0.06885896819069859, 0.0054671360636714406, 0.115716225092795, 0.2519716971745779, 0.17651056206019422, 0.042114514479145715, 0.10997297393303485, 0.07809806801548491, 0.07730388299439206, 0.20092318496006034, 0.4381240406678588, 0.01896678722665479, 0.10522548641038809, 0.07123294045731021, 0.03715247958542822, 0.20813792780477713, 0.0809324426292003, 0.03575139718994069, 0.15310502198029607, 0.10853554945603539, 0.11226288931168604, 0.16440635467436493, 0.16843442872682912, 0.09262217200844514, 0.41955188238689833, 0.13779264720725481, 0.04662091214650044, 0.16366409921958625, 0.11737840781778541, 0.39653690533969543, 0.6547923029864646, 0.6547833863747923, 0.4510577387351409, 0.6745769354747105, 0.5396227151123754, 0.45004830621740266, 0.6724895009300278, 0.637876749436173, 0.10604041711419343, 0.06969539376049128, 0.10507193385027536, 0.10098662288801386, 0.07920870574248495, 0.1015565417214066, 0.08363251475400335, 0.13859644973980267, 0.11934556947390884, 0.18015330915801586, 0.21010530423575768, 0.17250839248690786, 0.20039220956072346, 0.3311127413862779, 0.2761075422924425, 0.1676326332346687, 0.18245907175225495, 0.18071267616354725, 0.3217987544647696, 0.3048624912956468, 0.3708575122125807, 0.2670420964645477, 0.27760625803248273, 0.28391700881767123, 0.27062404014315655, 0.5176938441170376, 0.4379420405483041, 0.18872339184445686, 0.29359545941379717, 0.26406718194315204, 0.2142969928700037, 0.32280812091078415, 0.17563437531914206, 0.2065416484708008, 0.27519003522079355, 0.22026308744899648, 0.19726602204993138, 0.22395929338341747, 0.2108536618238268, 0.22162876985623226, 0.1938484686741736, 0.2622721452238864, 0.19724316955289856, 0.24242525172128748, 0.2685837000818272, 0.19500877040454434, 0.1938401475203667, 0.1752033246161785, 0.19355645695193058, 0.24289937982867127, 0.20443281216060227, 0.19750701573761842, 0.19527527926879418, 0.2030727636042866, 0.7158881787439417, 0.18726491642751664, 0.16623260677102558, 0.5689011719509045, 0.19917371122003946, 0.16874680673218223, 0.5827145101923965, 0.1649497387072122, 0.8875893257132338, 0.6508417682869401, 0.21072659393823734, 0.20501446267578394, 0.3777524864221945, 0.7477619110371698, 0.14274760081927107, 0.19389747327680706, 0.10457756420148467, 0.6860229856037879, 0.19136569461223096, 0.2048362328515847, 0.18958426673647077, 0.18356631539722423, 0.22226859326129267, 0.22125255774906316, 0.19385723363779073, 0.22118317853029557, 0.22139942347110864, 0.07966272315246714, 0.08991722607426145, 0.10163168182668947, 0.08171829539384967, 0.08615362781028957, 0.07812592731084567, 0.0655186521452612, 0.10760216627821284, 0.09572505709576051]}, "mutation_prompt": null}
{"id": "762d893c-9836-431c-acc2-d9b101ec7888", "solution": "import numpy as np\n\nclass RefinedAdaptiveProbabilisticPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.4 * np.random.rand()\n        self.c1 = 1.5 + 0.1 * np.random.rand()\n        self.c2 = 1.7 + 0.1 * np.random.rand()\n        self.F = 0.5 + 0.3 * np.random.rand()\n        self.CR = 0.6 + 0.3 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.07) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.w + 0.07)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.07) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.F + 0.07)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.05 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "RefinedAdaptiveProbabilisticPSO", "description": "A refined adaptive probabilistic hybrid PSO with self-adaptive mutation to balance exploration and exploitation.", "configspace": "", "generation": 65, "fitness": 0.35943593658261375, "feedback": "The algorithm RefinedAdaptiveProbabilisticPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.28.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.798386629940598, 0.8140038684614535, 0.8022257739253773, 0.8023115510660797, 0.8324033018839588, 0.8184184473952807, 0.8120566341802481, 0.7993198247980557, 0.830823275729308, 0.5795948532511028, 0.5184018813252469, 0.5279612888639034, 0.5918061856791046, 0.5572764850684835, 0.5971402525569998, 0.593117346688006, 0.6036054724537274, 0.5777604494417663, 0.11669860609931693, 0.16069576018193965, 0.10515671117543535, 0.11115510671037987, 0.09192719214687983, 0.1425447726839265, 0.1365145635804731, 0.17729713437732175, 0.17310659748063395, 0.10916456457730006, 0.09501007898284675, 0.11556753927066055, 0.09644785178445947, 0.11992227730625749, 0.06977562895438627, 0.11030940298197511, 0.10642740296674769, 0.10583141808703855, 0.972702869562636, 0.9734682035510478, 0.9831630328586503, 0.9724673614502476, 0.9601656476954725, 0.971776196486502, 0.9727960929662032, 0.983443976067325, 0.9811028069051303, 0.5860061461203013, 0.614958936450563, 0.4824813399814424, 0.5749243798309396, 0.5183423735427716, 0.5346874091244398, 0.3716568559129897, 0.5316056605031527, 0.6198740205272831, 0.818639586866515, 0.8557464882562138, 0.8446962081234877, 0.27693110622212247, 0.2810286150847312, 0.1913246094761576, 0.8667912388366211, 0.6776111362077089, 0.8719809217760112, 0.599760598012501, 0.31279641905649236, 0.47363532809451603, 0.35226551766115766, 0.539224002824372, 0.12711836465863946, 0.47142995242107355, 0.11781103706516582, 0.6525585029934937, 0.4706256080094052, 0.3660624169126805, 0.1188628285326302, 0.49851313964255883, 0.12933944798105035, 0.48349381480266684, 0.29951325546678376, 0.5541865179356009, 0.11907540124143434, 0.2015574593469862, 0.024079189879376628, 0.09212644549063753, 0.0005574733377475827, 9.999999999998899e-05, 0.005024103388300505, 0.15193662754138826, 0.007373356997960934, 0.0026853220055943483, 0.3862069038256317, 0.1308639359296876, 0.46188650429223466, 0.12692314380824532, 0.5982511478303985, 0.03206544678347767, 0.2231360977079263, 0.5997715183888047, 0.11162797799787183, 0.10523905600657457, 0.044269065988996936, 0.15943434761834907, 0.12992025203384017, 0.14205801688972008, 0.12922879311079782, 0.12137543076735224, 0.18127337626507045, 0.1794162716723957, 0.25041847638226267, 0.2321537829251844, 0.29425573727289767, 0.17064967965043287, 0.3423943177781099, 0.23154344838536112, 0.046791120164487277, 0.18065191530753177, 0.08151877538681807, 0.5793939088875715, 0.6132230275235317, 0.6669008482285673, 0.6433204586689387, 0.733932648379362, 0.6294404296832777, 0.6046570252268915, 0.7230082514781024, 0.6984237425627087, 0.0834325671990438, 0.08881094588975247, 0.07489263512343991, 0.12051603056305504, 0.08836200734603095, 0.12225722795775129, 0.08952770070009008, 0.17460663486795802, 0.08859689389089775, 0.1793335277069451, 0.7083661646768167, 0.679394607007183, 0.3713108550957366, 0.2734692359524077, 0.19337794445184608, 0.1525060408860438, 0.20849869612062322, 0.2734010044148508, 0.38168214527176425, 0.2043214517281865, 0.32112002384333416, 0.4312323109182896, 0.2688027628787678, 0.4527012119688615, 0.4444453649758131, 0.5569097490227879, 0.39121527241146914, 0.2836925656132451, 0.22356063774126156, 0.2424773204892876, 0.23477681174202092, 0.3161752085456172, 0.23883091560840775, 0.2394719535817702, 0.28942986971381335, 0.20623173049025045, 0.23152612979570453, 0.24251611653712013, 0.18695497620300017, 0.2335159925363629, 0.20977652042202155, 0.20193733614336074, 0.1931739391248376, 0.2552777578669372, 0.23321653550495047, 0.6127476312977345, 0.18592830997678622, 0.20312396905309782, 0.20062409426033934, 0.20386937699080754, 0.19629315268625358, 0.1830167088267054, 0.19555692176465977, 0.1787509790462729, 0.8597395584629448, 0.18808835825677095, 0.16785018580905475, 0.8328258435261078, 0.19930799163486668, 0.1690720345305654, 0.14249792249253768, 0.16210971051557066, 0.8983968451429901, 0.8497218458816995, 0.21101552451555516, 0.843832488821923, 0.8091987430182941, 0.8290098761366081, 0.15490699558431276, 0.20750644503642646, 0.10464825917080611, 0.8008128264896168, 0.19096637595505028, 0.227402232500599, 0.17840106690919433, 0.18234499013754357, 0.18753698498046445, 0.20520523876643992, 0.20259513208954738, 0.18463251153125004, 0.25451715914969175, 0.11865327581684937, 0.09584212818905946, 0.09172850776109787, 0.09895666545773152, 0.10068981796032461, 0.0958334016062592, 0.12800964299275142, 0.08053439922157068, 0.09035047680715236]}, "mutation_prompt": null}
{"id": "b26dc7da-d2b9-4f2a-a46c-94e6021a6514", "solution": "import numpy as np\n\nclass RefinedAdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.4 * np.random.rand()\n        self.c1 = 1.5 + 0.1 * np.random.rand()\n        self.c2 = 1.7 + 0.1 * np.random.rand()\n        self.F = 0.5 + 0.3 * np.random.rand()\n        self.CR = 0.6 + 0.3 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.07) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.w + 0.07)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.07) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.F + 0.07)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.05 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "RefinedAdaptiveHybridPSODE", "description": "A refined adaptive hybrid algorithm enhancing parameter tuning through dynamic probabilistic mutation and synergy optimization.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.798386629940598, 0.8140038684614535, 0.8022257739253773, 0.8023115510660797, 0.8324033018839588, 0.8184184473952807, 0.8120566341802481, 0.7993198247980557, 0.830823275729308, 0.5795948532511028, 0.5184018813252469, 0.5279612888639034, 0.5918061856791046, 0.5572764850684835, 0.5971402525569998, 0.593117346688006, 0.6036054724537274, 0.5777604494417663, 0.11669860609931693, 0.16069576018193965, 0.10515671117543535, 0.11115510671037987, 0.09192719214687983, 0.1425447726839265, 0.1365145635804731, 0.17729713437732175, 0.17310659748063395, 0.10916456457730006, 0.09501007898284675, 0.11556753927066055, 0.09644785178445947, 0.11992227730625749, 0.06977562895438627, 0.11030940298197511, 0.10642740296674769, 0.10583141808703855, 0.972702869562636, 0.9734682035510478, 0.9831630328586503, 0.9724673614502476, 0.9601656476954725, 0.971776196486502, 0.9727960929662032, 0.983443976067325, 0.9811028069051303, 0.5860061461203013, 0.614958936450563, 0.4824813399814424, 0.5749243798309396, 0.5183423735427716, 0.5346874091244398, 0.3716568559129897, 0.5316056605031527, 0.6198740205272831, 0.818639586866515, 0.8557464882562138, 0.8446962081234877, 0.27693110622212247, 0.2810286150847312, 0.1913246094761576, 0.8667912388366211, 0.6776111362077089, 0.8719809217760112, 0.599760598012501, 0.31279641905649236, 0.47363532809451603, 0.35226551766115766, 0.539224002824372, 0.12711836465863946, 0.47142995242107355, 0.11781103706516582, 0.6525585029934937, 0.4706256080094052, 0.3660624169126805, 0.1188628285326302, 0.49851313964255883, 0.12933944798105035, 0.48349381480266684, 0.29951325546678376, 0.5541865179356009, 0.11907540124143434, 0.2015574593469862, 0.024079189879376628, 0.09212644549063753, 0.0005574733377475827, 9.999999999998899e-05, 0.005024103388300505, 0.15193662754138826, 0.007373356997960934, 0.0026853220055943483, 0.3862069038256317, 0.1308639359296876, 0.46188650429223466, 0.12692314380824532, 0.5982511478303985, 0.03206544678347767, 0.2231360977079263, 0.5997715183888047, 0.11162797799787183, 0.10523905600657457, 0.044269065988996936, 0.15943434761834907, 0.12992025203384017, 0.14205801688972008, 0.12922879311079782, 0.12137543076735224, 0.18127337626507045, 0.1794162716723957, 0.25041847638226267, 0.2321537829251844, 0.29425573727289767, 0.17064967965043287, 0.3423943177781099, 0.23154344838536112, 0.046791120164487277, 0.18065191530753177, 0.08151877538681807, 0.5793939088875715, 0.6132230275235317, 0.6669008482285673, 0.6433204586689387, 0.733932648379362, 0.6294404296832777, 0.6046570252268915, 0.7230082514781024, 0.6984237425627087, 0.0834325671990438, 0.08881094588975247, 0.07489263512343991, 0.12051603056305504, 0.08836200734603095, 0.12225722795775129, 0.08952770070009008, 0.17460663486795802, 0.08859689389089775, 0.1793335277069451, 0.7083661646768167, 0.679394607007183, 0.3713108550957366, 0.2734692359524077, 0.19337794445184608, 0.1525060408860438, 0.20849869612062322, 0.2734010044148508, 0.38168214527176425, 0.2043214517281865, 0.32112002384333416, 0.4312323109182896, 0.2688027628787678, 0.4527012119688615, 0.4444453649758131, 0.5569097490227879, 0.39121527241146914, 0.2836925656132451, 0.22356063774126156, 0.2424773204892876, 0.23477681174202092, 0.3161752085456172, 0.23883091560840775, 0.2394719535817702, 0.28942986971381335, 0.20623173049025045, 0.23152612979570453, 0.24251611653712013, 0.18695497620300017, 0.2335159925363629, 0.20977652042202155, 0.20193733614336074, 0.1931739391248376, 0.2552777578669372, 0.23321653550495047, 0.6127476312977345, 0.18592830997678622, 0.20312396905309782, 0.20062409426033934, 0.20386937699080754, 0.19629315268625358, 0.1830167088267054, 0.19555692176465977, 0.1787509790462729, 0.8597395584629448, 0.18808835825677095, 0.16785018580905475, 0.8328258435261078, 0.19930799163486668, 0.1690720345305654, 0.14249792249253768, 0.16210971051557066, 0.8983968451429901, 0.8497218458816995, 0.21101552451555516, 0.843832488821923, 0.8091987430182941, 0.8290098761366081, 0.15490699558431276, 0.20750644503642646, 0.10464825917080611, 0.8008128264896168, 0.19096637595505028, 0.227402232500599, 0.17840106690919433, 0.18234499013754357, 0.18753698498046445, 0.20520523876643992, 0.20259513208954738, 0.18463251153125004, 0.25451715914969175, 0.11865327581684937, 0.09584212818905946, 0.09172850776109787, 0.09895666545773152, 0.10068981796032461, 0.0958334016062592, 0.12800964299275142, 0.08053439922157068, 0.09035047680715236]}, "mutation_prompt": null}
{"id": "276d10af-812c-4f80-a5b1-7f5892a14118", "solution": "import numpy as np\n\nclass EnhancedSynergyDrivenPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.5 * np.random.rand()\n        self.c1 = 1.5 + 0.2 * np.random.rand()\n        self.c2 = 1.7 + 0.2 * np.random.rand()\n        self.F = 0.6 + 0.2 * np.random.rand()\n        self.CR = 0.7 + 0.2 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c1 + 0.15)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c2 + 0.15)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(1.2, self.w + 0.05)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.F + 0.1)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.1 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedSynergyDrivenPSO", "description": "Enhanced Synergy-Driven PSO with adaptive velocity and mutation management balancing exploration-exploitation.", "configspace": "", "generation": 67, "fitness": 0.341679373687882, "feedback": "The algorithm EnhancedSynergyDrivenPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.26.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.7875044470810304, 0.7796574189702221, 0.7884835143023187, 0.7988046260820882, 0.8189191805171527, 0.7920329458939326, 0.7956198036729173, 0.8023866974132109, 0.7672476460736941, 0.46273832650138524, 0.45970844504920283, 0.45142829086244074, 0.4448691156192792, 0.5693410404694, 0.5657004745294942, 0.042360420066394955, 0.6153438745528897, 0.5380652568427703, 0.11098952772183002, 0.10601689719904084, 0.11125835264976724, 0.14941664992593906, 0.10359732740469785, 0.15180120113461548, 0.10275738565936832, 0.1462900978923326, 0.11348872107862662, 0.11008990051513268, 0.103175939933138, 0.08848562096977242, 0.13477992222266844, 0.07076986314902556, 0.09619217714934258, 0.15231067720348945, 0.09980491423375537, 0.0739621747728868, 0.9801700812609837, 0.9734494744201242, 0.9825740876423839, 0.9727689201738163, 0.9764085567758473, 0.9616248097138843, 0.9734084302825898, 0.9837915848831736, 0.9790158082184011, 0.5845872120100998, 0.5148872321563205, 0.5012692615310035, 0.5335769712730394, 0.6119835723362659, 0.5872078013307469, 0.17840846527568188, 0.4952753656192105, 0.5827422361279708, 0.22533806660343747, 0.7359519051328893, 0.7660496021649124, 0.19066390183294357, 0.2734546610704327, 0.18941434840099391, 0.24669463106277845, 0.7831650878577268, 0.8210123265843179, 0.3815424075068381, 0.21043788677795905, 0.4436045169867602, 0.10264902540304377, 0.5153218917212296, 0.3264956108092081, 0.5880047981138642, 0.11784337113398247, 0.4513769757375763, 0.19673667819312224, 0.5015120370786248, 0.24053710521267158, 0.42650280993483236, 0.4058444817136697, 0.13042075161294464, 0.12525316796918762, 0.5055170062600749, 0.09255114541227172, 0.05150174319467482, 0.24454980294670192, 0.07646462901100637, 0.03296418663538736, 0.04530277829858809, 0.014376643569910419, 0.06297337444099615, 0.3057863929509572, 0.33843942578562747, 0.14172465897545194, 0.229045456699013, 0.41232855087979947, 0.08147144986075983, 0.3463735097622992, 0.12346807112738911, 0.3881355918893027, 0.4557538209636729, 0.5240853368862052, 0.06345728537888007, 0.05667552220217298, 0.04310146263249848, 0.119754849036387, 0.23416575944695028, 0.16722766756367513, 0.08908452791860855, 0.08647193890471772, 0.14210895303393334, 0.2711325442174686, 0.17983708579054014, 0.3600310214121808, 0.2812745340893884, 0.31801256850407167, 0.2752108051500636, 0.04735694008250524, 0.20146964444012094, 0.25449992686550726, 0.6519303155870846, 0.6505014415956043, 0.6451853436011494, 0.696306838190226, 0.6566821058121863, 0.6077749111947761, 0.6335553859326181, 0.7340888401328667, 0.6830381161916732, 0.0938652916965681, 0.1143405135475124, 0.12932324730154687, 0.1324993985501025, 0.1069777030255924, 0.1396777484168995, 0.13534651580658774, 0.14269096544708082, 0.11398132632955638, 0.25508621767801476, 0.24731386792503085, 0.18004206600850825, 0.3716434175364659, 0.2894318920422976, 0.2695213858059027, 0.2031430669100298, 0.34043381965774666, 0.19296728056343726, 0.33170032220353063, 0.35259046921336346, 0.29299063643497614, 0.2612150323561948, 0.37589760037021047, 0.3782160871917718, 0.38500412897213854, 0.40312744397520683, 0.5039952373979479, 0.20327454904505238, 0.17421899423526066, 0.19968304344522814, 0.1978019928427759, 0.15924853505881276, 0.2855866977249689, 0.21034117546916586, 0.23761734930856282, 0.2423031170421941, 0.21199495264246038, 0.20472282452411694, 0.22506706874994775, 0.2817542025447006, 0.24671210262238885, 0.22535338355442625, 0.22459536574301642, 0.26672690931345455, 0.2710118333481436, 0.17870750345035813, 0.18594490420663534, 0.2062517736869497, 0.2184637606855233, 0.2015410495102694, 0.20819165903903103, 0.1865954566134066, 0.20056087308947668, 0.18022699905237838, 0.872518783259312, 0.1874387270074801, 0.1668021536511669, 0.8535416186843353, 0.19900777202477715, 0.8893038356187792, 0.14243610717514676, 0.16324102004270769, 0.8772708488772275, 0.8134018809331569, 0.20894544303905882, 0.7693963628836948, 0.7597748538231153, 0.6318916706132316, 0.10782738808288872, 0.20352211468337156, 0.10450021182901637, 0.8163938186270716, 0.19105818602078473, 0.23235474462518124, 0.18349304445205772, 0.1871525039007398, 0.229442195460415, 0.2156414686647311, 0.21502991106262737, 0.19641698689316234, 0.23589700682323023, 0.11483140649505763, 0.1032649175736764, 0.10123238199777629, 0.0841484140789669, 0.09961474547530347, 0.10301507412164557, 0.10078935633718777, 0.08500586590540293, 0.08249443350539609]}, "mutation_prompt": null}
{"id": "40a630a0-c756-456e-ae2d-a027dd3fb930", "solution": "import numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.2 * np.random.rand()\n        self.c1 = 1.5 + 0.2 * np.random.rand()\n        self.c2 = 1.8 + 0.2 * np.random.rand()\n        self.F = 0.5 + 0.25 * np.random.rand()\n        self.CR = 0.5 + 0.25 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategies = ['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust']\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            learning_strategy = np.random.choice(learning_strategies)\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c1 + 0.05)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c2 + 0.05)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.2, self.w - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.w + 0.05)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.F + 0.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.1 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedAdaptivePSODE", "description": "An enhanced adaptive algorithm integrating probabilistic mutation and self-adaptive parameters for optimized convergence.", "configspace": "", "generation": 68, "fitness": 0.3105392830941476, "feedback": "The algorithm EnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.27.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.8395318248928016, 0.8388960284740861, 0.8477604546371936, 0.8346764333426512, 0.8549636419413564, 0.8453920027945356, 0.8220104391933588, 0.84233712342768, 0.8356336347594051, 0.47788373706856246, 0.6667867939343008, 0.6153692115447085, 0.6324000260134989, 0.6624399860544794, 0.5995914664393593, 0.12492902855964061, 0.603748244777539, 0.5809014424692506, 0.13042489648379518, 0.11224414043110664, 0.17838539982974655, 0.16282561088580894, 0.18338296889201477, 0.14828396765405927, 0.12054912509331661, 0.1398119675363696, 0.11271402243560047, 0.1378560364244551, 0.09541742471823322, 0.1234648632034856, 0.1106063445555896, 0.1134145384516545, 0.085976671964765, 0.14610445294883811, 0.14526923174908601, 0.09321946601247622, 0.9824201226641016, 0.9725408119746647, 0.9825757873426492, 0.9619270613546801, 0.979540875742027, 0.963586375208504, 0.9837710596020692, 0.9836493076574013, 0.9750141852782862, 0.6823980363891463, 0.6761979947947614, 0.5851301463295242, 0.7056519391815782, 0.6073947043594188, 0.6474937733977619, 0.11802832270795005, 0.646663930984912, 0.5389277654266698, 0.2318824846027353, 0.8957624317227053, 0.3392318496344696, 0.8333673796919283, 0.19647578736500304, 0.19192243644240448, 0.1526127039630628, 0.15705171878805668, 0.8707227100587135, 0.23918060036827693, 0.1355637690600493, 0.12627077274674392, 0.23778238230187732, 0.2390304605295661, 9.999999999998899e-05, 0.21438465953504637, 0.2058668155854766, 0.1878210196208645, 0.19158347729308123, 0.15511301086278928, 0.11758948683404724, 0.2936603718857125, 0.1296770161506251, 0.45111711484176553, 0.3070886167155955, 0.19277845715869513, 0.12694759882619566, 0.0769260452735685, 0.050096047050904424, 0.09812259147060798, 0.0006428403343481381, 9.999999999998899e-05, 0.0781318522959682, 0.11831925518277786, 0.153341355263916, 0.05137914922489051, 0.23367419278096213, 0.07899746324757595, 0.288272182935443, 0.08506154556123768, 0.05900549707883651, 0.059309218422397, 0.09292363027543293, 0.05143011601462599, 0.2195584697898295, 0.12395660895847271, 0.04790805267454312, 0.2664071536297564, 0.16438856666496793, 0.1715302802340024, 0.08930293147199742, 0.13157347114091023, 0.16832500896464975, 0.15739242166947565, 0.14291869691811976, 0.13979240637224266, 0.36576317069235087, 0.12161716183299653, 0.047901082492043834, 0.12084433523019888, 0.12822270934274516, 0.08067002918664001, 0.10369991269513468, 0.5979079560657686, 0.5669736598906114, 0.5880312627797863, 0.6164635069041232, 0.5821894918076793, 0.6981815972794565, 0.6873261624790181, 0.5242636122313631, 0.6376401890459755, 0.08083847938176592, 0.0734725513407577, 0.09725869227655626, 0.0813473689951788, 0.06593738251882564, 0.10992537512670608, 0.11715728774120959, 0.11323211454038407, 0.13453131499160986, 0.24770860730141586, 0.2136988356173818, 0.17189308360967226, 0.20227922847560886, 0.3391028430745413, 0.33481906687043317, 0.2633484011851086, 0.12746067862966703, 0.2257093400348561, 0.23107337759497204, 0.3699288791357793, 0.4589818567500461, 0.28811689304912647, 0.3852501415544829, 0.283124842383248, 0.4114340416039788, 0.3005639104044673, 0.2729690741520976, 0.2865048812215817, 0.37430288606948636, 0.29129085561598234, 0.23774557630536397, 0.18905663476363466, 0.37435315259041746, 0.25278266607351685, 0.22275130807759946, 0.18660824432307888, 0.2032882700197246, 0.18635693696531042, 0.21546389596901705, 0.2886303678629786, 0.20686055549722138, 0.22533644886096116, 0.22755099560723568, 0.3002337460175658, 0.22900113266539102, 0.19584184390777637, 0.20715044685174921, 0.17887433050842283, 0.19888767996315682, 0.1998546836992624, 0.24710529783649915, 0.19625021226619976, 0.19182660464922618, 0.24638104327838006, 0.8918304212674404, 0.1785119760052688, 0.18751329011800877, 0.1724642518994256, 0.19982323964696946, 0.19825870454775552, 0.14165141929931158, 0.1608229859510144, 0.8982797472952213, 0.8395768441513521, 0.20843297744345624, 0.0735185753858908, 0.1656095717401217, 0.1680950861277688, 0.15231443069956951, 0.20396029452753417, 0.10481201212255364, 0.8773801607107109, 0.1877860489268316, 0.20760646608963484, 0.2381120322461312, 0.18468721285832712, 0.20048008436906228, 0.1939494216053741, 0.2409753454642748, 0.19873939163718002, 0.23049438969239167, 0.09759528269458462, 0.10174903258974188, 0.08388786152197247, 0.10275229242660955, 0.08986242000907918, 0.10618559517966064, 0.10625764109845115, 0.07883948453756695, 0.09703191720825821]}, "mutation_prompt": null}
{"id": "67f5c2d7-977e-42ff-8a12-ac8d7013f00f", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.4 * np.random.rand()\n        self.c1 = 1.5 + 0.1 * np.random.rand()\n        self.c2 = 1.7 + 0.1 * np.random.rand()\n        self.F = 0.5 + 0.3 * np.random.rand()\n        self.CR = 0.6 + 0.3 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n        self.restart_threshold = self.budget // 4  # Introduce a restart threshold\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust'])\n        \n        while self.evaluations < self.budget:\n            if self.evaluations % self.restart_threshold == 0:\n                # Stochastic restart mechanism\n                self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n                self.personal_best_positions = np.copy(self.population)\n                self.personal_best_scores.fill(np.inf)\n            \n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.08) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c1 + 0.08)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.08) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c2 + 0.08)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.w + 0.05)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.F + 0.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.05 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedAdaptiveHybridPSODE", "description": "An enhanced adaptive hybrid PSO-DE algorithm introducing stochastic restart and dynamic parameter adaptation for robust exploration and exploitation.", "configspace": "", "generation": 69, "fitness": 0.32041878676835855, "feedback": "The algorithm EnhancedAdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.26.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.8116215934082531, 0.8270576561700189, 0.816811049574994, 0.8311016131925191, 0.8299984726424191, 0.8025580475994116, 0.827343305623317, 0.8139035952460486, 0.8303251879276912, 0.582736698147783, 0.5569637879652487, 0.6180595350029104, 0.042617790283285495, 0.5597204616731939, 0.5955935528754484, 0.5369114951423233, 0.6402431926731018, 0.512866385598773, 0.13020111906205112, 0.13936217873731638, 0.15468683605396472, 0.10545396556304787, 0.1495234025199923, 0.1259244044600074, 0.10908744620091804, 0.12700213866941956, 0.13831273216154438, 0.10933470673150636, 0.1158579435639776, 0.10056914993470878, 0.11748464966014105, 0.0844589263464064, 0.10396155784815697, 0.12385744145400768, 0.11078184182465556, 0.1109120235252401, 0.9829646112985984, 0.9705210006991146, 0.9716527060278769, 0.9841391235963652, 0.9731949977972142, 0.9612551844119418, 0.971203303569012, 0.9747446794795416, 0.9715905384783725, 0.5057604436680687, 0.6382963296622163, 0.6183113125974835, 0.5827248451971696, 0.6064955768393969, 0.6795190891528194, 0.35179964376379513, 0.6554953504279548, 0.608508469584194, 0.23769046792608828, 0.8082732123273525, 0.8569118103178945, 0.2715900656568834, 0.8684876236950015, 0.271789887098734, 0.8206955828390676, 0.7848843247955816, 0.24345196360107324, 0.1283334357749749, 0.5730872692944111, 0.12856422077649676, 0.12894260399001345, 0.12732016228534027, 0.12234990481420738, 0.32809651096070447, 0.3573871613370485, 0.2291808876649173, 0.1579756092669684, 0.38667210646210903, 0.46528412849927503, 0.391346699585878, 0.12991189634081057, 0.1301776638154606, 0.37015581784731943, 0.4521949192978314, 0.12926221295716755, 0.05557348155815456, 0.06724552883682422, 0.07022581080742274, 0.045191905852512204, 0.06273809922665019, 0.24930778431978817, 0.19450343106106627, 0.18192886265031816, 9.999999999998899e-05, 0.09939728850361385, 0.1323330990991286, 0.5580880775456379, 0.1909347170998449, 0.051378830666228725, 0.1187571911052483, 0.21015640992542217, 0.3408572624706063, 0.46380578765656966, 0.11395343034241268, 0.06808563997650219, 0.031656503692374605, 0.06952915493107503, 0.18447830614355998, 0.07021709327918868, 0.09590464267932075, 0.069243770193128, 0.1640613797341881, 0.1964251696244883, 0.125141528447398, 0.13020800980293556, 0.3112360961382893, 0.32250331200828064, 0.3865643921689098, 0.2030221927072544, 0.17197062404309005, 0.0791851731861829, 0.6834014766892521, 0.6196114213686323, 0.7081822003162537, 0.6196312005354009, 0.643617251900094, 0.5755071873560929, 0.6224939313028022, 0.6449920491280461, 0.6428914927992517, 0.07996277885176972, 0.09636981065196504, 0.07741259943306944, 0.10978464780701436, 0.09060396275017668, 0.0868052708291499, 0.14937475959185686, 0.1111715968889353, 0.1445768977799713, 0.25036783235096005, 0.18357681221168154, 0.38842902924000877, 0.19336076870010055, 0.25748128834142436, 0.16292759789200684, 0.2369655082223645, 0.17532438627569968, 0.2813741367931718, 0.3396338531878751, 0.40704173695023127, 0.34047205138358594, 0.2815004520446952, 0.2694540728550071, 0.3739119485390363, 0.4487614266659067, 0.2043082923492, 0.4797350662669162, 0.24451752937777027, 0.18161413669016724, 0.23996915163807897, 0.22087202621816127, 0.23150304433720004, 0.2761857780578679, 0.30441559370997606, 0.29539337487249684, 0.2663043683188714, 0.21320211015916213, 0.2315423698593998, 0.25298273851894393, 0.21437209974799576, 0.22406254627754496, 0.2452471954557902, 0.2136226254179473, 0.23969600069127128, 0.21352304755402163, 0.2006862305976096, 0.7086679641811324, 0.18627544627583292, 0.17809895545393395, 0.2392362224282245, 0.19612559100088722, 0.1892548063686641, 0.19892492615085644, 0.23493948700928635, 0.18801603763931374, 0.18729471696388011, 0.1348799400402888, 0.18683045256978614, 0.1770312135484695, 0.18841913726386406, 0.1596798886779225, 0.12031833218300958, 0.1531239741087631, 0.16734368824568968, 0.16861484035084562, 0.21043673918509853, 0.2117231159996985, 0.2098266332480756, 0.8568282400340954, 0.1541882929234305, 0.31402150721280275, 0.16997350147660295, 0.20894971411756869, 0.215221394227612, 0.19972183182536207, 0.20289792811630614, 0.2050242568079158, 0.21811807387115156, 0.18128988848466443, 0.18894140436719176, 0.22382265231391296, 0.08930830639559895, 0.08099148741010065, 0.09267964719960908, 0.09145830117567089, 0.08953222908632252, 0.10205800881571758, 0.07352978986560788, 0.08486787535493368, 0.09393151021270385]}, "mutation_prompt": null}
{"id": "1565819d-6209-4e8a-91d8-e76d0b92e2b7", "solution": "import numpy as np\n\nclass AdaptiveMemoryInfluencePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.5 + 0.3 * np.random.rand()\n        self.c1 = 1.4 + 0.2 * np.random.rand()\n        self.c2 = 1.6 + 0.2 * np.random.rand()\n        self.F = 0.6 + 0.2 * np.random.rand()\n        self.CR = 0.5 + 0.4 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        adaptation_strategy = np.random.choice(['c1_decay', 'c2_decay', 'w_dynamic', 'F_influence'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if adaptation_strategy == 'c1_decay':\n                self.c1 = max(0.5, self.c1 - 0.05)\n            elif adaptation_strategy == 'c2_decay':\n                self.c2 = max(0.5, self.c2 - 0.05)\n            elif adaptation_strategy == 'w_dynamic':\n                self.w = max(0.2, self.w - 0.05) if self.global_best_score < np.mean(self.personal_best_scores) else min(1.0, self.w + 0.05)\n            elif adaptation_strategy == 'F_influence':\n                self.F = max(0.3, self.F - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.8, self.F + 0.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.05 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveMemoryInfluencePSO", "description": "An adaptive strategy using selective memory and environmental influence to dynamically adjust exploration and exploitation balance.", "configspace": "", "generation": 70, "fitness": 0.317755203986492, "feedback": "The algorithm AdaptiveMemoryInfluencePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.26.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.811511607633048, 0.8221124055666492, 0.823680713644549, 0.8279324661989662, 0.8382439105181004, 0.8381100887481189, 0.8169257273568302, 0.8246400799615228, 0.817182969052479, 0.620123437582061, 0.5714206251738628, 0.4946990180976236, 0.5122809942191355, 0.6424899923465098, 0.5484790301044447, 0.6380491240512878, 0.6806069071856988, 0.6303020184696166, 0.14645832822005656, 0.14725702812562902, 0.09464421583336802, 0.13151824958288894, 0.142574315536784, 0.11501114872996199, 0.09978529180066653, 0.13928108275263185, 0.1499442372480556, 0.10647878725177928, 0.1332077845900852, 0.11014537449784823, 0.11845428901883681, 0.10220963786604098, 0.1074788939956417, 0.12591204942553036, 0.10692988194174924, 0.10453680504214391, 0.9730501567701416, 0.9742421233001892, 0.9825153256429155, 0.9722941063366248, 0.958712356211936, 0.9624434057564716, 0.9736721839256867, 0.9833746002390975, 0.9811860161921271, 0.6428476349381296, 0.581249688695892, 0.46329080336756656, 0.5999346683048092, 0.5840171793921335, 0.681256298780258, 0.20419900279610825, 0.5980638810219662, 0.6944653307894852, 0.3862698876678248, 0.22810622269463832, 0.6830755750993277, 0.8779914124300703, 0.2728242091347771, 0.19198222465837023, 0.2244545169767943, 0.1903411068419777, 0.2323010817780674, 0.12698204058396445, 0.12025123710407315, 0.6716378648058701, 0.08823823336725822, 0.42547137471027896, 0.12868733167926472, 0.12835120221580565, 0.16295865316874714, 0.221266916992087, 0.5897445923358831, 0.12488279625697485, 0.26840767096129714, 0.5695189823504438, 0.3157220108421399, 0.1257397196371245, 0.4577662269994779, 0.46206969429652023, 0.1286656880478546, 0.05575393859195299, 0.03530921078561555, 0.037413191185728056, 0.01518405142795598, 0.03007922922644013, 0.045401525174399104, 0.06981226341439084, 0.028380711097356848, 0.0054407165973132665, 0.07468617519039455, 0.2025929290861994, 0.3213221026866646, 0.07912223540545038, 0.18486743643670067, 0.07919039468357603, 0.09926701732362786, 0.22806902353980762, 0.0997498695147675, 0.04947261722883434, 0.030202011993133104, 0.044556181093593605, 0.15413674037857816, 0.14015605633042727, 0.08338140381138925, 0.11869937453712232, 0.15833671159883111, 0.3185151290382311, 0.22307414144366944, 0.10895613468251997, 0.22584318328455744, 0.28558545393659174, 0.12711918173388181, 0.16907846429908346, 0.045674106657824676, 0.06880269138662276, 0.08131471731255402, 0.594241315155669, 0.668952113359339, 0.5683954162868133, 0.5518537899022384, 0.5745367701036579, 0.6552102562629054, 0.5763301694402387, 0.65456773712978, 0.5866084083558832, 0.08094226241029823, 0.07326148306664348, 0.09716871050366205, 0.15100824224406806, 0.13950624305902493, 0.1512305438165784, 0.09177093647815748, 0.17601663440877835, 0.06434934117824265, 0.17732258467904116, 0.1387635662544291, 0.19187874634299462, 0.3566438375302221, 0.35529587718839695, 0.35324302273068886, 0.17120723808092675, 0.2479967764819665, 0.2470224858167036, 0.314106528410103, 0.4670019102849212, 0.2889106290252149, 0.419030768004799, 0.31376709056651264, 0.620236759139924, 0.3883804098874165, 0.37868452831999533, 0.4233645852937912, 0.26292335818143364, 0.1924612700845718, 0.23612107577777885, 0.26847916529346894, 0.17879650496812938, 0.17625936232652017, 0.27160061132281, 0.2901062156012668, 0.17280376035082845, 0.2654840093666345, 0.21044202636258647, 0.20144209148199133, 0.2128954143558619, 0.21043957555253612, 0.22704029092565448, 0.19879174173577718, 0.2226013181814921, 0.2336959988661611, 0.19984936801902287, 0.19675207846109033, 0.23849380619992355, 0.19370807182039695, 0.22218169342770389, 0.20131344524562078, 0.2335917252588685, 0.1918603525598146, 0.20335407958123064, 0.8691266830919258, 0.18738466657287722, 0.1662785589153426, 0.1708849742327826, 0.1994924364051207, 0.16889348945523253, 0.1419109769542236, 0.16294847225106912, 0.8659500997334921, 0.8842937684170291, 0.20888264760306685, 0.2035891025003571, 0.20299443652679772, 0.7076410661757937, 0.1643839347595769, 0.20873356882785632, 0.10475775259524289, 0.8535513101451442, 0.19781537588207765, 0.20108178242529928, 0.24289945771296761, 0.1923004735495779, 0.1990996584959701, 0.21078762162049403, 0.21689061884503247, 0.1951666033277184, 0.22073804742173808, 0.08041629295050967, 0.09433016348170953, 0.09641988630898346, 0.07518179870017427, 0.0874963123198137, 0.08280792881476429, 0.09041865887554323, 0.09141604596142994, 0.08617518513188693]}, "mutation_prompt": null}
{"id": "4f47b9f9-9eed-4a66-a01a-a3350e828a7b", "solution": "import numpy as np\n\nclass RefinedAdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(80, budget // (dim * 3))  # Adjusted population size for better diversity\n        self.w = 0.2 + 0.5 * np.random.rand()  # Adjusted inertia weight range for dynamic adaptation\n        self.c1 = 1.4 + 0.2 * np.random.rand()  # Wider range for cognitive component\n        self.c2 = 1.6 + 0.2 * np.random.rand()  # Wider range for social component\n        self.F = 0.6 + 0.2 * np.random.rand()  # Adjusted mutation factor range\n        self.CR = 0.7 + 0.2 * np.random.rand()  # Adjusted crossover rate range\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, dim))  # Adjusted velocity initialization\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust', 'CR_adjust'])  # Added CR_adjust strategy\n\n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.4, self.c1 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(2.6, self.c1 + 0.05)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.4, self.c2 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(2.6, self.c2 + 0.05)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.2, self.w - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(1.1, self.w + 0.05)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.5, self.F - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.F + 0.05)\n            elif learning_strategy == 'CR_adjust':  # New adjustment strategy\n                self.CR = max(0.5, self.CR - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.CR + 0.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.05 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "RefinedAdaptiveHybridPSODE", "description": "A refined adaptive hybrid algorithm with enhanced probabilistic learning and diversification through stochastic adjustment of parameters.", "configspace": "", "generation": 71, "fitness": 0.31952472076941013, "feedback": "The algorithm RefinedAdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.25.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.7950669403793057, 0.7361794209551995, 0.7496449347440439, 0.7906879119743009, 0.711420742877531, 0.7593235418482405, 0.7917090658933515, 0.6748259310711775, 0.7467193029522989, 0.5449982402300656, 0.23700855437698298, 9.999999999998899e-05, 0.49476716978843205, 0.3479096126851591, 0.22574551350283312, 0.515731568322345, 0.24633672150849983, 0.39418029797090826, 0.1134703997114278, 0.10045193716250178, 0.2239631165288759, 0.10008701437868639, 0.13256457761983043, 0.11635412462187522, 0.10914087420799279, 0.10255561893881171, 0.1633677407436871, 0.08098442018486696, 0.13208042521296726, 0.10629292271064406, 0.09178435979346611, 0.092962284548881, 0.10751823735012567, 0.16969301767630984, 0.10298237939817423, 0.08887118468296884, 0.9781774388300247, 0.9803656602530527, 0.9751799739501172, 0.9503357935002659, 0.9623589110582642, 0.950039023218552, 0.9788606624582042, 0.9783585450021017, 0.9778804565669983, 0.5748070238257694, 0.4630639071448023, 0.41998158895556204, 0.5903014616619175, 0.5205424604428168, 0.5593532340526954, 0.38420039767500536, 0.4414431824262307, 0.5486649360839007, 0.7228580333437683, 0.22616929215529868, 0.7031443842931004, 0.21755667848898086, 0.2712428690463946, 0.1877309525258798, 0.8512315496346676, 0.6813167780984484, 0.2282581062165987, 0.35091580383827337, 0.12012273489965264, 0.12938066125363024, 0.523072958382601, 0.4131794755906868, 0.17857059187666624, 0.12764097468678848, 0.3150350569068201, 0.18968848468038968, 0.3484251395675012, 0.43055205669015184, 0.12655894882415197, 0.34954656036168796, 0.2965117839370588, 0.38985814742119473, 0.3784581455527578, 0.3911888129136466, 0.15951719354185256, 0.09993819970266415, 0.0628389130730791, 0.15670833225707315, 0.0004918759286122176, 9.999999999998899e-05, 0.0014507546651919556, 0.10970797494058493, 0.18732985730455198, 0.0025654381783684066, 0.552888894819142, 0.13558576951900903, 0.2930882668572474, 0.03670219470437719, 0.2831570053820459, 0.11861830038958654, 0.3014740928492021, 0.30264387813491467, 0.1588808735005539, 0.08413332913739724, 0.10687115331241748, 0.09790666422870387, 0.11239938815703987, 0.23020821132091474, 0.1147164693053273, 0.09335895643171865, 0.10110901071788847, 0.19561792794556343, 0.27116722989193653, 0.15875785412166166, 0.16630862413410918, 0.2094036480199446, 0.304653005730821, 0.2521238205298084, 0.04514624729549266, 0.22029067306727235, 0.08459537026774744, 0.6067073233124824, 0.539814557800453, 0.5681023781774138, 0.598862253966102, 0.5600717165338893, 0.5887066804932777, 0.632300087541054, 0.5413925555717691, 0.5667144198624281, 0.0905535142817413, 0.14076718988289738, 0.1026243704368448, 0.116020769937349, 0.1193923092482535, 0.15817291861352145, 0.07542060429127473, 0.10031247909366559, 0.10141447760676714, 0.1875927564994172, 0.2533450913421308, 0.22473711041850186, 0.1782032348951914, 0.24517202166920893, 0.2367807340590372, 0.20174472856697423, 0.21659287815082728, 0.3232427544753852, 0.3389202383859463, 0.39086246125050605, 0.41527872198031535, 0.46863556891233193, 0.42808467467665956, 0.31139214996894227, 0.3366260658326541, 0.41235392456323716, 0.2815120035289417, 0.31615545260608624, 0.22361129891411569, 0.3401347720580721, 0.2078622069986933, 0.2538821954854922, 0.23291366641892186, 0.2399325539233369, 0.29525868300614144, 0.1880365162739478, 0.20979039929903354, 0.19782071173931304, 0.20323509119115313, 0.207963725306755, 0.2348153222589361, 0.22374896503698116, 0.23269356042604472, 0.21453669195958414, 0.2503058349342715, 0.24694135665402084, 0.20296061870719218, 0.21364315266349154, 0.634749319157395, 0.24528784516778757, 0.24528059862942997, 0.1950082419139212, 0.18686350647219552, 0.2168088504670772, 0.8103720790239762, 0.18679022282311153, 0.8671724088476016, 0.8580136138845883, 0.1994277406465892, 0.16705891323242217, 0.1419026884973793, 0.15583254561353443, 0.8222998842442006, 0.8168843756211428, 0.2088855738922354, 0.20361972529317307, 0.7393646593053935, 0.6929301537077865, 0.15266632189564822, 0.16601792732999543, 0.10406168757161738, 0.637721038312546, 0.2128458947063897, 0.2333108570609057, 0.18551260080145815, 0.24502565761885153, 0.21978544814476386, 0.18929314114829365, 0.18407926366831096, 0.21755560425241716, 0.18649322103338073, 0.09221811657215384, 0.0828369305763057, 0.08468205818796082, 0.10472424368055833, 0.09432512740860388, 0.07757106610675746, 0.08415422348273582, 0.095382017209516, 0.08578864708383116]}, "mutation_prompt": null}
{"id": "1692cdf0-0061-4d0c-990c-df5c69fffde1", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.4 + 0.3 * np.random.rand()\n        self.c1 = 1.4 + 0.2 * np.random.rand()\n        self.c2 = 1.8 + 0.2 * np.random.rand()\n        self.F = 0.6 + 0.2 * np.random.rand()\n        self.CR = 0.7 + 0.2 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust', 'CR_adjust'])\n\n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(1.2, self.w + 0.05)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.F + 0.05)\n            elif learning_strategy == 'CR_adjust':\n                self.CR = max(0.5, self.CR - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.CR + 0.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.06 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedAdaptiveHybridPSODE", "description": "An enhanced hybrid metaheuristic algorithm integrating adaptive parameter tuning with probabilistic exploration to optimize convergence.", "configspace": "", "generation": 72, "fitness": 0.3095682776573241, "feedback": "The algorithm EnhancedAdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.25.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.509296041477736, 0.8072533358404358, 0.7905396161117995, 0.5947681970187347, 0.8121303892443419, 0.8226891484732531, 0.5660903646809254, 0.7725705313765997, 0.7879708822907401, 0.18552785122063054, 0.5792535701066512, 0.49634007686517734, 0.2025684910567528, 0.5483999348203218, 0.5768331910694161, 0.1706616744727023, 0.513719056599676, 0.3638813753992005, 0.10950176906162667, 0.10583966947129553, 0.10467406857060846, 0.11741137937692459, 0.15118738285136402, 0.10105380030701527, 0.11029310438044215, 0.11161793816173282, 0.13373128827086878, 0.09534033911095119, 0.09213270147060904, 0.08732912148467198, 0.09532884111185136, 0.09805301531264665, 0.09748579452857065, 0.09898472312740136, 0.10187592669105894, 0.13019251091968853, 0.9832259711763041, 0.9734814221425185, 0.9838195680317775, 0.9588279668980754, 0.9764520632916073, 0.9632167581436993, 0.973127330521621, 0.9845422365693672, 0.9814394336522457, 0.34947759165831527, 0.6177175468210947, 0.05699665070104021, 0.3562800726124582, 0.44830019642410424, 0.6117154556223048, 0.08725656068031218, 0.252781735731765, 0.47514542794182957, 0.6711033228975496, 0.8702015307963477, 0.22239902643546416, 0.6604573095780555, 0.8493904484263, 0.4114463051949788, 0.5774953260568265, 0.35006867739518377, 0.4671121372598138, 0.1881192694661249, 0.30753212135777697, 0.5081638143639253, 0.09692412841090914, 0.4785100897497918, 0.15805506428233562, 0.2258794621047031, 0.37748141693547843, 0.4655084114227622, 0.2508273076744896, 0.601468163001418, 0.120302772164256, 0.20574328714323442, 0.5661621566895898, 0.12256976283665333, 0.20177788291658694, 0.4401840864284159, 0.12113910465712685, 0.031172606058284313, 0.1843594629525569, 0.05665986612305407, 9.999999999998899e-05, 9.999999999998899e-05, 0.12129410025069043, 0.18482811967388824, 0.17387213865859086, 0.13592675231720108, 0.06963536858289843, 0.061549108182203605, 0.38206803149425117, 0.03786389307816718, 0.3059709251636207, 0.0252436213011783, 0.16138862246875196, 0.47097260595591495, 0.34142794898033835, 0.057323062567237515, 0.08225106570871088, 0.051273774863275556, 0.03197824489228751, 0.1321000326351297, 0.1367008640772125, 0.04752439747353199, 0.08818471003602169, 0.16710998438893165, 0.17713785703685303, 0.04177533810701517, 0.28282685759269066, 0.12239037776662332, 0.21280373827797272, 0.33233339522168504, 0.04453496457777195, 0.053475969648478894, 0.2588792610705076, 0.44096010876584646, 0.7165645664536453, 0.7113903630380485, 0.4436875649041524, 0.6142466404899902, 0.20678709343715818, 0.5585170048354513, 0.6635632749124338, 0.5755415728603414, 0.08180422531451625, 0.12579595766282314, 0.09047495772531089, 0.12693068633294702, 0.11109126689533622, 0.10587912832369206, 0.11791793612140178, 0.10454169619009879, 0.09084475092734534, 0.25453118793598506, 0.17895749086150903, 0.17555603549382104, 0.23839005915706435, 0.5691896011368592, 0.33470605327251113, 0.23908588749506154, 0.26639888310170723, 0.3513797812529228, 0.28086403724229514, 0.24282538461916325, 0.24095193244969892, 0.3279177263688773, 0.24954533675260504, 0.4406602675447121, 0.312011508411283, 0.48896344029617844, 0.4550740434876267, 0.24621986594549294, 0.19930277486142045, 0.23021004073705675, 0.2554736153197408, 0.176001549532528, 0.25011666403460786, 0.2218828408030905, 0.29201871725681827, 0.2151066564413392, 0.20967313095493556, 0.2200331194394477, 0.18670379541839566, 0.21581788662118195, 0.18423429768016364, 0.24398638565819364, 0.21041879272664588, 0.2371939602268731, 0.2270100766708355, 0.20065629106495642, 0.19718927856040103, 0.17860909746603826, 0.2771154625044001, 0.239569235268017, 0.1842411243350146, 0.19166738461283872, 0.20216119766412677, 0.18767880150976168, 0.7974251191529511, 0.18746396821076872, 0.16736957282736675, 0.7822692516213013, 0.1998585665331961, 0.19697408141518657, 0.14170882521625372, 0.16255959818331756, 0.8725813613950224, 0.7227320262954895, 0.20812863327827347, 0.20382280593984448, 0.5701373010060811, 0.646000084296445, 0.1495897491412721, 0.19344697426807334, 0.1997188161697846, 0.7856684088810532, 0.19730934332757688, 0.19168443038634064, 0.2306600817190917, 0.1770446033014219, 0.18557686785087457, 0.19735331872077344, 0.18870505225138345, 0.21363217432702442, 0.24256388600071632, 0.08522058062668092, 0.10324239131530522, 0.08087820979763305, 0.08156258101524838, 0.0979747103251064, 0.07953250976211135, 0.07862125903799755, 0.08834190576928869, 0.08815888544651773]}, "mutation_prompt": null}
{"id": "82f853bc-0bf5-4973-b43b-692da6c6d2f3", "solution": "import numpy as np\n\nclass SynergyDrivenPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.4 * np.random.rand()\n        self.c1 = 1.5 + 0.1 * np.random.rand()\n        self.c2 = 1.7 + 0.1 * np.random.rand()\n        self.F = 0.5 + 0.3 * np.random.rand()\n        self.CR = 0.6 + 0.3 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust', 'CR_adjust'])\n\n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c1 + 0.2)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c2 + 0.2)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.2, self.w - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.w + 0.05)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.07) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.F + 0.07)\n            elif learning_strategy == 'CR_adjust':\n                self.CR = max(0.3, self.CR - 0.07) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.CR + 0.07)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.05 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "SynergyDrivenPSODE", "description": "A synergy-driven PSO-DE hybrid algorithm with adaptive parameter tuning leveraging probabilistic mutation and learning strategy refinement.", "configspace": "", "generation": 73, "fitness": 0.3100877799748724, "feedback": "The algorithm SynergyDrivenPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.26.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.6461620715601748, 0.8472748305566553, 0.839427454385768, 0.653523117799059, 0.8520654833239778, 0.8315346494166995, 0.6406032312853991, 0.8424740068671932, 0.8545873106595457, 0.2103452751151943, 0.6518531527855477, 0.61158817194065, 0.051786695790356996, 0.6589142888118329, 0.6118454371244023, 0.16255537636037842, 0.6701455899809758, 0.5842745144622721, 0.09892852988016676, 0.09437055236448455, 0.10605280829690023, 0.13005967653217543, 0.17799694772654362, 0.11919191374057225, 0.12273512331905223, 0.1292259216902738, 0.1773003494473413, 0.0860930251021026, 0.07418174483038908, 0.08905054300022364, 0.10225372865059634, 0.09565895306856709, 0.10470479458135973, 0.1038704638708483, 0.13761399615328251, 0.10543265527001144, 0.9831314291426827, 0.973489399693894, 0.9831655121814441, 0.942228324258133, 0.9602126944169558, 0.971773895238011, 0.9728085848755749, 0.9834442671095414, 0.9811072560065687, 0.39041886089373334, 0.6798086337493311, 0.3881940475141694, 0.4082213949918925, 0.6195379732132354, 0.6477858390191833, 0.35641295445377086, 0.6079306943709983, 0.6139595639223548, 0.20848433549655243, 0.3817606452268486, 0.22222462449342328, 0.21362229868975569, 0.2823134708980546, 0.2045363636085904, 0.5628399167732512, 0.23340771398529525, 0.2267841896184457, 0.12271900755528042, 0.12270077229727472, 0.26325305535968546, 0.12663740985359984, 0.7210603181291666, 0.12686769490137506, 0.42218082754369024, 0.1154537938996707, 0.6654436509268435, 0.21092932334199122, 0.3243664635795732, 0.11908900478617668, 0.24128669745045894, 0.3895866547469634, 0.18308906078255982, 0.3429096698983921, 0.2218602670125268, 0.09641582854536557, 0.1440640040825254, 9.999999999998899e-05, 0.081973964615222, 0.03069828430018806, 0.0313145344891862, 0.046373776220349106, 0.07171049312572597, 0.004268561526447723, 0.0026982246221605166, 0.18633748499890412, 0.15997631040215332, 0.20323659622445978, 0.13683346434721333, 0.29425698659252086, 0.06822040562871534, 0.18859751663051516, 0.5835892132416383, 0.10904964350320656, 0.03447556393140816, 0.06692532568071508, 0.21459377029786997, 0.0969459986856196, 0.11508612792441031, 0.10484783965763433, 0.07310062973775278, 0.10569063284267755, 0.2335582184107291, 0.12730540537773505, 0.21022762958740537, 0.08574895480286271, 0.034889589808203114, 0.21919928114030618, 0.08090342841030085, 0.04843952786878525, 0.16237048170934087, 0.08382584388009395, 0.5441553569714204, 0.6578668405656545, 0.6856667545658279, 0.4244045872427171, 0.6242359986536279, 0.516735410934011, 0.5424603729594886, 0.7341313182233098, 0.6319708592077298, 0.11673554895455651, 0.11772832758790142, 0.0932491279733656, 0.13493916210811785, 0.10977723208535461, 0.14320812469494382, 0.13492336140849093, 0.1565538976254064, 0.11361567411065066, 0.1336037512321656, 0.21896254321771502, 0.24808362476946555, 0.3941682788584965, 0.2587590934968864, 0.21548837158539447, 0.34714865067679457, 0.1982535419071616, 0.4674368240179324, 0.2909218490254353, 0.300950307669792, 0.34018740806362513, 0.2883564468823484, 0.34754358106235217, 0.2664341900537994, 0.3169477072668857, 0.47607228454753814, 0.4531326749234499, 0.23324597557526427, 0.2096318371975684, 0.24170262819869026, 0.29734242112904596, 0.3386604797298248, 0.2189965410293767, 0.20432035234519408, 0.19739717309288185, 0.1807675527640158, 0.21222362512296966, 0.21818556484379859, 0.1933370706737303, 0.2754064468733355, 0.2234292899741328, 0.2045779208024392, 0.23332129345220443, 0.25117956321954404, 0.2065199944829278, 0.21809900245075686, 0.18097456664124711, 0.17973821420357416, 0.21773236858156308, 0.21343361965710217, 0.20810888352113988, 0.20167158551222564, 0.18074363074383504, 0.18896153782756187, 0.8237608091830645, 0.1879917614879102, 0.16775101005959026, 0.8444163540362736, 0.19958289273901142, 0.1691691956202681, 0.8082684394186419, 0.1617058776027579, 0.8907359304033091, 0.8298328857046797, 0.2111147026327589, 0.7752204845690034, 0.2047851575431079, 0.16585664492553565, 0.1546077554966192, 0.20144336304983312, 0.10464436721221759, 0.783559704782096, 0.20161077201137012, 0.20907560163791017, 0.2184784622429402, 0.2094331427506494, 0.23916538650980335, 0.25476161935737474, 0.18805681241547167, 0.21151219566704793, 0.2137827146664878, 0.08474853979459518, 0.08715916372417853, 0.09400122841815794, 0.0909782170511213, 0.09687849970259665, 0.1066409069756512, 0.09155073928353519, 0.0985327168866117, 0.09105770972626126]}, "mutation_prompt": null}
{"id": "5c572fbe-9c01-4b79-a366-2d7a928a757d", "solution": "import numpy as np\n\nclass EnhancedStochasticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.4 * np.random.rand()\n        self.c1 = 1.5 + 0.1 * np.random.rand()\n        self.c2 = 1.7 + 0.1 * np.random.rand()\n        self.F = 0.5 + 0.3 * np.random.rand()\n        self.CR = 0.6 + 0.3 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust'])\n\n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if np.random.rand() < 0.2:  # Probabilistic improvement\n                    self.personal_best_positions[i] += 0.1 * np.random.randn(self.dim)\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.3, self.c1 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(3.0, self.c1 + 0.05)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.3, self.c2 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(3.0, self.c2 + 0.05)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.2, self.w - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(1.2, self.w + 0.05)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.3, self.F - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.F + 0.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.05 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedStochasticOptimizer", "description": "Enhanced stochastic optimizer leveraging adaptive swarm and differential evolution strategies for robust and dynamic exploration.", "configspace": "", "generation": 74, "fitness": 0.28645059479028767, "feedback": "The algorithm EnhancedStochasticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.25.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.8143232309154416, 0.8242007287542094, 0.7875192524252927, 0.767021362613786, 0.8444750611087003, 0.80858549249665, 0.8166859627329376, 0.8074193856226446, 0.8256646771708767, 0.13436416226553116, 0.1251680263041819, 0.22959687864168532, 0.36475573942325845, 0.3695807274416112, 0.21547493431074716, 0.12183274233806174, 0.18729170879258383, 0.05278181176047003, 0.1064085387983863, 0.14376777611856073, 0.15319038369959403, 0.14276998252141126, 0.2880171378767149, 0.12833553122564267, 0.1481636705654853, 0.1490464667153839, 0.11469296365692683, 0.12361968475175877, 0.12127394479858888, 0.08701513757801405, 0.11788971924159364, 0.08542660470848862, 0.11456063840934005, 0.10662253717185832, 0.17637506615436593, 0.10163760344945116, 0.9779756265430825, 0.9711677402916816, 0.9823725915096209, 0.9616526070653009, 0.9607047452836679, 0.9485175629337869, 0.9734073874131903, 0.98364366737923, 0.9760569148266512, 0.4446503014892491, 0.4490523082597171, 0.3651994971560776, 0.44318051353597065, 0.41402614610399047, 0.46871391455302014, 0.40124682201990736, 0.3748591402327681, 0.42698159360222687, 0.22044153972716907, 0.8682389285452661, 0.2256909828529583, 0.26918101113965887, 0.7448506122691168, 0.21759380679004858, 0.12466448038006406, 0.791525950120624, 0.23041352441810337, 0.24556842396600642, 0.20622301296551437, 0.11129824533343058, 0.2564861408331368, 0.2224537653233043, 0.0959846360076474, 0.2470852885612992, 0.21528609603916105, 0.32318239624020506, 0.2206023960605079, 0.10960324371760466, 0.23284530281500293, 0.2295561265349082, 0.2991615113846321, 0.19727908702644603, 0.2179492413150259, 0.29513249425793653, 0.11335271434980354, 0.0819915602054212, 0.07050717781713067, 0.08553722716434531, 0.01244051165106208, 0.16680387780678085, 0.022888897361694416, 0.04993426254639721, 0.06769273844960733, 0.009173796229952624, 0.0742038996998795, 0.1169098998066509, 0.29083107162280075, 0.10371236286746877, 0.12587440824150575, 0.05413679467033894, 0.12506733511905588, 0.1909988981466334, 0.13228465967590908, 9.999999999998899e-05, 0.03443014456500282, 0.04772153384483224, 0.12855086783110548, 0.07193034859482617, 0.09689707165657457, 0.09146848336190783, 0.19139123346492581, 0.0701988853039911, 0.2506940364993423, 0.12555915081097135, 0.11170938610609937, 0.16794606312714255, 0.1721551388597896, 0.11965969797776765, 0.06098771163219696, 0.08432175061020919, 0.10626773507998388, 0.5233804841660818, 0.4585073127883811, 0.5000316358968555, 0.5133170314351503, 0.5636307459161418, 0.4745034033801666, 0.6137827466310448, 0.5220887200648713, 0.5542297089465044, 0.10248681020636319, 0.06646603498760928, 0.12016919418646343, 0.11136739968507792, 0.15721204507875863, 0.13442984436028071, 0.09455980124925645, 0.07642466359637379, 0.09053569091864355, 0.19146983335556977, 0.25989407427959255, 0.22540999786965887, 0.41096026919983497, 0.3181128357908569, 0.5529834166542993, 0.23181881918171243, 0.3041694149690396, 0.2559793230075139, 0.2093455189330259, 0.18988690799474894, 0.36894417588523865, 0.2668871728154759, 0.32451614516296, 0.26359848803315933, 0.33570989225252024, 0.34019722446795453, 0.2545857165755555, 0.3689027926310221, 0.19457103290208821, 0.23826451665718096, 0.2360892803348219, 0.31731320288154197, 0.2578452093974354, 0.17346871470725977, 0.38415577203476226, 0.2069886956494288, 0.2359155092361248, 0.19304555222975273, 0.1917879211778868, 0.23779443928605282, 0.19795689045261888, 0.25580016836666375, 0.20671644253863297, 0.23941872707502765, 0.2297910775221521, 0.1885014984728901, 0.19587301055843376, 0.2028048452665685, 0.20670699358147882, 0.22741735042557243, 0.1967306194123799, 0.2047494364550132, 0.19312609328998553, 0.2041259012728246, 0.8895941249171915, 0.18726907059219455, 0.16766322962128488, 0.8758609116538175, 0.19984739037902022, 0.1678598436004788, 0.14256976352347606, 0.16231268782576402, 0.8532842785026483, 0.8631025284067388, 0.21029993573947658, 0.07346910032675891, 0.10268586435669746, 0.6029222697546028, 0.1549023042457497, 0.21087576348282355, 0.10442803952704927, 0.8845720329062712, 0.20043185424351673, 0.1807340477274123, 0.18204387265888677, 0.20415733829750993, 0.19693201197687593, 0.20500044056985012, 0.18603926392804981, 0.1826945268148148, 0.18382152494352244, 0.08524291892996516, 0.10137881801921433, 0.11065423073520886, 0.09133191327234147, 0.10172186279271866, 0.09391961402440552, 0.09400849870810657, 0.09142876792790777, 0.08721970588818728]}, "mutation_prompt": null}
{"id": "d97d70fd-fa79-40a2-b8de-44cbe2ab2857", "solution": "import numpy as np\n\nclass EnhancedHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.4 * np.random.rand()\n        self.c1 = 1.5 + 0.1 * np.random.rand()\n        self.c2 = 1.7 + 0.1 * np.random.rand()\n        self.F = 0.5 + 0.3 * np.random.rand()\n        self.CR = 0.6 + 0.3 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategies = ['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust']\n        \n        while self.evaluations < self.budget:\n            dynamic_learning_strategy = np.random.choice(learning_strategies)\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if dynamic_learning_strategy == 'c1_adjust':\n                self.c1 = self.c1 * (0.9 + 0.2 * np.random.rand())\n            elif dynamic_learning_strategy == 'c2_adjust':\n                self.c2 = self.c2 * (0.9 + 0.2 * np.random.rand())\n            elif dynamic_learning_strategy == 'w_adjust':\n                self.w = self.w * (0.95 + 0.1 * np.random.rand())\n            elif dynamic_learning_strategy == 'F_adjust':\n                self.F = self.F * (0.95 + 0.1 * np.random.rand())\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + 0.05 * np.random.rand()\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridOptimizer", "description": "An enhanced adaptive hybrid algorithm utilizing dynamic parameter adaptation and cross-population mutation to optimize diverse tasks robustly.", "configspace": "", "generation": 75, "fitness": 0.294874052365303, "feedback": "The algorithm EnhancedHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.24.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.643631966813226, 0.7560948198943854, 0.6933476054980621, 0.6615116320028016, 0.7181058248670156, 0.6425570460912129, 0.6578043698432268, 0.7226220439288221, 0.6542748817192712, 0.11773001935452809, 0.33573322835176655, 0.2744338550674591, 0.25118516816416825, 0.37309197823579854, 0.28928091611517925, 0.22940174269324898, 0.4167313179192311, 0.039840751933991836, 0.4279132942879884, 0.12386660973025432, 0.10748469066104649, 0.12635775373621239, 0.1309747782209404, 0.1571965391272735, 0.10582403010697305, 0.10651476747520516, 0.12764122572943748, 0.10795586075442243, 0.10230608330519186, 0.09721901707395575, 0.10486835681949835, 0.10537415459212074, 0.11447242353605125, 0.13472082337754454, 0.1172113933780995, 0.13893215981360385, 0.9727310046039264, 0.9501892687699717, 0.9801247912702428, 0.9820130054275208, 0.9785651568951351, 0.9707422197095374, 0.9742138206934037, 0.9829855857101599, 0.9735328646376008, 0.3613479767187968, 0.5096726669043165, 0.307003433792851, 0.14759290420536586, 0.25460819802898815, 0.38418005164412605, 0.11585850040247259, 0.5263958259335059, 0.3660780141159026, 0.2197226766355237, 0.22703399969760885, 0.6961458568248031, 0.21110595279593813, 0.2107684467175791, 0.7617245503654461, 0.7385334129189999, 0.7469413283029682, 0.7352210669098326, 0.18919503471678722, 0.10866045587957285, 0.25195607527674657, 0.10083480922924226, 0.12381877747288306, 0.09942637610781968, 0.2239205945135856, 0.14940456811059577, 0.2049260204314639, 0.3183916948386889, 0.12376129312261397, 0.2948604792742282, 0.31046601043645405, 0.45637000462683375, 0.15720729846292947, 0.12693090786586858, 0.11798920277857228, 0.09289551008385011, 0.0004089309615404879, 9.999999999998899e-05, 0.06279893540529613, 0.00048617175777021515, 9.999999999998899e-05, 0.010406092041741477, 0.061738749867886744, 0.15664576251498852, 0.06632354585014688, 0.3880587773565761, 0.3580697602864311, 0.21973730612484965, 0.292671662864051, 0.24533831715920407, 0.023288223344286263, 0.20787581590241877, 0.4877691207792575, 0.12610959967556734, 0.03407934742783747, 0.028641105788210774, 0.05675875250029094, 0.0871511363939853, 0.0920387568196287, 0.1362929861269031, 0.06571519523156599, 0.1151687687348083, 0.06451856365314057, 0.038561759415246866, 0.18845858669985494, 0.1514685876352745, 0.034009508181641834, 0.17559941622537567, 0.17025753880929917, 0.20513257007351604, 0.24738195203190838, 0.17470006807311256, 0.5133313239310375, 0.6117657218484907, 0.5514756837659156, 0.538556851381663, 0.538417427591837, 0.5135491186266028, 0.5346234382048012, 0.6026988279854124, 0.5622768234599288, 0.08015685639299941, 0.10011712078369694, 0.12652009896978667, 0.13546982680866948, 0.102124356656485, 0.10445359947355937, 0.11012893913836475, 0.06954094114496023, 0.09885192501104922, 0.4239519253174664, 0.2733787423111852, 0.19343721760530308, 0.4165409935939476, 0.3439225824183111, 0.19133378773833043, 0.21241385202757523, 0.2721989902280685, 0.25722127403967665, 0.21256857708381682, 0.34517652952793276, 0.36107183452687064, 0.3729145532011382, 0.4129045774749749, 0.2973257495438545, 0.3774100138255372, 0.4603045321254364, 0.3604252254811522, 0.27128565875015453, 0.27547584843491324, 0.29703522822364337, 0.2930873572050906, 0.2131297549051442, 0.3162361424223482, 0.2361953895160338, 0.3343253179892408, 0.2259701623724919, 0.2201006085756141, 0.27989123479008615, 0.19869652662499404, 0.2215633363403129, 0.1938202925892819, 0.19365573425489535, 0.22362264061204473, 0.2119440622086174, 0.20991272778875247, 0.44958475331468917, 0.18647704880927007, 0.19858474832151973, 0.2442199623322494, 0.22361991527655378, 0.21826618803417241, 0.20257772002905938, 0.23853582411526608, 0.18707881243206936, 0.6912365326608784, 0.18785300803984406, 0.20377668864725973, 0.7869680264567405, 0.19918896321523794, 0.19646217314988257, 0.14252112797608896, 0.16031094506130172, 0.8189498564736655, 0.7755533769667005, 0.20994431947638081, 0.07328818457525954, 0.6386920308842294, 0.6532389409164365, 0.14770505377499377, 0.12608011666323016, 0.784054365568666, 0.6685507281814485, 0.18771498532484787, 0.18918224711758946, 0.18948239895325558, 0.2048662080469097, 0.1940515500137462, 0.19818527829169075, 0.2057886815761506, 0.19589165803685715, 0.20123009978334516, 0.08395092179896835, 0.09432600122897816, 0.07753723148826941, 0.09905100705167169, 0.09301871508968029, 0.08355479123299103, 0.0743018707644475, 0.09532348623790621, 0.09338870887145967]}, "mutation_prompt": null}
{"id": "5822dd68-3535-4e66-ae55-72d9fc539694", "solution": "import numpy as np\n\nclass ModifiedAdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.4 * np.random.rand()\n        self.c1 = 1.5 + 0.1 * np.random.rand()\n        self.c2 = 1.7 + 0.1 * np.random.rand()\n        self.F = 0.5 + 0.3 * np.random.rand()\n        self.CR = 0.6 + 0.3 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'F_adjust', 'neighborhood_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c2 + 0.1)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.07) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.F + 0.07)\n            elif learning_strategy == 'neighborhood_adjust':\n                self.CR = max(0.4, self.CR - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.CR + 0.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.05 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "ModifiedAdaptiveHybridPSODE", "description": "A modified adaptive hybrid PSODE utilizing probabilistic mutation tuning and enhanced diversity mechanisms through random neighborhood-based adjustment.", "configspace": "", "generation": 76, "fitness": 0.3041257134491615, "feedback": "The algorithm ModifiedAdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.24.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.6542612995154046, 0.710369692886828, 0.6726614905456647, 0.6632987401076083, 0.6906671109940772, 0.7349790905837497, 0.6252878745134778, 0.7010033426507762, 0.6726715928541991, 0.19449083927048616, 0.38314917270430504, 0.34310682837097106, 0.23328755284751856, 0.3149919687312823, 0.30448514180621256, 0.2816507037021321, 0.3883787542206485, 0.3012235296280862, 0.10622561782036866, 0.12014825422250319, 0.15821519891040026, 0.11635411833917564, 0.14218693787033354, 0.12289486742417699, 0.13981136557416374, 0.12799351961543703, 0.15326114788392564, 0.10085935840091531, 0.09958649052602431, 0.14736281665360185, 0.13428503444866913, 0.09465446969892743, 0.07293149109611219, 0.1011574699727309, 0.13345348029808846, 0.09851361980837703, 0.9726290483359153, 0.9734450755195889, 0.9790327269016472, 0.9690569563147347, 0.960113959506211, 0.9625982634705459, 0.973046225441411, 0.983419906371779, 0.981131689456559, 0.3921202947058954, 0.459794304897877, 0.4416010512707108, 0.3881442581130208, 0.5175567021054621, 0.45263431433096546, 0.11646343357492783, 0.43715691701564274, 0.48726556843376023, 0.2250493120433168, 0.7688127638916945, 0.6669661543698584, 0.2545642949692708, 0.8008411761378766, 0.20354621894403546, 0.7601182556825226, 0.21846223008834542, 0.7930522695899507, 0.3027534959785677, 0.17872000984457248, 0.25255047446651246, 0.11932378152886813, 0.5033009637097102, 0.1244664191602105, 0.32030444192419383, 0.20999823813528173, 0.36438247562475023, 0.42016236658491624, 0.12201773669225313, 0.21140606461523326, 0.2245926056642158, 0.1280716658036567, 0.12918246999224792, 0.3349673476141114, 0.4591984292189245, 0.10881448004585059, 0.07166867134148291, 9.999999999998899e-05, 0.27068273366532003, 0.029718289796261566, 9.999999999998899e-05, 0.08192319437572793, 0.13364272576615388, 0.061301100673215814, 0.0025510870675934383, 0.08512344625271195, 0.1905882475650149, 0.34043259427639216, 0.23755676925600244, 0.22736131644991586, 0.08097871385165145, 0.11674184713403735, 0.3870325503540173, 0.10821331845926507, 0.03273439758347485, 0.025590861616968663, 0.17610165484433726, 0.09325817155390759, 0.12297551215724689, 0.07866422037946141, 0.06922568910729066, 0.07727130529500192, 0.2510135250290364, 0.1809359463445127, 0.18574625471912454, 0.166673760874957, 0.14431881759277532, 0.22966663594172476, 0.3034771301079282, 0.17401384665307118, 0.048459063507865, 0.09815005129327514, 0.5447436973107727, 0.5357363283188428, 0.598368748185897, 0.4637620355781763, 0.5582712786490345, 0.5857758934771515, 0.5725613308858468, 0.5509978833511054, 0.5379178799837325, 0.10771957627391127, 0.07555177533764201, 0.09348617959365657, 0.10355074628476102, 0.12653310008826757, 0.1382692902483923, 0.12199952062262642, 0.15393082272572522, 0.08026995928009295, 0.1742606605540915, 0.24630611037315087, 0.35445786815112834, 0.3417614568553955, 0.5298147696421341, 0.4562538189426456, 0.14675088666710745, 0.19059285285780236, 0.1662650335188116, 0.3423558804483978, 0.2426006853699808, 0.42111702357611236, 0.2324144666983683, 0.38799791164721564, 0.4073200225836481, 0.37736676068836883, 0.41539252774193847, 0.42006983187722413, 0.33746198849754716, 0.31001093732487794, 0.30130846774501585, 0.20831809554014236, 0.21186262286367508, 0.24920060331669658, 0.22880411136616285, 0.18506708043427234, 0.20648723497654942, 0.23329758608108708, 0.21896757852079107, 0.20261201962474273, 0.19849845485313367, 0.19887669222970894, 0.22648972162403858, 0.19342870811519774, 0.2698861947503588, 0.24832092767866454, 0.47637439262686, 0.21793839037541196, 0.21825772800236343, 0.198535767011506, 0.4873418676892124, 0.203384962508946, 0.19394178562770814, 0.2012215214470474, 0.19038011987352854, 0.7531870434704404, 0.1867617421881571, 0.16776959380937684, 0.7789141220826328, 0.19872736374150834, 0.16928121380296712, 0.14217661419628835, 0.16176118912407944, 0.8655061426247874, 0.7690582580638695, 0.20586009387213522, 0.10745936830450487, 0.6360356218931188, 0.6887177902364376, 0.1482201514058663, 0.19822108823509232, 0.10441437843774715, 0.800859518232697, 0.20105422700584297, 0.19685773991838518, 0.2210867056360789, 0.1795397227103791, 0.20171167563195336, 0.20052785539720686, 0.175003642136069, 0.2027941914443271, 0.19862914716131486, 0.08960291441418289, 0.09786431341619062, 0.08673423660025492, 0.09790320588714507, 0.10705000941355558, 0.09227451383638219, 0.08439589674446601, 0.08269048636257192, 0.09699187901478123]}, "mutation_prompt": null}
{"id": "a5a326a1-a03b-4057-a33e-0f557133e9dd", "solution": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.4 * np.random.rand()\n        self.c1 = 1.5 + 0.1 * np.random.rand()\n        self.c2 = 1.7 + 0.1 * np.random.rand()\n        self.F = 0.5 + 0.3 * np.random.rand()\n        self.CR = 0.6 + 0.1 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            if np.random.rand() < 0.2:\n                strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust'])\n            else:\n                strategy = np.random.choice(['F_adjust', 'CR_adjust'])\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.1) if np.mean(self.personal_best_scores) < self.global_best_score else min(2.5, self.c1 + 0.1)\n            elif strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.1) if np.mean(self.personal_best_scores) < self.global_best_score else min(2.5, self.c2 + 0.1)\n            elif strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.07) if np.mean(self.personal_best_scores) < self.global_best_score else min(1.0, self.w + 0.07)\n            elif strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.07) if np.mean(self.personal_best_scores) < self.global_best_score else min(0.9, self.F + 0.07)\n            elif strategy == 'CR_adjust':\n                self.CR = max(0.3, self.CR - 0.07) if np.median(self.personal_best_scores) > self.global_best_score else min(0.9, self.CR + 0.07)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.05 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveHybridPSODE", "description": "A probabilistically adaptive hybrid PSO-DE algorithm fine-tuning parameters with context-aware adjustments and diverse mutation strategies.", "configspace": "", "generation": 77, "fitness": 0.22449781809977085, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.21.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.36976747386279685, 0.5074135567009496, 0.49007442561081505, 0.3747123588473573, 0.46878782316910694, 0.39937558949697505, 0.3720359150567363, 0.5347542542020278, 0.5018855999524006, 9.999999999998899e-05, 0.02628400813665377, 0.16293489826472052, 0.016375033865394628, 0.0700528735844127, 0.07822660093335687, 9.999999999998899e-05, 0.14921475450894572, 0.2097304953211383, 0.0976151101410081, 0.0817003653455497, 0.12735047646635234, 0.09170679531016612, 0.13272621091925774, 0.09936637039518559, 0.09218264329094505, 0.1214897241264905, 0.09841613659012438, 0.07639337391368661, 0.08847301385723472, 0.11296731248346203, 0.08553461701183096, 0.07951361333567442, 0.07993699954831623, 0.08222887809618584, 0.10782435273906377, 0.12708682650228476, 0.9726964019189752, 0.9682515401617343, 0.9838139453993604, 0.951367498401071, 0.9720625515984519, 0.9728658599784986, 0.9834392401513203, 0.9835596534561853, 0.9724174033598257, 0.2361184241824853, 0.25357571998354556, 0.270569892727629, 0.18921360693279266, 0.35816343698465036, 0.2750131979404862, 0.18948420677156586, 0.25425286620771714, 0.3230562587882506, 0.33139381394544876, 0.3553026435375416, 0.36407913434547334, 0.20753793458195147, 0.20839781367173704, 0.5043998648722974, 0.33791487394287245, 0.23703589784340828, 0.7141257724929966, 0.07988826548696504, 0.12287077600921548, 0.1511958581060826, 0.08934376466062388, 0.1380491911495696, 0.14586223899519302, 0.14568752422260967, 0.1549035217873057, 0.12753071196697474, 0.22088340728629396, 0.1090589066609764, 0.11972654562063234, 0.13141175292137197, 0.14112571966002174, 0.17946881048665797, 0.14793200140820084, 0.12288890793544782, 0.14782263580770827, 9.999999999998899e-05, 9.999999999998899e-05, 0.11575165105824503, 0.0625937723583424, 0.026455043231314312, 0.1416031355538282, 0.026043486790589987, 0.004275901847522023, 0.05046889493943196, 0.1462117182800926, 0.09064794193914061, 0.11050491038343402, 0.0603794229444069, 0.09044190353900139, 0.1022141621558672, 0.06080494657993274, 0.16626453256281037, 0.20292263022879464, 9.999999999998899e-05, 0.01390634963348436, 0.03435787693316339, 9.999999999998899e-05, 0.047991319673062915, 0.051999969088198705, 9.999999999998899e-05, 0.02694507761388354, 0.06515412431038281, 0.08480215495489685, 0.1556583114859761, 0.10872277132584984, 0.05418759650854277, 0.18632839696841907, 0.1349723045459459, 0.03859533507099855, 0.1698412021348169, 0.07560171615840117, 0.3234635245779449, 0.39020733360452464, 0.48240032485795836, 0.38260178561031377, 0.4686390135165134, 0.46805564801356336, 0.34648802555603575, 0.39458119981042705, 0.4711221732249009, 0.10561763156082593, 0.07057786631691543, 0.0842214323564523, 0.08431825806000792, 0.09253886098625697, 0.13445185083657885, 0.08175672461283323, 0.09582739272240537, 0.12742120763783604, 0.16425576755061755, 0.23484324112411348, 0.19414640880361667, 0.16898902040118757, 0.23918149408327904, 0.18073593382804953, 0.16293394725400334, 0.1768037295051781, 0.14464690040901185, 0.2710018693881381, 0.2414706188312814, 0.2943211123099222, 0.2708209525517855, 0.2930061406973622, 0.272520230992923, 0.21953323011729298, 0.2650180435114071, 0.2569294471043937, 0.15592586894219207, 0.2538094674197078, 0.22057172542241932, 0.20370100026203775, 0.19223117338757933, 0.2231054210031802, 0.19681199764854718, 0.26011226827628453, 0.253502827146159, 0.20097562936345725, 0.18660098701688455, 0.1752312574436995, 0.19471159547520311, 0.20081823850205316, 0.2151021047363605, 0.17979114407930807, 0.2126292825581222, 0.19124719532635215, 0.1838370609478034, 0.1835969091477967, 0.19205105791250043, 0.18302582139468804, 0.2564581880851201, 0.19323152239866237, 0.1835783390296888, 0.19684269905464524, 0.20276129850716684, 0.5355555565377295, 0.1858335290759351, 0.16638788915089664, 0.4645013800820106, 0.19886396962276742, 0.19820256535005476, 0.14191769170617696, 0.16100733356427155, 0.7374865149797978, 0.359390332986285, 0.21032917585905375, 0.6416119967776597, 0.20537733965370597, 0.43708063209540915, 0.15146058146208163, 0.20121658997502434, 0.21002338079402139, 0.6488289569296667, 0.19524754139185374, 0.18615623805351544, 0.18956904461463886, 0.19361651072836172, 0.19845933381224323, 0.18333817315629097, 0.18365889359656062, 0.1799080636324405, 0.181369698642723, 0.07364427479570257, 0.09649623272756236, 0.07844901297746565, 0.062860175780315, 0.10050231749816119, 0.09244162610923301, 0.0715614788414527, 0.0861327103835029, 0.06808450665694876]}, "mutation_prompt": null}
{"id": "f75a7dd2-6520-437c-9cd4-e40b0db57a13", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(80, budget // (dim * 2))\n        self.w = 0.3 + 0.5 * np.random.rand()\n        self.c1 = 1.4 + 0.2 * np.random.rand()\n        self.c2 = 1.6 + 0.2 * np.random.rand()\n        self.F = 0.5 + 0.25 * np.random.rand()\n        self.CR = 0.7 + 0.2 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.4, self.c1 - 0.15) if self.global_best_score < np.median(self.personal_best_scores) else min(2.4, self.c1 + 0.15)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.4, self.c2 - 0.15) if self.global_best_score < np.median(self.personal_best_scores) else min(2.4, self.c2 + 0.15)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.2, self.w - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(1.1, self.w + 0.1)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.3, self.F - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(0.95, self.F + 0.1)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.1 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedAdaptiveHybridPSODE", "description": "An enhanced adaptive hybrid PSO with stochastic parameter adaptation and dual strategy mutation.", "configspace": "", "generation": 78, "fitness": 0.30333105177197683, "feedback": "The algorithm EnhancedAdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.25.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.805500094035552, 0.5746047747910276, 0.716060719477728, 0.8253608505747141, 0.6230106477677909, 0.7120707776509227, 0.7919167140169804, 0.6359650338024345, 0.7107209196130808, 0.46986103768998644, 0.03261089965111874, 0.2779247294942281, 0.5393175268102008, 0.12504646520771534, 0.25319978645532015, 0.5064126516373664, 0.06974825729424317, 0.2943594201980504, 0.1386082889037068, 0.12122382978078805, 0.1577696194263717, 0.16348858159399993, 0.0980231721464917, 0.14670862154951536, 0.10026206604375765, 0.14109504081042756, 0.12756024064226223, 0.043522977094073045, 0.10388635223616205, 0.11309662822530298, 0.10805927214278233, 0.11846691226198491, 0.095217448039428, 0.13165156678530054, 0.09723480087446879, 0.1009932094058359, 0.9778424276976748, 0.980418338645122, 0.9752716319408119, 0.9500953402089963, 0.9622284718467236, 0.9490492738991132, 0.9787063799069124, 0.9785381644158015, 0.9780415509088912, 0.5976128886878782, 0.3668462631205822, 0.22650918652777796, 0.49899750550596633, 0.3648853702787608, 0.50569780741139, 0.541319132460143, 0.38674769737199166, 0.4072952392738777, 0.23822548802984833, 0.6344392224167317, 0.7369707571707249, 0.8300093967687301, 0.7263088936768726, 0.18990110644835578, 0.2099138734379118, 0.6563007635049045, 0.7105559379697552, 0.28179916102938374, 0.1755913853188198, 0.16002010165488123, 0.27779236039505517, 0.12200893202994922, 0.17769545589613078, 0.4716067581379352, 0.192326923642528, 0.17744473194483723, 0.43146778354091464, 0.2805481497097705, 0.16981759644635508, 0.4210058224766082, 0.20676242887967233, 0.21761819309121655, 0.12735515531129238, 0.24533263798609573, 0.18649017688040748, 0.06606874756122016, 0.10925550926773919, 0.18304757492353396, 0.05673562660803477, 9.999999999998899e-05, 0.012345737270113233, 0.04740982711074626, 0.02452761194403197, 0.0024456402366831442, 0.20767581915645583, 0.13262661380278262, 0.3025830307954881, 0.10201767547493823, 0.1474557541966398, 0.2806012083130026, 0.3741761904806019, 0.1937448441089772, 0.14213289244951488, 0.04341199152746522, 0.05279146274915747, 0.12469906733955882, 0.12375887587180645, 0.0809192747912828, 0.08269397752283203, 0.0889310185305876, 0.03997163118966274, 0.09640328746868165, 0.2912410058864382, 0.14750396543028532, 0.2514789380420295, 0.035852928804175455, 0.11523589454859828, 0.17668096057046445, 0.08268608075519057, 0.1460890567053349, 0.08343052991889677, 0.5878399711182936, 0.4638611942771076, 0.557801971457986, 0.6008613397572469, 0.4665679193663895, 0.5907446217231125, 0.700828104030669, 0.49120727147776055, 0.5415289520586584, 0.07813683103708502, 0.11145678604582843, 0.09618129299455414, 0.14959704219406977, 0.12143258805799373, 0.12664259030593206, 0.08905029518296492, 0.10409525972545619, 0.10713119812518601, 0.18810291484271235, 0.1712083538454855, 0.21172722986790982, 0.24075626146751972, 0.2181150581804332, 0.3171996050489486, 0.42063196959627014, 0.3375852301968303, 0.18579213525305682, 0.4515128831717802, 0.3359245786063155, 0.3468987626016661, 0.47003657930773424, 0.2585150181911696, 0.3005089413710723, 0.43186658576982495, 0.32557132856580306, 0.3641779795084401, 0.27277083379122613, 0.2894917998637434, 0.2882503158605144, 0.26764818206329555, 0.24927819345665836, 0.23719485384093175, 0.41034654321255914, 0.23439395113710715, 0.21922942591075656, 0.24105477437993872, 0.20033092577521572, 0.20735810967438284, 0.2263116533784265, 0.20615235435469592, 0.20083510776906544, 0.22207539103434748, 0.23517894318713073, 0.23906975587030332, 0.20871214441590047, 0.18069883500996764, 0.186416655131178, 0.18657942211919265, 0.20422973482815387, 0.18848011087112404, 0.24115246480359231, 0.20132774910519946, 0.1893382593575339, 0.13001049362778527, 0.18597071313910252, 0.8288826357869525, 0.8795976996793681, 0.1999068872544365, 0.16689170632842487, 0.14187593496708328, 0.16290608130488105, 0.8305805595594736, 0.8656453682793739, 0.20834066550977204, 0.2024861387589273, 0.7951760489335358, 0.5910717295903128, 0.4963542165298863, 0.16698744629090978, 0.10353536290680987, 0.7959712369856621, 0.18625724906160768, 0.17396520350651623, 0.17579020824303537, 0.20185304219993427, 0.21725203388203596, 0.2036127430857232, 0.2229640429294688, 0.20469570924040092, 0.18125161244122612, 0.095960637771759, 0.08549449507166285, 0.11023698694847683, 0.08679728009823007, 0.08907892617273283, 0.07883855064904632, 0.07882595266031245, 0.08715048813616211, 0.09158591129637661]}, "mutation_prompt": null}
{"id": "11c75724-46fe-43ac-a307-b9686920e66a", "solution": "import numpy as np\n\nclass RefinedAdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.4 * np.random.rand()\n        self.c1 = 1.5 + 0.1 * np.random.rand()\n        self.c2 = 1.7 + 0.1 * np.random.rand()\n        self.F = 0.5 + 0.3 * np.random.rand()\n        self.CR = 0.6 + 0.3 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust'])\n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.15) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c1 + 0.15)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.15) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c2 + 0.15)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.w + 0.1)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.F + 0.1)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.1 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "RefinedAdaptiveHybridPSODE", "description": "A refined adaptive hybrid algorithm with enhanced dynamic parameter tuning and stochastic mutation for improved convergence.", "configspace": "", "generation": 79, "fitness": 0.3460812952880056, "feedback": "The algorithm RefinedAdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.28.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.7685365489415362, 0.7983511390045422, 0.830176364818332, 0.8037229796041541, 0.8263671987143739, 0.8197375513341089, 0.8021470342359629, 0.8196523188603658, 0.8247219052529746, 0.5856953220917029, 0.6555955380482894, 0.5789662004603926, 0.511916737679123, 0.519004144521998, 0.5767234347017023, 0.5832640797312418, 0.5691142122551727, 0.4124956752199803, 0.10977774716020539, 0.1554018032544121, 0.12174867245227361, 0.12513172576725917, 0.1457968310149812, 0.1404670923918102, 0.13521476423722611, 0.12593048865490541, 0.14137453446321846, 0.0751947513925616, 0.1235299891713787, 0.1282983579610223, 0.11535009171911548, 0.10409476865723022, 0.11203206041122937, 0.08936985029831723, 0.1265488154497807, 0.1054246571315609, 0.9726353019584107, 0.9734181654016402, 0.98313921002821, 0.9724974008538458, 0.9586221627451242, 0.9626716462546053, 0.9727244917684361, 0.9834406464860724, 0.981105086316434, 0.5739011623444252, 0.643747158407979, 0.5388369689119059, 0.5951774372691188, 0.6298335888911094, 0.6338700538231614, 0.08633621589601903, 0.5906399495554862, 0.6781109140829853, 0.8801574240646597, 0.8325130790289131, 0.7958220061992669, 0.39204940892333906, 0.6344933173450937, 0.18922065727309034, 0.8473642002369944, 0.24227930280998522, 0.8719382236571586, 0.1281691677591189, 0.3587505189937641, 0.4545990836725011, 0.3746435541598815, 0.6060393461574112, 0.4757240507697815, 0.3699647434338601, 0.11103168994744395, 0.5985243418226718, 0.5162231345504308, 0.4778160755082006, 0.12966621230139375, 0.45825416146791054, 0.5169051478351294, 0.5602432478654316, 0.3887210650585252, 0.40346575462475565, 0.09114630713562766, 0.03888028150339762, 9.999999999998899e-05, 0.20768402325685986, 0.03629052923944853, 0.0004793771589207685, 9.999999999998899e-05, 0.031318211325566, 0.009182412913236626, 0.04190124925369165, 0.2643583055090687, 0.1495936733757255, 0.23895384540186748, 0.25662772251778365, 0.1728609171984803, 0.07636129454864804, 0.1666187744037274, 0.17024359291714786, 0.04397834936944056, 0.04674471795895585, 0.054424618777010214, 0.12289682444875472, 0.13407874723004876, 0.25943386908073085, 0.09777304657602581, 0.09136791694303081, 0.1271570857946248, 0.1889410933027862, 0.2190192618533915, 0.11215014843903537, 0.35907506533888545, 0.1788841795730537, 0.1787564915309653, 0.3666743224239831, 0.12166133165094417, 0.044524094463189834, 0.08227685389071648, 0.6510431741117979, 0.6797384612181219, 0.5844505927181898, 0.6826646543344215, 0.6313589167468519, 0.6418982336527664, 0.6265806503875901, 0.7050743855101829, 0.7193655685265904, 0.09778188770439211, 0.11783640674100848, 0.09047354880623204, 0.15475395170259, 0.09494284232324901, 0.1449966115202337, 0.13473300454691528, 0.1009329935185127, 0.08507288219754683, 0.3509303665676895, 0.19980805584442696, 0.1484271667752486, 0.24387659231458114, 0.3582574439761331, 0.2670315323033614, 0.1951980682104394, 0.20587115684715052, 0.17462604457633335, 0.43093744652682553, 0.1885602946819379, 0.44721634003129285, 0.41099023185747696, 0.25609312092716596, 0.3339953119880481, 0.3842675735015906, 0.4398441721364742, 0.28371824766954323, 0.33372566600715425, 0.21495533208745687, 0.18567043575050224, 0.3452992174224123, 0.24446411165458393, 0.27163954009173086, 0.3341435369371517, 0.2159140529072392, 0.26115365242111155, 0.19707329036532506, 0.21404032739693502, 0.1763163667367741, 0.23219754315030794, 0.24085845530669836, 0.2320948702919231, 0.2285430339536607, 0.29471733111269927, 0.2067677643320942, 0.21088866454020616, 0.21894421330156633, 0.18880812251981727, 0.20909891528139501, 0.21308066877856613, 0.1976323361213077, 0.19680005005766876, 0.20672252922981826, 0.17664499361100794, 0.8854402777556853, 0.18828879362325024, 0.16815085404184082, 0.8758130385438737, 0.1995251028789693, 0.16861651997393678, 0.14273090428865198, 0.15990764607451224, 0.9012430868362359, 0.8881531263903357, 0.2095655922347922, 0.8304217245928778, 0.10391716173012067, 0.8123166294952155, 0.15462688294189086, 0.20348235023263983, 0.10462935462584977, 0.853172258625006, 0.19122615290194567, 0.24914290688976892, 0.1923904548869898, 0.2171211322939003, 0.2009783948292717, 0.21726624905140757, 0.21554102823184595, 0.19320137623211497, 0.23769763328713323, 0.15492365147953846, 0.07690627520725335, 0.1026320352232375, 0.09637455455275068, 0.09535936925329802, 0.08944346451436291, 0.08576837640853197, 0.09771675683814773, 0.08364531104111406]}, "mutation_prompt": null}
{"id": "f6934c8a-084e-4bd6-96c6-5498a9a882a1", "solution": "import numpy as np\n\nclass SynergisticEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.4 * np.random.rand()\n        self.c1 = 1.5 + 0.1 * np.random.rand()\n        self.c2 = 1.7 + 0.1 * np.random.rand()\n        self.F = 0.5 + 0.3 * np.random.rand()\n        self.CR = 0.6 + 0.3 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c1 + 0.05)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c2 + 0.05)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.w + 0.05)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.F + 0.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.05 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "SynergisticEvolutionaryOptimizer", "description": "A synergistic evolutionary optimizer integrating adaptive parameter control with differential evolution and PSO for robust search dynamics.", "configspace": "", "generation": 80, "fitness": 0.338879906879886, "feedback": "The algorithm SynergisticEvolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.27.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.8207217517549342, 0.8097185557390185, 0.8019273027384167, 0.8256123776347752, 0.8304652751203402, 0.8179106076850359, 0.7853471093190761, 0.8110683333072258, 0.8196828848490364, 0.5683196272973384, 0.58832067940182, 0.5715441104109946, 0.5556829193688833, 0.6158862999047483, 0.5772231741687841, 0.5964054180274603, 0.49545048116927437, 0.580483225389514, 0.15297641704648235, 0.17070460683209554, 0.12525068437679998, 0.13645033987365807, 0.1541857400743054, 0.10221978519947539, 0.12835316054775614, 0.10569902001763565, 0.14094058839214407, 0.12783688261408965, 0.08877011689417957, 0.10028314957559614, 0.10576902532390575, 0.09786287278188688, 0.10787744759458018, 0.1257435467649446, 0.08908380658589377, 0.0931472693117601, 0.972750185866042, 0.973489399693894, 0.9831655121814441, 0.9721009772808679, 0.9602126944169558, 0.971773895238011, 0.9728328012779636, 0.9834442671095414, 0.9811072560065687, 0.6274380690851935, 0.6538608285365985, 0.45389056316534193, 0.5796576083181245, 0.6381748012168657, 0.5877216974980812, 0.08469725666199757, 0.597645678458759, 0.6243839242983893, 0.8675970156400071, 0.2283579280866993, 0.22303901363837386, 0.8584868709995094, 0.5915736427471496, 0.20543345419833814, 0.8407892769252907, 0.7766743439718363, 0.21501402770497602, 0.6034507167171868, 0.12407992634941822, 0.47289346820811884, 0.12614058585122534, 0.6679161147864983, 0.12528985122204417, 0.4421268995454146, 0.11614269499414753, 0.6576000326855809, 0.5486229617443462, 0.1232013835427006, 0.12010419709789244, 0.4016314176323571, 0.5219740273474093, 0.1297814011478624, 0.32587536975902587, 0.23075200262720985, 0.1095985118733408, 0.10800054663043834, 9.999999999998899e-05, 0.06888188937974937, 0.03965296232402049, 9.999999999998899e-05, 9.999999999998899e-05, 0.08528804681861624, 0.07073484648525241, 0.002858366163498993, 0.17252199766572573, 0.1304563568449566, 0.1300457244343992, 0.15535002740673443, 0.23367126061639154, 0.10809129698814701, 0.11472208151204522, 0.3073517187223094, 0.15756189208382998, 0.1184754037323219, 0.06495558460490469, 0.18344294263402594, 0.12030318399592088, 0.1289626850143224, 0.11224824016305701, 0.08594321778265568, 0.11317344647870542, 0.3345499368133331, 0.12960236515101242, 0.3560548606948758, 0.1460417463229754, 0.17414298593595867, 0.22922657653206446, 0.14266521003037924, 0.04799154533566197, 0.28298067778739155, 0.08038207266127961, 0.6343378451052673, 0.6472744286322651, 0.7490439054555903, 0.6116338012552694, 0.6777033128109718, 0.6076908794255895, 0.6427162423250234, 0.5738001534710415, 0.6184301720010554, 0.10149005830494895, 0.08637939330970967, 0.06326520169211836, 0.15720005182585395, 0.12490588759698074, 0.1447397726442301, 0.11526141640796961, 0.15667702141095396, 0.13492175592550737, 0.14551575829632202, 0.24115258124300532, 0.4626429642879408, 0.2512336980925691, 0.3224918194599671, 0.1967926903417806, 0.27162746522712755, 0.20749132807174464, 0.20607602588396878, 0.3365082842510031, 0.30179609772243254, 0.34924836357973377, 0.2744577466005581, 0.32152338910878564, 0.46110557297408583, 0.36248041410859855, 0.4510936196136297, 0.29117334726127087, 0.23412356898857511, 0.21187472600514934, 0.18804460603353046, 0.28269037879655423, 0.3012260578024789, 0.23800829392083223, 0.30583826668614156, 0.27961218115516207, 0.22252488462515763, 0.22474968987664, 0.23548106004902392, 0.19315142004688157, 0.23843234401596802, 0.26914994307246665, 0.2209541841594822, 0.22544436861945005, 0.27860975412806166, 0.2338243416492194, 0.1850266973647623, 0.18136200974820926, 0.19983624211925932, 0.20636370997391407, 0.7109069366231004, 0.2050326697694146, 0.24014714263538184, 0.23761670427576886, 0.18893748692704238, 0.8853653993208142, 0.18795633449397875, 0.16776019815323562, 0.8394748341967395, 0.19933204927173276, 0.16907528143425565, 0.14240833671547626, 0.16229206741470192, 0.8829014275441637, 0.8942391718229549, 0.21102973379665768, 0.8076773205321962, 0.8200704572572997, 0.16597623727081678, 0.15483286497782678, 0.20738156859293955, 0.10462778591154964, 0.8121585582207781, 0.1926755534581358, 0.19659875107243074, 0.19981661388315353, 0.20129078817780655, 0.2391723380190509, 0.22089650719951381, 0.2006085432085868, 0.20350556162257893, 0.22607968226319886, 0.10585290086133081, 0.0809741558618372, 0.0841364874457915, 0.09472312127777405, 0.08574993899232508, 0.07703836789637131, 0.10256617068462004, 0.10315341684996382, 0.09375838336486653]}, "mutation_prompt": null}
{"id": "b7b45f8b-da17-47bc-b9c6-e916bf94b718", "solution": "import numpy as np\n\nclass RefinedAdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.4 + 0.3 * np.random.rand()  # Slight adjustment to inertia weight initialization\n        self.c1 = 1.6 + 0.2 * np.random.rand()  # Slight adjustment to c1 initialization\n        self.c2 = 1.6 + 0.2 * np.random.rand()  # Slight adjustment to c2 initialization\n        self.F = 0.5 + 0.3 * np.random.rand()\n        self.CR = 0.7 + 0.2 * np.random.rand()  # Slight adjustment to crossover rate initialization\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'RandomRestart'])  # Added new strategy\n\n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.4, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.6, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.4, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.6, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.2, self.w - 0.07) if self.global_best_score < np.median(self.personal_best_scores) else min(1.2, self.w + 0.07)\n            elif learning_strategy == 'RandomRestart':  # New adjustment strategy\n                if np.random.rand() < 0.1:  # With probability, apply random restart to a subset\n                    indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n                    self.population[indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(indices), self.dim))\n                    for idx in indices:\n                        self.personal_best_scores[idx] = np.inf\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.05 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "RefinedAdaptiveHybridPSODE", "description": "A refined adaptive hybrid algorithm enhancing parameter tuning through stochastic component adjustment and adaptive synergy optimization.", "configspace": "", "generation": 81, "fitness": 0.33161533710252483, "feedback": "The algorithm RefinedAdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.28.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.8364067435432794, 0.8480361597349106, 0.8200182233422515, 0.8258265969148522, 0.8521548193296871, 0.8307363332404346, 0.8437731205962526, 0.8319227470975459, 0.8420024511275929, 0.3965929361371582, 0.04015354772051871, 0.6418022251002216, 0.5159809020867664, 0.6033785254544206, 0.5976016759228935, 0.6084153015459666, 0.6537671209637528, 0.05096026491454542, 0.09858033836710778, 0.10649992704526945, 0.09787065455586397, 0.1656467106892775, 0.11280399969124155, 0.09310149676008261, 0.13529338069072216, 0.12911051128062823, 0.13747214438464994, 0.10035971504888253, 0.0876677507477085, 0.13987306740190075, 0.10310019491438704, 0.09279549664123843, 0.11278016045228301, 0.1301726442681853, 0.10935767062134105, 0.09333903928692111, 0.9729923755729838, 0.973673103890579, 0.9823026542789479, 0.9724779154731934, 0.9729756005261514, 0.9717403773848606, 0.9729461586870466, 0.9836572239977093, 0.9792850251975227, 0.6522223385532435, 0.6158453803538362, 0.057248875218361195, 0.5954373017903809, 0.5017280204210579, 0.6071282250525529, 0.12352247281826423, 0.6328633824200195, 0.5498305307042963, 0.3899340951205984, 0.7874863699402236, 0.7628122116866549, 0.8804631842767097, 0.6528059974860747, 0.19393867261378372, 0.8028264229044885, 0.7274620987405154, 0.1937527838462979, 0.5135472274592168, 0.11560715667066868, 0.4499746053626056, 0.1178465350002903, 0.4327562342761896, 0.618604966769378, 0.541282759774457, 0.11783325458634608, 0.5970207963499989, 0.41362742281757914, 0.44730081247869935, 0.12357089575604774, 0.12954798379950372, 0.27142279130930835, 0.4488539128057537, 0.45985650344190143, 0.4070704234963224, 0.11895665286333001, 0.06933004385539121, 0.035552662611921027, 0.1223374634657719, 9.999999999998899e-05, 9.999999999998899e-05, 0.042681039891668826, 0.037717081561254084, 0.027448772232780527, 0.007141448245500559, 0.23179100036182, 0.20657986506218762, 0.29317529825043376, 0.12593469593531603, 0.14800753377584752, 0.06731903944468831, 0.10922584589012929, 0.39656592056924733, 0.28202265374007784, 0.04782280243838499, 0.0417882662856941, 0.19298710135605357, 0.12530801519998025, 0.21363137841909052, 0.18932202108590745, 0.09213373198715358, 0.20046714701643187, 0.13034984214746004, 0.14166865107435078, 0.23053187523413832, 0.35697300342580474, 0.14089275618604313, 0.147958296136818, 0.10114657078999367, 0.046549628772009966, 0.123031316978366, 0.09828612059655117, 0.6060970672870014, 0.6364265509037151, 0.7432453756139101, 0.666249220884798, 0.6526906825963552, 0.6590557901038487, 0.6802547935285415, 0.6573222399448395, 0.6710616100690284, 0.14746928244107782, 0.11768383973405705, 0.08045155070060794, 0.11513612008824059, 0.06763206718761106, 0.11035726820167857, 0.08707078602105611, 0.08761784790135407, 0.07949136638546428, 0.2680055706077601, 0.18057487144262452, 0.220030565975471, 0.26216903244765133, 0.4075081798778001, 0.2601044485890982, 0.19495614905892666, 0.17091108511379394, 0.17607326534143197, 0.4130480973909333, 0.46269025224564375, 0.2631644311008188, 0.2445648566789943, 0.27560187065944186, 0.25508214197444024, 0.2374685068515754, 0.4439937214190187, 0.4239955817779203, 0.22147988589775502, 0.1696303608787788, 0.24962448398864479, 0.23018278111509638, 0.18822218959366988, 0.20291481807642997, 0.2663213472235847, 0.34606568088720946, 0.2590594660742328, 0.18143323058653937, 0.22051767734919114, 0.25507043855365685, 0.20972628643286928, 0.23716462990909937, 0.2146578180562404, 0.21435677773916595, 0.2633495317334803, 0.21396974281294712, 0.17991024897956553, 0.19200103672654578, 0.21822510562730957, 0.2496039329506481, 0.18602165358654377, 0.1912364177427056, 0.19393665839917829, 0.18715165255673594, 0.2083904421746695, 0.8810403859267363, 0.18760130782405726, 0.16734508055816877, 0.8461169667743793, 0.20029514877304444, 0.16953019454529072, 0.14232715836086063, 0.16395662438791336, 0.8978809195045768, 0.9008509355461897, 0.21038525733673608, 0.07350160590945676, 0.20501237639353054, 0.6944056303505703, 0.14588949474413326, 0.10413940150004042, 0.7691210917664382, 0.7959919918670681, 0.22232252953841602, 0.21608540884966898, 0.21639802058634627, 0.21196074866742354, 0.20732994795361626, 0.2175635167287575, 0.19870902507456023, 0.24619905221292304, 0.1955140213934239, 0.08917077713648014, 0.08237069477012504, 0.08755292764230749, 0.08900113369573337, 0.09841482946954672, 0.09496648028378185, 0.0999783807536172, 0.08938843948539887, 0.09184170241606515]}, "mutation_prompt": null}
{"id": "b2f455ef-1898-4fac-99d4-40116ce49ee8", "solution": "import numpy as np\n\nclass RefinedAdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.4 * np.random.rand()\n        self.c1 = 1.5 + 0.1 * np.random.rand()\n        self.c2 = 1.7 + 0.1 * np.random.rand()\n        self.F = 0.5 + 0.3 * np.random.rand()\n        self.CR = 0.6 + 0.3 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust', 'CR_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.07) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.w + 0.07)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.07) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.F + 0.07)\n            elif learning_strategy == 'CR_adjust':\n                self.CR = max(0.5, self.CR - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.CR + 0.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.1 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "RefinedAdaptiveHybridPSODE", "description": "An adaptive hybrid particle swarm and differential evolution algorithm with probabilistic parameter tuning and enhanced synergy exploitation.", "configspace": "", "generation": 82, "fitness": 0.3191644807517104, "feedback": "The algorithm RefinedAdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.26.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.5924293191700452, 0.7965281863039995, 0.8260832946966602, 0.6767469744260325, 0.8178910544542707, 0.8050367754213019, 0.606848495922508, 0.8173150722965236, 0.8226278105263336, 9.999999999998899e-05, 0.45279328017162657, 0.538846509604592, 0.24244603483266058, 0.5479997382602364, 0.5661404321444486, 0.20854675390184374, 0.6349364541012106, 0.4885386119372799, 0.10016729147381287, 0.13564181793065144, 0.13754624105954882, 0.0845114575557876, 0.10399992808638558, 0.10479300579026729, 0.12233961326075116, 0.10483195599359207, 0.17288435880751984, 0.12211213172089541, 0.10959636332865907, 0.10633256321225637, 0.10755061326365245, 0.06381111649215832, 0.10072886470838804, 0.130456455701509, 0.1157953652935867, 0.09044006053538944, 0.9831365829500829, 0.9734439632873663, 0.9825775540142484, 0.9417328568647662, 0.9587334660392056, 0.9643819705066208, 0.9728130972789678, 0.9834411567644828, 0.9811043418839339, 0.40556618808608147, 0.655558067918572, 0.5248757320851994, 0.3868104052449829, 0.5655066788264783, 0.5587813702203683, 0.387920013731918, 0.5870598064542455, 0.6453718253065938, 0.45336744761270464, 0.2329266647648568, 0.8108724545479631, 0.2596064526081441, 0.2805071986942106, 0.20072207867432879, 0.7452857905006955, 0.23591443396177358, 0.8379166817807548, 0.37342525589113995, 0.3225454381546736, 0.12554887600384446, 0.10565624366291426, 0.5580576821970631, 0.6236608232638369, 0.315885691411421, 0.1098773855541576, 0.7264005675657859, 0.12324740842864379, 0.126536530475427, 0.11970223611259911, 0.1789935466726803, 0.12916005965613153, 0.3112879135511565, 0.2909364348220098, 0.5493228861557024, 0.11651240949842556, 0.04844075864262254, 0.06303745850179188, 0.22825516989829053, 0.03661732135463569, 9.999999999998899e-05, 0.023825816445476433, 0.18887279348865404, 0.05385858215995831, 0.003138546818635235, 0.19602706497816047, 0.19493013803397563, 0.30968384684806827, 0.08229124527142828, 0.17900716582529563, 0.18169816775620662, 0.24987715610026873, 0.33743309170858427, 0.058278465320773964, 0.036307171877414834, 0.03860623024932919, 0.20104359460704757, 0.08371306872794337, 0.13901646471703988, 0.1404304406360125, 0.07298403683846333, 0.11416708517655594, 0.08829799431358609, 0.17260083142387816, 0.2849945194619451, 0.20889964737270517, 0.12188173900689925, 0.20021296604568306, 0.34021375463715264, 0.04062308415825333, 0.18899166803875755, 0.0809540802883486, 0.4768301160201699, 0.6515249969139958, 0.6331524827137864, 0.5160638979008552, 0.6755927460804997, 0.7020143093574853, 0.5365450308201609, 0.6290074952858993, 0.7365030822092817, 0.11116605074178754, 0.07401456572666287, 0.09564297349315365, 0.08292295229992619, 0.12278267383124697, 0.12025573793771471, 0.136969564910975, 0.08776647518892644, 0.08931139788618259, 0.1691887241085691, 0.36577360188858465, 0.22182072325374624, 0.5179023541985085, 0.16570550342057666, 0.20939379451586282, 0.1843387755601732, 0.19806352866469923, 0.2278651565172528, 0.4052851718461572, 0.20409160627518264, 0.46028774067022227, 0.4110131778507804, 0.36325675883547626, 0.36817107327421494, 0.32399440713932615, 0.5522494990334779, 0.4726070866465071, 0.21369818230364268, 0.18526311164006115, 0.2452214431648898, 0.29419082712109357, 0.19219804265482954, 0.24301525000104507, 0.22060064708038352, 0.39419722826542114, 0.2292285711637485, 0.214514423487547, 0.22118189450795767, 0.19630129357495407, 0.2613498717850069, 0.2520932779746696, 0.21871861986874042, 0.19839825678162415, 0.24380486403899382, 0.24139478770891565, 0.18894597745062647, 0.18294504713841497, 0.1799594122545517, 0.21708516207543893, 0.24536845456438894, 0.19752210712818408, 0.22286408638622435, 0.2010491433013788, 0.1761198989195134, 0.8325192121241047, 0.18819765540374855, 0.1678140145568413, 0.85219603536977, 0.19965263538434663, 0.1688356097949525, 0.8083247869070675, 0.16187222528184975, 0.8965639728865211, 0.840836062337782, 0.21094517303849947, 0.795870903345109, 0.20333372683695816, 0.16656095574100582, 0.15432154583558988, 0.20066436970588275, 0.1046034178845382, 0.8255386408904823, 0.18636215522467892, 0.1977313089935121, 0.19283603462761734, 0.18218945612597204, 0.21560877485885233, 0.19013509963624442, 0.19944113211604064, 0.21171685117804528, 0.23808969635117727, 0.08913930174047258, 0.09830766237259436, 0.0850878175020493, 0.08883016258121079, 0.08960363348935974, 0.09067202493187199, 0.08329646380159994, 0.08699165283453825, 0.09113571651488928]}, "mutation_prompt": null}
{"id": "fcea3e89-6b48-4af0-a34b-b7a7a04a3658", "solution": "import numpy as np\n\nclass ProbabilisticallyAdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 4))\n        self.w = 0.3 + 0.5 * np.random.rand()\n        self.c1 = 1.4 + 0.2 * np.random.rand()\n        self.c2 = 1.8 + 0.2 * np.random.rand()\n        self.F = 0.4 + 0.4 * np.random.rand()\n        self.CR = 0.5 + 0.4 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust', 'CR_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.08) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.w + 0.08)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.08) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.F + 0.08)\n            elif learning_strategy == 'CR_adjust':\n                self.CR = max(0.3, self.CR - 0.08) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.CR + 0.08)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.05 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "ProbabilisticallyAdaptiveHybridPSODE", "description": "A probabilistically adaptive hybrid PSODE optimizing parameter synergy through targeted mutation and learning strategy adjustment.", "configspace": "", "generation": 83, "fitness": 0.29596140751274114, "feedback": "The algorithm ProbabilisticallyAdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.25.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.5927225284942377, 0.8171164182665074, 0.8269935288089225, 0.5514324324141089, 0.8260601285772725, 0.8415790223037496, 0.5618580682455099, 0.808329222673609, 0.8117301486260127, 0.1413890800561861, 0.522729626407604, 0.6110951474178997, 0.0293491943753712, 0.6018113284106157, 0.5797766242258182, 0.03722042329090125, 0.5710439693051277, 0.5228009469146261, 0.07347034651136053, 0.1449637069030767, 0.11797706219521809, 0.11438897894088573, 0.1110145875538141, 0.12374783266939726, 0.12514575311290355, 0.10445540186708568, 0.11146532844200896, 0.08660278796032417, 0.0872665340496025, 0.07431479605448732, 0.10341206533003733, 0.06035018155386496, 0.12261253427544594, 0.10624682207629343, 0.09927589277854021, 0.0884097430420121, 0.9831856022761115, 0.9734175942117937, 0.9824711618547269, 0.9533241400282425, 0.9606699481010409, 0.9622263775505104, 0.9730225003168952, 0.9835365427331723, 0.9812494512147636, 0.32946675968946415, 0.5739820992992601, 0.5525936813582997, 0.3510213608263175, 0.6492497633930615, 0.5615390131651876, 0.2927674994080679, 0.3565350609283806, 0.6342391465733593, 0.576458981212912, 0.29844715615727346, 0.2357975780686442, 0.26875768774170894, 0.26944382561850877, 0.1892332121073761, 0.6553747593558006, 0.7808602997261336, 0.24387971581785728, 0.13043162311733736, 0.3467644002473761, 0.34682571807362184, 0.10879606548103948, 0.12918648018276202, 0.27343732948752775, 0.1757408628600453, 0.147837980603988, 0.5038408309374758, 0.28989412624239075, 0.3669357325990209, 0.3048525016221033, 0.17517592802564852, 0.16858122009744891, 0.12854213249415825, 0.14427287217096396, 0.1774794656339036, 0.11601396411553977, 0.08293646778416441, 0.08121480621686827, 0.07974956887575935, 0.028134893936371586, 9.999999999998899e-05, 0.017702142570854784, 0.07387632424130786, 0.07795959870872449, 0.0028128100401556555, 0.16196622943847383, 0.07490398913831964, 0.34436021863524224, 0.060819222761289704, 0.5416752041752866, 0.01885365063791955, 0.22995273152574291, 0.355995454894528, 0.33897807411375247, 0.02278221648263201, 0.08245475108469491, 0.04558881692033734, 0.07870751458520642, 0.11393981933443631, 0.08247047218285986, 0.0480818390140465, 0.13599643647388182, 0.15551177436897123, 0.09721217126520587, 0.04195764344648689, 0.22507780572094893, 0.03281701157983985, 0.2254441425340329, 0.2062856671732748, 0.05061866393117487, 0.32345975765442536, 0.1105502955872345, 0.4848121227926293, 0.6848869245685432, 0.6471165541721742, 0.5111888005331724, 0.659165802139315, 0.6000291570721856, 0.4681718949094765, 0.5886057121177772, 0.6739449427528945, 0.11512383025689887, 0.06469178744182058, 0.07729615283839064, 0.1081306849392002, 0.12343504059320198, 0.11520158737805908, 0.08065917541246781, 0.1749900105924297, 0.12583812648632797, 0.18378349305778807, 0.24793428298466902, 0.2598063033875354, 0.20699543177973623, 0.33903181172483554, 0.16710118925188633, 0.4071299892796467, 0.20331411776365005, 0.49278384805304054, 0.2713272878466164, 0.23150964528254947, 0.36835221445247457, 0.29977855030824363, 0.4066690964166473, 0.46472010513070117, 0.3111602246357753, 0.37955583697758466, 0.2932916444483369, 0.2403356962223897, 0.23524311088283, 0.315096923430114, 0.19619465948746462, 0.1868798300131176, 0.26303298969518774, 0.28703514395302565, 0.32500377008630954, 0.19711305426491643, 0.2385964584275092, 0.22436995744264454, 0.21327464545560892, 0.22160911692881013, 0.20972134521331998, 0.21034328008540426, 0.194357898141288, 0.21810873200560477, 0.20269354200400425, 0.19197244942269875, 0.2146700136973987, 0.1931278776835328, 0.36131966929548887, 0.2252355798097997, 0.18415947526055976, 0.2259176921094962, 0.1912723463378314, 0.17309835488147185, 0.784148907359007, 0.18746857973896802, 0.16788487580541334, 0.7203314122582242, 0.1997708025468251, 0.1971025022200159, 0.1408241015762305, 0.1599033580236765, 0.8652356042183, 0.6508710805660254, 0.21113337268753074, 0.20178923005989213, 0.6915059913586881, 0.16701017973890453, 0.16558957184647205, 0.19627001776039077, 0.10479446375579005, 0.12655705529333428, 0.212632864213798, 0.20654368097782494, 0.2007037008320658, 0.18348912082072966, 0.19721507862786336, 0.2044298888852032, 0.1812207920128578, 0.19053744779652282, 0.24531586436933905, 0.08686648750395176, 0.09647693668283497, 0.09303482447022093, 0.08894629349885397, 0.09368648434526206, 0.09529958383711745, 0.08078078569765967, 0.08502803782089319, 0.1014815176367796]}, "mutation_prompt": null}
{"id": "1603599a-74ae-4026-903f-969df6af67ac", "solution": "import numpy as np\n\nclass ProbabilisticAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.4 * np.random.rand()\n        self.c1 = 1.5 + 0.1 * np.random.rand()\n        self.c2 = 1.7 + 0.1 * np.random.rand()\n        self.F = 0.5 + 0.3 * np.random.rand()\n        self.CR = 0.6 + 0.3 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.07) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.w + 0.07)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.07) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.F + 0.07)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.05 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "ProbabilisticAdaptiveHybridOptimizer", "description": "A probabilistic adaptive hybrid algorithm leveraging multi-strategy learning and stochastic perturbation for enhanced convergence.", "configspace": "", "generation": 84, "fitness": 0.35943593658261375, "feedback": "The algorithm ProbabilisticAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.28.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.798386629940598, 0.8140038684614535, 0.8022257739253773, 0.8023115510660797, 0.8324033018839588, 0.8184184473952807, 0.8120566341802481, 0.7993198247980557, 0.830823275729308, 0.5795948532511028, 0.5184018813252469, 0.5279612888639034, 0.5918061856791046, 0.5572764850684835, 0.5971402525569998, 0.593117346688006, 0.6036054724537274, 0.5777604494417663, 0.11669860609931693, 0.16069576018193965, 0.10515671117543535, 0.11115510671037987, 0.09192719214687983, 0.1425447726839265, 0.1365145635804731, 0.17729713437732175, 0.17310659748063395, 0.10916456457730006, 0.09501007898284675, 0.11556753927066055, 0.09644785178445947, 0.11992227730625749, 0.06977562895438627, 0.11030940298197511, 0.10642740296674769, 0.10583141808703855, 0.972702869562636, 0.9734682035510478, 0.9831630328586503, 0.9724673614502476, 0.9601656476954725, 0.971776196486502, 0.9727960929662032, 0.983443976067325, 0.9811028069051303, 0.5860061461203013, 0.614958936450563, 0.4824813399814424, 0.5749243798309396, 0.5183423735427716, 0.5346874091244398, 0.3716568559129897, 0.5316056605031527, 0.6198740205272831, 0.818639586866515, 0.8557464882562138, 0.8446962081234877, 0.27693110622212247, 0.2810286150847312, 0.1913246094761576, 0.8667912388366211, 0.6776111362077089, 0.8719809217760112, 0.599760598012501, 0.31279641905649236, 0.47363532809451603, 0.35226551766115766, 0.539224002824372, 0.12711836465863946, 0.47142995242107355, 0.11781103706516582, 0.6525585029934937, 0.4706256080094052, 0.3660624169126805, 0.1188628285326302, 0.49851313964255883, 0.12933944798105035, 0.48349381480266684, 0.29951325546678376, 0.5541865179356009, 0.11907540124143434, 0.2015574593469862, 0.024079189879376628, 0.09212644549063753, 0.0005574733377475827, 9.999999999998899e-05, 0.005024103388300505, 0.15193662754138826, 0.007373356997960934, 0.0026853220055943483, 0.3862069038256317, 0.1308639359296876, 0.46188650429223466, 0.12692314380824532, 0.5982511478303985, 0.03206544678347767, 0.2231360977079263, 0.5997715183888047, 0.11162797799787183, 0.10523905600657457, 0.044269065988996936, 0.15943434761834907, 0.12992025203384017, 0.14205801688972008, 0.12922879311079782, 0.12137543076735224, 0.18127337626507045, 0.1794162716723957, 0.25041847638226267, 0.2321537829251844, 0.29425573727289767, 0.17064967965043287, 0.3423943177781099, 0.23154344838536112, 0.046791120164487277, 0.18065191530753177, 0.08151877538681807, 0.5793939088875715, 0.6132230275235317, 0.6669008482285673, 0.6433204586689387, 0.733932648379362, 0.6294404296832777, 0.6046570252268915, 0.7230082514781024, 0.6984237425627087, 0.0834325671990438, 0.08881094588975247, 0.07489263512343991, 0.12051603056305504, 0.08836200734603095, 0.12225722795775129, 0.08952770070009008, 0.17460663486795802, 0.08859689389089775, 0.1793335277069451, 0.7083661646768167, 0.679394607007183, 0.3713108550957366, 0.2734692359524077, 0.19337794445184608, 0.1525060408860438, 0.20849869612062322, 0.2734010044148508, 0.38168214527176425, 0.2043214517281865, 0.32112002384333416, 0.4312323109182896, 0.2688027628787678, 0.4527012119688615, 0.4444453649758131, 0.5569097490227879, 0.39121527241146914, 0.2836925656132451, 0.22356063774126156, 0.2424773204892876, 0.23477681174202092, 0.3161752085456172, 0.23883091560840775, 0.2394719535817702, 0.28942986971381335, 0.20623173049025045, 0.23152612979570453, 0.24251611653712013, 0.18695497620300017, 0.2335159925363629, 0.20977652042202155, 0.20193733614336074, 0.1931739391248376, 0.2552777578669372, 0.23321653550495047, 0.6127476312977345, 0.18592830997678622, 0.20312396905309782, 0.20062409426033934, 0.20386937699080754, 0.19629315268625358, 0.1830167088267054, 0.19555692176465977, 0.1787509790462729, 0.8597395584629448, 0.18808835825677095, 0.16785018580905475, 0.8328258435261078, 0.19930799163486668, 0.1690720345305654, 0.14249792249253768, 0.16210971051557066, 0.8983968451429901, 0.8497218458816995, 0.21101552451555516, 0.843832488821923, 0.8091987430182941, 0.8290098761366081, 0.15490699558431276, 0.20750644503642646, 0.10464825917080611, 0.8008128264896168, 0.19096637595505028, 0.227402232500599, 0.17840106690919433, 0.18234499013754357, 0.18753698498046445, 0.20520523876643992, 0.20259513208954738, 0.18463251153125004, 0.25451715914969175, 0.11865327581684937, 0.09584212818905946, 0.09172850776109787, 0.09895666545773152, 0.10068981796032461, 0.0958334016062592, 0.12800964299275142, 0.08053439922157068, 0.09035047680715236]}, "mutation_prompt": null}
{"id": "d2e070fd-3b97-4c0d-8e5e-828dd058f206", "solution": "import numpy as np\n\nclass RefinedAdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.4 * np.random.rand()\n        self.c1 = 1.5 + 0.1 * np.random.rand()\n        self.c2 = 1.7 + 0.1 * np.random.rand()\n        self.F = 0.5 + 0.3 * np.random.rand()\n        self.CR = 0.6 + 0.3 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust', 'CR_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c1 + 0.05)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c2 + 0.05)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.w + 0.05)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.F + 0.05)\n            elif learning_strategy == 'CR_adjust':\n                self.CR = max(0.5, self.CR - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.CR + 0.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.05 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "RefinedAdaptiveHybridPSODE", "description": "A refined adaptive hybrid algorithm enhancing parameter tuning through probabilistic mutation and synergy optimization with dynamic adaptation of cognitive and social factors.", "configspace": "", "generation": 85, "fitness": 0.3192015760640836, "feedback": "The algorithm RefinedAdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.26.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.6037310684815933, 0.8097185557390185, 0.8019273027384167, 0.6989683731413201, 0.8304652751203402, 0.8179106076850359, 0.5029919378553408, 0.8110683333072258, 0.8196828848490364, 0.28517136396924747, 0.58832067940182, 0.5715441104109946, 0.05563889969120994, 0.6158862999047483, 0.5772231741687841, 0.2894732593192513, 0.49545048116927437, 0.580483225389514, 0.12556992550578783, 0.17070460683209554, 0.12525068437679998, 0.09993559846700062, 0.1541857400743054, 0.10221978519947539, 0.09485857205736392, 0.10569902001763565, 0.14094058839214407, 0.11362975708552325, 0.08877011689417957, 0.10028314957559614, 0.12664455811282638, 0.09786287278188688, 0.10787744759458018, 0.12635178116815482, 0.08908380658589377, 0.0931472693117601, 0.9831348707296332, 0.973489399693894, 0.9831655121814441, 0.9491992454785214, 0.9602126944169558, 0.971773895238011, 0.9728279559249258, 0.9834442671095414, 0.9811072560065687, 0.4257911716587224, 0.6538608285365985, 0.45389056316534193, 0.35744315983531827, 0.6381748012168657, 0.5877216974980812, 0.3312346234826816, 0.597645678458759, 0.6243839242983893, 0.6913294494530808, 0.2283579280866993, 0.22303901363837386, 0.20890703309198233, 0.5915736427471496, 0.20543345419833814, 0.22329219782908738, 0.7766743439718363, 0.21501402770497602, 0.12056276178765002, 0.12407992634941822, 0.47289346820811884, 0.22074244502124496, 0.6679161147864983, 0.12528985122204417, 0.3754444964771201, 0.11614269499414753, 0.6576000326855809, 0.40970169252292954, 0.1232013835427006, 0.12010419709789244, 0.12814654705549178, 0.5219740273474093, 0.1297814011478624, 0.2548423121221427, 0.23075200262720985, 0.1095985118733408, 0.1850167965605516, 9.999999999998899e-05, 0.06888188937974937, 0.030805894724869387, 9.999999999998899e-05, 9.999999999998899e-05, 0.1925333341464407, 0.07073484648525241, 0.002858366163498993, 0.2051332659355385, 0.1304563568449566, 0.1300457244343992, 0.13590468567839542, 0.23367126061639154, 0.10809129698814701, 0.2181143200085086, 0.3073517187223094, 0.15756189208382998, 0.03820916083466219, 0.06495558460490469, 0.18344294263402594, 0.09607761938488435, 0.1289626850143224, 0.11224824016305701, 0.0746982823117518, 0.11317344647870542, 0.3345499368133331, 0.1696121012926598, 0.3560548606948758, 0.1460417463229754, 0.13262971353798747, 0.22922657653206446, 0.14266521003037924, 0.046145014801409534, 0.28298067778739155, 0.08038207266127961, 0.574615810004939, 0.6472744286322651, 0.7490439054555903, 0.5056444924410941, 0.6777033128109718, 0.6076908794255895, 0.5522522217794664, 0.5738001534710415, 0.6184301720010554, 0.09887133404432102, 0.08637939330970967, 0.06326520169211836, 0.11513073128648066, 0.12490588759698074, 0.1447397726442301, 0.11895805959587047, 0.15667702141095396, 0.13492175592550737, 0.10366427270101997, 0.24115258124300532, 0.4626429642879408, 0.416850111750835, 0.3224918194599671, 0.1967926903417806, 0.3284717436997744, 0.20749132807174464, 0.20607602588396878, 0.41438490995224775, 0.30179609772243254, 0.34924836357973377, 0.3102412242269763, 0.32152338910878564, 0.46110557297408583, 0.36357206489975413, 0.4510936196136297, 0.29117334726127087, 0.22132135181655888, 0.21187472600514934, 0.18804460603353046, 0.28244694552849636, 0.3012260578024789, 0.23800829392083223, 0.2108341318034641, 0.27961218115516207, 0.22252488462515763, 0.2129575760053266, 0.23548106004902392, 0.19315142004688157, 0.2328259839120448, 0.26914994307246665, 0.2209541841594822, 0.21294496870134827, 0.27860975412806166, 0.2338243416492194, 0.1969992635524942, 0.18136200974820926, 0.19983624211925932, 0.48345436932300456, 0.7109069366231004, 0.2050326697694146, 0.2034414311189957, 0.23761670427576886, 0.18893748692704238, 0.8037394720686971, 0.18795633449397875, 0.16776019815323562, 0.8417152393588623, 0.19933204927173276, 0.16907528143425565, 0.8188355388827713, 0.16229206741470192, 0.8829014275441637, 0.8035052481481343, 0.21102973379665768, 0.8076773205321962, 0.20437788953002323, 0.16597623727081678, 0.15483286497782678, 0.19911812362455916, 0.10462778591154964, 0.8121585582207781, 0.19434174113326286, 0.19659875107243074, 0.19981661388315353, 0.18258821415489135, 0.2391723380190509, 0.22089650719951381, 0.2104401020972626, 0.20350556162257893, 0.22607968226319886, 0.08986119617343902, 0.0809741558618372, 0.0841364874457915, 0.09770263505666021, 0.08574993899232508, 0.07703836789637131, 0.08227364637215762, 0.10315341684996382, 0.09375838336486653]}, "mutation_prompt": null}
{"id": "1ec3e095-e4d8-48ba-bb58-e369d622b911", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.4 * np.random.rand()\n        self.c1 = 1.5 + 0.1 * np.random.rand()\n        self.c2 = 1.7 + 0.1 * np.random.rand()\n        self.F = 0.5 + 0.3 * np.random.rand()\n        self.CR = 0.6 + 0.3 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.rand(3)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                chaos_component = 0.5 * r3 * (np.random.uniform(self.lower_bound, self.upper_bound, self.dim) - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component + chaos_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.07) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.w + 0.07)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.07) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.F + 0.07)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.05 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedAdaptiveHybridPSODE", "description": "An enhanced adaptive hybrid PSO-DE algorithm utilizing strategic parameter shifts and chaos-inspired perturbations for robust exploration.", "configspace": "", "generation": 86, "fitness": 0.16405309408014446, "feedback": "The algorithm EnhancedAdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16 with standard deviation 0.19.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.2617723865354976, 0.25399537228389646, 0.26948495528341965, 0.2891787826235116, 0.2565801456104906, 0.2644410088284339, 0.25589922350905925, 0.2734910828968248, 0.2620555138774524, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.000925645955047405, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06719963039353338, 0.06524899251654237, 0.07831907897055312, 0.0827102118679448, 0.08676328289825253, 0.08092452360020741, 0.0828950160119808, 0.057846028996073384, 0.0851991334466935, 0.06927305695466035, 0.08047598872763628, 0.05607908162401676, 0.058473829914326814, 0.06472105106469439, 0.06920342446389749, 0.05835599106898082, 0.058840813767237155, 0.07150425075504185, 0.9723471939751855, 0.9415645163095051, 0.9786143761570683, 0.9740484638728637, 0.9705054666800461, 0.9726117864617542, 0.9661816461313484, 0.9816050355296368, 0.9752479608664574, 0.14507928183039154, 0.12538604569786016, 0.14448882541648833, 0.13711890448970587, 0.128626551379181, 0.1442802120549459, 0.17508501314755265, 0.1471220809091095, 0.1622367058734182, 0.21185480383377375, 0.21199305494713339, 0.23807446289272483, 0.1686190884725638, 0.18037280801708244, 0.200299548392466, 0.16654776298671603, 0.18874610980228512, 0.1647826777257, 0.08194035609992656, 0.06523933605933185, 0.08484829657850335, 0.058519360020243605, 0.0734746029524993, 0.0534008738703291, 0.08209550415330502, 0.05962737954008823, 0.07206822164105453, 0.0867615729244039, 0.08515803542731115, 0.10165676199430185, 0.08682106232334097, 0.10105081002397487, 0.10802768934601625, 0.0648393193098713, 0.07673624956202607, 0.08800426452228038, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.100463766815027, 0.06060204342735431, 0.057560915324000095, 0.058584782852622586, 0.08791712845182553, 0.040876426063757965, 0.08764646677864751, 0.11440610428593467, 0.08722501099673641, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007275876342825671, 0.03782419219008859, 0.03737615480240586, 0.010802801223199654, 0.014226375857160023, 0.029970508026042952, 0.015749065424036757, 0.04054284144361886, 0.018995748389639133, 0.2660188122341406, 0.27955679496317587, 0.2747528719889849, 0.26017253711289845, 0.2792397014209993, 0.2597473516178219, 0.2675565418784268, 0.2623010986182146, 0.2566380525121781, 0.06823876852187749, 0.06556516815204527, 0.0807997973359863, 0.0648942060351324, 0.06323015862450065, 0.08241984253346923, 0.0698710331928063, 0.08547965482678266, 0.07591913933435912, 0.14709642779192478, 0.14765829598251, 0.13791101200176892, 0.18237974983496152, 0.1285685274166286, 0.13384883154676386, 0.1626524234049761, 0.21062718672421865, 0.13646593045859012, 0.1992370090645582, 0.19550298132483745, 0.2139367681763118, 0.20078719302174108, 0.2188102284436233, 0.2088097176439464, 0.19506396534935488, 0.22740210486319856, 0.2165837708534194, 0.14384425772512532, 0.13329104690466498, 0.16871944777405223, 0.15136972922865954, 0.15198179322324212, 0.16704152808667405, 0.1746881712333005, 0.14473411827663696, 0.16186210275019708, 0.18595643662369776, 0.19487655563513873, 0.2125002325800529, 0.19473432937858437, 0.1915018855551731, 0.17568506516322324, 0.21319887191891673, 0.20739959535607988, 0.20033240733736823, 0.1741756379226772, 0.17447997571575946, 0.1737802297812514, 0.16614976285849092, 0.17210588776950497, 0.1662837107669708, 0.16195658803379032, 0.1761091453225394, 0.1577929579886559, 0.352834641434989, 0.2819456701211338, 0.195801566581571, 0.28924002983407027, 0.17323446184722868, 0.2078215871052458, 0.3056364699180677, 0.1918855937958317, 0.29283999521968884, 0.2665183674401904, 0.216899888769431, 0.3341074852862632, 0.18891849817907824, 0.23655410846313174, 0.17622346389070387, 0.19162440188571783, 0.1895589208127474, 0.29434578638505493, 0.18372461823562658, 0.17503438243558667, 0.18562955940963521, 0.17626171535086288, 0.17804117958778443, 0.1992303550396035, 0.1715165519452596, 0.18153030060774678, 0.1734592840686059, 0.07497820196759386, 0.06630829776533409, 0.06941044828547804, 0.07483029989815781, 0.06494031337510786, 0.070753747539818, 0.07024752527246092, 0.06767770170282295, 0.06739398279340858]}, "mutation_prompt": null}
{"id": "e2e8bf7a-bd4c-480c-977e-17a2b16ecae5", "solution": "import numpy as np\n\nclass RefinedAdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // (dim * 3))\n        self.w = 0.4 + 0.2 * np.random.rand()\n        self.c1 = 1.5 + 0.2 * np.random.rand()\n        self.c2 = 1.8 + 0.2 * np.random.rand()\n        self.F = 0.6 + 0.2 * np.random.rand()\n        self.CR = 0.7 + 0.2 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = np.clip(self.c1 + 0.1 * np.random.uniform(-1, 1), 0.5, 2.5)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = np.clip(self.c2 + 0.1 * np.random.uniform(-1, 1), 0.5, 2.5)\n            elif learning_strategy == 'w_adjust':\n                self.w = np.clip(self.w + 0.05 * np.random.uniform(-1, 1), 0.2, 1.0)\n            elif learning_strategy == 'F_adjust':\n                self.F = np.clip(self.F + 0.05 * np.random.uniform(-1, 1), 0.3, 0.9)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.05 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "RefinedAdaptiveHybridPSODE", "description": "A probabilistic parameter adjustment enhances the hybrid optimization strategy by dynamically adapting to the function landscape.", "configspace": "", "generation": 87, "fitness": 0.29891014634346846, "feedback": "The algorithm RefinedAdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.24.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.6364886017563127, 0.7137681637169646, 0.7422377122788554, 0.6365843724844344, 0.7703166581785688, 0.7438371062188822, 0.6596791890263152, 0.7090322073916759, 0.6457070126235052, 0.2701915447668428, 0.4115279304867592, 0.3276092290611875, 0.37629621707706506, 0.4427395827016868, 0.2964027414700745, 0.3417954415729515, 0.46320749856969434, 0.04800673570436376, 0.11534026863028579, 0.15661768175462243, 0.14515273056253586, 0.15856193435611676, 0.11588070281768492, 0.13010117807720345, 0.12004930636702738, 0.11918029636502847, 0.12118037912881519, 0.138001567425857, 0.09195621187524994, 0.10178283288463785, 0.09690387658035293, 0.1030323917713436, 0.09518824582145424, 0.1315170069930276, 0.17790498785463338, 0.07779705335805942, 0.9827014869328173, 0.9774687440624104, 0.9860736546585364, 0.9790096891889886, 0.9761888731916739, 0.977540633891157, 0.9785820068123364, 0.9680158559964382, 0.9766276383621363, 0.41190875937747295, 0.527410449230457, 0.392700618367394, 0.3584476497377289, 0.5417119450026358, 0.14819935022916675, 0.2820158438474596, 0.08778098304473692, 0.3592633432462867, 0.7714974109221218, 0.22312559185171743, 0.6704287438118403, 0.21555090444315872, 0.7795717285890902, 0.2081480681812905, 0.625269157103028, 0.6977940925110094, 0.7191888808974349, 0.3890510181922646, 0.27942827360550204, 0.2683244530922331, 0.0999417407525014, 0.33624171974564965, 0.12167587279372549, 0.14710260904227257, 0.33817129928905043, 0.2525495005080216, 0.29144655631856287, 0.5007178105477734, 0.14664319033372486, 0.1822240213131021, 0.337644680757445, 0.2822313833575294, 0.2898371655288624, 0.11118700406951665, 0.3258601711718535, 0.03368587002957679, 0.04024465354599305, 0.07957487072536984, 0.03373215423408893, 9.999999999998899e-05, 0.005656204201439863, 0.1895216449281274, 0.09644357170479145, 0.1841216735742529, 0.07851512420009599, 0.38873415463288885, 0.19614320704411048, 0.2839724287080946, 0.03547254008267042, 0.06472339632332058, 0.26740309694796416, 0.3398018997309098, 0.04597199501687843, 0.06603413078959874, 9.999999999998899e-05, 0.08427743823460787, 0.09855887335652114, 0.05922259362788895, 0.05926994431797994, 0.06954974017942095, 0.10382689430194258, 0.14538427472356674, 0.1516930851753806, 0.24213711134529148, 0.19897009913739028, 0.20351139026606835, 0.27024510857875383, 0.18143688511748934, 0.04561496268663634, 9.999999999998899e-05, 0.0773211415943561, 0.5659399043507852, 0.6022565344742639, 0.6097758598461218, 0.48502865885755075, 0.587355680466807, 0.20678095263087748, 0.5101219733343522, 0.5611012459005269, 0.5174873883483144, 0.11320650436756985, 0.08438229132178077, 0.08625006640646193, 0.11415174155428609, 0.3298001606673252, 0.12160543622811115, 0.13969667906979355, 0.12850907648238685, 0.08764251455808447, 0.15501268255134548, 0.22354720060140576, 0.20335713590640514, 0.3713087873457461, 0.466026399049949, 0.23266221722382485, 0.3559751900987842, 0.4865854905560174, 0.15162184077580876, 0.30790196492453825, 0.3760528121758736, 0.35635151616628513, 0.37976186758404873, 0.41497988240821637, 0.22553044689901913, 0.3261772212630579, 0.3912195091889541, 0.39202560596573044, 0.2324248707555061, 0.18585158727588336, 0.27767693219133904, 0.23520679809294887, 0.23295505965736785, 0.2498561115776614, 0.20081161374739753, 0.3821403692141384, 0.22644212756109738, 0.19827797175711315, 0.1541955171013124, 0.2330658775180383, 0.22249118931141754, 0.23918781277473877, 0.2628892833835984, 0.2272048591996949, 0.2210765264500838, 0.24146714501795186, 0.2296520903125332, 0.2350137119798943, 0.38529270863876053, 0.2402220650491117, 0.2286623049522577, 0.2170483722047991, 0.19694093161931403, 0.1732464578598356, 0.2077976920475113, 0.8162442018816478, 0.16637617942107064, 0.167895373829675, 0.7470311679763113, 0.19693122991600487, 0.1988735567178611, 0.14225093425795965, 0.16021052389050838, 0.20581291457633988, 0.7313598828249728, 0.20847733104559973, 0.20014843398112514, 0.649332925689386, 0.773644677065545, 0.14317297843950672, 0.10406082751125323, 0.19881549175914237, 0.7642280574090418, 0.18564293958855482, 0.21618760206094467, 0.20357746820176803, 0.17526053184748003, 0.1916238257430377, 0.19090046576009712, 0.19345689313663306, 0.19328140041047004, 0.18939846494240542, 0.11572311099616306, 0.09050387067518328, 0.0905935117479163, 0.09655556576463387, 0.09534205650833771, 0.07554330251894137, 0.12548029338193933, 0.09109843250257599, 0.09011742872377926]}, "mutation_prompt": null}
{"id": "86ad89f6-6dd0-403b-b8b9-43b88f8d2c6e", "solution": "import numpy as np\n\nclass DiversifiedAdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(70, budget // (dim * 4))\n        self.w = 0.3 + 0.5 * np.random.rand()\n        self.c1 = 1.4 + 0.2 * np.random.rand()\n        self.c2 = 1.8 + 0.2 * np.random.rand()\n        self.F = 0.4 + 0.4 * np.random.rand()\n        self.CR = 0.5 + 0.4 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust', 'CR_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.4, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.6, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.4, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.6, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.2, self.w - 0.07) if self.global_best_score < np.median(self.personal_best_scores) else min(1.2, self.w + 0.07)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.3, self.F - 0.07) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.F + 0.07)\n            elif learning_strategy == 'CR_adjust':\n                self.CR = max(0.4, self.CR - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.CR + 0.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.05 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "DiversifiedAdaptiveHybridPSODE", "description": "A diversified adaptive hybrid algorithm utilizing stochastic parameter variations and synergistic optimization with enhanced mutation for robust performance.", "configspace": "", "generation": 88, "fitness": 0.2625630367564575, "feedback": "The algorithm DiversifiedAdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.23.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.5648131320149157, 0.6363061121501721, 0.5737311863313587, 0.5087792506089603, 0.6573819529004756, 0.6651216786450838, 0.5223172215939639, 0.6644820987983945, 0.6208276305129852, 0.12576995156015458, 0.20139576916815383, 0.26986829340671303, 0.12652500249133958, 0.2589550452177265, 0.19522411362505854, 0.10536457826540413, 0.21916301763912738, 0.1509304486924502, 0.11382104875646437, 0.11707016667517833, 0.13752508899210047, 0.1114734392674549, 0.13322551554414097, 0.12679026774191693, 0.11709380145055115, 0.14213229184462506, 0.1183059861493122, 0.08534610353250116, 0.1242166215070194, 0.11860792762388339, 0.11157791032334374, 0.10028628695892072, 0.09487338609635376, 0.11647332521124532, 0.11910999741090944, 0.08852978950134982, 0.9800374936235406, 0.986829319621335, 0.9798311408253854, 0.9567428058487033, 0.9555660385598523, 0.9686594068494959, 0.9881640590099908, 0.9811115047578273, 0.9691167134360531, 0.30019871819285193, 0.4158443953176114, 0.3962982224823228, 0.27084585931444394, 0.40779709623581606, 0.3600434727075158, 0.11820104230552864, 0.3553019971641531, 0.3643326362437862, 0.5650906310521541, 0.22406372501735683, 0.22614943682682387, 0.19881059795844613, 0.2093807397697126, 0.20137052055951365, 0.5577325397458432, 0.8097861049703013, 0.754413864977108, 0.10329333214526681, 0.18802314622613814, 0.18146121374927038, 0.11469673962190774, 0.22583635808942026, 9.999999999998899e-05, 0.16783263067847531, 0.3095445238163024, 0.26079052306745354, 0.213846626378822, 0.12019189865787105, 0.2013205635896208, 0.16100248889755564, 0.28784678865643787, 0.2339626241803734, 0.17456340860546538, 0.22293511667623023, 0.11063909818477946, 9.999999999998899e-05, 9.999999999998899e-05, 0.08933705691115623, 0.04298536795054131, 0.0021486758442746945, 0.00217245400140742, 0.0056190680247787395, 0.0707269917859581, 0.0016219640352641562, 0.19244775006969217, 0.06838097092769535, 0.19258005707060877, 0.06760762252944674, 0.1884943518385307, 0.04900206077467906, 0.0966379243765847, 0.18443071584026816, 0.23681043255238265, 0.07387567126851913, 0.03417107659069718, 0.07472870137089194, 0.09794541062561168, 0.0572567925083598, 0.11535278985665043, 0.05143416945534496, 0.043926351986796175, 0.048907532808819765, 0.13123597333502435, 0.14817909577839605, 0.18596338347790942, 0.10369992498545688, 0.17402945953252824, 0.12396240632873778, 0.04602480950901011, 0.0730191893667621, 0.0862524998664096, 0.41841148308107023, 0.554607188832772, 0.5029207153047495, 0.47393375178896235, 0.5352625029185509, 0.4967441837359594, 0.4668164075871257, 0.5337693658767961, 0.5391355247415053, 0.09356342078718749, 0.06590903882051735, 0.06333415135381748, 0.12426746444513015, 0.10907146135836499, 0.1145423942172874, 0.11469621696229004, 0.09292551573568708, 0.1375793757964361, 0.27232430397667484, 0.18116762356884508, 0.20556033543356966, 0.32730784920249234, 0.20470391899915874, 0.298676658827408, 0.1896955051953767, 0.22984967940452306, 0.20554210820781227, 0.3014875697524133, 0.3190650033563256, 0.38230506566357203, 0.324200215862292, 0.31364663020171535, 0.32482453324517613, 0.30944690558381793, 0.38242840058639493, 0.36873348509206494, 0.24069665872551682, 0.16647948268633606, 0.2610438599437881, 0.16241401857906423, 0.23056547191383203, 0.2005673477729627, 0.19544947291341752, 0.2858493175184529, 0.23182593691042885, 0.22306587610867235, 0.23535753823255956, 0.27208388782813553, 0.22374769875428568, 0.2228140274435485, 0.24913455772767545, 0.21800131446860282, 0.20920150894858236, 0.22230726617036045, 0.1919462428309976, 0.1951104963179956, 0.19602157127217656, 0.21784196031537595, 0.23231382855508154, 0.19676860560780707, 0.1831152684131051, 0.2138097846553606, 0.19825324499015318, 0.12940970447969224, 0.18445985600427983, 0.6976972559256385, 0.5850231275262459, 0.19903094887893447, 0.1670060247594971, 0.13990247002516387, 0.15960773999060895, 0.768259954879861, 0.6733937824598323, 0.20847280721684558, 0.6898359258792784, 0.20441220352915357, 0.7167422171508016, 0.14919049774319626, 0.2018399347436396, 0.11225164709952129, 0.6801564322023503, 0.1807098354993728, 0.20311466814435886, 0.24752121400210803, 0.19482798525452028, 0.1758175797459306, 0.20744170977924592, 0.20914197417010305, 0.1817327316576116, 0.19565243799432652, 0.08211483254341023, 0.057605380081690916, 0.07338967467982616, 0.07934584693139035, 0.09623981158991324, 0.07551865827016702, 0.07672246130226779, 0.08228871819198591, 0.08930438196415924]}, "mutation_prompt": null}
{"id": "c92ee659-6de3-4e0a-b1a4-3c96bf0a3315", "solution": "import numpy as np\n\nclass DynamicMultiStrategyPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.4 * np.random.rand()  # inertia\n        self.c1 = 1.5 + 0.1 * np.random.rand()  # cognitive\n        self.c2 = 1.7 + 0.1 * np.random.rand()  # social\n        self.F = 0.5 + 0.3 * np.random.rand()   # mutation\n        self.CR = 0.6 + 0.3 * np.random.rand()  # crossover\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.rand(3)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                random_component = self.w * r3 * self.velocities[i]\n                self.velocities[i] = random_component + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c1 + 0.05)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c2 + 0.05)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.w + 0.05)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.F + 0.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.05 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "DynamicMultiStrategyPSODE", "description": "A dynamic multi-strategy PSO-DE hybrid optimization algorithm with probabilistic mutation and feedback parameter adjustment.", "configspace": "", "generation": 89, "fitness": 0.3294621404316, "feedback": "The algorithm DynamicMultiStrategyPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.27.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.859563770400566, 0.8454003177668923, 0.8734899468097287, 0.8684442819339837, 0.8463069736166261, 0.8611985661508607, 0.8342892961202237, 0.8767625054097158, 0.8505947260190918, 0.5603093784783943, 0.5840515989140537, 0.6274444564885746, 0.6183706686589276, 0.6894139267887367, 0.6116957396102767, 0.6728577749630157, 0.7143433336118182, 0.05387026612044865, 0.12390381518991622, 0.10949929050676455, 0.13025928362259487, 0.14264239094822273, 0.11732949845951246, 0.11771677425660587, 0.17500467400919384, 0.15384542596765483, 0.11815870898871239, 0.10064890397431703, 0.1149787226921335, 0.1281014345346021, 0.09516623228611842, 0.10036199640427823, 0.131224840497014, 0.13482170285953676, 0.14832609783439143, 0.10147191472010586, 0.9718630034036084, 0.9826220581854753, 0.9728167559108782, 0.9273247240230007, 0.9695904551861977, 0.9609124538515474, 0.9836924627376561, 0.9829722592110269, 0.9712791049770545, 0.7115579695450445, 0.6046748435421241, 0.5882349462215861, 0.6027754192492234, 0.6057488551564145, 0.5090080965433004, 0.6513161971822499, 0.5680514241570251, 0.6431834894011301, 0.22875517908287646, 0.867142396002678, 0.39004993006450517, 0.2214393491297415, 0.19386780055460362, 0.1913338267639817, 0.22809819534904496, 0.22877221298860106, 0.21995494976800156, 0.7347182880611256, 0.1411489601355812, 0.34472685445151063, 0.36608456668936595, 0.3723968206666056, 9.999999999998899e-05, 0.35900090718453637, 0.3008305848358458, 0.3131660500363822, 0.34308562637671836, 0.17182820741355576, 0.4585419418698409, 0.43168997621780114, 0.5391875780080712, 0.57980805053425, 0.3945737151841303, 0.3583116335635098, 0.12233132307367212, 0.1535382902764335, 0.07841200613903254, 0.08806216819154977, 0.0004671154321593818, 9.999999999998899e-05, 0.06147273261340103, 0.05684310609961718, 0.15000676311157135, 0.011262593879267091, 0.12394169901759655, 0.09847775619636834, 0.18267990757620622, 0.1210382440435418, 0.17935526775939548, 0.08920872499812826, 0.1461932343371125, 0.23213605837004503, 0.10380765695869743, 0.1179964440075204, 0.07684543401312494, 0.1988975347327746, 0.13432096427623652, 0.18827403123890396, 0.1264812511343325, 0.13910171621618406, 0.1025261993845028, 0.2210292666582, 0.19325075382570878, 0.18659642806063714, 0.15956343710018805, 0.31288875137478056, 0.16639417739970797, 0.1688401016958021, 0.17829785094792827, 0.16988643752332588, 0.08167426211835171, 0.6838713820817683, 0.7355891410079529, 0.5598708786521003, 0.6445680123945308, 0.5724994233787937, 0.656034520898616, 0.6469761233521524, 0.577868382803465, 0.6999344610862831, 0.07583036900429885, 0.07706905066849867, 0.08525960421420242, 0.10516487561591548, 0.07993679795483077, 0.0951807990518806, 0.08416739366464554, 0.156568490613737, 0.1160767922158813, 0.17621367242987818, 0.24882359601112392, 0.21702500861930663, 0.1959270719641102, 0.36660921594181906, 0.21032191995152738, 0.15552713867984236, 0.16975005468331927, 0.26835705132443743, 0.31072932081562055, 0.3924173712146053, 0.31418496974104904, 0.3727928648789015, 0.42679582113680736, 0.3073676790467963, 0.23987951753512549, 0.47698726023779203, 0.2911768506380159, 0.23728917669952576, 0.18412927992432315, 0.19836187924655446, 0.23058958908725402, 0.4196691806765682, 0.21517694010518795, 0.15841185549013503, 0.22811499061431717, 0.17697139274439855, 0.22534919294362676, 0.24781183363213377, 0.21668500212856368, 0.2251663627852989, 0.19619049734916816, 0.20914053029693425, 0.18752574414304846, 0.22956410315620124, 0.2311731598452773, 0.2434131530779865, 0.18015291727140015, 0.19869332244901716, 0.2502314776234672, 0.7365842848603826, 0.1961182306937217, 0.177320562666769, 0.20028554577875024, 0.17969138676795005, 0.8641738571371826, 0.1883760034459473, 0.1678993766985788, 0.9046152227269502, 0.20018212748030195, 0.20001798341747468, 0.14245675252922196, 0.16394355568874708, 0.8869209253378103, 0.8964149004960871, 0.21132313311501993, 0.07357877491892728, 0.7292934487450067, 0.16668897229780288, 0.15394648408487133, 0.21010029023889587, 0.10433763816623998, 0.7833490717761737, 0.20317081359567624, 0.21241675373320834, 0.22688210029539846, 0.20125207716631544, 0.21346543501782667, 0.17608014766809665, 0.2509579917536029, 0.17782452588031195, 0.24901160936207112, 0.1027130681216506, 0.08913379183528125, 0.08720476812125111, 0.08221644281786944, 0.10096848524760571, 0.09417702865124411, 0.09091206113485661, 0.08477182693791763, 0.09957336720354493]}, "mutation_prompt": null}
{"id": "05989466-29c8-4de6-9e66-64bf108ab4eb", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.5 + 0.3 * np.random.rand()\n        self.c1 = 1.4 + 0.2 * np.random.rand()\n        self.c2 = 1.8 + 0.2 * np.random.rand()\n        self.F = 0.6 + 0.3 * np.random.rand()\n        self.CR = 0.5 + 0.3 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust', 'CR_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.08) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.w + 0.08)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.06) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.F + 0.06)\n            elif learning_strategy == 'CR_adjust':\n                self.CR = max(0.4, self.CR - 0.07) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.CR + 0.07)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.05 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedAdaptiveHybridPSODE", "description": "An enhanced hybrid PSO-DE algorithm with adaptive inertia and mutation strategies to balance exploration and exploitation effectively.", "configspace": "", "generation": 90, "fitness": 0.277437492276838, "feedback": "The algorithm EnhancedAdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.25.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.41353866403857986, 0.8067920863227831, 0.7901216088132355, 0.43315557950452177, 0.8168398594579093, 0.8325873431354406, 0.4158244244976538, 0.8154375982723594, 0.8248671032044802, 0.01531723163496923, 0.5958380699535226, 0.5908957645770827, 0.08563195079370234, 0.5990269724875078, 0.38602518379347306, 0.06807931287680835, 0.6054121731689349, 0.4661158357627664, 0.10354925916827051, 0.11261279180633521, 0.10485474271247242, 0.09423400404547133, 0.1443026811238407, 0.13069473221843542, 0.10513770493502794, 0.09916336969527151, 0.12642886289949107, 0.08068616411658536, 0.07729945501755975, 0.14533797791950798, 0.10607471196909724, 0.08771847037942693, 0.13756238226122386, 0.10234000110945451, 0.12806596570829665, 0.14717638133296718, 0.9832130670230023, 0.9738257793864685, 0.9842275032443799, 0.9614857393903689, 0.9724263820355847, 0.9623843835620887, 0.9835913425064023, 0.9836204634101937, 0.9814850855383673, 0.3110610231301917, 0.5388819268323837, 0.05721792033878992, 0.1717924454406884, 0.5220513404545614, 0.6678636542135239, 0.07858282531078276, 0.494200903873131, 0.5526304708948536, 0.48720943133605665, 0.8607595214274446, 0.4329333406954179, 0.5194546970783867, 0.18861833856009558, 0.20228003653693727, 0.26889486798473283, 0.13890028518528452, 0.23176371597464362, 0.11733768869534544, 0.11719871841378204, 0.39816251871356967, 0.08768614073029801, 0.12985324843128765, 0.11216406568655424, 0.11656162850190699, 0.11338382800553537, 0.4817178197739648, 0.12684450104841294, 0.4565844596549846, 0.11802999377247692, 0.1388211008593191, 0.5187925120392953, 0.12528986920388174, 0.1655395392286969, 0.23461484145678513, 0.0863498983963753, 0.029655934989261223, 0.0753212979831871, 0.04523483072191736, 0.00843469298245525, 9.999999999998899e-05, 0.027113551091200505, 0.0201592113051966, 0.05066289669979618, 0.00530117596558799, 0.09283671248219039, 0.06949158093498409, 0.13437517292467926, 0.06467785928717762, 0.14155828955872696, 0.11278974017456, 0.07314631329963817, 0.535519777283223, 0.19841726091820833, 0.01498700019259247, 0.07328262653375406, 0.1251825746092572, 0.03010588564272798, 0.07531850575644672, 0.27909031610642654, 0.012013881501131474, 0.1487842867530268, 0.08955656130037137, 0.13836004189953743, 0.04208247542197241, 0.2213905312647898, 0.04180893757815396, 0.28038203773524983, 0.20813480818568897, 0.04651785973087841, 0.05498428584498816, 0.08115637731417158, 0.36652698971003006, 0.6578240123825596, 0.6996532186989542, 0.39941618181138183, 0.6161922953596894, 0.5743856289408005, 0.3638302409030473, 0.5674288451204867, 0.5691609119723777, 0.0992193844551339, 0.06472669591913183, 0.09623982595319758, 0.10761300227042903, 0.0806588284305968, 0.11581192945321694, 0.09430010724634119, 0.11485551799650873, 0.12508088067828194, 0.1635334295636265, 0.12881554875450385, 0.18025971993881262, 0.19149854719035897, 0.3892799786860516, 0.3286411722989463, 0.2451474175560041, 0.3227088162450591, 0.3165994536160588, 0.25881672394369404, 0.23022416195333195, 0.34448994073587647, 0.2680890157226651, 0.25000265076464934, 0.44748657110651224, 0.26209403068656734, 0.38502720909533494, 0.49968653052579837, 0.184273369417994, 0.2142817024208632, 0.2827452443040468, 0.20824378388854903, 0.1544289120934389, 0.18793223983574114, 0.224544580967578, 0.31427665673554617, 0.16318743725489115, 0.20652876830479028, 0.252494107792515, 0.24361195342076025, 0.20363037670009076, 0.2080700303553915, 0.22279471054739441, 0.2326957108922375, 0.24269072106191514, 0.30047644910938065, 0.19706393767983277, 0.20868202637025202, 0.21043670927677927, 0.18415730579368117, 0.18283181861452757, 0.22162029858701715, 0.18626655007974668, 0.1941894262927355, 0.18641641660065256, 0.2500151475730248, 0.18747651969757761, 0.18695067744592642, 0.5097588756253987, 0.19852447630337589, 0.19787647107904882, 0.14093149254397463, 0.16213196764639648, 0.8563335021041609, 0.47277262768918416, 0.20900035573504316, 0.7239860070390673, 0.5529201463492588, 0.16661958070343297, 0.14249422325161287, 0.19770409562365465, 0.2070364975912714, 0.7894428032172432, 0.1895936082040195, 0.19666805295858636, 0.20374230015997508, 0.19975105099183965, 0.23530547214774933, 0.21399605810149802, 0.18124661971755418, 0.18887969054885734, 0.2114672637010785, 0.07482400260582545, 0.09742770303964787, 0.10820147755318321, 0.07249254335479072, 0.0915620122246723, 0.09782514611122606, 0.0782550959850068, 0.10100656686787768, 0.0894109635557454]}, "mutation_prompt": null}
{"id": "9ba1a62a-6e72-4530-8e60-bcd51ea63137", "solution": "import numpy as np\n\nclass RefinedAdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.4 * np.random.rand()\n        self.c1 = 1.5 + 0.1 * np.random.rand()\n        self.c2 = 1.7 + 0.1 * np.random.rand()\n        self.F = 0.5 + 0.3 * np.random.rand()\n        self.CR = 0.6 + 0.3 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        elite_indices = np.random.choice(self.population_size, size=self.population_size // 5, replace=False)\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust'])\n\n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.07) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.w + 0.07)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.07) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.F + 0.07)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.05 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n            # Elite guidance\n            for i in elite_indices:\n                if self.evaluations >= self.budget:\n                    break\n                elite_vector = self.global_best_position + 0.1 * np.random.randn(self.dim)\n                elite_vector = np.clip(elite_vector, self.lower_bound, self.upper_bound)\n                elite_score = func(elite_vector)\n                self.evaluations += 1\n                if elite_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = elite_score\n                    self.personal_best_positions[i] = elite_vector\n                if elite_score < self.global_best_score:\n                    self.global_best_score = elite_score\n                    self.global_best_position = elite_vector\n\n        return self.global_best_position, self.global_best_score", "name": "RefinedAdaptiveHybridPSODE", "description": "A refined adaptive hybrid algorithm enhancing parameter tuning through dynamic probabilistic mutation, synergy optimization, and elite guidance.", "configspace": "", "generation": 91, "fitness": 0.3220143468537414, "feedback": "The algorithm RefinedAdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.26.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.7737642012978565, 0.7549349342394402, 0.8299435210650228, 0.8312952154230938, 0.7266557768430665, 0.8154238539898963, 0.8191626995322374, 0.7498246659771652, 0.7945321291103788, 0.5562279202322169, 0.27052752032968574, 0.5675889013852552, 0.479481650311657, 0.036875409846843676, 0.49081958453377594, 0.4844965626804568, 0.36220105027076266, 0.4999561735221054, 0.09738251553744193, 0.08153510854830348, 0.14591274802362642, 0.122483802418622, 0.07469729904316924, 0.13567079322439568, 0.10852033993635957, 0.11566524110493648, 0.1446354234729097, 0.06816972509336117, 0.0998502844371687, 0.10724999796012435, 0.10832514349743816, 0.04970461462481812, 0.12749986641320388, 0.06935980144414933, 0.13885173710400467, 0.14168914528526366, 0.9810405221133908, 0.9668143499806601, 0.9813737889206672, 0.9701669362139627, 0.9783295021486044, 0.9589740421080223, 0.9824022500205054, 0.9832970323718301, 0.9807789308456568, 0.5667209747833002, 0.559535321590632, 0.5967140894168366, 0.6076141906371649, 0.44778663690118237, 0.5693105903814011, 0.5621009376631956, 0.527638316977342, 0.6335700506572637, 0.5934582642756739, 0.22483495877336113, 0.817544978533046, 0.8256717073712317, 0.2752369427937653, 0.29231766892986966, 0.7806962431719682, 0.23497194861732318, 0.723600050381737, 0.12456886649808863, 0.09985141299631539, 0.30278496605887983, 0.5163443416415269, 0.28824921702297523, 0.12667172551252603, 0.5196130183355696, 0.1495060489788641, 0.47435906695749386, 0.6199628683325402, 0.1267210788187756, 0.5942371348577611, 0.2504693962301422, 0.30858637423630164, 0.5980136356720773, 0.4844257567866541, 0.11942880398422417, 0.11533455138828486, 0.053674954792841345, 9.999999999998899e-05, 0.0455313520954056, 0.0390895679093648, 0.0075230937172678924, 0.06193680342065311, 0.1710803798861883, 0.06826153856020978, 0.008576340547401973, 0.23343364795627042, 0.1560716321433009, 0.30444875494650736, 0.14234841448439217, 0.20172953720510323, 0.14966824304211168, 0.18206821982634003, 0.2593799846957098, 0.18660979813690814, 0.13892491540489105, 0.0765755085783465, 0.04366821521639597, 0.12563094017964505, 0.19980817402949658, 0.14004722457166152, 0.08945876623107907, 0.1900316016173681, 0.13106274345831093, 0.202291447208915, 0.13864222680297555, 0.21044475127318618, 0.12944983152844303, 0.1812049831774002, 0.22616179917113455, 0.299748135118025, 0.10754061645027868, 0.1484382780643695, 0.5890868542336438, 0.5389301712348741, 0.6953195982995157, 0.6634942374090453, 0.5208184677140221, 0.628687160056967, 0.6564860744475616, 0.5630185593764088, 0.64534514463225, 0.08883095527273821, 0.06413175823219952, 0.11059849514220188, 0.11552374680342836, 0.13368987589715908, 0.14275474160088342, 0.08496090139254941, 0.09369993369106666, 0.08544420596707025, 0.146978528426849, 0.26378127547018704, 0.21502295850579545, 0.24634171357393664, 0.23025150172894016, 0.6059915270869728, 0.4088035327487032, 0.18326696584835922, 0.2745310345522748, 0.38026115097218693, 0.28725117806093736, 0.3238377556684281, 0.20452952385688272, 0.3976593533388123, 0.3578119832370701, 0.38784449516054875, 0.28920580386805217, 0.2824105177512516, 0.23412531768914946, 0.21334530640942317, 0.23389509471428038, 0.20714890926291896, 0.1943925364552801, 0.25177117158684226, 0.1876552355177702, 0.24769803180379557, 0.16487214806993922, 0.2273042407611725, 0.1618170254444654, 0.23159754540944766, 0.25373620552329623, 0.23478798203082074, 0.2650268397715745, 0.2265649577258736, 0.21509507552283735, 0.24053877716284955, 0.2073432731307263, 0.1752900056284954, 0.17188919986515028, 0.18940399939857233, 0.22372322383068022, 0.21773811423930556, 0.2071247642510493, 0.19535613273234598, 0.18720188856577602, 0.8962581486266149, 0.1687312620689545, 0.16748489195201088, 0.17265573868183215, 0.2009364069211118, 0.19966644376357667, 0.1428491275025, 0.1650983017229639, 0.8557411589255913, 0.8720650329205744, 0.20961785249114162, 0.07340019450649671, 0.8267223027107995, 0.7090346348845318, 0.16865792359668963, 0.10475433749602725, 0.10463255870832966, 0.8460644779731228, 0.2023531960271614, 0.21367874026448463, 0.21408623567746832, 0.19248098441289585, 0.19016175727449613, 0.2211060024578848, 0.19862712904777446, 0.22551178343626588, 0.20934892217721157, 0.09611824543728253, 0.09312957162677471, 0.07910860631849481, 0.10857281538525132, 0.08563340733565128, 0.1009760724766906, 0.10158161705561475, 0.10178186326565686, 0.09021922141788641]}, "mutation_prompt": null}
{"id": "9039b562-441e-435a-89b0-bf71173707de", "solution": "import numpy as np\n\nclass EnhancedDynamicPopulationOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.4 + 0.3 * np.random.rand()\n        self.c1 = 1.3 + 0.2 * np.random.rand()\n        self.c2 = 1.9 + 0.2 * np.random.rand()\n        self.F = 0.6 + 0.2 * np.random.rand()\n        self.CR = 0.7 + 0.2 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'CR_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c1 + 0.05)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c2 + 0.05)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.07) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.w + 0.03)\n            elif learning_strategy == 'CR_adjust':\n                self.CR = max(0.4, self.CR - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.CR + 0.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.07 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedDynamicPopulationOptimizer", "description": "Enhanced Dynamic Population-Based Optimization using adaptive parameter adjustments and hybrid strategy integration.", "configspace": "", "generation": 92, "fitness": 0.326136786606278, "feedback": "The algorithm EnhancedDynamicPopulationOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.25.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.8046178009991938, 0.7716833597262426, 0.8027536120606197, 0.7818059560762838, 0.8014872694201824, 0.7766789589292666, 0.7949659362033904, 0.8225264426569076, 0.8037411375053731, 0.5537473660639387, 0.5413523961868354, 0.5215120541354512, 0.47387955082921274, 0.5660753308187391, 0.4903667927962201, 0.23796274880015178, 0.5096653535038899, 0.5073586683451319, 0.13576895718053406, 0.08240803423174381, 0.1124260054863373, 0.1142230680556795, 0.08800771449975742, 0.1698843284224245, 0.1587174822183055, 0.10929876498566282, 0.09660229330302006, 0.1418125430356849, 0.12665838409591812, 0.09013466949370108, 0.118219441515102, 0.08650467819174645, 0.06682982453328457, 0.13703917528202036, 0.1138241612076969, 0.11131232049133377, 0.9804914024581004, 0.9734163129557776, 0.9841517747658034, 0.972953914887349, 0.9764421349737228, 0.9622953926493231, 0.983108913817177, 0.984358912659763, 0.9815057592443808, 0.5035530532748091, 0.4913967050915904, 0.4752923185763305, 0.6030875768047206, 0.5801562288544301, 0.42912228830735244, 0.08088408980493045, 0.25353082884746725, 0.5197911342773709, 0.2234666959008751, 0.22881398503020245, 0.24326080418179363, 0.19323734460195807, 0.8431899891791306, 0.20441649030101194, 0.7447037122098783, 0.6193450182299576, 0.40762003367583455, 0.3845566020194734, 0.11657555089782823, 0.4230974910591715, 0.4410226089695719, 0.405426176606165, 0.36600064439562885, 0.36594079304899496, 0.43771196647874067, 0.4648928258805055, 0.35098312401665777, 0.12465784944363945, 0.40843861340581566, 0.4128282065827511, 0.5269916699923982, 0.337366399000561, 0.33089639492701217, 0.28658173136738374, 0.4387122076066039, 0.09704339663317518, 9.999999999998899e-05, 0.0954420764951659, 0.061749715995613186, 9.999999999998899e-05, 0.24659391232527483, 0.18046393212897804, 0.2801630900722263, 0.0033910185603890364, 0.07519529319954998, 0.03546336261141392, 0.18289315100893888, 0.0182319138645487, 0.28199775525357573, 0.06710320836204087, 0.47536085466228584, 0.25695235135452354, 0.43946185010005623, 0.1452925521957379, 0.031003158894489347, 0.04544421512293628, 0.12217470565734512, 0.12778612311877913, 0.15794598799067494, 0.08382999384130929, 0.08689348405634223, 0.14187651956078684, 0.24909805173625477, 0.28458298777785496, 0.1462681335162639, 0.14810151955015338, 0.36003436673453093, 0.20066578265644286, 0.1683703829764316, 0.08044063398785362, 0.17148780728237578, 0.7243624501233554, 0.6133267406465696, 0.7411395820165813, 0.5986911237203064, 0.6034913562142696, 0.631793022490021, 0.6450111966344352, 0.6280640684641059, 0.6587396830814432, 0.13225766054965116, 0.09144382137040996, 0.1308047478006451, 0.08486606206839187, 0.12680711024960145, 0.6053037765991007, 0.09845876940422116, 0.10179437544388514, 0.12768917692730652, 0.188067453010191, 0.20461699254376486, 0.17487414648660127, 0.33307010993022634, 0.2797409179749193, 0.21624657919733759, 0.2626768342603425, 0.22573098821246718, 0.1647849338773444, 0.30251988875237823, 0.339769495617645, 0.3126459542468031, 0.3341535836524152, 0.26082296917474357, 0.23994795375472278, 0.4752315451380994, 0.4346983484339926, 0.40521641271111275, 0.31506921790204756, 0.2107296814773283, 0.20213268909956583, 0.23573156613282598, 0.18869372964144182, 0.3711039153440443, 0.2360682411824372, 0.25404433967784246, 0.16271922154594753, 0.21907560189750996, 0.2278837081014783, 0.2109470380048153, 0.23219481301802858, 0.24651757686845222, 0.20189978000733821, 0.2284526999573292, 0.21489932599250117, 0.21436004361165328, 0.18392716890739436, 0.19502399465450604, 0.2085656868608009, 0.20405780657067674, 0.22126285722957495, 0.1915029582410307, 0.17837615339565926, 0.17681955994229215, 0.1892794262096933, 0.831762757022428, 0.18748898791038504, 0.1667276615778719, 0.8444609602430633, 0.19912465673157753, 0.1979428015076079, 0.1416574781250527, 0.16056067510206617, 0.8613587908403958, 0.808859540159412, 0.2080680378610099, 0.20324888263792962, 0.7732252053892894, 0.1669166258166046, 0.15365921311620456, 0.2041450818380608, 0.20949171356943275, 0.819525761362182, 0.20483763208731576, 0.20699552411369737, 0.2153747111802996, 0.25057339950894686, 0.20283506409824315, 0.18833077334111137, 0.2189654938951997, 0.18690340479103318, 0.19605548694568486, 0.08409000310674442, 0.07027084365209069, 0.09414639342976916, 0.10614898617401647, 0.08539341413832169, 0.0756891621023904, 0.09321699275361783, 0.0996402458670107, 0.07052537087511423]}, "mutation_prompt": null}
{"id": "221ca6a4-ef10-4dbc-9811-398f38aa71a6", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.4 * np.random.rand()\n        self.c1 = 1.5 + 0.1 * np.random.rand()\n        self.c2 = 1.7 + 0.1 * np.random.rand()\n        self.F = 0.5 + 0.3 * np.random.rand()\n        self.CR = 0.6 + 0.3 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        exploration_exploitation_factor = np.random.rand()\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if self.global_best_score < np.median(self.personal_best_scores):\n                self.c1 = max(0.5, self.c1 - 0.1)\n                self.c2 = max(0.5, self.c2 - 0.1)\n                self.w = max(0.3, self.w - 0.07)\n            else:\n                self.c1 = min(2.5, self.c1 + 0.1)\n                self.c2 = min(2.5, self.c2 + 0.1)\n                self.w = min(1.0, self.w + 0.07)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.05 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n            if np.random.rand() < 0.2:\n                exploration_exploitation_factor = np.random.rand()\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "A refined adaptive hybrid algorithm improving parameter tuning through probabilistic mutation, synergy optimization, and dynamic exploration-exploitation balancing.", "configspace": "", "generation": 93, "fitness": 0.2579495621217631, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.25.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.8497125980990362, 0.8523196269786233, 0.8507020768879248, 0.8522320355675531, 0.8648697354858201, 0.8357651917761207, 0.8617450110888005, 0.85417871093944, 0.831836931651592, 0.05059583586308802, 0.05661389062435285, 9.999999999998899e-05, 0.037240757516436185, 0.06148633222194333, 9.999999999998899e-05, 0.020517748569320204, 0.13977109611730354, 9.999999999998899e-05, 0.08800261969513068, 0.15347633279921413, 0.11832506693747014, 0.14081078734900299, 0.06906147275896324, 0.10798567906742451, 0.14058884163971852, 0.12273800600600204, 0.12905474727725164, 0.11196498422207146, 0.12194783697095157, 0.10416650861601962, 0.09682755642790253, 0.09192870768425687, 0.08093103594120277, 0.152518717276112, 0.13859900301226624, 0.0833798317305553, 0.9782012670647895, 0.9502879905230252, 0.9936840372882328, 0.9307695306988899, 0.9614501159332622, 0.9381189822948884, 0.9729245807321593, 0.9830932376245761, 0.979366016786549, 0.33809054779277325, 0.2818144932682083, 0.07864209976911096, 0.23492413142473956, 0.4229670902923254, 0.37874411276109143, 0.11056354868914642, 0.09265876983797117, 0.33227635477216233, 0.35477882110323244, 0.30053759581225437, 0.38807268784163085, 0.279561918701839, 0.1903769253757862, 0.7506260131795246, 0.13034040766532562, 0.8771450183984134, 0.1825900876975416, 0.13276314614871831, 0.12332318759799998, 0.1413495243989944, 0.13687590092182778, 0.1399106986292965, 9.999999999998899e-05, 0.1371540267818182, 0.1547818950402443, 0.15287045956662293, 0.1712611744569016, 0.2563662615396486, 0.12182082396912286, 0.15143902886983562, 0.1443897484708616, 0.15830476782051084, 0.144119915346282, 0.16352706874949785, 0.14804478481051664, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.010202917978896275, 9.999999999998899e-05, 0.024838385544257435, 0.007552781301869427, 9.999999999998899e-05, 9.999999999998899e-05, 0.10220734900421646, 0.06572359922834803, 0.05782593080348197, 0.0640960336176295, 0.07999948157026915, 0.03792640242904033, 0.06771964308410827, 0.08098169669854838, 0.07899042051949035, 0.09769977296839494, 0.08910426657944337, 0.0970176001996369, 0.1526551080981715, 0.0870734918650512, 0.08920942130145615, 0.09081831169926502, 0.0868951212423621, 0.09499830301825019, 0.09353506509295073, 0.2961987505969129, 0.21367436022260478, 0.15454971200583445, 0.10132193062020944, 0.06008573450689403, 0.07832398167318277, 0.05593441132293209, 0.10574188819297903, 0.44456037071252574, 0.49771833649713115, 0.4577392443248556, 0.5513042400115243, 0.5532914798597801, 0.4763985392231449, 0.5446852742752861, 0.42833334135691814, 0.398858737550601, 0.15347458239528966, 0.04631083821436155, 0.09139441157169381, 0.1369548504331196, 0.08981952360920187, 0.09598658552585826, 0.09925774350342087, 0.08150984874891853, 0.10915783527930256, 0.1669879282038388, 0.1975178128993028, 0.3959584677386889, 0.2649951826918209, 0.4482499014786928, 0.19869379261377684, 0.318877083885161, 0.3004845541789486, 0.20365993295120965, 0.3606237623631239, 0.41114198445359873, 0.401592103873906, 0.22660908401212287, 0.3135258839945715, 0.5301160043639092, 0.2872288584553264, 0.43827407727601897, 0.21491380218843903, 0.17809521350748891, 0.23076781318035622, 0.32928519272108225, 0.225823407261193, 0.3293522314034253, 0.35047227657421887, 0.25057822276378894, 0.2980453194953929, 0.16325624627322344, 0.23189959463160126, 0.2005882720007306, 0.22180140536246662, 0.30644292078893953, 0.16940450826940034, 0.20753749077429606, 0.23017615210667142, 0.22461474272033388, 0.25286255490983156, 0.17558413437248455, 0.18113926347707987, 0.1746556397897877, 0.17926200777166323, 0.19582064223945872, 0.2228921177087707, 0.1809741577915791, 0.17271377297403145, 0.19326151103838352, 0.8990596696050757, 0.18760851413000523, 0.18687734837695613, 0.7896011701535607, 0.2002996885063828, 0.5770985319863045, 0.14192735115939759, 0.15442899315795255, 0.899174445559446, 0.41811584057342166, 0.2116923154864786, 0.07355742929230236, 0.6225510612864542, 0.16639944622007186, 0.27336656448148555, 0.1041842945690099, 0.10485770936087468, 0.2801785447355487, 0.18691574614433437, 0.2133106556729668, 0.20322955529047226, 0.18922041699443604, 0.19630793906416588, 0.17814882059210635, 0.1807152852535333, 0.19687991927060589, 0.23050192772793654, 0.14091003506997968, 0.10421837722261373, 0.07625025769791371, 0.08891781521895703, 0.08176276351245837, 0.10575790571303878, 0.09650184801979578, 0.07559458567147082, 0.08076384866653641]}, "mutation_prompt": null}
{"id": "f4cefe30-9555-44cf-8bd3-26393ac9d19b", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.4 * np.random.rand()\n        self.c1 = 1.5 + 0.1 * np.random.rand()\n        self.c2 = 1.7 + 0.1 * np.random.rand()\n        self.F = 0.5 + 0.3 * np.random.rand()\n        self.CR = 0.6 + 0.3 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust', 'competitive_learning'])\n\n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.07) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.w + 0.07)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.07) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.F + 0.07)\n            elif learning_strategy == 'competitive_learning':\n                self.CR = 0.9 if self.global_best_score < np.median(self.personal_best_scores) else 0.5\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.05 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedAdaptiveHybridMetaheuristic", "description": "An enhanced adaptive hybrid metaheuristic algorithm that refines particle movement and mutation strategies through probabilistic and competitive learning mechanisms.", "configspace": "", "generation": 94, "fitness": 0.331815287325254, "feedback": "The algorithm EnhancedAdaptiveHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.27.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.6461620715601748, 0.8140038684614535, 0.8022257739253773, 0.653523117799059, 0.8324033018839588, 0.8184184473952807, 0.6406032312853991, 0.7993198247980557, 0.830823275729308, 0.2103452751151943, 0.5184018813252469, 0.5279612888639034, 0.051786695790356996, 0.5572764850684835, 0.5971402525569998, 0.16255537636037842, 0.6036054724537274, 0.5777604494417663, 0.09892852988016676, 0.16069576018193965, 0.10515671117543535, 0.13005967653217543, 0.09192719214687983, 0.1425447726839265, 0.12273512331905223, 0.17729713437732175, 0.17310659748063395, 0.0860930251021026, 0.09501007898284675, 0.11556753927066055, 0.10225372865059634, 0.11992227730625749, 0.06977562895438627, 0.1038704638708483, 0.10642740296674769, 0.10583141808703855, 0.9831314291426827, 0.9734682035510478, 0.9831630328586503, 0.942228324258133, 0.9601656476954725, 0.971776196486502, 0.9728085848755749, 0.983443976067325, 0.9811028069051303, 0.39041886089373334, 0.614958936450563, 0.4824813399814424, 0.4082213949918925, 0.5183423735427716, 0.5346874091244398, 0.35641295445377086, 0.5316056605031527, 0.6198740205272831, 0.20848433549655243, 0.8557464882562138, 0.8446962081234877, 0.21362229868975569, 0.2810286150847312, 0.1913246094761576, 0.5628399167732512, 0.6776111362077089, 0.8719809217760112, 0.12271900755528042, 0.31279641905649236, 0.47363532809451603, 0.12663740985359984, 0.539224002824372, 0.12711836465863946, 0.42218082754369024, 0.11781103706516582, 0.6525585029934937, 0.21092932334199122, 0.3660624169126805, 0.1188628285326302, 0.24128669745045894, 0.12933944798105035, 0.48349381480266684, 0.3429096698983921, 0.5541865179356009, 0.11907540124143434, 0.1440640040825254, 0.024079189879376628, 0.09212644549063753, 0.03069828430018806, 9.999999999998899e-05, 0.005024103388300505, 0.07171049312572597, 0.007373356997960934, 0.0026853220055943483, 0.18633748499890412, 0.1308639359296876, 0.46188650429223466, 0.13683346434721333, 0.5982511478303985, 0.03206544678347767, 0.18859751663051516, 0.5997715183888047, 0.11162797799787183, 0.03447556393140816, 0.044269065988996936, 0.15943434761834907, 0.0969459986856196, 0.14205801688972008, 0.12922879311079782, 0.07310062973775278, 0.18127337626507045, 0.1794162716723957, 0.12730540537773505, 0.2321537829251844, 0.29425573727289767, 0.034889589808203114, 0.3423943177781099, 0.23154344838536112, 0.04843952786878525, 0.18065191530753177, 0.08151877538681807, 0.5441553569714204, 0.6132230275235317, 0.6669008482285673, 0.4244045872427171, 0.733932648379362, 0.6294404296832777, 0.5424603729594886, 0.7230082514781024, 0.6984237425627087, 0.11673554895455651, 0.08881094588975247, 0.07489263512343991, 0.13493916210811785, 0.08836200734603095, 0.12225722795775129, 0.13492336140849093, 0.17460663486795802, 0.08859689389089775, 0.1336037512321656, 0.7083661646768167, 0.679394607007183, 0.3941682788584965, 0.2734692359524077, 0.19337794445184608, 0.34714865067679457, 0.20849869612062322, 0.2734010044148508, 0.2909218490254353, 0.2043214517281865, 0.32112002384333416, 0.2883564468823484, 0.2688027628787678, 0.4527012119688615, 0.3169477072668857, 0.5569097490227879, 0.39121527241146914, 0.23324597557526427, 0.22356063774126156, 0.2424773204892876, 0.29734242112904596, 0.3161752085456172, 0.23883091560840775, 0.20432035234519408, 0.28942986971381335, 0.20623173049025045, 0.21222362512296966, 0.24251611653712013, 0.18695497620300017, 0.2754064468733355, 0.20977652042202155, 0.20193733614336074, 0.23332129345220443, 0.2552777578669372, 0.23321653550495047, 0.21809900245075686, 0.18592830997678622, 0.20312396905309782, 0.21773236858156308, 0.20386937699080754, 0.19629315268625358, 0.20167158551222564, 0.19555692176465977, 0.1787509790462729, 0.8237608091830645, 0.18808835825677095, 0.16785018580905475, 0.8444163540362736, 0.19930799163486668, 0.1690720345305654, 0.8082684394186419, 0.16210971051557066, 0.8983968451429901, 0.8298328857046797, 0.21101552451555516, 0.843832488821923, 0.2047851575431079, 0.8290098761366081, 0.15490699558431276, 0.20144336304983312, 0.10464825917080611, 0.8008128264896168, 0.20161077201137012, 0.227402232500599, 0.17840106690919433, 0.2094331427506494, 0.18753698498046445, 0.20520523876643992, 0.18805681241547167, 0.18463251153125004, 0.25451715914969175, 0.08474853979459518, 0.09584212818905946, 0.09172850776109787, 0.0909782170511213, 0.10068981796032461, 0.0958334016062592, 0.09155073928353519, 0.08053439922157068, 0.09035047680715236]}, "mutation_prompt": null}
{"id": "2702c76f-7b56-4609-a469-78f375d15a4d", "solution": "import numpy as np\n\nclass ProbabilisticAdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.2 + 0.5 * np.random.rand()\n        self.c1 = 1.4 + 0.2 * np.random.rand()\n        self.c2 = 1.8 + 0.2 * np.random.rand()\n        self.F = 0.5 + 0.4 * np.random.rand()\n        self.CR = 0.7 + 0.2 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust', 'CR_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.12) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c1 + 0.12)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.12) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c2 + 0.12)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.08) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.w + 0.08)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.08) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.F + 0.08)\n            elif learning_strategy == 'CR_adjust':\n                self.CR = max(0.5, self.CR - 0.08) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.CR + 0.08)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.05 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "ProbabilisticAdaptiveHybridPSODE", "description": "A probabilistic adaptive hybrid PSO and DE algorithm with enhanced dynamic tuning and adaptive learning strategies to explore diverse search spaces efficiently.", "configspace": "", "generation": 95, "fitness": 0.30886558474466463, "feedback": "The algorithm ProbabilisticAdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.25.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.6709459140770081, 0.8021496903665679, 0.802750732998515, 0.6194818747343522, 0.8211632348965532, 0.82142120859829, 0.7063552656699746, 0.8185607845231538, 0.7926730244290475, 0.2962838171778158, 0.5778422603298686, 0.5318202396741749, 0.2889962002278793, 0.5944045328798284, 0.5125059928705495, 0.3410054049160548, 0.5511362857122291, 0.05206860995882523, 0.0955704782129485, 0.09194764946717404, 0.10877319544433517, 0.12183103022372999, 0.10379489611903048, 0.16078988803754912, 0.15968261520541727, 0.1412730220849695, 0.1217103210479632, 0.10756703005937762, 0.10443739587531797, 0.06749671392307244, 0.13266396701057115, 0.1105704597327507, 0.07635996428985325, 0.09345009422061668, 0.11331722015748213, 0.07131797970008413, 0.9818861429985571, 0.9732628517366395, 0.983548301832435, 0.9689354830501864, 0.9764733371462472, 0.9622887803215463, 0.9729194518552117, 0.9844277691240318, 0.9810796904803671, 0.45789426292051094, 0.596347766313007, 0.6061066658473339, 0.3000493522805794, 0.4373075798592825, 0.5943724891311005, 0.41166855182192685, 0.604018425567195, 0.5686485777009918, 0.7609344209181585, 0.49067301583145295, 0.22188586732351023, 0.2628608880349267, 0.19277942929311898, 0.19553652323264115, 0.19490899400217454, 0.8277467878913501, 0.5775893066205957, 0.12201770074802731, 0.13083601518575705, 0.33387315532496886, 0.10456462141330014, 0.3809875015314841, 0.45300701401093046, 0.29391907358492997, 0.44393406580613115, 0.5776967237153583, 0.40460398745986736, 0.25443424814392446, 0.2729652323652988, 0.12847018286961642, 0.3952572756388165, 0.22064343377581175, 0.3063641815225473, 0.49925163965671904, 0.11208465937333767, 0.15007081337595007, 9.999999999998899e-05, 0.031920258546649705, 0.031403993327275614, 9.999999999998899e-05, 0.14920958805070428, 0.00317421946236518, 0.00567934107858914, 0.0030674443432971987, 0.07020316437455132, 0.12031589376355112, 0.2892662235026081, 0.05442965508516595, 0.19567741232266367, 0.11325708202559359, 0.1363217453340485, 0.3143872118873555, 0.20134690935028532, 0.037103502607412686, 0.04957864316893623, 0.12993342713707567, 0.11044415260657514, 0.13994960380598132, 0.09817114127638416, 0.07471272326427647, 0.08616993526817462, 0.13558168397178083, 0.11750781396658638, 0.041647263788387456, 0.28966296474880127, 0.17097265681375107, 0.2859336976370025, 0.16742152973949465, 0.044885342977614706, 0.05412647094561651, 0.09025313340643648, 0.5037759795199294, 0.6822177737916151, 0.6341237015449124, 0.5235655762750819, 0.6638402281421155, 0.6349773144632758, 0.5039387795201502, 0.7088447736588047, 0.5926806657030861, 0.13782812678927325, 0.11020829913246266, 0.07104298689482746, 0.17154039531774867, 0.10957683542626051, 0.11541827168066066, 0.09940158292469514, 0.12538733522599887, 0.08889642507521511, 0.23984256709833573, 0.18932010918226372, 0.18064416182568244, 0.5047573015413382, 0.22548324267284892, 0.2623981107047534, 0.3777290588333564, 0.27563371661604474, 0.21279751234184718, 0.38886100450361394, 0.34536810081995295, 0.3758734578148293, 0.3993823008120364, 0.2644024107665377, 0.37103826540861384, 0.3732187053649414, 0.4018722572496213, 0.35963723865847363, 0.217110507427427, 0.17578338330772691, 0.2417954809466144, 0.23260203976994465, 0.21318942723452916, 0.24556866716324732, 0.31047975410469264, 0.28445095748515936, 0.2022651910850214, 0.20901552577307692, 0.2220658089880191, 0.19087871634805564, 0.2183593388654962, 0.23968969229337977, 0.26639737014768894, 0.20744955918290398, 0.24084026284043525, 0.2565552915086642, 0.185761557078594, 0.17708142758912948, 0.19009441902203617, 0.19039852959310266, 0.19319301171652226, 0.20562989375484886, 0.22306505984990876, 0.20649044083426082, 0.20194871026880146, 0.8590342980596911, 0.18790562022845658, 0.16807893859746748, 0.8489729912131907, 0.1998333088183587, 0.16812615216772087, 0.14200397617139338, 0.16055834256671953, 0.89348587326627, 0.7531684326300699, 0.20957423808118902, 0.07339465419049607, 0.5969635937106859, 0.1663370365591873, 0.14864682468382218, 0.10397442392813938, 0.16374687177429736, 0.8556113294918815, 0.1926956744291175, 0.21110299715330816, 0.19227782192085197, 0.20862773371011512, 0.19842402269204862, 0.21577075905991638, 0.20940148058517505, 0.2147513074566133, 0.24212104987096483, 0.11403061583486995, 0.08474789515157266, 0.09677894096101314, 0.10039047943509738, 0.10028231497766793, 0.10476118080107932, 0.09348745165426187, 0.08877167718951573, 0.0742743352690639]}, "mutation_prompt": null}
{"id": "a173d9bb-1b03-4271-9f17-9cf95c904afb", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.4 + 0.3 * np.random.rand()\n        self.c1 = 1.6 + 0.2 * np.random.rand()\n        self.c2 = 1.8 + 0.2 * np.random.rand()\n        self.F = 0.5 + 0.4 * np.random.rand()\n        self.CR = 0.7 + 0.2 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.6, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.6, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.6, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.6, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.08) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.w + 0.08)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.3, self.F - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.F + 0.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.08 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedAdaptiveHybridPSODE", "description": "A refined adaptive hybrid algorithm with dynamic parameter adjustment and probabilistic mutation to enhance exploration and exploitation balance.", "configspace": "", "generation": 96, "fitness": 0.32324837665409234, "feedback": "The algorithm EnhancedAdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.26.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.7830084929809069, 0.7945460840251193, 0.7779022675098518, 0.8129922610232343, 0.8150131219299976, 0.8095823928003565, 0.7973750670600702, 0.8014910112910746, 0.7994978833873452, 0.20978347248701734, 0.5457907872240423, 0.5522479457271672, 0.5225474250356783, 0.5003949751985918, 0.5529362194761511, 0.4504380677519143, 0.48545188952889196, 0.5371747647923656, 0.1137165497412338, 0.08877293122080099, 0.1595277511179224, 0.12848477421413995, 0.10899311397175881, 0.12726040462047128, 0.1239355842220029, 0.16818509763912337, 0.0660883456984368, 0.09452837626519617, 0.0981834961815754, 0.12052178603220876, 0.10902638876634885, 0.10511561359096722, 0.09827326196536501, 0.12925846450715472, 0.1051993548247947, 0.08433971792393569, 0.9803839390327183, 0.9733789027074872, 0.9837601946373017, 0.9728162965475609, 0.9764392851114623, 0.9717603637504253, 0.9735604840649483, 0.9844901885486397, 0.9811835944464219, 0.5118077841566173, 0.5936761427674766, 0.4876724415968029, 0.46682817259770726, 0.556104367997647, 0.5619240255188243, 0.11886749810797304, 0.2631919711469163, 0.5605577797564532, 0.8587206634637632, 0.22845386427593883, 0.20994623994254502, 0.2701206965958092, 0.8217956894126199, 0.18906163617983918, 0.16846953129653952, 0.30145277090678424, 0.37422778324840233, 0.12228237925492957, 0.36105819497627634, 0.12075929213758552, 0.3274391584198384, 0.423085461483823, 0.5608453416259187, 0.4231688455928384, 0.376453937484199, 0.43236433675671293, 0.2869876945115709, 0.4620455790293211, 0.1173852420506899, 0.6305830237369175, 0.1203244009203972, 0.297080754569349, 0.3077115427431434, 0.12986617847025517, 0.09913000725419863, 0.050588936173751264, 9.999999999998899e-05, 0.08094336867240659, 0.03439998032960523, 0.06710224213273741, 0.041623289461792945, 0.10231232805788892, 0.007047709357474563, 0.19513109579176846, 0.22009004302704893, 0.317386989268718, 0.43253278305392073, 0.06612121133309468, 0.09079321995751488, 0.30647201038418104, 0.12178517099304986, 0.3406156728155394, 0.5233760202089519, 0.0451741751595468, 0.04767031113112863, 0.042630570948690716, 0.14989429953348277, 0.16917598217146956, 0.0785216295413822, 0.08618661136849337, 0.09171411677938957, 0.19754779283510882, 0.24046515470456653, 0.042291553456685116, 0.15390346151686285, 0.3607410129822448, 0.1864865957274151, 0.2218225626970911, 0.3182429537242064, 0.19209714211120876, 0.20484181204938823, 0.6608263239795087, 0.6924597290970644, 0.5896469012440066, 0.6476615860432987, 0.6184833172469426, 0.6451846473177356, 0.7626214251944532, 0.6300445484198036, 0.649175400895118, 0.14252529450819162, 0.12528978036037153, 0.0930560719278547, 0.11512342837367928, 0.09314369580266357, 0.1044616491597049, 0.07689482323470109, 0.10060825514081517, 0.13909601958759632, 0.3277512311543861, 0.19766381279452794, 0.2180795091108615, 0.19969465369093964, 0.3267771012669104, 0.2122536593891967, 0.19394474621071234, 0.28879866478272287, 0.1665341652602974, 0.30626180015341586, 0.2910786057512502, 0.2357858088181527, 0.3847505091700467, 0.46244230344311765, 0.2837163892976938, 0.44850820928300295, 0.4073400380451835, 0.47021385438036833, 0.28863619090658044, 0.19803721791990736, 0.2403432276345655, 0.24761433008853606, 0.22536303381635858, 0.32113271293387147, 0.4132312419256161, 0.2778340127164335, 0.22002538324979215, 0.21163996105604987, 0.22451353101999538, 0.19672901046718294, 0.2426523910654711, 0.18424656012038232, 0.256408861636924, 0.20357321507624004, 0.2351050860217362, 0.27058462501093006, 0.19705265679475492, 0.18038489593663565, 0.1760132722137676, 0.18645959933207967, 0.561863577180213, 0.20132879908241152, 0.19497932453022715, 0.18974645421986747, 0.21631583696493595, 0.8651853137098783, 0.18696272430973748, 0.16689335165906483, 0.8119944935300875, 0.199513080490346, 0.860322046990381, 0.14120840275920166, 0.16162257645954292, 0.9001539852344063, 0.8296321739346091, 0.20851626721680727, 0.16222984237284654, 0.20471665527080718, 0.16620266920877513, 0.15420223513456732, 0.19577495796286082, 0.2025367440632071, 0.5355773613400616, 0.1991211614484628, 0.2033670989539368, 0.194310123800709, 0.19109428265820827, 0.2000967065283744, 0.22299748017293208, 0.19405813451985965, 0.1728241317524447, 0.21877059371555474, 0.09403609523629874, 0.07917198605552733, 0.10109125302468458, 0.09850849624865754, 0.09186136528659938, 0.08876025208908034, 0.1142453134572865, 0.10524596212440485, 0.08449244008137324]}, "mutation_prompt": null}
{"id": "a3bedbe2-e6f5-477a-9041-225a01cca04c", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.4 + 0.3 * np.random.rand()\n        self.c1 = 1.4 + 0.2 * np.random.rand()\n        self.c2 = 1.8 + 0.2 * np.random.rand()\n        self.F = 0.6 + 0.2 * np.random.rand()\n        self.CR = 0.7 + 0.2 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategy = np.random.choice(['c1_adjust', 'c2_adjust', 'w_adjust', 'CR_adjust'])\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c1 + 0.05)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c2 + 0.05)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.w + 0.05)\n            elif learning_strategy == 'CR_adjust':\n                self.CR = max(0.4, self.CR - 0.05) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.CR + 0.05)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = self.F + (0.05 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedAdaptiveHybridPSODE", "description": "Enhanced adaptive hybrid PSODE with probabilistic mutation control and dynamic parameter synergy.", "configspace": "", "generation": 97, "fitness": 0.32477955291132415, "feedback": "The algorithm EnhancedAdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.26.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.7929719891781225, 0.7667659646514244, 0.8241101686742471, 0.7805375055447261, 0.8162555099644231, 0.8195614170910192, 0.7865185448415519, 0.7996881395558104, 0.8024402939294625, 0.5114928237445667, 0.5907893816501385, 0.47202018041022753, 0.5300555496170202, 0.5435784686326723, 0.5262169618185042, 0.4359728971117909, 0.5362786133669468, 0.4987352390594375, 0.0999373282174012, 0.07860631050359224, 0.12746918709034072, 0.11407160905674463, 0.11923783232420593, 0.08838417959565381, 0.131948843326389, 0.13353875670369308, 0.08106561793048406, 0.07889804013138602, 0.07230355367936259, 0.10642439572475637, 0.09286351546976146, 0.0880068084966863, 0.09705061092705869, 0.10964024296797836, 0.07920115077516843, 0.0990822470296685, 0.9803951635096461, 0.9734772738285751, 0.9838244382957062, 0.9728432784479727, 0.9764563454481694, 0.9630039649068896, 0.9740552844769145, 0.9845451205649334, 0.9814390398183841, 0.5059183693224585, 0.5509356837787285, 0.4463077055231339, 0.5336542520646668, 0.4297031116617217, 0.5957094515652608, 0.49320250229902085, 0.12626543670132329, 0.37391685306502365, 0.7632890060355367, 0.8441078239323421, 0.22282240800035547, 0.2679777317219181, 0.1925672345748649, 0.2666598521477418, 0.743115301742068, 0.20580908025014955, 0.231935360692604, 0.25862942745588957, 0.26374905477083055, 0.5097907394206623, 0.113913129407196, 0.5257580375633361, 0.11296541089932888, 0.4139201214438797, 0.5321770322775563, 0.451761972870487, 0.5047762092497953, 0.6211034570392611, 0.12129016402466264, 0.43573617836605727, 0.45372579383034195, 0.3441919415200758, 0.30198139942347046, 0.546499065625988, 0.12336184812263562, 0.16945434009817584, 0.03724147005175504, 0.055646767744910175, 0.035609568535015734, 9.999999999998899e-05, 0.1599325205258214, 0.18004275379399204, 0.16756433315341512, 0.05339538511174069, 0.2628377487398751, 0.36680034169158937, 0.18648233309267015, 0.12990703553544258, 0.11585342599151571, 0.025200556114505557, 0.15844029108058366, 0.23544686650910074, 0.05495831664097073, 0.2254334981879691, 0.058107320332432155, 0.04410013698146653, 0.13712061978549717, 0.12017576530031349, 0.11823642423584535, 0.08765631696900178, 0.09057102297121944, 0.18057246062193577, 0.18627864521954052, 0.04181015631616314, 0.32097905717970265, 0.2913093939161665, 0.2398588184825613, 0.2422202095882139, 0.047708773713309394, 0.05641697037451798, 0.19551688472793494, 0.6527380076987224, 0.713678110937725, 0.6861890452842879, 0.5852220974467875, 0.5983009638417438, 0.20696872147245926, 0.6721612882759213, 0.6380231287575886, 0.6487386872580715, 0.07062309397494315, 0.11348410538755993, 0.07059554383157629, 0.0888936595338331, 0.13717863251756168, 0.10524601448926185, 0.0946360541153799, 0.14883200962380894, 0.11110523781975934, 0.3210042320863531, 0.22598943900025026, 0.1759952786186163, 0.22893326639846234, 0.39294468167304697, 0.19345729869183692, 0.19012491143818055, 0.4815971505867639, 0.23628297780873375, 0.28478492408605927, 0.3006165568807131, 0.23946232000724688, 0.2445084421554371, 0.2526458137526313, 0.2567258461702959, 0.3948105694779728, 0.419733429898422, 0.31708012225834414, 0.36691594464375554, 0.21215864658195605, 0.27477904094076444, 0.38347848478198887, 0.17758057942397898, 0.3833659707309506, 0.3025623451918058, 0.2841623166815852, 0.22793152513505932, 0.23928488351407928, 0.1997372212568127, 0.20693453261749706, 0.23464236548823514, 0.20057884388603764, 0.2329341201561863, 0.18559219187351628, 0.2449826738905887, 0.21674235636669215, 0.17747081078878546, 0.19722461527494406, 0.17886835662873057, 0.2417344528875821, 0.22083810406574533, 0.18415666726591773, 0.18674042128434265, 0.22123550259453206, 0.20692739103342417, 0.848158616551278, 0.1874913650474498, 0.1673749793187519, 0.8472955107251774, 0.19842401056953973, 0.19697756670951072, 0.1415306379056518, 0.16268290154953813, 0.8901219434665552, 0.8589120940955356, 0.20816948767300514, 0.2043986058964795, 0.7301466230761094, 0.6563500738580694, 0.14975883861117267, 0.20489452913527595, 0.19876060106257698, 0.8209316053960805, 0.19966132042633467, 0.21557534781646226, 0.22369525198829532, 0.19289279962326256, 0.19975426225151605, 0.18877711507172157, 0.19758177051336512, 0.2198258175657477, 0.18991584448820753, 0.09829721327563201, 0.10098422778913463, 0.09493357622051934, 0.09789926574229046, 0.09244980959357307, 0.09125906770855363, 0.09388606752612672, 0.08602802293505452, 0.07774016362575809]}, "mutation_prompt": null}
{"id": "5aaa025e-fd14-413d-a0b3-a54eaf4bddb2", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.3 + 0.4 * np.random.rand()\n        self.c1 = 1.5 + 0.1 * np.random.rand()\n        self.c2 = 1.7 + 0.1 * np.random.rand()\n        self.F = 0.5 + 0.3 * np.random.rand()\n        self.CR = 0.6 + 0.3 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        learning_strategies = ['c1_adjust', 'c2_adjust', 'w_adjust', 'F_adjust']\n        \n        while self.evaluations < self.budget:\n            for i, solution in enumerate(self.population):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(solution)\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = solution\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = solution\n\n            learning_strategy = np.random.choice(learning_strategies)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if learning_strategy == 'c1_adjust':\n                self.c1 = max(0.5, self.c1 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c1 + 0.1)\n            elif learning_strategy == 'c2_adjust':\n                self.c2 = max(0.5, self.c2 - 0.1) if self.global_best_score < np.median(self.personal_best_scores) else min(2.5, self.c2 + 0.1)\n            elif learning_strategy == 'w_adjust':\n                self.w = max(0.3, self.w - 0.07) if self.global_best_score < np.median(self.personal_best_scores) else min(1.0, self.w + 0.07)\n            elif learning_strategy == 'F_adjust':\n                self.F = max(0.4, self.F - 0.07) if self.global_best_score < np.median(self.personal_best_scores) else min(0.9, self.F + 0.07)\n\n            dynamic_neigh_size = np.random.randint(3, 6)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                indices = np.random.choice(indices, dynamic_neigh_size, replace=False)\n                a, b, c = indices[:3]\n                mutation_factor = self.F + (0.05 * np.random.randn())\n                mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                self.evaluations += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedAdaptiveHybridPSODE", "description": "An enhanced hybrid PSO-DE algorithm introducing adaptive learning rates and dynamic neighborhood adjustments to optimize convergence and solution accuracy.", "configspace": "", "generation": 98, "fitness": 0.2812075845350766, "feedback": "The algorithm EnhancedAdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.26.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.8232918955190187, 0.8169089836387333, 0.8405118988380842, 0.8250500586503409, 0.8226443770514212, 0.8308189376497097, 0.8338374212376456, 0.8174452544768692, 0.8306368690910471, 0.6007835935521739, 0.060536408772046135, 0.20127140520215303, 0.6048339319378766, 0.12247096472077923, 0.11032546791688658, 0.04267186243362142, 0.21347360242723112, 0.12012519480388728, 0.1196124434832656, 0.11809092307115265, 0.12373355833990407, 0.13183970350951424, 0.13411532913953306, 0.07894961883248885, 0.13824522673579653, 0.11187902251019333, 0.17115766859260295, 0.07285817120987381, 0.08582586966751338, 0.0788383859719679, 0.11462387833703747, 0.1028631361932617, 0.09240235760400772, 0.11974595775221064, 0.103547344730752, 0.10796756194620816, 0.973251987761487, 0.9734277465495405, 0.9830996536467959, 0.9713304857235049, 0.9519331216468658, 0.9524792871074755, 0.9814800638275595, 0.9834445959573257, 0.9825015865736202, 0.6181449247554436, 0.6257570222063282, 0.10934134328878098, 0.5798034557058298, 0.30246580312833315, 0.36974720487666624, 0.12861706659061944, 0.5641892174615548, 0.7016071542254352, 0.4212888539963595, 0.8077253051651576, 0.22054083836965777, 0.22660507133887353, 0.28607417907924815, 0.1911311783940184, 0.873274734262701, 0.1558138858072451, 0.38242594347602166, 0.12618901015129325, 0.20052951902267946, 0.10287179159796067, 0.15462992175711954, 0.48630799500386623, 0.1545055319115809, 0.11831972799775681, 0.20618073026283446, 0.17213384734501502, 0.21170410649498805, 0.17432149816598308, 0.1789113254880209, 0.17963430870072739, 0.17536874151700044, 0.1708980586454405, 0.1274439786489231, 0.2015446216185316, 0.09327858155052637, 9.999999999998899e-05, 9.999999999998899e-05, 0.007758729310659684, 0.05257918023822672, 9.999999999998899e-05, 9.999999999998899e-05, 0.13639503877317438, 0.007088674662177663, 9.999999999998899e-05, 0.16109323835484124, 0.14567948881878712, 0.20248655403718163, 0.016649690689205077, 0.19673087879758067, 0.0234078321527722, 0.13713436145763513, 0.05434572922385983, 0.14875255345263416, 0.04576384396279387, 0.06018831674566849, 0.1315153224106954, 0.101733030551443, 0.11561002629614447, 0.10432146731663439, 0.0914717041494354, 0.1258334699386644, 0.08608725614657631, 0.1407169002988078, 0.15707977038258336, 0.024682708096605888, 0.21472988970015416, 0.07104425043745144, 0.15386660981877753, 0.04757858577739804, 0.10402804824083012, 0.08038211184746347, 0.5153758918642293, 0.5174614354927733, 0.5604869206660623, 0.3801447769632149, 0.5257353548783275, 0.6258258544313445, 0.6236943060952025, 0.5961789853264416, 0.4974979230496783, 0.0934839121218558, 0.05434173625295313, 0.08548856944076777, 0.10571428882521172, 0.13090302615789473, 0.11162190204007927, 0.10451716258435229, 0.09144178697320027, 0.1353312573902613, 0.255212887891091, 0.22526587832147138, 0.31418345325239694, 0.26504659252460594, 0.2522910170429783, 0.451297959626793, 0.15432457862901594, 0.18768256503718428, 0.1713169759834161, 0.2373965083709103, 0.36160317178692425, 0.4268391445706957, 0.2672590847789449, 0.28106561289388843, 0.34297154810542274, 0.3056392771127492, 0.3381944701448697, 0.3660351925017168, 0.26381262295382635, 0.17815093087907008, 0.2951448592730691, 0.36223439110796884, 0.2093490090084602, 0.2625632635580878, 0.23152829305298672, 0.2612005346155388, 0.22297407026759197, 0.2169265078007434, 0.18762258672507037, 0.2561733939997486, 0.24809215100486604, 0.24274479141350747, 0.18925307091008836, 0.1962704733552605, 0.23669774306528502, 0.23054876528804558, 0.19618446160909053, 0.21549147391366974, 0.21852091511328975, 0.20604035264896892, 0.24741094786041207, 0.2062977422778678, 0.20712250919441377, 0.20755004877017713, 0.221031953549227, 0.869692182233791, 0.18766515643948822, 0.16687800137226783, 0.8788460429904758, 0.19907918870622543, 0.16914509547665546, 0.1418056575001434, 0.1602030963388239, 0.8826065639875245, 0.8647074560979798, 0.2096413532271798, 0.20558415883347514, 0.6679694068056423, 0.2237270173122219, 0.16451402863211384, 0.20395527100718536, 0.10473006269145568, 0.291127816186443, 0.21751380967023193, 0.19834635781982757, 0.1929291731946291, 0.23766062615814787, 0.19127978858952355, 0.22356442114865116, 0.1958580541098478, 0.21182925143834996, 0.21442466817186656, 0.11724463625874326, 0.0915033231841953, 0.08938333220237415, 0.0864616601616297, 0.10278074167687823, 0.09160863296503063, 0.08675944242549816, 0.10475815134815569, 0.09580120643224088]}, "mutation_prompt": null}
{"id": "edce7623-1be0-40e7-ac45-de6b0f58511a", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSODER:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // (dim * 3))\n        self.w = 0.4 + 0.3 * np.random.rand()\n        self.c1 = 1.4 + 0.2 * np.random.rand()\n        self.c2 = 1.8 + 0.1 * np.random.rand()\n        self.F = 0.5 + 0.2 * np.random.rand()\n        self.CR = 0.7 + 0.2 * np.random.rand()\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        adapt_strategy = np.random.choice(['rank_based', 'elitist_recombination'])\n        \n        while self.evaluations < self.budget:\n            scores = np.array([func(ind) for ind in self.population])\n            self.evaluations += len(self.population)\n            ordering = np.argsort(scores)\n            self.personal_best_positions = self.population[ordering[:self.population_size // 2]]\n            self.personal_best_scores = scores[ordering[:self.population_size // 2]]\n            if min(scores) < self.global_best_score:\n                self.global_best_score = min(scores)\n                self.global_best_position = self.population[np.argmin(scores)]\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i % (self.population_size // 2)] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n\n            if adapt_strategy == 'rank_based':\n                self.c1, self.c2 = sorted(np.random.normal(loc=[1.5, 1.7], scale=0.1, size=2))\n                self.w = 0.5 + 0.5 * (self.global_best_score / np.sum(self.personal_best_scores))\n            elif adapt_strategy == 'elitist_recombination':\n                for i in range(self.population_size):\n                    indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = self.population[a] + self.F * (self.population[b] - self.population[c])\n                    mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    self.evaluations += 1\n                    if trial_score < scores[i]:\n                        self.population[i] = trial_vector\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedAdaptiveHybridPSODER", "description": "An enhanced adaptive hybrid PSO-DE algorithm utilizing stochastic rank-based parameter adaptation and elitist recombination.", "configspace": "", "generation": 99, "fitness": 0.11510727062684499, "feedback": "The algorithm EnhancedAdaptiveHybridPSODER got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.19.", "error": "", "parent_id": "76dda838-807b-43bc-b716-7c182cb1fc0f", "metadata": {"aucs": [0.12997213403847363, 0.13904141527960545, 0.18171105408526378, 0.1637702069718855, 0.15267494159496908, 0.149489345100129, 0.1437583004585936, 0.21976424092433877, 0.16132323316668573, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.027589825079102903, 0.027872560430857063, 0.02589049660467191, 0.062439667698108825, 0.04322380934979997, 0.018123928611461615, 0.031438651205469625, 0.06550977621061282, 0.05089391001686239, 0.01782167334156315, 0.024476778631438045, 0.03248178891626108, 0.01960167310977723, 0.029782608278740574, 0.029890874894733632, 0.014764865741611732, 0.005699497915048757, 0.04248426341153755, 0.9837394048402837, 0.9833324894981993, 0.988737548080828, 0.9887876289943888, 0.98293363522404, 0.9843502339416372, 0.9837204058041192, 0.9937492880307711, 0.9888917886824276, 0.06275423285318793, 0.04341544942023956, 0.06359762333663599, 0.08296605468567575, 0.011659150231136284, 0.02042517114682252, 0.07847789777823477, 0.06046957323033697, 0.06298075943394466, 0.10026423215546731, 0.09440494729029414, 0.0970773129229825, 0.09877672016527761, 0.11517146690071711, 0.08053960742740585, 0.0991731263444171, 0.12491199606970826, 0.12416615668523134, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04364084317349226, 9.999999999998899e-05, 9.999999999998899e-05, 0.03369777453915723, 9.999999999998899e-05, 9.999999999998899e-05, 0.010061931359822474, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04208185414583765, 0.05175681104371832, 9.999999999998899e-05, 9.999999999998899e-05, 0.00671778641226195, 0.0018922368945418766, 0.04920559078292985, 0.025981776549787172, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00590765889373579, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007828518878208013, 0.008351816933668488, 9.999999999998899e-05, 9.999999999998899e-05, 0.1396321738742694, 0.15758132322734197, 0.18981779267697607, 0.20669873518122228, 0.15268081144890944, 0.1668976124717365, 0.3526070316361142, 0.23402855098982234, 0.3340674295981615, 0.04078362453179485, 0.034308627513274015, 0.046554343938576714, 0.04536488594273269, 0.03963717535799205, 0.041006059900167924, 0.057311794241560854, 0.03410026049547721, 0.04981840900633738, 0.1337583000347049, 0.10801391509106417, 0.1310752818857136, 0.1376756941369922, 0.1381585250431583, 0.10798477775134396, 0.10757631984312466, 0.11991230785696949, 0.11408357112889222, 0.1571606322801996, 0.12799726864851124, 0.17226342549358287, 0.1501205426009501, 0.1698245272204717, 0.13210935181128858, 0.1449013149599927, 0.17378852289228075, 0.14294332482114136, 0.13457957208228566, 0.06900155126095908, 0.1373988050269379, 0.13854626506260104, 0.11021719480978354, 0.10164568115007533, 0.10214587693448718, 0.09977902079590073, 0.09397687454903392, 0.1221580435063484, 0.13111461614507247, 0.13344594199783655, 0.16563937387431138, 0.16051829858959132, 0.13414846002493086, 0.13760053813378292, 0.15776796788281588, 0.12620142977777327, 0.13882260503530475, 0.15206539519225948, 0.007100819953092308, 9.999999999998899e-05, 0.17086853819499725, 0.1432165354648428, 0.14350227917947211, 0.14535380580821367, 0.16420672233041644, 0.14513357507790492, 0.12379163026943063, 0.14018024133740237, 0.11900217391597345, 0.13718758436104384, 0.20011521886918993, 0.11391317430456971, 0.11345963686245664, 0.16225850375353112, 0.1104123681252368, 0.14559879628211037, 0.092743999350276, 0.06455437390353602, 0.06949409990278277, 0.10228124534986294, 0.13279315521677215, 0.18481253978588164, 0.10334570080871142, 0.17656822091679625, 0.1503232169483455, 0.15926969967097304, 0.19861125472715424, 0.16958449540304665, 0.14998001709861908, 0.1759641921478423, 0.1493950320019305, 0.1812158466785303, 0.02990136924150577, 0.0468677837587782, 0.05238662456502263, 0.037868765791977954, 0.03425436066355236, 0.04106529049894947, 0.04078077055319207, 0.0468722713656714, 0.04462674574480463]}, "mutation_prompt": null}

{"id": "a830d638-67ae-4012-80c9-1b519e4c1852", "solution": "", "name": "", "description": "", "configspace": "", "generation": 0, "fitness": -Infinity, "feedback": "No code was extracted.", "error": "", "parent_id": null, "metadata": {}, "mutation_prompt": null}
{"id": "edf5cf29-719d-4128-a8d2-2f8c3e0bc5b1", "solution": "", "name": "", "description": "", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a830d638-67ae-4012-80c9-1b519e4c1852", "metadata": {}, "mutation_prompt": null}
{"id": "f1a1379a-0955-4df8-8ab6-9149974e8196", "solution": "", "name": "", "description": "", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a830d638-67ae-4012-80c9-1b519e4c1852", "metadata": {}, "mutation_prompt": null}
{"id": "591ae04a-81e7-4289-b016-badb6cad14bd", "solution": "", "name": "", "description": "", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a830d638-67ae-4012-80c9-1b519e4c1852", "metadata": {}, "mutation_prompt": null}
{"id": "9292064c-94c8-4ec6-aeb6-293ebe83cfbc", "solution": "", "name": "", "description": "", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a830d638-67ae-4012-80c9-1b519e4c1852", "metadata": {}, "mutation_prompt": null}
{"id": "5f4583f5-f55a-4579-a439-fc088241cc34", "solution": "import numpy as np\n\nclass ADEDSOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * self.dim\n        self.scale_factor = 0.5\n        self.crossover_rate = 0.7\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.eval_count = 0\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = self.population[indices]\n                mutant = a + self.scale_factor * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover\n                trial = np.where(np.random.rand(self.dim) <= self.crossover_rate, mutant, self.population[i])\n\n                # Evaluate\n                trial_fitness = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n\n            # Dynamic adaptation of parameters\n            self.scale_factor = 0.5 + 0.5 * (1 - self.eval_count / self.budget)\n            self.crossover_rate = 0.1 + 0.9 * (self.eval_count / self.budget)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "ADEDSOptimizer", "description": "Adaptive Differential Evolution with Dynamic Scaling for efficient exploration and exploitation balance.", "configspace": "", "generation": 5, "fitness": 0.20322600020557502, "feedback": "The algorithm ADEDSOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.19.", "error": "", "parent_id": "a830d638-67ae-4012-80c9-1b519e4c1852", "metadata": {"aucs": [0.5846217338820296, 0.5967857525044518, 0.5663266809444905, 0.6012928786740002, 0.5681299526345591, 0.6077247155285213, 0.6085519739685878, 0.5730889324857423, 0.5829552321367075, 0.31904017852278577, 0.32777960777264714, 0.3136420934665676, 0.30207327732075784, 0.3061115021468769, 0.339081784006277, 0.30423503160567933, 0.30639193572068657, 0.32803633640702545, 0.1172807185625856, 0.11651000655047428, 0.13415994879281223, 0.11056884685134027, 0.1296975671306887, 0.12428324062548202, 0.12348944737916023, 0.1310445348512298, 0.1144327133528148, 0.1076359198971748, 0.11144976397499518, 0.12516460681487895, 0.10720483060434394, 0.10968357243607241, 0.10569645882876211, 0.10827144602200112, 0.11119852298522814, 0.10225436870088012, 0.9042047587733595, 0.9002839219364076, 0.9037028974806897, 0.919435693189188, 0.9012368240594127, 0.9108621009600577, 0.9386826193047941, 0.9019672636877167, 0.9148872956192984, 0.19623853363122112, 0.18236821675287807, 0.18132081392725885, 0.18516997237332244, 0.1636907516515892, 0.18595953068122528, 0.19950500473066268, 0.186866443859933, 0.1915280406847274, 0.28283032634771055, 0.24814257878328505, 0.21693933946800936, 0.2584486063701402, 0.24963205607191608, 0.25967366101545963, 0.25363588021996886, 0.21590393933568353, 0.2469175205335976, 0.11553126160274574, 0.1070890239765735, 0.10382863076099513, 0.13194854152802704, 0.11724489966673624, 0.09238180535802243, 0.10391976728632057, 0.11318943710161111, 0.14700358621743836, 0.09809270372319112, 0.07221662043036758, 0.07128271490476867, 0.1172572780999449, 0.1164053812356397, 0.11678249882753666, 0.07924906482546301, 0.100061350081881, 0.07896060641257596, 0.01573447344811718, 0.011160180653832508, 0.024555017186390637, 0.007897204069130415, 0.014670692811439623, 0.010978176232239067, 0.01438015592479458, 0.013144178074636303, 0.014840867755510079, 0.07578231344423092, 0.08163582727875651, 0.08904050255388374, 0.11239902730538487, 0.10564270277465515, 0.08317134179221297, 0.10356511182342243, 0.08323479776340992, 0.12035536526865453, 0.004525309245396736, 0.005250575021318982, 0.003888753737029904, 0.006814933122574085, 0.0044687911082949006, 0.006768600727392715, 0.01293421547020479, 0.0070325622907295715, 0.010352377141586988, 0.061435309831142315, 0.07357075152277026, 0.0654957143297401, 0.0769876918203648, 0.08130212431931982, 0.08696314132446825, 0.07001372937674188, 0.07648206643061273, 0.08211529352373093, 0.4167736908620634, 0.3742472455010454, 0.40635445219809563, 0.3951982430784534, 0.3905859991596162, 0.40551658301123106, 0.4036198066966078, 0.40445836719106565, 0.3985158196111954, 0.07278528079146929, 0.07507330779764598, 0.07259741230362449, 0.07897796923547562, 0.06888318481794764, 0.07015411643953817, 0.10168946354906816, 0.08100799659438473, 0.07155334689127835, 0.12873769552731285, 0.1582814208289779, 0.15286167707678888, 0.13659964435068128, 0.146253602392997, 0.14751745157676088, 0.15018274275496202, 0.1516175199310823, 0.15302956792306, 0.2235037925870944, 0.20741115367462404, 0.22035913772690285, 0.22507057590154578, 0.20923085703796174, 0.22424887822787065, 0.2325147206209387, 0.22812464741328453, 0.23245046671022107, 0.15589246414163538, 0.15083895055321228, 0.15294149563400983, 0.15885070178065375, 0.14147791402735765, 0.14728983780223703, 0.17308920189209853, 0.17272345089636876, 0.16043814736461426, 0.18097762514382332, 0.18235512086663752, 0.18760635067217646, 0.1766728579975475, 0.18007228191875435, 0.20551535094595286, 0.16151272691506635, 0.17835304690008746, 0.18337137069202314, 0.1803649156415762, 0.16772210733416615, 0.18773658935768522, 0.16553038854915791, 0.2157757363061683, 0.17520519804220513, 0.17386117971598902, 0.19010149959745282, 0.18072344598718848, 0.1558342604938251, 0.20626180856032417, 0.17325873396045577, 0.16886394091397183, 0.20015878159727296, 0.1641486185436224, 0.17349943767299925, 0.1554996110120308, 0.1858687093046314, 0.21543136026520182, 0.22568207311391197, 0.20840648908566484, 0.16625554314509028, 0.2410721458614139, 0.19055765739331765, 0.25044160893641787, 0.20202617245237664, 0.17159753146633627, 0.1866922624959958, 0.18309640351559187, 0.16768619001090013, 0.1899464073399164, 0.18739466455567932, 0.17887365426373292, 0.17688458454910483, 0.18389612651873766, 0.18040094471554713, 0.06985308353958442, 0.0673652074494474, 0.06082101315827404, 0.06800197257767726, 0.06257690830900775, 0.0690050505902835, 0.05985167268336267, 0.06248020248437369, 0.057171663116615146]}, "mutation_prompt": null}
{"id": "1ed9e574-d02e-4314-a9dd-d8c98645349f", "solution": "import numpy as np\n\nclass ADEDSOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * self.dim\n        self.scale_factor = 0.5\n        self.crossover_rate = 0.7\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.eval_count = 0\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Mutation with dynamic scale factor adjustment\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = self.population[indices]\n                dynamic_factor = np.abs(np.random.normal(self.scale_factor, 0.1))\n                mutant = a + dynamic_factor * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with adaptive probability\n                crossover_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover_points, mutant, self.population[i])\n\n                # Evaluate\n                trial_fitness = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n\n            # Dynamic adaptation of parameters\n            self.scale_factor = 0.4 + 0.6 * (1 - self.eval_count / self.budget)\n            self.crossover_rate = 0.2 + 0.8 * (self.eval_count / self.budget)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "ADEDSOptimizer", "description": "Adaptive Differential Evolution with Dynamic Mutation Control for enhanced balance between exploration and exploitation.", "configspace": "", "generation": 6, "fitness": 0.2257606030579906, "feedback": "The algorithm ADEDSOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "5f4583f5-f55a-4579-a439-fc088241cc34", "metadata": {"aucs": [0.6348191525549249, 0.6398294088441203, 0.6189615068906968, 0.6427883063423934, 0.6379700556488541, 0.6544357321509856, 0.626312032992993, 0.654111260682031, 0.6330879307955339, 0.39451913985146947, 0.3864893795151132, 0.3802988159561892, 0.37486744127393057, 0.39331007755475966, 0.3710821079628672, 0.39950595479125395, 0.396381228477801, 0.3849055425717939, 0.1258640024800447, 0.18984798095353606, 0.12006601044989096, 0.12482806185352768, 0.11020873747928506, 0.14320014207944154, 0.14566337165943566, 0.15938482951502886, 0.12111360137186367, 0.1253900526725391, 0.11093121279189067, 0.11959542547723834, 0.11102843935779072, 0.10700289987287093, 0.1138303954150286, 0.1325969405792211, 0.12040432847837224, 0.09890684181146914, 0.9284997712393134, 0.94538996946205, 0.959976416352898, 0.9521372893229908, 0.9319892371064966, 0.9569611819904994, 0.9359848362322941, 0.9397032714081317, 0.964820567561964, 0.20637610996135414, 0.20033826443484293, 0.20400992396637374, 0.20281206280695185, 0.2307392279764553, 0.2211737928639803, 0.23275222374467053, 0.2309705615029477, 0.210201061893857, 0.30447272860168306, 0.31664753220079733, 0.3352956375137315, 0.3411040183891052, 0.33871116147853186, 0.3435825487592863, 0.3254832723077409, 0.27459676890827955, 0.3166644375651998, 0.13951016433891195, 0.13450905160865112, 0.11111699235445771, 0.13165289469305985, 0.10702819105009398, 0.1655520162916433, 0.13296462376794138, 0.13536525317533177, 0.13558281193261024, 0.11099150024420179, 0.12234499286150691, 0.09515346232863142, 0.1260177107718291, 0.13790477910932764, 0.1362251721165152, 0.10890895095055819, 0.12229612820224389, 0.1099906963004631, 0.023152285409000384, 0.022739300301207743, 0.023841488190800342, 0.024841448419786638, 0.023542677966649217, 0.02620032158476393, 0.02657258678227281, 0.030235937197003127, 0.03182893974884571, 0.1092094842138609, 0.08393824730209476, 0.1156599896402033, 0.08744622201602126, 0.08597364426001308, 0.11199772890995408, 0.12396439523756941, 0.1260926873167597, 0.15835528922868447, 0.00935764602051714, 0.01751648440158826, 0.011192089139561934, 0.016557693425984454, 0.025467678329099575, 0.014231670925829887, 0.01612106216572995, 0.019110433296703144, 0.021347430298373937, 0.09458146735473916, 0.09268956821091412, 0.08715396420735866, 0.09962571263255382, 0.10296440623234282, 0.08769788189318373, 0.09115823893695618, 0.10108903738339958, 0.09280879322744007, 0.41518469832371907, 0.3992915004170968, 0.42389069634306653, 0.4444494579503101, 0.4341864463918329, 0.4268067402316087, 0.45432686581744053, 0.4220396512233747, 0.4363429372629185, 0.08944131358973118, 0.07967187428541633, 0.07598510654396562, 0.09267164202459777, 0.07782430935739337, 0.06906242783971828, 0.0828028661468686, 0.08667894167589962, 0.07899011310172954, 0.1524719757422789, 0.16242532725584968, 0.14342510135173903, 0.13656971400346862, 0.14807472696283042, 0.13586553498821574, 0.1503201033944066, 0.13270719855868207, 0.12848786087796815, 0.2257991836260277, 0.23456069484128206, 0.22944168169739365, 0.24469495961383614, 0.24563771461806216, 0.2398947104801119, 0.2746846681053011, 0.25117237169882745, 0.25069310365140196, 0.17879284023825093, 0.15703788609258118, 0.1826704778127931, 0.17505819341828033, 0.1638806328181205, 0.16107408666235912, 0.19130304615625948, 0.17711265904177487, 0.16779794498866996, 0.18131148109272055, 0.17264522226534407, 0.1734693791004589, 0.18427084050779619, 0.17148758019564248, 0.17801943102878448, 0.17955491320461991, 0.1755684810929966, 0.18194974322330248, 0.16959069226542578, 0.18933050179748212, 0.18579845766644676, 0.17160879653926953, 0.2119202090690926, 0.17809148025932098, 0.18006054352914946, 0.18553612556097787, 0.1775349877109309, 0.29016134864790233, 0.27752544829618386, 0.1814063611999175, 0.23863188018211, 0.23291099365583412, 0.19495318869404887, 0.16574626534092474, 0.26748938911932096, 0.24784745179882317, 0.1702951410708331, 0.1846333600790072, 0.3310650404229818, 0.20718493734871146, 0.20312648516773912, 0.17558054088975628, 0.3086500872330171, 0.31574399361172256, 0.2721925626015146, 0.18593079349941033, 0.17871946124696825, 0.1819580195619086, 0.179213722838946, 0.19121013492857775, 0.18995396103695283, 0.18068828559471184, 0.17447286108692428, 0.18057020963825143, 0.069469538959819, 0.07328069601511111, 0.07035282999227888, 0.06782964451667794, 0.06595235733125848, 0.07673202382832855, 0.06658488287699582, 0.06402958803093284, 0.06883437223397781]}, "mutation_prompt": null}
{"id": "5ebc7b27-1dbe-4ff4-80de-e583b1f2c6a0", "solution": "import numpy as np\n\nclass ADEDSOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * self.dim\n        self.scale_factor = 0.5\n        self.crossover_rate = 0.7\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.eval_count = 0\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Mutation with dynamic scale factor adjustment\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = self.population[indices]\n                dynamic_factor = np.abs(np.random.normal(self.scale_factor, 0.1))\n                mutant = a + dynamic_factor * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with adaptive probability\n                crossover_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover_points, mutant, self.population[i])\n\n                # Evaluate\n                trial_fitness = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n\n            # Dynamic adaptation of parameters\n            self.scale_factor = 0.4 + 0.6 * (1 - self.eval_count / self.budget)\n            self.crossover_rate = 0.2 + 0.8 * (self.eval_count / self.budget)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "ADEDSOptimizer", "description": "Adaptive Differential Evolution with Dynamic Mutation Control for enhanced balance between exploration and exploitation.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "1ed9e574-d02e-4314-a9dd-d8c98645349f", "metadata": {"aucs": [0.6348191525549249, 0.6398294088441203, 0.6189615068906968, 0.6427883063423934, 0.6379700556488541, 0.6544357321509856, 0.626312032992993, 0.654111260682031, 0.6330879307955339, 0.39451913985146947, 0.3864893795151132, 0.3802988159561892, 0.37486744127393057, 0.39331007755475966, 0.3710821079628672, 0.39950595479125395, 0.396381228477801, 0.3849055425717939, 0.1258640024800447, 0.18984798095353606, 0.12006601044989096, 0.12482806185352768, 0.11020873747928506, 0.14320014207944154, 0.14566337165943566, 0.15938482951502886, 0.12111360137186367, 0.1253900526725391, 0.11093121279189067, 0.11959542547723834, 0.11102843935779072, 0.10700289987287093, 0.1138303954150286, 0.1325969405792211, 0.12040432847837224, 0.09890684181146914, 0.9284997712393134, 0.94538996946205, 0.959976416352898, 0.9521372893229908, 0.9319892371064966, 0.9569611819904994, 0.9359848362322941, 0.9397032714081317, 0.964820567561964, 0.20637610996135414, 0.20033826443484293, 0.20400992396637374, 0.20281206280695185, 0.2307392279764553, 0.2211737928639803, 0.23275222374467053, 0.2309705615029477, 0.210201061893857, 0.30447272860168306, 0.31664753220079733, 0.3352956375137315, 0.3411040183891052, 0.33871116147853186, 0.3435825487592863, 0.3254832723077409, 0.27459676890827955, 0.3166644375651998, 0.13951016433891195, 0.13450905160865112, 0.11111699235445771, 0.13165289469305985, 0.10702819105009398, 0.1655520162916433, 0.13296462376794138, 0.13536525317533177, 0.13558281193261024, 0.11099150024420179, 0.12234499286150691, 0.09515346232863142, 0.1260177107718291, 0.13790477910932764, 0.1362251721165152, 0.10890895095055819, 0.12229612820224389, 0.1099906963004631, 0.023152285409000384, 0.022739300301207743, 0.023841488190800342, 0.024841448419786638, 0.023542677966649217, 0.02620032158476393, 0.02657258678227281, 0.030235937197003127, 0.03182893974884571, 0.1092094842138609, 0.08393824730209476, 0.1156599896402033, 0.08744622201602126, 0.08597364426001308, 0.11199772890995408, 0.12396439523756941, 0.1260926873167597, 0.15835528922868447, 0.00935764602051714, 0.01751648440158826, 0.011192089139561934, 0.016557693425984454, 0.025467678329099575, 0.014231670925829887, 0.01612106216572995, 0.019110433296703144, 0.021347430298373937, 0.09458146735473916, 0.09268956821091412, 0.08715396420735866, 0.09962571263255382, 0.10296440623234282, 0.08769788189318373, 0.09115823893695618, 0.10108903738339958, 0.09280879322744007, 0.41518469832371907, 0.3992915004170968, 0.42389069634306653, 0.4444494579503101, 0.4341864463918329, 0.4268067402316087, 0.45432686581744053, 0.4220396512233747, 0.4363429372629185, 0.08944131358973118, 0.07967187428541633, 0.07598510654396562, 0.09267164202459777, 0.07782430935739337, 0.06906242783971828, 0.0828028661468686, 0.08667894167589962, 0.07899011310172954, 0.1524719757422789, 0.16242532725584968, 0.14342510135173903, 0.13656971400346862, 0.14807472696283042, 0.13586553498821574, 0.1503201033944066, 0.13270719855868207, 0.12848786087796815, 0.2257991836260277, 0.23456069484128206, 0.22944168169739365, 0.24469495961383614, 0.24563771461806216, 0.2398947104801119, 0.2746846681053011, 0.25117237169882745, 0.25069310365140196, 0.17879284023825093, 0.15703788609258118, 0.1826704778127931, 0.17505819341828033, 0.1638806328181205, 0.16107408666235912, 0.19130304615625948, 0.17711265904177487, 0.16779794498866996, 0.18131148109272055, 0.17264522226534407, 0.1734693791004589, 0.18427084050779619, 0.17148758019564248, 0.17801943102878448, 0.17955491320461991, 0.1755684810929966, 0.18194974322330248, 0.16959069226542578, 0.18933050179748212, 0.18579845766644676, 0.17160879653926953, 0.2119202090690926, 0.17809148025932098, 0.18006054352914946, 0.18553612556097787, 0.1775349877109309, 0.29016134864790233, 0.27752544829618386, 0.1814063611999175, 0.23863188018211, 0.23291099365583412, 0.19495318869404887, 0.16574626534092474, 0.26748938911932096, 0.24784745179882317, 0.1702951410708331, 0.1846333600790072, 0.3310650404229818, 0.20718493734871146, 0.20312648516773912, 0.17558054088975628, 0.3086500872330171, 0.31574399361172256, 0.2721925626015146, 0.18593079349941033, 0.17871946124696825, 0.1819580195619086, 0.179213722838946, 0.19121013492857775, 0.18995396103695283, 0.18068828559471184, 0.17447286108692428, 0.18057020963825143, 0.069469538959819, 0.07328069601511111, 0.07035282999227888, 0.06782964451667794, 0.06595235733125848, 0.07673202382832855, 0.06658488287699582, 0.06402958803093284, 0.06883437223397781]}, "mutation_prompt": null}
{"id": "6fab280b-0181-47a0-aae0-06b2f8805c9a", "solution": "import numpy as np\n\nclass ADEDSOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * self.dim\n        self.scale_factor = 0.5\n        self.crossover_rate = 0.7\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.eval_count = 0\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Mutation with dynamic scale factor adjustment\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = self.population[indices]\n                dynamic_factor = np.abs(np.random.normal(self.scale_factor, 0.1))\n                mutant = a + dynamic_factor * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with adaptive probability\n                crossover_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover_points, mutant, self.population[i])\n\n                # Evaluate\n                trial_fitness = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n\n            # Dynamic adaptation of parameters\n            self.scale_factor = 0.4 + 0.6 * (1 - self.eval_count / self.budget)\n            self.crossover_rate = 0.2 + 0.8 * (self.eval_count / self.budget)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "ADEDSOptimizer", "description": "Adaptive Differential Evolution with Dynamic Mutation Control for enhanced balance between exploration and exploitation.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "1ed9e574-d02e-4314-a9dd-d8c98645349f", "metadata": {"aucs": [0.6348191525549249, 0.6398294088441203, 0.6189615068906968, 0.6427883063423934, 0.6379700556488541, 0.6544357321509856, 0.626312032992993, 0.654111260682031, 0.6330879307955339, 0.39451913985146947, 0.3864893795151132, 0.3802988159561892, 0.37486744127393057, 0.39331007755475966, 0.3710821079628672, 0.39950595479125395, 0.396381228477801, 0.3849055425717939, 0.1258640024800447, 0.18984798095353606, 0.12006601044989096, 0.12482806185352768, 0.11020873747928506, 0.14320014207944154, 0.14566337165943566, 0.15938482951502886, 0.12111360137186367, 0.1253900526725391, 0.11093121279189067, 0.11959542547723834, 0.11102843935779072, 0.10700289987287093, 0.1138303954150286, 0.1325969405792211, 0.12040432847837224, 0.09890684181146914, 0.9284997712393134, 0.94538996946205, 0.959976416352898, 0.9521372893229908, 0.9319892371064966, 0.9569611819904994, 0.9359848362322941, 0.9397032714081317, 0.964820567561964, 0.20637610996135414, 0.20033826443484293, 0.20400992396637374, 0.20281206280695185, 0.2307392279764553, 0.2211737928639803, 0.23275222374467053, 0.2309705615029477, 0.210201061893857, 0.30447272860168306, 0.31664753220079733, 0.3352956375137315, 0.3411040183891052, 0.33871116147853186, 0.3435825487592863, 0.3254832723077409, 0.27459676890827955, 0.3166644375651998, 0.13951016433891195, 0.13450905160865112, 0.11111699235445771, 0.13165289469305985, 0.10702819105009398, 0.1655520162916433, 0.13296462376794138, 0.13536525317533177, 0.13558281193261024, 0.11099150024420179, 0.12234499286150691, 0.09515346232863142, 0.1260177107718291, 0.13790477910932764, 0.1362251721165152, 0.10890895095055819, 0.12229612820224389, 0.1099906963004631, 0.023152285409000384, 0.022739300301207743, 0.023841488190800342, 0.024841448419786638, 0.023542677966649217, 0.02620032158476393, 0.02657258678227281, 0.030235937197003127, 0.03182893974884571, 0.1092094842138609, 0.08393824730209476, 0.1156599896402033, 0.08744622201602126, 0.08597364426001308, 0.11199772890995408, 0.12396439523756941, 0.1260926873167597, 0.15835528922868447, 0.00935764602051714, 0.01751648440158826, 0.011192089139561934, 0.016557693425984454, 0.025467678329099575, 0.014231670925829887, 0.01612106216572995, 0.019110433296703144, 0.021347430298373937, 0.09458146735473916, 0.09268956821091412, 0.08715396420735866, 0.09962571263255382, 0.10296440623234282, 0.08769788189318373, 0.09115823893695618, 0.10108903738339958, 0.09280879322744007, 0.41518469832371907, 0.3992915004170968, 0.42389069634306653, 0.4444494579503101, 0.4341864463918329, 0.4268067402316087, 0.45432686581744053, 0.4220396512233747, 0.4363429372629185, 0.08944131358973118, 0.07967187428541633, 0.07598510654396562, 0.09267164202459777, 0.07782430935739337, 0.06906242783971828, 0.0828028661468686, 0.08667894167589962, 0.07899011310172954, 0.1524719757422789, 0.16242532725584968, 0.14342510135173903, 0.13656971400346862, 0.14807472696283042, 0.13586553498821574, 0.1503201033944066, 0.13270719855868207, 0.12848786087796815, 0.2257991836260277, 0.23456069484128206, 0.22944168169739365, 0.24469495961383614, 0.24563771461806216, 0.2398947104801119, 0.2746846681053011, 0.25117237169882745, 0.25069310365140196, 0.17879284023825093, 0.15703788609258118, 0.1826704778127931, 0.17505819341828033, 0.1638806328181205, 0.16107408666235912, 0.19130304615625948, 0.17711265904177487, 0.16779794498866996, 0.18131148109272055, 0.17264522226534407, 0.1734693791004589, 0.18427084050779619, 0.17148758019564248, 0.17801943102878448, 0.17955491320461991, 0.1755684810929966, 0.18194974322330248, 0.16959069226542578, 0.18933050179748212, 0.18579845766644676, 0.17160879653926953, 0.2119202090690926, 0.17809148025932098, 0.18006054352914946, 0.18553612556097787, 0.1775349877109309, 0.29016134864790233, 0.27752544829618386, 0.1814063611999175, 0.23863188018211, 0.23291099365583412, 0.19495318869404887, 0.16574626534092474, 0.26748938911932096, 0.24784745179882317, 0.1702951410708331, 0.1846333600790072, 0.3310650404229818, 0.20718493734871146, 0.20312648516773912, 0.17558054088975628, 0.3086500872330171, 0.31574399361172256, 0.2721925626015146, 0.18593079349941033, 0.17871946124696825, 0.1819580195619086, 0.179213722838946, 0.19121013492857775, 0.18995396103695283, 0.18068828559471184, 0.17447286108692428, 0.18057020963825143, 0.069469538959819, 0.07328069601511111, 0.07035282999227888, 0.06782964451667794, 0.06595235733125848, 0.07673202382832855, 0.06658488287699582, 0.06402958803093284, 0.06883437223397781]}, "mutation_prompt": null}
{"id": "b3d56820-66ce-49e1-b5ac-f2e9bae399e3", "solution": "import numpy as np\n\nclass ADEDSOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * self.dim\n        self.scale_factor = 0.5\n        self.crossover_rate = 0.7\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.eval_count = 0\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Mutation with dynamic scale factor adjustment\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = self.population[indices]\n                dynamic_factor = np.abs(np.random.normal(self.scale_factor, 0.1))\n                mutant = a + dynamic_factor * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with adaptive probability\n                crossover_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover_points, mutant, self.population[i])\n\n                # Evaluate\n                trial_fitness = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n\n            # Dynamic adaptation of parameters\n            self.scale_factor = 0.4 + 0.6 * (1 - self.eval_count / self.budget)\n            self.crossover_rate = 0.2 + 0.8 * (self.eval_count / self.budget)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "ADEDSOptimizer", "description": "Adaptive Differential Evolution with Dynamic Mutation Control for enhanced balance between exploration and exploitation.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "1ed9e574-d02e-4314-a9dd-d8c98645349f", "metadata": {"aucs": [0.6348191525549249, 0.6398294088441203, 0.6189615068906968, 0.6427883063423934, 0.6379700556488541, 0.6544357321509856, 0.626312032992993, 0.654111260682031, 0.6330879307955339, 0.39451913985146947, 0.3864893795151132, 0.3802988159561892, 0.37486744127393057, 0.39331007755475966, 0.3710821079628672, 0.39950595479125395, 0.396381228477801, 0.3849055425717939, 0.1258640024800447, 0.18984798095353606, 0.12006601044989096, 0.12482806185352768, 0.11020873747928506, 0.14320014207944154, 0.14566337165943566, 0.15938482951502886, 0.12111360137186367, 0.1253900526725391, 0.11093121279189067, 0.11959542547723834, 0.11102843935779072, 0.10700289987287093, 0.1138303954150286, 0.1325969405792211, 0.12040432847837224, 0.09890684181146914, 0.9284997712393134, 0.94538996946205, 0.959976416352898, 0.9521372893229908, 0.9319892371064966, 0.9569611819904994, 0.9359848362322941, 0.9397032714081317, 0.964820567561964, 0.20637610996135414, 0.20033826443484293, 0.20400992396637374, 0.20281206280695185, 0.2307392279764553, 0.2211737928639803, 0.23275222374467053, 0.2309705615029477, 0.210201061893857, 0.30447272860168306, 0.31664753220079733, 0.3352956375137315, 0.3411040183891052, 0.33871116147853186, 0.3435825487592863, 0.3254832723077409, 0.27459676890827955, 0.3166644375651998, 0.13951016433891195, 0.13450905160865112, 0.11111699235445771, 0.13165289469305985, 0.10702819105009398, 0.1655520162916433, 0.13296462376794138, 0.13536525317533177, 0.13558281193261024, 0.11099150024420179, 0.12234499286150691, 0.09515346232863142, 0.1260177107718291, 0.13790477910932764, 0.1362251721165152, 0.10890895095055819, 0.12229612820224389, 0.1099906963004631, 0.023152285409000384, 0.022739300301207743, 0.023841488190800342, 0.024841448419786638, 0.023542677966649217, 0.02620032158476393, 0.02657258678227281, 0.030235937197003127, 0.03182893974884571, 0.1092094842138609, 0.08393824730209476, 0.1156599896402033, 0.08744622201602126, 0.08597364426001308, 0.11199772890995408, 0.12396439523756941, 0.1260926873167597, 0.15835528922868447, 0.00935764602051714, 0.01751648440158826, 0.011192089139561934, 0.016557693425984454, 0.025467678329099575, 0.014231670925829887, 0.01612106216572995, 0.019110433296703144, 0.021347430298373937, 0.09458146735473916, 0.09268956821091412, 0.08715396420735866, 0.09962571263255382, 0.10296440623234282, 0.08769788189318373, 0.09115823893695618, 0.10108903738339958, 0.09280879322744007, 0.41518469832371907, 0.3992915004170968, 0.42389069634306653, 0.4444494579503101, 0.4341864463918329, 0.4268067402316087, 0.45432686581744053, 0.4220396512233747, 0.4363429372629185, 0.08944131358973118, 0.07967187428541633, 0.07598510654396562, 0.09267164202459777, 0.07782430935739337, 0.06906242783971828, 0.0828028661468686, 0.08667894167589962, 0.07899011310172954, 0.1524719757422789, 0.16242532725584968, 0.14342510135173903, 0.13656971400346862, 0.14807472696283042, 0.13586553498821574, 0.1503201033944066, 0.13270719855868207, 0.12848786087796815, 0.2257991836260277, 0.23456069484128206, 0.22944168169739365, 0.24469495961383614, 0.24563771461806216, 0.2398947104801119, 0.2746846681053011, 0.25117237169882745, 0.25069310365140196, 0.17879284023825093, 0.15703788609258118, 0.1826704778127931, 0.17505819341828033, 0.1638806328181205, 0.16107408666235912, 0.19130304615625948, 0.17711265904177487, 0.16779794498866996, 0.18131148109272055, 0.17264522226534407, 0.1734693791004589, 0.18427084050779619, 0.17148758019564248, 0.17801943102878448, 0.17955491320461991, 0.1755684810929966, 0.18194974322330248, 0.16959069226542578, 0.18933050179748212, 0.18579845766644676, 0.17160879653926953, 0.2119202090690926, 0.17809148025932098, 0.18006054352914946, 0.18553612556097787, 0.1775349877109309, 0.29016134864790233, 0.27752544829618386, 0.1814063611999175, 0.23863188018211, 0.23291099365583412, 0.19495318869404887, 0.16574626534092474, 0.26748938911932096, 0.24784745179882317, 0.1702951410708331, 0.1846333600790072, 0.3310650404229818, 0.20718493734871146, 0.20312648516773912, 0.17558054088975628, 0.3086500872330171, 0.31574399361172256, 0.2721925626015146, 0.18593079349941033, 0.17871946124696825, 0.1819580195619086, 0.179213722838946, 0.19121013492857775, 0.18995396103695283, 0.18068828559471184, 0.17447286108692428, 0.18057020963825143, 0.069469538959819, 0.07328069601511111, 0.07035282999227888, 0.06782964451667794, 0.06595235733125848, 0.07673202382832855, 0.06658488287699582, 0.06402958803093284, 0.06883437223397781]}, "mutation_prompt": null}
{"id": "00a79563-091d-4825-b072-b20bd1925e19", "solution": "import numpy as np\n\nclass ADEDSOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * self.dim\n        self.scale_factor = 0.5\n        self.crossover_rate = 0.7\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.eval_count = 0\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Mutation with dynamic scale factor adjustment\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = self.population[indices]\n                dynamic_factor = np.abs(np.random.normal(self.scale_factor, 0.1))\n                mutant = a + dynamic_factor * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with adaptive probability\n                crossover_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover_points, mutant, self.population[i])\n\n                # Evaluate\n                trial_fitness = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n\n            # Dynamic adaptation of parameters\n            self.scale_factor = 0.4 + 0.6 * (1 - self.eval_count / self.budget)\n            self.crossover_rate = 0.2 + 0.8 * (self.eval_count / self.budget)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "ADEDSOptimizer", "description": "Adaptive Differential Evolution with Dynamic Mutation Control for enhanced balance between exploration and exploitation.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "1ed9e574-d02e-4314-a9dd-d8c98645349f", "metadata": {"aucs": [0.6348191525549249, 0.6398294088441203, 0.6189615068906968, 0.6427883063423934, 0.6379700556488541, 0.6544357321509856, 0.626312032992993, 0.654111260682031, 0.6330879307955339, 0.39451913985146947, 0.3864893795151132, 0.3802988159561892, 0.37486744127393057, 0.39331007755475966, 0.3710821079628672, 0.39950595479125395, 0.396381228477801, 0.3849055425717939, 0.1258640024800447, 0.18984798095353606, 0.12006601044989096, 0.12482806185352768, 0.11020873747928506, 0.14320014207944154, 0.14566337165943566, 0.15938482951502886, 0.12111360137186367, 0.1253900526725391, 0.11093121279189067, 0.11959542547723834, 0.11102843935779072, 0.10700289987287093, 0.1138303954150286, 0.1325969405792211, 0.12040432847837224, 0.09890684181146914, 0.9284997712393134, 0.94538996946205, 0.959976416352898, 0.9521372893229908, 0.9319892371064966, 0.9569611819904994, 0.9359848362322941, 0.9397032714081317, 0.964820567561964, 0.20637610996135414, 0.20033826443484293, 0.20400992396637374, 0.20281206280695185, 0.2307392279764553, 0.2211737928639803, 0.23275222374467053, 0.2309705615029477, 0.210201061893857, 0.30447272860168306, 0.31664753220079733, 0.3352956375137315, 0.3411040183891052, 0.33871116147853186, 0.3435825487592863, 0.3254832723077409, 0.27459676890827955, 0.3166644375651998, 0.13951016433891195, 0.13450905160865112, 0.11111699235445771, 0.13165289469305985, 0.10702819105009398, 0.1655520162916433, 0.13296462376794138, 0.13536525317533177, 0.13558281193261024, 0.11099150024420179, 0.12234499286150691, 0.09515346232863142, 0.1260177107718291, 0.13790477910932764, 0.1362251721165152, 0.10890895095055819, 0.12229612820224389, 0.1099906963004631, 0.023152285409000384, 0.022739300301207743, 0.023841488190800342, 0.024841448419786638, 0.023542677966649217, 0.02620032158476393, 0.02657258678227281, 0.030235937197003127, 0.03182893974884571, 0.1092094842138609, 0.08393824730209476, 0.1156599896402033, 0.08744622201602126, 0.08597364426001308, 0.11199772890995408, 0.12396439523756941, 0.1260926873167597, 0.15835528922868447, 0.00935764602051714, 0.01751648440158826, 0.011192089139561934, 0.016557693425984454, 0.025467678329099575, 0.014231670925829887, 0.01612106216572995, 0.019110433296703144, 0.021347430298373937, 0.09458146735473916, 0.09268956821091412, 0.08715396420735866, 0.09962571263255382, 0.10296440623234282, 0.08769788189318373, 0.09115823893695618, 0.10108903738339958, 0.09280879322744007, 0.41518469832371907, 0.3992915004170968, 0.42389069634306653, 0.4444494579503101, 0.4341864463918329, 0.4268067402316087, 0.45432686581744053, 0.4220396512233747, 0.4363429372629185, 0.08944131358973118, 0.07967187428541633, 0.07598510654396562, 0.09267164202459777, 0.07782430935739337, 0.06906242783971828, 0.0828028661468686, 0.08667894167589962, 0.07899011310172954, 0.1524719757422789, 0.16242532725584968, 0.14342510135173903, 0.13656971400346862, 0.14807472696283042, 0.13586553498821574, 0.1503201033944066, 0.13270719855868207, 0.12848786087796815, 0.2257991836260277, 0.23456069484128206, 0.22944168169739365, 0.24469495961383614, 0.24563771461806216, 0.2398947104801119, 0.2746846681053011, 0.25117237169882745, 0.25069310365140196, 0.17879284023825093, 0.15703788609258118, 0.1826704778127931, 0.17505819341828033, 0.1638806328181205, 0.16107408666235912, 0.19130304615625948, 0.17711265904177487, 0.16779794498866996, 0.18131148109272055, 0.17264522226534407, 0.1734693791004589, 0.18427084050779619, 0.17148758019564248, 0.17801943102878448, 0.17955491320461991, 0.1755684810929966, 0.18194974322330248, 0.16959069226542578, 0.18933050179748212, 0.18579845766644676, 0.17160879653926953, 0.2119202090690926, 0.17809148025932098, 0.18006054352914946, 0.18553612556097787, 0.1775349877109309, 0.29016134864790233, 0.27752544829618386, 0.1814063611999175, 0.23863188018211, 0.23291099365583412, 0.19495318869404887, 0.16574626534092474, 0.26748938911932096, 0.24784745179882317, 0.1702951410708331, 0.1846333600790072, 0.3310650404229818, 0.20718493734871146, 0.20312648516773912, 0.17558054088975628, 0.3086500872330171, 0.31574399361172256, 0.2721925626015146, 0.18593079349941033, 0.17871946124696825, 0.1819580195619086, 0.179213722838946, 0.19121013492857775, 0.18995396103695283, 0.18068828559471184, 0.17447286108692428, 0.18057020963825143, 0.069469538959819, 0.07328069601511111, 0.07035282999227888, 0.06782964451667794, 0.06595235733125848, 0.07673202382832855, 0.06658488287699582, 0.06402958803093284, 0.06883437223397781]}, "mutation_prompt": null}
{"id": "ab0f7757-69c9-4ba3-b334-34a0dd8d0c67", "solution": "import numpy as np\n\nclass ADEDSOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * self.dim\n        self.scale_factor = 0.5\n        self.crossover_rate = 0.7\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.eval_count = 0\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Mutation with dynamic scale factor adjustment\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = self.population[indices]\n                dynamic_factor = np.abs(np.random.normal(self.scale_factor, 0.1))\n                mutant = a + dynamic_factor * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with adaptive probability\n                crossover_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover_points, mutant, self.population[i])\n\n                # Evaluate\n                trial_fitness = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n\n            # Dynamic adaptation of parameters\n            self.scale_factor = 0.4 + 0.6 * (1 - self.eval_count / self.budget)\n            self.crossover_rate = 0.2 + 0.8 * (self.eval_count / self.budget)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "ADEDSOptimizer", "description": "Adaptive Differential Evolution with Dynamic Mutation Control for enhanced balance between exploration and exploitation.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "1ed9e574-d02e-4314-a9dd-d8c98645349f", "metadata": {"aucs": [0.6348191525549249, 0.6398294088441203, 0.6189615068906968, 0.6427883063423934, 0.6379700556488541, 0.6544357321509856, 0.626312032992993, 0.654111260682031, 0.6330879307955339, 0.39451913985146947, 0.3864893795151132, 0.3802988159561892, 0.37486744127393057, 0.39331007755475966, 0.3710821079628672, 0.39950595479125395, 0.396381228477801, 0.3849055425717939, 0.1258640024800447, 0.18984798095353606, 0.12006601044989096, 0.12482806185352768, 0.11020873747928506, 0.14320014207944154, 0.14566337165943566, 0.15938482951502886, 0.12111360137186367, 0.1253900526725391, 0.11093121279189067, 0.11959542547723834, 0.11102843935779072, 0.10700289987287093, 0.1138303954150286, 0.1325969405792211, 0.12040432847837224, 0.09890684181146914, 0.9284997712393134, 0.94538996946205, 0.959976416352898, 0.9521372893229908, 0.9319892371064966, 0.9569611819904994, 0.9359848362322941, 0.9397032714081317, 0.964820567561964, 0.20637610996135414, 0.20033826443484293, 0.20400992396637374, 0.20281206280695185, 0.2307392279764553, 0.2211737928639803, 0.23275222374467053, 0.2309705615029477, 0.210201061893857, 0.30447272860168306, 0.31664753220079733, 0.3352956375137315, 0.3411040183891052, 0.33871116147853186, 0.3435825487592863, 0.3254832723077409, 0.27459676890827955, 0.3166644375651998, 0.13951016433891195, 0.13450905160865112, 0.11111699235445771, 0.13165289469305985, 0.10702819105009398, 0.1655520162916433, 0.13296462376794138, 0.13536525317533177, 0.13558281193261024, 0.11099150024420179, 0.12234499286150691, 0.09515346232863142, 0.1260177107718291, 0.13790477910932764, 0.1362251721165152, 0.10890895095055819, 0.12229612820224389, 0.1099906963004631, 0.023152285409000384, 0.022739300301207743, 0.023841488190800342, 0.024841448419786638, 0.023542677966649217, 0.02620032158476393, 0.02657258678227281, 0.030235937197003127, 0.03182893974884571, 0.1092094842138609, 0.08393824730209476, 0.1156599896402033, 0.08744622201602126, 0.08597364426001308, 0.11199772890995408, 0.12396439523756941, 0.1260926873167597, 0.15835528922868447, 0.00935764602051714, 0.01751648440158826, 0.011192089139561934, 0.016557693425984454, 0.025467678329099575, 0.014231670925829887, 0.01612106216572995, 0.019110433296703144, 0.021347430298373937, 0.09458146735473916, 0.09268956821091412, 0.08715396420735866, 0.09962571263255382, 0.10296440623234282, 0.08769788189318373, 0.09115823893695618, 0.10108903738339958, 0.09280879322744007, 0.41518469832371907, 0.3992915004170968, 0.42389069634306653, 0.4444494579503101, 0.4341864463918329, 0.4268067402316087, 0.45432686581744053, 0.4220396512233747, 0.4363429372629185, 0.08944131358973118, 0.07967187428541633, 0.07598510654396562, 0.09267164202459777, 0.07782430935739337, 0.06906242783971828, 0.0828028661468686, 0.08667894167589962, 0.07899011310172954, 0.1524719757422789, 0.16242532725584968, 0.14342510135173903, 0.13656971400346862, 0.14807472696283042, 0.13586553498821574, 0.1503201033944066, 0.13270719855868207, 0.12848786087796815, 0.2257991836260277, 0.23456069484128206, 0.22944168169739365, 0.24469495961383614, 0.24563771461806216, 0.2398947104801119, 0.2746846681053011, 0.25117237169882745, 0.25069310365140196, 0.17879284023825093, 0.15703788609258118, 0.1826704778127931, 0.17505819341828033, 0.1638806328181205, 0.16107408666235912, 0.19130304615625948, 0.17711265904177487, 0.16779794498866996, 0.18131148109272055, 0.17264522226534407, 0.1734693791004589, 0.18427084050779619, 0.17148758019564248, 0.17801943102878448, 0.17955491320461991, 0.1755684810929966, 0.18194974322330248, 0.16959069226542578, 0.18933050179748212, 0.18579845766644676, 0.17160879653926953, 0.2119202090690926, 0.17809148025932098, 0.18006054352914946, 0.18553612556097787, 0.1775349877109309, 0.29016134864790233, 0.27752544829618386, 0.1814063611999175, 0.23863188018211, 0.23291099365583412, 0.19495318869404887, 0.16574626534092474, 0.26748938911932096, 0.24784745179882317, 0.1702951410708331, 0.1846333600790072, 0.3310650404229818, 0.20718493734871146, 0.20312648516773912, 0.17558054088975628, 0.3086500872330171, 0.31574399361172256, 0.2721925626015146, 0.18593079349941033, 0.17871946124696825, 0.1819580195619086, 0.179213722838946, 0.19121013492857775, 0.18995396103695283, 0.18068828559471184, 0.17447286108692428, 0.18057020963825143, 0.069469538959819, 0.07328069601511111, 0.07035282999227888, 0.06782964451667794, 0.06595235733125848, 0.07673202382832855, 0.06658488287699582, 0.06402958803093284, 0.06883437223397781]}, "mutation_prompt": null}
{"id": "f0736993-6abd-4403-bee1-d1fcd231d61f", "solution": "import numpy as np\n\nclass ADEDSOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * self.dim\n        self.scale_factor = 0.5\n        self.crossover_rate = 0.7\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.eval_count = 0\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Mutation with dynamic scale factor adjustment\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = self.population[indices]\n                dynamic_factor = np.abs(np.random.normal(self.scale_factor, 0.1))\n                mutant = a + dynamic_factor * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with adaptive probability\n                crossover_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover_points, mutant, self.population[i])\n\n                # Evaluate\n                trial_fitness = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n\n            # Dynamic adaptation of parameters\n            self.scale_factor = 0.4 + 0.6 * (1 - self.eval_count / self.budget)\n            self.crossover_rate = 0.2 + 0.8 * (self.eval_count / self.budget)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "ADEDSOptimizer", "description": "Adaptive Differential Evolution with Dynamic Mutation Control for enhanced balance between exploration and exploitation.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "1ed9e574-d02e-4314-a9dd-d8c98645349f", "metadata": {"aucs": [0.6348191525549249, 0.6398294088441203, 0.6189615068906968, 0.6427883063423934, 0.6379700556488541, 0.6544357321509856, 0.626312032992993, 0.654111260682031, 0.6330879307955339, 0.39451913985146947, 0.3864893795151132, 0.3802988159561892, 0.37486744127393057, 0.39331007755475966, 0.3710821079628672, 0.39950595479125395, 0.396381228477801, 0.3849055425717939, 0.1258640024800447, 0.18984798095353606, 0.12006601044989096, 0.12482806185352768, 0.11020873747928506, 0.14320014207944154, 0.14566337165943566, 0.15938482951502886, 0.12111360137186367, 0.1253900526725391, 0.11093121279189067, 0.11959542547723834, 0.11102843935779072, 0.10700289987287093, 0.1138303954150286, 0.1325969405792211, 0.12040432847837224, 0.09890684181146914, 0.9284997712393134, 0.94538996946205, 0.959976416352898, 0.9521372893229908, 0.9319892371064966, 0.9569611819904994, 0.9359848362322941, 0.9397032714081317, 0.964820567561964, 0.20637610996135414, 0.20033826443484293, 0.20400992396637374, 0.20281206280695185, 0.2307392279764553, 0.2211737928639803, 0.23275222374467053, 0.2309705615029477, 0.210201061893857, 0.30447272860168306, 0.31664753220079733, 0.3352956375137315, 0.3411040183891052, 0.33871116147853186, 0.3435825487592863, 0.3254832723077409, 0.27459676890827955, 0.3166644375651998, 0.13951016433891195, 0.13450905160865112, 0.11111699235445771, 0.13165289469305985, 0.10702819105009398, 0.1655520162916433, 0.13296462376794138, 0.13536525317533177, 0.13558281193261024, 0.11099150024420179, 0.12234499286150691, 0.09515346232863142, 0.1260177107718291, 0.13790477910932764, 0.1362251721165152, 0.10890895095055819, 0.12229612820224389, 0.1099906963004631, 0.023152285409000384, 0.022739300301207743, 0.023841488190800342, 0.024841448419786638, 0.023542677966649217, 0.02620032158476393, 0.02657258678227281, 0.030235937197003127, 0.03182893974884571, 0.1092094842138609, 0.08393824730209476, 0.1156599896402033, 0.08744622201602126, 0.08597364426001308, 0.11199772890995408, 0.12396439523756941, 0.1260926873167597, 0.15835528922868447, 0.00935764602051714, 0.01751648440158826, 0.011192089139561934, 0.016557693425984454, 0.025467678329099575, 0.014231670925829887, 0.01612106216572995, 0.019110433296703144, 0.021347430298373937, 0.09458146735473916, 0.09268956821091412, 0.08715396420735866, 0.09962571263255382, 0.10296440623234282, 0.08769788189318373, 0.09115823893695618, 0.10108903738339958, 0.09280879322744007, 0.41518469832371907, 0.3992915004170968, 0.42389069634306653, 0.4444494579503101, 0.4341864463918329, 0.4268067402316087, 0.45432686581744053, 0.4220396512233747, 0.4363429372629185, 0.08944131358973118, 0.07967187428541633, 0.07598510654396562, 0.09267164202459777, 0.07782430935739337, 0.06906242783971828, 0.0828028661468686, 0.08667894167589962, 0.07899011310172954, 0.1524719757422789, 0.16242532725584968, 0.14342510135173903, 0.13656971400346862, 0.14807472696283042, 0.13586553498821574, 0.1503201033944066, 0.13270719855868207, 0.12848786087796815, 0.2257991836260277, 0.23456069484128206, 0.22944168169739365, 0.24469495961383614, 0.24563771461806216, 0.2398947104801119, 0.2746846681053011, 0.25117237169882745, 0.25069310365140196, 0.17879284023825093, 0.15703788609258118, 0.1826704778127931, 0.17505819341828033, 0.1638806328181205, 0.16107408666235912, 0.19130304615625948, 0.17711265904177487, 0.16779794498866996, 0.18131148109272055, 0.17264522226534407, 0.1734693791004589, 0.18427084050779619, 0.17148758019564248, 0.17801943102878448, 0.17955491320461991, 0.1755684810929966, 0.18194974322330248, 0.16959069226542578, 0.18933050179748212, 0.18579845766644676, 0.17160879653926953, 0.2119202090690926, 0.17809148025932098, 0.18006054352914946, 0.18553612556097787, 0.1775349877109309, 0.29016134864790233, 0.27752544829618386, 0.1814063611999175, 0.23863188018211, 0.23291099365583412, 0.19495318869404887, 0.16574626534092474, 0.26748938911932096, 0.24784745179882317, 0.1702951410708331, 0.1846333600790072, 0.3310650404229818, 0.20718493734871146, 0.20312648516773912, 0.17558054088975628, 0.3086500872330171, 0.31574399361172256, 0.2721925626015146, 0.18593079349941033, 0.17871946124696825, 0.1819580195619086, 0.179213722838946, 0.19121013492857775, 0.18995396103695283, 0.18068828559471184, 0.17447286108692428, 0.18057020963825143, 0.069469538959819, 0.07328069601511111, 0.07035282999227888, 0.06782964451667794, 0.06595235733125848, 0.07673202382832855, 0.06658488287699582, 0.06402958803093284, 0.06883437223397781]}, "mutation_prompt": null}
{"id": "886827ba-d4f6-434e-9f86-ae972d6f1200", "solution": "import numpy as np\n\nclass ADEDSOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * self.dim\n        self.scale_factor = 0.5\n        self.crossover_rate = 0.7\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.eval_count = 0\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Mutation with dynamic scale factor adjustment\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = self.population[indices]\n                dynamic_factor = np.abs(np.random.normal(self.scale_factor, 0.1))\n                mutant = a + dynamic_factor * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with adaptive probability\n                crossover_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover_points, mutant, self.population[i])\n\n                # Evaluate\n                trial_fitness = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n\n            # Dynamic adaptation of parameters\n            self.scale_factor = 0.4 + 0.6 * (1 - self.eval_count / self.budget)\n            self.crossover_rate = 0.2 + 0.8 * (self.eval_count / self.budget)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "ADEDSOptimizer", "description": "Adaptive Differential Evolution with Dynamic Mutation Control for enhanced balance between exploration and exploitation.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "1ed9e574-d02e-4314-a9dd-d8c98645349f", "metadata": {"aucs": [0.6348191525549249, 0.6398294088441203, 0.6189615068906968, 0.6427883063423934, 0.6379700556488541, 0.6544357321509856, 0.626312032992993, 0.654111260682031, 0.6330879307955339, 0.39451913985146947, 0.3864893795151132, 0.3802988159561892, 0.37486744127393057, 0.39331007755475966, 0.3710821079628672, 0.39950595479125395, 0.396381228477801, 0.3849055425717939, 0.1258640024800447, 0.18984798095353606, 0.12006601044989096, 0.12482806185352768, 0.11020873747928506, 0.14320014207944154, 0.14566337165943566, 0.15938482951502886, 0.12111360137186367, 0.1253900526725391, 0.11093121279189067, 0.11959542547723834, 0.11102843935779072, 0.10700289987287093, 0.1138303954150286, 0.1325969405792211, 0.12040432847837224, 0.09890684181146914, 0.9284997712393134, 0.94538996946205, 0.959976416352898, 0.9521372893229908, 0.9319892371064966, 0.9569611819904994, 0.9359848362322941, 0.9397032714081317, 0.964820567561964, 0.20637610996135414, 0.20033826443484293, 0.20400992396637374, 0.20281206280695185, 0.2307392279764553, 0.2211737928639803, 0.23275222374467053, 0.2309705615029477, 0.210201061893857, 0.30447272860168306, 0.31664753220079733, 0.3352956375137315, 0.3411040183891052, 0.33871116147853186, 0.3435825487592863, 0.3254832723077409, 0.27459676890827955, 0.3166644375651998, 0.13951016433891195, 0.13450905160865112, 0.11111699235445771, 0.13165289469305985, 0.10702819105009398, 0.1655520162916433, 0.13296462376794138, 0.13536525317533177, 0.13558281193261024, 0.11099150024420179, 0.12234499286150691, 0.09515346232863142, 0.1260177107718291, 0.13790477910932764, 0.1362251721165152, 0.10890895095055819, 0.12229612820224389, 0.1099906963004631, 0.023152285409000384, 0.022739300301207743, 0.023841488190800342, 0.024841448419786638, 0.023542677966649217, 0.02620032158476393, 0.02657258678227281, 0.030235937197003127, 0.03182893974884571, 0.1092094842138609, 0.08393824730209476, 0.1156599896402033, 0.08744622201602126, 0.08597364426001308, 0.11199772890995408, 0.12396439523756941, 0.1260926873167597, 0.15835528922868447, 0.00935764602051714, 0.01751648440158826, 0.011192089139561934, 0.016557693425984454, 0.025467678329099575, 0.014231670925829887, 0.01612106216572995, 0.019110433296703144, 0.021347430298373937, 0.09458146735473916, 0.09268956821091412, 0.08715396420735866, 0.09962571263255382, 0.10296440623234282, 0.08769788189318373, 0.09115823893695618, 0.10108903738339958, 0.09280879322744007, 0.41518469832371907, 0.3992915004170968, 0.42389069634306653, 0.4444494579503101, 0.4341864463918329, 0.4268067402316087, 0.45432686581744053, 0.4220396512233747, 0.4363429372629185, 0.08944131358973118, 0.07967187428541633, 0.07598510654396562, 0.09267164202459777, 0.07782430935739337, 0.06906242783971828, 0.0828028661468686, 0.08667894167589962, 0.07899011310172954, 0.1524719757422789, 0.16242532725584968, 0.14342510135173903, 0.13656971400346862, 0.14807472696283042, 0.13586553498821574, 0.1503201033944066, 0.13270719855868207, 0.12848786087796815, 0.2257991836260277, 0.23456069484128206, 0.22944168169739365, 0.24469495961383614, 0.24563771461806216, 0.2398947104801119, 0.2746846681053011, 0.25117237169882745, 0.25069310365140196, 0.17879284023825093, 0.15703788609258118, 0.1826704778127931, 0.17505819341828033, 0.1638806328181205, 0.16107408666235912, 0.19130304615625948, 0.17711265904177487, 0.16779794498866996, 0.18131148109272055, 0.17264522226534407, 0.1734693791004589, 0.18427084050779619, 0.17148758019564248, 0.17801943102878448, 0.17955491320461991, 0.1755684810929966, 0.18194974322330248, 0.16959069226542578, 0.18933050179748212, 0.18579845766644676, 0.17160879653926953, 0.2119202090690926, 0.17809148025932098, 0.18006054352914946, 0.18553612556097787, 0.1775349877109309, 0.29016134864790233, 0.27752544829618386, 0.1814063611999175, 0.23863188018211, 0.23291099365583412, 0.19495318869404887, 0.16574626534092474, 0.26748938911932096, 0.24784745179882317, 0.1702951410708331, 0.1846333600790072, 0.3310650404229818, 0.20718493734871146, 0.20312648516773912, 0.17558054088975628, 0.3086500872330171, 0.31574399361172256, 0.2721925626015146, 0.18593079349941033, 0.17871946124696825, 0.1819580195619086, 0.179213722838946, 0.19121013492857775, 0.18995396103695283, 0.18068828559471184, 0.17447286108692428, 0.18057020963825143, 0.069469538959819, 0.07328069601511111, 0.07035282999227888, 0.06782964451667794, 0.06595235733125848, 0.07673202382832855, 0.06658488287699582, 0.06402958803093284, 0.06883437223397781]}, "mutation_prompt": null}
{"id": "32d73b64-1784-49a1-ae29-90f7b670dc8c", "solution": "import numpy as np\n\nclass ADEDSOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * self.dim\n        self.scale_factor = 0.5\n        self.crossover_rate = 0.7\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.eval_count = 0\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Mutation with dynamic scale factor adjustment\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = self.population[indices]\n                dynamic_factor = np.abs(np.random.normal(self.scale_factor, 0.1))\n                mutant = a + dynamic_factor * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with adaptive probability\n                crossover_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover_points, mutant, self.population[i])\n\n                # Evaluate\n                trial_fitness = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n\n            # Dynamic adaptation of parameters\n            self.scale_factor = 0.4 + 0.6 * (1 - self.eval_count / self.budget)\n            self.crossover_rate = 0.2 + 0.8 * (self.eval_count / self.budget)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "ADEDSOptimizer", "description": "Adaptive Differential Evolution with Dynamic Mutation Control for enhanced balance between exploration and exploitation.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "1ed9e574-d02e-4314-a9dd-d8c98645349f", "metadata": {"aucs": [0.6348191525549249, 0.6398294088441203, 0.6189615068906968, 0.6427883063423934, 0.6379700556488541, 0.6544357321509856, 0.626312032992993, 0.654111260682031, 0.6330879307955339, 0.39451913985146947, 0.3864893795151132, 0.3802988159561892, 0.37486744127393057, 0.39331007755475966, 0.3710821079628672, 0.39950595479125395, 0.396381228477801, 0.3849055425717939, 0.1258640024800447, 0.18984798095353606, 0.12006601044989096, 0.12482806185352768, 0.11020873747928506, 0.14320014207944154, 0.14566337165943566, 0.15938482951502886, 0.12111360137186367, 0.1253900526725391, 0.11093121279189067, 0.11959542547723834, 0.11102843935779072, 0.10700289987287093, 0.1138303954150286, 0.1325969405792211, 0.12040432847837224, 0.09890684181146914, 0.9284997712393134, 0.94538996946205, 0.959976416352898, 0.9521372893229908, 0.9319892371064966, 0.9569611819904994, 0.9359848362322941, 0.9397032714081317, 0.964820567561964, 0.20637610996135414, 0.20033826443484293, 0.20400992396637374, 0.20281206280695185, 0.2307392279764553, 0.2211737928639803, 0.23275222374467053, 0.2309705615029477, 0.210201061893857, 0.30447272860168306, 0.31664753220079733, 0.3352956375137315, 0.3411040183891052, 0.33871116147853186, 0.3435825487592863, 0.3254832723077409, 0.27459676890827955, 0.3166644375651998, 0.13951016433891195, 0.13450905160865112, 0.11111699235445771, 0.13165289469305985, 0.10702819105009398, 0.1655520162916433, 0.13296462376794138, 0.13536525317533177, 0.13558281193261024, 0.11099150024420179, 0.12234499286150691, 0.09515346232863142, 0.1260177107718291, 0.13790477910932764, 0.1362251721165152, 0.10890895095055819, 0.12229612820224389, 0.1099906963004631, 0.023152285409000384, 0.022739300301207743, 0.023841488190800342, 0.024841448419786638, 0.023542677966649217, 0.02620032158476393, 0.02657258678227281, 0.030235937197003127, 0.03182893974884571, 0.1092094842138609, 0.08393824730209476, 0.1156599896402033, 0.08744622201602126, 0.08597364426001308, 0.11199772890995408, 0.12396439523756941, 0.1260926873167597, 0.15835528922868447, 0.00935764602051714, 0.01751648440158826, 0.011192089139561934, 0.016557693425984454, 0.025467678329099575, 0.014231670925829887, 0.01612106216572995, 0.019110433296703144, 0.021347430298373937, 0.09458146735473916, 0.09268956821091412, 0.08715396420735866, 0.09962571263255382, 0.10296440623234282, 0.08769788189318373, 0.09115823893695618, 0.10108903738339958, 0.09280879322744007, 0.41518469832371907, 0.3992915004170968, 0.42389069634306653, 0.4444494579503101, 0.4341864463918329, 0.4268067402316087, 0.45432686581744053, 0.4220396512233747, 0.4363429372629185, 0.08944131358973118, 0.07967187428541633, 0.07598510654396562, 0.09267164202459777, 0.07782430935739337, 0.06906242783971828, 0.0828028661468686, 0.08667894167589962, 0.07899011310172954, 0.1524719757422789, 0.16242532725584968, 0.14342510135173903, 0.13656971400346862, 0.14807472696283042, 0.13586553498821574, 0.1503201033944066, 0.13270719855868207, 0.12848786087796815, 0.2257991836260277, 0.23456069484128206, 0.22944168169739365, 0.24469495961383614, 0.24563771461806216, 0.2398947104801119, 0.2746846681053011, 0.25117237169882745, 0.25069310365140196, 0.17879284023825093, 0.15703788609258118, 0.1826704778127931, 0.17505819341828033, 0.1638806328181205, 0.16107408666235912, 0.19130304615625948, 0.17711265904177487, 0.16779794498866996, 0.18131148109272055, 0.17264522226534407, 0.1734693791004589, 0.18427084050779619, 0.17148758019564248, 0.17801943102878448, 0.17955491320461991, 0.1755684810929966, 0.18194974322330248, 0.16959069226542578, 0.18933050179748212, 0.18579845766644676, 0.17160879653926953, 0.2119202090690926, 0.17809148025932098, 0.18006054352914946, 0.18553612556097787, 0.1775349877109309, 0.29016134864790233, 0.27752544829618386, 0.1814063611999175, 0.23863188018211, 0.23291099365583412, 0.19495318869404887, 0.16574626534092474, 0.26748938911932096, 0.24784745179882317, 0.1702951410708331, 0.1846333600790072, 0.3310650404229818, 0.20718493734871146, 0.20312648516773912, 0.17558054088975628, 0.3086500872330171, 0.31574399361172256, 0.2721925626015146, 0.18593079349941033, 0.17871946124696825, 0.1819580195619086, 0.179213722838946, 0.19121013492857775, 0.18995396103695283, 0.18068828559471184, 0.17447286108692428, 0.18057020963825143, 0.069469538959819, 0.07328069601511111, 0.07035282999227888, 0.06782964451667794, 0.06595235733125848, 0.07673202382832855, 0.06658488287699582, 0.06402958803093284, 0.06883437223397781]}, "mutation_prompt": null}
{"id": "5b516984-b0e7-412d-ad23-4dd82a5c7512", "solution": "import numpy as np\n\nclass ADEDSOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * self.dim\n        self.scale_factor = 0.5\n        self.crossover_rate = 0.7\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.eval_count = 0\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Mutation with dynamic scale factor adjustment\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = self.population[indices]\n                dynamic_factor = np.abs(np.random.normal(self.scale_factor, 0.1))\n                mutant = a + dynamic_factor * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with adaptive probability\n                crossover_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover_points, mutant, self.population[i])\n\n                # Evaluate\n                trial_fitness = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n\n            # Dynamic adaptation of parameters\n            self.scale_factor = 0.4 + 0.6 * (1 - self.eval_count / self.budget)\n            self.crossover_rate = 0.2 + 0.8 * (self.eval_count / self.budget)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "ADEDSOptimizer", "description": "Adaptive Differential Evolution with Dynamic Mutation Control for enhanced balance between exploration and exploitation.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "1ed9e574-d02e-4314-a9dd-d8c98645349f", "metadata": {"aucs": [0.6348191525549249, 0.6398294088441203, 0.6189615068906968, 0.6427883063423934, 0.6379700556488541, 0.6544357321509856, 0.626312032992993, 0.654111260682031, 0.6330879307955339, 0.39451913985146947, 0.3864893795151132, 0.3802988159561892, 0.37486744127393057, 0.39331007755475966, 0.3710821079628672, 0.39950595479125395, 0.396381228477801, 0.3849055425717939, 0.1258640024800447, 0.18984798095353606, 0.12006601044989096, 0.12482806185352768, 0.11020873747928506, 0.14320014207944154, 0.14566337165943566, 0.15938482951502886, 0.12111360137186367, 0.1253900526725391, 0.11093121279189067, 0.11959542547723834, 0.11102843935779072, 0.10700289987287093, 0.1138303954150286, 0.1325969405792211, 0.12040432847837224, 0.09890684181146914, 0.9284997712393134, 0.94538996946205, 0.959976416352898, 0.9521372893229908, 0.9319892371064966, 0.9569611819904994, 0.9359848362322941, 0.9397032714081317, 0.964820567561964, 0.20637610996135414, 0.20033826443484293, 0.20400992396637374, 0.20281206280695185, 0.2307392279764553, 0.2211737928639803, 0.23275222374467053, 0.2309705615029477, 0.210201061893857, 0.30447272860168306, 0.31664753220079733, 0.3352956375137315, 0.3411040183891052, 0.33871116147853186, 0.3435825487592863, 0.3254832723077409, 0.27459676890827955, 0.3166644375651998, 0.13951016433891195, 0.13450905160865112, 0.11111699235445771, 0.13165289469305985, 0.10702819105009398, 0.1655520162916433, 0.13296462376794138, 0.13536525317533177, 0.13558281193261024, 0.11099150024420179, 0.12234499286150691, 0.09515346232863142, 0.1260177107718291, 0.13790477910932764, 0.1362251721165152, 0.10890895095055819, 0.12229612820224389, 0.1099906963004631, 0.023152285409000384, 0.022739300301207743, 0.023841488190800342, 0.024841448419786638, 0.023542677966649217, 0.02620032158476393, 0.02657258678227281, 0.030235937197003127, 0.03182893974884571, 0.1092094842138609, 0.08393824730209476, 0.1156599896402033, 0.08744622201602126, 0.08597364426001308, 0.11199772890995408, 0.12396439523756941, 0.1260926873167597, 0.15835528922868447, 0.00935764602051714, 0.01751648440158826, 0.011192089139561934, 0.016557693425984454, 0.025467678329099575, 0.014231670925829887, 0.01612106216572995, 0.019110433296703144, 0.021347430298373937, 0.09458146735473916, 0.09268956821091412, 0.08715396420735866, 0.09962571263255382, 0.10296440623234282, 0.08769788189318373, 0.09115823893695618, 0.10108903738339958, 0.09280879322744007, 0.41518469832371907, 0.3992915004170968, 0.42389069634306653, 0.4444494579503101, 0.4341864463918329, 0.4268067402316087, 0.45432686581744053, 0.4220396512233747, 0.4363429372629185, 0.08944131358973118, 0.07967187428541633, 0.07598510654396562, 0.09267164202459777, 0.07782430935739337, 0.06906242783971828, 0.0828028661468686, 0.08667894167589962, 0.07899011310172954, 0.1524719757422789, 0.16242532725584968, 0.14342510135173903, 0.13656971400346862, 0.14807472696283042, 0.13586553498821574, 0.1503201033944066, 0.13270719855868207, 0.12848786087796815, 0.2257991836260277, 0.23456069484128206, 0.22944168169739365, 0.24469495961383614, 0.24563771461806216, 0.2398947104801119, 0.2746846681053011, 0.25117237169882745, 0.25069310365140196, 0.17879284023825093, 0.15703788609258118, 0.1826704778127931, 0.17505819341828033, 0.1638806328181205, 0.16107408666235912, 0.19130304615625948, 0.17711265904177487, 0.16779794498866996, 0.18131148109272055, 0.17264522226534407, 0.1734693791004589, 0.18427084050779619, 0.17148758019564248, 0.17801943102878448, 0.17955491320461991, 0.1755684810929966, 0.18194974322330248, 0.16959069226542578, 0.18933050179748212, 0.18579845766644676, 0.17160879653926953, 0.2119202090690926, 0.17809148025932098, 0.18006054352914946, 0.18553612556097787, 0.1775349877109309, 0.29016134864790233, 0.27752544829618386, 0.1814063611999175, 0.23863188018211, 0.23291099365583412, 0.19495318869404887, 0.16574626534092474, 0.26748938911932096, 0.24784745179882317, 0.1702951410708331, 0.1846333600790072, 0.3310650404229818, 0.20718493734871146, 0.20312648516773912, 0.17558054088975628, 0.3086500872330171, 0.31574399361172256, 0.2721925626015146, 0.18593079349941033, 0.17871946124696825, 0.1819580195619086, 0.179213722838946, 0.19121013492857775, 0.18995396103695283, 0.18068828559471184, 0.17447286108692428, 0.18057020963825143, 0.069469538959819, 0.07328069601511111, 0.07035282999227888, 0.06782964451667794, 0.06595235733125848, 0.07673202382832855, 0.06658488287699582, 0.06402958803093284, 0.06883437223397781]}, "mutation_prompt": null}
{"id": "a66f05dd-b130-4872-8cf6-11e039e0b5c0", "solution": "import numpy as np\n\nclass ADEDSOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * self.dim\n        self.scale_factor = 0.5\n        self.crossover_rate = 0.7\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.eval_count = 0\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Mutation with dynamic scale factor adjustment\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = self.population[indices]\n                dynamic_factor = np.abs(np.random.normal(self.scale_factor, 0.1))\n                mutant = a + dynamic_factor * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with adaptive probability\n                crossover_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover_points, mutant, self.population[i])\n\n                # Evaluate\n                trial_fitness = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n\n            # Dynamic adaptation of parameters\n            self.scale_factor = 0.4 + 0.6 * (1 - self.eval_count / self.budget)\n            self.crossover_rate = 0.2 + 0.8 * (self.eval_count / self.budget)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "ADEDSOptimizer", "description": "Adaptive Differential Evolution with Dynamic Mutation Control for enhanced balance between exploration and exploitation.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "1ed9e574-d02e-4314-a9dd-d8c98645349f", "metadata": {"aucs": [0.6348191525549249, 0.6398294088441203, 0.6189615068906968, 0.6427883063423934, 0.6379700556488541, 0.6544357321509856, 0.626312032992993, 0.654111260682031, 0.6330879307955339, 0.39451913985146947, 0.3864893795151132, 0.3802988159561892, 0.37486744127393057, 0.39331007755475966, 0.3710821079628672, 0.39950595479125395, 0.396381228477801, 0.3849055425717939, 0.1258640024800447, 0.18984798095353606, 0.12006601044989096, 0.12482806185352768, 0.11020873747928506, 0.14320014207944154, 0.14566337165943566, 0.15938482951502886, 0.12111360137186367, 0.1253900526725391, 0.11093121279189067, 0.11959542547723834, 0.11102843935779072, 0.10700289987287093, 0.1138303954150286, 0.1325969405792211, 0.12040432847837224, 0.09890684181146914, 0.9284997712393134, 0.94538996946205, 0.959976416352898, 0.9521372893229908, 0.9319892371064966, 0.9569611819904994, 0.9359848362322941, 0.9397032714081317, 0.964820567561964, 0.20637610996135414, 0.20033826443484293, 0.20400992396637374, 0.20281206280695185, 0.2307392279764553, 0.2211737928639803, 0.23275222374467053, 0.2309705615029477, 0.210201061893857, 0.30447272860168306, 0.31664753220079733, 0.3352956375137315, 0.3411040183891052, 0.33871116147853186, 0.3435825487592863, 0.3254832723077409, 0.27459676890827955, 0.3166644375651998, 0.13951016433891195, 0.13450905160865112, 0.11111699235445771, 0.13165289469305985, 0.10702819105009398, 0.1655520162916433, 0.13296462376794138, 0.13536525317533177, 0.13558281193261024, 0.11099150024420179, 0.12234499286150691, 0.09515346232863142, 0.1260177107718291, 0.13790477910932764, 0.1362251721165152, 0.10890895095055819, 0.12229612820224389, 0.1099906963004631, 0.023152285409000384, 0.022739300301207743, 0.023841488190800342, 0.024841448419786638, 0.023542677966649217, 0.02620032158476393, 0.02657258678227281, 0.030235937197003127, 0.03182893974884571, 0.1092094842138609, 0.08393824730209476, 0.1156599896402033, 0.08744622201602126, 0.08597364426001308, 0.11199772890995408, 0.12396439523756941, 0.1260926873167597, 0.15835528922868447, 0.00935764602051714, 0.01751648440158826, 0.011192089139561934, 0.016557693425984454, 0.025467678329099575, 0.014231670925829887, 0.01612106216572995, 0.019110433296703144, 0.021347430298373937, 0.09458146735473916, 0.09268956821091412, 0.08715396420735866, 0.09962571263255382, 0.10296440623234282, 0.08769788189318373, 0.09115823893695618, 0.10108903738339958, 0.09280879322744007, 0.41518469832371907, 0.3992915004170968, 0.42389069634306653, 0.4444494579503101, 0.4341864463918329, 0.4268067402316087, 0.45432686581744053, 0.4220396512233747, 0.4363429372629185, 0.08944131358973118, 0.07967187428541633, 0.07598510654396562, 0.09267164202459777, 0.07782430935739337, 0.06906242783971828, 0.0828028661468686, 0.08667894167589962, 0.07899011310172954, 0.1524719757422789, 0.16242532725584968, 0.14342510135173903, 0.13656971400346862, 0.14807472696283042, 0.13586553498821574, 0.1503201033944066, 0.13270719855868207, 0.12848786087796815, 0.2257991836260277, 0.23456069484128206, 0.22944168169739365, 0.24469495961383614, 0.24563771461806216, 0.2398947104801119, 0.2746846681053011, 0.25117237169882745, 0.25069310365140196, 0.17879284023825093, 0.15703788609258118, 0.1826704778127931, 0.17505819341828033, 0.1638806328181205, 0.16107408666235912, 0.19130304615625948, 0.17711265904177487, 0.16779794498866996, 0.18131148109272055, 0.17264522226534407, 0.1734693791004589, 0.18427084050779619, 0.17148758019564248, 0.17801943102878448, 0.17955491320461991, 0.1755684810929966, 0.18194974322330248, 0.16959069226542578, 0.18933050179748212, 0.18579845766644676, 0.17160879653926953, 0.2119202090690926, 0.17809148025932098, 0.18006054352914946, 0.18553612556097787, 0.1775349877109309, 0.29016134864790233, 0.27752544829618386, 0.1814063611999175, 0.23863188018211, 0.23291099365583412, 0.19495318869404887, 0.16574626534092474, 0.26748938911932096, 0.24784745179882317, 0.1702951410708331, 0.1846333600790072, 0.3310650404229818, 0.20718493734871146, 0.20312648516773912, 0.17558054088975628, 0.3086500872330171, 0.31574399361172256, 0.2721925626015146, 0.18593079349941033, 0.17871946124696825, 0.1819580195619086, 0.179213722838946, 0.19121013492857775, 0.18995396103695283, 0.18068828559471184, 0.17447286108692428, 0.18057020963825143, 0.069469538959819, 0.07328069601511111, 0.07035282999227888, 0.06782964451667794, 0.06595235733125848, 0.07673202382832855, 0.06658488287699582, 0.06402958803093284, 0.06883437223397781]}, "mutation_prompt": null}
{"id": "b255e9c8-3ac2-411f-8fc5-84d7654b0150", "solution": "import numpy as np\n\nclass ADEDSOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * self.dim\n        self.scale_factor = 0.5\n        self.crossover_rate = 0.7\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.eval_count = 0\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Mutation with dynamic scale factor adjustment\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = self.population[indices]\n                dynamic_factor = np.abs(np.random.normal(self.scale_factor, 0.1))\n                mutant = a + dynamic_factor * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with adaptive probability\n                crossover_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover_points, mutant, self.population[i])\n\n                # Evaluate\n                trial_fitness = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n\n            # Dynamic adaptation of parameters\n            self.scale_factor = 0.4 + 0.6 * (1 - self.eval_count / self.budget)\n            self.crossover_rate = 0.2 + 0.8 * (self.eval_count / self.budget)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "ADEDSOptimizer", "description": "Adaptive Differential Evolution with Dynamic Mutation Control for enhanced balance between exploration and exploitation.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "1ed9e574-d02e-4314-a9dd-d8c98645349f", "metadata": {"aucs": [0.6348191525549249, 0.6398294088441203, 0.6189615068906968, 0.6427883063423934, 0.6379700556488541, 0.6544357321509856, 0.626312032992993, 0.654111260682031, 0.6330879307955339, 0.39451913985146947, 0.3864893795151132, 0.3802988159561892, 0.37486744127393057, 0.39331007755475966, 0.3710821079628672, 0.39950595479125395, 0.396381228477801, 0.3849055425717939, 0.1258640024800447, 0.18984798095353606, 0.12006601044989096, 0.12482806185352768, 0.11020873747928506, 0.14320014207944154, 0.14566337165943566, 0.15938482951502886, 0.12111360137186367, 0.1253900526725391, 0.11093121279189067, 0.11959542547723834, 0.11102843935779072, 0.10700289987287093, 0.1138303954150286, 0.1325969405792211, 0.12040432847837224, 0.09890684181146914, 0.9284997712393134, 0.94538996946205, 0.959976416352898, 0.9521372893229908, 0.9319892371064966, 0.9569611819904994, 0.9359848362322941, 0.9397032714081317, 0.964820567561964, 0.20637610996135414, 0.20033826443484293, 0.20400992396637374, 0.20281206280695185, 0.2307392279764553, 0.2211737928639803, 0.23275222374467053, 0.2309705615029477, 0.210201061893857, 0.30447272860168306, 0.31664753220079733, 0.3352956375137315, 0.3411040183891052, 0.33871116147853186, 0.3435825487592863, 0.3254832723077409, 0.27459676890827955, 0.3166644375651998, 0.13951016433891195, 0.13450905160865112, 0.11111699235445771, 0.13165289469305985, 0.10702819105009398, 0.1655520162916433, 0.13296462376794138, 0.13536525317533177, 0.13558281193261024, 0.11099150024420179, 0.12234499286150691, 0.09515346232863142, 0.1260177107718291, 0.13790477910932764, 0.1362251721165152, 0.10890895095055819, 0.12229612820224389, 0.1099906963004631, 0.023152285409000384, 0.022739300301207743, 0.023841488190800342, 0.024841448419786638, 0.023542677966649217, 0.02620032158476393, 0.02657258678227281, 0.030235937197003127, 0.03182893974884571, 0.1092094842138609, 0.08393824730209476, 0.1156599896402033, 0.08744622201602126, 0.08597364426001308, 0.11199772890995408, 0.12396439523756941, 0.1260926873167597, 0.15835528922868447, 0.00935764602051714, 0.01751648440158826, 0.011192089139561934, 0.016557693425984454, 0.025467678329099575, 0.014231670925829887, 0.01612106216572995, 0.019110433296703144, 0.021347430298373937, 0.09458146735473916, 0.09268956821091412, 0.08715396420735866, 0.09962571263255382, 0.10296440623234282, 0.08769788189318373, 0.09115823893695618, 0.10108903738339958, 0.09280879322744007, 0.41518469832371907, 0.3992915004170968, 0.42389069634306653, 0.4444494579503101, 0.4341864463918329, 0.4268067402316087, 0.45432686581744053, 0.4220396512233747, 0.4363429372629185, 0.08944131358973118, 0.07967187428541633, 0.07598510654396562, 0.09267164202459777, 0.07782430935739337, 0.06906242783971828, 0.0828028661468686, 0.08667894167589962, 0.07899011310172954, 0.1524719757422789, 0.16242532725584968, 0.14342510135173903, 0.13656971400346862, 0.14807472696283042, 0.13586553498821574, 0.1503201033944066, 0.13270719855868207, 0.12848786087796815, 0.2257991836260277, 0.23456069484128206, 0.22944168169739365, 0.24469495961383614, 0.24563771461806216, 0.2398947104801119, 0.2746846681053011, 0.25117237169882745, 0.25069310365140196, 0.17879284023825093, 0.15703788609258118, 0.1826704778127931, 0.17505819341828033, 0.1638806328181205, 0.16107408666235912, 0.19130304615625948, 0.17711265904177487, 0.16779794498866996, 0.18131148109272055, 0.17264522226534407, 0.1734693791004589, 0.18427084050779619, 0.17148758019564248, 0.17801943102878448, 0.17955491320461991, 0.1755684810929966, 0.18194974322330248, 0.16959069226542578, 0.18933050179748212, 0.18579845766644676, 0.17160879653926953, 0.2119202090690926, 0.17809148025932098, 0.18006054352914946, 0.18553612556097787, 0.1775349877109309, 0.29016134864790233, 0.27752544829618386, 0.1814063611999175, 0.23863188018211, 0.23291099365583412, 0.19495318869404887, 0.16574626534092474, 0.26748938911932096, 0.24784745179882317, 0.1702951410708331, 0.1846333600790072, 0.3310650404229818, 0.20718493734871146, 0.20312648516773912, 0.17558054088975628, 0.3086500872330171, 0.31574399361172256, 0.2721925626015146, 0.18593079349941033, 0.17871946124696825, 0.1819580195619086, 0.179213722838946, 0.19121013492857775, 0.18995396103695283, 0.18068828559471184, 0.17447286108692428, 0.18057020963825143, 0.069469538959819, 0.07328069601511111, 0.07035282999227888, 0.06782964451667794, 0.06595235733125848, 0.07673202382832855, 0.06658488287699582, 0.06402958803093284, 0.06883437223397781]}, "mutation_prompt": null}
{"id": "5a102d74-6c79-4d7f-90fa-a0f63361c7e5", "solution": "import numpy as np\n\nclass DCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.3)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean += np.dot(weights, selected - self.mean)\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "DCMAESOptimizer", "description": "Dynamic Covariance Matrix Adaptation Evolution Strategy (DCMA-ES) tailored with feedback-driven self-adaptation of strategy parameters.", "configspace": "", "generation": 18, "fitness": 0.23770035643599569, "feedback": "The algorithm DCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.23.", "error": "", "parent_id": "1ed9e574-d02e-4314-a9dd-d8c98645349f", "metadata": {"aucs": [0.8014806973055866, 0.8358980558988997, 0.8291976485995799, 0.7941651959799176, 0.8128239408337135, 0.8797587038109886, 0.8860677824518267, 0.8205888576047901, 0.833366431316752, 0.4793369605385459, 0.37127449826039716, 0.4599585812487873, 0.4840984969880967, 0.4888003142387133, 0.46762626383710637, 0.35074531093363204, 0.43681859110379584, 0.5162763810592278, 0.08176633037132919, 0.09045753440556814, 0.07950106240172294, 0.0965257605850185, 0.0825453059457697, 0.08102446741089897, 0.08353371304042845, 0.08468915643590247, 0.08994738353113407, 0.03491405596637265, 0.0545101137523718, 0.052940146370301755, 0.04959179784535461, 0.039114943166644656, 0.04118015044288126, 0.059680585592965185, 0.05732695867472759, 0.03298258525042985, 0.9585045895078593, 0.8967492099312204, 0.7813922208827235, 0.9173855986720169, 0.9157256559993987, 0.794618644948665, 0.6022275653205145, 0.9511468397707423, 0.9661652433296222, 0.09053684364298153, 0.08974591179477465, 0.08711285849728778, 0.10080183090540618, 0.11566227074375424, 0.1774833860345818, 0.10600581384010366, 0.09848258405029608, 0.10986109730208449, 0.3022128952008404, 0.2628526233817863, 0.5266157965469996, 0.3658589026751248, 0.2357324718090109, 0.3280451939205993, 0.2900788151678567, 0.29164142518921266, 0.2734259590438801, 0.12590182225797109, 0.1472031375208286, 0.15669313002402685, 0.14303218196673173, 0.13315001506208668, 0.18413968015262294, 0.16260376179667324, 0.13612586348724742, 0.1134764664620066, 0.15732683601105402, 0.11814101042932201, 0.1056329446217058, 0.14235759804221504, 0.17817519012574845, 0.19562063978845945, 0.1638468324940845, 0.14285298282765402, 0.10542314091178284, 9.999999999998899e-05, 0.00016358001984173587, 9.999999999998899e-05, 9.999999999998899e-05, 0.09631224860321141, 9.999999999998899e-05, 9.999999999998899e-05, 0.06698625291697169, 0.004300169788878705, 0.07894974992511583, 0.058493831604142676, 0.1000709627193217, 0.12824414216793434, 0.058833016760291845, 0.05793910026901472, 0.08990146752567763, 0.0913999533312091, 0.0718369529994558, 0.017335207826943533, 0.13490425571052567, 0.06744965642811096, 0.1367392736118852, 0.14200372381861093, 0.07853771392211073, 0.15021410699327042, 0.11830824238129445, 0.12015985942950014, 0.42596267547427824, 0.2968986086355371, 0.2285450329967813, 0.4379652138466765, 0.3937776085120108, 0.29228492019903474, 0.4740589493361079, 0.15522547566364808, 0.5281439210251319, 0.636014884093757, 0.4830453951384337, 0.47703831865212043, 0.45166526995597034, 0.44317236171834695, 0.7010653366022983, 0.7233925671861468, 0.4883179290285373, 0.6398384007181426, 0.09074001811897758, 0.11447487284723334, 0.08599945254513675, 0.10445296239121105, 0.07936453511213548, 0.0902022023411515, 0.07610180159147617, 0.07515634191794962, 0.06674644755198988, 0.14022114818226294, 0.17554822439945406, 0.13359783446297246, 0.1409317284612791, 0.14092198360658326, 0.173145445585847, 0.1449018995448389, 0.13942587974498477, 0.12232620957981266, 0.28376739659617134, 0.22381707669572792, 0.2601819829713049, 0.26952781511886026, 0.2157964862317372, 0.2178078272205336, 0.2642683756273435, 0.23100316439009871, 0.20065644798030202, 0.17742319564079212, 0.15412023236126593, 0.1810101519066759, 0.16004458854665715, 0.1702387126095477, 0.1516491258663939, 0.156661141434705, 0.1994859781121351, 0.17330634449843418, 0.19993708169671176, 0.19048025195359986, 0.16724013546566252, 0.1907040780597128, 0.19520819839333414, 0.17850112741899826, 0.1833145714205161, 0.19171286471924376, 0.17561415061767005, 0.17488737360461093, 0.18460204910281852, 0.176939782836949, 0.17452577824083526, 0.18107762546836048, 0.17131717162742865, 0.18021118620234522, 0.1741440754844623, 0.1784250139988841, 0.15879164141693258, 0.16082910616076262, 0.17264970519403666, 0.17365134524246517, 0.15506891738962314, 0.1464547940763723, 0.1587999886323549, 0.136946766671451, 0.15788650229594003, 0.17045161151046762, 0.11341698965273606, 0.08312855118409768, 0.16858208476913716, 0.16848174449937592, 0.16626748291694926, 0.20970016121485302, 0.20581584844571754, 0.11222534786131122, 0.1857834028736911, 0.201541362708058, 0.19182533851673378, 0.18152758673360014, 0.19046476353487107, 0.17098304755913918, 0.18416765744607277, 0.1951861190240901, 0.18837431136735427, 0.07858697649318669, 0.06910253444303494, 0.07685981900388472, 0.06763231100865907, 0.06660814129602255, 0.07802661596948401, 0.06826479334851698, 0.0744118850802512, 0.06662760369968368]}, "mutation_prompt": null}
{"id": "2bc8ed8b-dd40-4a5f-9d55-599305270e84", "solution": "import numpy as np\n\nclass DCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.3)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean += np.dot(weights, selected - self.mean)\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "DCMAESOptimizer", "description": "Dynamic Covariance Matrix Adaptation Evolution Strategy (DCMA-ES) tailored with feedback-driven self-adaptation of strategy parameters.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5a102d74-6c79-4d7f-90fa-a0f63361c7e5", "metadata": {"aucs": [0.8014806973055866, 0.8358980558988997, 0.8291976485995799, 0.7941651959799176, 0.8128239408337135, 0.8797587038109886, 0.8860677824518267, 0.8205888576047901, 0.833366431316752, 0.4793369605385459, 0.37127449826039716, 0.4599585812487873, 0.4840984969880967, 0.4888003142387133, 0.46762626383710637, 0.35074531093363204, 0.43681859110379584, 0.5162763810592278, 0.08176633037132919, 0.09045753440556814, 0.07950106240172294, 0.0965257605850185, 0.0825453059457697, 0.08102446741089897, 0.08353371304042845, 0.08468915643590247, 0.08994738353113407, 0.03491405596637265, 0.0545101137523718, 0.052940146370301755, 0.04959179784535461, 0.039114943166644656, 0.04118015044288126, 0.059680585592965185, 0.05732695867472759, 0.03298258525042985, 0.9585045895078593, 0.8967492099312204, 0.7813922208827235, 0.9173855986720169, 0.9157256559993987, 0.794618644948665, 0.6022275653205145, 0.9511468397707423, 0.9661652433296222, 0.09053684364298153, 0.08974591179477465, 0.08711285849728778, 0.10080183090540618, 0.11566227074375424, 0.1774833860345818, 0.10600581384010366, 0.09848258405029608, 0.10986109730208449, 0.3022128952008404, 0.2628526233817863, 0.5266157965469996, 0.3658589026751248, 0.2357324718090109, 0.3280451939205993, 0.2900788151678567, 0.29164142518921266, 0.2734259590438801, 0.12590182225797109, 0.1472031375208286, 0.15669313002402685, 0.14303218196673173, 0.13315001506208668, 0.18413968015262294, 0.16260376179667324, 0.13612586348724742, 0.1134764664620066, 0.15732683601105402, 0.11814101042932201, 0.1056329446217058, 0.14235759804221504, 0.17817519012574845, 0.19562063978845945, 0.1638468324940845, 0.14285298282765402, 0.10542314091178284, 9.999999999998899e-05, 0.00016358001984173587, 9.999999999998899e-05, 9.999999999998899e-05, 0.09631224860321141, 9.999999999998899e-05, 9.999999999998899e-05, 0.06698625291697169, 0.004300169788878705, 0.07894974992511583, 0.058493831604142676, 0.1000709627193217, 0.12824414216793434, 0.058833016760291845, 0.05793910026901472, 0.08990146752567763, 0.0913999533312091, 0.0718369529994558, 0.017335207826943533, 0.13490425571052567, 0.06744965642811096, 0.1367392736118852, 0.14200372381861093, 0.07853771392211073, 0.15021410699327042, 0.11830824238129445, 0.12015985942950014, 0.42596267547427824, 0.2968986086355371, 0.2285450329967813, 0.4379652138466765, 0.3937776085120108, 0.29228492019903474, 0.4740589493361079, 0.15522547566364808, 0.5281439210251319, 0.636014884093757, 0.4830453951384337, 0.47703831865212043, 0.45166526995597034, 0.44317236171834695, 0.7010653366022983, 0.7233925671861468, 0.4883179290285373, 0.6398384007181426, 0.09074001811897758, 0.11447487284723334, 0.08599945254513675, 0.10445296239121105, 0.07936453511213548, 0.0902022023411515, 0.07610180159147617, 0.07515634191794962, 0.06674644755198988, 0.14022114818226294, 0.17554822439945406, 0.13359783446297246, 0.1409317284612791, 0.14092198360658326, 0.173145445585847, 0.1449018995448389, 0.13942587974498477, 0.12232620957981266, 0.28376739659617134, 0.22381707669572792, 0.2601819829713049, 0.26952781511886026, 0.2157964862317372, 0.2178078272205336, 0.2642683756273435, 0.23100316439009871, 0.20065644798030202, 0.17742319564079212, 0.15412023236126593, 0.1810101519066759, 0.16004458854665715, 0.1702387126095477, 0.1516491258663939, 0.156661141434705, 0.1994859781121351, 0.17330634449843418, 0.19993708169671176, 0.19048025195359986, 0.16724013546566252, 0.1907040780597128, 0.19520819839333414, 0.17850112741899826, 0.1833145714205161, 0.19171286471924376, 0.17561415061767005, 0.17488737360461093, 0.18460204910281852, 0.176939782836949, 0.17452577824083526, 0.18107762546836048, 0.17131717162742865, 0.18021118620234522, 0.1741440754844623, 0.1784250139988841, 0.15879164141693258, 0.16082910616076262, 0.17264970519403666, 0.17365134524246517, 0.15506891738962314, 0.1464547940763723, 0.1587999886323549, 0.136946766671451, 0.15788650229594003, 0.17045161151046762, 0.11341698965273606, 0.08312855118409768, 0.16858208476913716, 0.16848174449937592, 0.16626748291694926, 0.20970016121485302, 0.20581584844571754, 0.11222534786131122, 0.1857834028736911, 0.201541362708058, 0.19182533851673378, 0.18152758673360014, 0.19046476353487107, 0.17098304755913918, 0.18416765744607277, 0.1951861190240901, 0.18837431136735427, 0.07858697649318669, 0.06910253444303494, 0.07685981900388472, 0.06763231100865907, 0.06660814129602255, 0.07802661596948401, 0.06826479334851698, 0.0744118850802512, 0.06662760369968368]}, "mutation_prompt": null}
{"id": "aa948287-7f86-440d-b8e9-0d396510b553", "solution": "import numpy as np\n\nclass APCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n        self.dynamic_population = True  # Allow dynamic population size\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.3)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            if self.dynamic_population and self.eval_count > self.budget / 2:\n                # Reduce population size dynamically in the second half of the budget\n                self.population_size = max(2, int(self.population_size * 0.75))\n                weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n                weights /= np.sum(weights)\n\n            samples = np.random.multivariate_normal(self.mean, self.step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean += np.dot(weights, selected - self.mean)\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "APCMAESOptimizer", "description": "Adaptive Population Size Covariance Matrix Adaptation Evolution Strategy with Dynamic Feedback Mechanisms for Enhanced Optimization.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 7 is out of bounds for axis 0 with size 6').", "error": "IndexError('index 7 is out of bounds for axis 0 with size 6')", "parent_id": "5a102d74-6c79-4d7f-90fa-a0f63361c7e5", "metadata": {}, "mutation_prompt": null}
{"id": "6630b75f-88d6-4e61-bdc7-bb7c0ac2b0ee", "solution": "import numpy as np\n\nclass DCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.3)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean += np.dot(weights, selected - self.mean)\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "DCMAESOptimizer", "description": "Dynamic Covariance Matrix Adaptation Evolution Strategy (DCMA-ES) tailored with feedback-driven self-adaptation of strategy parameters.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5a102d74-6c79-4d7f-90fa-a0f63361c7e5", "metadata": {"aucs": [0.8014806973055866, 0.8358980558988997, 0.8291976485995799, 0.7941651959799176, 0.8128239408337135, 0.8797587038109886, 0.8860677824518267, 0.8205888576047901, 0.833366431316752, 0.4793369605385459, 0.37127449826039716, 0.4599585812487873, 0.4840984969880967, 0.4888003142387133, 0.46762626383710637, 0.35074531093363204, 0.43681859110379584, 0.5162763810592278, 0.08176633037132919, 0.09045753440556814, 0.07950106240172294, 0.0965257605850185, 0.0825453059457697, 0.08102446741089897, 0.08353371304042845, 0.08468915643590247, 0.08994738353113407, 0.03491405596637265, 0.0545101137523718, 0.052940146370301755, 0.04959179784535461, 0.039114943166644656, 0.04118015044288126, 0.059680585592965185, 0.05732695867472759, 0.03298258525042985, 0.9585045895078593, 0.8967492099312204, 0.7813922208827235, 0.9173855986720169, 0.9157256559993987, 0.794618644948665, 0.6022275653205145, 0.9511468397707423, 0.9661652433296222, 0.09053684364298153, 0.08974591179477465, 0.08711285849728778, 0.10080183090540618, 0.11566227074375424, 0.1774833860345818, 0.10600581384010366, 0.09848258405029608, 0.10986109730208449, 0.3022128952008404, 0.2628526233817863, 0.5266157965469996, 0.3658589026751248, 0.2357324718090109, 0.3280451939205993, 0.2900788151678567, 0.29164142518921266, 0.2734259590438801, 0.12590182225797109, 0.1472031375208286, 0.15669313002402685, 0.14303218196673173, 0.13315001506208668, 0.18413968015262294, 0.16260376179667324, 0.13612586348724742, 0.1134764664620066, 0.15732683601105402, 0.11814101042932201, 0.1056329446217058, 0.14235759804221504, 0.17817519012574845, 0.19562063978845945, 0.1638468324940845, 0.14285298282765402, 0.10542314091178284, 9.999999999998899e-05, 0.00016358001984173587, 9.999999999998899e-05, 9.999999999998899e-05, 0.09631224860321141, 9.999999999998899e-05, 9.999999999998899e-05, 0.06698625291697169, 0.004300169788878705, 0.07894974992511583, 0.058493831604142676, 0.1000709627193217, 0.12824414216793434, 0.058833016760291845, 0.05793910026901472, 0.08990146752567763, 0.0913999533312091, 0.0718369529994558, 0.017335207826943533, 0.13490425571052567, 0.06744965642811096, 0.1367392736118852, 0.14200372381861093, 0.07853771392211073, 0.15021410699327042, 0.11830824238129445, 0.12015985942950014, 0.42596267547427824, 0.2968986086355371, 0.2285450329967813, 0.4379652138466765, 0.3937776085120108, 0.29228492019903474, 0.4740589493361079, 0.15522547566364808, 0.5281439210251319, 0.636014884093757, 0.4830453951384337, 0.47703831865212043, 0.45166526995597034, 0.44317236171834695, 0.7010653366022983, 0.7233925671861468, 0.4883179290285373, 0.6398384007181426, 0.09074001811897758, 0.11447487284723334, 0.08599945254513675, 0.10445296239121105, 0.07936453511213548, 0.0902022023411515, 0.07610180159147617, 0.07515634191794962, 0.06674644755198988, 0.14022114818226294, 0.17554822439945406, 0.13359783446297246, 0.1409317284612791, 0.14092198360658326, 0.173145445585847, 0.1449018995448389, 0.13942587974498477, 0.12232620957981266, 0.28376739659617134, 0.22381707669572792, 0.2601819829713049, 0.26952781511886026, 0.2157964862317372, 0.2178078272205336, 0.2642683756273435, 0.23100316439009871, 0.20065644798030202, 0.17742319564079212, 0.15412023236126593, 0.1810101519066759, 0.16004458854665715, 0.1702387126095477, 0.1516491258663939, 0.156661141434705, 0.1994859781121351, 0.17330634449843418, 0.19993708169671176, 0.19048025195359986, 0.16724013546566252, 0.1907040780597128, 0.19520819839333414, 0.17850112741899826, 0.1833145714205161, 0.19171286471924376, 0.17561415061767005, 0.17488737360461093, 0.18460204910281852, 0.176939782836949, 0.17452577824083526, 0.18107762546836048, 0.17131717162742865, 0.18021118620234522, 0.1741440754844623, 0.1784250139988841, 0.15879164141693258, 0.16082910616076262, 0.17264970519403666, 0.17365134524246517, 0.15506891738962314, 0.1464547940763723, 0.1587999886323549, 0.136946766671451, 0.15788650229594003, 0.17045161151046762, 0.11341698965273606, 0.08312855118409768, 0.16858208476913716, 0.16848174449937592, 0.16626748291694926, 0.20970016121485302, 0.20581584844571754, 0.11222534786131122, 0.1857834028736911, 0.201541362708058, 0.19182533851673378, 0.18152758673360014, 0.19046476353487107, 0.17098304755913918, 0.18416765744607277, 0.1951861190240901, 0.18837431136735427, 0.07858697649318669, 0.06910253444303494, 0.07685981900388472, 0.06763231100865907, 0.06660814129602255, 0.07802661596948401, 0.06826479334851698, 0.0744118850802512, 0.06662760369968368]}, "mutation_prompt": null}
{"id": "2178690c-326f-43d1-87e5-7e18b220a843", "solution": "import numpy as np\n\nclass DCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.3)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean += np.dot(weights, selected - self.mean)\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "DCMAESOptimizer", "description": "Dynamic Covariance Matrix Adaptation Evolution Strategy (DCMA-ES) tailored with feedback-driven self-adaptation of strategy parameters.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5a102d74-6c79-4d7f-90fa-a0f63361c7e5", "metadata": {"aucs": [0.8014806973055866, 0.8358980558988997, 0.8291976485995799, 0.7941651959799176, 0.8128239408337135, 0.8797587038109886, 0.8860677824518267, 0.8205888576047901, 0.833366431316752, 0.4793369605385459, 0.37127449826039716, 0.4599585812487873, 0.4840984969880967, 0.4888003142387133, 0.46762626383710637, 0.35074531093363204, 0.43681859110379584, 0.5162763810592278, 0.08176633037132919, 0.09045753440556814, 0.07950106240172294, 0.0965257605850185, 0.0825453059457697, 0.08102446741089897, 0.08353371304042845, 0.08468915643590247, 0.08994738353113407, 0.03491405596637265, 0.0545101137523718, 0.052940146370301755, 0.04959179784535461, 0.039114943166644656, 0.04118015044288126, 0.059680585592965185, 0.05732695867472759, 0.03298258525042985, 0.9585045895078593, 0.8967492099312204, 0.7813922208827235, 0.9173855986720169, 0.9157256559993987, 0.794618644948665, 0.6022275653205145, 0.9511468397707423, 0.9661652433296222, 0.09053684364298153, 0.08974591179477465, 0.08711285849728778, 0.10080183090540618, 0.11566227074375424, 0.1774833860345818, 0.10600581384010366, 0.09848258405029608, 0.10986109730208449, 0.3022128952008404, 0.2628526233817863, 0.5266157965469996, 0.3658589026751248, 0.2357324718090109, 0.3280451939205993, 0.2900788151678567, 0.29164142518921266, 0.2734259590438801, 0.12590182225797109, 0.1472031375208286, 0.15669313002402685, 0.14303218196673173, 0.13315001506208668, 0.18413968015262294, 0.16260376179667324, 0.13612586348724742, 0.1134764664620066, 0.15732683601105402, 0.11814101042932201, 0.1056329446217058, 0.14235759804221504, 0.17817519012574845, 0.19562063978845945, 0.1638468324940845, 0.14285298282765402, 0.10542314091178284, 9.999999999998899e-05, 0.00016358001984173587, 9.999999999998899e-05, 9.999999999998899e-05, 0.09631224860321141, 9.999999999998899e-05, 9.999999999998899e-05, 0.06698625291697169, 0.004300169788878705, 0.07894974992511583, 0.058493831604142676, 0.1000709627193217, 0.12824414216793434, 0.058833016760291845, 0.05793910026901472, 0.08990146752567763, 0.0913999533312091, 0.0718369529994558, 0.017335207826943533, 0.13490425571052567, 0.06744965642811096, 0.1367392736118852, 0.14200372381861093, 0.07853771392211073, 0.15021410699327042, 0.11830824238129445, 0.12015985942950014, 0.42596267547427824, 0.2968986086355371, 0.2285450329967813, 0.4379652138466765, 0.3937776085120108, 0.29228492019903474, 0.4740589493361079, 0.15522547566364808, 0.5281439210251319, 0.636014884093757, 0.4830453951384337, 0.47703831865212043, 0.45166526995597034, 0.44317236171834695, 0.7010653366022983, 0.7233925671861468, 0.4883179290285373, 0.6398384007181426, 0.09074001811897758, 0.11447487284723334, 0.08599945254513675, 0.10445296239121105, 0.07936453511213548, 0.0902022023411515, 0.07610180159147617, 0.07515634191794962, 0.06674644755198988, 0.14022114818226294, 0.17554822439945406, 0.13359783446297246, 0.1409317284612791, 0.14092198360658326, 0.173145445585847, 0.1449018995448389, 0.13942587974498477, 0.12232620957981266, 0.28376739659617134, 0.22381707669572792, 0.2601819829713049, 0.26952781511886026, 0.2157964862317372, 0.2178078272205336, 0.2642683756273435, 0.23100316439009871, 0.20065644798030202, 0.17742319564079212, 0.15412023236126593, 0.1810101519066759, 0.16004458854665715, 0.1702387126095477, 0.1516491258663939, 0.156661141434705, 0.1994859781121351, 0.17330634449843418, 0.19993708169671176, 0.19048025195359986, 0.16724013546566252, 0.1907040780597128, 0.19520819839333414, 0.17850112741899826, 0.1833145714205161, 0.19171286471924376, 0.17561415061767005, 0.17488737360461093, 0.18460204910281852, 0.176939782836949, 0.17452577824083526, 0.18107762546836048, 0.17131717162742865, 0.18021118620234522, 0.1741440754844623, 0.1784250139988841, 0.15879164141693258, 0.16082910616076262, 0.17264970519403666, 0.17365134524246517, 0.15506891738962314, 0.1464547940763723, 0.1587999886323549, 0.136946766671451, 0.15788650229594003, 0.17045161151046762, 0.11341698965273606, 0.08312855118409768, 0.16858208476913716, 0.16848174449937592, 0.16626748291694926, 0.20970016121485302, 0.20581584844571754, 0.11222534786131122, 0.1857834028736911, 0.201541362708058, 0.19182533851673378, 0.18152758673360014, 0.19046476353487107, 0.17098304755913918, 0.18416765744607277, 0.1951861190240901, 0.18837431136735427, 0.07858697649318669, 0.06910253444303494, 0.07685981900388472, 0.06763231100865907, 0.06660814129602255, 0.07802661596948401, 0.06826479334851698, 0.0744118850802512, 0.06662760369968368]}, "mutation_prompt": null}
{"id": "21190634-ded5-4f91-9ca6-c1aa33dbb231", "solution": "import numpy as np\n\nclass DCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.3)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean += np.dot(weights, selected - self.mean)\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "DCMAESOptimizer", "description": "Dynamic Covariance Matrix Adaptation Evolution Strategy (DCMA-ES) tailored with feedback-driven self-adaptation of strategy parameters.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5a102d74-6c79-4d7f-90fa-a0f63361c7e5", "metadata": {"aucs": [0.8014806973055866, 0.8358980558988997, 0.8291976485995799, 0.7941651959799176, 0.8128239408337135, 0.8797587038109886, 0.8860677824518267, 0.8205888576047901, 0.833366431316752, 0.4793369605385459, 0.37127449826039716, 0.4599585812487873, 0.4840984969880967, 0.4888003142387133, 0.46762626383710637, 0.35074531093363204, 0.43681859110379584, 0.5162763810592278, 0.08176633037132919, 0.09045753440556814, 0.07950106240172294, 0.0965257605850185, 0.0825453059457697, 0.08102446741089897, 0.08353371304042845, 0.08468915643590247, 0.08994738353113407, 0.03491405596637265, 0.0545101137523718, 0.052940146370301755, 0.04959179784535461, 0.039114943166644656, 0.04118015044288126, 0.059680585592965185, 0.05732695867472759, 0.03298258525042985, 0.9585045895078593, 0.8967492099312204, 0.7813922208827235, 0.9173855986720169, 0.9157256559993987, 0.794618644948665, 0.6022275653205145, 0.9511468397707423, 0.9661652433296222, 0.09053684364298153, 0.08974591179477465, 0.08711285849728778, 0.10080183090540618, 0.11566227074375424, 0.1774833860345818, 0.10600581384010366, 0.09848258405029608, 0.10986109730208449, 0.3022128952008404, 0.2628526233817863, 0.5266157965469996, 0.3658589026751248, 0.2357324718090109, 0.3280451939205993, 0.2900788151678567, 0.29164142518921266, 0.2734259590438801, 0.12590182225797109, 0.1472031375208286, 0.15669313002402685, 0.14303218196673173, 0.13315001506208668, 0.18413968015262294, 0.16260376179667324, 0.13612586348724742, 0.1134764664620066, 0.15732683601105402, 0.11814101042932201, 0.1056329446217058, 0.14235759804221504, 0.17817519012574845, 0.19562063978845945, 0.1638468324940845, 0.14285298282765402, 0.10542314091178284, 9.999999999998899e-05, 0.00016358001984173587, 9.999999999998899e-05, 9.999999999998899e-05, 0.09631224860321141, 9.999999999998899e-05, 9.999999999998899e-05, 0.06698625291697169, 0.004300169788878705, 0.07894974992511583, 0.058493831604142676, 0.1000709627193217, 0.12824414216793434, 0.058833016760291845, 0.05793910026901472, 0.08990146752567763, 0.0913999533312091, 0.0718369529994558, 0.017335207826943533, 0.13490425571052567, 0.06744965642811096, 0.1367392736118852, 0.14200372381861093, 0.07853771392211073, 0.15021410699327042, 0.11830824238129445, 0.12015985942950014, 0.42596267547427824, 0.2968986086355371, 0.2285450329967813, 0.4379652138466765, 0.3937776085120108, 0.29228492019903474, 0.4740589493361079, 0.15522547566364808, 0.5281439210251319, 0.636014884093757, 0.4830453951384337, 0.47703831865212043, 0.45166526995597034, 0.44317236171834695, 0.7010653366022983, 0.7233925671861468, 0.4883179290285373, 0.6398384007181426, 0.09074001811897758, 0.11447487284723334, 0.08599945254513675, 0.10445296239121105, 0.07936453511213548, 0.0902022023411515, 0.07610180159147617, 0.07515634191794962, 0.06674644755198988, 0.14022114818226294, 0.17554822439945406, 0.13359783446297246, 0.1409317284612791, 0.14092198360658326, 0.173145445585847, 0.1449018995448389, 0.13942587974498477, 0.12232620957981266, 0.28376739659617134, 0.22381707669572792, 0.2601819829713049, 0.26952781511886026, 0.2157964862317372, 0.2178078272205336, 0.2642683756273435, 0.23100316439009871, 0.20065644798030202, 0.17742319564079212, 0.15412023236126593, 0.1810101519066759, 0.16004458854665715, 0.1702387126095477, 0.1516491258663939, 0.156661141434705, 0.1994859781121351, 0.17330634449843418, 0.19993708169671176, 0.19048025195359986, 0.16724013546566252, 0.1907040780597128, 0.19520819839333414, 0.17850112741899826, 0.1833145714205161, 0.19171286471924376, 0.17561415061767005, 0.17488737360461093, 0.18460204910281852, 0.176939782836949, 0.17452577824083526, 0.18107762546836048, 0.17131717162742865, 0.18021118620234522, 0.1741440754844623, 0.1784250139988841, 0.15879164141693258, 0.16082910616076262, 0.17264970519403666, 0.17365134524246517, 0.15506891738962314, 0.1464547940763723, 0.1587999886323549, 0.136946766671451, 0.15788650229594003, 0.17045161151046762, 0.11341698965273606, 0.08312855118409768, 0.16858208476913716, 0.16848174449937592, 0.16626748291694926, 0.20970016121485302, 0.20581584844571754, 0.11222534786131122, 0.1857834028736911, 0.201541362708058, 0.19182533851673378, 0.18152758673360014, 0.19046476353487107, 0.17098304755913918, 0.18416765744607277, 0.1951861190240901, 0.18837431136735427, 0.07858697649318669, 0.06910253444303494, 0.07685981900388472, 0.06763231100865907, 0.06660814129602255, 0.07802661596948401, 0.06826479334851698, 0.0744118850802512, 0.06662760369968368]}, "mutation_prompt": null}
{"id": "d5e6e0cd-e23c-41ef-828f-25936e927aaa", "solution": "import numpy as np\n\nclass EnhancedDCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n        self.diversity_threshold = 0.1  # New parameter for diversity preservation\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.3)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                if np.linalg.norm(samples[i] - self.mean) < self.diversity_threshold:  # Check diversity\n                    samples[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean += np.dot(weights, selected - self.mean)\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "EnhancedDCMAESOptimizer", "description": "Enhanced Covariance Matrix Adaptation with Adaptive Step-size and Diversity Preservation for Robust Optimization.", "configspace": "", "generation": 24, "fitness": 0.17950198918194024, "feedback": "The algorithm EnhancedDCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.18.", "error": "", "parent_id": "5a102d74-6c79-4d7f-90fa-a0f63361c7e5", "metadata": {"aucs": [0.44392974157566645, 0.42904840561059154, 0.4139348909977074, 0.39088510881997385, 0.39867640236458723, 0.40082001595020345, 0.4484187177779617, 0.3833634810892853, 0.40111797371354574, 0.08989198131863052, 0.07837989050220218, 0.08071191767421915, 0.12103843688133142, 0.06881026268367463, 0.07211803465309763, 0.059929336886595186, 0.1472183615996615, 0.08186235180625734, 0.08176633037132919, 0.09045753440556814, 0.07950106240172294, 0.0965257605850185, 0.0825453059457697, 0.08102446741089897, 0.08353371304042845, 0.08468915643590247, 0.08994738353113407, 0.03491405596637265, 0.0545101137523718, 0.052940146370301755, 0.04959179784535461, 0.039114943166644656, 0.04118015044288126, 0.059680585592965185, 0.05732695867472759, 0.03298258525042985, 0.9585045895078593, 0.8967492099312204, 0.7813922208827235, 0.9173855986720169, 0.9157256559993987, 0.794618644948665, 0.6022275653205145, 0.9511468397707423, 0.9661652433296222, 0.09053684364298153, 0.08974591179477465, 0.08711285849728778, 0.10080183090540618, 0.11566227074375424, 0.1774833860345818, 0.10600581384010366, 0.09848258405029608, 0.10986109730208449, 0.3234602545462957, 0.2628526233817863, 0.2640417417701275, 0.31392359789963054, 0.2357324718090109, 0.3280451939205993, 0.29029460173306476, 0.29164142518921266, 0.2729079371843073, 0.12819545076416672, 0.1288141021197362, 0.12882170341085242, 0.13618326909561607, 0.1285930071461273, 0.14199313169336403, 0.1307704346803339, 0.13612586348724742, 0.11423209444865645, 0.15194028671587, 0.10340794312964663, 0.09777342916295306, 0.13598514963799002, 0.14853357513060295, 0.13679552448860666, 0.12281189638328283, 0.11992966235984315, 0.10542314091178284, 9.999999999998899e-05, 0.00016358001984173587, 9.999999999998899e-05, 9.999999999998899e-05, 0.04259961503457599, 9.999999999998899e-05, 9.999999999998899e-05, 0.06698625291697169, 0.004300169788878705, 0.07894974992511583, 0.058493831604142676, 0.1000709627193217, 0.12824414216793434, 0.058833016760291845, 0.05793910026901472, 0.08990146752567763, 0.0913999533312091, 0.0718369529994558, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11168121926531926, 0.12244359031803631, 0.10503301349544691, 0.09853923947881393, 0.10634541864818325, 0.08548058749946408, 0.09359703838084843, 0.09824869535211433, 0.104017219092704, 0.38495383063855027, 0.36374097738592026, 0.37241530855634464, 0.35572540720572765, 0.3575841706213292, 0.36393342200385104, 0.3986361368715877, 0.3872317945359458, 0.3787758464025496, 0.09074001811897758, 0.11447487284723334, 0.08599945254513675, 0.10445296239121105, 0.07936453511213548, 0.0902022023411515, 0.07610180159147617, 0.07515634191794962, 0.06674644755198988, 0.14022114818226294, 0.17554822439945406, 0.13359783446297246, 0.1409317284612791, 0.14092198360658326, 0.173145445585847, 0.1449018995448389, 0.13942587974498477, 0.12232620957981266, 0.2578599259448401, 0.22381707669572792, 0.23914942678835527, 0.26401504924758845, 0.2157964862317372, 0.2152217184911911, 0.2514449543688233, 0.23100316439009871, 0.20065644798030202, 0.17742319564079212, 0.15412023236126593, 0.1810101519066759, 0.16004458854665715, 0.1702387126095477, 0.1516491258663939, 0.156661141434705, 0.1753888384832598, 0.17330634449843418, 0.19993708169671176, 0.19048025195359986, 0.16724013546566252, 0.1907040780597128, 0.19520819839333414, 0.17850112741899826, 0.1833145714205161, 0.19171286471924376, 0.17561415061767005, 0.17488737360461093, 0.18460204910281852, 0.176939782836949, 0.17452577824083526, 0.18107762546836048, 0.17131717162742865, 0.18021118620234522, 0.1741440754844623, 0.1784250139988841, 0.15867138827390936, 0.1735074656843406, 0.17264970519403666, 0.20822090295651274, 0.15506891738962314, 0.14929555833455566, 0.16611808989117793, 0.136946766671451, 0.15788650229594003, 0.17042684577255063, 0.16042448458391134, 0.1336748768602658, 0.16851696162340446, 0.16838130614404, 0.1667254966158742, 0.2090878040788291, 0.20522112569505535, 0.13299635805851873, 0.1857834028736911, 0.201541362708058, 0.19182533851673378, 0.18152758673360014, 0.19046476353487107, 0.17098304755913918, 0.18416765744607277, 0.1951861190240901, 0.18837431136735427, 0.07858697649318669, 0.06910253444303494, 0.07685981900388472, 0.06763231100865907, 0.06660814129602255, 0.07802661596948401, 0.06826479334851698, 0.0744118850802512, 0.06662760369968368]}, "mutation_prompt": null}
{"id": "c57c9bc9-258e-4ef3-b462-abffd68480c5", "solution": "import numpy as np\n\nclass ACMESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)  # Adjusted factor\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)  # Adjusted factor\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 3)**2 + mu_eff))  # Adjusted factor\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, (self.step_size**2) * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean += np.dot(weights, selected - self.mean)\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "ACMESOptimizer", "description": "Adaptive Covariance Matrix Evolution Strategy (ACMES) with enhanced correlation-based mutation and adaptive sampling for diverse exploration and efficient convergence.", "configspace": "", "generation": 25, "fitness": 0.20681713989240336, "feedback": "The algorithm ACMESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.22.", "error": "", "parent_id": "5a102d74-6c79-4d7f-90fa-a0f63361c7e5", "metadata": {"aucs": [0.8478378256504393, 0.6412752120331917, 0.8666305593022414, 0.8118566783010466, 0.8420689350431604, 0.702699001186765, 0.8332057388757226, 0.6255459226111644, 0.7882508843108966, 0.218930549698373, 0.22617839870021383, 0.1793387779481027, 0.14859317346316636, 0.16135416389826318, 0.12553696539203463, 0.4147115466085891, 0.15527971042601363, 0.287318272658562, 0.06861987004929593, 0.07603529151167499, 0.08314851791912026, 0.07868806670360917, 0.06631498322817497, 0.07992299061127828, 0.07622252818095532, 0.0732808404674068, 0.07186808352810936, 0.056521808293201636, 0.045546704628743995, 0.032742761700688794, 0.05366460419303398, 0.029280763792931763, 0.035848872005924015, 0.042953272267216236, 0.037370835863560936, 0.03250618699372387, 0.5296034809517512, 0.9672551872241492, 0.9725349101238433, 0.9390044713298672, 0.8996477758956996, 0.9096048242145969, 0.961425013191876, 0.9834542761370697, 0.988897647153643, 0.11889315825746849, 0.09160934746718485, 0.09141363025229943, 0.07697812456318776, 0.08874047074232438, 0.09697987105525241, 0.12357078591403736, 0.10281712605213322, 0.12320632685597777, 0.2921510134037859, 0.220727259824945, 0.22824565477302883, 0.3097366753418108, 0.8306510785580672, 0.26942824751424166, 0.21844494365439915, 0.24219780319431317, 0.20649826140736227, 0.10888070617858625, 0.10741388310136057, 0.10907756825229409, 0.11095675414800665, 0.10395827059854068, 0.11503413691760345, 0.12178738539970346, 0.08688952925425697, 0.09043447929873216, 0.0626399056926199, 0.09436724281602638, 0.09105601047593004, 0.155271344677946, 0.06772223597323068, 0.1395231375956466, 0.14024575469370537, 0.09663265058922876, 0.0986846618150008, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06417651855821116, 0.0860454755364024, 0.10806050210030549, 0.04392900412925227, 0.07711531674682914, 0.07951485301706185, 0.14281915205666174, 0.059759624339628115, 0.09984454442371238, 0.011845667667755855, 0.020186409686321127, 0.0515445779877346, 0.003363553547448328, 0.0437887092055933, 9.999999999998899e-05, 9.999999999998899e-05, 0.017168487207779415, 0.030627473895744717, 0.32305947896024256, 0.3102619859781961, 0.23075525868737712, 0.3620714494873203, 0.331874152855252, 0.32109148238711616, 0.16034901629430154, 0.1466019748674655, 0.2903744543912503, 0.391801605297721, 0.3931211211014949, 0.41714355329717256, 0.528429090584831, 0.35649760844592027, 0.41031804813326866, 0.418134245047573, 0.32713704521687303, 0.36479201740772926, 0.08670454542696826, 0.07358033535084285, 0.07114354313055449, 0.082189879699897, 0.0946988046526851, 0.08847988096009318, 0.07097478799694623, 0.07463546646303254, 0.0759095112377205, 0.13814401267561494, 0.12493546151136725, 0.17574843596891265, 0.12134731258115572, 0.13092206813360086, 0.13739841038271183, 0.1452763218002885, 0.13946353123096755, 0.14881131094365996, 0.23112588370088138, 0.1892016332848796, 0.23049664694878258, 0.20814670504501298, 0.21053384618633986, 0.20244816884005756, 0.1954207031952031, 0.24724074458754552, 0.21997455514162123, 0.1333256829836238, 0.1493081935513092, 0.1539779613160257, 0.14617426769833142, 0.16573382522885027, 0.13824969240843255, 0.18123158642216108, 0.1355327268963984, 0.14346809049276088, 0.1925263164051464, 0.18266836407652032, 0.1917711430624085, 0.18964986029715725, 0.16731685230944804, 0.1921848591734816, 0.20681872731343265, 0.17842247468066652, 0.18007819108382372, 0.1711026087548203, 0.16877719186541396, 0.17150018680610557, 0.16951324062470918, 0.16983673564780544, 0.1688889890137154, 0.16965205075296597, 0.1738023153438848, 0.17667336000730538, 0.16510950423619397, 0.1812164868173206, 0.17588428058902283, 0.15990608665210926, 0.1612613472113673, 0.129029878692686, 0.19488411501600977, 0.1571875010079411, 0.14901906519713903, 0.31361514801346146, 0.16156909984759327, 0.18586962975051136, 0.16782441959947336, 0.16177188420421118, 0.14999151371298736, 0.16753480704530233, 0.20020448399763113, 0.2076273115790428, 0.17863889988620085, 0.1790210758989932, 0.19935073567721995, 0.19345590438202032, 0.1981134672051651, 0.17825623704039195, 0.18534258782473312, 0.17429316357800395, 0.19525739326668923, 0.06335269308487745, 0.06235492342807214, 0.07179558456688662, 0.06926774520286672, 0.05933729901613183, 0.06504657795741009, 0.06401918656310812, 0.06971496749626171, 0.06709343109316801]}, "mutation_prompt": null}
{"id": "5e048220-f8be-437d-9fcf-73601dcd652e", "solution": "import numpy as np\n\nclass ADECML:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)  # Modified for stability\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2.5)**2 + mu_eff))  # Modified for better learning rate\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        F = 0.8  # Differential Evolution mutation factor\n        CR = 0.9  # Crossover probability\n\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n                donor_vector = x1 + F * (x2 - x3)\n                trial_vector = np.where(np.random.rand(self.dim) < CR, donor_vector, population[i])\n                trial_vector = np.clip(trial_vector, self.lower_bound, self.upper_bound)\n\n                # Evaluate the new trial vector\n                trial_fitness = func(trial_vector)\n                self.eval_count += 1\n\n                # Selection\n                if trial_fitness < self.fitness[i]:\n                    population[i] = trial_vector\n                    self.fitness[i] = trial_fitness\n\n            # Update covariance matrix\n            indices = np.argsort(self.fitness)\n            selected = population[indices[:len(weights)]]\n            self.mean += np.dot(weights, selected - self.mean)\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return population[best_idx], self.fitness[best_idx]", "name": "ADECML", "description": "Adaptive Differential Evolution with Covariance Matrix Learning (ADE-CML) that combines differential evolution with covariance matrix adaptation for enhanced convergence.", "configspace": "", "generation": 26, "fitness": -Infinity, "feedback": "An exception occurred: LinAlgError('Matrix is not positive definite').", "error": "LinAlgError('Matrix is not positive definite')", "parent_id": "5a102d74-6c79-4d7f-90fa-a0f63361c7e5", "metadata": {}, "mutation_prompt": null}
{"id": "b6a0c9d9-efc1-42e0-b780-2189d2e0381a", "solution": "import numpy as np\n\nclass DCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.3)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean += np.dot(weights, selected - self.mean)\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "DCMAESOptimizer", "description": "Dynamic Covariance Matrix Adaptation Evolution Strategy (DCMA-ES) tailored with feedback-driven self-adaptation of strategy parameters.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5a102d74-6c79-4d7f-90fa-a0f63361c7e5", "metadata": {"aucs": [0.8014806973055866, 0.8358980558988997, 0.8291976485995799, 0.7941651959799176, 0.8128239408337135, 0.8797587038109886, 0.8860677824518267, 0.8205888576047901, 0.833366431316752, 0.4793369605385459, 0.37127449826039716, 0.4599585812487873, 0.4840984969880967, 0.4888003142387133, 0.46762626383710637, 0.35074531093363204, 0.43681859110379584, 0.5162763810592278, 0.08176633037132919, 0.09045753440556814, 0.07950106240172294, 0.0965257605850185, 0.0825453059457697, 0.08102446741089897, 0.08353371304042845, 0.08468915643590247, 0.08994738353113407, 0.03491405596637265, 0.0545101137523718, 0.052940146370301755, 0.04959179784535461, 0.039114943166644656, 0.04118015044288126, 0.059680585592965185, 0.05732695867472759, 0.03298258525042985, 0.9585045895078593, 0.8967492099312204, 0.7813922208827235, 0.9173855986720169, 0.9157256559993987, 0.794618644948665, 0.6022275653205145, 0.9511468397707423, 0.9661652433296222, 0.09053684364298153, 0.08974591179477465, 0.08711285849728778, 0.10080183090540618, 0.11566227074375424, 0.1774833860345818, 0.10600581384010366, 0.09848258405029608, 0.10986109730208449, 0.3022128952008404, 0.2628526233817863, 0.5266157965469996, 0.3658589026751248, 0.2357324718090109, 0.3280451939205993, 0.2900788151678567, 0.29164142518921266, 0.2734259590438801, 0.12590182225797109, 0.1472031375208286, 0.15669313002402685, 0.14303218196673173, 0.13315001506208668, 0.18413968015262294, 0.16260376179667324, 0.13612586348724742, 0.1134764664620066, 0.15732683601105402, 0.11814101042932201, 0.1056329446217058, 0.14235759804221504, 0.17817519012574845, 0.19562063978845945, 0.1638468324940845, 0.14285298282765402, 0.10542314091178284, 9.999999999998899e-05, 0.00016358001984173587, 9.999999999998899e-05, 9.999999999998899e-05, 0.09631224860321141, 9.999999999998899e-05, 9.999999999998899e-05, 0.06698625291697169, 0.004300169788878705, 0.07894974992511583, 0.058493831604142676, 0.1000709627193217, 0.12824414216793434, 0.058833016760291845, 0.05793910026901472, 0.08990146752567763, 0.0913999533312091, 0.0718369529994558, 0.017335207826943533, 0.13490425571052567, 0.06744965642811096, 0.1367392736118852, 0.14200372381861093, 0.07853771392211073, 0.15021410699327042, 0.11830824238129445, 0.12015985942950014, 0.42596267547427824, 0.2968986086355371, 0.2285450329967813, 0.4379652138466765, 0.3937776085120108, 0.29228492019903474, 0.4740589493361079, 0.15522547566364808, 0.5281439210251319, 0.636014884093757, 0.4830453951384337, 0.47703831865212043, 0.45166526995597034, 0.44317236171834695, 0.7010653366022983, 0.7233925671861468, 0.4883179290285373, 0.6398384007181426, 0.09074001811897758, 0.11447487284723334, 0.08599945254513675, 0.10445296239121105, 0.07936453511213548, 0.0902022023411515, 0.07610180159147617, 0.07515634191794962, 0.06674644755198988, 0.14022114818226294, 0.17554822439945406, 0.13359783446297246, 0.1409317284612791, 0.14092198360658326, 0.173145445585847, 0.1449018995448389, 0.13942587974498477, 0.12232620957981266, 0.28376739659617134, 0.22381707669572792, 0.2601819829713049, 0.26952781511886026, 0.2157964862317372, 0.2178078272205336, 0.2642683756273435, 0.23100316439009871, 0.20065644798030202, 0.17742319564079212, 0.15412023236126593, 0.1810101519066759, 0.16004458854665715, 0.1702387126095477, 0.1516491258663939, 0.156661141434705, 0.1994859781121351, 0.17330634449843418, 0.19993708169671176, 0.19048025195359986, 0.16724013546566252, 0.1907040780597128, 0.19520819839333414, 0.17850112741899826, 0.1833145714205161, 0.19171286471924376, 0.17561415061767005, 0.17488737360461093, 0.18460204910281852, 0.176939782836949, 0.17452577824083526, 0.18107762546836048, 0.17131717162742865, 0.18021118620234522, 0.1741440754844623, 0.1784250139988841, 0.15879164141693258, 0.16082910616076262, 0.17264970519403666, 0.17365134524246517, 0.15506891738962314, 0.1464547940763723, 0.1587999886323549, 0.136946766671451, 0.15788650229594003, 0.17045161151046762, 0.11341698965273606, 0.08312855118409768, 0.16858208476913716, 0.16848174449937592, 0.16626748291694926, 0.20970016121485302, 0.20581584844571754, 0.11222534786131122, 0.1857834028736911, 0.201541362708058, 0.19182533851673378, 0.18152758673360014, 0.19046476353487107, 0.17098304755913918, 0.18416765744607277, 0.1951861190240901, 0.18837431136735427, 0.07858697649318669, 0.06910253444303494, 0.07685981900388472, 0.06763231100865907, 0.06660814129602255, 0.07802661596948401, 0.06826479334851698, 0.0744118850802512, 0.06662760369968368]}, "mutation_prompt": null}
{"id": "67ce14b4-cd59-45c2-98f7-0fcc823b3d33", "solution": "import numpy as np\n\nclass AGPCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.3)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.step_size**2 * self.covariance_matrix, self.population_size)\n            noise = np.random.normal(0, 0.2, (self.population_size, self.dim))\n            samples = np.clip(samples + noise, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "AGPCMAESOptimizer", "description": "Adaptive Gradient-Perturbed CMA-ES using stochastic perturbations and adaptive learning.", "configspace": "", "generation": 28, "fitness": 0.16484388469883288, "feedback": "The algorithm AGPCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16 with standard deviation 0.18.", "error": "", "parent_id": "5a102d74-6c79-4d7f-90fa-a0f63361c7e5", "metadata": {"aucs": [0.3357874174456752, 0.3316726621024496, 0.3029565473784158, 0.3384770026642395, 0.32057876351482484, 0.34962391334300025, 0.36790106170984616, 0.3487753739838275, 0.3336087573701547, 9.999999999998899e-05, 9.999999999998899e-05, 0.002846875847875019, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08267612139724134, 0.07207926226418981, 0.07970373324108482, 0.07876693162221904, 0.08464283198317846, 0.10756616526191953, 0.0732603750177635, 0.08553462754312113, 0.08495959472988579, 0.04709911251685994, 0.031971734726757295, 0.02676628574039297, 0.04745974711668366, 0.06009488324802281, 0.04243342850236409, 0.05083342463726859, 0.042809347634898964, 0.0423631581558207, 0.9474892065837637, 0.9032611926891595, 0.9768178721717682, 0.9898327469437274, 0.9760726979291829, 0.9903732842698032, 0.8470994777227709, 0.968818348403557, 0.8784462495948022, 0.08634699072341223, 0.10932193553693503, 0.08806304427315903, 0.10333941318124995, 0.1165715453706152, 0.10666289653450423, 0.12436242709173095, 0.10970764684069545, 0.10801884978510967, 0.21730398847220023, 0.1963236385061643, 0.20440438941502248, 0.32742955255988737, 0.24360007635993175, 0.21762009248731495, 0.20197761157164018, 0.19521873816134128, 0.21977479456403315, 0.08752403586457735, 0.10243496218440251, 0.09309742950946875, 0.10340860257261142, 0.1016199120339315, 0.09800762207137959, 0.11282861810346423, 0.11175245970043834, 0.09317254032420386, 0.10024317979399311, 0.08149807116101115, 0.09230169275943789, 0.12359418298308678, 0.10826635065798096, 0.10030644744035544, 0.10576205670441252, 0.071391890266709, 0.0763964169544874, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.22946815736911252, 0.10123433205502463, 0.10868422766090424, 0.07465673266607542, 0.0617354727886672, 0.10616131710304655, 0.11360121834610815, 0.07576239767909387, 0.07940875644014522, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04702454652589072, 0.05198982500439486, 0.047511776488270874, 0.04746441183854222, 0.06765403851325902, 0.047080859939805486, 0.05449020930772308, 0.06608281058075705, 0.049290646790395076, 0.30809247377454185, 0.2922015053961229, 0.2981927819713476, 0.32956302476168875, 0.3117194636760713, 0.3163515512236661, 0.3062476104186038, 0.3170203899518891, 0.31381840201068434, 0.09381802284790952, 0.09942100166891177, 0.08117577114152696, 0.08054167282629987, 0.08205597394193176, 0.09589870759789465, 0.06382811217868967, 0.08175413687111954, 0.08835730656735541, 0.14495779673450238, 0.15238831227713567, 0.14585190752105592, 0.12209156456192016, 0.13908525638174885, 0.1441412105536437, 0.15073681186095567, 0.15744775448432669, 0.1728220219080513, 0.2815589819008778, 0.19572543552086674, 0.21248127704551245, 0.219968311384923, 0.21743556837878197, 0.20647873800356742, 0.2727608532769502, 0.20906209445841728, 0.19854172156802874, 0.1628242131129073, 0.13532107304721464, 0.13797832232603047, 0.13488519693281265, 0.15259650716331363, 0.14213132364883097, 0.14557092888114298, 0.146340122536871, 0.13861496787742456, 0.18761771011471506, 0.16289598281155826, 0.1834123643092891, 0.16884804671347753, 0.19766162593323855, 0.17924995970862911, 0.1921193007680022, 0.17456666733496418, 0.19541433610404968, 0.16823301895142106, 0.17082550878890101, 0.1847268909463945, 0.16948893552081046, 0.17845660358690585, 0.17323389787475119, 0.1723684202491268, 0.17341509682881207, 0.17712966665397212, 0.18060184847528493, 0.14257353729726274, 0.1981578094045655, 0.15715871701512807, 0.15743116824391223, 0.1675045574968923, 0.13862466361892944, 0.16252931799878967, 0.16629972923863423, 0.1724104051133203, 0.16171532855419224, 0.1549793499658244, 0.15801408953154494, 0.2184879824599879, 0.1658995561763018, 0.20644804810335604, 0.20175709573254275, 0.1704085567096223, 0.1922955793218064, 0.19061981587763477, 0.1877767845259516, 0.17329141432868478, 0.18799687905544282, 0.1917183682315231, 0.1831919687179242, 0.17375818285278033, 0.19713469793402805, 0.06125487532988916, 0.07403624487849936, 0.07356307676813234, 0.06198738496748846, 0.06454274686945571, 0.0634013855246085, 0.07557658005921852, 0.07031327899277962, 0.07028179757624153]}, "mutation_prompt": null}
{"id": "2d488606-9e06-4f55-9f5d-f73f194ce83e", "solution": "import numpy as np\n\nclass EnhancedDCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 4 + int(3 * np.log(self.dim))\n        self.population_size = self.initial_population_size\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def adapt_population_size(self):\n        if self.eval_count >= 0.5 * self.budget:\n            self.population_size = max(self.initial_population_size // 2, 4)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.3)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            self.adapt_population_size()\n            samples = np.random.multivariate_normal(self.mean, self.step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean += np.dot(weights, selected - self.mean)\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "EnhancedDCMAESOptimizer", "description": "Enhanced DCMA-ES with adaptive population size and boundary correction strategy for robust optimization.", "configspace": "", "generation": 29, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 5 is out of bounds for axis 0 with size 4').", "error": "IndexError('index 5 is out of bounds for axis 0 with size 4')", "parent_id": "5a102d74-6c79-4d7f-90fa-a0f63361c7e5", "metadata": {}, "mutation_prompt": null}
{"id": "e5f56bee-3ff8-4736-a989-fe7d7a298008", "solution": "import numpy as np\n\nclass DCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.3)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean += np.dot(weights, selected - self.mean)\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "DCMAESOptimizer", "description": "Dynamic Covariance Matrix Adaptation Evolution Strategy (DCMA-ES) tailored with feedback-driven self-adaptation of strategy parameters.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5a102d74-6c79-4d7f-90fa-a0f63361c7e5", "metadata": {"aucs": [0.8014806973055866, 0.8358980558988997, 0.8291976485995799, 0.7941651959799176, 0.8128239408337135, 0.8797587038109886, 0.8860677824518267, 0.8205888576047901, 0.833366431316752, 0.4793369605385459, 0.37127449826039716, 0.4599585812487873, 0.4840984969880967, 0.4888003142387133, 0.46762626383710637, 0.35074531093363204, 0.43681859110379584, 0.5162763810592278, 0.08176633037132919, 0.09045753440556814, 0.07950106240172294, 0.0965257605850185, 0.0825453059457697, 0.08102446741089897, 0.08353371304042845, 0.08468915643590247, 0.08994738353113407, 0.03491405596637265, 0.0545101137523718, 0.052940146370301755, 0.04959179784535461, 0.039114943166644656, 0.04118015044288126, 0.059680585592965185, 0.05732695867472759, 0.03298258525042985, 0.9585045895078593, 0.8967492099312204, 0.7813922208827235, 0.9173855986720169, 0.9157256559993987, 0.794618644948665, 0.6022275653205145, 0.9511468397707423, 0.9661652433296222, 0.09053684364298153, 0.08974591179477465, 0.08711285849728778, 0.10080183090540618, 0.11566227074375424, 0.1774833860345818, 0.10600581384010366, 0.09848258405029608, 0.10986109730208449, 0.3022128952008404, 0.2628526233817863, 0.5266157965469996, 0.3658589026751248, 0.2357324718090109, 0.3280451939205993, 0.2900788151678567, 0.29164142518921266, 0.2734259590438801, 0.12590182225797109, 0.1472031375208286, 0.15669313002402685, 0.14303218196673173, 0.13315001506208668, 0.18413968015262294, 0.16260376179667324, 0.13612586348724742, 0.1134764664620066, 0.15732683601105402, 0.11814101042932201, 0.1056329446217058, 0.14235759804221504, 0.17817519012574845, 0.19562063978845945, 0.1638468324940845, 0.14285298282765402, 0.10542314091178284, 9.999999999998899e-05, 0.00016358001984173587, 9.999999999998899e-05, 9.999999999998899e-05, 0.09631224860321141, 9.999999999998899e-05, 9.999999999998899e-05, 0.06698625291697169, 0.004300169788878705, 0.07894974992511583, 0.058493831604142676, 0.1000709627193217, 0.12824414216793434, 0.058833016760291845, 0.05793910026901472, 0.08990146752567763, 0.0913999533312091, 0.0718369529994558, 0.017335207826943533, 0.13490425571052567, 0.06744965642811096, 0.1367392736118852, 0.14200372381861093, 0.07853771392211073, 0.15021410699327042, 0.11830824238129445, 0.12015985942950014, 0.42596267547427824, 0.2968986086355371, 0.2285450329967813, 0.4379652138466765, 0.3937776085120108, 0.29228492019903474, 0.4740589493361079, 0.15522547566364808, 0.5281439210251319, 0.636014884093757, 0.4830453951384337, 0.47703831865212043, 0.45166526995597034, 0.44317236171834695, 0.7010653366022983, 0.7233925671861468, 0.4883179290285373, 0.6398384007181426, 0.09074001811897758, 0.11447487284723334, 0.08599945254513675, 0.10445296239121105, 0.07936453511213548, 0.0902022023411515, 0.07610180159147617, 0.07515634191794962, 0.06674644755198988, 0.14022114818226294, 0.17554822439945406, 0.13359783446297246, 0.1409317284612791, 0.14092198360658326, 0.173145445585847, 0.1449018995448389, 0.13942587974498477, 0.12232620957981266, 0.28376739659617134, 0.22381707669572792, 0.2601819829713049, 0.26952781511886026, 0.2157964862317372, 0.2178078272205336, 0.2642683756273435, 0.23100316439009871, 0.20065644798030202, 0.17742319564079212, 0.15412023236126593, 0.1810101519066759, 0.16004458854665715, 0.1702387126095477, 0.1516491258663939, 0.156661141434705, 0.1994859781121351, 0.17330634449843418, 0.19993708169671176, 0.19048025195359986, 0.16724013546566252, 0.1907040780597128, 0.19520819839333414, 0.17850112741899826, 0.1833145714205161, 0.19171286471924376, 0.17561415061767005, 0.17488737360461093, 0.18460204910281852, 0.176939782836949, 0.17452577824083526, 0.18107762546836048, 0.17131717162742865, 0.18021118620234522, 0.1741440754844623, 0.1784250139988841, 0.15879164141693258, 0.16082910616076262, 0.17264970519403666, 0.17365134524246517, 0.15506891738962314, 0.1464547940763723, 0.1587999886323549, 0.136946766671451, 0.15788650229594003, 0.17045161151046762, 0.11341698965273606, 0.08312855118409768, 0.16858208476913716, 0.16848174449937592, 0.16626748291694926, 0.20970016121485302, 0.20581584844571754, 0.11222534786131122, 0.1857834028736911, 0.201541362708058, 0.19182533851673378, 0.18152758673360014, 0.19046476353487107, 0.17098304755913918, 0.18416765744607277, 0.1951861190240901, 0.18837431136735427, 0.07858697649318669, 0.06910253444303494, 0.07685981900388472, 0.06763231100865907, 0.06660814129602255, 0.07802661596948401, 0.06826479334851698, 0.0744118850802512, 0.06662760369968368]}, "mutation_prompt": null}
{"id": "0daa3001-347f-416a-87a5-6e6ce20b01cb", "solution": "import numpy as np\n\nclass EACMESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n        self.best_solution = self.mean.copy()\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.3)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n                if self.fitness[i] < self.best_fitness:\n                    self.best_fitness = self.fitness[i]\n                    self.best_solution = samples[i].copy()\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean += np.dot(weights, selected - self.mean)\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        return self.best_solution, self.best_fitness", "name": "EACMESOptimizer", "description": "Enhanced Adaptive Covariance Matrix Evolution Strategy (EACM-ES) with dynamic step size adjustment and elite-preservation mechanism for improved convergence.", "configspace": "", "generation": 31, "fitness": 0.23770035643599569, "feedback": "The algorithm EACMESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.23.", "error": "", "parent_id": "5a102d74-6c79-4d7f-90fa-a0f63361c7e5", "metadata": {"aucs": [0.8014806973055866, 0.8358980558988997, 0.8291976485995799, 0.7941651959799176, 0.8128239408337135, 0.8797587038109886, 0.8860677824518267, 0.8205888576047901, 0.833366431316752, 0.4793369605385459, 0.37127449826039716, 0.4599585812487873, 0.4840984969880967, 0.4888003142387133, 0.46762626383710637, 0.35074531093363204, 0.43681859110379584, 0.5162763810592278, 0.08176633037132919, 0.09045753440556814, 0.07950106240172294, 0.0965257605850185, 0.0825453059457697, 0.08102446741089897, 0.08353371304042845, 0.08468915643590247, 0.08994738353113407, 0.03491405596637265, 0.0545101137523718, 0.052940146370301755, 0.04959179784535461, 0.039114943166644656, 0.04118015044288126, 0.059680585592965185, 0.05732695867472759, 0.03298258525042985, 0.9585045895078593, 0.8967492099312204, 0.7813922208827235, 0.9173855986720169, 0.9157256559993987, 0.794618644948665, 0.6022275653205145, 0.9511468397707423, 0.9661652433296222, 0.09053684364298153, 0.08974591179477465, 0.08711285849728778, 0.10080183090540618, 0.11566227074375424, 0.1774833860345818, 0.10600581384010366, 0.09848258405029608, 0.10986109730208449, 0.3022128952008404, 0.2628526233817863, 0.5266157965469996, 0.3658589026751248, 0.2357324718090109, 0.3280451939205993, 0.2900788151678567, 0.29164142518921266, 0.2734259590438801, 0.12590182225797109, 0.1472031375208286, 0.15669313002402685, 0.14303218196673173, 0.13315001506208668, 0.18413968015262294, 0.16260376179667324, 0.13612586348724742, 0.1134764664620066, 0.15732683601105402, 0.11814101042932201, 0.1056329446217058, 0.14235759804221504, 0.17817519012574845, 0.19562063978845945, 0.1638468324940845, 0.14285298282765402, 0.10542314091178284, 9.999999999998899e-05, 0.00016358001984173587, 9.999999999998899e-05, 9.999999999998899e-05, 0.09631224860321141, 9.999999999998899e-05, 9.999999999998899e-05, 0.06698625291697169, 0.004300169788878705, 0.07894974992511583, 0.058493831604142676, 0.1000709627193217, 0.12824414216793434, 0.058833016760291845, 0.05793910026901472, 0.08990146752567763, 0.0913999533312091, 0.0718369529994558, 0.017335207826943533, 0.13490425571052567, 0.06744965642811096, 0.1367392736118852, 0.14200372381861093, 0.07853771392211073, 0.15021410699327042, 0.11830824238129445, 0.12015985942950014, 0.42596267547427824, 0.2968986086355371, 0.2285450329967813, 0.4379652138466765, 0.3937776085120108, 0.29228492019903474, 0.4740589493361079, 0.15522547566364808, 0.5281439210251319, 0.636014884093757, 0.4830453951384337, 0.47703831865212043, 0.45166526995597034, 0.44317236171834695, 0.7010653366022983, 0.7233925671861468, 0.4883179290285373, 0.6398384007181426, 0.09074001811897758, 0.11447487284723334, 0.08599945254513675, 0.10445296239121105, 0.07936453511213548, 0.0902022023411515, 0.07610180159147617, 0.07515634191794962, 0.06674644755198988, 0.14022114818226294, 0.17554822439945406, 0.13359783446297246, 0.1409317284612791, 0.14092198360658326, 0.173145445585847, 0.1449018995448389, 0.13942587974498477, 0.12232620957981266, 0.28376739659617134, 0.22381707669572792, 0.2601819829713049, 0.26952781511886026, 0.2157964862317372, 0.2178078272205336, 0.2642683756273435, 0.23100316439009871, 0.20065644798030202, 0.17742319564079212, 0.15412023236126593, 0.1810101519066759, 0.16004458854665715, 0.1702387126095477, 0.1516491258663939, 0.156661141434705, 0.1994859781121351, 0.17330634449843418, 0.19993708169671176, 0.19048025195359986, 0.16724013546566252, 0.1907040780597128, 0.19520819839333414, 0.17850112741899826, 0.1833145714205161, 0.19171286471924376, 0.17561415061767005, 0.17488737360461093, 0.18460204910281852, 0.176939782836949, 0.17452577824083526, 0.18107762546836048, 0.17131717162742865, 0.18021118620234522, 0.1741440754844623, 0.1784250139988841, 0.15879164141693258, 0.16082910616076262, 0.17264970519403666, 0.17365134524246517, 0.15506891738962314, 0.1464547940763723, 0.1587999886323549, 0.136946766671451, 0.15788650229594003, 0.17045161151046762, 0.11341698965273606, 0.08312855118409768, 0.16858208476913716, 0.16848174449937592, 0.16626748291694926, 0.20970016121485302, 0.20581584844571754, 0.11222534786131122, 0.1857834028736911, 0.201541362708058, 0.19182533851673378, 0.18152758673360014, 0.19046476353487107, 0.17098304755913918, 0.18416765744607277, 0.1951861190240901, 0.18837431136735427, 0.07858697649318669, 0.06910253444303494, 0.07685981900388472, 0.06763231100865907, 0.06660814129602255, 0.07802661596948401, 0.06826479334851698, 0.0744118850802512, 0.06662760369968368]}, "mutation_prompt": null}
{"id": "e0fdb2a9-de57-4d8a-8cd0-bd7c14325218", "solution": "import numpy as np\n\nclass DCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.3)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean += np.dot(weights, selected - self.mean)\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "DCMAESOptimizer", "description": "Dynamic Covariance Matrix Adaptation Evolution Strategy (DCMA-ES) tailored with feedback-driven self-adaptation of strategy parameters.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5a102d74-6c79-4d7f-90fa-a0f63361c7e5", "metadata": {"aucs": [0.8014806973055866, 0.8358980558988997, 0.8291976485995799, 0.7941651959799176, 0.8128239408337135, 0.8797587038109886, 0.8860677824518267, 0.8205888576047901, 0.833366431316752, 0.4793369605385459, 0.37127449826039716, 0.4599585812487873, 0.4840984969880967, 0.4888003142387133, 0.46762626383710637, 0.35074531093363204, 0.43681859110379584, 0.5162763810592278, 0.08176633037132919, 0.09045753440556814, 0.07950106240172294, 0.0965257605850185, 0.0825453059457697, 0.08102446741089897, 0.08353371304042845, 0.08468915643590247, 0.08994738353113407, 0.03491405596637265, 0.0545101137523718, 0.052940146370301755, 0.04959179784535461, 0.039114943166644656, 0.04118015044288126, 0.059680585592965185, 0.05732695867472759, 0.03298258525042985, 0.9585045895078593, 0.8967492099312204, 0.7813922208827235, 0.9173855986720169, 0.9157256559993987, 0.794618644948665, 0.6022275653205145, 0.9511468397707423, 0.9661652433296222, 0.09053684364298153, 0.08974591179477465, 0.08711285849728778, 0.10080183090540618, 0.11566227074375424, 0.1774833860345818, 0.10600581384010366, 0.09848258405029608, 0.10986109730208449, 0.3022128952008404, 0.2628526233817863, 0.5266157965469996, 0.3658589026751248, 0.2357324718090109, 0.3280451939205993, 0.2900788151678567, 0.29164142518921266, 0.2734259590438801, 0.12590182225797109, 0.1472031375208286, 0.15669313002402685, 0.14303218196673173, 0.13315001506208668, 0.18413968015262294, 0.16260376179667324, 0.13612586348724742, 0.1134764664620066, 0.15732683601105402, 0.11814101042932201, 0.1056329446217058, 0.14235759804221504, 0.17817519012574845, 0.19562063978845945, 0.1638468324940845, 0.14285298282765402, 0.10542314091178284, 9.999999999998899e-05, 0.00016358001984173587, 9.999999999998899e-05, 9.999999999998899e-05, 0.09631224860321141, 9.999999999998899e-05, 9.999999999998899e-05, 0.06698625291697169, 0.004300169788878705, 0.07894974992511583, 0.058493831604142676, 0.1000709627193217, 0.12824414216793434, 0.058833016760291845, 0.05793910026901472, 0.08990146752567763, 0.0913999533312091, 0.0718369529994558, 0.017335207826943533, 0.13490425571052567, 0.06744965642811096, 0.1367392736118852, 0.14200372381861093, 0.07853771392211073, 0.15021410699327042, 0.11830824238129445, 0.12015985942950014, 0.42596267547427824, 0.2968986086355371, 0.2285450329967813, 0.4379652138466765, 0.3937776085120108, 0.29228492019903474, 0.4740589493361079, 0.15522547566364808, 0.5281439210251319, 0.636014884093757, 0.4830453951384337, 0.47703831865212043, 0.45166526995597034, 0.44317236171834695, 0.7010653366022983, 0.7233925671861468, 0.4883179290285373, 0.6398384007181426, 0.09074001811897758, 0.11447487284723334, 0.08599945254513675, 0.10445296239121105, 0.07936453511213548, 0.0902022023411515, 0.07610180159147617, 0.07515634191794962, 0.06674644755198988, 0.14022114818226294, 0.17554822439945406, 0.13359783446297246, 0.1409317284612791, 0.14092198360658326, 0.173145445585847, 0.1449018995448389, 0.13942587974498477, 0.12232620957981266, 0.28376739659617134, 0.22381707669572792, 0.2601819829713049, 0.26952781511886026, 0.2157964862317372, 0.2178078272205336, 0.2642683756273435, 0.23100316439009871, 0.20065644798030202, 0.17742319564079212, 0.15412023236126593, 0.1810101519066759, 0.16004458854665715, 0.1702387126095477, 0.1516491258663939, 0.156661141434705, 0.1994859781121351, 0.17330634449843418, 0.19993708169671176, 0.19048025195359986, 0.16724013546566252, 0.1907040780597128, 0.19520819839333414, 0.17850112741899826, 0.1833145714205161, 0.19171286471924376, 0.17561415061767005, 0.17488737360461093, 0.18460204910281852, 0.176939782836949, 0.17452577824083526, 0.18107762546836048, 0.17131717162742865, 0.18021118620234522, 0.1741440754844623, 0.1784250139988841, 0.15879164141693258, 0.16082910616076262, 0.17264970519403666, 0.17365134524246517, 0.15506891738962314, 0.1464547940763723, 0.1587999886323549, 0.136946766671451, 0.15788650229594003, 0.17045161151046762, 0.11341698965273606, 0.08312855118409768, 0.16858208476913716, 0.16848174449937592, 0.16626748291694926, 0.20970016121485302, 0.20581584844571754, 0.11222534786131122, 0.1857834028736911, 0.201541362708058, 0.19182533851673378, 0.18152758673360014, 0.19046476353487107, 0.17098304755913918, 0.18416765744607277, 0.1951861190240901, 0.18837431136735427, 0.07858697649318669, 0.06910253444303494, 0.07685981900388472, 0.06763231100865907, 0.06660814129602255, 0.07802661596948401, 0.06826479334851698, 0.0744118850802512, 0.06662760369968368]}, "mutation_prompt": null}
{"id": "164927f9-c04f-4fc9-818e-a6d9eb2eab25", "solution": "import numpy as np\n\nclass DCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.3)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean += np.dot(weights, selected - self.mean)\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "DCMAESOptimizer", "description": "Dynamic Covariance Matrix Adaptation Evolution Strategy (DCMA-ES) tailored with feedback-driven self-adaptation of strategy parameters.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5a102d74-6c79-4d7f-90fa-a0f63361c7e5", "metadata": {"aucs": [0.8014806973055866, 0.8358980558988997, 0.8291976485995799, 0.7941651959799176, 0.8128239408337135, 0.8797587038109886, 0.8860677824518267, 0.8205888576047901, 0.833366431316752, 0.4793369605385459, 0.37127449826039716, 0.4599585812487873, 0.4840984969880967, 0.4888003142387133, 0.46762626383710637, 0.35074531093363204, 0.43681859110379584, 0.5162763810592278, 0.08176633037132919, 0.09045753440556814, 0.07950106240172294, 0.0965257605850185, 0.0825453059457697, 0.08102446741089897, 0.08353371304042845, 0.08468915643590247, 0.08994738353113407, 0.03491405596637265, 0.0545101137523718, 0.052940146370301755, 0.04959179784535461, 0.039114943166644656, 0.04118015044288126, 0.059680585592965185, 0.05732695867472759, 0.03298258525042985, 0.9585045895078593, 0.8967492099312204, 0.7813922208827235, 0.9173855986720169, 0.9157256559993987, 0.794618644948665, 0.6022275653205145, 0.9511468397707423, 0.9661652433296222, 0.09053684364298153, 0.08974591179477465, 0.08711285849728778, 0.10080183090540618, 0.11566227074375424, 0.1774833860345818, 0.10600581384010366, 0.09848258405029608, 0.10986109730208449, 0.3022128952008404, 0.2628526233817863, 0.5266157965469996, 0.3658589026751248, 0.2357324718090109, 0.3280451939205993, 0.2900788151678567, 0.29164142518921266, 0.2734259590438801, 0.12590182225797109, 0.1472031375208286, 0.15669313002402685, 0.14303218196673173, 0.13315001506208668, 0.18413968015262294, 0.16260376179667324, 0.13612586348724742, 0.1134764664620066, 0.15732683601105402, 0.11814101042932201, 0.1056329446217058, 0.14235759804221504, 0.17817519012574845, 0.19562063978845945, 0.1638468324940845, 0.14285298282765402, 0.10542314091178284, 9.999999999998899e-05, 0.00016358001984173587, 9.999999999998899e-05, 9.999999999998899e-05, 0.09631224860321141, 9.999999999998899e-05, 9.999999999998899e-05, 0.06698625291697169, 0.004300169788878705, 0.07894974992511583, 0.058493831604142676, 0.1000709627193217, 0.12824414216793434, 0.058833016760291845, 0.05793910026901472, 0.08990146752567763, 0.0913999533312091, 0.0718369529994558, 0.017335207826943533, 0.13490425571052567, 0.06744965642811096, 0.1367392736118852, 0.14200372381861093, 0.07853771392211073, 0.15021410699327042, 0.11830824238129445, 0.12015985942950014, 0.42596267547427824, 0.2968986086355371, 0.2285450329967813, 0.4379652138466765, 0.3937776085120108, 0.29228492019903474, 0.4740589493361079, 0.15522547566364808, 0.5281439210251319, 0.636014884093757, 0.4830453951384337, 0.47703831865212043, 0.45166526995597034, 0.44317236171834695, 0.7010653366022983, 0.7233925671861468, 0.4883179290285373, 0.6398384007181426, 0.09074001811897758, 0.11447487284723334, 0.08599945254513675, 0.10445296239121105, 0.07936453511213548, 0.0902022023411515, 0.07610180159147617, 0.07515634191794962, 0.06674644755198988, 0.14022114818226294, 0.17554822439945406, 0.13359783446297246, 0.1409317284612791, 0.14092198360658326, 0.173145445585847, 0.1449018995448389, 0.13942587974498477, 0.12232620957981266, 0.28376739659617134, 0.22381707669572792, 0.2601819829713049, 0.26952781511886026, 0.2157964862317372, 0.2178078272205336, 0.2642683756273435, 0.23100316439009871, 0.20065644798030202, 0.17742319564079212, 0.15412023236126593, 0.1810101519066759, 0.16004458854665715, 0.1702387126095477, 0.1516491258663939, 0.156661141434705, 0.1994859781121351, 0.17330634449843418, 0.19993708169671176, 0.19048025195359986, 0.16724013546566252, 0.1907040780597128, 0.19520819839333414, 0.17850112741899826, 0.1833145714205161, 0.19171286471924376, 0.17561415061767005, 0.17488737360461093, 0.18460204910281852, 0.176939782836949, 0.17452577824083526, 0.18107762546836048, 0.17131717162742865, 0.18021118620234522, 0.1741440754844623, 0.1784250139988841, 0.15879164141693258, 0.16082910616076262, 0.17264970519403666, 0.17365134524246517, 0.15506891738962314, 0.1464547940763723, 0.1587999886323549, 0.136946766671451, 0.15788650229594003, 0.17045161151046762, 0.11341698965273606, 0.08312855118409768, 0.16858208476913716, 0.16848174449937592, 0.16626748291694926, 0.20970016121485302, 0.20581584844571754, 0.11222534786131122, 0.1857834028736911, 0.201541362708058, 0.19182533851673378, 0.18152758673360014, 0.19046476353487107, 0.17098304755913918, 0.18416765744607277, 0.1951861190240901, 0.18837431136735427, 0.07858697649318669, 0.06910253444303494, 0.07685981900388472, 0.06763231100865907, 0.06660814129602255, 0.07802661596948401, 0.06826479334851698, 0.0744118850802512, 0.06662760369968368]}, "mutation_prompt": null}
{"id": "d50db9e7-38e1-4d0b-8446-13cb677e679e", "solution": "import numpy as np\n\nclass AdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n        self.diversity_threshold = 1e-6\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.3)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            diversity = np.std(samples, axis=0).mean()\n            if diversity < self.diversity_threshold:\n                self.covariance_matrix += np.eye(self.dim) * 1e-3\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            new_mean = np.dot(weights, selected - self.mean)\n            self.mean += new_mean\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n            # Dynamic population size adjustment\n            if self.eval_count < self.budget / 2 and np.min(self.fitness) < np.median(self.fitness):\n                self.population_size = min(int(1.2 * self.population_size), self.budget - self.eval_count)\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "AdaptiveCMAESOptimizer", "description": "Adaptive Covariance Matrix Evolution Strategy with dynamic population scaling and enhanced diversity preservation.", "configspace": "", "generation": 34, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 8 is out of bounds for axis 0 with size 8').", "error": "IndexError('index 8 is out of bounds for axis 0 with size 8')", "parent_id": "5a102d74-6c79-4d7f-90fa-a0f63361c7e5", "metadata": {}, "mutation_prompt": null}
{"id": "a9cc8c06-d2ab-479b-a79a-a257ed60c7f9", "solution": "import numpy as np\n\nclass APSOOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = np.inf\n        self.omega = 0.5\n        self.phi_p = 0.5\n        self.phi_g = 0.9\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            r_p = np.random.uniform(0, 1, (self.population_size, self.dim))\n            r_g = np.random.uniform(0, 1, (self.population_size, self.dim))\n            self.velocities = (\n                self.omega * self.velocities +\n                self.phi_p * r_p * (self.personal_best_positions - self.positions) +\n                self.phi_g * r_g * (self.global_best_position - self.positions)\n            )\n            self.positions += self.velocities\n            self.positions = np.clip(self.positions, self.lower_bound, self.upper_bound)\n\n            # Adaptive parameter tuning\n            success_ratio = np.sum(self.personal_best_scores < score) / self.population_size\n            self.omega = max(0.4, self.omega * (1.0 if success_ratio > 0.5 else 0.9))\n            self.phi_p = min(1.0, self.phi_p + (0.1 if success_ratio < 0.2 else -0.1))\n            self.phi_g = max(0.5, self.phi_g - (0.1 if success_ratio > 0.7 else -0.1))\n\n        return self.global_best_position, self.global_best_score", "name": "APSOOptimizer", "description": "Adaptive Particle Swarm Optimization (APSO) with feedback-driven dynamic parameter tuning for enhanced exploration and exploitation balance.", "configspace": "", "generation": 35, "fitness": 0.15156834946131362, "feedback": "The algorithm APSOOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.20.", "error": "", "parent_id": "5a102d74-6c79-4d7f-90fa-a0f63361c7e5", "metadata": {"aucs": [0.6963317530207356, 0.24738324604492368, 0.5957230295308398, 0.29628232429845214, 0.37425256896220094, 0.1793466377986086, 0.2952166971515692, 0.6661588433824188, 0.36983961658588393, 0.015509186177593226, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0034227439003139404, 9.999999999998899e-05, 9.999999999998899e-05, 0.05043955296799618, 9.999999999998899e-05, 0.06541263214830018, 0.08488563686439865, 0.05167029345855645, 0.049376119858734135, 0.11432387298313063, 0.07546932345721902, 0.0328787447499459, 0.10498625387429983, 0.04847941513409404, 0.042014555137810716, 0.04095019454928028, 0.05464817757513252, 0.0587364057534302, 0.07667497236317322, 0.04865320528912054, 0.03379462732990157, 0.03987197674623966, 0.04800871247802274, 0.9248550780857628, 0.897309807616394, 0.9269343254177642, 0.9678444263437267, 0.8917870499727854, 0.9405443276621877, 0.9268674780004776, 0.8991491237767159, 0.9379509848080734, 0.15242488718799363, 0.11130096378688725, 0.05983528615623379, 0.02454192722077264, 0.018416881367444127, 0.15114454269555622, 0.09263554372819749, 0.20506663341890663, 0.1444475985955409, 0.17720035509888699, 0.09183760072939895, 0.13527595825189942, 0.2118831227319542, 0.1448647416802472, 0.12077683629450586, 0.14624314721134635, 0.11254740715606071, 0.23869039763990962, 0.06611275762162039, 0.11585544159646488, 9.999999999998899e-05, 0.13046871260997572, 0.168692532864406, 0.10214993901915637, 9.999999999998899e-05, 0.11998513971694813, 0.13555260031173022, 9.999999999998899e-05, 9.999999999998899e-05, 0.14777600780879196, 0.029880253589450567, 0.13637851487851893, 0.09751476123665126, 0.18859370060599, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.012470275071380654, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0664307858312948, 0.018661177195518186, 0.047988663021964584, 9.999999999998899e-05, 9.999999999998899e-05, 0.020309008122550765, 9.999999999998899e-05, 0.015534908321028107, 0.041618931524694425, 0.01911997993728165, 9.999999999998899e-05, 0.06247484180398988, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016923318932124176, 9.999999999998899e-05, 0.00460231235677111, 0.029698032396742513, 9.999999999998899e-05, 0.05965266791823032, 0.0758301081458983, 0.5094195269363762, 0.2584642345107955, 0.4028130606270691, 0.21047257161974653, 0.43650899922490594, 0.33426577129845025, 0.41582877130814877, 0.174288575590409, 0.21496728901488527, 0.015740231796043336, 0.04105081563535862, 0.057588845096424146, 0.06442405172972487, 0.10130478790832154, 0.02304216961988459, 0.04632254120115087, 0.04362318749305705, 0.040194389061095515, 0.09712376611560358, 0.13520057794733698, 0.1117729098273128, 0.13039321758722633, 0.20857976543804224, 0.09065339080326462, 0.19197820724899206, 0.1054261542664039, 0.12127910602323677, 0.1284294654928948, 0.14439873195636077, 0.1687796500129083, 0.19671212562102003, 0.20458054617110466, 0.24204169586429236, 0.15104941752525625, 0.2029670703604579, 0.10050998378989973, 0.15099976171390883, 0.11788616152861908, 0.1452751558622858, 0.10978091046897176, 0.10369058721880609, 0.13793980982202447, 0.12128040800410544, 0.1686994966260088, 0.042968006041182005, 0.14604303469794755, 0.16077459195281085, 0.13345086981233123, 0.1849960687488864, 0.13520094398305083, 0.15302096186446346, 0.14331674660512417, 0.14732251979907285, 0.1487851239044936, 0.020385446058351242, 0.17016288272697844, 0.18696087079246526, 0.16617632035755592, 0.16510225577145643, 0.1429864912558354, 9.999999999998899e-05, 0.1715157109185469, 0.1666014795424151, 0.9680955946215928, 0.12173172440686464, 0.11399342109885124, 0.24847361329672568, 0.17069870506332063, 0.19973339691082348, 0.1000131668076536, 0.17049878778848582, 0.13424046463343986, 0.1328018468878277, 0.21212811686305655, 0.06231125390513592, 0.21312585565942432, 0.16836688300656533, 0.05497298761290059, 0.10539166251929943, 0.3133547742901662, 0.11250675030654056, 0.16231541669136096, 0.1731935790194391, 0.14787213646260966, 0.18791868670660794, 0.174383974155766, 0.146403840010507, 0.17707778330090673, 0.17196667883453431, 0.16039670745220647, 0.035722037466083156, 0.029302379391132116, 0.07082748728025567, 0.06954259819914954, 0.034460621412014225, 0.04555870975260279, 0.043129354991952695, 0.04873145283057023, 0.04710969155908462]}, "mutation_prompt": null}
{"id": "63f95337-883f-48f9-80f4-49dae78141a7", "solution": "import numpy as np\n\nclass AMCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 3) / (self.dim + mu_eff + 4)  # Adjusted c_sigma for adaptive step size\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 3 * mu_eff / self.dim)  # Adjusted c_c for better convergence\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)  # Adjusted c_1 for more stability\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 1.5)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean += np.dot(weights, selected - self.mean)\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1 + 0.1))  # Adjusted step size update for exploration\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "AMCMAESOptimizer", "description": "Adaptive Multimodal CMA-ES with Enhanced Step Size Control (AM-CMA-ES) for robust exploration and exploitation with dynamic step size adaptation.", "configspace": "", "generation": 36, "fitness": 0.1579729866743918, "feedback": "The algorithm AMCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16 with standard deviation 0.18.", "error": "", "parent_id": "5a102d74-6c79-4d7f-90fa-a0f63361c7e5", "metadata": {"aucs": [0.43439974499139367, 0.3661128629939615, 0.30628636122925623, 0.3447600147180999, 0.4097271122903038, 0.45561136842410366, 0.4575813853215971, 0.40619005747504067, 0.4146189541929012, 0.028348271245912326, 0.02788153387274539, 0.051130679027049375, 0.030664402526193957, 0.012848897671278281, 0.022658092971670873, 0.020831818755832177, 0.02191724950619578, 0.02165200958561453, 0.08121822526707712, 0.057306604659168814, 0.08270497664951748, 0.06986092843097336, 0.06575463638562218, 0.05791596264916443, 0.08635248593634226, 0.08049296340141587, 0.07975992516633501, 0.0449048369893571, 0.034279205462019346, 0.02153849834127175, 0.026389669793794535, 0.03399893998942316, 0.03572738824931199, 0.04723221232711117, 0.03243094081989206, 0.035798836308972404, 0.9562753569845671, 0.9673028322764785, 0.9042013413021516, 0.8498817878548005, 0.5658071416229429, 0.9458096879248072, 0.6790098965815392, 0.9549580873739423, 0.9808090609675181, 0.08291665894684808, 0.10136550546620127, 0.08956613521447565, 0.10935979997872769, 0.11884910874138366, 0.08896477615044263, 0.11176317650493495, 0.09035473138493266, 0.09907412313217667, 0.22762428146222224, 0.21610389734507673, 0.21609344512156758, 0.19682151034028283, 0.1763850094847803, 0.21952015446509376, 0.2125947363742181, 0.19578933446577285, 0.207189601388174, 0.04931313546156613, 0.06370801182889685, 0.02682867447117987, 0.05778821523401734, 0.10374698839451468, 0.10781054126868772, 0.06085300045873554, 0.07882589693025088, 0.09005421538489622, 0.14221390378150567, 0.08930941864412545, 0.08547259155488685, 0.12186042092355676, 0.08985518763539169, 0.0800911318287173, 0.02871759388861206, 0.04730369549646862, 0.08062606675112438, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0598197553535228, 0.12285060934279313, 0.07712019076110432, 0.05147541509349285, 0.056410749942322425, 0.049860905913481135, 0.06527374211974979, 0.06501809092739108, 0.07691484270668303, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.004256300639243982, 9.999999999998899e-05, 0.10822959043492486, 0.0677965599042093, 0.07023296504010523, 0.11086340125651006, 0.06017603893531576, 0.05299259423873737, 0.06366482716474964, 0.03816947012294836, 0.07346281191776449, 0.2785868740104829, 0.2618656227644135, 0.28045678436811017, 0.2613821442815216, 0.3169175019657062, 0.2378733857098837, 0.29854312344153555, 0.3018873809070074, 0.25758936511283526, 0.0712581562626714, 0.08122293661324997, 0.09141351311288304, 0.06469019304645485, 0.06134927159402981, 0.06557251790567586, 0.06406558391282124, 0.05352693356335603, 0.06761291370835898, 0.1460105417632107, 0.13955137774621273, 0.1350739328313615, 0.16857162918217805, 0.16416964610452944, 0.1536821295136468, 0.12556293101432425, 0.14504152540411364, 0.13598229867401046, 0.177194789763778, 0.211026565752103, 0.1913067190282398, 0.19730049491378876, 0.181012440534001, 0.17133933735777596, 0.20499288158619, 0.19749393980401653, 0.20562590393909685, 0.11619164477904687, 0.11718186310444745, 0.13671877117211084, 0.1453067692616138, 0.13995214823570512, 0.12284010126220946, 0.12916329623181333, 0.13031742066102014, 0.12245035820809858, 0.18688301080263825, 0.17651270808439024, 0.17795960961490254, 0.20226196615879588, 0.17578590352669454, 0.16689315576491204, 0.15985857921195024, 0.16491743854464025, 0.16629584696716737, 0.17284637048931162, 0.1664393081191754, 0.16777962136053703, 0.16474349459773785, 0.17977942270080616, 0.17257109700495676, 0.16964978822623433, 0.16752324626652515, 0.18735623409540703, 0.16581171523727045, 0.14686098819130056, 0.16386619215416431, 0.197310845184282, 0.15412580886694727, 0.23563931595381604, 0.12341115158692006, 0.15259869869532372, 0.14889576524197035, 0.21558581627891726, 0.22463713245862404, 0.24160663213293565, 0.14555275496273568, 0.2079005395446264, 0.10877091145606754, 0.1973480284530108, 0.20039089520730669, 0.20509846833966272, 0.19938995479802002, 0.1823547765044765, 0.2431494073439896, 0.18569537342920817, 0.20578834968968696, 0.17798615163733356, 0.18254466194849106, 0.1851986867361053, 0.18694352219431754, 0.06964987085042662, 0.06868916823035598, 0.07349510170091256, 0.0642012896570372, 0.06548908973320944, 0.07380629156192842, 0.08444783484954876, 0.0608683044004642, 0.07217638057665465]}, "mutation_prompt": null}
{"id": "54d7076d-468d-4d72-8268-6cf76eea90c2", "solution": "import numpy as np\n\nclass APSOCovarianceOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 5 + int(3 * np.log(self.dim))\n        self.positions = np.random.uniform(-5.0, 5.0, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n\n    def __call__(self, func):\n        inertia_weight = 0.7\n        cognitive_coefficient = 1.5\n        social_coefficient = 1.5\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.positions[i])\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.positions[i])\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = cognitive_coefficient * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = social_coefficient * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive_velocity + social_velocity\n\n                # Covariance adaptation\n                cov_matrix = np.cov(self.positions.T)\n                self.positions[i] += np.dot(np.linalg.cholesky(cov_matrix), self.velocities[i])\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "name": "APSOCovarianceOptimizer", "description": "Adaptive Particle Swarm Optimization (APSO) with covariance adaptation for enhanced exploration and exploitation in high-dimensional spaces.", "configspace": "", "generation": 37, "fitness": -Infinity, "feedback": "An exception occurred: LinAlgError('Matrix is not positive definite').", "error": "LinAlgError('Matrix is not positive definite')", "parent_id": "5a102d74-6c79-4d7f-90fa-a0f63361c7e5", "metadata": {}, "mutation_prompt": null}
{"id": "ef6c4e06-c192-4031-b923-c9204b870261", "solution": "import numpy as np\n\nclass AMDCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n        self.best_individuals = []\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.3)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n                if self.fitness[i] < self.best_fitness:\n                    self.best_fitness = self.fitness[i]\n                    self.best_individuals.append(samples[i])\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean += np.dot(weights, selected - self.mean)\n\n            if len(self.best_individuals) > 0:\n                historical_mean = np.mean(self.best_individuals, axis=0)\n                self.mean = 0.5 * self.mean + 0.5 * historical_mean\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "AMDCMAESOptimizer", "description": "Adaptive Memory-based Dynamic CMA-ES incorporating historical bests for enhanced exploration-exploitation balance.", "configspace": "", "generation": 38, "fitness": 0.12107064963067674, "feedback": "The algorithm AMDCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.17.", "error": "", "parent_id": "5a102d74-6c79-4d7f-90fa-a0f63361c7e5", "metadata": {"aucs": [0.1712146472273165, 0.19465962500545997, 0.20854925345119912, 0.14629302976056646, 0.16588689729721695, 0.19066132838760375, 0.18095201477542078, 0.18083396586223321, 0.19362109235855607, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05307201297618447, 0.03224237553123388, 0.04072921590190215, 0.05824637963850221, 0.045195475230650484, 0.05301471607018715, 0.040128872475136634, 0.04163291533005997, 0.05377987011090668, 0.08542045138059384, 0.03526515460970803, 0.022572599942772498, 0.020180294472420757, 0.01623205071110101, 0.025097429746129052, 0.019445406133164922, 0.007093009537175954, 0.029271136627440852, 0.8678563439363733, 0.9578229154759408, 0.9854736662643223, 0.9521266345084853, 0.5677488198892072, 0.9601238128481542, 0.5567036774191889, 0.9904043486584543, 0.9742108482528775, 0.06950597727357655, 0.05964246412498142, 0.06352154254575249, 0.04229066231018919, 0.07076250079924606, 0.07646505955046601, 0.0783153143261397, 0.07329445451781724, 0.06979926372280698, 0.16760336718128255, 0.13943508984023234, 0.11270529480936275, 0.20399138433460162, 0.08610019298185323, 0.09361327202261505, 0.18789723889433985, 0.08614677894630363, 0.10625679124384191, 0.0005549817552477077, 0.0020783212233742576, 0.01437036463728747, 9.999999999998899e-05, 0.04643006341302003, 9.999999999998899e-05, 0.0037957855699314313, 9.999999999998899e-05, 0.03347961019671675, 0.04301093341454121, 0.009124102961255987, 0.028772432696341665, 0.06599448784760209, 9.999999999998899e-05, 0.05437783767649884, 0.026130596330062095, 0.0030802380975512023, 0.002022936088923011, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07484601971989724, 0.06820008426453528, 0.06060257055544771, 0.03634547716743686, 0.0614703620008098, 0.042602536388427925, 0.05148346499065026, 0.0429704836709881, 0.02449698231572528, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0059095956587014165, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00863832003121845, 0.1661953549657983, 0.1598561755151119, 0.2592358733869953, 0.22761555605291606, 0.19286270047289622, 0.1924304310162589, 0.1953519333014786, 0.22171172639266867, 0.19360196962234966, 0.047648804844044546, 0.03525806315151081, 0.04018254796894383, 0.02964102863081186, 0.042902285702788645, 0.06206705658918121, 0.04236523531867897, 0.05191607499652107, 0.050539550893584084, 0.12753515409929428, 0.15379660267366013, 0.13865746003669444, 0.1299341529658643, 0.14476753785564667, 0.1504962051078108, 0.1412761646947125, 0.13388282061520218, 0.15801817087341974, 0.15608841815220442, 0.1555967840161393, 0.15745368109020907, 0.18358134455211705, 0.17397820103001327, 0.1680481589270505, 0.17564061810199016, 0.14047700095434523, 0.1510829984843789, 0.10894833767930123, 0.0931719997155891, 0.10020748682033409, 0.11779234582999976, 0.0963805346388843, 0.10763488942117982, 0.11063361888007128, 0.0941006338885001, 0.09956016949943425, 0.14480279058144463, 0.17801599339898644, 0.1753706003720159, 0.17602376255442687, 0.15856333121205957, 0.1608334943626849, 0.17463591220190888, 0.14259900531233305, 0.15615696849323535, 0.164750880459538, 0.13480499406248436, 0.12718057017639095, 0.1559767154248366, 0.15629387607339107, 0.153393493418021, 0.1590108089107225, 0.07940297269815089, 0.10389945366227293, 0.15284455844373968, 0.14930479398555396, 0.132394110053755, 0.14345744724639675, 0.14752024746290227, 0.14690664180267654, 0.16788433817643467, 0.14859970094594688, 0.1596886431204535, 0.1753087533091926, 0.11354697950378101, 0.14278190223842324, 0.1349712350800084, 0.12106080049980394, 0.16489562746251507, 0.15998964803786675, 0.169215103278893, 0.1662707206327696, 0.18219905690362093, 0.18091299853635356, 0.18618164288970396, 0.19075377164682095, 0.18257591166453568, 0.19217936597820384, 0.19535855843899863, 0.18342274327422103, 0.18746028559367767, 0.05965285012229071, 0.04372473672672417, 0.05639738744779865, 0.060061512396004435, 0.036852751107023685, 0.04855937080564077, 0.0501792688448115, 0.054827141639225196, 0.0557827062264703]}, "mutation_prompt": null}
{"id": "55c6616e-52aa-4cd1-a4e9-88b3a91e4b68", "solution": "import numpy as np\n\nclass ARCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n        self.rotation_matrix = np.eye(self.dim)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.3)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.step_size**2 * (self.rotation_matrix @ self.covariance_matrix @ self.rotation_matrix.T), self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean += np.dot(weights, selected - self.mean)\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n            \n            if self.eval_count % (self.population_size * 10) == 0:\n                self.rotation_matrix = np.linalg.qr(np.random.randn(self.dim, self.dim))[0]\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "ARCMAESOptimizer", "description": "Adaptive Riemannian CMA-ES (AR-CMA-ES) with manifold-aware covariance adaptation for enhanced exploration.", "configspace": "", "generation": 39, "fitness": 0.201300053772071, "feedback": "The algorithm ARCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.23.", "error": "", "parent_id": "5a102d74-6c79-4d7f-90fa-a0f63361c7e5", "metadata": {"aucs": [0.892111427941133, 0.8973013518792924, 0.889345514052222, 0.8464236342098186, 0.902292966314818, 0.8664059401721462, 0.8540630390039727, 0.8665778662235417, 0.7758492615969217, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08340700009112534, 0.0777995078589524, 0.06473528039788579, 0.07855475654862099, 0.07304508175184854, 0.0780056851934745, 0.0831554467707607, 0.07629230280397137, 0.08179003815616381, 0.032845566121274206, 0.04559025850839493, 0.04204655830960269, 0.056814105207336096, 0.032969702277986235, 0.03326424427786556, 0.024227555488510966, 0.04132611893199212, 0.03241139815795391, 0.940566800168373, 0.9519057303252259, 0.9870347504484747, 0.9374419000652492, 0.9061911302114821, 0.9634652451656713, 0.8621356052717597, 0.9463354369976678, 0.9743681501557403, 0.13889458388017306, 0.1024593623588349, 0.09438891633065993, 0.07343540692715522, 0.08863097505592687, 0.09394652905230905, 0.14226180154208634, 0.11386994097153891, 0.11235151886873551, 0.20609728629453516, 0.2075411226235535, 0.18022234438115314, 0.24549127912493163, 0.28145719906203315, 0.24729500720391306, 0.20992844269947442, 0.18285824550650454, 0.18661286395049304, 0.1267582229928017, 0.10211042835220396, 0.1130568762912384, 0.13689231680701175, 0.17829101782543655, 0.13742523037461707, 0.1413720921193644, 0.14020081975820087, 0.14269912372692228, 0.11256278810558429, 0.1132184950786066, 0.15305563719655546, 0.12976248730790596, 0.13618032377709333, 0.13666888439622815, 0.11111499286784021, 0.10107155563134806, 0.11730570361878467, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08558812501017088, 0.06930821367746665, 0.08569366435369052, 0.04187922342258554, 0.07427101036266992, 0.045088546950938335, 0.08155131705129826, 0.04985265964980701, 0.09396808693754266, 0.17013196641353756, 0.16944062020992823, 0.1576324348122471, 0.11795413771530971, 0.10043871464462373, 0.1552037566208483, 0.20576992304896835, 0.138206438039284, 0.18162925210618497, 0.1540102535791863, 0.10469735824451254, 0.08242727568678765, 0.10420489609381078, 0.18769914042087965, 0.22682902037779307, 0.09978433455810554, 0.07986288020635857, 0.09825718009747031, 0.42229922228311645, 0.3841798485401682, 0.37358346571011736, 0.4238600716120331, 0.3993578879110793, 0.3961198114475478, 0.3343708314927778, 0.38611950010951934, 0.41879463461939936, 0.10020341788966092, 0.0836645027679207, 0.08962354548048934, 0.08335463016833655, 0.07450252708951643, 0.07919975878630625, 0.07482811608166628, 0.0827426272422197, 0.09172197622806766, 0.13503534010748042, 0.15219466296827178, 0.1541828319357612, 0.14636838552188114, 0.13243033277383087, 0.12493583533023689, 0.14108494654775805, 0.1718035206558881, 0.1796811483542733, 0.2464601403793708, 0.23438426677058455, 0.23846752995606357, 0.20642991752801731, 0.20957256080875764, 0.22938037252415533, 0.252248045385827, 0.2165713028158318, 0.21684104821120287, 0.1473056078756646, 0.20147672955139784, 0.17428983559247024, 0.15887322327100195, 0.14791985880375957, 0.14799823576094828, 0.15532338461429096, 0.1880440735894534, 0.16059067747891254, 0.1770758866265827, 0.19189085217286828, 0.18703919960963478, 0.17620120597430033, 0.18432304471865868, 0.19099584116595447, 0.18060825216484977, 0.23439981333033677, 0.1732792268553407, 0.1723157770612037, 0.1772832221954559, 0.18527995435896205, 0.17155985936711315, 0.16825904133214187, 0.20570554106746175, 0.1820879281469916, 0.1667275155495519, 0.1664967895423135, 0.1781890051396614, 0.15141275891053407, 0.18241947460463248, 0.23043286534188168, 0.14768704017125078, 0.1942825273514096, 0.21209264193437305, 0.16816924753706786, 0.10395057182807299, 0.17045457837324507, 0.16283556561105783, 0.08312071028450663, 0.1584770075139268, 0.1636024329383423, 0.13290841555810418, 0.19911991669636153, 0.21121173492369893, 0.17845478717900665, 0.1927773662721175, 0.1823815367339836, 0.19350708763401347, 0.17591149427784836, 0.17069988599579067, 0.18245521437630785, 0.1893833139977179, 0.1868961030308528, 0.17598204458607958, 0.06695433758110281, 0.06692913265451117, 0.06403678258741596, 0.06887753251301343, 0.07620594098991151, 0.06638867154654016, 0.06945104186743634, 0.0832742521824894, 0.08116284281931418]}, "mutation_prompt": null}
{"id": "e1b20f7a-32ed-42ed-b7ff-07495388899d", "solution": "import numpy as np\n\nclass AGIDCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 1) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean += np.dot(weights, selected - self.mean)\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "AGIDCMAESOptimizer", "description": "Adaptive Gradient-Inspired DCMA-ES leveraging deterministic perturbations for enhanced convergence.", "configspace": "", "generation": 40, "fitness": 0.2528234412486607, "feedback": "The algorithm AGIDCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.25.", "error": "", "parent_id": "5a102d74-6c79-4d7f-90fa-a0f63361c7e5", "metadata": {"aucs": [0.8861368216249015, 0.7823755218756737, 0.8404035625718849, 0.8861265284034724, 0.7732547426885413, 0.9037288463788069, 0.8183197582079078, 0.8085494029304832, 0.804286152001728, 0.504597130078857, 0.3647565088038064, 0.4492678506601059, 0.36989750515999, 0.3114470711781363, 0.5813549991937468, 0.5435313986462553, 0.3427764236808044, 0.5863399844436207, 0.08173169482885245, 0.08269893619719693, 0.07771120795749487, 0.11344389817264366, 0.08681732804198494, 0.07810090989089458, 0.08446424392505136, 0.08477097087038032, 0.08835484170799102, 0.07140995010784812, 0.04229962349239447, 0.04108140921090164, 0.04352857055531878, 0.051388055765172025, 0.037268268773184565, 0.047959384217665546, 0.06119177457222735, 0.029232068372114783, 0.9633237370159276, 0.768194640361427, 0.9561488670233561, 0.9400045542271402, 0.9673776123918243, 0.9498415154127768, 0.980016069967393, 0.9539545901250047, 0.987741662214771, 0.07887666732956167, 0.10110842305264578, 0.10032308498566, 0.07700879226714274, 0.09809079762421336, 0.08461391813294972, 0.114141433735507, 0.1255672551149699, 0.11649257177400307, 0.3452240226971649, 0.3524873741184187, 0.283881312694762, 0.33377488447172343, 0.2631018331699079, 0.5162969091487122, 0.8261462509025106, 0.27714464969948827, 0.2277514570911826, 0.18389458622210064, 0.13845623749599423, 0.19132524628502856, 0.14516277355558416, 0.1261985116254205, 0.12725924052337545, 0.12381324186314102, 0.12339719208098576, 0.185263722126065, 0.14327821248225814, 0.13006260151659266, 0.11356154550790254, 0.17773342372324152, 0.1250596657586548, 0.16201872138498308, 0.11904649438456638, 0.10374619271333452, 0.1513015148504866, 0.0002769545837458809, 0.028936787619115778, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0066798321794573345, 0.11208800971701471, 9.999999999998899e-05, 0.1298232225167294, 0.11075740139859158, 0.09623695636796925, 0.08156939801621699, 0.0747214761919831, 0.06075095473510028, 0.09123505340582672, 0.09891885908861564, 0.07614486383369456, 0.06684544113621105, 0.05104508359441229, 0.0567688306602675, 0.1279509970907653, 0.05999941352542937, 0.047947146392200324, 0.2080751670488583, 0.02554380338862261, 0.042081993144444274, 0.48432360859878865, 0.32259680774004795, 0.30307206573968537, 0.5996104887833607, 0.48334507021691997, 0.46379497819094495, 0.5506383030793287, 0.46263833620938255, 0.5576813090596353, 0.45399916729592293, 0.4782368786809874, 0.6817045111204183, 0.5930051905834951, 0.5689718604740204, 0.6958533533786727, 0.6568868059352553, 0.5247454323312972, 0.4771084053484317, 0.09993345311158319, 0.08339137729473955, 0.08715267371193858, 0.08605054841997795, 0.07721632321668426, 0.07225149608129655, 0.08292613055742826, 0.07780867747270315, 0.09577848823238078, 0.15325189604752576, 0.1336658015364266, 0.15412480757556946, 0.1299331528019858, 0.16146366508088172, 0.13679125336634368, 0.149276821534706, 0.17108756766808042, 0.13454053835198299, 0.24285438211328714, 0.22532468558180774, 0.21749575757289352, 0.20569285611640897, 0.22633861925759136, 0.22569500790317676, 0.24076586842084846, 0.24627199492609375, 0.24001416188338942, 0.1778842218501655, 0.14078452963123, 0.1808023506307277, 0.17577674506924634, 0.14647107570318707, 0.16213322652279827, 0.16876770119572482, 0.18145499987853553, 0.16429447235492478, 0.1860196309929486, 0.17880785550053502, 0.17478007372520754, 0.22283474013154092, 0.20086915325908428, 0.17629877972790386, 0.1890240291181664, 0.2019340052597034, 0.18113493138951853, 0.1760065454462758, 0.18211643097228003, 0.1806933051483276, 0.17101036829163352, 0.1820624136714123, 0.17608093930920365, 0.1719091063397733, 0.1693089832091611, 0.16874255536495852, 0.17049415353820985, 0.13714781341988114, 0.9331674172529746, 0.30567975777430545, 0.1618455540577286, 0.14727350631556624, 0.16777496799489056, 0.16904698378289196, 0.1969441809293151, 0.2364687424753661, 0.1907856082275966, 0.10736145834082489, 0.16920811386248347, 0.20091137048244578, 0.15523437757895553, 0.16360095690982035, 0.21859743182622138, 0.35490745057217876, 0.18169138003156382, 0.19295004085091005, 0.1993949751610531, 0.18641559726364787, 0.18473124135298435, 0.1900802974805803, 0.1885199353299506, 0.1886045511452551, 0.17973240122011425, 0.07259754795250006, 0.0818370740198574, 0.06600371144453854, 0.06991170102455357, 0.07081824807559756, 0.07605704650556655, 0.07850213775636816, 0.06628520796927839, 0.07125161981306138]}, "mutation_prompt": null}
{"id": "254b2a84-950e-4b63-a58a-c1250b287d05", "solution": "import numpy as np\n\nclass ImprovedAGIDCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 1) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n        adaptation_rate = 0.2  # New parameter for adaptive learning rate\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean += adaptation_rate * np.dot(weights, selected - self.mean)  # Adjusted learning rate\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "ImprovedAGIDCMAESOptimizer", "description": "Enhanced Dynamic Covariance Adaptation with Adaptive Learning Rate and Stochastic Perturbations for Improved Optimization.", "configspace": "", "generation": 41, "fitness": 0.1492133793546585, "feedback": "The algorithm ImprovedAGIDCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.19.", "error": "", "parent_id": "e1b20f7a-32ed-42ed-b7ff-07495388899d", "metadata": {"aucs": [0.45129510500710845, 0.3100887281106245, 0.44008268830324704, 0.4752186248897541, 0.3159027276934089, 0.3650699891017585, 0.3678352969007139, 0.40122702963776624, 0.4325046542038432, 9.999999999998899e-05, 9.999999999998899e-05, 0.0066740151373134715, 0.01758980555949452, 9.999999999998899e-05, 0.010031087143300699, 0.006859670622775593, 9.999999999998899e-05, 0.014633520695473856, 0.07863339113871914, 0.0667816169920632, 0.05252541675548705, 0.08368588763418627, 0.06453363519339583, 0.06865388543854001, 0.07994609847787815, 0.07170421056791187, 0.06087253281426308, 0.03268377795161581, 0.02113910492971771, 0.01368531903473269, 0.027443813237183035, 0.021625992757471013, 0.02133310256104959, 0.021453765675654712, 0.019950708197829403, 0.019004667498125682, 0.984643677531452, 0.9564941012498511, 0.9801110221238655, 0.9819710033702146, 0.956601413992725, 0.9900917459690912, 0.9725143614453207, 0.986800632250739, 0.9378442550747157, 0.09967809274212358, 0.07441719388004331, 0.08207181440079003, 0.075612304325828, 0.10964074279586478, 0.06607909137599521, 0.08488244475194573, 0.10763784233872453, 0.09744838317602467, 0.17151361577012103, 0.20339539658875394, 0.17172609735021016, 0.19514260615228518, 0.12305750408324201, 0.1655328803290964, 0.13188840897491172, 0.12739011635381992, 0.14053565400704016, 0.0168211918381983, 0.026717007737295018, 0.01765693056829387, 0.03449435940906864, 0.036733780800258686, 0.02936462449375976, 0.0500457911945168, 0.10828448965951643, 0.054724408091777366, 0.076894110438397, 0.06888868370369805, 0.045547564858319456, 0.054579623696745516, 0.021112616991197486, 0.04379802880568573, 0.0821037048195592, 0.031458433551059484, 0.03415848400069732, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07197674610789706, 0.06820816791899653, 0.08724113858987348, 0.04044388719228231, 0.038358962424466014, 0.11383483839473552, 0.0699778730227989, 0.07778699785941223, 0.06138200968454477, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11643358216579558, 0.043386347917447, 0.08331218591843514, 0.05489644392647208, 0.04800093611394818, 0.07054138227102413, 0.011360590851362984, 0.007775051280495382, 0.02493903945403675, 0.2916024713729055, 0.26629482242228064, 0.2923952761680845, 0.18409929578106232, 0.2393654283426, 0.19552220487733207, 0.2594218112791171, 0.28424905794777255, 0.25654425728335584, 0.0648734009764701, 0.05809284208837018, 0.08999429102942702, 0.05696083767323867, 0.058977243619398156, 0.058496984242960015, 0.053505173177955445, 0.06253732363124509, 0.050492783134975294, 0.14984394335243556, 0.1821150339355302, 0.13165648151467468, 0.1486412436412491, 0.14643332925712094, 0.15724354617339598, 0.12988001383919745, 0.12612794331260357, 0.1389284300879584, 0.166922459448826, 0.20367510025465219, 0.17607072728810036, 0.1843216053131499, 0.1786676386351912, 0.16704343843332659, 0.17877253986956443, 0.16190131415373143, 0.16528440573377734, 0.10853241970221206, 0.1142957540320394, 0.09901181155834715, 0.12534401677346163, 0.1181136126528971, 0.1340866791422699, 0.14432783129743088, 0.11781617752472229, 0.10685910185174252, 0.1819429004279869, 0.1786167136888187, 0.20828662462555192, 0.1700917558144016, 0.16466807744467638, 0.1766476606828441, 0.17663894065899388, 0.1704486117721299, 0.1861534233656531, 0.16725971604620027, 0.1616409115860964, 0.16435487162559492, 0.182302684527053, 0.1617291230581377, 0.16872472096819635, 0.167846719579423, 0.15822063526545593, 0.17234892741266905, 0.1581292654016534, 0.15794806145979623, 0.1382991984615568, 0.16570311452535136, 0.1609628100811582, 0.15049537708878047, 0.11882126740847287, 0.16174715400453843, 0.1468978821900393, 0.1305422904316934, 0.15425237813897807, 0.16794797454322874, 0.10690628048491058, 0.15577160052542782, 0.137113429342264, 0.21725490094402855, 0.15622280165952684, 0.1466397893737056, 0.18497731153514796, 0.18119384540616623, 0.18031979943898546, 0.2025193328882603, 0.1859068752364229, 0.1922869734801903, 0.20960833207213503, 0.1789121080539824, 0.18261105292704838, 0.05914335320858677, 0.06222814932144227, 0.05373346558673675, 0.06746975450492299, 0.06380113445703706, 0.06049991456925674, 0.06364079800896472, 0.05616947663242011, 0.06931527681611116]}, "mutation_prompt": null}
{"id": "bb45ad55-d6b5-4129-8ae8-9846db1e804a", "solution": "import numpy as np\n\nclass EnhancedAGIDCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 1) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Introduce a crossover for half the population\n                if np.random.rand() < 0.5:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.5 * (samples[i] + samples[crossover_idx])\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean += np.dot(weights, selected - self.mean)\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "EnhancedAGIDCMAESOptimizer", "description": "Enhanced Gradient-Inspired DCMA-ES with adaptive step size and crossover strategy for improved global exploration.", "configspace": "", "generation": 42, "fitness": 0.3408285069114729, "feedback": "The algorithm EnhancedAGIDCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.26.", "error": "", "parent_id": "e1b20f7a-32ed-42ed-b7ff-07495388899d", "metadata": {"aucs": [0.9474550548002822, 0.9377314796022677, 0.9377701200910731, 0.9272011104586387, 0.9108195186015363, 0.9260468123312169, 0.9447634888714841, 0.9287015573781117, 0.9433648218982313, 0.4797575584488819, 0.5578044485601088, 0.5766464627227987, 0.6449346597523136, 0.5629490824103871, 0.49988925072300183, 0.4604874303123393, 0.5816457098056869, 0.5411972599728865, 0.1639901886718057, 0.11067855895189427, 0.049154766474167055, 0.12026213053496082, 0.14045150684249108, 0.1272325102302313, 0.0720319679925231, 0.11106864609312617, 0.161517538412825, 0.11768540593719645, 0.08722826878148571, 0.06332882689241293, 0.12117988787919842, 0.0851826925537571, 0.08663040197817606, 0.07472541671058786, 0.08719516061063859, 0.010270405684493555, 0.20248563299936773, 0.6268743224459721, 0.8383911420844264, 0.14685411034803797, 0.3703274036206987, 0.19649490724494978, 0.2910709648134505, 0.22825654257905803, 0.5721660817782491, 0.22645625201247144, 0.1570276329030469, 0.3327542108679574, 0.16613780825923585, 0.15750106738925929, 0.27948686653803667, 0.21962188229362656, 0.2057521303797324, 0.30573223528976523, 0.6343092826486161, 0.7668755157137426, 0.2067321085822691, 0.9407248660990387, 0.502701431019307, 0.22961758421660727, 0.1971285461845942, 0.5806805515972372, 0.25416034398120324, 0.5504635852645344, 0.5133078123841157, 0.3738776519802971, 0.5673788698617358, 0.37712911464167587, 0.6931681955821776, 0.13678745781129142, 0.330903744448533, 0.473606967018261, 0.530546616334231, 0.24768238405453347, 0.44056944522489483, 0.4361445468618357, 0.1311517997932331, 0.1369661204438044, 0.6056004739902752, 0.29523975951185044, 0.5129839208007155, 0.39716643416141373, 0.5937901435604962, 0.39474599440250846, 0.4936939515936828, 0.6070039217662058, 0.47343841170610534, 0.5762604391391523, 0.567635418149828, 0.6511196406189312, 0.4817887663410829, 0.6311032895585297, 0.4064010126841747, 0.6925908406364951, 0.1139959246518556, 0.06412626561876167, 0.7078336259335506, 0.5092587772784714, 0.38182890004508785, 0.2488665947348594, 0.05992803240575706, 0.24037896550596483, 0.34774471205364366, 0.35230133937486285, 0.1267366636374858, 0.2583943266545845, 0.4403521855260547, 0.1150978043689922, 0.3331085272055406, 0.3056191461822928, 0.19030774427110242, 0.3345881068989244, 0.2840654146896645, 0.3491993344928027, 0.281341935734419, 0.28176315691836606, 0.21923668616321101, 0.8385532325261953, 0.8290958630929363, 0.7816678509012274, 0.814216323678629, 0.7548501447426151, 0.8119571057993333, 0.7810658919888454, 0.7986777643537095, 0.783458022438906, 0.09758641534523049, 0.1140959506426017, 0.14481323158253967, 0.11727398132905231, 0.07279847560478847, 0.16386170762414876, 0.0574851602117209, 0.13553582735465408, 0.09993801551409742, 0.45768926816158517, 0.16355781096477007, 0.3560712309452875, 0.1405277906490211, 0.17531639596293858, 0.23023249898836207, 0.1717457574530512, 0.3848520777603509, 0.20282812301337538, 0.27819894206964846, 0.33612419723156195, 0.1078727046705058, 0.4602343420543753, 0.41391126684840607, 0.13189280293384276, 0.22201156508237563, 0.27371183495497575, 0.24188135263424848, 0.05037011622866172, 0.3613262974700929, 0.1710641595463187, 0.31528559626037445, 0.25474729254385875, 0.13391868359689163, 0.3179227634612102, 0.27390496221610827, 0.025022215434976403, 0.22486466055192544, 0.20125585620856168, 0.20454360889417744, 0.19524069619752737, 0.19592888072092296, 0.2390179501830162, 0.19300749865132416, 0.2019761690012628, 0.23362838703183608, 0.16925079712164548, 0.18611584417338123, 0.18249561773776846, 0.17041372272845823, 0.22313340757291988, 0.18914271122310655, 0.17823935518251632, 0.17743255880815778, 0.16926598014591288, 0.12327292097383868, 0.13764657017119042, 0.9311315237125583, 0.9526446615977946, 0.11198375247928505, 0.16674790756505353, 0.10867577455503996, 0.1153574165829665, 0.15397011626874768, 0.914295364264797, 0.11343234790602763, 0.08263668159700044, 0.16913162357214884, 0.21215725070849822, 0.8708904159692253, 0.8833507230209274, 0.05910956009546242, 0.8037792099013492, 0.19191705335231213, 0.24771305808433763, 0.18769743601346522, 0.1727341849692282, 0.21011385148935047, 0.18017760765845559, 0.17835175168504047, 0.1882387700639091, 0.18514089453563953, 0.07547868249293965, 0.08825092253499733, 0.07811957158375316, 0.08317433342710279, 0.09107829402541556, 0.0998748785912007, 0.0879759300534444, 0.08126731151409983, 0.09570999132267421]}, "mutation_prompt": null}
{"id": "f559353f-728e-4081-94a2-58f8649d8061", "solution": "import numpy as np\n\nclass EnhancedAGIDCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 1) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Introduce a crossover for half the population\n                if np.random.rand() < 0.5:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.5 * (samples[i] + samples[crossover_idx])\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean += np.dot(weights, selected - self.mean)\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "EnhancedAGIDCMAESOptimizer", "description": "Enhanced Gradient-Inspired DCMA-ES with adaptive step size and crossover strategy for improved global exploration.", "configspace": "", "generation": 43, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "bb45ad55-d6b5-4129-8ae8-9846db1e804a", "metadata": {"aucs": [0.9474550548002822, 0.9377314796022677, 0.9377701200910731, 0.9272011104586387, 0.9108195186015363, 0.9260468123312169, 0.9447634888714841, 0.9287015573781117, 0.9433648218982313, 0.4797575584488819, 0.5578044485601088, 0.5766464627227987, 0.6449346597523136, 0.5629490824103871, 0.49988925072300183, 0.4604874303123393, 0.5816457098056869, 0.5411972599728865, 0.1639901886718057, 0.11067855895189427, 0.049154766474167055, 0.12026213053496082, 0.14045150684249108, 0.1272325102302313, 0.0720319679925231, 0.11106864609312617, 0.161517538412825, 0.11768540593719645, 0.08722826878148571, 0.06332882689241293, 0.12117988787919842, 0.0851826925537571, 0.08663040197817606, 0.07472541671058786, 0.08719516061063859, 0.010270405684493555, 0.20248563299936773, 0.6268743224459721, 0.8383911420844264, 0.14685411034803797, 0.3703274036206987, 0.19649490724494978, 0.2910709648134505, 0.22825654257905803, 0.5721660817782491, 0.22645625201247144, 0.1570276329030469, 0.3327542108679574, 0.16613780825923585, 0.15750106738925929, 0.27948686653803667, 0.21962188229362656, 0.2057521303797324, 0.30573223528976523, 0.6343092826486161, 0.7668755157137426, 0.2067321085822691, 0.9407248660990387, 0.502701431019307, 0.22961758421660727, 0.1971285461845942, 0.5806805515972372, 0.25416034398120324, 0.5504635852645344, 0.5133078123841157, 0.3738776519802971, 0.5673788698617358, 0.37712911464167587, 0.6931681955821776, 0.13678745781129142, 0.330903744448533, 0.473606967018261, 0.530546616334231, 0.24768238405453347, 0.44056944522489483, 0.4361445468618357, 0.1311517997932331, 0.1369661204438044, 0.6056004739902752, 0.29523975951185044, 0.5129839208007155, 0.39716643416141373, 0.5937901435604962, 0.39474599440250846, 0.4936939515936828, 0.6070039217662058, 0.47343841170610534, 0.5762604391391523, 0.567635418149828, 0.6511196406189312, 0.4817887663410829, 0.6311032895585297, 0.4064010126841747, 0.6925908406364951, 0.1139959246518556, 0.06412626561876167, 0.7078336259335506, 0.5092587772784714, 0.38182890004508785, 0.2488665947348594, 0.05992803240575706, 0.24037896550596483, 0.34774471205364366, 0.35230133937486285, 0.1267366636374858, 0.2583943266545845, 0.4403521855260547, 0.1150978043689922, 0.3331085272055406, 0.3056191461822928, 0.19030774427110242, 0.3345881068989244, 0.2840654146896645, 0.3491993344928027, 0.281341935734419, 0.28176315691836606, 0.21923668616321101, 0.8385532325261953, 0.8290958630929363, 0.7816678509012274, 0.814216323678629, 0.7548501447426151, 0.8119571057993333, 0.7810658919888454, 0.7986777643537095, 0.783458022438906, 0.09758641534523049, 0.1140959506426017, 0.14481323158253967, 0.11727398132905231, 0.07279847560478847, 0.16386170762414876, 0.0574851602117209, 0.13553582735465408, 0.09993801551409742, 0.45768926816158517, 0.16355781096477007, 0.3560712309452875, 0.1405277906490211, 0.17531639596293858, 0.23023249898836207, 0.1717457574530512, 0.3848520777603509, 0.20282812301337538, 0.27819894206964846, 0.33612419723156195, 0.1078727046705058, 0.4602343420543753, 0.41391126684840607, 0.13189280293384276, 0.22201156508237563, 0.27371183495497575, 0.24188135263424848, 0.05037011622866172, 0.3613262974700929, 0.1710641595463187, 0.31528559626037445, 0.25474729254385875, 0.13391868359689163, 0.3179227634612102, 0.27390496221610827, 0.025022215434976403, 0.22486466055192544, 0.20125585620856168, 0.20454360889417744, 0.19524069619752737, 0.19592888072092296, 0.2390179501830162, 0.19300749865132416, 0.2019761690012628, 0.23362838703183608, 0.16925079712164548, 0.18611584417338123, 0.18249561773776846, 0.17041372272845823, 0.22313340757291988, 0.18914271122310655, 0.17823935518251632, 0.17743255880815778, 0.16926598014591288, 0.12327292097383868, 0.13764657017119042, 0.9311315237125583, 0.9526446615977946, 0.11198375247928505, 0.16674790756505353, 0.10867577455503996, 0.1153574165829665, 0.15397011626874768, 0.914295364264797, 0.11343234790602763, 0.08263668159700044, 0.16913162357214884, 0.21215725070849822, 0.8708904159692253, 0.8833507230209274, 0.05910956009546242, 0.8037792099013492, 0.19191705335231213, 0.24771305808433763, 0.18769743601346522, 0.1727341849692282, 0.21011385148935047, 0.18017760765845559, 0.17835175168504047, 0.1882387700639091, 0.18514089453563953, 0.07547868249293965, 0.08825092253499733, 0.07811957158375316, 0.08317433342710279, 0.09107829402541556, 0.0998748785912007, 0.0879759300534444, 0.08126731151409983, 0.09570999132267421]}, "mutation_prompt": null}
{"id": "2b9e19b8-9576-45bc-abb6-6e67c2e8cf1e", "solution": "import numpy as np\n\nclass HybridDEACOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.6\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        F = 0.8  # Differential weight\n        CR = 0.9  # Crossover probability\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 1) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_sigma = np.zeros(self.dim)\n        \n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            self.fitness[i] = func(population[i])\n            self.eval_count += 1\n\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), self.lower_bound, self.upper_bound)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < self.fitness[i]:\n                    self.fitness[i] = trial_fitness\n                    population[i] = trial\n\n            indices = np.argsort(self.fitness)\n            selected = population[indices[:len(weights)]]\n            self.mean += np.dot(weights, selected - self.mean)\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * np.outer(self.mean - selected[0], self.mean - selected[0]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return population[best_idx], self.fitness[best_idx]", "name": "HybridDEACOptimizer", "description": "Hybrid Differential Evolution with Adaptive Covariance Strategy improving global exploration and convergence speed.", "configspace": "", "generation": 44, "fitness": -Infinity, "feedback": "An exception occurred: LinAlgError('Matrix is not positive definite').", "error": "LinAlgError('Matrix is not positive definite')", "parent_id": "bb45ad55-d6b5-4129-8ae8-9846db1e804a", "metadata": {}, "mutation_prompt": null}
{"id": "e09320bb-0e41-4023-8262-b90f8c24f4cd", "solution": "import numpy as np\n\nclass EnhancedAGIDCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 1) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Introduce a crossover for half the population\n                if np.random.rand() < 0.5:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.5 * (samples[i] + samples[crossover_idx])\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean += np.dot(weights, selected - self.mean)\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "EnhancedAGIDCMAESOptimizer", "description": "Enhanced Gradient-Inspired DCMA-ES with adaptive step size and crossover strategy for improved global exploration.", "configspace": "", "generation": 43, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "bb45ad55-d6b5-4129-8ae8-9846db1e804a", "metadata": {"aucs": [0.9474550548002822, 0.9377314796022677, 0.9377701200910731, 0.9272011104586387, 0.9108195186015363, 0.9260468123312169, 0.9447634888714841, 0.9287015573781117, 0.9433648218982313, 0.4797575584488819, 0.5578044485601088, 0.5766464627227987, 0.6449346597523136, 0.5629490824103871, 0.49988925072300183, 0.4604874303123393, 0.5816457098056869, 0.5411972599728865, 0.1639901886718057, 0.11067855895189427, 0.049154766474167055, 0.12026213053496082, 0.14045150684249108, 0.1272325102302313, 0.0720319679925231, 0.11106864609312617, 0.161517538412825, 0.11768540593719645, 0.08722826878148571, 0.06332882689241293, 0.12117988787919842, 0.0851826925537571, 0.08663040197817606, 0.07472541671058786, 0.08719516061063859, 0.010270405684493555, 0.20248563299936773, 0.6268743224459721, 0.8383911420844264, 0.14685411034803797, 0.3703274036206987, 0.19649490724494978, 0.2910709648134505, 0.22825654257905803, 0.5721660817782491, 0.22645625201247144, 0.1570276329030469, 0.3327542108679574, 0.16613780825923585, 0.15750106738925929, 0.27948686653803667, 0.21962188229362656, 0.2057521303797324, 0.30573223528976523, 0.6343092826486161, 0.7668755157137426, 0.2067321085822691, 0.9407248660990387, 0.502701431019307, 0.22961758421660727, 0.1971285461845942, 0.5806805515972372, 0.25416034398120324, 0.5504635852645344, 0.5133078123841157, 0.3738776519802971, 0.5673788698617358, 0.37712911464167587, 0.6931681955821776, 0.13678745781129142, 0.330903744448533, 0.473606967018261, 0.530546616334231, 0.24768238405453347, 0.44056944522489483, 0.4361445468618357, 0.1311517997932331, 0.1369661204438044, 0.6056004739902752, 0.29523975951185044, 0.5129839208007155, 0.39716643416141373, 0.5937901435604962, 0.39474599440250846, 0.4936939515936828, 0.6070039217662058, 0.47343841170610534, 0.5762604391391523, 0.567635418149828, 0.6511196406189312, 0.4817887663410829, 0.6311032895585297, 0.4064010126841747, 0.6925908406364951, 0.1139959246518556, 0.06412626561876167, 0.7078336259335506, 0.5092587772784714, 0.38182890004508785, 0.2488665947348594, 0.05992803240575706, 0.24037896550596483, 0.34774471205364366, 0.35230133937486285, 0.1267366636374858, 0.2583943266545845, 0.4403521855260547, 0.1150978043689922, 0.3331085272055406, 0.3056191461822928, 0.19030774427110242, 0.3345881068989244, 0.2840654146896645, 0.3491993344928027, 0.281341935734419, 0.28176315691836606, 0.21923668616321101, 0.8385532325261953, 0.8290958630929363, 0.7816678509012274, 0.814216323678629, 0.7548501447426151, 0.8119571057993333, 0.7810658919888454, 0.7986777643537095, 0.783458022438906, 0.09758641534523049, 0.1140959506426017, 0.14481323158253967, 0.11727398132905231, 0.07279847560478847, 0.16386170762414876, 0.0574851602117209, 0.13553582735465408, 0.09993801551409742, 0.45768926816158517, 0.16355781096477007, 0.3560712309452875, 0.1405277906490211, 0.17531639596293858, 0.23023249898836207, 0.1717457574530512, 0.3848520777603509, 0.20282812301337538, 0.27819894206964846, 0.33612419723156195, 0.1078727046705058, 0.4602343420543753, 0.41391126684840607, 0.13189280293384276, 0.22201156508237563, 0.27371183495497575, 0.24188135263424848, 0.05037011622866172, 0.3613262974700929, 0.1710641595463187, 0.31528559626037445, 0.25474729254385875, 0.13391868359689163, 0.3179227634612102, 0.27390496221610827, 0.025022215434976403, 0.22486466055192544, 0.20125585620856168, 0.20454360889417744, 0.19524069619752737, 0.19592888072092296, 0.2390179501830162, 0.19300749865132416, 0.2019761690012628, 0.23362838703183608, 0.16925079712164548, 0.18611584417338123, 0.18249561773776846, 0.17041372272845823, 0.22313340757291988, 0.18914271122310655, 0.17823935518251632, 0.17743255880815778, 0.16926598014591288, 0.12327292097383868, 0.13764657017119042, 0.9311315237125583, 0.9526446615977946, 0.11198375247928505, 0.16674790756505353, 0.10867577455503996, 0.1153574165829665, 0.15397011626874768, 0.914295364264797, 0.11343234790602763, 0.08263668159700044, 0.16913162357214884, 0.21215725070849822, 0.8708904159692253, 0.8833507230209274, 0.05910956009546242, 0.8037792099013492, 0.19191705335231213, 0.24771305808433763, 0.18769743601346522, 0.1727341849692282, 0.21011385148935047, 0.18017760765845559, 0.17835175168504047, 0.1882387700639091, 0.18514089453563953, 0.07547868249293965, 0.08825092253499733, 0.07811957158375316, 0.08317433342710279, 0.09107829402541556, 0.0998748785912007, 0.0879759300534444, 0.08126731151409983, 0.09570999132267421]}, "mutation_prompt": null}
{"id": "97c6ddbe-b69b-43b6-a02e-bac204de3ff1", "solution": "import numpy as np\n\nclass AdaptiveQuantumDCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n        self.quantum_rate = 0.1\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 1) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Introduce a quantum tunneling mechanism for some individuals\n                if np.random.rand() < self.quantum_rate:\n                    samples[i] = self.mean + np.random.normal(0, self.step_size, self.dim)\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean += np.dot(weights, selected - self.mean)\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "AdaptiveQuantumDCMAESOptimizer", "description": "Adaptive Quantum-inspired DCMA-ES with dynamic quantum tunneling for enhanced local search and improved convergence.", "configspace": "", "generation": 46, "fitness": 0.13174102489303777, "feedback": "The algorithm AdaptiveQuantumDCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.19.", "error": "", "parent_id": "bb45ad55-d6b5-4129-8ae8-9846db1e804a", "metadata": {"aucs": [0.21087361674248872, 0.2094033926392126, 0.21123531681314034, 0.22422027454210092, 0.17436460868061365, 0.2388963012988612, 0.19390665865024337, 0.34969719855451364, 0.20617077042139442, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08090456729875639, 0.04829934083953591, 0.07299470949920828, 0.05254973001183638, 0.047047336516472194, 0.05342865107324757, 0.06449637240130246, 0.033659010614358165, 0.059108931616789206, 0.05519168505959082, 0.031469275389258144, 0.019332415983945084, 0.027446807948092067, 0.020650288313598164, 0.019662221709898065, 0.02289254580464184, 0.054511668896704446, 0.04273364968481841, 0.9796952241442638, 0.985618500084178, 0.990727911878924, 0.9887454470469207, 0.9892553997949182, 0.9835291647006364, 0.9818245134956316, 0.9823868898335895, 0.97957918653263, 0.06430760437915017, 0.07272501974955958, 0.07709168294546676, 0.06620890017545822, 0.08698599176751265, 0.08166603990374666, 0.06670796832479786, 0.07205356801462481, 0.08522540028088277, 0.1587220141198773, 0.12915710810088732, 0.16167493727935267, 0.14521672795712015, 0.1416500530266931, 0.1258475980461069, 0.1771231894854729, 0.11965212649689638, 0.1597458618580072, 0.005777095883866434, 9.999999999998899e-05, 9.999999999998899e-05, 0.025870727688548145, 9.999999999998899e-05, 9.999999999998899e-05, 0.0026690228177636, 0.007640107927462614, 0.006339757034036442, 0.022943092563301848, 0.004494360841106548, 0.01413378964375911, 0.07586917162755125, 0.006765170491723982, 0.010294241201560528, 0.12515897461951409, 0.0319329336055203, 0.05506551526904824, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03717000305260132, 0.049561344620868475, 0.03544329334649232, 0.05009999604294513, 0.04806663171949366, 0.023824798318435758, 0.03840895921264986, 0.13163189925119823, 0.037837533709146554, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00011929605107796615, 0.012848825024257549, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01757337652631108, 0.28883607729788974, 0.1806710045110005, 0.20867661641707935, 0.20008462668993998, 0.17517707635862967, 0.19367023550656626, 0.20949437128959347, 0.2027744348051268, 0.20070186418236968, 0.05759447300259668, 0.052413948252041154, 0.04177179324745739, 0.04742027668377613, 0.03184215720929895, 0.04344344437589731, 0.06448277180342687, 0.04331446053568799, 0.08001363503966408, 0.1411732062751545, 0.13766405084758404, 0.1949788618924726, 0.13595207167710854, 0.13730470861538602, 0.1327908153977081, 0.15010511259213344, 0.14991190703823887, 0.13579645625044812, 0.17226152554086294, 0.16602564539567088, 0.16686156022910614, 0.17010940098478056, 0.15716246951952995, 0.1637955680928146, 0.17435985516237074, 0.15923574773312577, 0.16533391764166994, 0.11594721163410504, 0.11855533465134016, 0.1263186088666447, 0.11653852219721994, 0.09953563984116631, 0.10369510625303846, 0.1281352676744264, 0.1044463154372659, 0.10437499462565025, 0.15795487695025767, 0.14518673636542467, 0.15182458889067074, 0.15760237915156272, 0.19274022699983884, 0.15477154572111196, 0.17542266454184086, 0.14104624137217237, 0.17245177352959984, 0.1685533840714003, 0.14784752312497784, 0.1561290962783225, 0.1637924452253372, 0.14810627235717233, 0.16033747763800943, 0.1685306287509949, 0.16350234178109624, 0.16798108098508235, 0.15179333127200223, 0.17142311828657586, 0.16635231568326125, 0.16671155859043196, 0.11481106723786039, 0.1151358746023623, 0.12471753446268319, 0.2100142689562654, 0.13283349620878904, 0.22629648329582475, 0.15246635804273423, 0.13189376104377648, 0.11217592435083257, 0.1438841276787609, 0.10531305146820014, 0.1399039470567759, 0.18020231783892704, 0.12634451661929413, 0.18042247915276532, 0.19378978492339194, 0.1718970076793488, 0.18621198433313513, 0.18322756476812596, 0.18464975976363074, 0.18420668509620441, 0.18335175580806662, 0.18644875280827122, 0.07218582552500086, 0.050740968450862955, 0.07679455180332095, 0.050957394876667284, 0.06082289442807942, 0.04564537651683076, 0.05782994317652557, 0.05222967534998624, 0.058330192212481036]}, "mutation_prompt": null}
{"id": "342c5b17-a686-4aad-b26d-cf5e2c32ad8c", "solution": "import numpy as np\n\nclass EnhancedAGIDCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 1) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Introduce a crossover for half the population\n                if np.random.rand() < 0.5:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.5 * (samples[i] + samples[crossover_idx])\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean += np.dot(weights, selected - self.mean)\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "EnhancedAGIDCMAESOptimizer", "description": "Enhanced Gradient-Inspired DCMA-ES with adaptive step size and crossover strategy for improved global exploration.", "configspace": "", "generation": 43, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "bb45ad55-d6b5-4129-8ae8-9846db1e804a", "metadata": {"aucs": [0.9474550548002822, 0.9377314796022677, 0.9377701200910731, 0.9272011104586387, 0.9108195186015363, 0.9260468123312169, 0.9447634888714841, 0.9287015573781117, 0.9433648218982313, 0.4797575584488819, 0.5578044485601088, 0.5766464627227987, 0.6449346597523136, 0.5629490824103871, 0.49988925072300183, 0.4604874303123393, 0.5816457098056869, 0.5411972599728865, 0.1639901886718057, 0.11067855895189427, 0.049154766474167055, 0.12026213053496082, 0.14045150684249108, 0.1272325102302313, 0.0720319679925231, 0.11106864609312617, 0.161517538412825, 0.11768540593719645, 0.08722826878148571, 0.06332882689241293, 0.12117988787919842, 0.0851826925537571, 0.08663040197817606, 0.07472541671058786, 0.08719516061063859, 0.010270405684493555, 0.20248563299936773, 0.6268743224459721, 0.8383911420844264, 0.14685411034803797, 0.3703274036206987, 0.19649490724494978, 0.2910709648134505, 0.22825654257905803, 0.5721660817782491, 0.22645625201247144, 0.1570276329030469, 0.3327542108679574, 0.16613780825923585, 0.15750106738925929, 0.27948686653803667, 0.21962188229362656, 0.2057521303797324, 0.30573223528976523, 0.6343092826486161, 0.7668755157137426, 0.2067321085822691, 0.9407248660990387, 0.502701431019307, 0.22961758421660727, 0.1971285461845942, 0.5806805515972372, 0.25416034398120324, 0.5504635852645344, 0.5133078123841157, 0.3738776519802971, 0.5673788698617358, 0.37712911464167587, 0.6931681955821776, 0.13678745781129142, 0.330903744448533, 0.473606967018261, 0.530546616334231, 0.24768238405453347, 0.44056944522489483, 0.4361445468618357, 0.1311517997932331, 0.1369661204438044, 0.6056004739902752, 0.29523975951185044, 0.5129839208007155, 0.39716643416141373, 0.5937901435604962, 0.39474599440250846, 0.4936939515936828, 0.6070039217662058, 0.47343841170610534, 0.5762604391391523, 0.567635418149828, 0.6511196406189312, 0.4817887663410829, 0.6311032895585297, 0.4064010126841747, 0.6925908406364951, 0.1139959246518556, 0.06412626561876167, 0.7078336259335506, 0.5092587772784714, 0.38182890004508785, 0.2488665947348594, 0.05992803240575706, 0.24037896550596483, 0.34774471205364366, 0.35230133937486285, 0.1267366636374858, 0.2583943266545845, 0.4403521855260547, 0.1150978043689922, 0.3331085272055406, 0.3056191461822928, 0.19030774427110242, 0.3345881068989244, 0.2840654146896645, 0.3491993344928027, 0.281341935734419, 0.28176315691836606, 0.21923668616321101, 0.8385532325261953, 0.8290958630929363, 0.7816678509012274, 0.814216323678629, 0.7548501447426151, 0.8119571057993333, 0.7810658919888454, 0.7986777643537095, 0.783458022438906, 0.09758641534523049, 0.1140959506426017, 0.14481323158253967, 0.11727398132905231, 0.07279847560478847, 0.16386170762414876, 0.0574851602117209, 0.13553582735465408, 0.09993801551409742, 0.45768926816158517, 0.16355781096477007, 0.3560712309452875, 0.1405277906490211, 0.17531639596293858, 0.23023249898836207, 0.1717457574530512, 0.3848520777603509, 0.20282812301337538, 0.27819894206964846, 0.33612419723156195, 0.1078727046705058, 0.4602343420543753, 0.41391126684840607, 0.13189280293384276, 0.22201156508237563, 0.27371183495497575, 0.24188135263424848, 0.05037011622866172, 0.3613262974700929, 0.1710641595463187, 0.31528559626037445, 0.25474729254385875, 0.13391868359689163, 0.3179227634612102, 0.27390496221610827, 0.025022215434976403, 0.22486466055192544, 0.20125585620856168, 0.20454360889417744, 0.19524069619752737, 0.19592888072092296, 0.2390179501830162, 0.19300749865132416, 0.2019761690012628, 0.23362838703183608, 0.16925079712164548, 0.18611584417338123, 0.18249561773776846, 0.17041372272845823, 0.22313340757291988, 0.18914271122310655, 0.17823935518251632, 0.17743255880815778, 0.16926598014591288, 0.12327292097383868, 0.13764657017119042, 0.9311315237125583, 0.9526446615977946, 0.11198375247928505, 0.16674790756505353, 0.10867577455503996, 0.1153574165829665, 0.15397011626874768, 0.914295364264797, 0.11343234790602763, 0.08263668159700044, 0.16913162357214884, 0.21215725070849822, 0.8708904159692253, 0.8833507230209274, 0.05910956009546242, 0.8037792099013492, 0.19191705335231213, 0.24771305808433763, 0.18769743601346522, 0.1727341849692282, 0.21011385148935047, 0.18017760765845559, 0.17835175168504047, 0.1882387700639091, 0.18514089453563953, 0.07547868249293965, 0.08825092253499733, 0.07811957158375316, 0.08317433342710279, 0.09107829402541556, 0.0998748785912007, 0.0879759300534444, 0.08126731151409983, 0.09570999132267421]}, "mutation_prompt": null}
{"id": "03ece562-4dbc-4e12-80c5-33f74caa932c", "solution": "import numpy as np\n\nclass QuantumCoherentHybridDCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                if np.random.rand() < 0.2:  # Enhanced crossover probability\n                    crossover_idx1 = np.random.randint(0, self.population_size)\n                    crossover_idx2 = np.random.randint(0, self.population_size)\n                    samples[i] = 0.5 * (samples[crossover_idx1] + samples[crossover_idx2])\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean += np.dot(weights, selected - self.mean)\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "QuantumCoherentHybridDCMAESOptimizer", "description": "Quantum-Coherent Hybrid DCMA-ES leveraging quantum-inspired mechanisms and adaptive crossover for enhanced exploration.", "configspace": "", "generation": 48, "fitness": 0.32756386117607783, "feedback": "The algorithm QuantumCoherentHybridDCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.26.", "error": "", "parent_id": "bb45ad55-d6b5-4129-8ae8-9846db1e804a", "metadata": {"aucs": [0.8511315954262699, 0.8423872573386895, 0.9191527700073993, 0.8804999358906624, 0.882025362791629, 0.9225543640517598, 0.9074801248949245, 0.881440321811052, 0.8759110432421839, 0.48137974143779705, 0.5841379931739896, 0.625929043350845, 0.5377162088785914, 0.6318854173893165, 0.6296227005943057, 0.6055785121429998, 0.5918503686459171, 0.5852076866646874, 0.07979704332572912, 0.09645611347248084, 0.09169698783087366, 0.08980802202287219, 0.08315250264833796, 0.09193194221836876, 0.09749539421429654, 0.09081803711487824, 0.11190431610543616, 0.08704977244605194, 0.06857623696908488, 0.06223993553290241, 0.06477141123772168, 0.07088093723945788, 0.09124540157805239, 0.06650446861210824, 0.07924775718118449, 0.06795336927896223, 0.5174653778955138, 0.8098720171973736, 0.9120253639648361, 0.18691871634895663, 0.18444279366973626, 0.9854485796756794, 0.9741953341670697, 0.9661578564818515, 0.6870911559298745, 0.12799442711902853, 0.145061641249551, 0.13253921617181674, 0.12177623758486045, 0.11758705995552976, 0.11772899544087945, 0.12676921650158035, 0.133055256675493, 0.20541322601387613, 0.26351795132441536, 0.6701888339679727, 0.767593931855119, 0.7773280768788302, 0.708955054174931, 0.7164327300548987, 0.35510038865491866, 0.5943139357156216, 0.7185122087367224, 0.5258982657663784, 0.3401903156473941, 0.4684197465869604, 0.5933466986497113, 0.3823771806351691, 0.264762748364859, 0.5128675125641771, 0.5286779786588298, 0.41088703859846143, 0.31282603168761813, 0.4526184969605538, 0.2878887970757792, 0.5063342734251055, 0.3949079544436781, 0.12202003775890002, 0.48001465051983483, 0.43201530531651544, 0.5239432422152014, 0.4008288858037632, 0.26824701806528706, 0.6006750213905081, 0.5242439690192713, 0.2633082807434407, 0.5527203077465286, 0.5529943750703876, 0.43443699134107827, 0.383702959290913, 0.0975984238934865, 0.10704362687632929, 0.1064934843798161, 0.14758488437088402, 0.09858853151455005, 0.11479597869450575, 0.10869788736075481, 0.1122101768867898, 0.1269827876795182, 0.37690805158301466, 0.08438898585225485, 0.17674448036424217, 0.3081933430778382, 0.360137365530691, 0.4983751112386119, 0.17564155333219844, 0.203536417642865, 0.19043899002342723, 0.3778658723874452, 0.3258079054329054, 0.5173634375287763, 0.4724790447733268, 0.43379415078811634, 0.5270800423828645, 0.36262800162154685, 0.44859598723606386, 0.40611931811036595, 0.8135219614500638, 0.7166959615837142, 0.7695497764807171, 0.7163017793931616, 0.7157720022352545, 0.777885165860297, 0.7058775701035234, 0.7790018722350723, 0.7050153473959369, 0.09561715567373741, 0.08602564374049448, 0.10666294030866885, 0.07906218386332675, 0.09499813457610584, 0.09665306413564412, 0.0883759273850343, 0.08476161657930914, 0.10296572563294881, 0.16315504807024173, 0.16246589899708364, 0.3061403025291177, 0.13646483512673802, 0.15429403053916124, 0.14460046845862995, 0.12816819355649134, 0.20919756708468018, 0.11953704044939573, 0.3079233448642267, 0.30983516786357124, 0.35015258932990834, 0.25853898061418135, 0.27407639305453735, 0.3228662725436501, 0.3435563732185516, 0.3928061665288496, 0.3694184400321333, 0.22289630754130285, 0.375554667029666, 0.2441669693727666, 0.2958895715418618, 0.32094265883959183, 0.27473695433984635, 0.2431766157418025, 0.29686153413543537, 0.295013494631326, 0.20070716889360907, 0.22117265835024724, 0.1991094681801413, 0.1919814252556712, 0.19418807684601913, 0.202370322786127, 0.21588286866325812, 0.19777177494760712, 0.204316060041552, 0.18608434339813096, 0.17532622156569888, 0.1730914992196203, 0.17586265688175595, 0.18073824840571218, 0.17323109117547442, 0.17790761750949258, 0.17738422300649181, 0.17344307870879516, 0.15948384528911297, 0.13737263667522515, 0.9169190175357136, 0.11511653124736021, 0.08816947345840687, 0.14761610316479712, 0.15760041802224645, 0.11533347701309526, 0.1670964607326898, 0.9203561533294337, 0.11345588930459438, 0.06550110883699234, 0.16679373224500282, 0.20790848343365442, 0.06299760755784978, 0.10517175826012082, 0.1145565617044243, 0.130142786722641, 0.18399959904583374, 0.19595293145207304, 0.17654463405985588, 0.1922357090028971, 0.19119122115558362, 0.18034372093025086, 0.18110201425254224, 0.19046391151869835, 0.18584874738089474, 0.06808174279989143, 0.06711632662359357, 0.07333827238341806, 0.06679432492161763, 0.06717628713666923, 0.07347393263265112, 0.08899169048545374, 0.07904411913789222, 0.08460066199821736]}, "mutation_prompt": null}
{"id": "732ddb34-bb15-4167-a2f0-a9c703f9cd1e", "solution": "import numpy as np\n\nclass QuantumInspiredDCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.6\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 1) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                if np.random.rand() < 0.5:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.5 * (samples[i] + samples[crossover_idx])\n                if np.random.rand() < 0.1:  # Quantum-inspired stochastic tunneling\n                    samples[i] += np.random.uniform(-0.1, 0.1, self.dim) \n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean += np.dot(weights, selected - self.mean)\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredDCMAESOptimizer", "description": "Quantum-Inspired DCMA-ES with stochastic tunneling and diversity enhancement for improved exploration and exploitation balance.", "configspace": "", "generation": 49, "fitness": 0.2474695212360126, "feedback": "The algorithm QuantumInspiredDCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.21.", "error": "", "parent_id": "bb45ad55-d6b5-4129-8ae8-9846db1e804a", "metadata": {"aucs": [0.6868315720594222, 0.7083153772304298, 0.6888429727136918, 0.7121367149305782, 0.6922816997227079, 0.6949559672769465, 0.6823909741527772, 0.7137258758192384, 0.7049038731645707, 0.10268865497033852, 0.046842956798837765, 0.10372372594586299, 0.018779561531911737, 0.056556313717330386, 0.1038854444772247, 9.999999999998899e-05, 0.11561280365296733, 0.09550861531524002, 0.08675773945176823, 0.11690180910264003, 0.11996635288368984, 0.09349706338039943, 0.10607792097202495, 0.10145715107790054, 0.09934519378948004, 0.08736114811244211, 0.11163184437557061, 0.07295979219745874, 0.07373758892524696, 0.08706295672293529, 0.13237803299157802, 0.09578699016842052, 0.07981972078759758, 0.11109360005282665, 0.09765356049919971, 0.0927347896950288, 0.9680079569767936, 0.20396578668180787, 0.25023158821737623, 0.9674055626394598, 0.21362538587449287, 0.9674161283523924, 0.8216569159123182, 0.25755204677797805, 0.9483172380506999, 0.21658073395311617, 0.1679099076394961, 0.15562354599490613, 0.18069053065967944, 0.18009123639399183, 0.17939793666102433, 0.23717986381205025, 0.17301565003818264, 0.2747520707041039, 0.7862040475917483, 0.5680752952882875, 0.8088315286269983, 0.32859477360766776, 0.7156447526299257, 0.5011383577913149, 0.2408616291591702, 0.25621578865359784, 0.6854055199201117, 0.2290606579649852, 0.21584164054356025, 0.24483721067507136, 0.13063078153441254, 0.19752391527520086, 0.133782950272064, 0.22062537297781293, 0.2018408244940857, 0.21838382112666, 0.2321061573619908, 0.2222502274143785, 0.2161551963741234, 0.23294725865663546, 0.20026694975384052, 0.2272778502091659, 0.22696675700368218, 0.2150692882331805, 0.23376494325205321, 0.15249801071325675, 0.07004483386718607, 0.07321841987149347, 0.06773545798670988, 0.09354665579166921, 0.04399987351696821, 0.0739539294259306, 0.0857362422859338, 0.0591061099332717, 0.08747439303370319, 0.17115996976319148, 0.10077657528017969, 0.07585447104331211, 0.09090636106314887, 0.051458747657880166, 0.1293331101209635, 0.10056221817218991, 0.09673217198771877, 0.15639112625219131, 0.1529344589428009, 0.12481009499030027, 0.13152105988936236, 0.08291008787247667, 0.13588403230492407, 0.09220174893680577, 0.11202002045221293, 0.1064811736407828, 0.1415750190936842, 0.19023731497695995, 0.21203369699638008, 0.18309058383243582, 0.1364719927566035, 0.19605956447490214, 0.14899723463215164, 0.21020694018583186, 0.15877717906578015, 0.5085420295063645, 0.550141754296513, 0.5174286564549808, 0.5328963147534335, 0.49092860440514674, 0.5171363251775812, 0.5149978840501195, 0.5078103366487379, 0.4997693426189569, 0.1136736785681296, 0.12402371307641802, 0.13543438906462202, 0.10372314727311582, 0.10228212331952813, 0.13373479193303717, 0.14264443312214004, 0.09956442343294492, 0.09342039015979176, 0.4006764161219539, 0.3892241509478699, 0.4167853972894816, 0.3946309986642248, 0.20125988469011336, 0.21252315865040472, 0.21587892018005728, 0.3869130851697501, 0.36260343259800076, 0.37324215692230256, 0.38111936096749055, 0.36169580443975136, 0.3747307019991891, 0.3924461578910615, 0.36400357119920357, 0.23511175345667923, 0.40154068786803376, 0.38284342368927204, 0.29969646942659856, 0.08283131605516114, 0.21870099675114785, 0.31978532460088915, 0.2067670887212183, 0.2819599446914979, 0.16471651904849116, 0.19113721156789487, 0.30473419218304265, 0.21173603388558926, 0.21964345980396593, 0.19590184959961832, 0.20172335250537776, 0.21620789431798504, 0.18930089998773758, 0.19114905356597833, 0.22396586108213246, 0.21633510883622598, 0.18226573699493287, 0.18271419567569736, 0.18301501587191316, 0.17263947769535137, 0.17368638179943374, 0.18712999840683853, 0.18914540288511872, 0.18808531528596606, 0.19633164621614718, 0.188947125694356, 0.13749376783462108, 0.0711679924177624, 0.17392477767012537, 0.11180866129985423, 0.062025175564570545, 0.10874299832538348, 0.11538652203933286, 0.16711630419444523, 0.8959563119929591, 0.11347493463905811, 0.8204004931386096, 0.16910664852876034, 0.21243609771312155, 0.04427932715474159, 0.8797756957060567, 0.05914526860392744, 0.10462166973418074, 0.18404352192033835, 0.18608192183000138, 0.18374842331309682, 0.1789796318463468, 0.1801723584705669, 0.1980828641283462, 0.18028979179760085, 0.18312303874749414, 0.21621549348490776, 0.09172941506386145, 0.07968135146156818, 0.08168980882048726, 0.07755451743456765, 0.08294233146700025, 0.09472262962954192, 0.09610184694260393, 0.0778535515346852, 0.07317634755630664]}, "mutation_prompt": null}
{"id": "cc4f1eab-09bd-4b87-b28a-dd8387453317", "solution": "import numpy as np\n\nclass EnhancedAGIDCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Introduce a probabilistic crossover\n                if np.random.rand() < 0.25:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.5 * (samples[i] + samples[crossover_idx])\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            mean_old = self.mean\n            self.mean += np.dot(weights, selected - self.mean)\n\n            y_k = (selected - mean_old) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            if np.random.rand() < 0.25:\n                p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "EnhancedAGIDCMAESOptimizer", "description": "Enhanced Adaptive Gradient-Inspired DCMA-ES with dynamic covariance update and probabilistic crossover for robust exploration.", "configspace": "", "generation": 50, "fitness": 0.30769687837471693, "feedback": "The algorithm EnhancedAGIDCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.26.", "error": "", "parent_id": "bb45ad55-d6b5-4129-8ae8-9846db1e804a", "metadata": {"aucs": [0.9156333073708963, 0.9062269643749381, 0.8993132807299208, 0.9349773510480104, 0.9067183024371561, 0.7676366323432137, 0.9045383320975626, 0.8817674948220128, 0.8703509658377337, 0.38528323989687285, 0.505546390582196, 0.35988975984068927, 0.5639207507836392, 0.5709717590958769, 0.5208220929252761, 0.5076733996372385, 0.45515187862621775, 0.5264980408226206, 0.1411237244667054, 0.07598540374401941, 9.999999999998899e-05, 0.12359407380309295, 0.11868070367243633, 9.999999999998899e-05, 0.07691292143064854, 0.07219418578865155, 9.999999999998899e-05, 0.11227611144836902, 0.07772502745349952, 9.999999999998899e-05, 9.999999999998899e-05, 0.08434545881627675, 9.999999999998899e-05, 0.08924713081963387, 0.07920241848024978, 9.999999999998899e-05, 0.9849749857601376, 0.9639919658891115, 0.7817886857298892, 0.9530436245557709, 0.9577719001115509, 0.7055022080205338, 0.9153870050908849, 0.9313506085102028, 0.9615179549612638, 0.13714403521517582, 0.1474964113532411, 0.17432597082803736, 0.15906114388302417, 0.14390190338893538, 0.16166931301869647, 0.16685414213220517, 0.19833039146626952, 0.21441850447703537, 0.7942937594217562, 0.47662626877945335, 0.7550452728893371, 0.8552457453611735, 0.5244465816562232, 0.5980013580200343, 0.9006532605400752, 0.578222063318592, 0.5124200367155005, 0.18009241078416305, 0.13529416503831249, 0.13676924307659633, 0.530110274975477, 0.18010657769783045, 0.3677503154109696, 0.18632775089140308, 0.16360617445489078, 0.46737392507941566, 0.2091995879870434, 0.2478795720655972, 0.36016423539273923, 0.17846742146214856, 0.5903236975391734, 0.27575034066513593, 0.23310717163213723, 0.15268505980811642, 0.13237646952809778, 0.4215913434764633, 0.09638450443050683, 0.35523997655879114, 0.6669985577117652, 0.051815211222757895, 0.1794050538460943, 0.20690885548586702, 0.4869104614210058, 0.03911457202684454, 0.12130083558390126, 0.12178300107282991, 0.1623997887137555, 0.16903314231962707, 0.10273323916918253, 0.11275430537458964, 0.18721266028532368, 0.0886536508309217, 0.11847003695925107, 0.2207872046041588, 0.09390863453274068, 0.2331226266959917, 0.3338992501658611, 0.14787654001136796, 0.23039301381302835, 0.19207044698933096, 0.2877907832929305, 0.13307671370435914, 0.34354808712204965, 0.41299787835934343, 0.36270758035281037, 0.36606891193323954, 0.36188713987642684, 0.29471214299678583, 0.39906554371518, 0.2295358330159717, 0.26115258319211787, 0.7198784047914742, 0.605143928881956, 0.6995725689046217, 0.7951053540168024, 0.5608027652724271, 0.7486425943689905, 0.6502591008066176, 0.7383517390734242, 0.5670171905627579, 0.11901157670888929, 0.09662288100757777, 9.999999999998899e-05, 0.14954321097063217, 0.09874373382250601, 0.09842869147742217, 0.10675456068061828, 0.07300769722962308, 9.999999999998899e-05, 0.18028305200988248, 0.13603250661895816, 0.7110391597496226, 0.2443090793940892, 0.1773163110646292, 0.20065120849309737, 0.22931845173836163, 0.7529509416950579, 0.21965732331952392, 0.34096533642531535, 0.26973140349758873, 0.10346393553521482, 0.3692932391826278, 0.0877585402297274, 0.33328659028910057, 0.5604727899372969, 0.3393151891604642, 0.09487339967453268, 0.17244947953755596, 0.22729153793423695, 0.03785766759255471, 0.23153302085227, 0.2202018629892044, 0.11402720237694375, 0.1500371281053383, 0.16009289723326114, 0.21923758066257149, 0.2180267110143187, 0.18592046263050188, 0.2063000251359436, 0.21296879688893822, 0.21354095035912923, 0.19317724045526086, 0.1873070279655361, 0.20007021354575794, 0.19801251039554812, 0.17644600393468612, 0.1772624685590909, 0.17780530587383714, 0.1696773259215657, 0.17891749566051152, 0.16961793983316276, 0.1669467407691705, 0.17734603325377596, 0.1513399132806852, 0.12283188682767354, 0.198811697504648, 0.1758066710181898, 0.1710003463371238, 0.8292219507602794, 0.891811243106989, 0.16666742113042743, 0.11536129009487961, 0.1591758814584342, 0.25918489335038586, 0.11334608392533485, 0.1539542391004668, 0.16853547601016838, 0.2086612653436064, 0.19646886460277724, 0.2543929622722725, 0.19337480877982605, 0.15057867000574277, 0.21383234374413895, 0.19845223312914606, 0.18729190051176525, 0.18433554390954054, 0.1891516339580166, 0.23132889902614118, 0.193891162616174, 0.20319320489289172, 0.1805274281093231, 0.10014752418051576, 0.08286642116015996, 0.03657848410639819, 0.07967816248048387, 0.07982188878916674, 0.09013435188147778, 0.07584721275413309, 0.08049892868285902, 0.045460045382328285]}, "mutation_prompt": null}
{"id": "cfec7171-0f90-42c5-8d01-a193519e5d38", "solution": "import numpy as np\n\nclass AdaptiveQuantumDCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n        self.quantum_radius = 0.1  # Quantum-inspired radius\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Introduce a quantum-walk inspired mutation for enhanced exploration\n                if np.random.rand() < 0.25:\n                    quantum_shift = np.random.uniform(-self.quantum_radius, self.quantum_radius, self.dim)\n                    samples[i] += quantum_shift\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean += np.dot(weights, selected - self.mean)\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "AdaptiveQuantumDCMAESOptimizer", "description": "Adaptive Quantum-Inspired DCMA-ES with quantum-walk search strategy for enhanced exploration and convergence.", "configspace": "", "generation": 51, "fitness": 0.1839167146176502, "feedback": "The algorithm AdaptiveQuantumDCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.18.", "error": "", "parent_id": "bb45ad55-d6b5-4129-8ae8-9846db1e804a", "metadata": {"aucs": [0.5596154865448922, 0.5329863503668746, 0.48000766194322464, 0.5605702748394652, 0.4735016735226403, 0.46674140953203846, 0.5153325670845965, 0.5072406486613403, 0.5388754585983123, 0.06836017894975066, 0.030786324915132335, 0.059553462430891324, 0.0533168944474246, 0.025490500117766324, 0.037644679102616485, 0.06519005559769409, 0.012386153545303036, 0.06509588291174129, 0.06774418499034818, 0.09761838963408931, 0.07430433720875462, 0.10852205271193238, 0.08302944620718355, 0.08547858218758342, 0.09302522607641317, 0.08424192601707525, 0.07997070588097854, 0.06504702216328073, 0.05541681117623298, 0.0455008967494861, 0.04712851418817443, 0.050907071214182364, 0.04378701037472488, 0.0663279233190508, 0.04044240818304756, 0.05033579500117158, 0.7846822159410651, 0.8396237784204905, 0.956016554642505, 0.2700715048208302, 0.9744892212940199, 0.8101462543834024, 0.9386513707040841, 0.694312336702851, 0.9873693975259888, 0.11189447495423643, 0.08833914825923495, 0.08774699684003628, 0.08990085581789065, 0.11043923277052325, 0.1287002692001632, 0.10797143902689188, 0.10340748804535449, 0.10345439857946037, 0.3437573434813572, 0.2971017434461459, 0.3134927998358107, 0.3204363319624134, 0.3022887255163227, 0.24131554460685134, 0.2712590863302887, 0.28279816729844387, 0.3429202595438795, 0.12686029915591168, 0.1361502385992801, 0.15599438354738582, 0.1339010869856424, 0.14253310581569711, 0.15596592926412955, 0.17339441250084908, 0.15700883902474838, 0.1478277375732534, 0.1300072101867219, 0.11197044918371613, 0.12438701346145264, 0.14658513887238567, 0.1175224303069684, 0.14663694829783724, 0.16574120289424232, 0.11125133600994253, 0.13995380742071162, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0021551090549150054, 0.00018958016893810825, 9.999999999998899e-05, 0.07044007592518087, 0.13680166014301698, 0.09135392147369037, 0.08236755409070651, 0.08523375780469467, 0.05575692086369777, 0.10940038834375532, 0.07190149520395794, 0.10076934551912842, 0.00045986194492486643, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.15002716930274074, 0.1302131120820159, 0.127440028632818, 0.16723079938470342, 0.14285039864252136, 0.11889033816890116, 0.1625358636851697, 0.1403451009289829, 0.15283192630227405, 0.4409460058169551, 0.37083713249892203, 0.4344180658280581, 0.3910213519002348, 0.38462494623289945, 0.4057832527076656, 0.4389197233822699, 0.39619054913211915, 0.3883654335996888, 0.08397508644376739, 0.07873142287166845, 0.09722861213597844, 0.08045656859118244, 0.10547105003045931, 0.07893590851333554, 0.08000991029010407, 0.07443333537346664, 0.07707455917813533, 0.12784232801343698, 0.18438464731435422, 0.1366617999175227, 0.13692465740783832, 0.12961140045521913, 0.13955500575957636, 0.1582276144119067, 0.1319029025312135, 0.1626540758917845, 0.22088377251609193, 0.23441245679314948, 0.21004091895102373, 0.22935790686903113, 0.21075863017959195, 0.20809154528021168, 0.24043831595944065, 0.22249914917170355, 0.2283463455972906, 0.13753936991753057, 0.1372465641999039, 0.182329566442755, 0.1729351356972043, 0.16574366092732484, 0.17570426557178342, 0.14345146858337576, 0.1771722792695526, 0.17147383151348583, 0.1845879919078982, 0.17686426704939773, 0.20803149867599036, 0.18930211352776072, 0.17855933117748957, 0.1850247877359612, 0.18128967485796477, 0.18543922523159484, 0.18073003336033833, 0.17584168454570592, 0.17059362742397677, 0.17560208601368088, 0.17677567839868313, 0.17022160710468215, 0.1808956927731833, 0.17456440906699644, 0.16961088722231266, 0.1870898862023711, 0.1881201708483391, 0.18479358863504824, 0.18764175662526072, 0.17394386931498707, 0.15808290238884126, 0.16522371965731797, 0.14550718953292818, 0.17556797914186062, 0.18476777356630059, 0.2260948163190699, 0.14805289911833663, 0.16385992103115565, 0.16668378771067383, 0.16785274271530637, 0.16525523858633073, 0.20837832859043381, 0.2051857416445666, 0.10676177375430729, 0.17417621800257133, 0.19607538008135184, 0.18760930532967424, 0.1815704446794555, 0.18726155876897188, 0.1881053815784799, 0.19759139213584154, 0.1928508260982683, 0.2026819280669161, 0.07725473629597579, 0.07224736321285741, 0.06850140900566115, 0.06685940052698114, 0.06457496176544097, 0.07617277734822947, 0.07596967562015122, 0.06539336992614031, 0.0762061347286419]}, "mutation_prompt": null}
{"id": "4987f8a8-1304-45e6-8798-15db23ba7647", "solution": "import numpy as np\n\nclass HybridQuantumGradientDCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n        self.gradient_step = 0.01\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 1) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Quantum-inspired superposition and gradient-assisted refinement\n                if np.random.rand() < 0.25:\n                    perturbation = self.gradient_step * np.random.normal(size=self.dim)\n                    grad_estimate = (func(samples[i] + perturbation) - func(samples[i] - perturbation)) / (2 * self.gradient_step)\n                    samples[i] -= grad_estimate * self.step_size\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean += np.dot(weights, selected - self.mean)\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "HybridQuantumGradientDCMAESOptimizer", "description": "Hybrid Quantum-Inspired and Gradient-Assisted DCMA-ES leveraging quantum superposition for rapid exploration and gradient estimation for exploitation.", "configspace": "", "generation": 52, "fitness": -Infinity, "feedback": "An exception occurred: LinAlgError('Matrix is not positive definite').", "error": "LinAlgError('Matrix is not positive definite')", "parent_id": "bb45ad55-d6b5-4129-8ae8-9846db1e804a", "metadata": {}, "mutation_prompt": null}
{"id": "df440958-cdf6-4894-8e70-7de6a7df197d", "solution": "import numpy as np\n\nclass QuantumEnhancedDCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 1) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n        \n        tunneling_probability = 0.1\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Quantum-inspired tunneling: probabilistically choose a distant point\n                if np.random.rand() < tunneling_probability:\n                    samples[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean += np.dot(weights, selected - self.mean)\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "QuantumEnhancedDCMAESOptimizer", "description": "Adaptive Quantum-Inspired DCMA-ES with stochastic tunneling for enhanced global convergence through probabilistic exploration.", "configspace": "", "generation": 53, "fitness": 0.1535859254963461, "feedback": "The algorithm QuantumEnhancedDCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.17.", "error": "", "parent_id": "bb45ad55-d6b5-4129-8ae8-9846db1e804a", "metadata": {"aucs": [0.32561287589221266, 0.2955188561239619, 0.3006438484640228, 0.31317006853463725, 0.28149145034407996, 0.30366882226511616, 0.407921877439161, 0.3103293328510114, 0.2928209212142373, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.067553070461147, 0.0807722781472956, 0.06716080745594188, 0.07246613502003019, 0.067906864164065, 0.0687957419186851, 0.08239174103651525, 0.08490298719102574, 0.07000248547690224, 0.05554840495130742, 0.024889249059519503, 0.02912562093104698, 0.05057262883997993, 0.026265679400520492, 0.03513801214662182, 0.05560959458445536, 0.052060647436935836, 0.03259674082825581, 0.9139904558800214, 0.9175041287755487, 0.9416232657251418, 0.7180786170834441, 0.9319403467934942, 0.9510963571924718, 0.8684774876069714, 0.834767634438339, 0.8230460421317949, 0.11534428814971875, 0.08760628486892796, 0.08734163924505445, 0.08649263101151572, 0.08526187158847132, 0.08403866601733312, 0.09764771051658461, 0.08720910949965632, 0.08805945817822503, 0.18844267128531889, 0.17682405269649537, 0.1898319611580831, 0.18695130468054666, 0.1833787620108085, 0.19411528501876285, 0.18459318133521385, 0.20031403996021602, 0.18057027853347318, 0.0951335874488266, 0.05079385771029743, 0.05880059303154117, 0.07869288163958188, 0.07172752564514817, 0.09807730347678612, 0.07012356910321194, 0.10036750941099959, 0.08573457199100543, 0.13266799159942844, 0.0999549243951251, 0.10437237197323634, 0.10723629163249648, 0.10961429979246218, 0.11525195693953516, 0.1210449097705808, 0.07116464763497476, 0.08095381464710427, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06758230156565825, 0.05870149878213493, 0.08417594885936541, 0.07905822177083333, 0.07256720039709563, 0.0568238339528514, 0.0700309361825543, 0.06746071942506093, 0.05806489987558139, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.028035214871334424, 0.0290452516310159, 0.05213498626112578, 0.03889301910994325, 0.02042580779518155, 0.03711029144586864, 0.024630143630043677, 0.04021280265193805, 0.030353457399256545, 0.32562238291671175, 0.28869380391938027, 0.32152516999971825, 0.2654568339931105, 0.2795481710329867, 0.2356161868361243, 0.2956824166130744, 0.27196983611114, 0.27560958025695337, 0.0681574173890267, 0.07723025630084102, 0.07031835261527852, 0.08312939948814657, 0.06914788948210848, 0.07990136258609892, 0.08377516673471619, 0.06460161810044496, 0.06683627955198557, 0.13903479077581127, 0.1595757923783918, 0.14592160307376767, 0.14615691219875748, 0.14753841838600856, 0.1454758241716192, 0.1635142048708612, 0.1406930801066999, 0.1403909634263617, 0.21295194120023275, 0.1967382543648477, 0.18711513894305754, 0.21596917602960553, 0.22111517464545127, 0.21068237310556404, 0.18094998099412896, 0.1958415570440296, 0.18751379179738137, 0.13378826521187603, 0.12401685501404425, 0.13426561172945006, 0.13401993223749864, 0.140039021558791, 0.13824897537337022, 0.12459121550985897, 0.13519476305013123, 0.13021498027433887, 0.20950540906923043, 0.18481373388056288, 0.19512376487722582, 0.18169173084481582, 0.1676011943784782, 0.18387471298819802, 0.171146254123546, 0.1722039582391186, 0.19395013362221136, 0.17135300621267446, 0.17078964378803918, 0.17722276121652192, 0.1791717153296558, 0.1749407656482186, 0.16839751021041194, 0.17042914820435795, 0.16491485596293165, 0.16801134389998407, 0.18156065271610378, 0.17099865564681038, 0.21939810400574045, 0.18086672540419302, 0.1374879119999558, 0.1915145111363329, 0.1629170088089379, 0.17199861686872986, 0.20002344932186178, 0.27755584407431155, 0.16481115529527857, 0.2037234018036318, 0.1850987870809222, 0.18403863464957093, 0.18718200546589858, 0.16569978875188685, 0.1409004422820186, 0.1871365287002823, 0.1821792335311161, 0.20030851856788734, 0.19517152284585038, 0.18280602445674954, 0.18424819371793788, 0.1833625045430629, 0.17007567281101144, 0.18522599995311184, 0.18189621406629408, 0.06203897241325651, 0.08351002655243955, 0.06950158577528032, 0.06411107908872438, 0.06245153352980848, 0.06672677726098042, 0.06445018541376135, 0.06049736398781058, 0.07436049377773102]}, "mutation_prompt": null}
{"id": "8a39c7fc-b8b9-481c-b4e6-0be874581d14", "solution": "import numpy as np\n\nclass AdaptiveMomentumDCMAES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n        self.momentum = np.zeros(self.dim)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Introduce a crossover and momentum for half the population\n                if np.random.rand() < 0.5:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] += 0.5 * (samples[crossover_idx] - samples[i]) + 0.1 * self.momentum\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean += np.dot(weights, selected - self.mean)\n            self.momentum = 0.9 * self.momentum + 0.1 * np.mean(selected - self.mean, axis=0)\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "AdaptiveMomentumDCMAES", "description": "Adaptive Momentum-Inspired DCMA-ES with dynamic sampling and crossover for enhanced exploitation and exploration balance.", "configspace": "", "generation": 54, "fitness": 0.3249813253199819, "feedback": "The algorithm AdaptiveMomentumDCMAES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.26.", "error": "", "parent_id": "bb45ad55-d6b5-4129-8ae8-9846db1e804a", "metadata": {"aucs": [0.9459068088714129, 0.9313141605487808, 0.9436552371359302, 0.9239350244524258, 0.9464872407246498, 0.9347253842040171, 0.9189059786713483, 0.9325473434676588, 0.9310622566564295, 0.4028752321374287, 0.5529021787126935, 0.5249756572841009, 0.44070247740741586, 0.5864017519525275, 0.5088948510639472, 0.5006504598403678, 0.5566309143458099, 0.5677180141768506, 0.09719644899349567, 0.11432643530779896, 0.18434665534782757, 0.1138628659718639, 0.1003426642912485, 0.10039168529815357, 0.10302196749904147, 0.11169582280999824, 0.08641700729338098, 0.11120771223333503, 0.10504285770638944, 0.05155689250552298, 0.06086873841014584, 0.07630422171797413, 0.05358530921620508, 0.09793838014323297, 0.09437871648349994, 0.045838425439233665, 0.13540225732792388, 0.9581640508633742, 0.9311294117965062, 0.15356183893458997, 0.8249266014914249, 0.16856257736982294, 0.12013545567704731, 0.8259839286346935, 0.2148974262541522, 0.22018361720999347, 0.17166507026316868, 0.20546004684168662, 0.20667111795964643, 0.21026143159953248, 0.3046275810091653, 0.18547101710883418, 0.2074070415887137, 0.24718149793273225, 0.7992102862431398, 0.4301985282777928, 0.2508717602245939, 0.6416907690065006, 0.25952536144792504, 0.9092703391985527, 0.8741016001922902, 0.8561079646317352, 0.2674216433656258, 0.41011307679832765, 0.5240416483165631, 0.5284159081890478, 0.13479865115913237, 0.4975080043004878, 0.541840780570199, 0.4537248159511079, 0.312744177577429, 0.44352717269508946, 0.5973264172004252, 0.537596472957105, 0.13500289861975723, 0.5905649432858486, 0.5125109117505482, 0.4397546554974904, 0.6177817317256814, 0.6698307870405269, 0.461362003743212, 0.5547975692922176, 0.44095816355191175, 0.5999550767772591, 0.6415128403488973, 0.45549343345351423, 0.44421876647943814, 0.42056315472111483, 0.5787291538342036, 0.45666209617414943, 0.3339223573603616, 0.11047267152361018, 0.14785833515260927, 0.1271607275856923, 0.12625116181309004, 0.26808877820934285, 0.26558237930021666, 0.2845009694202667, 0.1503611395759803, 0.21837283365977178, 0.08065602350084922, 0.21098859899367595, 0.35814902302841434, 0.19467485574662347, 0.1358838376539443, 0.23609281697938855, 0.3370516918966797, 0.12959004619237402, 0.3061186332155621, 0.3621374415683143, 0.17769727702193538, 0.32010447608103687, 0.23098097497568215, 0.22157291762824594, 0.2948148494130398, 0.1951657121501632, 0.2307827419882018, 0.7512575432228397, 0.834144820912158, 0.799272087797476, 0.7851383250164637, 0.7818476126576146, 0.7835243491471653, 0.7504551650519509, 0.7990214827711186, 0.8051780762132597, 0.10543559886981257, 0.11823710656367636, 0.14419357768902663, 0.13284028259115965, 0.11685574259311793, 0.16209604482408213, 0.07724839239984616, 0.14410574145446775, 0.08754723337416948, 0.19024683900250539, 0.17085704185042871, 0.2874277251213093, 0.15045621715107793, 0.3112512838476321, 0.1596617134288626, 0.37049207561744224, 0.2800632665442465, 0.21060823838712228, 0.44712429837904655, 0.40309611240216414, 0.12107183006963318, 0.296833121715659, 0.2612469530687844, 0.14015706487364454, 0.16557066266142406, 0.42158813536854467, 0.2983759289236836, 0.26985304063592797, 0.3053393169188986, 0.48875336243828604, 0.24039989424380037, 0.2237091946061971, 0.15494139490323855, 0.2080454476547513, 0.20152075675755443, 0.03034875767777645, 0.19869290389530636, 0.207765573521561, 0.2330036619100173, 0.1911157682837682, 0.19977393455161496, 0.2226036582587242, 0.18842259259635652, 0.20039536955085546, 0.20738877699898317, 0.18898628889051716, 0.19482262876003476, 0.16493633051654888, 0.18286763507336, 0.17540974608787818, 0.1748756908699699, 0.1778547187565651, 0.17205917547314908, 0.17256691542839686, 0.12356767219458831, 0.13756298662890054, 0.9672063736019554, 0.17320867176969568, 0.0659292255133973, 0.061942480115597776, 0.10873156475574819, 0.11538852210589434, 0.15468094995624337, 0.930536189798142, 0.11318330166885715, 0.08303276250174463, 0.16973366839536086, 0.09865248405186844, 0.20853876501220536, 0.11312065390512849, 0.1271405028590199, 0.1220319245950161, 0.19239109118046271, 0.19453888314201673, 0.18059288990728928, 0.17509377064938159, 0.17553488362282899, 0.1985855736222365, 0.18455679374861222, 0.17502510677044225, 0.17902529953794344, 0.08631835710732882, 0.12909283154902862, 0.09010780675541974, 0.0814530020390486, 0.08442785277047038, 0.08867552732859585, 0.10960933426726482, 0.07431360800669229, 0.08638214643994402]}, "mutation_prompt": null}
{"id": "a8611eb5-d729-431b-968f-65e4c46b1415", "solution": "import numpy as np\n\nclass AdaptiveCMMOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.3 + (0.2 * np.random.rand())  # Adaptive step size initialization\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n        self.dim_reduction_factor = 0.1  # Introduce dimensionality reduction factor\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 1) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Introduce a cooperative mechanism for part of the population\n                if np.random.rand() < 0.5:\n                    partner_idx = np.random.randint(0, self.population_size)\n                    samples[i] += self.dim_reduction_factor * (samples[partner_idx] - samples[i])\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean += np.dot(weights, selected - self.mean)\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "AdaptiveCMMOptimizer", "description": "Adaptive Cooperative Multimodal Strategy with dynamic dimensionality reduction and weighted aggregation for enhanced optimization performance.", "configspace": "", "generation": 55, "fitness": 0.29247160912162584, "feedback": "The algorithm AdaptiveCMMOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.24.", "error": "", "parent_id": "bb45ad55-d6b5-4129-8ae8-9846db1e804a", "metadata": {"aucs": [0.8961635987115872, 0.8353058965071258, 0.8523225583265501, 0.892896011897115, 0.8919811124830098, 0.8352463289150055, 0.8907567146890164, 0.8978337300849687, 0.8582844694898812, 0.6456773386997448, 0.5250322992556707, 0.4803639820316147, 0.5779265915609291, 0.4892618029816037, 0.5551161179834838, 0.6055916007262795, 0.5801001554466079, 0.4577808317861253, 0.07989332900008761, 0.1018411763369218, 0.08943096592193145, 0.08329094749669852, 0.09187993981670428, 0.08892627044482415, 0.08660658994298187, 0.07903089526175733, 0.07791361559426346, 0.06474980450670087, 0.051595505945253195, 0.053889578244902814, 0.0549581474834715, 0.04782435825647058, 0.044841742094934633, 0.050043142809770846, 0.05996468607415628, 0.04564823517998451, 0.9864615174323345, 0.6288927648414774, 0.9098786289129078, 0.6359732338092452, 0.8397005473699646, 0.6548679776387869, 0.928883765966629, 0.9888603458449496, 0.9386311824156777, 0.11481328031554494, 0.0959310346990776, 0.1050811724414773, 0.11422025409304037, 0.08598109907899287, 0.09558131815167004, 0.1570511828309623, 0.14276383822475314, 0.13128415207953403, 0.30350048144778163, 0.4538486297369655, 0.29004573155103675, 0.6627524515421971, 0.31740391184310834, 0.30505907316953385, 0.6291618315130103, 0.5444922032415922, 0.624744202451748, 0.21794119619081298, 0.3152416489380817, 0.29852446360948304, 0.4472185436007068, 0.2559074235607811, 0.292935294209, 0.22024646204228193, 0.4273719532738054, 0.3864949618159941, 0.21765004138366773, 0.23438686712167722, 0.5160328090217707, 0.1460311520573856, 0.14120047055123197, 0.16021844875455082, 0.5479340194573005, 0.13621897724205023, 0.38082641499786307, 0.14761895381447432, 0.009454191908470633, 0.16292337119558664, 0.021333118108317506, 0.28919797886574483, 0.4135101596499794, 0.018585210760364457, 0.11854437721910382, 0.5493481822702573, 0.11246540850771758, 0.11966785897012211, 0.09128792955393805, 0.12745074336151407, 0.10204344376266727, 0.09180700630370975, 0.11148615333939238, 0.09303786418059679, 0.08965772588316867, 0.2404887269658852, 0.12433071911163862, 0.16409174958161654, 0.29789543256567275, 0.53232899644143, 0.23272343696262165, 0.2736237167292749, 0.3412402008779618, 0.19128250941660907, 0.5987916236787618, 0.4864878570391725, 0.4462295356543474, 0.5133841267286641, 0.5379830924803057, 0.5147351424070359, 0.4033863585848574, 0.5428456399186318, 0.4993576610837259, 0.7245636321133793, 0.6182899368944252, 0.745042735075983, 0.7527068420806484, 0.48722114777317316, 0.6686136696171874, 0.6926512090880508, 0.6229948535662411, 0.6671796703331702, 0.0876787452999408, 0.08267751844662086, 0.10734818572355287, 0.12113313233247336, 0.08668558947667171, 0.08050960925906236, 0.0952071706205676, 0.07833335253851692, 0.09937169549963687, 0.12485460226399903, 0.13250891431680245, 0.12347286237148059, 0.1419607491939736, 0.1401587661591388, 0.15144907889307524, 0.1487327111875707, 0.14983115201842845, 0.21362604175816313, 0.29146652451626387, 0.3150518509716431, 0.2871312535336834, 0.33965170846349935, 0.25244742503247586, 0.2980019796901333, 0.3130210157616261, 0.36486154680620153, 0.32556774453872994, 0.19774193445934418, 0.20605258144748018, 0.21634246443357097, 0.18138991893683476, 0.19680436511798072, 0.25932536781944515, 0.22882208276995197, 0.19663999636227425, 0.24487929919026485, 0.2090624901554955, 0.16774918228576785, 0.19398220698932378, 0.19558659311083837, 0.20566370469204953, 0.19062647271008915, 0.19407638804034577, 0.18711379697988162, 0.18137940633534877, 0.1745421263704715, 0.17422322708762983, 0.17568863785233169, 0.18448104091215511, 0.16953927310789518, 0.18447585151118295, 0.18096035650726472, 0.17018150462864745, 0.17506054109316338, 0.20052309341552932, 0.18530544950801364, 0.06208309539388668, 0.11538503861463045, 0.15610859750938688, 0.16356526983062636, 0.18514118592456907, 0.16010194178152215, 0.16140003074298914, 0.12172494128812328, 0.21179437557274472, 0.213466661154041, 0.15723895982186897, 0.051968388632598006, 0.2134285264287218, 0.20855043284056396, 0.20382182792892622, 0.1964844548200776, 0.20432911806890341, 0.18024172820135687, 0.17508546362075683, 0.1970282006018913, 0.17665078847979165, 0.1679598938605097, 0.18013027414333616, 0.17945577180393357, 0.20236440718617, 0.07459918562530687, 0.06817209908819077, 0.08492268884708387, 0.07345243843193361, 0.10668986191014063, 0.06565595802459123, 0.08069843552695433, 0.07760990323143724, 0.07749041194293882]}, "mutation_prompt": null}
{"id": "0df273fa-d1d7-4aa1-9915-44726359589b", "solution": "import numpy as np\n\nclass AdaptiveMemeticDCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n        \n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Dynamic crossover probability\n                if i < self.population_size * 0.3:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.7 * samples[i] + 0.3 * samples[crossover_idx]\n                elif np.random.rand() < 0.5:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.5 * (samples[i] + samples[crossover_idx])\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean += np.dot(weights, selected - self.mean)\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n        \n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "AdaptiveMemeticDCMAESOptimizer", "description": "Adaptive Memetic DCMA-ES with Dynamic Niching and Variable Crossover for Enhanced Multimodal Search.", "configspace": "", "generation": 56, "fitness": 0.3143928022311148, "feedback": "The algorithm AdaptiveMemeticDCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.25.", "error": "", "parent_id": "bb45ad55-d6b5-4129-8ae8-9846db1e804a", "metadata": {"aucs": [0.9546878333596447, 0.9433122980238154, 0.9331621702153154, 0.9413969576967441, 0.9400722027916215, 0.9404052765602378, 0.9353304810544782, 0.9380605270843608, 0.9274735128090132, 0.45855229841120937, 0.36155415628474663, 0.4428554921968755, 0.45686316366401325, 0.23542793777578397, 0.5096128060959334, 0.4852880177662168, 0.45254090339425423, 0.43579725696348603, 0.11695444537088406, 0.10576699336097739, 0.029368811831027797, 0.11433106387799397, 0.10282257814527807, 0.11302575379078039, 0.1353930977368445, 0.08879027396601613, 0.05964109084977498, 0.07087850966125475, 0.09949259779266018, 0.027128085691204284, 0.11222094516828607, 0.12374146215397719, 0.09575422115241794, 0.08326942657762537, 0.05706215864446551, 0.05712627888174915, 0.4205433804215999, 0.1406383842287653, 0.21728073705370932, 0.16769456950971384, 0.17335215669052373, 0.18299917183794845, 0.16812703891829783, 0.8564674036822566, 0.16662674031597102, 0.3691119751315314, 0.23832492651023163, 0.4838130363046025, 0.42838291872397183, 0.29823646893276456, 0.28845271539503725, 0.4743997549650698, 0.3255351738273028, 0.37019810208458237, 0.10454935258125164, 0.8220519808531541, 0.2213139499014214, 0.21566011727938117, 0.27899222768560206, 0.21248947379929917, 0.15311818533875154, 0.2210153138698152, 0.17755793983400303, 0.5481976202486177, 0.2837782272760144, 0.5027227373426695, 0.5899603828438631, 0.13426516577589898, 0.3858284351588671, 0.46161288552086566, 0.13331952331956176, 0.47645165006393164, 0.6543633116273853, 0.43878308951620026, 0.1374787195228382, 0.41554265641964494, 0.2763032918137994, 0.43393290694952125, 0.6145735514310593, 0.4432477325200309, 0.5694970805855575, 0.48737791886911075, 0.30142712873782107, 0.5867426187542706, 0.5183409050783538, 0.5276349327120081, 0.3782116260827677, 0.4436979154143905, 0.4622050336542861, 0.5007329559279123, 0.6312134046154914, 0.6431481664890435, 0.6732283862576143, 0.4702850388624291, 0.20793669970459439, 0.667462396317198, 0.6608501676069495, 0.610175546884075, 0.6759676172433435, 0.20431367586659066, 0.05822137232479996, 0.1162466694849108, 0.1373221156702299, 0.14218029505131435, 0.20904355223233884, 0.3575827630889997, 0.20266343017637023, 0.08680488925364238, 0.1993446341377828, 0.181647388399232, 0.14617179821114168, 0.24454950572867307, 0.21194194569825042, 0.21714048402930541, 0.1729563207355288, 0.2199097404083502, 0.11284943654609303, 0.7751693935644218, 0.7386510028625362, 0.8207351056490013, 0.7682887262990594, 0.803431275255275, 0.7944775300932945, 0.7540916924603839, 0.7608594030794296, 0.7797017588391909, 0.1331301970605262, 0.09886957265487295, 0.1042582725405482, 0.12363200972082689, 0.11188356896120644, 0.13209942200457248, 0.09531337248687544, 0.12181378543663468, 0.11149406096815506, 0.14232591340829914, 0.15806210058877745, 0.26935353567318165, 0.23806902127401974, 0.22395092074818845, 0.2274658799958048, 0.25350049552868026, 0.1766442178555846, 0.1766311380873774, 0.3462169172540509, 0.09845901374710897, 0.1598348498300547, 0.39837598277179764, 0.2614937267419766, 0.16859154630537543, 0.2389192330481441, 0.10314039564034283, 0.09702585577878176, 0.31034024643048064, 0.27421908312902077, 0.2044506688192409, 0.30869229585375335, 0.2567019067913249, 0.14667403783446675, 0.14666338566179582, 0.23185028939983798, 0.421002206479519, 0.2143209308455064, 0.2162350643491805, 0.2234409230250537, 0.21350505552119514, 0.2359232629706577, 0.23924754724524178, 0.21472586719889752, 0.2166590990797217, 0.21300231685922855, 0.1874133007394695, 0.2069175252530635, 0.1649549351492171, 0.17202422351265745, 0.1931904902367516, 0.17018678443042423, 0.18865622797800685, 0.1800571292707227, 0.16639532695351333, 0.1231929736395625, 0.1375832918166734, 0.18707668966234425, 0.17397353184961106, 0.11195135678558021, 0.11400878252460056, 0.1087510700397083, 0.11521433417025417, 0.9369641188951907, 0.9175888908572318, 0.11297991263932639, 0.12741660362454843, 0.16887627853081777, 0.21148291855084567, 0.036194203213084086, 0.908106737067162, 0.1668149971579691, 0.7918639457752625, 0.18204900055216244, 0.22930579565543685, 0.18890365879209448, 0.18420278581109661, 0.17659589235858586, 0.20565788260579976, 0.17209453991583035, 0.2138870810383875, 0.18759801716880475, 0.08269620326458516, 0.09184599069588062, 0.08155293061796165, 0.08742759697146885, 0.08308027493553671, 0.11210321333402695, 0.09431769289955372, 0.08250958622479898, 0.09008375037764094]}, "mutation_prompt": null}
{"id": "9dc0721a-abe5-48b8-973e-e9fffed26691", "solution": "import numpy as np\n\nclass DualPhaseAGIDCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n        self.crossover_rate = 0.6  # Adjust crossover rate\n        self.mutation_prob = 0.1  # Introduce mutation probability\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 1) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Introduce a dual-phase strategy: crossover and mutation\n                if np.random.rand() < self.crossover_rate:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.5 * (samples[i] + samples[crossover_idx])\n                if np.random.rand() < self.mutation_prob:\n                    samples[i] += np.random.normal(0, self.step_size, self.dim)\n\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean += np.dot(weights, selected - self.mean)\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "DualPhaseAGIDCMAESOptimizer", "description": "Dual-Phase Adaptive Gradient-Inspired DCMA-ES with enhanced exploration and exploitation cycles through variable crossover and mutation strategies.", "configspace": "", "generation": 57, "fitness": 0.16203892995947988, "feedback": "The algorithm DualPhaseAGIDCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16 with standard deviation 0.19.", "error": "", "parent_id": "bb45ad55-d6b5-4129-8ae8-9846db1e804a", "metadata": {"aucs": [0.3418022914206231, 0.2913345820790272, 0.3202454940242836, 0.31723008135156505, 0.5012185569402383, 0.2951803478456544, 0.32627313487914344, 0.2871398770233661, 0.3584653360953175, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06523748892058723, 0.06013796980042585, 0.07604787127454438, 0.08875729113566233, 0.0809169251256413, 0.07050849308556428, 0.06985625564929776, 0.058363759718058295, 0.07198610880629752, 0.06553988152918278, 0.0816991142850011, 0.04711904825413571, 0.061677420653789006, 0.05795865885142559, 0.05351923437547357, 0.047047445916823416, 0.051989442082359894, 0.06214037426381569, 0.9880912794884283, 0.9673649568041784, 0.9706452860267043, 0.9705121074301981, 0.9566492173059316, 0.9683601735684638, 0.9702498653100284, 0.9584226605335118, 0.9631744547778645, 0.1318841191333, 0.10011661969990437, 0.11267404733314723, 0.07558119800084007, 0.09830425514544472, 0.0898097133897019, 0.09676676381706506, 0.09619803718232012, 0.10892570449254801, 0.16248470630927037, 0.1626624496387371, 0.17890886091072356, 0.2513043214976748, 0.2334458703666068, 0.16967529029471784, 0.16088275994922985, 0.16817171688179455, 0.22219776697527693, 0.09060127387215311, 0.038389925713023465, 0.1456195628142024, 0.11813897761790526, 0.05838925717705712, 0.09364866705022012, 0.09285483098082636, 0.06072270912386335, 0.09007014201099905, 0.1464259947917642, 0.06771542163978705, 0.049901920728214644, 0.12613022843971577, 0.07627405328770132, 0.09691179076530021, 0.1447266104595657, 0.0780883092385466, 0.13883262287166231, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14247209781706716, 0.04222390146429755, 0.08329350582936279, 0.06697364478078904, 0.04659968326462116, 0.050919504633207935, 0.11278443564518914, 0.06486677872903968, 0.08940099739505836, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.014273146590415342, 0.03718134586612487, 0.03559431359239407, 0.06072160962594697, 0.019656791250983963, 0.04946068633050238, 0.052416355765215306, 0.010146387907180032, 0.061116809755770385, 0.2640991722651108, 0.28956075020793026, 0.24841365322515285, 0.2900213222420033, 0.25932589597682354, 0.2441838834939355, 0.25473530909012365, 0.26810153614407406, 0.2737537548520814, 0.08559828125147417, 0.07282879941123721, 0.07279468597391336, 0.09882375199700333, 0.06847423076581183, 0.08140185025572244, 0.0816000831410616, 0.08332563248294578, 0.06937922759231607, 0.14746679170452004, 0.13093436914811485, 0.19914829739977735, 0.13090031772115418, 0.14757848402025697, 0.15180157685766427, 0.14557910783110006, 0.13929438886916012, 0.15414519033461915, 0.1904649931584822, 0.20098322314789352, 0.18344701119596907, 0.19178795928484726, 0.18377237974208205, 0.19418065985165456, 0.1945254370911068, 0.1803700219858696, 0.18999127196633747, 0.18912280183236962, 0.13351296683852265, 0.13048363482093395, 0.20550392256973304, 0.12423684692104742, 0.13346361274477347, 0.16693273562098054, 0.12337706556429506, 0.1297885833638429, 0.18431348728527341, 0.2384058280098751, 0.17952298372434894, 0.19798565984421257, 0.18024988054745827, 0.20057398360518774, 0.19231059098435455, 0.17939870542306802, 0.1914915033127912, 0.1761480678432492, 0.17566386808963885, 0.16650597707552828, 0.1803519614132696, 0.1667263297414593, 0.17371665522352964, 0.19056866582388554, 0.16816767000995492, 0.16594335391139448, 0.25739185338411597, 0.18033667485463323, 0.16935920870246335, 0.22233441493717687, 0.20512226333379702, 0.20398055996498188, 0.19362997950562655, 0.1593934679921718, 0.1543080830833491, 0.260648295503494, 0.1619104307563064, 0.16205809188294007, 0.18651513401279773, 0.16798139303278292, 0.22627865344133513, 0.21362991161999056, 0.21693124744335324, 0.2470987459902032, 0.17956279903518535, 0.17312680422172821, 0.18574876500513005, 0.17828096112591196, 0.20178295067434293, 0.18435717485218917, 0.17974318094470487, 0.18454418020907237, 0.18754516506532382, 0.06646999433971068, 0.06772836563330642, 0.07780767667881827, 0.07482188713749871, 0.07224984742356177, 0.07028657989852327, 0.08130817069268048, 0.07109260207382162, 0.06868173049372872]}, "mutation_prompt": null}
{"id": "15a5fb2b-59e3-475b-9faf-c3c7f076185d", "solution": "import numpy as np\n\nclass DiversityDrivenDCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 1) / (self.dim + mu_eff + 5)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n            \n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            diversity_weight = 1.0 + 0.1 * np.random.rand(len(weights))  # Introduce diversity in weights\n            self.mean += np.dot(weights * diversity_weight, selected - self.mean)\n\n            y_k = (selected - self.mean) / self.step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.step_size\n            self.step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "DiversityDrivenDCMAESOptimizer", "description": "Diversity-Driven DCMA-ES with adaptive mutation strength and dynamic parent adjustment for robust optimization.", "configspace": "", "generation": 58, "fitness": 0.25450406633127337, "feedback": "The algorithm DiversityDrivenDCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.24.", "error": "", "parent_id": "bb45ad55-d6b5-4129-8ae8-9846db1e804a", "metadata": {"aucs": [0.8764176320526781, 0.8083753473832764, 0.7499505167488452, 0.7434013894844258, 0.8244037738568822, 0.838051906540036, 0.8710778221044626, 0.8177847656888763, 0.7731041176312627, 0.43579329613037876, 0.4129222772676223, 0.4833276289607664, 0.48558897128856615, 0.39462283858218805, 0.5262899181773075, 0.2599382694847845, 0.4549584221509665, 0.4990400010925715, 0.1082482241081294, 0.08543224406933281, 0.08010019827009962, 0.08034798160499612, 0.07620610457254207, 0.07779211941314479, 0.07672327206514218, 0.08245969736924019, 0.08762692570031472, 0.051141186280904916, 0.03743173546733958, 0.03799321834217151, 0.036882062620140266, 0.06219787642931385, 0.03778677984462009, 0.060334282450860366, 0.05773833382355864, 0.037830567060295306, 0.964076003454302, 0.871104305101039, 0.9092098190768243, 0.9663421098388749, 0.9590605645356668, 0.9901871415948836, 0.9697260991589177, 0.9813924450765948, 0.9768901302301604, 0.09661832387764901, 0.08706677155858544, 0.10924760262542399, 0.08652082436827968, 0.09962018220328661, 0.08590968466861737, 0.11076529870557039, 0.11575190767210608, 0.10295811747758055, 0.2823941790952692, 0.3134596674116721, 0.27749043900112147, 0.2841222063027262, 0.25784783004789924, 0.8267659515986963, 0.24489787478503555, 0.31884875938593893, 0.2576408190047548, 0.11324835929136334, 0.13377339102767838, 0.1803469209547155, 0.16274791417072665, 0.144109392047722, 0.4044765615414768, 0.12422220003345141, 0.14112488260131306, 0.15900622189098723, 0.15131312837436273, 0.09797999515049305, 0.1375025807024831, 0.1704690181651236, 0.14950615807711087, 0.3140694635384058, 0.13605955419201476, 0.13647249028690878, 0.11656421395358196, 9.999999999998899e-05, 0.24452095856678457, 9.999999999998899e-05, 9.999999999998899e-05, 0.05666814829594946, 0.11998180997954, 0.12412951886207302, 0.008710880102002383, 0.20853545486990832, 0.1273788443730438, 0.10208774740645499, 0.08901880274350793, 0.1126195642486909, 0.07252285402580838, 0.05328120287757998, 0.09494440408702887, 0.07466015310892105, 0.08029978461769838, 0.09561677750514441, 0.24272859684720516, 0.038975332604130886, 0.10794516613992311, 0.09396322746168584, 0.07590860394423093, 0.056810828527948276, 0.1515547189391706, 0.08121134139803765, 0.31915317944053445, 0.43723512589640745, 0.4476737605898594, 0.16880497486253754, 0.5298410462809329, 0.505043774220191, 0.2150013941216231, 0.39407854815461474, 0.5108537842558003, 0.4940602562674521, 0.5264559190124353, 0.6891380452342848, 0.46094788262240827, 0.5540470625930622, 0.6358845550013995, 0.47443598371430074, 0.4497242946114838, 0.41797116443580784, 0.0854205043179318, 0.08618122426695862, 0.08922201056714818, 0.08300061617795895, 0.07115664002149336, 0.0846238860009435, 0.08523838031978326, 0.07990368826981598, 0.07390737652610258, 0.16279720991525481, 0.12723907740401996, 0.1411143727675469, 0.13968834989238166, 0.15304533882177818, 0.13497718118133184, 0.1430163137625916, 0.13622013910645092, 0.15758558965203373, 0.22802004825331623, 0.23188892675828654, 0.2171650866062168, 0.21380418212707641, 0.23785218537432118, 0.25164761591284057, 0.26673879029902303, 0.23423597914371064, 0.2968733759808938, 0.1603627660590592, 0.15144695426527344, 0.16359367681024284, 0.18938876943560345, 0.1495412815791327, 0.1750949355108069, 0.1989092834303552, 0.13513174274345763, 0.16543682952875294, 0.19028976697370037, 0.18046113469890934, 0.19813936347144523, 0.17208232885375785, 0.18012494247387367, 0.1819061360895723, 0.20334255672755663, 0.18283960118126052, 0.18431159801523778, 0.17793441303241853, 0.16707140690539635, 0.18609048791136706, 0.17230033979950132, 0.17407593829743329, 0.171536865134726, 0.18001411840668702, 0.17574478407009153, 0.17996057139236088, 0.6932663986242549, 0.16263213634448292, 0.16304327939509788, 0.16953391508286808, 0.21095459536076422, 0.20023044896056574, 0.10877415390794598, 0.17311896283900585, 0.9080249300551159, 0.16860708639372113, 0.1602581867177476, 0.16897558280193803, 0.16920943589380255, 0.19394296108370512, 0.20802455303809597, 0.7246282065211183, 0.20696724398360022, 0.20087864089585428, 0.18970307130523634, 0.17697083843957295, 0.18688847739989278, 0.17479000133848444, 0.19395144716771384, 0.19222778603424862, 0.18322136375853693, 0.17984733186142743, 0.19536039470495348, 0.07067595162237361, 0.06893823550475131, 0.09491941691175576, 0.06070562536849844, 0.0688691036356478, 0.06816702672763153, 0.07326313699563947, 0.07013065147389264, 0.0805263863568767]}, "mutation_prompt": null}
{"id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "solution": "import numpy as np\n\nclass AdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Dynamic recombination for enhanced diversity\n                if np.random.rand() < 0.25:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.5 * (samples[i] + samples[crossover_idx])\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "AdaptiveCMAESOptimizer", "description": "Adaptive Covariance Matrix Evolution Strategy with dynamic recombination and mutation for enhanced convergence.", "configspace": "", "generation": 59, "fitness": 0.3463833598559589, "feedback": "The algorithm AdaptiveCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.27.", "error": "", "parent_id": "bb45ad55-d6b5-4129-8ae8-9846db1e804a", "metadata": {"aucs": [0.9023680266036419, 0.9081023544281063, 0.9281146974576004, 0.930892291885995, 0.9219787824141944, 0.921662910916557, 0.9253496587408858, 0.9198976701332013, 0.8847700681413939, 0.6537384997193425, 0.6160233287733642, 0.6563208825227356, 0.6163645354010334, 0.5768076919963834, 0.6381877627976046, 0.644490588013349, 0.5723090794014429, 0.45378070407697757, 0.08901225759668219, 0.08069933266641716, 0.0961342739978509, 0.099610970046912, 0.09499813978399019, 0.0886141914423455, 0.09451995461399343, 0.10446707574883207, 0.15500087634258986, 0.07798333773041666, 0.06658768529066161, 0.07179466685719293, 0.07145984692128038, 0.0851935053973022, 0.07802987436392017, 0.07222210166057508, 0.08258468312889511, 0.07427182600206739, 0.6091481360187416, 0.9819545449057234, 0.9759395480499687, 0.164332031884469, 0.9233971247708334, 0.3349708133828754, 0.9831550828331599, 0.7204988622159381, 0.7945783918736788, 0.12131148762740662, 0.11385627259380837, 0.1569470808834601, 0.10782219947965443, 0.12120919432047816, 0.14355034381092524, 0.11822544820012792, 0.16769198135787444, 0.17681514906892148, 0.4974155913939722, 0.6849128440711825, 0.7842133683239996, 0.672012207194317, 0.8480711271649748, 0.6796432405036426, 0.8954085979215428, 0.8326094600710127, 0.6515106088993727, 0.5269321278983987, 0.5947373568933536, 0.5526691326065478, 0.43522980904509134, 0.5348548697379482, 0.6398425297369021, 0.558463546066519, 0.48939640873544454, 0.6437009647178075, 0.6162203176217613, 0.21540826118668244, 0.6499992954286005, 0.5920147180523607, 0.13367462986243395, 0.5810318345249562, 0.35072235832687515, 0.36817035973293344, 0.5277854784111609, 0.014822481291476786, 0.5285000690540047, 0.04132173516397286, 0.6512040325663568, 0.34734137864289527, 0.3498285984480014, 0.6507698260475001, 0.5354703005594958, 0.5076797772836159, 0.12000997613822295, 0.12175453972737671, 0.13846230608738952, 0.06853185946056961, 0.09639694698524526, 0.08172739214702673, 0.15114811768212144, 0.1110753656541974, 0.0925426499046369, 0.19163678705971732, 0.11341340633531449, 0.1046397698255731, 0.5334657675938494, 0.5497659172580223, 0.2045808383492046, 0.34947965189042596, 0.17873208853523614, 0.3915250587230973, 0.34666025533866374, 0.4676478354235024, 0.4589802477528143, 0.4866993458579195, 0.5312657043113183, 0.4928459309786626, 0.5445365508809483, 0.3960437700285889, 0.4131884130947828, 0.6643903562737061, 0.7861418067115693, 0.8084228474496885, 0.7793230934920117, 0.7966479203522617, 0.7863881139257743, 0.7715900806405529, 0.778539823974718, 0.8281816734807076, 0.0918996711011103, 0.09877196676920119, 0.08874303604861711, 0.09161436042296323, 0.08136139684257193, 0.08640539215225784, 0.0881334940861841, 0.10268818382127243, 0.0981351971408625, 0.13506434713536697, 0.1515448729815897, 0.24684634107717307, 0.14311114262614466, 0.14125619370056575, 0.3635093698779386, 0.1385257128578372, 0.14240206290355817, 0.1355352781089858, 0.36917900558592887, 0.41295726937187005, 0.3154188696319773, 0.36578107747030497, 0.31601428877521653, 0.2821232434363976, 0.3462112977338552, 0.4449176873076617, 0.31795753817837236, 0.25890957784394253, 0.2658308799915914, 0.2675456226024867, 0.2670050054573174, 0.27254527128016803, 0.28696162055961827, 0.23859561382946182, 0.20508754761596282, 0.21693712871027504, 0.22393141643099757, 0.2093896129171794, 0.19534720459646693, 0.1875031115669622, 0.19655151895434841, 0.1995010071891854, 0.24652639534315646, 0.19566618428180993, 0.20086272543637773, 0.17996985626028472, 0.1733059921179596, 0.18544071905885617, 0.18091556901734662, 0.19601546264621506, 0.18429188106073924, 0.1802237873167809, 0.17749067261337803, 0.1814150932219487, 0.16790370323636672, 0.13700333746676874, 0.18798251344252626, 0.25465882516861915, 0.11251569061669475, 0.06195736121941131, 0.10844492011293916, 0.11539635329329212, 0.1679757307819293, 0.9092061871259115, 0.11330628995217107, 0.07470532371094218, 0.1689555118903996, 0.2105062448836338, 0.10964117318970734, 0.15266116496777926, 0.16111052747759347, 0.8842952216887596, 0.19787910695861288, 0.1755555489653421, 0.17898912356561414, 0.18551946106308925, 0.178132609872514, 0.200623280797112, 0.19777465898479918, 0.18571648012704656, 0.1890567748439579, 0.07447559490759104, 0.1103887086576113, 0.0775128836441108, 0.06805950066870903, 0.10216033936920044, 0.0818471689160466, 0.08823977908982705, 0.07695783038107873, 0.09209674397649559]}, "mutation_prompt": null}
{"id": "36681c89-7622-4dca-8652-457e33a1bb76", "solution": "import numpy as np\n\nclass HybridAdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Introduce stochastic perturbation for enhanced exploration\n                if np.random.rand() < 0.25:\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    samples[i] += perturbation\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "HybridAdaptiveCMAESOptimizer", "description": "Hybrid Adaptive CMA-ES with Stochastic Perturbation for Enhanced Exploration and Convergence.", "configspace": "", "generation": 60, "fitness": 0.17545848746586026, "feedback": "The algorithm HybridAdaptiveCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.18.", "error": "", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {"aucs": [0.4869877773919158, 0.42357066367805696, 0.45253329823191535, 0.485777218334306, 0.47513492646990385, 0.4656908880675764, 0.49745573613449556, 0.4426018171885171, 0.4584687446349709, 0.023297703422838656, 0.022779468036460693, 0.024182426280051406, 9.999999999998899e-05, 0.00876346548643192, 0.03739674794657222, 0.025741057899847375, 0.013726021886736772, 0.026582438657097973, 0.07420717954535849, 0.07113739679680164, 0.06300292645153327, 0.08792618646844808, 0.07623555899929446, 0.1043141462237398, 0.09993569425486293, 0.08696600819421596, 0.07973946825920175, 0.06074748009014452, 0.03977648174029913, 0.05718639939694081, 0.049225493228854944, 0.057421898261951876, 0.0669298916428599, 0.05190672447750566, 0.04387478058101901, 0.060352643832881636, 0.22483173405853185, 0.8438964642942911, 0.9373868616518553, 0.7326826729357316, 0.941791689302064, 0.7461560778012835, 0.8919606387710701, 0.9461332017127312, 0.9920519344394486, 0.09883102708076708, 0.10699395552975255, 0.08827349568968079, 0.09184880512368376, 0.09927110268859285, 0.07743340783547392, 0.11020988260556752, 0.11310601993967939, 0.1417932502052226, 0.27372029870332404, 0.28109646519856646, 0.2673836661800236, 0.2976366747142818, 0.2961663402988719, 0.23639860198876417, 0.2673620658844871, 0.26402966988840537, 0.2217537204358503, 0.1274320165437739, 0.1402850087921188, 0.10606045928805763, 0.09553843136373541, 0.12850960916192833, 0.1403958775505969, 0.13047462912062258, 0.09227159756111902, 0.13978792034731646, 0.13523076447047933, 0.12339650843276306, 0.10580945493039084, 0.14032144793816137, 0.10325619173242939, 0.13666928186102434, 0.11552585324312126, 0.14215586143770287, 0.08256725598954795, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08460986953236083, 0.0992989600819918, 0.1323590669868141, 0.07356808989880592, 0.07145065022358399, 0.0796276818447279, 0.1160533507513688, 0.0802664671100134, 0.06398663520470205, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12215325602218163, 0.1371333043205093, 0.11815372855321604, 0.10806709866521469, 0.11068545597750745, 0.11555415172928918, 0.1014656465882906, 0.15788812754187398, 0.09633230898212475, 0.4007382187351929, 0.42570915780907603, 0.40976499199858374, 0.4033310600201928, 0.3891587883520897, 0.3988871022598892, 0.4037238696123704, 0.39902271259427513, 0.39258338407531435, 0.07734032441335914, 0.08449253209577401, 0.07693605804172587, 0.08878624657010092, 0.07845657173741383, 0.0685998586504395, 0.07908836390480267, 0.07828444452986183, 0.08236875740599992, 0.12845008450382556, 0.14001578768952894, 0.1392683256367998, 0.1301946984954635, 0.14360909162919433, 0.15090694603476895, 0.1377090853682088, 0.15659196910006212, 0.1531509995767485, 0.2464120238788292, 0.20600712738898874, 0.2182588906866224, 0.19236271527897952, 0.23799255581910728, 0.20822169442213168, 0.23194315415604072, 0.2339681502857407, 0.20186786409048407, 0.1468154061387309, 0.14930223959468147, 0.16730515503168608, 0.1468507010299689, 0.15022362066493788, 0.16372732242074328, 0.15891661442646088, 0.17609447860882044, 0.1608796432912757, 0.17594949868535548, 0.17662213826888196, 0.20373957792967212, 0.19033667138178423, 0.17447260988438762, 0.18087816221313968, 0.22739469043854577, 0.17393785484210678, 0.18064894437101497, 0.17685708128316469, 0.1766452129853393, 0.17893988895818091, 0.17250414868495068, 0.1948954558710172, 0.16719118260566934, 0.172894800759274, 0.17498984248926186, 0.1704046454884417, 0.12327062980342851, 0.13786765990431216, 0.1900510983006477, 0.16751563587708151, 0.19812294605823633, 0.14679080535922473, 0.22441154622264625, 0.1635385559213982, 0.22793740258445783, 0.22325140278654, 0.16196709749628768, 0.09274187127017486, 0.16759086197066375, 0.1870439202039167, 0.13707294763175437, 0.1552811029683504, 0.2095634340075092, 0.16856771528743208, 0.18839195422743205, 0.1930103602226807, 0.18066662845972004, 0.19548599262236444, 0.1861102026389726, 0.1857867773989511, 0.17685413687501572, 0.1666141459047612, 0.19215123421259428, 0.06658268926055211, 0.07001861482639238, 0.07348703743564078, 0.0733633137822588, 0.07082614722395597, 0.07607508572431432, 0.06262931507975522, 0.06702171264050016, 0.05973161230933588]}, "mutation_prompt": null}
{"id": "2e6c558c-69d6-40b0-9615-7552e2593ed1", "solution": "import numpy as np\n\nclass AdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Enhanced dynamic recombination for improved diversity\n                if np.random.rand() < 0.25:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.7 * samples[i] + 0.3 * samples[crossover_idx]\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1)) * np.random.uniform(0.9, 1.1)\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "AdaptiveCMAESOptimizer", "description": "Adaptive Covariance Matrix Evolution Strategy with enhanced dynamic recombination and adaptive mutation rate for improved convergence.", "configspace": "", "generation": 61, "fitness": 0.33697305658783205, "feedback": "The algorithm AdaptiveCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.27.", "error": "", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {"aucs": [0.9322773160102655, 0.9253959564815324, 0.9233968964888711, 0.930353118334072, 0.9111063432462501, 0.9330061574221977, 0.8904783416821374, 0.9256089414115182, 0.9214909769533567, 0.5964452910410267, 0.5124400935791734, 0.6785221786268844, 0.6604482523008315, 0.5025715406811251, 0.6610790752147143, 0.5966670801952239, 0.6003869568575166, 0.6427283329454718, 0.08500875667613805, 0.09574199856453947, 0.08708621355547441, 0.0780420550710682, 0.10421889951626073, 0.10621333986949555, 0.09845633018259448, 0.0903857298500963, 0.08367477109104515, 0.06619058012327805, 0.06895788399189073, 0.07102451581598612, 0.08559743097071282, 0.05712394805345611, 0.067875475522019, 0.082848607285821, 0.08949478121313437, 0.0732229561963823, 0.7719381476189737, 0.9266380237844508, 0.185165881118037, 0.4768931022507512, 0.8354521298377802, 0.19756445582430993, 0.9513538249613859, 0.7647339556589826, 0.9539724981461677, 0.13458399731799853, 0.10371723251506393, 0.13416299200119974, 0.10643071984518515, 0.11779576081121179, 0.14342882267136847, 0.15245100182252025, 0.11561892093651971, 0.16274443164832753, 0.8859762132490089, 0.6432308420424033, 0.8311575433875105, 0.8415383456720223, 0.5606220396557658, 0.693328343701412, 0.8708843563255204, 0.5821319680300812, 0.3841014616418357, 0.3325602467486467, 0.575229073378107, 0.639633829121236, 0.44263439461816123, 0.5336780804440968, 0.6419255169278937, 0.47700488870554614, 0.445236140150838, 0.6084935241145155, 0.6069928311064638, 0.13500231410822383, 0.6328855028934464, 0.6497364151297548, 0.44838697721449805, 0.6776973501542009, 0.680286338629303, 0.1315800826414415, 0.624911622750763, 0.009423904259171278, 0.002094223450763266, 0.02795302334467653, 0.6180737511715436, 0.19699244865727106, 0.0317123637417519, 0.6465238054096548, 0.3025149431032288, 0.6354098360063123, 0.131105095515066, 0.10414240453424661, 0.09002646274906967, 0.09578082098360685, 0.08412683804361187, 0.08689498550908248, 0.12139689459773506, 0.09359581811861606, 0.08808836688960997, 0.44704526737248673, 0.09098874472096263, 0.41429420177089704, 0.5518346130820647, 0.4759328912815818, 0.16765497887873204, 0.20767366257881215, 0.20618510795966216, 0.0804754063861357, 0.5387847281164257, 0.5152348761384458, 0.40520340576460956, 0.5779130610920895, 0.5832163796351026, 0.5834134908519798, 0.4624594840231976, 0.4784525990117723, 0.5184180941424592, 0.8284765043517343, 0.756166379252565, 0.8044367145385041, 0.8126447383501993, 0.6585679598079611, 0.7995102739424088, 0.834675853320777, 0.6875896313805654, 0.8217369927949131, 0.07968039725321363, 0.09997463828246889, 0.09263937587525928, 0.08699338704550008, 0.08753288083415467, 0.08170461893470915, 0.0926929858660791, 0.07880397058987199, 0.11377957869000488, 0.13192836044875034, 0.1590963650329058, 0.14100945242368745, 0.15521568796495155, 0.13897135234933633, 0.3429976893734322, 0.13290163243010633, 0.15274075059905756, 0.16138422757043513, 0.33592428997563883, 0.31084115407671165, 0.30165168046892643, 0.3004068132325982, 0.32892261111919885, 0.3037702207356183, 0.44359912838834004, 0.2960678373476483, 0.28903830264170716, 0.24091967820781923, 0.2534968120165457, 0.3740219675988463, 0.2736727441076299, 0.2522736667152403, 0.2386397153140709, 0.20953360948216737, 0.2599858523447376, 0.20238625503775598, 0.1922559910105499, 0.18236509730722106, 0.20454221159673958, 0.21563070662021422, 0.19306774244697011, 0.1907404033817659, 0.20695389200000303, 0.17754787146963424, 0.1861123198462581, 0.17234560821480882, 0.17827264091391803, 0.1706265305273742, 0.18018678384208286, 0.17032823058612956, 0.186793240567803, 0.182475800217889, 0.17493625279811764, 0.1801441989799767, 0.18915247640021104, 0.16145172744041958, 0.17374464812818946, 0.16935717348100532, 0.2665873120281045, 0.16854804703378268, 0.13699034375923114, 0.11541623699359604, 0.15951489769313598, 0.20987622936257877, 0.16209500659586806, 0.9047550112301905, 0.21319556652895966, 0.20219454546775473, 0.21042254790412462, 0.2217098150417386, 0.0591117854126596, 0.0949487040500866, 0.17683626492866789, 0.19264312700420916, 0.20204566806254876, 0.1809984090517065, 0.1897758507437295, 0.178303093745244, 0.20762276134329694, 0.18098026681026735, 0.18044983769220302, 0.07453660457381484, 0.0650664378797342, 0.07297733050894151, 0.07798432879328887, 0.06691218869748627, 0.07852144448754639, 0.07449590089950286, 0.07149004048761254, 0.08304208904115129]}, "mutation_prompt": null}
{"id": "729959a8-7c8b-4efb-a262-bb1ce08e0c02", "solution": "import numpy as np\n\nclass EnhancedAdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n        self.mutation_pulse_freq = 10  # New parameter for mutation pulse frequency\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Dynamic recombination for enhanced diversity\n                if np.random.rand() < 0.25:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.5 * (samples[i] + samples[crossover_idx])\n\n                # Periodic mutation pulse\n                if self.eval_count % self.mutation_pulse_freq == 0:\n                    mutation_vector = np.random.normal(0, self.adaptive_step_size, self.dim)\n                    samples[i] += mutation_vector\n\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "EnhancedAdaptiveCMAESOptimizer", "description": "Enhanced Adaptive CMA-ES with periodic mutation pulse and diversity boost for improved exploration and exploitation.", "configspace": "", "generation": 62, "fitness": 0.15607574348971356, "feedback": "The algorithm EnhancedAdaptiveCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16 with standard deviation 0.19.", "error": "", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {"aucs": [0.3615593006811044, 0.31362548022704695, 0.28818801709411623, 0.43176657400272733, 0.3388393180931698, 0.3399344074463454, 0.44929075915885164, 0.3183414831731617, 0.3974278942821172, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08622797322179487, 0.07794087382531667, 0.08592346573046672, 0.07613090107096232, 0.08366944971197499, 0.07516111577535234, 0.07694300494202, 0.07551324637207013, 0.08880991307553887, 0.06606849236734347, 0.037343241825516404, 0.044502109014441515, 0.0398092073279549, 0.03129113841052367, 0.04170913177145763, 0.0387562747419512, 0.030708731651334698, 0.032195236201630006, 0.945570160845046, 0.964490357139138, 0.9465656831229375, 0.9805150417530963, 0.9290333343852635, 0.9004051150758097, 0.9743842924456038, 0.9568793713751396, 0.9849480885612524, 0.09125322432515603, 0.11071355245536174, 0.0832925239027732, 0.08708072631725972, 0.0779276894574994, 0.08441425807540637, 0.08924468385018003, 0.08934383637088739, 0.09564045443959257, 0.17220613443003385, 0.15482892282718608, 0.16657593648079005, 0.17494997858324846, 0.17440686162351327, 0.17096233985742582, 0.16625483720993073, 0.19366835436137175, 0.14250432835863647, 0.042954248767500425, 0.03413555863201978, 0.12912196294714262, 0.08283623754954372, 0.08399417013267174, 0.0946454622427928, 0.07668894944507543, 0.11327651761494417, 0.14560054786942023, 0.1212351181933009, 0.03257183616733528, 0.09922060045318082, 0.1062334584385124, 0.08474679255861761, 0.09853072554428488, 0.1436989609058117, 0.047823557416958984, 0.04940453897223651, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06644627126128289, 0.04506079810940211, 0.08302970626453521, 0.09159002483081424, 0.052186335605789114, 0.050829546864002983, 0.037935931955859314, 0.06373263648591587, 0.02788595994000731, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.001421464919300508, 0.017913474597490264, 0.05772785120241064, 0.031232673655771426, 0.04852218106466666, 0.01613755467233624, 0.07098427109947625, 0.02539738576900963, 0.030842796655649374, 0.3361532007610345, 0.24442476256414114, 0.2620271230290876, 0.3260213739188066, 0.2257740845028421, 0.21343642236501614, 0.34000908704193267, 0.29543336759883587, 0.26773696446880924, 0.09145674594831721, 0.07064422072258947, 0.08348002602692017, 0.06556518097376574, 0.07146272481655502, 0.06971722583731521, 0.08304840899616317, 0.06469047236248082, 0.06662765533371107, 0.17615255729873958, 0.14984488916046268, 0.16157365211726227, 0.13312945100752094, 0.1397709851498954, 0.1406764845753713, 0.13564686692736982, 0.16082818844751257, 0.14537556996337353, 0.20216090976679713, 0.1982986449816624, 0.18014128202103052, 0.2593002918255386, 0.17767278956286425, 0.17959517237064082, 0.2289598725130061, 0.1716391348288323, 0.18572565015498566, 0.1260079205507505, 0.11491057028687246, 0.12058578832874467, 0.15916131441830805, 0.11826191494907834, 0.12114688291074072, 0.1740255761678804, 0.13745506477604308, 0.12920861829630959, 0.17719933217584616, 0.17623316455086135, 0.180740804549253, 0.1901795765471629, 0.17619997150221167, 0.1763775657317328, 0.16552589374551574, 0.1644780653355199, 0.18162225215953098, 0.18210879589525708, 0.17377649097368086, 0.16862538675344674, 0.16882986533021815, 0.17236775953983374, 0.16768612474047406, 0.16659212335250817, 0.1755489236279003, 0.1676599549501181, 0.140615733851151, 0.163397435413844, 0.20358048668027173, 0.22241022921129683, 0.14073659067497413, 0.20488243396450612, 0.16129921037398276, 0.1496637637173912, 0.20645933114298098, 0.2026514608745169, 0.12539315827944553, 0.14754335710415611, 0.16584250453151383, 0.1789734839858882, 0.17953707722713808, 0.1999489075001536, 0.186068274713863, 0.1788200514182765, 0.2062551545426865, 0.18115466334138486, 0.18634501683363092, 0.18220343466630495, 0.18039892546558622, 0.1909914909771625, 0.19066088298230077, 0.17790124785466344, 0.17983565560279746, 0.07579593106882243, 0.05777015851286049, 0.06454260203298512, 0.07146145833818118, 0.06444639897829474, 0.05717955152135912, 0.06042713251761067, 0.06387405524768075, 0.08254326291057545]}, "mutation_prompt": null}
{"id": "5f1484e5-1b81-406c-aa3d-fb3dd4fc0869", "solution": "import numpy as np\n\nclass EnhancedAdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                if np.random.rand() < 0.25:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.5 * (samples[i] + samples[crossover_idx])\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            rank_one_update = np.outer(selected[0] - self.mean, selected[0] - self.mean) / self.adaptive_step_size**2\n            self.covariance_matrix += rank_one_update * c_1\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "EnhancedAdaptiveCMAESOptimizer", "description": "Enhanced Adaptive Covariance Matrix Evolution Strategy with rank-based adaptation for improved convergence and robustness.", "configspace": "", "generation": 63, "fitness": -Infinity, "feedback": "An exception occurred: LinAlgError('Matrix is not positive definite').", "error": "LinAlgError('Matrix is not positive definite')", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {}, "mutation_prompt": null}
{"id": "441be06c-40cf-435c-b925-8ca9a6b41cc9", "solution": "import numpy as np\n\nclass AdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Probabilistic parent-centric recombination\n                if np.random.rand() < 0.25:\n                    parent_idx = np.random.randint(0, self.population_size)\n                    samples[i] = self.mean + 0.5 * (samples[i] - samples[parent_idx])\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "AdaptiveCMAESOptimizer", "description": "Enhanced Adaptive CMA-ES with a probabilistic parent-centric recombination and step-size adaptation for improved exploration.", "configspace": "", "generation": 64, "fitness": -Infinity, "feedback": "An exception occurred: LinAlgError('Matrix is not positive definite').", "error": "LinAlgError('Matrix is not positive definite')", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {}, "mutation_prompt": null}
{"id": "30d3a9ec-80d3-4060-9a14-fa46bc03836d", "solution": "import numpy as np\n\nclass EnhancedAdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n        self.covariance_scaling_factor = 2.0  # New scaling factor for covariance matrix\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            # Apply covariance scaling factor\n            scaled_covariance_matrix = self.covariance_scaling_factor * self.covariance_matrix\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * scaled_covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Stochastic crossover adjustment\n                if np.random.rand() < 0.25:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = np.random.rand() * samples[i] + (1 - np.random.rand()) * samples[crossover_idx]\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "EnhancedAdaptiveCMAESOptimizer", "description": "Enhanced Adaptive CMA-ES with stochastic crossover and adaptive covariance scaling for improved exploration and exploitation balance.", "configspace": "", "generation": 65, "fitness": 0.1329546521205333, "feedback": "The algorithm EnhancedAdaptiveCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.18.", "error": "", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {"aucs": [0.1880119370484996, 0.20265751220356532, 0.2279394968976426, 0.22299981094335686, 0.1851116764265145, 0.22076549525693712, 0.19718959608312547, 0.21688110130460014, 0.23198840633574902, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05125663401278502, 0.059288430705398465, 0.07428001228106806, 0.050078423583052034, 0.056947241629585865, 0.05116841439878661, 0.05543214956265219, 0.05308791321815021, 0.0633627489891766, 0.04617789896128799, 0.02802218022588565, 0.02073852046417124, 0.01914471828865094, 0.025241900459196276, 0.03441708673083399, 0.02898351974366664, 0.02215366678492736, 0.027898785857772612, 0.9677448931812949, 0.9254613778007316, 0.9642205655858788, 0.9769643886925133, 0.7729926952744152, 0.9804322188012082, 0.9513410372032925, 0.9891188203002961, 0.8914000623745533, 0.0765971051478076, 0.09521846171429083, 0.08972818955664386, 0.09467447984733846, 0.08746034968209715, 0.061643632654385105, 0.07885034008620373, 0.08129565661596738, 0.08749045462931593, 0.15616611405161074, 0.15848982924381505, 0.18838702247854122, 0.11870545425887635, 0.12160745392419992, 0.11753924030393814, 0.1100104818554446, 0.12160054144148547, 0.12246454226149872, 0.02447806103463679, 0.02900076350403491, 0.00020620466978549246, 0.014476052001112683, 0.031639065414656, 0.03589396862391092, 0.035546053116749854, 0.01693824472335459, 0.04018811843431758, 0.0694400202732437, 0.08730980914402275, 0.0787776265611867, 0.05783943496736754, 0.06970415494908577, 0.08454926922576489, 0.06842830650254983, 0.06660178764174018, 0.07131546533632405, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0789566831468339, 0.055858197878159266, 0.038911958087871956, 0.040847891218832255, 0.055831642969655704, 0.06210567103842335, 0.08281680257689639, 0.040162250654192544, 0.03667139547297871, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0001522868826883128, 9.999999999998899e-05, 0.007245379759506565, 0.010139918716315477, 0.001885140824945175, 9.999999999998899e-05, 0.00025960873373698234, 0.0013092708235288297, 9.999999999998899e-05, 0.19501648496855506, 0.20402782904635974, 0.19888784095289413, 0.2108533316566955, 0.18295002853207043, 0.21067153484686751, 0.22142517791455418, 0.24832801636119706, 0.2268750974704109, 0.055520264770203775, 0.04050813920702134, 0.048914796060103405, 0.043852466747651864, 0.04703732163466923, 0.045410874858500594, 0.03847920575070307, 0.04476459263921573, 0.055959400438087004, 0.13244952087299222, 0.12722372090655698, 0.12961349743891037, 0.11793872576418563, 0.13828885948129988, 0.12847734074331363, 0.13670082995365318, 0.1567480671764221, 0.12155046277444159, 0.1658619521795376, 0.17381232509664024, 0.14921025577428304, 0.18025254265159296, 0.18804124660238397, 0.17092125579249495, 0.16588179791880253, 0.16073705303027597, 0.16337756419281035, 0.11963658757388862, 0.09709058312280505, 0.11637258488410285, 0.11493437235764725, 0.12317145012701736, 0.12284532085472744, 0.09830654882259382, 0.10313482404846452, 0.10436685622699515, 0.17861938277118228, 0.17513575255633318, 0.2109825894008236, 0.1827708754141979, 0.17944369455078557, 0.19426499879851067, 0.18440744373919937, 0.1840118262686492, 0.2164077354523276, 0.1529453120314651, 0.16205078104121617, 0.15286183507150075, 0.15568083481694306, 0.1687102557653114, 0.16344393389362144, 0.15572518856185014, 0.1548583251597938, 0.14756386907507224, 0.16829999747973956, 0.16571970318759088, 0.15656396810505335, 0.1724942076391044, 0.14916428629335643, 0.13329979652397472, 0.16559500504942604, 0.162468609785706, 0.17432326998505487, 0.17021807486839335, 0.1305913541211361, 0.1357148435740232, 0.14628093581968438, 0.15677987492316603, 0.21977599376279888, 0.1592243945495493, 0.14847852210630264, 0.15913436487729138, 0.19446155747716598, 0.18466718732281617, 0.18103174332464245, 0.19367737824553055, 0.21563203922974317, 0.1805156018211974, 0.18720895045605346, 0.17952856564680153, 0.17830264153564945, 0.06098019581113445, 0.05967019353156633, 0.06770323627313668, 0.053950373722943534, 0.057272217438834705, 0.062342051327420434, 0.05604942182633421, 0.06584566329104613, 0.0716082602353536]}, "mutation_prompt": null}
{"id": "6c125706-40ff-4a6f-9580-74d869746cd5", "solution": "import numpy as np\n\nclass AdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                if np.random.rand() < 0.25:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.5 * (samples[i] + samples[crossover_idx])\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "AdaptiveCMAESOptimizer", "description": "Adaptive Covariance Matrix Evolution Strategy with enhanced diversity and adaptive step size adjustments for improved exploration-exploitation balance.", "configspace": "", "generation": 66, "fitness": 0.3463833598559589, "feedback": "The algorithm AdaptiveCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.27.", "error": "", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {"aucs": [0.9023680266036419, 0.9081023544281063, 0.9281146974576004, 0.930892291885995, 0.9219787824141944, 0.921662910916557, 0.9253496587408858, 0.9198976701332013, 0.8847700681413939, 0.6537384997193425, 0.6160233287733642, 0.6563208825227356, 0.6163645354010334, 0.5768076919963834, 0.6381877627976046, 0.644490588013349, 0.5723090794014429, 0.45378070407697757, 0.08901225759668219, 0.08069933266641716, 0.0961342739978509, 0.099610970046912, 0.09499813978399019, 0.0886141914423455, 0.09451995461399343, 0.10446707574883207, 0.15500087634258986, 0.07798333773041666, 0.06658768529066161, 0.07179466685719293, 0.07145984692128038, 0.0851935053973022, 0.07802987436392017, 0.07222210166057508, 0.08258468312889511, 0.07427182600206739, 0.6091481360187416, 0.9819545449057234, 0.9759395480499687, 0.164332031884469, 0.9233971247708334, 0.3349708133828754, 0.9831550828331599, 0.7204988622159381, 0.7945783918736788, 0.12131148762740662, 0.11385627259380837, 0.1569470808834601, 0.10782219947965443, 0.12120919432047816, 0.14355034381092524, 0.11822544820012792, 0.16769198135787444, 0.17681514906892148, 0.4974155913939722, 0.6849128440711825, 0.7842133683239996, 0.672012207194317, 0.8480711271649748, 0.6796432405036426, 0.8954085979215428, 0.8326094600710127, 0.6515106088993727, 0.5269321278983987, 0.5947373568933536, 0.5526691326065478, 0.43522980904509134, 0.5348548697379482, 0.6398425297369021, 0.558463546066519, 0.48939640873544454, 0.6437009647178075, 0.6162203176217613, 0.21540826118668244, 0.6499992954286005, 0.5920147180523607, 0.13367462986243395, 0.5810318345249562, 0.35072235832687515, 0.36817035973293344, 0.5277854784111609, 0.014822481291476786, 0.5285000690540047, 0.04132173516397286, 0.6512040325663568, 0.34734137864289527, 0.3498285984480014, 0.6507698260475001, 0.5354703005594958, 0.5076797772836159, 0.12000997613822295, 0.12175453972737671, 0.13846230608738952, 0.06853185946056961, 0.09639694698524526, 0.08172739214702673, 0.15114811768212144, 0.1110753656541974, 0.0925426499046369, 0.19163678705971732, 0.11341340633531449, 0.1046397698255731, 0.5334657675938494, 0.5497659172580223, 0.2045808383492046, 0.34947965189042596, 0.17873208853523614, 0.3915250587230973, 0.34666025533866374, 0.4676478354235024, 0.4589802477528143, 0.4866993458579195, 0.5312657043113183, 0.4928459309786626, 0.5445365508809483, 0.3960437700285889, 0.4131884130947828, 0.6643903562737061, 0.7861418067115693, 0.8084228474496885, 0.7793230934920117, 0.7966479203522617, 0.7863881139257743, 0.7715900806405529, 0.778539823974718, 0.8281816734807076, 0.0918996711011103, 0.09877196676920119, 0.08874303604861711, 0.09161436042296323, 0.08136139684257193, 0.08640539215225784, 0.0881334940861841, 0.10268818382127243, 0.0981351971408625, 0.13506434713536697, 0.1515448729815897, 0.24684634107717307, 0.14311114262614466, 0.14125619370056575, 0.3635093698779386, 0.1385257128578372, 0.14240206290355817, 0.1355352781089858, 0.36917900558592887, 0.41295726937187005, 0.3154188696319773, 0.36578107747030497, 0.31601428877521653, 0.2821232434363976, 0.3462112977338552, 0.4449176873076617, 0.31795753817837236, 0.25890957784394253, 0.2658308799915914, 0.2675456226024867, 0.2670050054573174, 0.27254527128016803, 0.28696162055961827, 0.23859561382946182, 0.20508754761596282, 0.21693712871027504, 0.22393141643099757, 0.2093896129171794, 0.19534720459646693, 0.1875031115669622, 0.19655151895434841, 0.1995010071891854, 0.24652639534315646, 0.19566618428180993, 0.20086272543637773, 0.17996985626028472, 0.1733059921179596, 0.18544071905885617, 0.18091556901734662, 0.19601546264621506, 0.18429188106073924, 0.1802237873167809, 0.17749067261337803, 0.1814150932219487, 0.16790370323636672, 0.13700333746676874, 0.18798251344252626, 0.25465882516861915, 0.11251569061669475, 0.06195736121941131, 0.10844492011293916, 0.11539635329329212, 0.1679757307819293, 0.9092061871259115, 0.11330628995217107, 0.07470532371094218, 0.1689555118903996, 0.2105062448836338, 0.10964117318970734, 0.15266116496777926, 0.16111052747759347, 0.8842952216887596, 0.19787910695861288, 0.1755555489653421, 0.17898912356561414, 0.18551946106308925, 0.178132609872514, 0.200623280797112, 0.19777465898479918, 0.18571648012704656, 0.1890567748439579, 0.07447559490759104, 0.1103887086576113, 0.0775128836441108, 0.06805950066870903, 0.10216033936920044, 0.0818471689160466, 0.08823977908982705, 0.07695783038107873, 0.09209674397649559]}, "mutation_prompt": null}
{"id": "8d5c8b70-7d30-47ea-9e8d-855155f8b2de", "solution": "import numpy as np\n\nclass EnhancedAdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                if np.random.rand() < 0.25:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.5 * (samples[i] + samples[crossover_idx])\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            improvement_factor = np.mean(self.fitness[indices[:len(weights)]])\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1)) * (1 + 0.5 * (1 - improvement_factor / np.max(self.fitness)))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "EnhancedAdaptiveCMAESOptimizer", "description": "Enhanced Adaptive CMA-ES with stochastic rank-based selection and adaptive mutation for improved exploration and convergence.", "configspace": "", "generation": 67, "fitness": 0.17847801188100387, "feedback": "The algorithm EnhancedAdaptiveCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.26.", "error": "", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {"aucs": [0.9040957568797144, 0.7833649245045496, 0.9369619171554191, 0.9101611268763182, 0.9159796153577693, 0.8980642462992263, 0.9025425010809682, 0.9375517537690587, 0.9240492740869318, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13957127607412823, 0.016186147060770262, 9.999999999998899e-05, 0.03954123940365428, 0.03532824488423958, 0.03679353822803566, 0.024901169718855476, 0.02478564036279074, 0.027246606413320884, 0.05831352772957743, 0.013223885861369356, 0.014914573675350429, 0.03520255370102621, 0.011752362285345042, 0.02266302073870652, 0.02706290936133704, 0.012084182442437141, 0.018786758954834837, 0.985803463312707, 0.9852662993544286, 0.9729960233026781, 0.250466874403513, 0.9487991768156718, 0.8680892113776687, 0.9330891875556162, 0.9738490187889944, 0.7776820947298884, 0.03321463550150616, 0.051417368871677915, 0.040476184377273405, 0.03330709766763851, 0.07405107875348205, 0.038557038104829244, 0.0644243883174711, 0.06152967417931943, 0.037249094365068736, 0.14125447846696793, 0.12841880032722097, 0.1351354805417544, 0.15744900394892958, 0.11018045833112122, 0.0927071885318066, 0.0879986783875607, 0.08862093029433349, 0.09414921888701733, 9.999999999998899e-05, 9.999999999998899e-05, 0.017732470952030233, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00028196367606581063, 9.999999999998899e-05, 0.058600045247131693, 0.06645635194967159, 0.05639308784996522, 0.05968886310288546, 0.0462816393888299, 0.020689535296361417, 0.06796842661725022, 0.10689316271847116, 0.06327504293837904, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.030824541906234515, 0.04639505973889446, 0.016260795866129385, 0.03182766077199628, 0.05950175372042499, 0.028311969422162075, 0.11278443564518914, 0.022861276490018456, 0.030666005244584293, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013781457576570344, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14917247435091707, 0.14288479106352647, 0.8096800467252706, 0.7850414883286267, 0.770757608118042, 0.5463277938656557, 0.6067374680625444, 0.6033473789420283, 0.6559179441481605, 0.09162087648913508, 0.0493038913594277, 0.09836662529318296, 0.03377988217914574, 0.038386244618459964, 0.03841806012746929, 0.03708094655625005, 0.04794960865445408, 0.041015487890153635, 0.13807145609296567, 0.14634146786170732, 0.1322953955717261, 0.6771989281838908, 0.5982887890854214, 0.21450424762721865, 0.14424299278313557, 0.16684211939442206, 0.15213999127557365, 0.15393206619213995, 0.1481817268897967, 0.14681204009411575, 0.17511998547951024, 0.17770568952054744, 0.16623072633805935, 0.41201123737653245, 0.2791691198878028, 0.35713018204670766, 0.07772711500987894, 0.09177905989075952, 0.09826703667572179, 0.10320606799098464, 0.1082506396609968, 0.11123378541528384, 0.15602216655689172, 0.11826598925209164, 0.1752372572633527, 0.23776400348707716, 0.23007668315371088, 0.2162906945241876, 0.20376550694836348, 0.21009381307374564, 0.22176949996616402, 0.1815108483738953, 0.1796099444672158, 0.187247099687045, 0.1480612920668788, 0.06859574748182606, 0.13218605770761915, 0.1149830612149626, 0.14547093261583544, 0.1457757708606543, 0.16127483770101225, 0.08290803548171755, 0.11563527229491155, 0.16122748509727958, 0.17832093817775296, 0.17991043114075234, 0.14207218226744245, 0.1516407080895602, 0.1456174493894501, 0.10854419892583556, 0.11543486700224226, 0.16809330799070943, 0.9135126089443405, 0.1133738127190953, 0.09309247133588272, 0.16969466383310206, 0.20995006926861615, 0.21312744984279475, 0.12751335174425038, 0.17802891698960444, 0.1590913446296479, 0.18376407721602916, 0.17722731339188846, 0.1849729949100657, 0.18920808163737968, 0.1837606201677482, 0.20230248124106054, 0.18333264243157488, 0.19135375687625122, 0.22226444175776439, 0.06644492294175175, 0.05732696746875332, 0.053293609576355094, 0.06185535454935365, 0.061699737507970864, 0.06336877228198956, 0.07079301744698496, 0.05303019334811665, 0.0629038803398082]}, "mutation_prompt": null}
{"id": "4ff40d18-c5dc-4ed9-97b9-875f1b4a89f8", "solution": "import numpy as np\n\nclass DifferentiallyWeightedAdaptiveCMAES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        weights = weights**2  # Increase weight effect\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                if np.random.rand() < 0.25:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.5 * (samples[i] + samples[crossover_idx]) + 0.1 * np.random.randn(self.dim)\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "DifferentiallyWeightedAdaptiveCMAES", "description": "Differentially Weighted Adaptive CMA-ES with stochastic blending for diverse population dynamics.", "configspace": "", "generation": 68, "fitness": -Infinity, "feedback": "An exception occurred: LinAlgError('SVD did not converge').", "error": "LinAlgError('SVD did not converge')", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {}, "mutation_prompt": null}
{"id": "9c7f5a61-a473-45db-96c2-708cc9441cd4", "solution": "import numpy as np\n\nclass ImprovedAdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n        self.mutation_rate = 0.25\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Adjust mutation rate based on progress\n                if np.random.rand() < self.mutation_rate:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.5 * (samples[i] + samples[crossover_idx])\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n            # Repair covariance matrix if needed\n            if np.any(np.linalg.eigvalsh(self.covariance_matrix) <= 0):\n                self.covariance_matrix += np.eye(self.dim) * 1e-8\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "ImprovedAdaptiveCMAESOptimizer", "description": "Enhanced Adaptive CMA-ES with mutation probability adaptation and covariance matrix repair for better reliability.", "configspace": "", "generation": 69, "fitness": 0.3463833598559589, "feedback": "The algorithm ImprovedAdaptiveCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.27.", "error": "", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {"aucs": [0.9023680266036419, 0.9081023544281063, 0.9281146974576004, 0.930892291885995, 0.9219787824141944, 0.921662910916557, 0.9253496587408858, 0.9198976701332013, 0.8847700681413939, 0.6537384997193425, 0.6160233287733642, 0.6563208825227356, 0.6163645354010334, 0.5768076919963834, 0.6381877627976046, 0.644490588013349, 0.5723090794014429, 0.45378070407697757, 0.08901225759668219, 0.08069933266641716, 0.0961342739978509, 0.099610970046912, 0.09499813978399019, 0.0886141914423455, 0.09451995461399343, 0.10446707574883207, 0.15500087634258986, 0.07798333773041666, 0.06658768529066161, 0.07179466685719293, 0.07145984692128038, 0.0851935053973022, 0.07802987436392017, 0.07222210166057508, 0.08258468312889511, 0.07427182600206739, 0.6091481360187416, 0.9819545449057234, 0.9759395480499687, 0.164332031884469, 0.9233971247708334, 0.3349708133828754, 0.9831550828331599, 0.7204988622159381, 0.7945783918736788, 0.12131148762740662, 0.11385627259380837, 0.1569470808834601, 0.10782219947965443, 0.12120919432047816, 0.14355034381092524, 0.11822544820012792, 0.16769198135787444, 0.17681514906892148, 0.4974155913939722, 0.6849128440711825, 0.7842133683239996, 0.672012207194317, 0.8480711271649748, 0.6796432405036426, 0.8954085979215428, 0.8326094600710127, 0.6515106088993727, 0.5269321278983987, 0.5947373568933536, 0.5526691326065478, 0.43522980904509134, 0.5348548697379482, 0.6398425297369021, 0.558463546066519, 0.48939640873544454, 0.6437009647178075, 0.6162203176217613, 0.21540826118668244, 0.6499992954286005, 0.5920147180523607, 0.13367462986243395, 0.5810318345249562, 0.35072235832687515, 0.36817035973293344, 0.5277854784111609, 0.014822481291476786, 0.5285000690540047, 0.04132173516397286, 0.6512040325663568, 0.34734137864289527, 0.3498285984480014, 0.6507698260475001, 0.5354703005594958, 0.5076797772836159, 0.12000997613822295, 0.12175453972737671, 0.13846230608738952, 0.06853185946056961, 0.09639694698524526, 0.08172739214702673, 0.15114811768212144, 0.1110753656541974, 0.0925426499046369, 0.19163678705971732, 0.11341340633531449, 0.1046397698255731, 0.5334657675938494, 0.5497659172580223, 0.2045808383492046, 0.34947965189042596, 0.17873208853523614, 0.3915250587230973, 0.34666025533866374, 0.4676478354235024, 0.4589802477528143, 0.4866993458579195, 0.5312657043113183, 0.4928459309786626, 0.5445365508809483, 0.3960437700285889, 0.4131884130947828, 0.6643903562737061, 0.7861418067115693, 0.8084228474496885, 0.7793230934920117, 0.7966479203522617, 0.7863881139257743, 0.7715900806405529, 0.778539823974718, 0.8281816734807076, 0.0918996711011103, 0.09877196676920119, 0.08874303604861711, 0.09161436042296323, 0.08136139684257193, 0.08640539215225784, 0.0881334940861841, 0.10268818382127243, 0.0981351971408625, 0.13506434713536697, 0.1515448729815897, 0.24684634107717307, 0.14311114262614466, 0.14125619370056575, 0.3635093698779386, 0.1385257128578372, 0.14240206290355817, 0.1355352781089858, 0.36917900558592887, 0.41295726937187005, 0.3154188696319773, 0.36578107747030497, 0.31601428877521653, 0.2821232434363976, 0.3462112977338552, 0.4449176873076617, 0.31795753817837236, 0.25890957784394253, 0.2658308799915914, 0.2675456226024867, 0.2670050054573174, 0.27254527128016803, 0.28696162055961827, 0.23859561382946182, 0.20508754761596282, 0.21693712871027504, 0.22393141643099757, 0.2093896129171794, 0.19534720459646693, 0.1875031115669622, 0.19655151895434841, 0.1995010071891854, 0.24652639534315646, 0.19566618428180993, 0.20086272543637773, 0.17996985626028472, 0.1733059921179596, 0.18544071905885617, 0.18091556901734662, 0.19601546264621506, 0.18429188106073924, 0.1802237873167809, 0.17749067261337803, 0.1814150932219487, 0.16790370323636672, 0.13700333746676874, 0.18798251344252626, 0.25465882516861915, 0.11251569061669475, 0.06195736121941131, 0.10844492011293916, 0.11539635329329212, 0.1679757307819293, 0.9092061871259115, 0.11330628995217107, 0.07470532371094218, 0.1689555118903996, 0.2105062448836338, 0.10964117318970734, 0.15266116496777926, 0.16111052747759347, 0.8842952216887596, 0.19787910695861288, 0.1755555489653421, 0.17898912356561414, 0.18551946106308925, 0.178132609872514, 0.200623280797112, 0.19777465898479918, 0.18571648012704656, 0.1890567748439579, 0.07447559490759104, 0.1103887086576113, 0.0775128836441108, 0.06805950066870903, 0.10216033936920044, 0.0818471689160466, 0.08823977908982705, 0.07695783038107873, 0.09209674397649559]}, "mutation_prompt": null}
{"id": "78ea3085-84be-45f4-8a25-b93e1d837237", "solution": "import numpy as np\n\nclass EnhancedAdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n        self.success_rate = 0.2  # Added for adaptive step-size tuning\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                if np.random.rand() < 0.25:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = (samples[i] + samples[crossover_idx]) / 2  # Modified crossover strategy\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n            \n            # Adapt the step size based on success rate\n            if np.linalg.norm(p_sigma) / np.sqrt(self.dim) < 1:\n                self.adaptive_step_size *= (1.0 + self.success_rate)\n            else:\n                self.adaptive_step_size *= (1.0 - self.success_rate)\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "EnhancedAdaptiveCMAESOptimizer", "description": "Enhanced Adaptive Covariance Matrix Evolution Strategy using dynamic step-size adjustment and crossover for improved exploration and convergence.", "configspace": "", "generation": 70, "fitness": 0.11123745044669588, "feedback": "The algorithm EnhancedAdaptiveCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11 with standard deviation 0.11.", "error": "", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {"aucs": [0.15887842132578878, 0.17233709236618378, 0.23710103067931754, 0.06620255420614773, 0.0223144584623457, 0.1767144251367776, 0.1361895442221437, 0.198421132385598, 0.25021955947251995, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0814820671859996, 9.999999999998899e-05, 0.029297341825849754, 0.05772316606152017, 9.999999999998899e-05, 0.03748661475685111, 0.05183733702764637, 0.015989928756713567, 0.05334948366887571, 0.11364679410464229, 9.999999999998899e-05, 9.999999999998899e-05, 0.02831648859868552, 9.999999999998899e-05, 0.0003019247190337859, 0.00382110664995694, 9.999999999998899e-05, 9.999999999998899e-05, 0.10540979381246929, 0.12036506173750838, 0.15813243174073943, 0.1308035608568946, 0.09766791405106579, 0.12457953596827664, 0.14453531020455557, 0.03745474543447491, 0.09527764941370387, 0.10929661354805409, 0.06032340707215278, 0.05204979476589744, 0.020323970496449517, 0.2162101630225115, 0.11047024720353638, 0.15938524289213096, 9.999999999998899e-05, 0.21391114243627574, 0.15852000381585862, 0.06235727890689391, 0.03520586272692294, 0.11544818362222109, 9.999999999998899e-05, 0.001245206066746718, 0.11401050143190805, 9.999999999998899e-05, 0.08888568910031858, 0.2093247415852486, 0.14575358406147265, 0.13695492097957196, 0.22505607057413113, 0.002317378335753295, 0.016145292271715128, 0.3101533248178212, 0.15329126950067262, 0.1781269049214147, 0.1460445275125154, 0.15529666117515495, 0.13268357058917568, 0.19084916618710823, 0.08199765160869443, 0.1315594632600181, 0.18060700927568396, 0.010101047445965405, 0.14312257154260966, 9.999999999998899e-05, 9.999999999998899e-05, 0.13823245582873755, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1595948316754633, 0.07102189965993, 0.043162903045856904, 0.20528228274781102, 0.06181874856835423, 0.007614592162241252, 0.017728797082324332, 0.13898817203509783, 0.02643795764324619, 0.1331645552988746, 0.43915950006572113, 0.042146695892291586, 0.10303145838276817, 0.19673234214056734, 9.999999999998899e-05, 0.10854563867621603, 0.22623606899984539, 9.999999999998899e-05, 0.13273829721122077, 9.999999999998899e-05, 9.999999999998899e-05, 0.36624560090153035, 0.28181958565574683, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09502090390470308, 0.39078246834293073, 0.0872184010775724, 0.3487174471252593, 0.15906568575308777, 0.09096406471765439, 0.18472525235690807, 0.3828528754136292, 0.3667494103208945, 0.188781110673635, 0.0006877842009109791, 0.0874374379908972, 0.0007177800311531923, 9.999999999998899e-05, 0.0798974206651335, 0.06691402054856188, 0.014993834185562438, 0.09514001545257234, 0.10737693881871424, 0.1454323011624209, 0.1788720666669147, 0.1388006009720193, 0.12099149550792154, 0.14176090342051761, 0.20876532211779153, 0.15058383300327782, 0.18042632004393622, 0.13449362015394506, 0.124808351942578, 0.0897264913715129, 0.10866895147910638, 0.172678772636495, 0.13388873217563946, 0.15941905390324296, 0.15686862599787632, 0.1016283227195035, 0.09728868894245024, 0.0632602366738052, 0.04237834692975162, 0.04802073355855718, 0.09248902674595538, 0.03829632809282779, 0.09591074608791572, 0.1527452911225191, 0.019784289656587517, 0.033883066268574624, 0.1871318123386827, 0.1233991020479156, 0.22764823641363763, 0.18830989369669093, 0.07419460900058128, 0.1147717225807573, 0.21003112047969985, 0.09741222410234518, 0.18040600192524126, 0.16236324748680597, 0.17758899385866955, 0.1785215561928073, 0.17206768228009772, 0.17095795507229994, 0.15310802226237863, 0.1752428257690175, 9.999999999998899e-05, 0.18529473003455632, 0.18867018181990713, 0.13676269065991942, 0.9504072889470951, 0.07671782076760336, 0.10485801665552774, 0.061679749648411386, 0.10852899515120495, 0.1153761725474668, 0.15440440497005037, 0.436060089067574, 0.10989495432463936, 0.08268330393315482, 0.15447856072585597, 0.076947565921058, 0.11068753584011737, 0.1681419128144186, 0.04358662689026693, 0.07521126843924353, 0.2420525672943762, 0.20031710001336744, 0.1816558356286816, 0.232707742533784, 0.24622186066381269, 0.20522299932483123, 0.2311020529714548, 0.16903317828287723, 0.23250030153593437, 0.043259051678575466, 0.062430479855423604, 0.03722012424939225, 0.0399383999319145, 0.02258444804779358, 0.017240282964620546, 0.08007235112867561, 0.022625690968125722, 0.07145726255480933]}, "mutation_prompt": null}
{"id": "5e8a4ca3-ab3a-4e8c-8cc6-870a50da057b", "solution": "import numpy as np\n\nclass HierarchicalAdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n        self.hierarchy_factor = 0.75  # New parameter to enhance exploration\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Hierarchical dynamic crossover for enhanced exploration\n                if np.random.rand() < self.hierarchy_factor:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.5 * (samples[i] + samples[crossover_idx])\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "HierarchicalAdaptiveCMAESOptimizer", "description": "Hierarchical Adaptive Covariance Matrix Evolution Strategy with dynamic crossover and mutation for enhanced exploration and convergence.", "configspace": "", "generation": 71, "fitness": 0.25367168313193444, "feedback": "The algorithm HierarchicalAdaptiveCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.23.", "error": "", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {"aucs": [0.9368716198982128, 0.9444507261011441, 0.9335118694823913, 0.9353788429927807, 0.9430144073697801, 0.9365774221299717, 0.9367433805288622, 0.9469288827715798, 0.945209652801294, 0.001971707188184846, 0.020342485092349705, 0.14049212323852933, 0.47327275332855345, 0.39673353194486893, 0.023303467696769053, 0.23536724663674768, 0.07079329032654236, 0.16294681533866373, 0.08987258305190404, 0.11439916722565668, 0.0997307274320065, 0.08351251622963851, 0.011269299238552577, 0.04643315711309437, 0.10598248489448414, 0.09691799362466413, 0.07874505469189119, 0.054256636411224135, 9.999999999998899e-05, 0.0758056436865212, 0.04612247075800502, 0.06494846765067763, 0.062279584191463844, 0.04654779052884517, 0.06256408403190783, 0.06070785158667569, 0.22633609105223196, 0.1903671847113051, 0.15571495875306918, 0.2825272858073037, 0.33298753195086606, 0.11725743538275402, 0.18430219931129888, 0.3160757007186896, 0.30207610397500306, 0.8231503754500487, 0.6543831345910532, 0.6429165738797289, 0.6685558461501209, 0.6604397556295736, 0.7729929801430828, 0.7708186213458239, 0.6946906773551313, 0.7622511384970979, 0.16370341181615566, 0.08381179861398647, 0.02722487047271338, 0.18204422268056009, 0.20162581803613233, 0.3263724422059662, 0.12201171287672496, 0.0541092727678355, 0.33815128491350765, 0.3016259579170464, 0.27522767061312425, 0.11972074016812273, 0.2496490494514576, 0.19048163884457647, 0.154132236299949, 0.17965883924815007, 0.35593991427262783, 0.18275728439473382, 0.21412267828480425, 0.22035835264887405, 0.19044853942968942, 0.2084754703057582, 0.2516905923220967, 0.13462033923712702, 0.3152706126289986, 0.24983684174165266, 0.1457202694878038, 0.20918253384952235, 0.3097860039185649, 0.3788753695533562, 0.03623113257927524, 0.3558418106004728, 0.11239379324743659, 0.10059913168949919, 0.13853863900633256, 0.10689159820988425, 0.43803281568418184, 0.5329692496073734, 0.2708670845705594, 0.5598088450713239, 0.4508781323077641, 0.334315370282556, 0.4987556635310719, 0.45656766708753826, 0.3661462636618379, 0.2318028938171377, 0.0792122728956941, 0.04959462012458171, 0.1718949382225825, 0.10446820622268294, 0.11814488904602893, 0.19151744312529329, 0.23838705339142496, 0.23302025802994397, 0.043913765579318365, 0.1510621296487672, 0.25823580946630587, 0.3265371706052774, 0.3424377679003593, 0.16437564179627284, 0.2222603800494226, 0.1505099047086531, 0.10184160042427104, 0.6454942668796516, 0.6816767663126766, 0.5844408121883216, 0.6510155231809502, 0.6465514366561458, 0.5827656442937286, 0.6428537957574367, 0.7375662465658148, 0.6428389221369478, 0.11329740361152874, 0.07508265804880287, 0.014429554434084113, 0.09680196897607929, 0.08829741350801212, 0.08939474045504414, 9.999999999998899e-05, 0.06543281193593353, 0.057550102002533854, 0.30112701627711735, 0.122276902314299, 0.1279188666695198, 0.17541019014033477, 0.1192777605715104, 0.16956678683182513, 0.18225470999171434, 0.18133122248084488, 0.19925155868674793, 0.21483515302049572, 0.31449695034238456, 0.11674836316615167, 0.3319405506416472, 0.07346629411991357, 0.1900073104339648, 0.23264269218209666, 0.0904429934077765, 0.09813539628280488, 0.2289291057749855, 0.04563851789493545, 0.18737942194571433, 0.13845371611041424, 0.1652653389660902, 0.15015422342581775, 0.21470949094229375, 0.1920427362217747, 0.029753989874559683, 0.1821661327123405, 0.18954652217896617, 0.1844857720667724, 0.1876388099358567, 0.23876764663902228, 0.1094004374316715, 0.22474937672030804, 0.1718689226698079, 0.17717979041606957, 0.17059850330441584, 0.1944055027749202, 0.17259110468371075, 0.17736258510947722, 0.15495573662153672, 0.19055717805067907, 0.18307074643137733, 0.19286765021656227, 0.20068365813332567, 0.12346663770540423, 0.13691909586493167, 0.07114612276502352, 0.17350448344988267, 0.11112777791525608, 0.06187246330483809, 0.1089202445408104, 0.11530210530935436, 0.09565975629847745, 0.9553383588502264, 0.11265433526474533, 0.15522190188094542, 0.16996431005899937, 0.2103948503386761, 0.20549030949459546, 0.6777730133275008, 0.05840537049852268, 0.44399669997525537, 0.1759440485639534, 0.17345093515287413, 0.2056036146734017, 0.24847761419579417, 0.16545764610616165, 0.19015307801641856, 0.1873131694413006, 0.20359542976211797, 0.25305721109027457, 0.10792393511292553, 0.1076037320850064, 0.09552346082267082, 0.0841642491554756, 0.009128263489498023, 0.06756027373922502, 0.11565585505712117, 0.024283647147723575, 0.0624471111728373]}, "mutation_prompt": null}
{"id": "def02f8e-d5f0-4439-8828-d9d03e75a1de", "solution": "import numpy as np\n\nclass HybridCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Introduce Gaussian perturbations randomly\n                if np.random.rand() < 0.25:\n                    samples[i] += np.random.normal(0, self.adaptive_step_size, self.dim)\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "HybridCMAESOptimizer", "description": "Hybrid Adaptive CMA-ES integrating random Gaussian perturbations for increased exploration.", "configspace": "", "generation": 72, "fitness": 0.12419865350185447, "feedback": "The algorithm HybridCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.19.", "error": "", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {"aucs": [0.2195805493026356, 0.21250745946574656, 0.2498695952717166, 0.15681322655526642, 0.17177159426392685, 0.17543199720887404, 0.2118001136428065, 0.22075047284820293, 0.19257220418056298, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05327631380870457, 0.04974073724896533, 0.0637663533361541, 0.05059580415937892, 0.04127308613972813, 0.06022568642247783, 0.04022066936376212, 0.028800278259486722, 0.03813030804131379, 0.022752004569783435, 0.009631144243162804, 0.019322920459874715, 0.05806993894357293, 0.012798248853738925, 0.01972508525551908, 0.028657364955826825, 0.01251008103868989, 0.019311919144085588, 0.978424777989928, 0.9645075176028396, 0.9720974681923609, 0.9729804283228589, 0.9826186266610928, 0.9930408255462985, 0.9933969841814839, 0.9787931510797863, 0.9882662742722035, 0.0907229537218811, 0.055826059545861395, 0.05071673468045379, 0.06120307032082761, 0.06831142442261684, 0.04257882085683107, 0.05507974907431057, 0.07004789087377372, 0.0704560192496212, 0.12901000973476695, 0.09241790885883605, 0.11524274878855745, 0.17770375408951622, 0.12436906442036688, 0.1345802242214943, 0.11090233471860556, 0.12504035940240177, 0.12586653256867297, 9.999999999998899e-05, 9.999999999998899e-05, 0.0012976052385863523, 9.999999999998899e-05, 9.999999999998899e-05, 0.003707644321665593, 9.999999999998899e-05, 9.999999999998899e-05, 0.012534434718377119, 0.037976515713539105, 0.003043536211024711, 0.027217516556858223, 0.021155354323521003, 9.999999999998899e-05, 9.999999999998899e-05, 0.028351119421391346, 0.0013251834541817553, 0.09286066589348152, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03665539309644794, 0.03441476646894348, 0.038663364945919376, 0.028888879486301033, 0.0019266421274347634, 0.02159427949519721, 0.046975931086310485, 0.01681915334571371, 0.010824449719953222, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.032267661225773514, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006226440262267707, 9.999999999998899e-05, 9.999999999998899e-05, 0.2041240722055221, 0.19358620670078674, 0.2394274777195451, 0.17290449488618942, 0.17767901367103422, 0.18184363476589438, 0.1995014183836875, 0.17713456402203376, 0.19658779649720082, 0.057717034990978355, 0.044140769674764435, 0.03356126774278312, 0.04620267914849885, 0.06834494312393125, 0.037823061794241, 0.057673189288563353, 0.034952655729353466, 0.044502173354958874, 0.12114123731494308, 0.13426432552776912, 0.12829794889020107, 0.15462564515050925, 0.1536474781635736, 0.15121388190845864, 0.17924512594156838, 0.1490035541076461, 0.1260566991486668, 0.17472799178677356, 0.14154830575329236, 0.14551286740352665, 0.1813812026365026, 0.14935331718169909, 0.16156430668115396, 0.1699620785255267, 0.1691920287194445, 0.17961580449754533, 0.09533880174494547, 0.08747668949928267, 0.09673580735326937, 0.12617320662711118, 0.09714942672967541, 0.10456709044668222, 0.10529011774487573, 0.11154105932937053, 0.10523891834174592, 0.1685432276853862, 0.14080915405992378, 0.14941427920628558, 0.19171207144617286, 0.14588952316672077, 0.15105148583083505, 0.18276345667761307, 0.15063442119774006, 0.15022426634350505, 0.15797687158660356, 0.16399724543069427, 0.14751522184523425, 0.16367199458814352, 0.14842634190528137, 0.1543648078534119, 0.15505750754854453, 0.06880262235657408, 0.14708267821961896, 0.12372414636174911, 0.15712438377904203, 0.1579293442580676, 0.187519749506034, 0.15641429414164865, 0.13279806384369008, 0.1315861523754951, 0.1195729443353386, 0.13977720828004458, 0.130119528220352, 0.15458174081888787, 0.14430934539294538, 0.13082538996732584, 0.11497373662295851, 0.15015206891830946, 0.22673873521619925, 0.1934877982586063, 0.1638010225055988, 0.17181046647289533, 0.19101033541925838, 0.17760785206157603, 0.1817635743555811, 0.16902399505842935, 0.1800733145847342, 0.19754550225784273, 0.1746724582688759, 0.1763252137798227, 0.0458204981614565, 0.04811261211031892, 0.04267687026308087, 0.041714208728059754, 0.043720191313860624, 0.03971605906761888, 0.06461360497689617, 0.04676332018305507, 0.03996147123579308]}, "mutation_prompt": null}
{"id": "c8daad8a-be22-47e9-96f4-0e05d731c2eb", "solution": "import numpy as np\n\nclass EnhancedAdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Enhanced mutation strategy\n                if np.random.rand() < 0.3:\n                    samples[i] = self.mean + np.random.normal(0, self.adaptive_step_size, self.dim)\n                # Enhanced crossover strategy\n                if np.random.rand() < 0.2:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.6 * samples[i] + 0.4 * samples[crossover_idx]\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "EnhancedAdaptiveCMAESOptimizer", "description": "Enhanced Adaptive CMA-ES with guided mutation and crossover strategies for robust convergence.", "configspace": "", "generation": 73, "fitness": 0.12968648916322814, "feedback": "The algorithm EnhancedAdaptiveCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.19.", "error": "", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {"aucs": [0.19484340050411897, 0.1870987572591304, 0.20334011459842927, 0.16425870873854842, 0.18552707122722845, 0.19794662231688898, 0.201847071564486, 0.2032321929769143, 0.20903765237876404, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06433203129209997, 0.05579576440139078, 0.051721129430565616, 0.04615935479625821, 0.04233008897985602, 0.05008529659447536, 0.03737228589897823, 0.04914610639025063, 0.052108947167052944, 0.05109214927674566, 0.020254636443033602, 0.023647041493440657, 0.023369093593772372, 0.0492402192069219, 0.027373557063849474, 0.035075184812924265, 0.018929706847941263, 0.025366949377204406, 0.9812645692125168, 0.9844447289955619, 0.9906239708824242, 0.9756637975095577, 0.9719604808273408, 0.9924732447251114, 0.9833400935715247, 0.9741907465610335, 0.984022954636203, 0.06136144390506215, 0.053606977096217645, 0.0708664299822116, 0.08562259617484036, 0.08623235307118671, 0.07667492758673611, 0.07416177566256588, 0.0664067297654043, 0.1132499542460782, 0.21217689987309563, 0.1046947012165983, 0.14750814511856059, 0.12840441422560345, 0.11336214301928627, 0.13721393559037554, 0.1089509561309453, 0.13419434389425133, 0.12115294270573629, 9.999999999998899e-05, 0.004212599098744274, 0.04429994543863813, 0.02194568474259817, 9.999999999998899e-05, 0.0031237064253651914, 0.013599917002797834, 0.028971310596362265, 9.999999999998899e-05, 0.09775163433321232, 0.00563405583542731, 0.025123838255547537, 0.0722034455027809, 0.0712340926957229, 0.003569624507560154, 0.07678858914281883, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.046887522464910236, 0.05685153795043607, 0.01740569867905195, 0.025655058776904882, 0.03495612301457274, 0.03743129752896346, 0.0464409003744366, 0.06060222846681396, 0.05980225997743982, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009467285450684537, 9.999999999998899e-05, 9.999999999998899e-05, 0.0004518409295899417, 0.007233988522594492, 9.999999999998899e-05, 0.19418504421059668, 0.21591461433167647, 0.23341194048852654, 0.18491995788179272, 0.1932448200400838, 0.17953546222999106, 0.25206055354451606, 0.2226770998803077, 0.20043808486697612, 0.07714126181424052, 0.04949511781155247, 0.032341513638174724, 0.03618871895659592, 0.041152184275904946, 0.03897627986847185, 0.045704666124433246, 0.04236880426215006, 0.05428368073693668, 0.16529264968313528, 0.16116129630762732, 0.13070494297933588, 0.12462770179185789, 0.14098496637481095, 0.14295403236631898, 0.11161326903948099, 0.12056942040699936, 0.1481343364020309, 0.17475703157310496, 0.16488407325161658, 0.15635208096025233, 0.17676518548315456, 0.15934307578084406, 0.1799168802241955, 0.16638797282686613, 0.15553974774369272, 0.14615995831250916, 0.10864139388537841, 0.1197801732573156, 0.09490165152610464, 0.12531090854518023, 0.09991833202826494, 0.11770886582493656, 0.11967936149494085, 0.13361962445287767, 0.1343984931141935, 0.19244487554738976, 0.14749806233755314, 0.1609277404517908, 0.18226141561046938, 0.16880331569872054, 0.14623939588398538, 0.18099829678429902, 0.1584625817433516, 0.1463606333710339, 0.15761573964998266, 0.1519233928487984, 0.15716439551435302, 0.1570543667415093, 0.1585631450322369, 0.16306301094630782, 0.16390280538492863, 0.1621393325565288, 0.15008865655386638, 0.17090209309582938, 0.1495347881753729, 0.19937250436332465, 0.16452194735648884, 0.12272132222113774, 0.1631570953472894, 0.15380762023798378, 0.12566981270691013, 0.19287239466716355, 0.13108956667152982, 0.14461206659364323, 0.14640317092067856, 0.15539262542283672, 0.18498395976114757, 0.12440993063697059, 0.13997153020352193, 0.1668800571693282, 0.12894330955936473, 0.17549391348266785, 0.18846609026692218, 0.17895711412828552, 0.17154259147072315, 0.17623350647792047, 0.20148419950263452, 0.19491858569399367, 0.19971343256738827, 0.20015853623094526, 0.054860945484210055, 0.04912879329095121, 0.06381462417562578, 0.05360960133724346, 0.047020498126303156, 0.06549064196054366, 0.06144921196547837, 0.05089876103853053, 0.05433484715805337]}, "mutation_prompt": null}
{"id": "8d66beaa-f9b7-4787-97e9-a6bff9d05131", "solution": "import numpy as np\n\nclass AdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Dynamic recombination for enhanced diversity\n                if np.random.rand() < 0.25:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.5 * (samples[i] + samples[crossover_idx])\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "AdaptiveCMAESOptimizer", "description": "Adaptive Covariance Matrix Evolution Strategy with dynamic recombination and mutation for enhanced convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {"aucs": [0.9023680266036419, 0.9081023544281063, 0.9281146974576004, 0.930892291885995, 0.9219787824141944, 0.921662910916557, 0.9253496587408858, 0.9198976701332013, 0.8847700681413939, 0.6537384997193425, 0.6160233287733642, 0.6563208825227356, 0.6163645354010334, 0.5768076919963834, 0.6381877627976046, 0.644490588013349, 0.5723090794014429, 0.45378070407697757, 0.08901225759668219, 0.08069933266641716, 0.0961342739978509, 0.099610970046912, 0.09499813978399019, 0.0886141914423455, 0.09451995461399343, 0.10446707574883207, 0.15500087634258986, 0.07798333773041666, 0.06658768529066161, 0.07179466685719293, 0.07145984692128038, 0.0851935053973022, 0.07802987436392017, 0.07222210166057508, 0.08258468312889511, 0.07427182600206739, 0.6091481360187416, 0.9819545449057234, 0.9759395480499687, 0.164332031884469, 0.9233971247708334, 0.3349708133828754, 0.9831550828331599, 0.7204988622159381, 0.7945783918736788, 0.12131148762740662, 0.11385627259380837, 0.1569470808834601, 0.10782219947965443, 0.12120919432047816, 0.14355034381092524, 0.11822544820012792, 0.16769198135787444, 0.17681514906892148, 0.4974155913939722, 0.6849128440711825, 0.7842133683239996, 0.672012207194317, 0.8480711271649748, 0.6796432405036426, 0.8954085979215428, 0.8326094600710127, 0.6515106088993727, 0.5269321278983987, 0.5947373568933536, 0.5526691326065478, 0.43522980904509134, 0.5348548697379482, 0.6398425297369021, 0.558463546066519, 0.48939640873544454, 0.6437009647178075, 0.6162203176217613, 0.21540826118668244, 0.6499992954286005, 0.5920147180523607, 0.13367462986243395, 0.5810318345249562, 0.35072235832687515, 0.36817035973293344, 0.5277854784111609, 0.014822481291476786, 0.5285000690540047, 0.04132173516397286, 0.6512040325663568, 0.34734137864289527, 0.3498285984480014, 0.6507698260475001, 0.5354703005594958, 0.5076797772836159, 0.12000997613822295, 0.12175453972737671, 0.13846230608738952, 0.06853185946056961, 0.09639694698524526, 0.08172739214702673, 0.15114811768212144, 0.1110753656541974, 0.0925426499046369, 0.19163678705971732, 0.11341340633531449, 0.1046397698255731, 0.5334657675938494, 0.5497659172580223, 0.2045808383492046, 0.34947965189042596, 0.17873208853523614, 0.3915250587230973, 0.34666025533866374, 0.4676478354235024, 0.4589802477528143, 0.4866993458579195, 0.5312657043113183, 0.4928459309786626, 0.5445365508809483, 0.3960437700285889, 0.4131884130947828, 0.6643903562737061, 0.7861418067115693, 0.8084228474496885, 0.7793230934920117, 0.7966479203522617, 0.7863881139257743, 0.7715900806405529, 0.778539823974718, 0.8281816734807076, 0.0918996711011103, 0.09877196676920119, 0.08874303604861711, 0.09161436042296323, 0.08136139684257193, 0.08640539215225784, 0.0881334940861841, 0.10268818382127243, 0.0981351971408625, 0.13506434713536697, 0.1515448729815897, 0.24684634107717307, 0.14311114262614466, 0.14125619370056575, 0.3635093698779386, 0.1385257128578372, 0.14240206290355817, 0.1355352781089858, 0.36917900558592887, 0.41295726937187005, 0.3154188696319773, 0.36578107747030497, 0.31601428877521653, 0.2821232434363976, 0.3462112977338552, 0.4449176873076617, 0.31795753817837236, 0.25890957784394253, 0.2658308799915914, 0.2675456226024867, 0.2670050054573174, 0.27254527128016803, 0.28696162055961827, 0.23859561382946182, 0.20508754761596282, 0.21693712871027504, 0.22393141643099757, 0.2093896129171794, 0.19534720459646693, 0.1875031115669622, 0.19655151895434841, 0.1995010071891854, 0.24652639534315646, 0.19566618428180993, 0.20086272543637773, 0.17996985626028472, 0.1733059921179596, 0.18544071905885617, 0.18091556901734662, 0.19601546264621506, 0.18429188106073924, 0.1802237873167809, 0.17749067261337803, 0.1814150932219487, 0.16790370323636672, 0.13700333746676874, 0.18798251344252626, 0.25465882516861915, 0.11251569061669475, 0.06195736121941131, 0.10844492011293916, 0.11539635329329212, 0.1679757307819293, 0.9092061871259115, 0.11330628995217107, 0.07470532371094218, 0.1689555118903996, 0.2105062448836338, 0.10964117318970734, 0.15266116496777926, 0.16111052747759347, 0.8842952216887596, 0.19787910695861288, 0.1755555489653421, 0.17898912356561414, 0.18551946106308925, 0.178132609872514, 0.200623280797112, 0.19777465898479918, 0.18571648012704656, 0.1890567748439579, 0.07447559490759104, 0.1103887086576113, 0.0775128836441108, 0.06805950066870903, 0.10216033936920044, 0.0818471689160466, 0.08823977908982705, 0.07695783038107873, 0.09209674397649559]}, "mutation_prompt": null}
{"id": "728a4b6f-5d4c-4678-8cd4-0f0e1d615a80", "solution": "import numpy as np\n\nclass EnhancedAdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Tournament selection for diversification\n                if np.random.rand() < 0.25:\n                    tournament_size = np.random.randint(2, self.population_size // 2)\n                    tournament_indices = np.random.choice(self.population_size, tournament_size, replace=False)\n                    best_in_tournament = np.argmin(self.fitness[tournament_indices])\n                    samples[i] = 0.5 * (samples[i] + samples[tournament_indices[best_in_tournament]])\n                # Adaptive mutation rate\n                samples[i] += self.mutation_rate * np.random.randn(self.dim)\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n            # Adjust mutation rate\n            self.mutation_rate *= 0.9 if self.eval_count > self.budget / 2 else 1.1\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "EnhancedAdaptiveCMAESOptimizer", "description": "Enhanced Adaptive CMA-ES with a novel adaptive mutation rate and tournament selection for improved convergence.", "configspace": "", "generation": 75, "fitness": 0.12117802896629509, "feedback": "The algorithm EnhancedAdaptiveCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.19.", "error": "", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {"aucs": [0.22398355696239036, 0.233821355412413, 0.24068646954874362, 0.21304212914371645, 0.28345774358761533, 0.20940848325025896, 0.20084793929064015, 0.2273102982721732, 0.1710141154915542, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04796354850495099, 0.03318285945699151, 0.05124551617732909, 0.05470894776692348, 0.0642573598139552, 0.04461320872563157, 0.06353166122211495, 0.03521339185340733, 0.05921010319113562, 0.05538199275157951, 0.00920464999562487, 0.019906178535550656, 0.0302567154763157, 0.0031595946008959874, 0.024456301315492812, 0.016080441809185997, 0.025537747089650287, 0.034822194226068914, 0.9562548648344926, 0.976968850771522, 0.9497984402925991, 0.9544098120139447, 0.9600774099762088, 0.9565748391302824, 0.9709080845552586, 0.9598879363894676, 0.957691932618933, 0.08608899313488616, 0.03463423292529966, 0.05248889090890696, 0.06411959026083436, 0.06533684601389611, 0.05780246015234225, 0.059941771793618814, 0.0413223916846327, 0.08834222070818809, 0.18397890874621226, 0.19466096454743387, 0.07375516466582377, 0.19658290978000392, 0.07644156966401883, 0.0935242412667523, 0.11783918096981794, 0.09825269830413874, 0.1014817278055028, 0.005700593654769048, 0.004069447211392463, 0.029349538279707654, 0.002949515758381094, 0.00440047662324361, 0.004901615238283141, 0.004272282115118098, 0.0053608188119764755, 0.02930228365142451, 0.06415901938974078, 0.0010213985392234504, 0.03602532146584159, 0.0007812616028650687, 0.00479215384827425, 0.003718441778174375, 0.03472932496506287, 0.027445240778614433, 0.021585821212024903, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.000233770584007309, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0014042284579188768, 0.00902311295992786, 0.10099938460114122, 0.0452238138063642, 0.0068978770079441976, 0.00015446370390126418, 0.05770911352451136, 0.014771993038497966, 0.0015362570692319943, 9.999999999998899e-05, 9.999999999998899e-05, 0.00010464819562439054, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.004047051682028346, 0.00034680365079764464, 0.0028219371843420937, 0.00375800447772201, 0.0031497753461592337, 0.002180909032298395, 0.0031557852896392236, 0.0038676054221159495, 0.012788859729856439, 0.2316996556986004, 0.2358123285035083, 0.22789854877348348, 0.1846218168484275, 0.18534065575726832, 0.2508961376180796, 0.1948505294896884, 0.21136298161152078, 0.17045851242681442, 0.06457147322179912, 0.037987068741923036, 0.05612030394341838, 0.04274389852127425, 0.05034027363388649, 0.05876671235943309, 0.04320401291267795, 0.05799883123052296, 0.05206928600850369, 0.10903364752645905, 0.11704177093210832, 0.12700060959782444, 0.08671999206610637, 0.11436026407903632, 0.1183772490362871, 0.0897692499960887, 0.09000112009020544, 0.10417731806251196, 0.16674137224898733, 0.14366501485655359, 0.12896017720348596, 0.20413183157426984, 0.14071910152363054, 0.148605667287233, 0.15296415624365378, 0.15214829111122075, 0.1532652213030935, 0.11419294340426345, 0.09311091294837548, 0.06584780216283925, 0.1219193274258501, 0.10154928590800139, 0.09130494416740786, 0.12023557528706386, 0.0711325338761104, 0.08001525550078381, 0.1538040278278291, 0.12813398051080405, 0.15346021681671862, 0.16612304984274306, 0.1450591605902195, 0.16246715824224245, 0.1649310200062395, 0.1682996062534301, 0.14471457361047546, 0.17997816006586054, 0.1455885661133579, 0.14568652712871788, 0.15669985670597542, 0.15844533891173573, 0.15003128489268514, 0.15434895681747463, 0.14097665346387023, 0.15433441740166998, 0.12409152847975458, 0.12151497654692012, 0.21939815347170044, 0.1685588533235507, 0.11587442199980436, 0.1291443932916091, 0.11002907503167136, 0.12611088609414534, 0.10787385297238905, 0.2909487530839312, 0.09898060534987796, 0.08657743014977404, 0.1668291868885563, 0.08120000403371286, 0.09923727853278475, 0.14608792943965077, 0.06378048280304505, 0.08495920399209445, 0.18160728882283994, 0.1600677129650454, 0.14985186280464624, 0.14706832634657363, 0.14588565291308186, 0.1694906736866162, 0.14679517898093186, 0.158981889872174, 0.16780514441510153, 0.053383273545122956, 0.050501045872140105, 0.0514920171944353, 0.10224734142913272, 0.0494139432752394, 0.045311189685332875, 0.05782814272973902, 0.04456486602352838, 0.04743408567527985]}, "mutation_prompt": null}
{"id": "69e8f873-e3a9-4a65-a3f3-4cc86a8047b5", "solution": "import numpy as np\n\nclass EnhancedAdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n        self.sigma_scaling = 0.1\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, (self.adaptive_step_size**2 + self.sigma_scaling) * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                if np.random.rand() < 0.3:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.5 * (samples[i] + samples[crossover_idx])\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n            if self.eval_count % (self.budget // 10) == 0:\n                self.sigma_scaling *= 0.9\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "EnhancedAdaptiveCMAESOptimizer", "description": "Enhanced Adaptive CMA-ES with stochastic covariance adaptation and adaptive scaling for dynamic exploration-exploitation balance.", "configspace": "", "generation": 76, "fitness": -Infinity, "feedback": "An exception occurred: LinAlgError('Matrix is not positive definite').", "error": "LinAlgError('Matrix is not positive definite')", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {}, "mutation_prompt": null}
{"id": "b6073269-5dc9-4cb2-aedb-8894a76d8700", "solution": "import numpy as np\n\nclass EnhancedAdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                if np.random.rand() < 0.25:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.5 * (samples[i] + samples[crossover_idx])\n                if np.random.rand() < 0.25:\n                    samples[i] += np.random.normal(0, 0.1, self.dim)\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "EnhancedAdaptiveCMAESOptimizer", "description": "Enhanced Adaptive CMA-ES with stochastic sample perturbation and covariance adaptation for robust optimization.", "configspace": "", "generation": 77, "fitness": 0.19316321319724092, "feedback": "The algorithm EnhancedAdaptiveCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.16.", "error": "", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {"aucs": [0.5182009285405127, 0.5193647244701046, 0.5315181579957343, 0.5232604120767446, 0.5383158541763458, 0.5567189680099669, 0.4986112695336554, 0.5317637801577608, 0.5335853578654595, 0.03858692306685385, 0.04850336184664594, 0.039488753526140896, 0.03469810151836883, 0.05701907953934637, 0.03817033730296737, 0.06359730816851228, 0.07805579611572755, 0.014810897409073376, 0.08063145477828604, 0.0878941588739175, 0.09297167565759623, 0.09113633921559539, 0.09245228746225553, 0.08665484962511605, 0.08788740109072246, 0.11655353692743375, 0.105715965472163, 0.07980733097092507, 0.07054106335290056, 0.07205803322272963, 0.07702180288975669, 0.07936672796209587, 0.08780215649469958, 0.07993423136304412, 0.08632180480332519, 0.08269211893266148, 0.19854573130320619, 0.7353460643782521, 0.6200970329878819, 0.9546443115976263, 0.5289730487171942, 0.18492516883240184, 0.255017117772967, 0.22636233538920525, 0.9356085961909965, 0.1260239298276854, 0.11275823248503891, 0.12687388132748578, 0.0980600554480292, 0.10888306099315814, 0.11144341264310353, 0.15132387916871703, 0.14415046928131448, 0.12298904206953465, 0.3198410341276693, 0.44259654774064916, 0.30523088282346167, 0.3199079243952814, 0.4624838135790389, 0.3645830861612298, 0.6202770973517912, 0.3136837945786357, 0.901521806784096, 0.17493444002933978, 0.172931268125878, 0.16376508488008512, 0.1805254017344219, 0.16894519732798252, 0.17015879850932292, 0.15123608921619347, 0.23076969620874277, 0.17195454424751222, 0.20469568782515812, 0.1821357720567115, 0.15528856712366634, 0.19568354860557824, 0.18355768044658238, 0.19265572587386193, 0.1603663964389589, 0.1670158110491058, 0.18770652537435728, 0.025174882229719198, 0.020068272072207072, 0.059206601758957866, 0.00858576190944893, 0.01920603781305874, 0.009804671734906845, 0.03127538184821055, 0.08105629961452854, 0.02833642651187651, 0.09406135690960016, 0.08012348024586768, 0.1477689740867688, 0.1274757143425781, 0.11843395534446122, 0.07791242123749798, 0.12645217134903886, 0.12280466544483115, 0.11376889519623368, 0.028928822519050157, 0.03227016185415399, 0.02830114896739999, 0.026055770327488292, 0.00016698515297608463, 9.999999999998899e-05, 0.052368033878409714, 0.013595541041034442, 0.004464998009130028, 0.138630511336032, 0.13676277778666512, 0.14198535885056807, 0.15922099232492437, 0.14399369556268016, 0.14427207849916612, 0.14869536669048666, 0.13655994361259816, 0.14260528998725353, 0.45629198448757646, 0.4492845069934074, 0.4537702701662565, 0.4928347284078015, 0.4637817856552843, 0.43527872011897606, 0.4340481991413928, 0.44878325764898097, 0.4271644017963364, 0.11115933676936651, 0.09317170712556111, 0.1042170112172024, 0.09896039337310991, 0.09448103652245499, 0.09108332641091421, 0.093894847519428, 0.10703245879638856, 0.08089197156217376, 0.16253371506498693, 0.16493626086628244, 0.14972152285982943, 0.13841573538423513, 0.13559005584278294, 0.1573575755693608, 0.12869375698643748, 0.12195428948347908, 0.14099527233877085, 0.2814886571196271, 0.26809457175600016, 0.30482101493083924, 0.2889513661456664, 0.2766397770472615, 0.2676440922997564, 0.2770740377246631, 0.28981579449301875, 0.29243301328455185, 0.2266094599405264, 0.22768970063636473, 0.21188281143474175, 0.22111815603278862, 0.22141145199136325, 0.18763752724325122, 0.2098701726615061, 0.22499667078162533, 0.21614720139349475, 0.1956528853713987, 0.21258648506253341, 0.19575247392002126, 0.18133856729436515, 0.18157695386562678, 0.20725562212198345, 0.1979664906207036, 0.1799797758174787, 0.19821053584025006, 0.1805640235465571, 0.17884238363184501, 0.17284647572416179, 0.1795623036803189, 0.17605650615678747, 0.1784767855085615, 0.17667908896817974, 0.18094039775967474, 0.1768465705203236, 0.18920475930408542, 0.13740701966043012, 0.16803451868284813, 0.1733171725405428, 0.112020787887818, 0.06206584300460383, 0.10876900094672437, 0.11722792324474063, 0.15465691439135498, 0.322913207167582, 0.16724034096083107, 0.19702152208222923, 0.0963581298097348, 0.2120823170646775, 0.2098604956417034, 0.18526789130262056, 0.05907112772137191, 0.11826483221855599, 0.1833310721765169, 0.17736400952725184, 0.19358220882601707, 0.179035597726105, 0.1807298995368939, 0.19752454267802777, 0.18001779284040076, 0.18058930020926678, 0.17640499327151615, 0.09547825211937311, 0.07572239601697528, 0.07412955470324556, 0.08255631079177417, 0.07831906410134015, 0.07220541546853032, 0.078314589092767, 0.0778034202091703, 0.06888990774574921]}, "mutation_prompt": null}
{"id": "f2396d31-90aa-4504-9e15-9d48d22c9647", "solution": "import numpy as np\n\nclass EnhancedAdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.6  # Adjusted to improve exploration\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Stochastic selection with rank-based probability\n                if np.random.rand() < 0.25:\n                    crossover_idx = np.random.choice(self.population_size, p=np.arange(1, self.population_size + 1)[::-1] / np.sum(np.arange(1, self.population_size + 1)))\n                    samples[i] = 0.5 * (samples[i] + samples[crossover_idx])\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "EnhancedAdaptiveCMAESOptimizer", "description": "Enhanced Adaptive CMA-ES with stochastic rank-based selection and adaptive mutation rate.", "configspace": "", "generation": 78, "fitness": 0.34229329545830545, "feedback": "The algorithm EnhancedAdaptiveCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.27.", "error": "", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {"aucs": [0.9109345446974939, 0.867526138374078, 0.9221182398943879, 0.9147515282486625, 0.9105545307665756, 0.9355189625637637, 0.9269366180316886, 0.9153084915546386, 0.9176911155805598, 0.6692914626878597, 0.4575308419565963, 0.6887630340920318, 0.4798217646075563, 0.5501023783378871, 0.5398208237488542, 0.5118795001959637, 0.6455685875859266, 0.6893528182518391, 0.10834593529560821, 0.09429356607578998, 0.09941711463998604, 0.1125847852227202, 0.09855659617612733, 0.10387560713818789, 0.09375429188012363, 0.08818321837710519, 0.10005447554693525, 0.0634541877364676, 0.08430988923365146, 0.08574873563629803, 0.05060153052657623, 0.06589030945367935, 0.06246379454471862, 0.07896297734227586, 0.06185742524249016, 0.08791308887883353, 0.9658868261676639, 0.9173905206833337, 0.8938245761865625, 0.2557947487343736, 0.8877148697415224, 0.9150773015930447, 0.9363138450028982, 0.3236491139254828, 0.6976577021025541, 0.13689847674187172, 0.14254422069239714, 0.10491735919785683, 0.13063760780776834, 0.1367631830329883, 0.12618752293582147, 0.17316574551629094, 0.19124286372607302, 0.15883225938403356, 0.8401038893700923, 0.7178590301365098, 0.6149200524362997, 0.8614296027105339, 0.7531920025955656, 0.9149875490878525, 0.8688867647417239, 0.7121340617646854, 0.8890433272554108, 0.1353444369171719, 0.31320803297920663, 0.13534271803394893, 0.3126921471922597, 0.13229883224676664, 0.5015951439881121, 0.13641623225345956, 0.6305944971274853, 0.4974691716144478, 0.34265085607528234, 0.5705658618349408, 0.47953311685602507, 0.6476931599340241, 0.6360947891774178, 0.6391670784419361, 0.6160660440457307, 0.43017028093729825, 0.12998884977097147, 0.5815780423030992, 0.6524770245749534, 0.19091061870196913, 0.6298997434617858, 0.39584347111864693, 0.398394173458842, 0.16797108905117386, 0.5987253925741429, 0.5477322763957087, 0.08996100243987426, 0.11768087075992606, 0.10638285475947029, 0.13041140027004416, 0.0867032377131638, 0.11932527804374882, 0.15964375374048323, 0.09426478835663599, 0.10003344913986989, 0.1340229102413909, 0.18698862028867347, 0.2871447517238115, 0.37403440225300044, 0.24851289067427484, 0.5351755430124128, 0.5155631094084977, 0.24420302375637915, 0.1828986583231329, 0.4604519425475374, 0.5182520681032516, 0.28786352836122364, 0.41870612681574604, 0.490170655134901, 0.34950057205632634, 0.44927745847508493, 0.4723977058166122, 0.2355162142935836, 0.7650351004589996, 0.7231372440173816, 0.8156720817772092, 0.7740256953238753, 0.7564038151928401, 0.7508236874125506, 0.8156202895948689, 0.7762177611573251, 0.8058142631355762, 0.11729448543592169, 0.09468431546110401, 0.11658279861705445, 0.1139671960439751, 0.08537219388864925, 0.08937479415903615, 0.09948654611507068, 0.0849771060790705, 0.0939280610497859, 0.1232773606339419, 0.12935134421649397, 0.15714964118860442, 0.1547381797163232, 0.1571992916165562, 0.13926980082876106, 0.13596729323914136, 0.1425205880642637, 0.1354702509858725, 0.38719717322371205, 0.34545879149220504, 0.29452496537967543, 0.3913483841645873, 0.3230245355021061, 0.49303421332100994, 0.4335373026187711, 0.3753085288764515, 0.3378108529150795, 0.2822632151776875, 0.3163234387010876, 0.3067931090350904, 0.36476920944841773, 0.34245219523617176, 0.3421919438681833, 0.28427870357977003, 0.31169019052767477, 0.31188747477767287, 0.17839751254786607, 0.17760296395394726, 0.1862240246241701, 0.1999541484386539, 0.183598008109503, 0.18964861344022965, 0.1917017051274852, 0.20972648939307292, 0.17823452031243525, 0.17317062412245665, 0.18113189280229558, 0.18443477879908854, 0.1743951669057746, 0.18935338324188444, 0.19541955933624044, 0.20264772992130642, 0.17759165907934038, 0.17957645681163525, 0.18928310846269747, 0.17940339059003274, 0.1779730108697355, 0.936920957942343, 0.1975495342829069, 0.06203102619127965, 0.1718769965047493, 0.11539073707148095, 0.16296359359505985, 0.2203350319117393, 0.11344148312738067, 0.08301712044550169, 0.16845848093809968, 0.16480695780372667, 0.21242247572021655, 0.20464976146134495, 0.16795774620460446, 0.20807095824535515, 0.18191097285157742, 0.18668632633647175, 0.17499065275141545, 0.18759793218819765, 0.18653899678556685, 0.18590092462100127, 0.1819095635905914, 0.1771223383293341, 0.18357286475397705, 0.07434149535545143, 0.07754823265975341, 0.08016563124132114, 0.08030792729794067, 0.07907192477394942, 0.07809241704104575, 0.07663597785304777, 0.07361481031796469, 0.07642197768311365]}, "mutation_prompt": null}
{"id": "3082a132-2c54-4bac-b055-53080bb0f409", "solution": "import numpy as np\n\nclass AdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Dynamic recombination with probability\n                if np.random.rand() < 0.25:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.5 * (samples[i] + samples[crossover_idx])\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "AdaptiveCMAESOptimizer", "description": "Adaptive CMA-ES with enhanced diversity through stochastic recombination and step size adaptation for improved exploration-exploitation balance.", "configspace": "", "generation": 79, "fitness": 0.3463833598559589, "feedback": "The algorithm AdaptiveCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.27.", "error": "", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {"aucs": [0.9023680266036419, 0.9081023544281063, 0.9281146974576004, 0.930892291885995, 0.9219787824141944, 0.921662910916557, 0.9253496587408858, 0.9198976701332013, 0.8847700681413939, 0.6537384997193425, 0.6160233287733642, 0.6563208825227356, 0.6163645354010334, 0.5768076919963834, 0.6381877627976046, 0.644490588013349, 0.5723090794014429, 0.45378070407697757, 0.08901225759668219, 0.08069933266641716, 0.0961342739978509, 0.099610970046912, 0.09499813978399019, 0.0886141914423455, 0.09451995461399343, 0.10446707574883207, 0.15500087634258986, 0.07798333773041666, 0.06658768529066161, 0.07179466685719293, 0.07145984692128038, 0.0851935053973022, 0.07802987436392017, 0.07222210166057508, 0.08258468312889511, 0.07427182600206739, 0.6091481360187416, 0.9819545449057234, 0.9759395480499687, 0.164332031884469, 0.9233971247708334, 0.3349708133828754, 0.9831550828331599, 0.7204988622159381, 0.7945783918736788, 0.12131148762740662, 0.11385627259380837, 0.1569470808834601, 0.10782219947965443, 0.12120919432047816, 0.14355034381092524, 0.11822544820012792, 0.16769198135787444, 0.17681514906892148, 0.4974155913939722, 0.6849128440711825, 0.7842133683239996, 0.672012207194317, 0.8480711271649748, 0.6796432405036426, 0.8954085979215428, 0.8326094600710127, 0.6515106088993727, 0.5269321278983987, 0.5947373568933536, 0.5526691326065478, 0.43522980904509134, 0.5348548697379482, 0.6398425297369021, 0.558463546066519, 0.48939640873544454, 0.6437009647178075, 0.6162203176217613, 0.21540826118668244, 0.6499992954286005, 0.5920147180523607, 0.13367462986243395, 0.5810318345249562, 0.35072235832687515, 0.36817035973293344, 0.5277854784111609, 0.014822481291476786, 0.5285000690540047, 0.04132173516397286, 0.6512040325663568, 0.34734137864289527, 0.3498285984480014, 0.6507698260475001, 0.5354703005594958, 0.5076797772836159, 0.12000997613822295, 0.12175453972737671, 0.13846230608738952, 0.06853185946056961, 0.09639694698524526, 0.08172739214702673, 0.15114811768212144, 0.1110753656541974, 0.0925426499046369, 0.19163678705971732, 0.11341340633531449, 0.1046397698255731, 0.5334657675938494, 0.5497659172580223, 0.2045808383492046, 0.34947965189042596, 0.17873208853523614, 0.3915250587230973, 0.34666025533866374, 0.4676478354235024, 0.4589802477528143, 0.4866993458579195, 0.5312657043113183, 0.4928459309786626, 0.5445365508809483, 0.3960437700285889, 0.4131884130947828, 0.6643903562737061, 0.7861418067115693, 0.8084228474496885, 0.7793230934920117, 0.7966479203522617, 0.7863881139257743, 0.7715900806405529, 0.778539823974718, 0.8281816734807076, 0.0918996711011103, 0.09877196676920119, 0.08874303604861711, 0.09161436042296323, 0.08136139684257193, 0.08640539215225784, 0.0881334940861841, 0.10268818382127243, 0.0981351971408625, 0.13506434713536697, 0.1515448729815897, 0.24684634107717307, 0.14311114262614466, 0.14125619370056575, 0.3635093698779386, 0.1385257128578372, 0.14240206290355817, 0.1355352781089858, 0.36917900558592887, 0.41295726937187005, 0.3154188696319773, 0.36578107747030497, 0.31601428877521653, 0.2821232434363976, 0.3462112977338552, 0.4449176873076617, 0.31795753817837236, 0.25890957784394253, 0.2658308799915914, 0.2675456226024867, 0.2670050054573174, 0.27254527128016803, 0.28696162055961827, 0.23859561382946182, 0.20508754761596282, 0.21693712871027504, 0.22393141643099757, 0.2093896129171794, 0.19534720459646693, 0.1875031115669622, 0.19655151895434841, 0.1995010071891854, 0.24652639534315646, 0.19566618428180993, 0.20086272543637773, 0.17996985626028472, 0.1733059921179596, 0.18544071905885617, 0.18091556901734662, 0.19601546264621506, 0.18429188106073924, 0.1802237873167809, 0.17749067261337803, 0.1814150932219487, 0.16790370323636672, 0.13700333746676874, 0.18798251344252626, 0.25465882516861915, 0.11251569061669475, 0.06195736121941131, 0.10844492011293916, 0.11539635329329212, 0.1679757307819293, 0.9092061871259115, 0.11330628995217107, 0.07470532371094218, 0.1689555118903996, 0.2105062448836338, 0.10964117318970734, 0.15266116496777926, 0.16111052747759347, 0.8842952216887596, 0.19787910695861288, 0.1755555489653421, 0.17898912356561414, 0.18551946106308925, 0.178132609872514, 0.200623280797112, 0.19777465898479918, 0.18571648012704656, 0.1890567748439579, 0.07447559490759104, 0.1103887086576113, 0.0775128836441108, 0.06805950066870903, 0.10216033936920044, 0.0818471689160466, 0.08823977908982705, 0.07695783038107873, 0.09209674397649559]}, "mutation_prompt": null}
{"id": "0321e87c-f300-4019-8f07-03c74600a785", "solution": "import numpy as np\n\nclass EnhancedAdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Stochastic adaptive crossover\n                if np.random.rand() < 0.25:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = np.random.rand() * samples[i] + (1 - np.random.rand()) * samples[crossover_idx]\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            # More robust step-size adaptation\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.random.uniform(0.5, 1.5) * np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "EnhancedAdaptiveCMAESOptimizer", "description": "Enhanced Adaptive Covariance Matrix Evolution Strategy with stochastic adaptive step-size and crossover for improved exploration and convergence.", "configspace": "", "generation": 80, "fitness": 0.11874153585420667, "feedback": "The algorithm EnhancedAdaptiveCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.19.", "error": "", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {"aucs": [0.15235333010624108, 0.15193316338506702, 0.17550651906853032, 0.12093109718497197, 0.1349632506784898, 0.1362355516635726, 0.11960506829226292, 0.15335329378133078, 0.13636837458080064, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03510294514300971, 0.030798855621571808, 0.043274340321908134, 0.04938335471647037, 0.026799170282472362, 0.02725824087937634, 0.019432161365219636, 0.021141999952575263, 0.020228035701744917, 0.03117993643712691, 0.024324558860448264, 0.043149358599837484, 0.02074027631205788, 0.013663205275761703, 0.02518066065190505, 0.012032486293250266, 0.018349177638837144, 0.010483197288780666, 0.9967554333381446, 0.9953362127932129, 0.9913857996173709, 0.9948748226975701, 0.9930033956791702, 0.9926022349577996, 0.9965973039416068, 0.9947838401683715, 0.9904412819015959, 0.059441284054224885, 0.04404224976978599, 0.05864538745110881, 0.058088758109654415, 0.04333621701808821, 0.024785511213283873, 0.021274838502586157, 0.03198201943792278, 0.013090160674557927, 0.121086454058981, 0.12969899848533495, 0.12310094240122127, 0.07186524592072197, 0.08477837292402024, 0.07269134163491531, 0.06857437144554657, 0.0755699012660569, 0.08138776859324515, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09698558872210472, 0.07792255948406601, 0.06409922449894878, 0.07000662561702653, 0.06842866153441685, 0.06697844971618538, 0.06573462134746555, 0.05453798527009879, 0.052304230740197855, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.025479239788448238, 0.004901053685900658, 0.026849276170638592, 0.04818254074308992, 0.01192559317620523, 0.04933707461695014, 0.0827638820892096, 0.039685552222553766, 0.026348394526947594, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.18072815631200356, 0.17146825401031152, 0.18199248427368786, 0.17301156380190752, 0.14216661876547498, 0.154072542000403, 0.19260120982360662, 0.2151489236530264, 0.19072476416948325, 0.03437840322940555, 0.048598710416051794, 0.03764154306043965, 0.023568898370935676, 0.031712188520499174, 0.031432497053295094, 0.030172081338354806, 0.02864844261656596, 0.023387930644694466, 0.1516528729472828, 0.13460681528514373, 0.1258644009463875, 0.13554532004972408, 0.1549718656934761, 0.12973406474951865, 0.12558519093991927, 0.1404845141908938, 0.13287072064804706, 0.13947453194609394, 0.13325785636914278, 0.16811465732822584, 0.17501754548045323, 0.14954614840404734, 0.15958612566614738, 0.14473678489858754, 0.14231294915868142, 0.13867099652394832, 0.09132262220255127, 0.09733456508994642, 0.09056020396744047, 0.12608920137573076, 0.10856586169927873, 0.10986529570272652, 0.09105435914247029, 0.09182655332148137, 0.1033057817893498, 0.17339999911135473, 0.1981251659587242, 0.1599153475308267, 0.16369518798702298, 0.16268147648070685, 0.1684147763603916, 0.20050526302311578, 0.1589839301722935, 0.1584320702425157, 0.16348555850396984, 0.15317203580018923, 0.1460392692168616, 0.14976864706019277, 0.1546835632677548, 0.14690857097014798, 0.14161297029429187, 0.13866868520222364, 0.15228380987114487, 0.13465032905238805, 0.1305792260386739, 0.13651540428995046, 0.12478280285599996, 0.12221591558462275, 0.1291537188397035, 0.11574631630965126, 0.16402204544999244, 0.16866102168730324, 0.1078540987268245, 0.19440809522579117, 0.11445155544829855, 0.11380824656684618, 0.1936070716852586, 0.13392815151883752, 0.13714893940579675, 0.1723375139736285, 0.12766276564324597, 0.18729777427598215, 0.17235536288496567, 0.16386367885191544, 0.17732691522280253, 0.17506024864738434, 0.17169375468474568, 0.1841716005236389, 0.18154915870190025, 0.17571348672926745, 0.049284849547947984, 0.04331870056192222, 0.04281014192296151, 0.0553519870312712, 0.04228235888092202, 0.04986451759990573, 0.05283242232534535, 0.06790462758055782, 0.03980528351164758]}, "mutation_prompt": null}
{"id": "fa9978d5-cbee-4da0-add0-4c391e970926", "solution": "import numpy as np\n\nclass EnhancedAdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Enhanced dynamic recombination for diverse exploration\n                if np.random.rand() < 0.3:  # Increased probability for more diversity\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.7 * samples[i] + 0.3 * samples[crossover_idx]  # Adjusted mixing ratio\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n            # Adaptive adjustment of the step size for robustness\n            if self.eval_count % self.population_size == 0 and self.eval_count > 0:\n                f_best = self.fitness[indices[0]]\n                if f_best < 1e-10:  # Arbitrary convergence threshold\n                    self.adaptive_step_size *= 0.9  # Reduce step size for fine-tuning\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "EnhancedAdaptiveCMAESOptimizer", "description": "Enhanced Adaptive CMA-ES using self-adaptive step size control and dynamic diversity injection for robust optimization across diverse landscapes.", "configspace": "", "generation": 81, "fitness": 0.32368397084380923, "feedback": "The algorithm EnhancedAdaptiveCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.27.", "error": "", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {"aucs": [0.9123831318032034, 0.9330903187151203, 0.9197725684876568, 0.9253172660119761, 0.9156416203249599, 0.9107339861717949, 0.9644949914156935, 0.9579689388961741, 0.9686726511865736, 0.6280431808001565, 0.48262981249109227, 0.29703650843399365, 0.18070533272844735, 0.2503870060778446, 0.17142134970072054, 0.07962901509624332, 0.32506149907084825, 0.18898619149025475, 0.09455898069306734, 0.11866227803414009, 0.1258209390562619, 0.10026193939570693, 0.08564615804392017, 0.08270733914413264, 0.09054914180232587, 0.09157547344855865, 0.10324515798087264, 0.12035966411170251, 0.08807434682007698, 0.019805459942353942, 0.07846540045348971, 0.07114974968974841, 0.07352367607609556, 0.06561573939385035, 0.07350519982749903, 0.07796676613605524, 0.9744073686296338, 0.7416750899466811, 0.7217500427026443, 0.97277400900313, 0.2265444434184789, 0.7236652199268152, 0.9895084209941213, 0.8144176168595265, 0.2421700796015448, 0.1264633861932689, 0.1215891823510643, 0.10680081025615695, 0.1538368474287447, 0.09421550131241607, 0.12422662751270597, 0.7503727957765989, 0.6925164620326993, 0.772654124955418, 0.6861369293938953, 0.5963876621310558, 0.6978164941664297, 0.9169198994470003, 0.5699772900916457, 0.8514310908992417, 0.6716748021136414, 0.6917401783923741, 0.6647546401996569, 0.46553839060364743, 0.38062577790407615, 0.34455058929513105, 0.1582481846651843, 0.3651483489257453, 0.320201747157564, 0.49960743382584627, 0.45258311975985854, 0.5572433833733427, 0.45589521273271527, 0.5229233109137302, 0.31638118644902047, 0.633964825541062, 0.27030602485126687, 0.4512699205192169, 0.4525128585038446, 0.5797708073517019, 0.4537675540483562, 0.23912743138327375, 0.2302239970229636, 0.04489446130321195, 0.04595200726587323, 0.4580008848929299, 0.3304730508974951, 0.4576005506526911, 0.4548335736838076, 0.13025633796478342, 0.10764320704877284, 0.11580016905836232, 0.1020676208642659, 0.08629388728530507, 0.09668168763308349, 0.10195791877832094, 0.12823655045579396, 0.11805422471847637, 0.08644201948771202, 0.16727946955487327, 0.05128050729893696, 0.363195655560138, 0.1920397771591137, 0.13613732988170413, 0.21588211803898028, 0.18352115957364468, 0.17068831645365956, 0.41091041062529865, 0.5476358554728042, 0.5597975014611248, 0.4781820209606318, 0.31740512504662843, 0.16548831597436442, 0.20508284665394094, 0.14295206634655655, 0.2551333772671168, 0.14633764564562024, 0.8067435542390302, 0.6912418877538296, 0.846588255043446, 0.8040151731699348, 0.752263490800526, 0.6893364327698994, 0.8183228962180964, 0.7289411077841625, 0.7658647116317086, 0.0996718043387822, 0.10698248016132206, 0.11979626475859151, 0.07763835137619413, 0.09017693435959495, 0.10107719446000774, 0.11762991473608286, 0.11215946247302888, 0.13626992634522161, 0.136433632525513, 0.1404889375819932, 0.8173080513980314, 0.2512442074370457, 0.27497708279584, 0.1964533782735578, 0.11632476930474545, 0.1268531814534103, 0.14021599789367933, 0.22860718564431504, 0.311225459657261, 0.1444076481867631, 0.4515734357008253, 0.3136978272456137, 0.3573892708947115, 0.3947199919882102, 0.3376484942203051, 0.4405197453600904, 0.2613974921840062, 0.25648449143799457, 0.27364024203515314, 0.29119285393334504, 0.2231599869470703, 0.23988375899353642, 0.3352840789971888, 0.3612031822654064, 0.23257242317176108, 0.20023329743286633, 0.19341251370512924, 0.16264016256863978, 0.19872754624485323, 0.19396390908891947, 0.19818013439218995, 0.18746423843196047, 0.18785771986653765, 0.1986920489445374, 0.1871436460424346, 0.17883688546660903, 0.16930444544927248, 0.17540419158873244, 0.1751415541379876, 0.1743658613946527, 0.17578345311742083, 0.1789743566776527, 0.1847191989643926, 0.18974624810266483, 0.13737035339504455, 0.18768419762866517, 0.9122749128314752, 0.11245672279017493, 0.06196082564533567, 0.10875668217879486, 0.11537401179996176, 0.16668941320409414, 0.9405156032422889, 0.11328251934293876, 0.08292215617077636, 0.1696509876617518, 0.20389048434881196, 0.09146492157417108, 0.11276298006821084, 0.16816340891003634, 0.5642847383808015, 0.1833975505694998, 0.19750473003345181, 0.21440445557480436, 0.17794605878840464, 0.19502759531485114, 0.1807180557954089, 0.27159726743447965, 0.19897452490834489, 0.327001640584736, 0.09100924677659883, 0.0670039655509016, 0.0724239558999441, 0.08762750488180715, 0.07426628727556528, 0.0756189526855282, 0.07867478039648867, 0.07769463688116152, 0.07119996169042464]}, "mutation_prompt": null}
{"id": "a0971ef5-63bb-42ba-ace9-cbac0f40455d", "solution": "import numpy as np\n\nclass AdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Dynamic recombination for enhanced diversity\n                if np.random.rand() < 0.25:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.5 * (samples[i] + samples[crossover_idx])\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "AdaptiveCMAESOptimizer", "description": "Adaptive Covariance Matrix Evolution Strategy with dynamic recombination and mutation for enhanced convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {"aucs": [0.9023680266036419, 0.9081023544281063, 0.9281146974576004, 0.930892291885995, 0.9219787824141944, 0.921662910916557, 0.9253496587408858, 0.9198976701332013, 0.8847700681413939, 0.6537384997193425, 0.6160233287733642, 0.6563208825227356, 0.6163645354010334, 0.5768076919963834, 0.6381877627976046, 0.644490588013349, 0.5723090794014429, 0.45378070407697757, 0.08901225759668219, 0.08069933266641716, 0.0961342739978509, 0.099610970046912, 0.09499813978399019, 0.0886141914423455, 0.09451995461399343, 0.10446707574883207, 0.15500087634258986, 0.07798333773041666, 0.06658768529066161, 0.07179466685719293, 0.07145984692128038, 0.0851935053973022, 0.07802987436392017, 0.07222210166057508, 0.08258468312889511, 0.07427182600206739, 0.6091481360187416, 0.9819545449057234, 0.9759395480499687, 0.164332031884469, 0.9233971247708334, 0.3349708133828754, 0.9831550828331599, 0.7204988622159381, 0.7945783918736788, 0.12131148762740662, 0.11385627259380837, 0.1569470808834601, 0.10782219947965443, 0.12120919432047816, 0.14355034381092524, 0.11822544820012792, 0.16769198135787444, 0.17681514906892148, 0.4974155913939722, 0.6849128440711825, 0.7842133683239996, 0.672012207194317, 0.8480711271649748, 0.6796432405036426, 0.8954085979215428, 0.8326094600710127, 0.6515106088993727, 0.5269321278983987, 0.5947373568933536, 0.5526691326065478, 0.43522980904509134, 0.5348548697379482, 0.6398425297369021, 0.558463546066519, 0.48939640873544454, 0.6437009647178075, 0.6162203176217613, 0.21540826118668244, 0.6499992954286005, 0.5920147180523607, 0.13367462986243395, 0.5810318345249562, 0.35072235832687515, 0.36817035973293344, 0.5277854784111609, 0.014822481291476786, 0.5285000690540047, 0.04132173516397286, 0.6512040325663568, 0.34734137864289527, 0.3498285984480014, 0.6507698260475001, 0.5354703005594958, 0.5076797772836159, 0.12000997613822295, 0.12175453972737671, 0.13846230608738952, 0.06853185946056961, 0.09639694698524526, 0.08172739214702673, 0.15114811768212144, 0.1110753656541974, 0.0925426499046369, 0.19163678705971732, 0.11341340633531449, 0.1046397698255731, 0.5334657675938494, 0.5497659172580223, 0.2045808383492046, 0.34947965189042596, 0.17873208853523614, 0.3915250587230973, 0.34666025533866374, 0.4676478354235024, 0.4589802477528143, 0.4866993458579195, 0.5312657043113183, 0.4928459309786626, 0.5445365508809483, 0.3960437700285889, 0.4131884130947828, 0.6643903562737061, 0.7861418067115693, 0.8084228474496885, 0.7793230934920117, 0.7966479203522617, 0.7863881139257743, 0.7715900806405529, 0.778539823974718, 0.8281816734807076, 0.0918996711011103, 0.09877196676920119, 0.08874303604861711, 0.09161436042296323, 0.08136139684257193, 0.08640539215225784, 0.0881334940861841, 0.10268818382127243, 0.0981351971408625, 0.13506434713536697, 0.1515448729815897, 0.24684634107717307, 0.14311114262614466, 0.14125619370056575, 0.3635093698779386, 0.1385257128578372, 0.14240206290355817, 0.1355352781089858, 0.36917900558592887, 0.41295726937187005, 0.3154188696319773, 0.36578107747030497, 0.31601428877521653, 0.2821232434363976, 0.3462112977338552, 0.4449176873076617, 0.31795753817837236, 0.25890957784394253, 0.2658308799915914, 0.2675456226024867, 0.2670050054573174, 0.27254527128016803, 0.28696162055961827, 0.23859561382946182, 0.20508754761596282, 0.21693712871027504, 0.22393141643099757, 0.2093896129171794, 0.19534720459646693, 0.1875031115669622, 0.19655151895434841, 0.1995010071891854, 0.24652639534315646, 0.19566618428180993, 0.20086272543637773, 0.17996985626028472, 0.1733059921179596, 0.18544071905885617, 0.18091556901734662, 0.19601546264621506, 0.18429188106073924, 0.1802237873167809, 0.17749067261337803, 0.1814150932219487, 0.16790370323636672, 0.13700333746676874, 0.18798251344252626, 0.25465882516861915, 0.11251569061669475, 0.06195736121941131, 0.10844492011293916, 0.11539635329329212, 0.1679757307819293, 0.9092061871259115, 0.11330628995217107, 0.07470532371094218, 0.1689555118903996, 0.2105062448836338, 0.10964117318970734, 0.15266116496777926, 0.16111052747759347, 0.8842952216887596, 0.19787910695861288, 0.1755555489653421, 0.17898912356561414, 0.18551946106308925, 0.178132609872514, 0.200623280797112, 0.19777465898479918, 0.18571648012704656, 0.1890567748439579, 0.07447559490759104, 0.1103887086576113, 0.0775128836441108, 0.06805950066870903, 0.10216033936920044, 0.0818471689160466, 0.08823977908982705, 0.07695783038107873, 0.09209674397649559]}, "mutation_prompt": null}
{"id": "8653b833-06ee-4075-b0b2-337dda96a4ca", "solution": "import numpy as np\n\nclass HybridADE_CMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n        f_weight = 0.8\n        crossover_rate = 0.9\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                if np.random.rand() < 0.25:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = samples[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + f_weight * (b - c), self.lower_bound, self.upper_bound)\n                    cross_points = np.random.rand(self.dim) < crossover_rate\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    samples[i] = np.where(cross_points, mutant, samples[i])\n\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "HybridADE_CMAESOptimizer", "description": "Hybrid Adaptive Differential Evolution integrated with CMA-ES for robust exploration and exploitation.", "configspace": "", "generation": 83, "fitness": 0.15059878988002962, "feedback": "The algorithm HybridADE_CMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.17.", "error": "", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {"aucs": [0.2842665432102386, 0.25386167121957115, 0.2852363004596209, 0.3389283819211588, 0.3160893326966244, 0.49375552356595886, 0.36754195227243813, 0.2621998445750523, 0.3458262076130745, 9.999999999998899e-05, 0.01692324800830125, 9.999999999998899e-05, 0.036078916267039185, 9.999999999998899e-05, 0.0009358419281714214, 0.03554520735411937, 9.999999999998899e-05, 9.999999999998899e-05, 0.06158003094035047, 0.06539594425028206, 0.056422409690896846, 0.0784996601361434, 0.06662109699623064, 0.06563518876553875, 0.07957664212172788, 0.07758222510703894, 0.10395345329109973, 0.04891073401849211, 0.02357527695066508, 0.03522495525053981, 0.04272171859190077, 0.031244331834282657, 0.06110299392354157, 0.037824880479275125, 0.03310295425823784, 0.029408442921200595, 0.7010861791530443, 0.6610345606350123, 0.9713471441568414, 0.9562310109432282, 0.8422786329159997, 0.9538384333192246, 0.9547139320347463, 0.848118637882772, 0.9137010058674616, 0.10548470440826274, 0.08627142972957647, 0.08003679362459315, 0.07785888303553634, 0.06667208881661313, 0.0663502101748561, 0.11800893409480073, 0.09159448807658477, 0.11853288597758216, 0.19344389230856374, 0.1940409631226736, 0.1838623913042431, 0.195657882726736, 0.20778640083229094, 0.1927972307466984, 0.1900134957009335, 0.1778362772270191, 0.20350950455899897, 0.015876807273717763, 0.021750202569147392, 0.06873926582407408, 0.052543808819517146, 0.051772520767777275, 0.10397205318624181, 0.06752063758143301, 0.06409778761847429, 0.06548167939219929, 0.06421507282542693, 0.09595428113440119, 0.06211836199129339, 0.056094992564884705, 0.05195986864082969, 0.1122783702116027, 0.03379639452242267, 0.06874652610883092, 0.0706179575041167, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08139139642830373, 0.06897067800213386, 0.07323584278293727, 0.09474238935639967, 0.03454243506349519, 0.09530509034692491, 0.06305955332265534, 0.10608674860641365, 0.07414980837815999, 9.999999999998899e-05, 9.999999999998899e-05, 0.006360920069547471, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.025314779231864093, 0.03222418355714085, 0.07855261407103009, 0.06096684515751638, 0.06476339579287782, 0.0330682500495999, 0.06439899795941151, 0.03333095460286861, 0.04880896691972991, 0.3222112714926316, 0.28672286397404234, 0.2829643190061779, 0.25275570279086135, 0.2332841243967333, 0.33840577998528565, 0.2864960223830858, 0.2794286267944526, 0.26348585940310143, 0.06978442626772885, 0.06741083753008292, 0.08525363783618156, 0.07235490455141758, 0.06416981505714703, 0.11119445433584751, 0.06065551864455243, 0.06423198630593074, 0.07464038828382213, 0.14253751189337616, 0.15531571145320855, 0.1503993931735642, 0.13994367419101494, 0.13850978367746125, 0.15530638185322054, 0.17749975444342725, 0.14819182898837768, 0.12311990313013121, 0.1914245689140599, 0.17521534336538624, 0.1784055481274276, 0.17922780019998097, 0.17784685185676297, 0.1815106280785872, 0.18061048775264155, 0.22562388200907968, 0.1754535747134267, 0.12738203720882046, 0.12714365689186924, 0.11573327906348119, 0.1230897857824419, 0.12527833929933518, 0.12123535111685846, 0.1401640599564664, 0.1293716388555185, 0.11973836741066257, 0.17904910797312057, 0.21537833411375784, 0.19046116015743098, 0.1901318867388082, 0.19012353008480876, 0.17207249145167802, 0.1962736129731385, 0.19858754041477356, 0.17373136558954871, 0.1641706124274659, 0.16752912399479214, 0.16395029929862226, 0.16805168868985765, 0.1600161157118578, 0.1762921234327347, 0.16109464843813914, 0.16160324076107735, 0.16331754730182857, 0.16730555349762466, 0.16482733322923815, 0.1604816012205792, 0.21361596441656572, 0.16242047905432777, 0.16892716817257059, 0.1733539235104199, 0.15916504799007603, 0.15827100730299026, 0.15164445657299985, 0.1629041609610704, 0.16882827585159543, 0.13393517288549373, 0.17363501525214797, 0.14653337999350968, 0.20413378402265459, 0.19702688880234165, 0.20666410926373247, 0.19691153790620908, 0.19083018492630544, 0.17684997625538212, 0.17829140899056184, 0.18544693004266077, 0.18057432021297992, 0.18826630404461375, 0.19627875094370661, 0.18594875816242495, 0.054268002210835276, 0.06728775826512468, 0.08061525033345918, 0.06654415264680824, 0.05866118800658182, 0.06725700432448722, 0.06398189135431509, 0.06344745246149341, 0.06494996677028853]}, "mutation_prompt": null}
{"id": "da2c741d-715d-4124-89cc-5881850771b7", "solution": "import numpy as np\n\nclass EnhancedAdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                if np.random.rand() < 0.25:\n                    crossover_indices = np.random.choice(self.population_size, 2, replace=False)\n                    samples[i] = 0.5 * (samples[i] + samples[crossover_indices[0]])\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "EnhancedAdaptiveCMAESOptimizer", "description": "Enhanced Adaptive CMA-ES with optimized step-size control and adaptive population scaling for improved convergence efficiency.", "configspace": "", "generation": 84, "fitness": -Infinity, "feedback": "An exception occurred: LinAlgError('Matrix is not positive definite').", "error": "LinAlgError('Matrix is not positive definite')", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {}, "mutation_prompt": null}
{"id": "56232b13-36d3-4bd6-a6a1-368c778acc49", "solution": "import numpy as np\n\nclass AdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Dynamic recombination for enhanced diversity\n                if np.random.rand() < 0.25:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.5 * (samples[i] + samples[crossover_idx])\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "AdaptiveCMAESOptimizer", "description": "Adaptive Covariance Matrix Evolution Strategy with dynamic recombination and mutation for enhanced convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {"aucs": [0.9023680266036419, 0.9081023544281063, 0.9281146974576004, 0.930892291885995, 0.9219787824141944, 0.921662910916557, 0.9253496587408858, 0.9198976701332013, 0.8847700681413939, 0.6537384997193425, 0.6160233287733642, 0.6563208825227356, 0.6163645354010334, 0.5768076919963834, 0.6381877627976046, 0.644490588013349, 0.5723090794014429, 0.45378070407697757, 0.08901225759668219, 0.08069933266641716, 0.0961342739978509, 0.099610970046912, 0.09499813978399019, 0.0886141914423455, 0.09451995461399343, 0.10446707574883207, 0.15500087634258986, 0.07798333773041666, 0.06658768529066161, 0.07179466685719293, 0.07145984692128038, 0.0851935053973022, 0.07802987436392017, 0.07222210166057508, 0.08258468312889511, 0.07427182600206739, 0.6091481360187416, 0.9819545449057234, 0.9759395480499687, 0.164332031884469, 0.9233971247708334, 0.3349708133828754, 0.9831550828331599, 0.7204988622159381, 0.7945783918736788, 0.12131148762740662, 0.11385627259380837, 0.1569470808834601, 0.10782219947965443, 0.12120919432047816, 0.14355034381092524, 0.11822544820012792, 0.16769198135787444, 0.17681514906892148, 0.4974155913939722, 0.6849128440711825, 0.7842133683239996, 0.672012207194317, 0.8480711271649748, 0.6796432405036426, 0.8954085979215428, 0.8326094600710127, 0.6515106088993727, 0.5269321278983987, 0.5947373568933536, 0.5526691326065478, 0.43522980904509134, 0.5348548697379482, 0.6398425297369021, 0.558463546066519, 0.48939640873544454, 0.6437009647178075, 0.6162203176217613, 0.21540826118668244, 0.6499992954286005, 0.5920147180523607, 0.13367462986243395, 0.5810318345249562, 0.35072235832687515, 0.36817035973293344, 0.5277854784111609, 0.014822481291476786, 0.5285000690540047, 0.04132173516397286, 0.6512040325663568, 0.34734137864289527, 0.3498285984480014, 0.6507698260475001, 0.5354703005594958, 0.5076797772836159, 0.12000997613822295, 0.12175453972737671, 0.13846230608738952, 0.06853185946056961, 0.09639694698524526, 0.08172739214702673, 0.15114811768212144, 0.1110753656541974, 0.0925426499046369, 0.19163678705971732, 0.11341340633531449, 0.1046397698255731, 0.5334657675938494, 0.5497659172580223, 0.2045808383492046, 0.34947965189042596, 0.17873208853523614, 0.3915250587230973, 0.34666025533866374, 0.4676478354235024, 0.4589802477528143, 0.4866993458579195, 0.5312657043113183, 0.4928459309786626, 0.5445365508809483, 0.3960437700285889, 0.4131884130947828, 0.6643903562737061, 0.7861418067115693, 0.8084228474496885, 0.7793230934920117, 0.7966479203522617, 0.7863881139257743, 0.7715900806405529, 0.778539823974718, 0.8281816734807076, 0.0918996711011103, 0.09877196676920119, 0.08874303604861711, 0.09161436042296323, 0.08136139684257193, 0.08640539215225784, 0.0881334940861841, 0.10268818382127243, 0.0981351971408625, 0.13506434713536697, 0.1515448729815897, 0.24684634107717307, 0.14311114262614466, 0.14125619370056575, 0.3635093698779386, 0.1385257128578372, 0.14240206290355817, 0.1355352781089858, 0.36917900558592887, 0.41295726937187005, 0.3154188696319773, 0.36578107747030497, 0.31601428877521653, 0.2821232434363976, 0.3462112977338552, 0.4449176873076617, 0.31795753817837236, 0.25890957784394253, 0.2658308799915914, 0.2675456226024867, 0.2670050054573174, 0.27254527128016803, 0.28696162055961827, 0.23859561382946182, 0.20508754761596282, 0.21693712871027504, 0.22393141643099757, 0.2093896129171794, 0.19534720459646693, 0.1875031115669622, 0.19655151895434841, 0.1995010071891854, 0.24652639534315646, 0.19566618428180993, 0.20086272543637773, 0.17996985626028472, 0.1733059921179596, 0.18544071905885617, 0.18091556901734662, 0.19601546264621506, 0.18429188106073924, 0.1802237873167809, 0.17749067261337803, 0.1814150932219487, 0.16790370323636672, 0.13700333746676874, 0.18798251344252626, 0.25465882516861915, 0.11251569061669475, 0.06195736121941131, 0.10844492011293916, 0.11539635329329212, 0.1679757307819293, 0.9092061871259115, 0.11330628995217107, 0.07470532371094218, 0.1689555118903996, 0.2105062448836338, 0.10964117318970734, 0.15266116496777926, 0.16111052747759347, 0.8842952216887596, 0.19787910695861288, 0.1755555489653421, 0.17898912356561414, 0.18551946106308925, 0.178132609872514, 0.200623280797112, 0.19777465898479918, 0.18571648012704656, 0.1890567748439579, 0.07447559490759104, 0.1103887086576113, 0.0775128836441108, 0.06805950066870903, 0.10216033936920044, 0.0818471689160466, 0.08823977908982705, 0.07695783038107873, 0.09209674397649559]}, "mutation_prompt": null}
{"id": "b7c88fa3-142d-4f64-84af-f88c688490fa", "solution": "import numpy as np\n\nclass AdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Dynamic recombination for enhanced diversity\n                if np.random.rand() < 0.25:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.5 * (samples[i] + samples[crossover_idx])\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "AdaptiveCMAESOptimizer", "description": "Adaptive Covariance Matrix Evolution Strategy with dynamic recombination and mutation for enhanced convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {"aucs": [0.9023680266036419, 0.9081023544281063, 0.9281146974576004, 0.930892291885995, 0.9219787824141944, 0.921662910916557, 0.9253496587408858, 0.9198976701332013, 0.8847700681413939, 0.6537384997193425, 0.6160233287733642, 0.6563208825227356, 0.6163645354010334, 0.5768076919963834, 0.6381877627976046, 0.644490588013349, 0.5723090794014429, 0.45378070407697757, 0.08901225759668219, 0.08069933266641716, 0.0961342739978509, 0.099610970046912, 0.09499813978399019, 0.0886141914423455, 0.09451995461399343, 0.10446707574883207, 0.15500087634258986, 0.07798333773041666, 0.06658768529066161, 0.07179466685719293, 0.07145984692128038, 0.0851935053973022, 0.07802987436392017, 0.07222210166057508, 0.08258468312889511, 0.07427182600206739, 0.6091481360187416, 0.9819545449057234, 0.9759395480499687, 0.164332031884469, 0.9233971247708334, 0.3349708133828754, 0.9831550828331599, 0.7204988622159381, 0.7945783918736788, 0.12131148762740662, 0.11385627259380837, 0.1569470808834601, 0.10782219947965443, 0.12120919432047816, 0.14355034381092524, 0.11822544820012792, 0.16769198135787444, 0.17681514906892148, 0.4974155913939722, 0.6849128440711825, 0.7842133683239996, 0.672012207194317, 0.8480711271649748, 0.6796432405036426, 0.8954085979215428, 0.8326094600710127, 0.6515106088993727, 0.5269321278983987, 0.5947373568933536, 0.5526691326065478, 0.43522980904509134, 0.5348548697379482, 0.6398425297369021, 0.558463546066519, 0.48939640873544454, 0.6437009647178075, 0.6162203176217613, 0.21540826118668244, 0.6499992954286005, 0.5920147180523607, 0.13367462986243395, 0.5810318345249562, 0.35072235832687515, 0.36817035973293344, 0.5277854784111609, 0.014822481291476786, 0.5285000690540047, 0.04132173516397286, 0.6512040325663568, 0.34734137864289527, 0.3498285984480014, 0.6507698260475001, 0.5354703005594958, 0.5076797772836159, 0.12000997613822295, 0.12175453972737671, 0.13846230608738952, 0.06853185946056961, 0.09639694698524526, 0.08172739214702673, 0.15114811768212144, 0.1110753656541974, 0.0925426499046369, 0.19163678705971732, 0.11341340633531449, 0.1046397698255731, 0.5334657675938494, 0.5497659172580223, 0.2045808383492046, 0.34947965189042596, 0.17873208853523614, 0.3915250587230973, 0.34666025533866374, 0.4676478354235024, 0.4589802477528143, 0.4866993458579195, 0.5312657043113183, 0.4928459309786626, 0.5445365508809483, 0.3960437700285889, 0.4131884130947828, 0.6643903562737061, 0.7861418067115693, 0.8084228474496885, 0.7793230934920117, 0.7966479203522617, 0.7863881139257743, 0.7715900806405529, 0.778539823974718, 0.8281816734807076, 0.0918996711011103, 0.09877196676920119, 0.08874303604861711, 0.09161436042296323, 0.08136139684257193, 0.08640539215225784, 0.0881334940861841, 0.10268818382127243, 0.0981351971408625, 0.13506434713536697, 0.1515448729815897, 0.24684634107717307, 0.14311114262614466, 0.14125619370056575, 0.3635093698779386, 0.1385257128578372, 0.14240206290355817, 0.1355352781089858, 0.36917900558592887, 0.41295726937187005, 0.3154188696319773, 0.36578107747030497, 0.31601428877521653, 0.2821232434363976, 0.3462112977338552, 0.4449176873076617, 0.31795753817837236, 0.25890957784394253, 0.2658308799915914, 0.2675456226024867, 0.2670050054573174, 0.27254527128016803, 0.28696162055961827, 0.23859561382946182, 0.20508754761596282, 0.21693712871027504, 0.22393141643099757, 0.2093896129171794, 0.19534720459646693, 0.1875031115669622, 0.19655151895434841, 0.1995010071891854, 0.24652639534315646, 0.19566618428180993, 0.20086272543637773, 0.17996985626028472, 0.1733059921179596, 0.18544071905885617, 0.18091556901734662, 0.19601546264621506, 0.18429188106073924, 0.1802237873167809, 0.17749067261337803, 0.1814150932219487, 0.16790370323636672, 0.13700333746676874, 0.18798251344252626, 0.25465882516861915, 0.11251569061669475, 0.06195736121941131, 0.10844492011293916, 0.11539635329329212, 0.1679757307819293, 0.9092061871259115, 0.11330628995217107, 0.07470532371094218, 0.1689555118903996, 0.2105062448836338, 0.10964117318970734, 0.15266116496777926, 0.16111052747759347, 0.8842952216887596, 0.19787910695861288, 0.1755555489653421, 0.17898912356561414, 0.18551946106308925, 0.178132609872514, 0.200623280797112, 0.19777465898479918, 0.18571648012704656, 0.1890567748439579, 0.07447559490759104, 0.1103887086576113, 0.0775128836441108, 0.06805950066870903, 0.10216033936920044, 0.0818471689160466, 0.08823977908982705, 0.07695783038107873, 0.09209674397649559]}, "mutation_prompt": null}
{"id": "06f1b42d-424d-4bb7-ace8-4c212f5e4cd9", "solution": "import numpy as np\n\nclass EnhancedAdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n        best_fitness = np.inf\n        best_sample = None\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Dynamic mutation and elitism\n                if np.random.rand() < 0.25:\n                    mutation_idx = np.random.randint(0, self.population_size)\n                    samples[i] = samples[i] + 0.1 * (samples[mutation_idx] - samples[i])\n                self.fitness[i] = func(samples[i])\n                if self.fitness[i] < best_fitness:\n                    best_fitness = self.fitness[i]\n                    best_sample = samples[i]\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return best_sample if best_sample is not None else samples[best_idx], self.fitness[best_idx]", "name": "EnhancedAdaptiveCMAESOptimizer", "description": "Enhanced Adaptive CMA-ES with dynamic mutation and elitism for robust search efficiency.", "configspace": "", "generation": 87, "fitness": 0.25538803447372554, "feedback": "The algorithm EnhancedAdaptiveCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.23.", "error": "", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {"aucs": [0.8553303276973607, 0.8405652672697217, 0.9258692090985393, 0.9157249126658028, 0.8682431364492648, 0.9283975469870379, 0.8526132112699476, 0.8943875011896625, 0.9093751286690112, 0.49652890851825304, 0.5091174861379542, 0.46642362363192647, 0.5709536265836404, 0.5118912441075654, 0.555553017401984, 0.4341263646078599, 0.522854748706538, 0.5720911157041242, 0.09563865998512155, 0.09330386948995673, 0.07648034041877927, 0.08816182872408096, 0.09333260601051274, 0.082690352160673, 0.10130900898404072, 0.08235011081747112, 0.0854438021653694, 0.06947038364093261, 0.04018698185955605, 0.0612070805805941, 0.05079639813072112, 0.05040475011692758, 0.041557713220296, 0.06545619057703167, 0.046839655589034024, 0.05713410522041107, 0.9889176910649926, 0.3991496840913864, 0.4397941376023319, 0.7776599693815799, 0.9265722762659717, 0.9495082925726563, 0.2307531644817905, 0.9559290886124233, 0.39604864878230506, 0.09345896018599398, 0.1137329157644772, 0.08447215533130348, 0.07812323757242379, 0.15398703847507, 0.1099414220577577, 0.10802501125039965, 0.1247301502181104, 0.12009002990381157, 0.257050387899148, 0.541450287343779, 0.28984423115940783, 0.2970337747160312, 0.7449679806902865, 0.25426499038170336, 0.7112814329462889, 0.8069786246165174, 0.2542132656918703, 0.12426944780130122, 0.14917256813720636, 0.15588832240016215, 0.12282233146397759, 0.1351449449318376, 0.15394229149751648, 0.13871277175942065, 0.26016164212086246, 0.14047362620409676, 0.24302350148200014, 0.44418429184935504, 0.16038533149934975, 0.1466807874532602, 0.1741304959561969, 0.18903814894439097, 0.15153847425641487, 0.3337494183730536, 0.12020994829041887, 9.999999999998899e-05, 0.006958166969557311, 0.23053478379111403, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008476432761218566, 9.999999999998899e-05, 0.3518196637550528, 0.05096486815585921, 0.12288873438717962, 0.08231124955369595, 0.07828746560545263, 0.06658603498399496, 0.060197497133564704, 0.09392581700496305, 0.0766903847831436, 0.07946770059767527, 0.10614001380509219, 0.2707304724119769, 0.1898205192118546, 0.12104596530251743, 0.3163846152764379, 0.07822219951064358, 0.021302719601224984, 0.14358576743730211, 0.12350470783409329, 0.47047636884432964, 0.5313523456096065, 0.4892915017097461, 0.4148948419449402, 0.44356087202226313, 0.4210671681667474, 0.4869840568591052, 0.4398700852943761, 0.573908004849467, 0.49427377617710655, 0.6538369945134497, 0.5374049109141601, 0.5623850707881157, 0.6664291477311618, 0.7491099113914448, 0.6251174445015417, 0.4281916970286408, 0.5262601677793426, 0.0911148007912278, 0.09962881179185223, 0.07267058553167371, 0.07594750893185065, 0.0733326337349316, 0.09639395836803777, 0.08857396073602253, 0.07634692366811036, 0.08869136681567835, 0.14889736824748068, 0.12287745795915617, 0.1727537465268164, 0.1331320504419713, 0.1216982058666547, 0.13849231483224378, 0.12390960163354592, 0.14916311382842595, 0.13835434332492624, 0.22760770687343468, 0.2639378392637788, 0.24568073447338923, 0.22374841576572946, 0.25027849251280543, 0.2304077150625522, 0.3217524800788808, 0.26088437333820935, 0.2604442002287166, 0.1959363031304988, 0.17680739930231648, 0.19487558460730758, 0.16595468375922917, 0.1504419538133872, 0.18380217923010855, 0.15872211902437483, 0.16677994684001263, 0.16888622811618748, 0.192856394883953, 0.18359309003954494, 0.17337021001341368, 0.1985776554645824, 0.19679711593733573, 0.16313216483525994, 0.19582803261751036, 0.18646011154290854, 0.19021336101571718, 0.18938644025890772, 0.17074364369534867, 0.17520933671315708, 0.1764459718200171, 0.17345808809631003, 0.16953766023796002, 0.17749296315310326, 0.16763557852118938, 0.17325466573527615, 0.17110309851467354, 0.20010968372415927, 0.16988930129073343, 0.2953411666810102, 0.19571833285863016, 0.16429459957913384, 0.10860298170553595, 0.16579424550275546, 0.16681291427367284, 0.20730088922401968, 0.16626349149926523, 0.08306767052190245, 0.165078792629767, 0.08275940217847966, 0.21290686197354436, 0.19265307759833872, 0.2012454117267577, 0.10486123242704215, 0.18516339051611086, 0.19797893037619307, 0.17634910010524185, 0.18590713283744842, 0.18595004393538783, 0.17516271782483384, 0.18588593425300437, 0.17708397939113896, 0.18249791441336682, 0.08170756823250469, 0.08443017314073675, 0.07744671679563342, 0.07348370304708318, 0.07069899248861788, 0.07108830231897123, 0.07329078025205982, 0.08247467818798815, 0.07241508739845193]}, "mutation_prompt": null}
{"id": "27b220ea-a291-4aed-b170-0cd7db9a7845", "solution": "import numpy as np\n\nclass AdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Dynamic recombination for enhanced diversity\n                if np.random.rand() < 0.25:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.5 * (samples[i] + samples[crossover_idx])\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "AdaptiveCMAESOptimizer", "description": "Adaptive Covariance Matrix Evolution Strategy with dynamic recombination and mutation for enhanced convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {"aucs": [0.9023680266036419, 0.9081023544281063, 0.9281146974576004, 0.930892291885995, 0.9219787824141944, 0.921662910916557, 0.9253496587408858, 0.9198976701332013, 0.8847700681413939, 0.6537384997193425, 0.6160233287733642, 0.6563208825227356, 0.6163645354010334, 0.5768076919963834, 0.6381877627976046, 0.644490588013349, 0.5723090794014429, 0.45378070407697757, 0.08901225759668219, 0.08069933266641716, 0.0961342739978509, 0.099610970046912, 0.09499813978399019, 0.0886141914423455, 0.09451995461399343, 0.10446707574883207, 0.15500087634258986, 0.07798333773041666, 0.06658768529066161, 0.07179466685719293, 0.07145984692128038, 0.0851935053973022, 0.07802987436392017, 0.07222210166057508, 0.08258468312889511, 0.07427182600206739, 0.6091481360187416, 0.9819545449057234, 0.9759395480499687, 0.164332031884469, 0.9233971247708334, 0.3349708133828754, 0.9831550828331599, 0.7204988622159381, 0.7945783918736788, 0.12131148762740662, 0.11385627259380837, 0.1569470808834601, 0.10782219947965443, 0.12120919432047816, 0.14355034381092524, 0.11822544820012792, 0.16769198135787444, 0.17681514906892148, 0.4974155913939722, 0.6849128440711825, 0.7842133683239996, 0.672012207194317, 0.8480711271649748, 0.6796432405036426, 0.8954085979215428, 0.8326094600710127, 0.6515106088993727, 0.5269321278983987, 0.5947373568933536, 0.5526691326065478, 0.43522980904509134, 0.5348548697379482, 0.6398425297369021, 0.558463546066519, 0.48939640873544454, 0.6437009647178075, 0.6162203176217613, 0.21540826118668244, 0.6499992954286005, 0.5920147180523607, 0.13367462986243395, 0.5810318345249562, 0.35072235832687515, 0.36817035973293344, 0.5277854784111609, 0.014822481291476786, 0.5285000690540047, 0.04132173516397286, 0.6512040325663568, 0.34734137864289527, 0.3498285984480014, 0.6507698260475001, 0.5354703005594958, 0.5076797772836159, 0.12000997613822295, 0.12175453972737671, 0.13846230608738952, 0.06853185946056961, 0.09639694698524526, 0.08172739214702673, 0.15114811768212144, 0.1110753656541974, 0.0925426499046369, 0.19163678705971732, 0.11341340633531449, 0.1046397698255731, 0.5334657675938494, 0.5497659172580223, 0.2045808383492046, 0.34947965189042596, 0.17873208853523614, 0.3915250587230973, 0.34666025533866374, 0.4676478354235024, 0.4589802477528143, 0.4866993458579195, 0.5312657043113183, 0.4928459309786626, 0.5445365508809483, 0.3960437700285889, 0.4131884130947828, 0.6643903562737061, 0.7861418067115693, 0.8084228474496885, 0.7793230934920117, 0.7966479203522617, 0.7863881139257743, 0.7715900806405529, 0.778539823974718, 0.8281816734807076, 0.0918996711011103, 0.09877196676920119, 0.08874303604861711, 0.09161436042296323, 0.08136139684257193, 0.08640539215225784, 0.0881334940861841, 0.10268818382127243, 0.0981351971408625, 0.13506434713536697, 0.1515448729815897, 0.24684634107717307, 0.14311114262614466, 0.14125619370056575, 0.3635093698779386, 0.1385257128578372, 0.14240206290355817, 0.1355352781089858, 0.36917900558592887, 0.41295726937187005, 0.3154188696319773, 0.36578107747030497, 0.31601428877521653, 0.2821232434363976, 0.3462112977338552, 0.4449176873076617, 0.31795753817837236, 0.25890957784394253, 0.2658308799915914, 0.2675456226024867, 0.2670050054573174, 0.27254527128016803, 0.28696162055961827, 0.23859561382946182, 0.20508754761596282, 0.21693712871027504, 0.22393141643099757, 0.2093896129171794, 0.19534720459646693, 0.1875031115669622, 0.19655151895434841, 0.1995010071891854, 0.24652639534315646, 0.19566618428180993, 0.20086272543637773, 0.17996985626028472, 0.1733059921179596, 0.18544071905885617, 0.18091556901734662, 0.19601546264621506, 0.18429188106073924, 0.1802237873167809, 0.17749067261337803, 0.1814150932219487, 0.16790370323636672, 0.13700333746676874, 0.18798251344252626, 0.25465882516861915, 0.11251569061669475, 0.06195736121941131, 0.10844492011293916, 0.11539635329329212, 0.1679757307819293, 0.9092061871259115, 0.11330628995217107, 0.07470532371094218, 0.1689555118903996, 0.2105062448836338, 0.10964117318970734, 0.15266116496777926, 0.16111052747759347, 0.8842952216887596, 0.19787910695861288, 0.1755555489653421, 0.17898912356561414, 0.18551946106308925, 0.178132609872514, 0.200623280797112, 0.19777465898479918, 0.18571648012704656, 0.1890567748439579, 0.07447559490759104, 0.1103887086576113, 0.0775128836441108, 0.06805950066870903, 0.10216033936920044, 0.0818471689160466, 0.08823977908982705, 0.07695783038107873, 0.09209674397649559]}, "mutation_prompt": null}
{"id": "e6b02d5c-cfae-40bd-ae9a-db0e4f01d4fb", "solution": "import numpy as np\n\nclass AdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Dynamic recombination for enhanced diversity\n                if np.random.rand() < 0.25:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.5 * (samples[i] + samples[crossover_idx])\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "AdaptiveCMAESOptimizer", "description": "Adaptive Covariance Matrix Evolution Strategy with dynamic recombination and mutation for enhanced convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {"aucs": [0.9023680266036419, 0.9081023544281063, 0.9281146974576004, 0.930892291885995, 0.9219787824141944, 0.921662910916557, 0.9253496587408858, 0.9198976701332013, 0.8847700681413939, 0.6537384997193425, 0.6160233287733642, 0.6563208825227356, 0.6163645354010334, 0.5768076919963834, 0.6381877627976046, 0.644490588013349, 0.5723090794014429, 0.45378070407697757, 0.08901225759668219, 0.08069933266641716, 0.0961342739978509, 0.099610970046912, 0.09499813978399019, 0.0886141914423455, 0.09451995461399343, 0.10446707574883207, 0.15500087634258986, 0.07798333773041666, 0.06658768529066161, 0.07179466685719293, 0.07145984692128038, 0.0851935053973022, 0.07802987436392017, 0.07222210166057508, 0.08258468312889511, 0.07427182600206739, 0.6091481360187416, 0.9819545449057234, 0.9759395480499687, 0.164332031884469, 0.9233971247708334, 0.3349708133828754, 0.9831550828331599, 0.7204988622159381, 0.7945783918736788, 0.12131148762740662, 0.11385627259380837, 0.1569470808834601, 0.10782219947965443, 0.12120919432047816, 0.14355034381092524, 0.11822544820012792, 0.16769198135787444, 0.17681514906892148, 0.4974155913939722, 0.6849128440711825, 0.7842133683239996, 0.672012207194317, 0.8480711271649748, 0.6796432405036426, 0.8954085979215428, 0.8326094600710127, 0.6515106088993727, 0.5269321278983987, 0.5947373568933536, 0.5526691326065478, 0.43522980904509134, 0.5348548697379482, 0.6398425297369021, 0.558463546066519, 0.48939640873544454, 0.6437009647178075, 0.6162203176217613, 0.21540826118668244, 0.6499992954286005, 0.5920147180523607, 0.13367462986243395, 0.5810318345249562, 0.35072235832687515, 0.36817035973293344, 0.5277854784111609, 0.014822481291476786, 0.5285000690540047, 0.04132173516397286, 0.6512040325663568, 0.34734137864289527, 0.3498285984480014, 0.6507698260475001, 0.5354703005594958, 0.5076797772836159, 0.12000997613822295, 0.12175453972737671, 0.13846230608738952, 0.06853185946056961, 0.09639694698524526, 0.08172739214702673, 0.15114811768212144, 0.1110753656541974, 0.0925426499046369, 0.19163678705971732, 0.11341340633531449, 0.1046397698255731, 0.5334657675938494, 0.5497659172580223, 0.2045808383492046, 0.34947965189042596, 0.17873208853523614, 0.3915250587230973, 0.34666025533866374, 0.4676478354235024, 0.4589802477528143, 0.4866993458579195, 0.5312657043113183, 0.4928459309786626, 0.5445365508809483, 0.3960437700285889, 0.4131884130947828, 0.6643903562737061, 0.7861418067115693, 0.8084228474496885, 0.7793230934920117, 0.7966479203522617, 0.7863881139257743, 0.7715900806405529, 0.778539823974718, 0.8281816734807076, 0.0918996711011103, 0.09877196676920119, 0.08874303604861711, 0.09161436042296323, 0.08136139684257193, 0.08640539215225784, 0.0881334940861841, 0.10268818382127243, 0.0981351971408625, 0.13506434713536697, 0.1515448729815897, 0.24684634107717307, 0.14311114262614466, 0.14125619370056575, 0.3635093698779386, 0.1385257128578372, 0.14240206290355817, 0.1355352781089858, 0.36917900558592887, 0.41295726937187005, 0.3154188696319773, 0.36578107747030497, 0.31601428877521653, 0.2821232434363976, 0.3462112977338552, 0.4449176873076617, 0.31795753817837236, 0.25890957784394253, 0.2658308799915914, 0.2675456226024867, 0.2670050054573174, 0.27254527128016803, 0.28696162055961827, 0.23859561382946182, 0.20508754761596282, 0.21693712871027504, 0.22393141643099757, 0.2093896129171794, 0.19534720459646693, 0.1875031115669622, 0.19655151895434841, 0.1995010071891854, 0.24652639534315646, 0.19566618428180993, 0.20086272543637773, 0.17996985626028472, 0.1733059921179596, 0.18544071905885617, 0.18091556901734662, 0.19601546264621506, 0.18429188106073924, 0.1802237873167809, 0.17749067261337803, 0.1814150932219487, 0.16790370323636672, 0.13700333746676874, 0.18798251344252626, 0.25465882516861915, 0.11251569061669475, 0.06195736121941131, 0.10844492011293916, 0.11539635329329212, 0.1679757307819293, 0.9092061871259115, 0.11330628995217107, 0.07470532371094218, 0.1689555118903996, 0.2105062448836338, 0.10964117318970734, 0.15266116496777926, 0.16111052747759347, 0.8842952216887596, 0.19787910695861288, 0.1755555489653421, 0.17898912356561414, 0.18551946106308925, 0.178132609872514, 0.200623280797112, 0.19777465898479918, 0.18571648012704656, 0.1890567748439579, 0.07447559490759104, 0.1103887086576113, 0.0775128836441108, 0.06805950066870903, 0.10216033936920044, 0.0818471689160466, 0.08823977908982705, 0.07695783038107873, 0.09209674397649559]}, "mutation_prompt": null}
{"id": "cff2d0b7-f79c-4ea2-bf73-c0d57a98423d", "solution": "import numpy as np\n\nclass EnhancedAdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n        \n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                if np.random.rand() < 0.25:  # Stochastic rank-based recombination\n                    crossover_idx1, crossover_idx2 = np.random.choice(self.population_size, 2, replace=False)\n                    samples[i] = 0.5 * (samples[crossover_idx1] + samples[crossover_idx2])\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "EnhancedAdaptiveCMAESOptimizer", "description": "Enhanced Adaptive CMA-ES with stochastic rank-based recombination and adaptive mutation steps for robust optimization.", "configspace": "", "generation": 90, "fitness": 0.3344185514246277, "feedback": "The algorithm EnhancedAdaptiveCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.26.", "error": "", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {"aucs": [0.8975721736138499, 0.9422063415577931, 0.8993222877690576, 0.8910476356420383, 0.9107137510344857, 0.9224008667154673, 0.9089170520361132, 0.8890553014326473, 0.9369036762526975, 0.5732781803196174, 0.5588521144302498, 0.6327789356581622, 0.6101856500210256, 0.6013003989395042, 0.564026721560605, 0.5340493813378495, 0.5248978305506773, 0.5930208454336665, 0.10014633114890603, 0.08960135924122847, 0.09997212074501927, 0.10787059569193647, 0.09970144172676065, 0.09368764869470247, 0.09586605282115546, 0.09457201968321027, 0.08346699880579234, 0.0721944174029584, 0.08246977755281004, 0.072149866424296, 0.08749696685899433, 0.07736794074203313, 0.07980647188235057, 0.10481379538348934, 0.08655288121670035, 0.0878896286734906, 0.5731039051454383, 0.9702047885720637, 0.809623307657735, 0.6046806335344168, 0.8952792972036916, 0.45699691075949966, 0.19151879776458725, 0.7412282335103004, 0.9090306375327173, 0.12447168632929684, 0.16117213973994116, 0.14918759315861485, 0.12006552955172178, 0.1740442657116611, 0.14378391043346184, 0.1369443634563644, 0.13507485357734317, 0.182173432498011, 0.7901759163504795, 0.36243047014697816, 0.8471542989038044, 0.4951827184714851, 0.6950937472534553, 0.9124606927326737, 0.24579459181448582, 0.6215472144107806, 0.6828826979411018, 0.37960582252886244, 0.2609227988125833, 0.553747019968054, 0.8067941554230141, 0.1335087126565606, 0.4181032041033236, 0.42711375094594706, 0.5271228300259293, 0.46998784788622794, 0.5498852665903494, 0.43287403945739933, 0.2337976290035796, 0.4748191827391425, 0.49500504154820335, 0.5013084785932282, 0.42993839859971494, 0.2950073753435004, 0.13029248145133354, 0.4175284340099703, 0.6306029071979655, 0.5801925755601419, 0.45330331380162514, 0.27023374280383206, 0.6130110503875004, 0.22317313920414494, 0.5073705213916417, 0.5959897309481239, 0.13227312267441615, 0.10496874203314177, 0.5975155790711584, 0.137968178127307, 0.08330574903713239, 0.08425455287333683, 0.1182624836407784, 0.10597513799532665, 0.11626693514591735, 0.19231323504647446, 0.0651092835590793, 0.28183790870003456, 0.5080422079834666, 0.44185201454491774, 0.19666547890698727, 0.23658200072956237, 0.3833656823546263, 0.20641893718406168, 0.2790818425857311, 0.4030743640063933, 0.22192795262734233, 0.39432049442167827, 0.4542118366304473, 0.348627400669822, 0.34504190189890793, 0.3613609429150134, 0.36195744470224755, 0.7876190773070021, 0.7400774014339349, 0.7720067119354657, 0.8013518195866639, 0.7442960791417662, 0.7625425575459408, 0.7908020357976331, 0.7512270236108225, 0.7777566772399032, 0.09936980308954102, 0.10291711147946847, 0.12007005871270726, 0.09071342084304834, 0.10184862923305338, 0.12025747485429017, 0.09794372939987983, 0.0901707610871183, 0.08756825565584492, 0.1292417535822069, 0.14185518147209242, 0.141880110466459, 0.1651851664627364, 0.6101220149949895, 0.3226048151403209, 0.1488512452149482, 0.21895379392027547, 0.1234066919532002, 0.3182699273437277, 0.3210663594474972, 0.45708891478989955, 0.45447549944233456, 0.3082784264741246, 0.36536737032643785, 0.15361028894429563, 0.41070506879773794, 0.0948911868343002, 0.235939603066468, 0.28117137411540694, 0.3810976240356969, 0.27467898725157847, 0.2658090185269797, 0.2611334359090569, 0.43263257423948887, 0.2501632301030281, 0.24089275530786258, 0.19184021570231158, 0.19187333147050467, 0.2147749815599238, 0.20577386953656573, 0.2016277831425909, 0.19167882611809228, 0.20691675881338556, 0.19368743318881, 0.18568587917107493, 0.1874101345087692, 0.18652717724953105, 0.18173407907558792, 0.1976044834559798, 0.1704619631699621, 0.1808382653137044, 0.18290429105241934, 0.18107122427715538, 0.18143631998706, 0.18616873717130444, 0.13749763146231986, 0.1661125825619243, 0.16184575292209724, 0.1980652179562331, 0.9221550646209282, 0.10870604051229071, 0.11531483584215108, 0.15278571451723566, 0.9230782691894543, 0.17290032467599525, 0.1096089307950171, 0.08316270376793777, 0.16768064390788862, 0.0441572572019735, 0.1268407098537293, 0.10933232962340877, 0.0991115771005987, 0.1811193258531132, 0.17843382736702929, 0.17855571243419222, 0.18685691119954628, 0.18129739156815305, 0.17793177575849017, 0.1766296711148012, 0.18301651947129827, 0.18179026736489745, 0.0825807776482752, 0.08597158495246526, 0.07253430835873764, 0.07431254181229197, 0.0772509140240012, 0.09734525509315695, 0.09963721323246122, 0.07357377315508107, 0.06800399650777833]}, "mutation_prompt": null}
{"id": "b882495c-3bb8-4dd6-8eb2-95e868b60e79", "solution": "import numpy as np\n\nclass AdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Dynamic recombination for enhanced diversity\n                if np.random.rand() < 0.25:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.5 * (samples[i] + samples[crossover_idx])\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "AdaptiveCMAESOptimizer", "description": "Adaptive Covariance Matrix Evolution Strategy with dynamic recombination and mutation for enhanced convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {"aucs": [0.9023680266036419, 0.9081023544281063, 0.9281146974576004, 0.930892291885995, 0.9219787824141944, 0.921662910916557, 0.9253496587408858, 0.9198976701332013, 0.8847700681413939, 0.6537384997193425, 0.6160233287733642, 0.6563208825227356, 0.6163645354010334, 0.5768076919963834, 0.6381877627976046, 0.644490588013349, 0.5723090794014429, 0.45378070407697757, 0.08901225759668219, 0.08069933266641716, 0.0961342739978509, 0.099610970046912, 0.09499813978399019, 0.0886141914423455, 0.09451995461399343, 0.10446707574883207, 0.15500087634258986, 0.07798333773041666, 0.06658768529066161, 0.07179466685719293, 0.07145984692128038, 0.0851935053973022, 0.07802987436392017, 0.07222210166057508, 0.08258468312889511, 0.07427182600206739, 0.6091481360187416, 0.9819545449057234, 0.9759395480499687, 0.164332031884469, 0.9233971247708334, 0.3349708133828754, 0.9831550828331599, 0.7204988622159381, 0.7945783918736788, 0.12131148762740662, 0.11385627259380837, 0.1569470808834601, 0.10782219947965443, 0.12120919432047816, 0.14355034381092524, 0.11822544820012792, 0.16769198135787444, 0.17681514906892148, 0.4974155913939722, 0.6849128440711825, 0.7842133683239996, 0.672012207194317, 0.8480711271649748, 0.6796432405036426, 0.8954085979215428, 0.8326094600710127, 0.6515106088993727, 0.5269321278983987, 0.5947373568933536, 0.5526691326065478, 0.43522980904509134, 0.5348548697379482, 0.6398425297369021, 0.558463546066519, 0.48939640873544454, 0.6437009647178075, 0.6162203176217613, 0.21540826118668244, 0.6499992954286005, 0.5920147180523607, 0.13367462986243395, 0.5810318345249562, 0.35072235832687515, 0.36817035973293344, 0.5277854784111609, 0.014822481291476786, 0.5285000690540047, 0.04132173516397286, 0.6512040325663568, 0.34734137864289527, 0.3498285984480014, 0.6507698260475001, 0.5354703005594958, 0.5076797772836159, 0.12000997613822295, 0.12175453972737671, 0.13846230608738952, 0.06853185946056961, 0.09639694698524526, 0.08172739214702673, 0.15114811768212144, 0.1110753656541974, 0.0925426499046369, 0.19163678705971732, 0.11341340633531449, 0.1046397698255731, 0.5334657675938494, 0.5497659172580223, 0.2045808383492046, 0.34947965189042596, 0.17873208853523614, 0.3915250587230973, 0.34666025533866374, 0.4676478354235024, 0.4589802477528143, 0.4866993458579195, 0.5312657043113183, 0.4928459309786626, 0.5445365508809483, 0.3960437700285889, 0.4131884130947828, 0.6643903562737061, 0.7861418067115693, 0.8084228474496885, 0.7793230934920117, 0.7966479203522617, 0.7863881139257743, 0.7715900806405529, 0.778539823974718, 0.8281816734807076, 0.0918996711011103, 0.09877196676920119, 0.08874303604861711, 0.09161436042296323, 0.08136139684257193, 0.08640539215225784, 0.0881334940861841, 0.10268818382127243, 0.0981351971408625, 0.13506434713536697, 0.1515448729815897, 0.24684634107717307, 0.14311114262614466, 0.14125619370056575, 0.3635093698779386, 0.1385257128578372, 0.14240206290355817, 0.1355352781089858, 0.36917900558592887, 0.41295726937187005, 0.3154188696319773, 0.36578107747030497, 0.31601428877521653, 0.2821232434363976, 0.3462112977338552, 0.4449176873076617, 0.31795753817837236, 0.25890957784394253, 0.2658308799915914, 0.2675456226024867, 0.2670050054573174, 0.27254527128016803, 0.28696162055961827, 0.23859561382946182, 0.20508754761596282, 0.21693712871027504, 0.22393141643099757, 0.2093896129171794, 0.19534720459646693, 0.1875031115669622, 0.19655151895434841, 0.1995010071891854, 0.24652639534315646, 0.19566618428180993, 0.20086272543637773, 0.17996985626028472, 0.1733059921179596, 0.18544071905885617, 0.18091556901734662, 0.19601546264621506, 0.18429188106073924, 0.1802237873167809, 0.17749067261337803, 0.1814150932219487, 0.16790370323636672, 0.13700333746676874, 0.18798251344252626, 0.25465882516861915, 0.11251569061669475, 0.06195736121941131, 0.10844492011293916, 0.11539635329329212, 0.1679757307819293, 0.9092061871259115, 0.11330628995217107, 0.07470532371094218, 0.1689555118903996, 0.2105062448836338, 0.10964117318970734, 0.15266116496777926, 0.16111052747759347, 0.8842952216887596, 0.19787910695861288, 0.1755555489653421, 0.17898912356561414, 0.18551946106308925, 0.178132609872514, 0.200623280797112, 0.19777465898479918, 0.18571648012704656, 0.1890567748439579, 0.07447559490759104, 0.1103887086576113, 0.0775128836441108, 0.06805950066870903, 0.10216033936920044, 0.0818471689160466, 0.08823977908982705, 0.07695783038107873, 0.09209674397649559]}, "mutation_prompt": null}
{"id": "cc5d5428-eca7-4119-8c11-9e76c74c3f53", "solution": "import numpy as np\n\nclass EnhancedAdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elite_count = max(1, int(self.population_size * 0.1))\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            mirrored_samples = 2 * self.mean - samples  # Stochastic mirrored sampling\n            samples = np.concatenate((samples, mirrored_samples), axis=0)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(len(samples)):\n                if self.eval_count >= self.budget:\n                    break\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n            if self.eval_count < self.budget:\n                elite_samples = samples[indices[:self.elite_count]]\n                for elite_sample in elite_samples:\n                    self.fitness = np.append(self.fitness, func(elite_sample))\n                    self.eval_count += 1\n                    if self.eval_count >= self.budget:\n                        break\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "EnhancedAdaptiveCMAESOptimizer", "description": "Enhanced Adaptive CMA-ES with stochastic mirrored sampling and elite preservation for improved convergence stability and robustness.", "configspace": "", "generation": 92, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 8 is out of bounds for axis 0 with size 8').", "error": "IndexError('index 8 is out of bounds for axis 0 with size 8')", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {}, "mutation_prompt": null}
{"id": "54d7eaf4-6462-47f0-a595-97b1ba5f4114", "solution": "import numpy as np\n\nclass EnhancedAdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n        self.mutation_strength = 0.2\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Dynamic recombination for enhanced diversity\n                if np.random.rand() < 0.25:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.5 * (samples[i] + samples[crossover_idx])\n                # Mutation for exploring new areas\n                if np.random.rand() < 0.25:\n                    mutation_vector = np.random.normal(0, self.mutation_strength, self.dim)\n                    samples[i] += mutation_vector\n                    samples[i] = np.clip(samples[i], self.lower_bound, self.upper_bound)\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "EnhancedAdaptiveCMAESOptimizer", "description": "Adaptive Covariance Matrix Evolution Strategy with dynamic recombination, mutation, and adaptive weighting for improved convergence.", "configspace": "", "generation": 93, "fitness": 0.18296821981649009, "feedback": "The algorithm EnhancedAdaptiveCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.16.", "error": "", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {"aucs": [0.5087150108514097, 0.45671513523786955, 0.4795410043759283, 0.46488372431339686, 0.455592487690644, 0.482204974249709, 0.4897262929797783, 0.48911608992060307, 0.47633682910201214, 0.022088641357758565, 0.013486022355708838, 0.004762691979404932, 0.025930109004206336, 0.05695454409959233, 9.999999999998899e-05, 0.01654950264974031, 0.013273093347475284, 0.01022122777594836, 0.09282971352164682, 0.09184116118148833, 0.0878228715273992, 0.08670412792566151, 0.08388315563286675, 0.08524640245362103, 0.1321894725825672, 0.09191002697902861, 0.09224810255624138, 0.08019825563830074, 0.08207558407814763, 0.06785570748174108, 0.08169993854306723, 0.06393932510438338, 0.0796547583220949, 0.07012020887022152, 0.07238020982618076, 0.06744153136710884, 0.8526842418302312, 0.7331006113285702, 0.6428041509333735, 0.19830941156795256, 0.5396945622965723, 0.8463540142368978, 0.23084618704089488, 0.18821351185260626, 0.29830747792883894, 0.12896701127307464, 0.15549458130169347, 0.14178643544013025, 0.10280284175047105, 0.12455904924024963, 0.1235780306958153, 0.13312342718983217, 0.14790899536070123, 0.11975469711510744, 0.32944603761539215, 0.34436474597544475, 0.28644035534131873, 0.29098898798920847, 0.2741877992904278, 0.30640720709627345, 0.3043809839626387, 0.8256331973846283, 0.2743397320868278, 0.16635409563054615, 0.15365911510279862, 0.13735112007168793, 0.19610646253576902, 0.15015441088247405, 0.15488436700065866, 0.1766964629566502, 0.1412816593454178, 0.14595297015863273, 0.15869027451080342, 0.1505076285557061, 0.1318519882214667, 0.14938694674819886, 0.16084611840369667, 0.16225450464968527, 0.19545522701666007, 0.14978996633991704, 0.15218914799417416, 0.024316690976299515, 9.999999999998899e-05, 0.02211379627887977, 9.999999999998899e-05, 0.01451116843771938, 9.999999999998899e-05, 0.01087739688476197, 9.999999999998899e-05, 0.009035226064946666, 0.08847685241104919, 0.09787296692889236, 0.13404740183819408, 0.08091414965157506, 0.07418063623455928, 0.10572746006720646, 0.11305548645661345, 0.14223824089002135, 0.14895895955868788, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0013765815520435654, 0.11504333929221267, 0.10751384599628833, 0.10193988721025782, 0.11614808220038342, 0.11044542336910124, 0.13029465495710124, 0.10849718247928153, 0.11178554322984513, 0.10380148770350583, 0.4116185244997804, 0.42231016857908166, 0.43247478154407504, 0.40436716478605217, 0.40023602572294703, 0.40459709393474164, 0.41000681530088146, 0.40403162447464125, 0.41835758576111004, 0.09018891354128244, 0.08974949437647917, 0.08457350807485142, 0.08298918756660623, 0.07998983575400975, 0.08970466338950922, 0.08220365402065422, 0.0961793743655206, 0.09358765281951653, 0.12510193833928585, 0.13625358488501094, 0.12373092524813656, 0.17106671241173077, 0.14230403153257754, 0.1645763967578654, 0.13730019480047506, 0.12930331925575012, 0.13157782544260643, 0.2662521887414848, 0.2676099311269915, 0.28035238594863054, 0.2850746438856311, 0.27524547446211733, 0.259568477141611, 0.2691180007488708, 0.259749637533769, 0.27094133304333146, 0.21430144858452704, 0.2087378952931047, 0.18544115633572378, 0.19901232924030066, 0.20860449499754807, 0.21034963102788684, 0.20403944959506448, 0.20212875703251376, 0.20053732506438304, 0.1887590414818543, 0.1865001829914199, 0.19845213688838514, 0.21365389179910743, 0.1809297347377541, 0.18446846185199695, 0.18983857576947483, 0.20472926444483153, 0.1928479107685378, 0.17682237489541708, 0.18075959291224286, 0.17724486366562975, 0.18202179512954653, 0.18689018700944005, 0.17754265301062588, 0.17877152241736005, 0.17737494809501408, 0.17321763659168354, 0.15637670499465095, 0.14727443152795072, 0.7003256507485476, 0.11499943083152686, 0.14726796431677636, 0.16397934176103268, 0.10885356920520661, 0.11526359828209387, 0.15872251119130087, 0.6104464795271645, 0.11328302445688043, 0.3610013509100861, 0.21177599605926534, 0.19140547153311882, 0.20993095011024, 0.16736208286934673, 0.1548323821273685, 0.1161030531179118, 0.18141022025131892, 0.18188957189870814, 0.20869252279649364, 0.186881201109228, 0.1914318272388813, 0.17859157531312864, 0.18937627600034934, 0.18002831274840103, 0.18359623861583918, 0.06828545889808824, 0.07919966856511895, 0.0719138577970807, 0.07383891716719393, 0.07305466276841854, 0.07755821064323754, 0.08172211707203292, 0.07633366032388023, 0.08335570933249725]}, "mutation_prompt": null}
{"id": "b2436acb-e306-49b3-9771-9c467d1a924e", "solution": "import numpy as np\n\nclass EnhancedAdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n        self.diversity_threshold = 1e-6\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Dynamic recombination for enhanced diversity\n                if np.random.rand() < 0.25:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.5 * (samples[i] + samples[crossover_idx])\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n            # Diversity preservation mechanism\n            if np.linalg.norm(self.mean - selected[0]) < self.diversity_threshold:\n                self.adaptive_step_size *= 1.1\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "EnhancedAdaptiveCMAESOptimizer", "description": "Enhanced Adaptive Covariance Matrix Evolution Strategy with dynamic recombination, mutation control, and diversity preservation for improved convergence.", "configspace": "", "generation": 94, "fitness": 0.34609068194689335, "feedback": "The algorithm EnhancedAdaptiveCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.27.", "error": "", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {"aucs": [0.9023680266036419, 0.9081023544281063, 0.9281146974576004, 0.930892291885995, 0.9219787824141944, 0.921662910916557, 0.9253496587408858, 0.9198976701332013, 0.8847700681413939, 0.6537384997193425, 0.6160233287733642, 0.6563208825227356, 0.6163645354010334, 0.5768076919963834, 0.6381877627976046, 0.644490588013349, 0.5723090794014429, 0.45378070407697757, 0.08901225759668219, 0.08069933266641716, 0.0961342739978509, 0.099610970046912, 0.09499813978399019, 0.0886141914423455, 0.09451995461399343, 0.10446707574883207, 0.15500087633841142, 0.07798333773041666, 0.06658768529066161, 0.07179466685719293, 0.07145984692128038, 0.0851935053973022, 0.07802987436392017, 0.07222210166057508, 0.08258468312889511, 0.07427182600206739, 0.6091481360187416, 0.9819545449057234, 0.9759395480499687, 0.164332031884469, 0.9233971247708334, 0.3349708133828754, 0.9831550828331599, 0.7204988622159381, 0.7945783918736788, 0.12131148762740662, 0.11385627259380837, 0.1569470808834601, 0.10782219947965443, 0.12120919432047816, 0.14355034381092524, 0.11822544820012792, 0.16769198135787444, 0.17681514906892148, 0.4974155913939722, 0.6849128440711825, 0.7842133683239996, 0.672012207194317, 0.8480711271649748, 0.6796432405036426, 0.8954085979215428, 0.8326094600710127, 0.6515106088993727, 0.5269321278983987, 0.5947373568933536, 0.5526691326065478, 0.43522980904509134, 0.5348548697379482, 0.6398425297369021, 0.558463546066519, 0.48939640873544454, 0.6437009647178075, 0.6162203176217613, 0.21540826118668244, 0.6499992954286005, 0.5920147180523607, 0.13367462986243006, 0.5810318345249562, 0.35072235832687515, 0.36817035973293344, 0.5277854784111609, 0.014822481291476786, 0.5285000690540047, 0.04132173516397286, 0.6512040325663568, 0.34734137864289527, 0.3498285984480014, 0.6507698260475001, 0.5354703005594958, 0.5076797772836159, 0.12000997613822295, 0.12175453972737671, 0.13846230608738952, 0.06853185946056961, 0.09639694698524526, 0.08172739214702673, 0.15114811768212144, 0.1110753656541974, 0.0925426499046369, 0.19163678705971732, 0.11341340633531449, 0.1046397698255731, 0.5296577232410695, 0.5497353559035988, 0.2045808383492046, 0.34947965189042596, 0.17873208853523614, 0.3915250587230973, 0.35585264166454067, 0.4363709796230576, 0.45914813645558195, 0.479747626910366, 0.524249100950718, 0.4766307555505209, 0.5379241163385184, 0.39561965238059027, 0.41294704160204077, 0.6643903562737061, 0.7861418067115693, 0.8084228474496885, 0.7793230934920117, 0.7966479203522617, 0.7863881139257743, 0.7715900806405529, 0.778539823974718, 0.8281816734807076, 0.09189967110108266, 0.09877196676920119, 0.08874303604861711, 0.09161436042296323, 0.08136139684257193, 0.08640539215225784, 0.0881334940861841, 0.10268818382127243, 0.0981351971408625, 0.13506434713536697, 0.1515448729815897, 0.24684635217326145, 0.14311114262614466, 0.14125619370056575, 0.36350753832638416, 0.1385257128578372, 0.14240206290355817, 0.1355352781089858, 0.36917900558592887, 0.41295726937187005, 0.3154188696319773, 0.36578107747030497, 0.31601428877521653, 0.2821232434363976, 0.3462112977338552, 0.4449176873076617, 0.31795753817837236, 0.25890957784394253, 0.2658308799915914, 0.2675456226024867, 0.2670050054573174, 0.27254527128016803, 0.28696162055961827, 0.23859561382946182, 0.20508754761596282, 0.21693712871027504, 0.22393141643099757, 0.2093896129171794, 0.19534720459646693, 0.1875031115669622, 0.19655151895434841, 0.1995010071891854, 0.24652639534315646, 0.19566618428180993, 0.20086272543637773, 0.17996985626028472, 0.1733059921179596, 0.18544071905885617, 0.18091556901734662, 0.19601546264621506, 0.18429188106073924, 0.1802237873167809, 0.17749067261337803, 0.1814150932219487, 0.16790370323636672, 0.13700333746676274, 0.18798251344252703, 0.25465882516861915, 0.11251569061669475, 0.06195736121941131, 0.10844492011293916, 0.11539635329328923, 0.1679757307819293, 0.9092061871259115, 0.1133062899521694, 0.07470532371094218, 0.1689555118903996, 0.21050624488363112, 0.10964117318970734, 0.15266116496777926, 0.16111052747759347, 0.8842952216887596, 0.19787910695861288, 0.1755555489653421, 0.17898912356561414, 0.18551946106308925, 0.178132609872514, 0.200623280797112, 0.19777465898479918, 0.18571648012704656, 0.1890567748439579, 0.07447559490759104, 0.1103887086576113, 0.0775128836441108, 0.06805950066870903, 0.10216033936920044, 0.0818471689160466, 0.08823977908982705, 0.07695783038107873, 0.09209674397649559]}, "mutation_prompt": null}
{"id": "588a8790-b52c-451d-a6f3-f46aea3524b0", "solution": "import numpy as np\n\nclass AdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Dynamic recombination for enhanced diversity\n                if np.random.rand() < 0.25:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.5 * (samples[i] + samples[crossover_idx])\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "AdaptiveCMAESOptimizer", "description": "Adaptive Covariance Matrix Evolution Strategy with dynamic recombination and mutation for enhanced convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {"aucs": [0.9023680266036419, 0.9081023544281063, 0.9281146974576004, 0.930892291885995, 0.9219787824141944, 0.921662910916557, 0.9253496587408858, 0.9198976701332013, 0.8847700681413939, 0.6537384997193425, 0.6160233287733642, 0.6563208825227356, 0.6163645354010334, 0.5768076919963834, 0.6381877627976046, 0.644490588013349, 0.5723090794014429, 0.45378070407697757, 0.08901225759668219, 0.08069933266641716, 0.0961342739978509, 0.099610970046912, 0.09499813978399019, 0.0886141914423455, 0.09451995461399343, 0.10446707574883207, 0.15500087634258986, 0.07798333773041666, 0.06658768529066161, 0.07179466685719293, 0.07145984692128038, 0.0851935053973022, 0.07802987436392017, 0.07222210166057508, 0.08258468312889511, 0.07427182600206739, 0.6091481360187416, 0.9819545449057234, 0.9759395480499687, 0.164332031884469, 0.9233971247708334, 0.3349708133828754, 0.9831550828331599, 0.7204988622159381, 0.7945783918736788, 0.12131148762740662, 0.11385627259380837, 0.1569470808834601, 0.10782219947965443, 0.12120919432047816, 0.14355034381092524, 0.11822544820012792, 0.16769198135787444, 0.17681514906892148, 0.4974155913939722, 0.6849128440711825, 0.7842133683239996, 0.672012207194317, 0.8480711271649748, 0.6796432405036426, 0.8954085979215428, 0.8326094600710127, 0.6515106088993727, 0.5269321278983987, 0.5947373568933536, 0.5526691326065478, 0.43522980904509134, 0.5348548697379482, 0.6398425297369021, 0.558463546066519, 0.48939640873544454, 0.6437009647178075, 0.6162203176217613, 0.21540826118668244, 0.6499992954286005, 0.5920147180523607, 0.13367462986243395, 0.5810318345249562, 0.35072235832687515, 0.36817035973293344, 0.5277854784111609, 0.014822481291476786, 0.5285000690540047, 0.04132173516397286, 0.6512040325663568, 0.34734137864289527, 0.3498285984480014, 0.6507698260475001, 0.5354703005594958, 0.5076797772836159, 0.12000997613822295, 0.12175453972737671, 0.13846230608738952, 0.06853185946056961, 0.09639694698524526, 0.08172739214702673, 0.15114811768212144, 0.1110753656541974, 0.0925426499046369, 0.19163678705971732, 0.11341340633531449, 0.1046397698255731, 0.5334657675938494, 0.5497659172580223, 0.2045808383492046, 0.34947965189042596, 0.17873208853523614, 0.3915250587230973, 0.34666025533866374, 0.4676478354235024, 0.4589802477528143, 0.4866993458579195, 0.5312657043113183, 0.4928459309786626, 0.5445365508809483, 0.3960437700285889, 0.4131884130947828, 0.6643903562737061, 0.7861418067115693, 0.8084228474496885, 0.7793230934920117, 0.7966479203522617, 0.7863881139257743, 0.7715900806405529, 0.778539823974718, 0.8281816734807076, 0.0918996711011103, 0.09877196676920119, 0.08874303604861711, 0.09161436042296323, 0.08136139684257193, 0.08640539215225784, 0.0881334940861841, 0.10268818382127243, 0.0981351971408625, 0.13506434713536697, 0.1515448729815897, 0.24684634107717307, 0.14311114262614466, 0.14125619370056575, 0.3635093698779386, 0.1385257128578372, 0.14240206290355817, 0.1355352781089858, 0.36917900558592887, 0.41295726937187005, 0.3154188696319773, 0.36578107747030497, 0.31601428877521653, 0.2821232434363976, 0.3462112977338552, 0.4449176873076617, 0.31795753817837236, 0.25890957784394253, 0.2658308799915914, 0.2675456226024867, 0.2670050054573174, 0.27254527128016803, 0.28696162055961827, 0.23859561382946182, 0.20508754761596282, 0.21693712871027504, 0.22393141643099757, 0.2093896129171794, 0.19534720459646693, 0.1875031115669622, 0.19655151895434841, 0.1995010071891854, 0.24652639534315646, 0.19566618428180993, 0.20086272543637773, 0.17996985626028472, 0.1733059921179596, 0.18544071905885617, 0.18091556901734662, 0.19601546264621506, 0.18429188106073924, 0.1802237873167809, 0.17749067261337803, 0.1814150932219487, 0.16790370323636672, 0.13700333746676874, 0.18798251344252626, 0.25465882516861915, 0.11251569061669475, 0.06195736121941131, 0.10844492011293916, 0.11539635329329212, 0.1679757307819293, 0.9092061871259115, 0.11330628995217107, 0.07470532371094218, 0.1689555118903996, 0.2105062448836338, 0.10964117318970734, 0.15266116496777926, 0.16111052747759347, 0.8842952216887596, 0.19787910695861288, 0.1755555489653421, 0.17898912356561414, 0.18551946106308925, 0.178132609872514, 0.200623280797112, 0.19777465898479918, 0.18571648012704656, 0.1890567748439579, 0.07447559490759104, 0.1103887086576113, 0.0775128836441108, 0.06805950066870903, 0.10216033936920044, 0.0818471689160466, 0.08823977908982705, 0.07695783038107873, 0.09209674397649559]}, "mutation_prompt": null}
{"id": "0d00c325-7ba7-407c-b6df-19451910e778", "solution": "import numpy as np\n\nclass AdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Dynamic recombination for enhanced diversity\n                if np.random.rand() < 0.25:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.5 * (samples[i] + samples[crossover_idx])\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "AdaptiveCMAESOptimizer", "description": "Adaptive Covariance Matrix Evolution Strategy with dynamic recombination and mutation for enhanced convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {"aucs": [0.9023680266036419, 0.9081023544281063, 0.9281146974576004, 0.930892291885995, 0.9219787824141944, 0.921662910916557, 0.9253496587408858, 0.9198976701332013, 0.8847700681413939, 0.6537384997193425, 0.6160233287733642, 0.6563208825227356, 0.6163645354010334, 0.5768076919963834, 0.6381877627976046, 0.644490588013349, 0.5723090794014429, 0.45378070407697757, 0.08901225759668219, 0.08069933266641716, 0.0961342739978509, 0.099610970046912, 0.09499813978399019, 0.0886141914423455, 0.09451995461399343, 0.10446707574883207, 0.15500087634258986, 0.07798333773041666, 0.06658768529066161, 0.07179466685719293, 0.07145984692128038, 0.0851935053973022, 0.07802987436392017, 0.07222210166057508, 0.08258468312889511, 0.07427182600206739, 0.6091481360187416, 0.9819545449057234, 0.9759395480499687, 0.164332031884469, 0.9233971247708334, 0.3349708133828754, 0.9831550828331599, 0.7204988622159381, 0.7945783918736788, 0.12131148762740662, 0.11385627259380837, 0.1569470808834601, 0.10782219947965443, 0.12120919432047816, 0.14355034381092524, 0.11822544820012792, 0.16769198135787444, 0.17681514906892148, 0.4974155913939722, 0.6849128440711825, 0.7842133683239996, 0.672012207194317, 0.8480711271649748, 0.6796432405036426, 0.8954085979215428, 0.8326094600710127, 0.6515106088993727, 0.5269321278983987, 0.5947373568933536, 0.5526691326065478, 0.43522980904509134, 0.5348548697379482, 0.6398425297369021, 0.558463546066519, 0.48939640873544454, 0.6437009647178075, 0.6162203176217613, 0.21540826118668244, 0.6499992954286005, 0.5920147180523607, 0.13367462986243395, 0.5810318345249562, 0.35072235832687515, 0.36817035973293344, 0.5277854784111609, 0.014822481291476786, 0.5285000690540047, 0.04132173516397286, 0.6512040325663568, 0.34734137864289527, 0.3498285984480014, 0.6507698260475001, 0.5354703005594958, 0.5076797772836159, 0.12000997613822295, 0.12175453972737671, 0.13846230608738952, 0.06853185946056961, 0.09639694698524526, 0.08172739214702673, 0.15114811768212144, 0.1110753656541974, 0.0925426499046369, 0.19163678705971732, 0.11341340633531449, 0.1046397698255731, 0.5334657675938494, 0.5497659172580223, 0.2045808383492046, 0.34947965189042596, 0.17873208853523614, 0.3915250587230973, 0.34666025533866374, 0.4676478354235024, 0.4589802477528143, 0.4866993458579195, 0.5312657043113183, 0.4928459309786626, 0.5445365508809483, 0.3960437700285889, 0.4131884130947828, 0.6643903562737061, 0.7861418067115693, 0.8084228474496885, 0.7793230934920117, 0.7966479203522617, 0.7863881139257743, 0.7715900806405529, 0.778539823974718, 0.8281816734807076, 0.0918996711011103, 0.09877196676920119, 0.08874303604861711, 0.09161436042296323, 0.08136139684257193, 0.08640539215225784, 0.0881334940861841, 0.10268818382127243, 0.0981351971408625, 0.13506434713536697, 0.1515448729815897, 0.24684634107717307, 0.14311114262614466, 0.14125619370056575, 0.3635093698779386, 0.1385257128578372, 0.14240206290355817, 0.1355352781089858, 0.36917900558592887, 0.41295726937187005, 0.3154188696319773, 0.36578107747030497, 0.31601428877521653, 0.2821232434363976, 0.3462112977338552, 0.4449176873076617, 0.31795753817837236, 0.25890957784394253, 0.2658308799915914, 0.2675456226024867, 0.2670050054573174, 0.27254527128016803, 0.28696162055961827, 0.23859561382946182, 0.20508754761596282, 0.21693712871027504, 0.22393141643099757, 0.2093896129171794, 0.19534720459646693, 0.1875031115669622, 0.19655151895434841, 0.1995010071891854, 0.24652639534315646, 0.19566618428180993, 0.20086272543637773, 0.17996985626028472, 0.1733059921179596, 0.18544071905885617, 0.18091556901734662, 0.19601546264621506, 0.18429188106073924, 0.1802237873167809, 0.17749067261337803, 0.1814150932219487, 0.16790370323636672, 0.13700333746676874, 0.18798251344252626, 0.25465882516861915, 0.11251569061669475, 0.06195736121941131, 0.10844492011293916, 0.11539635329329212, 0.1679757307819293, 0.9092061871259115, 0.11330628995217107, 0.07470532371094218, 0.1689555118903996, 0.2105062448836338, 0.10964117318970734, 0.15266116496777926, 0.16111052747759347, 0.8842952216887596, 0.19787910695861288, 0.1755555489653421, 0.17898912356561414, 0.18551946106308925, 0.178132609872514, 0.200623280797112, 0.19777465898479918, 0.18571648012704656, 0.1890567748439579, 0.07447559490759104, 0.1103887086576113, 0.0775128836441108, 0.06805950066870903, 0.10216033936920044, 0.0818471689160466, 0.08823977908982705, 0.07695783038107873, 0.09209674397649559]}, "mutation_prompt": null}
{"id": "c4978a36-81f8-4ff9-97b5-a697befd83a3", "solution": "import numpy as np\n\nclass AdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Dynamic recombination for enhanced diversity\n                if np.random.rand() < 0.25:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.5 * (samples[i] + samples[crossover_idx])\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "AdaptiveCMAESOptimizer", "description": "Adaptive Covariance Matrix Evolution Strategy with dynamic recombination and mutation for enhanced convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {"aucs": [0.9023680266036419, 0.9081023544281063, 0.9281146974576004, 0.930892291885995, 0.9219787824141944, 0.921662910916557, 0.9253496587408858, 0.9198976701332013, 0.8847700681413939, 0.6537384997193425, 0.6160233287733642, 0.6563208825227356, 0.6163645354010334, 0.5768076919963834, 0.6381877627976046, 0.644490588013349, 0.5723090794014429, 0.45378070407697757, 0.08901225759668219, 0.08069933266641716, 0.0961342739978509, 0.099610970046912, 0.09499813978399019, 0.0886141914423455, 0.09451995461399343, 0.10446707574883207, 0.15500087634258986, 0.07798333773041666, 0.06658768529066161, 0.07179466685719293, 0.07145984692128038, 0.0851935053973022, 0.07802987436392017, 0.07222210166057508, 0.08258468312889511, 0.07427182600206739, 0.6091481360187416, 0.9819545449057234, 0.9759395480499687, 0.164332031884469, 0.9233971247708334, 0.3349708133828754, 0.9831550828331599, 0.7204988622159381, 0.7945783918736788, 0.12131148762740662, 0.11385627259380837, 0.1569470808834601, 0.10782219947965443, 0.12120919432047816, 0.14355034381092524, 0.11822544820012792, 0.16769198135787444, 0.17681514906892148, 0.4974155913939722, 0.6849128440711825, 0.7842133683239996, 0.672012207194317, 0.8480711271649748, 0.6796432405036426, 0.8954085979215428, 0.8326094600710127, 0.6515106088993727, 0.5269321278983987, 0.5947373568933536, 0.5526691326065478, 0.43522980904509134, 0.5348548697379482, 0.6398425297369021, 0.558463546066519, 0.48939640873544454, 0.6437009647178075, 0.6162203176217613, 0.21540826118668244, 0.6499992954286005, 0.5920147180523607, 0.13367462986243395, 0.5810318345249562, 0.35072235832687515, 0.36817035973293344, 0.5277854784111609, 0.014822481291476786, 0.5285000690540047, 0.04132173516397286, 0.6512040325663568, 0.34734137864289527, 0.3498285984480014, 0.6507698260475001, 0.5354703005594958, 0.5076797772836159, 0.12000997613822295, 0.12175453972737671, 0.13846230608738952, 0.06853185946056961, 0.09639694698524526, 0.08172739214702673, 0.15114811768212144, 0.1110753656541974, 0.0925426499046369, 0.19163678705971732, 0.11341340633531449, 0.1046397698255731, 0.5334657675938494, 0.5497659172580223, 0.2045808383492046, 0.34947965189042596, 0.17873208853523614, 0.3915250587230973, 0.34666025533866374, 0.4676478354235024, 0.4589802477528143, 0.4866993458579195, 0.5312657043113183, 0.4928459309786626, 0.5445365508809483, 0.3960437700285889, 0.4131884130947828, 0.6643903562737061, 0.7861418067115693, 0.8084228474496885, 0.7793230934920117, 0.7966479203522617, 0.7863881139257743, 0.7715900806405529, 0.778539823974718, 0.8281816734807076, 0.0918996711011103, 0.09877196676920119, 0.08874303604861711, 0.09161436042296323, 0.08136139684257193, 0.08640539215225784, 0.0881334940861841, 0.10268818382127243, 0.0981351971408625, 0.13506434713536697, 0.1515448729815897, 0.24684634107717307, 0.14311114262614466, 0.14125619370056575, 0.3635093698779386, 0.1385257128578372, 0.14240206290355817, 0.1355352781089858, 0.36917900558592887, 0.41295726937187005, 0.3154188696319773, 0.36578107747030497, 0.31601428877521653, 0.2821232434363976, 0.3462112977338552, 0.4449176873076617, 0.31795753817837236, 0.25890957784394253, 0.2658308799915914, 0.2675456226024867, 0.2670050054573174, 0.27254527128016803, 0.28696162055961827, 0.23859561382946182, 0.20508754761596282, 0.21693712871027504, 0.22393141643099757, 0.2093896129171794, 0.19534720459646693, 0.1875031115669622, 0.19655151895434841, 0.1995010071891854, 0.24652639534315646, 0.19566618428180993, 0.20086272543637773, 0.17996985626028472, 0.1733059921179596, 0.18544071905885617, 0.18091556901734662, 0.19601546264621506, 0.18429188106073924, 0.1802237873167809, 0.17749067261337803, 0.1814150932219487, 0.16790370323636672, 0.13700333746676874, 0.18798251344252626, 0.25465882516861915, 0.11251569061669475, 0.06195736121941131, 0.10844492011293916, 0.11539635329329212, 0.1679757307819293, 0.9092061871259115, 0.11330628995217107, 0.07470532371094218, 0.1689555118903996, 0.2105062448836338, 0.10964117318970734, 0.15266116496777926, 0.16111052747759347, 0.8842952216887596, 0.19787910695861288, 0.1755555489653421, 0.17898912356561414, 0.18551946106308925, 0.178132609872514, 0.200623280797112, 0.19777465898479918, 0.18571648012704656, 0.1890567748439579, 0.07447559490759104, 0.1103887086576113, 0.0775128836441108, 0.06805950066870903, 0.10216033936920044, 0.0818471689160466, 0.08823977908982705, 0.07695783038107873, 0.09209674397649559]}, "mutation_prompt": null}
{"id": "dd90cf7b-7f6b-44f5-81ec-8662b263dd34", "solution": "import numpy as np\n\nclass AdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Probabilistic dynamic recombination for enhanced diversity\n                if np.random.rand() < 0.25:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.5 * (samples[i] + samples[crossover_idx])\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n            # Probabilistic step-size adaptation\n            if np.random.rand() < 0.25:\n                self.adaptive_step_size *= 1 + np.random.uniform(-0.1, 0.1)\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "AdaptiveCMAESOptimizer", "description": "Adaptive CMA-ES with probabilistic step-size adaptation and dynamic selection for improved diversity.", "configspace": "", "generation": 98, "fitness": 0.35930512729679215, "feedback": "The algorithm AdaptiveCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.28.", "error": "", "parent_id": "2cc5622c-cea9-404c-8f0a-5abc58447bdd", "metadata": {"aucs": [0.9193015928240095, 0.9086958575205077, 0.9463375649042882, 0.9037531911527809, 0.9263469298149388, 0.927778645855478, 0.9347335529428882, 0.9360585762737235, 0.9180562981833391, 0.5087513667603054, 0.6071527515422728, 0.6640592031037811, 0.4711165569480211, 0.5667150473478828, 0.5684608576109148, 0.6600848732990761, 0.6125716171725282, 0.5366646151214463, 0.0894003523054111, 0.08608204358186466, 0.07866222765914022, 0.09074284414698708, 0.0908704329739457, 0.08735639030995335, 0.08858512562262133, 0.09587424904009423, 0.0995760519234209, 0.08187427926863222, 0.07801492986009162, 0.07600483392687762, 0.07995718178033462, 0.06399108191632696, 0.08764249143692304, 0.07650347046674233, 0.07410758291455133, 0.08405288740732197, 0.21992008379288974, 0.9299777209862878, 0.9039604193464134, 0.9455813876283932, 0.7612206534574338, 0.9850412635332105, 0.9472488941167986, 0.9618285602880751, 0.942704856376243, 0.13376726547284912, 0.11020536025968053, 0.12239906776618414, 0.10787411783094647, 0.10097200139252704, 0.11345034066911452, 0.14224426464805984, 0.12242180017746929, 0.15855145297749185, 0.9192706910395945, 0.5887524747899314, 0.6534736093901332, 0.7562196819249538, 0.9114237646011628, 0.7924613903481296, 0.7812165879592923, 0.8899473729539482, 0.8745331094642308, 0.589293107278557, 0.5262768018114632, 0.7145292525170192, 0.4826648257401617, 0.43191560309139376, 0.43952760512445865, 0.6148108923404043, 0.4736241118925981, 0.5005778429419647, 0.5859883612801214, 0.5017893855201975, 0.4327143957522791, 0.1359540873542464, 0.6629877408416088, 0.5846792587259422, 0.13421575220748527, 0.5687240611391864, 0.615919930841569, 0.08218560181735757, 0.4895254210744783, 0.5214769107936905, 0.14513830317977494, 0.5876308668889425, 0.5581907375337143, 0.6509046960716204, 0.30711117441931235, 0.6047640456274934, 0.11804901593633554, 0.12303477613873015, 0.12197404767978692, 0.1218558541872713, 0.07276483589244731, 0.10814046049485093, 0.13068123605440507, 0.12454903011047613, 0.11119712158130224, 0.321736652950936, 0.08598738580099907, 0.299080400824426, 0.3748207240566138, 0.4462160538995772, 0.2869516703927214, 0.20472692728583286, 0.1459993615592875, 0.14900798974344764, 0.4328609755444087, 0.5403619899113281, 0.40035008717688303, 0.3608689459775014, 0.611108716048478, 0.44372910168729285, 0.4288729634704248, 0.5170010617162553, 0.3694906807427015, 0.7483004640172572, 0.822846082009256, 0.7894476578440804, 0.7649270017086021, 0.7707458980297683, 0.8179039316150887, 0.8099939918914643, 0.8279155678925075, 0.8237207433979338, 0.10287719212750746, 0.08504330395883786, 0.0902401619251515, 0.08931155840459248, 0.08512147408223503, 0.08214192078455729, 0.08690659900097475, 0.09815007778944707, 0.10256353732658041, 0.12155420846012743, 0.1418217794895128, 0.1522113926719676, 0.12090654547148638, 0.15392943746785437, 0.15182735389366775, 0.4510526569758554, 0.1601116529548714, 0.1926011685643415, 0.24662719999464677, 0.43735127036275023, 0.45142756956668373, 0.4414365367698714, 0.39719020220564805, 0.48102427927945435, 0.4966675457124776, 0.4554619613921813, 0.44075284940818904, 0.37462074485079777, 0.3168657763613323, 0.3010912687483843, 0.3027528820015768, 0.3017585003243548, 0.33044700220412526, 0.26084467873514483, 0.21818938442586933, 0.2154770957511265, 0.19295108490861224, 0.1805372741175978, 0.20100234943188489, 0.18205908061770837, 0.2026299298952814, 0.18217362900161638, 0.20017229262514602, 0.1860222536366536, 0.21353098331783527, 0.2046602849574809, 0.1796861614395575, 0.16964714169881245, 0.17400444203342447, 0.17786494107937667, 0.18808876965398857, 0.17278724328649664, 0.17381224956370112, 0.1767432499746907, 0.18654579585342157, 0.13769109836947302, 0.18341990151203347, 0.17077972156832677, 0.19897949464873455, 0.188593972993774, 0.10862469630609173, 0.11539319392178526, 0.16237863266881358, 0.8988827514877327, 0.1136010736504941, 0.08301268147940832, 0.2287389696856411, 0.21094199013312287, 0.20882074782184534, 0.9088416977920764, 0.1642317906182258, 0.21056043962778004, 0.18686491509373904, 0.17959470317923387, 0.1970184196510154, 0.18435649602337123, 0.18065184940664536, 0.18278056273549725, 0.1786987968834719, 0.17541564634477513, 0.17608402892835473, 0.06970047605432972, 0.07164801433492829, 0.08224894812117489, 0.07811117488001307, 0.07921639421531035, 0.07490259782261799, 0.07761402502394665, 0.09171712466189441, 0.09356661473537153]}, "mutation_prompt": null}
{"id": "004d6650-8f7b-4e0f-95df-5d951bc27889", "solution": "import numpy as np\n\nclass StochasticAdaptiveCMAESOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 4 + int(3 * np.log(self.dim))\n        self.covariance_matrix = np.eye(self.dim)\n        self.adaptive_step_size = 0.5\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.eval_count = 0\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))\n        weights /= np.sum(weights)\n        mu_eff = 1.0 / np.sum(weights**2)\n        c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 3)\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n        c_1 = 2 / ((self.dim + 1.5)**2 + mu_eff)\n        c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n        p_c = np.zeros(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            samples = np.random.multivariate_normal(self.mean, self.adaptive_step_size**2 * self.covariance_matrix, self.population_size)\n            samples = np.clip(samples, self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                if np.random.rand() < 0.25:\n                    crossover_idx = np.random.randint(0, self.population_size)\n                    samples[i] = 0.5 * (samples[i] + samples[crossover_idx])\n                self.fitness[i] = func(samples[i])\n                self.eval_count += 1\n\n            indices = np.argsort(self.fitness)\n            selected = samples[indices[:len(weights)]]\n            self.mean = np.dot(weights, selected)\n\n            y_k = (selected - self.mean) / self.adaptive_step_size\n            c_y = np.sum(weights[:, None, None] * (y_k[:, :, None] @ y_k[:, None, :]), axis=0)\n            self.covariance_matrix = (1 - c_1 - c_mu) * self.covariance_matrix + c_1 * (p_c[:, None] @ p_c[None, :]) + c_mu * c_y\n\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * np.linalg.solve(np.linalg.cholesky(self.covariance_matrix), self.mean - selected[0]) / self.adaptive_step_size\n            self.adaptive_step_size *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n            if np.random.rand() < 0.25:\n                self.adaptive_step_size *= 1 + np.random.uniform(-0.2, 0.2)\n\n        best_idx = np.argmin(self.fitness)\n        return samples[best_idx], self.fitness[best_idx]", "name": "StochasticAdaptiveCMAESOptimizer", "description": "Stochastic Adaptive CMA-ES with enhanced diversity mechanisms and dynamic learning rate adjustments.", "configspace": "", "generation": 99, "fitness": 0.3582637265912798, "feedback": "The algorithm StochasticAdaptiveCMAESOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.28.", "error": "", "parent_id": "dd90cf7b-7f6b-44f5-81ec-8662b263dd34", "metadata": {"aucs": [0.9405808456935808, 0.9235105045966492, 0.9230209691928686, 0.9122398680553496, 0.9373432650305701, 0.924894801936905, 0.9314446720997037, 0.9396612972486428, 0.9237062912980507, 0.593026079593101, 0.6290084203513919, 0.6534624077581115, 0.5940836768278788, 0.5628401168091676, 0.6645600082716793, 0.6324729220508258, 0.5238449746423297, 0.695106485117514, 0.08761133657904885, 0.0960816393872801, 0.1043408771532186, 0.09802486386092912, 0.08294358187422346, 0.09635360772312884, 0.09137072604335394, 0.1024676202307383, 0.11536976450011804, 0.09571930106397109, 0.08241728832040951, 0.08868665123900266, 0.0769524039434013, 0.07311805264118154, 0.08257265013147697, 0.08177452333766, 0.06375993996901275, 0.06846405821722568, 0.9682956254475861, 0.95766290490569, 0.7767784873835557, 0.9766110261423347, 0.7556931969781817, 0.9262694589803474, 0.26505403673578654, 0.9512440613654363, 0.25586023463750074, 0.1629773363146172, 0.11523678420980776, 0.11832629343296663, 0.11014811971095273, 0.14082419042202532, 0.11461626496161825, 0.13720091984244942, 0.14905899060195005, 0.14997135240246628, 0.7797128547095915, 0.9182407971391461, 0.696975100617045, 0.6887768241787824, 0.6976664314819387, 0.9291142073729469, 0.7205542370452125, 0.8672888091143583, 0.8575060780112316, 0.5469214902852035, 0.5750736718889797, 0.5362206464458774, 0.6433714500128953, 0.4399233849453208, 0.6135686182652325, 0.5721808119338967, 0.13404912601801244, 0.5413436423574169, 0.5032781012897787, 0.512864347847922, 0.6263058802129118, 0.4570147254867234, 0.5806421947883531, 0.5477893189991833, 0.5840587695523382, 0.5452584682590962, 0.5801485298128854, 0.585552545020245, 0.5047619130053715, 0.5813328848690185, 0.6729308276403614, 0.08380887492186306, 0.5909621008404236, 0.4554821189497442, 0.6429944233266487, 0.6430689843474484, 0.10227946798797971, 0.10469253424318636, 0.12264187176017227, 0.09003278686970939, 0.07509670052805706, 0.11242029829783218, 0.12605309130442255, 0.08985321797181767, 0.1126413916353578, 0.0780082532415749, 0.06464355795304877, 0.294291540662208, 0.2527596115226697, 0.5575326986414326, 0.11029551668798432, 0.14526228377817407, 0.3316197579550827, 0.2212654248094349, 0.4563691316240024, 0.4289681768857988, 0.5056037730110838, 0.4299443605531975, 0.546914097394995, 0.45176925096176324, 0.4365654173638108, 0.45494474812451646, 0.41482277265008083, 0.7764423032869776, 0.8051619082284742, 0.7905241834276507, 0.7511626349681559, 0.8107406201319945, 0.7865380173985755, 0.7979793328728287, 0.7921567658567841, 0.8336595426199774, 0.09282096627825853, 0.10165418449366503, 0.10866697056542818, 0.08541295780962899, 0.07927678343265465, 0.09616646500292103, 0.08599019145844955, 0.0942216143619411, 0.1059657400358035, 0.13870519730608755, 0.14660276536589445, 0.1828405122505773, 0.13526266879342475, 0.17140145880350488, 0.1270064372811912, 0.13290391745255348, 0.1422407634413676, 0.15909707165624332, 0.47079525507177367, 0.30465830803426985, 0.4176627066082703, 0.2851247613756698, 0.3816791396913196, 0.37730479638131065, 0.4022601350770608, 0.4249369555118623, 0.3429936356709975, 0.38381126002243104, 0.3024774327018457, 0.3513918859759385, 0.2861555500804541, 0.36642677137985213, 0.3155720982659309, 0.4134029757063665, 0.2846743582103157, 0.3483631297796297, 0.20136554056430434, 0.19761899916063597, 0.21106483901464168, 0.18847692115634962, 0.19927098199444515, 0.20742021184353265, 0.19365795396208996, 0.22815649139921257, 0.19880651539699778, 0.17881792599834867, 0.18738148272647626, 0.1764059107327408, 0.18064102392735182, 0.17879461383659434, 0.1763039167119559, 0.17062857063301706, 0.1745320387815118, 0.17941252640360728, 0.16915247866297556, 0.13737341800092073, 0.18398149949360987, 0.20684947989047953, 0.11225714730504455, 0.9360787326705918, 0.10861427881369234, 0.11538995038125699, 0.1541774485025701, 0.2314943644987506, 0.11344826471088543, 0.0976301101830388, 0.16892706979744432, 0.21232885779841637, 0.24494170657490633, 0.1535161800503333, 0.2041417365413094, 0.1392234967812327, 0.19412750350920005, 0.17337271698497858, 0.20485885344199584, 0.177671857788407, 0.1914020694784142, 0.1909389851712916, 0.188263881683021, 0.18246177526183394, 0.20304027442231254, 0.07114613726784269, 0.0805476654867825, 0.07237418790558281, 0.07715278352799693, 0.06931924638345754, 0.08420793161056717, 0.06887806757975501, 0.0702008797518513, 0.07772360875579021]}, "mutation_prompt": null}

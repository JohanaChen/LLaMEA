{"id": "505ef0f6-5723-4925-87bf-884720d030d2", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            # Apply DE operator\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                mutant = self.particles[a] + self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "HybridDEPSO", "description": "A novel hybrid algorithm combining Differential Evolution and Particle Swarm Optimization to enhance exploration and exploitation balance for robust performance across diverse landscapes.", "configspace": "", "generation": 0, "fitness": 0.3167043466098378, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.29.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8900990019477379, 0.89092769490346, 0.9066460668214018, 0.9176130674635412, 0.9088491650975551, 0.9118050120239517, 0.9113793151900564, 0.9077960934658549, 0.892755696991544, 0.07872738393196355, 9.999999999998899e-05, 0.7793079666180738, 0.7919231152003227, 0.048059449619653805, 0.04817963447965434, 0.7727701840881872, 0.7722849488055272, 0.8080043421399508, 0.15658068252900392, 0.09678472870993593, 0.7946922575503073, 0.07208846483799458, 0.10968335727136524, 0.14355066161877406, 0.11543957757156409, 0.16379919854183167, 0.10067459325452965, 0.13688053548089707, 0.14021883638400445, 0.10048986199350018, 0.08969782138031146, 0.13143797114156808, 0.1167953471393115, 0.10596685256440619, 0.13238334807776497, 0.11477382102802147, 0.9876236145145476, 0.991374311622188, 0.9911783099568188, 0.9841530986438018, 0.9889551696119183, 0.9917552820443163, 0.9922579901640847, 0.988897639501434, 0.9926520346659433, 0.6662251163513542, 0.8094850799302723, 0.7675146011318694, 0.7344955616256368, 0.7358461806478355, 0.7700175797157736, 0.08861573543243173, 0.08910070729877972, 0.7743054263250162, 0.17176747306475915, 0.22283188078542526, 0.8785699641778988, 0.2150351838578134, 0.21291281117417038, 0.27731776369750427, 0.23146059852125744, 0.17554747705947338, 0.9166197411619681, 9.999999999998899e-05, 0.2732595094479293, 0.3004746296240377, 0.2868221603400891, 0.5001871901832114, 0.28766326815886, 0.27833980787727, 0.29556469077425396, 0.16116234266372254, 0.2524948210735912, 0.19503544433693631, 0.26926156354343145, 0.13180034975050525, 0.35199453632242694, 0.3027071561762362, 0.29694602140291815, 0.03499927363969324, 0.31477786282058373, 9.999999999998899e-05, 0.01452693343926148, 0.00010783751716769707, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008947401081708217, 0.0024279115096170756, 0.00013024716362797228, 0.046201196307257164, 0.030143940331972097, 0.08565291702263389, 0.06838898877404431, 0.003931646707601266, 0.019915189240502285, 0.06936507626246236, 0.021915525967728722, 0.11821276794774638, 0.05082456924008871, 0.08120513640448423, 0.20749252621183656, 0.08037030213335161, 0.09994147209313209, 0.09873089702055315, 0.1238420545345511, 0.14343721970508228, 0.07622150970491037, 0.09931007948954229, 0.1654845881649466, 0.33210023016836454, 0.2464346370701146, 0.2524826524160968, 0.13048714634784353, 0.05002093248825146, 0.137787535658621, 0.08405218530927216, 0.5951015314307353, 0.6221144149410612, 0.5507124555997577, 0.5619061187922376, 0.5941185204757871, 0.5641010231585922, 0.6094879377972506, 0.6084193430742164, 0.5890233387477107, 0.10965505338761339, 0.11712238154351129, 0.06450160734466193, 0.13022842326579542, 0.0841915091999128, 0.13240434576072713, 0.13576807249884348, 0.1399656532652791, 0.1598690072726756, 0.18773354636476947, 0.14623063027913885, 0.23812143897725935, 0.2248930821797649, 0.3592001037688345, 0.16401206778713584, 0.3844719706140769, 0.19428689649314101, 0.2309821741526511, 0.5536109303504454, 0.3676757501951414, 0.36636217675008975, 0.22870890285873924, 0.4249648596656641, 0.5438837045379954, 0.5425330265131443, 0.5897774276331924, 0.2557257946074083, 0.32344254480536816, 0.23729262664622697, 0.16020558081841862, 0.19429341466063976, 0.30086088427896307, 0.2207051488849161, 0.16430523425964183, 0.41096596546173625, 0.26061483452712264, 0.2195211202919023, 0.18850699037145213, 0.21993287328194944, 0.2924386840741149, 0.23960903525720378, 0.2475178999712272, 0.23658397498283557, 0.21535516057054616, 0.22266621610095216, 0.20202492044753284, 0.24811870363320265, 0.20016898873791877, 0.20337917295478836, 0.16868351201867715, 0.19090650130856346, 0.22628291961053204, 0.24806423452376913, 0.22618066274447923, 0.18759049242833592, 0.9151101152989991, 0.15455888964520437, 0.17241191141566325, 0.20106945842832358, 0.9339419096810264, 0.10012068844053279, 0.9008442349073164, 0.1698294417564291, 0.08304988231696098, 0.16898457641396103, 0.21166223404721807, 0.20871311375368085, 0.1689983504557646, 0.8815652922715175, 0.9156390842930975, 0.29094438342639495, 0.20250967422088428, 0.20139492935947434, 0.2002007244445203, 0.1925111624446919, 0.20246837154995978, 0.20015555394143425, 0.21613618534487022, 0.18870690807144397, 0.23433309615266473, 0.19944490508725599, 0.09482165299076928, 0.09408031443849108, 0.09822988791816711, 0.0947806650683668, 0.09713310231948014, 0.11867060746285119, 0.09539325231788387, 0.09526075534469214, 0.086613763639108]}, "mutation_prompt": null}
{"id": "3ef5b86c-3af2-4c9a-8eee-32aade25ad1a", "solution": "import numpy as np\n\nclass AdvancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5  # diversity threshold for adaptive learning\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            # Apply DE operator\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                mutant = self.particles[a] + self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Check diversity for adaptive PSO\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9  # adapt inertia weight\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "AdvancedHybridDEPSO", "description": "An advanced hybrid approach integrating Differential Evolution, Particle Swarm Optimization, and adaptive learning to enhance convergence speed and solution accuracy in diverse optimization landscapes.", "configspace": "", "generation": 1, "fitness": 0.3369598462139385, "feedback": "The algorithm AdvancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.", "error": "", "parent_id": "505ef0f6-5723-4925-87bf-884720d030d2", "metadata": {"aucs": [0.9111671634088075, 0.9131451943353056, 0.9255458854056, 0.9080122357346663, 0.9094559080304299, 0.9172445817437981, 0.9145163603411455, 0.9259497558932204, 0.9146587915505511, 0.8101621400259534, 0.8168549070823822, 0.7903581394833029, 0.7966728825285446, 0.8286205925870541, 0.8107824461917078, 0.8157799063137245, 0.8085430258635509, 0.8151248805326197, 0.14285115144011595, 0.1325894023446781, 0.09270884879253571, 0.13457332797023103, 0.13481855045299684, 0.14542898521429193, 0.14703580463925936, 0.11892595839356801, 0.1156811520285459, 0.17717043918630804, 0.08303399845658621, 0.1339919622186484, 0.14514893904389847, 0.0956575186901133, 0.11054469334823624, 0.14661649659128784, 0.08052401437218848, 0.11102297919645499, 0.9784159322775751, 0.9658090402324563, 0.9632936052267986, 0.984751528501409, 0.9809645705318761, 0.9787844889803349, 0.9859297327016984, 0.9783229444812245, 0.98371800000141, 0.8099295652500718, 0.8211245485386591, 0.8150342508289312, 0.8195343690437298, 0.7911790978662144, 0.7818602995278601, 0.08894778567662798, 0.7832896890004528, 0.8105934325759209, 0.3997670932054269, 0.22935832249187038, 0.21380614518815033, 0.2224262098467742, 0.19335091685301886, 0.2783486612213639, 0.17940669974563805, 0.39510326530093964, 0.9288236218218956, 0.274714276233462, 0.2567092674090372, 0.2888863825437036, 0.285585227342003, 0.2858525797078242, 0.3903256476929361, 0.3002895576830724, 0.1341210030882778, 0.31393748468412563, 0.2732625106774037, 0.2729488361967741, 0.2151622706023537, 0.31527599105399406, 0.30414435346353663, 0.3272464874894925, 0.3035884953158393, 0.3043787494304526, 0.31032995578681954, 0.01118322273000083, 0.03867522107624133, 0.003142693264613028, 9.999999999998899e-05, 9.999999999998899e-05, 0.06313372272485651, 0.04179319496781886, 0.01460784712994978, 9.999999999998899e-05, 0.07146379686700566, 0.16434292877049905, 0.1596287792279527, 0.17052860085547272, 0.049163716730877605, 0.028519534587570172, 0.2673345291121938, 0.08775993627820022, 0.07283812266485479, 0.06722545951049053, 0.06969303705664165, 0.049009284194444946, 0.08040441193400238, 0.12246758714057238, 0.4082643449022111, 0.09942137980727783, 0.10455341976538657, 0.11952046110330172, 0.146156973343457, 0.08233808905789974, 0.14661976649177633, 0.06671822970286267, 0.21212539083691906, 0.3592911328045638, 0.3666877723072215, 0.34713810023018377, 0.08452857920811907, 0.5692637978646483, 0.5771004036526453, 0.6199707596107583, 0.5934513198104745, 0.6191551564095095, 0.5792014858723108, 0.6161234557540658, 0.5891730249620946, 0.6248540751851932, 0.09662793871587327, 0.15636932710691276, 0.18330672558269556, 0.16135461407596663, 0.11088672343791806, 0.11645150487758582, 0.13044903036756272, 0.13298773177018341, 0.08640156156381129, 0.27186516418935625, 0.26553639440067245, 0.26949371466285776, 0.2566782874751029, 0.23874113151669585, 0.17625600999502333, 0.2615305013067456, 0.32345854355205317, 0.22579089997039736, 0.4525342499316979, 0.3883892537322631, 0.3429303061813298, 0.4174538031015883, 0.2372123989823558, 0.4725843055639206, 0.5487476328469583, 0.5733429529884178, 0.2505716895104255, 0.22147460239647287, 0.35175311390257136, 0.17389759816019468, 0.2263795949845444, 0.2835740147611415, 0.3009765590587511, 0.22811116492443284, 0.2707445144615708, 0.21776032923941635, 0.2195403200515118, 0.22206755336781248, 0.25415514563707764, 0.27694840547322586, 0.22141647679661436, 0.24073433139181288, 0.22044856742353747, 0.2156926608882629, 0.22726311543660238, 0.22743248938405702, 0.22792940002893292, 0.19002279325790672, 0.21115765430600253, 0.21137801210085205, 0.19244396283119314, 0.22553877311996873, 0.20878079954353368, 0.21059975683644494, 0.18823165236482076, 0.18827555214745761, 0.1539093643203825, 0.17278902935755136, 0.20157919753871278, 0.1486685662050653, 0.10003091421465526, 0.9384214834734638, 0.15897617417144883, 0.8655260131025424, 0.21282326613787872, 0.8076298134747878, 0.21220819793564127, 0.08314325647451914, 0.9064233195287974, 0.10529982772678437, 0.16860093478239246, 0.16740817366833394, 0.2007530010733224, 0.1891678309568563, 0.2010543902452312, 0.21206937582534802, 0.19848777592093725, 0.20624506645998475, 0.20219997675065904, 0.18742044640015687, 0.20477268226141565, 0.16635009588326644, 0.07897866422258815, 0.08601726771705631, 0.09012673775880153, 0.10370934176699831, 0.09212141606675939, 0.08576004348954958, 0.09681302843857209, 0.11073613891826739]}, "mutation_prompt": null}
{"id": "bff7a8af-1481-425e-89dd-764efb7916b6", "solution": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.85  # DE scaling factor\n        self.cr = 0.85  # DE crossover probability\n        self.w = 0.6  # inertia weight for PSO\n        self.c1 = 1.4  # cognitive coefficient for PSO\n        self.c2 = 1.6  # social coefficient for PSO\n        self.vel_max = 0.9  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-4  # diversity threshold for adaptive learning\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            # Apply DE operator\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                mutant = self.particles[a] + self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Check diversity for adaptive PSO\n            diversity = np.std(self.particles, axis=0).mean()\n            if diversity < self.diversity_threshold:\n                self.w *= 0.95  # adapt inertia weight\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "RefinedHybridDEPSO", "description": "A refined hybrid approach using Differential Evolution and Particle Swarm Optimization with enhanced adaptive mechanisms for robust convergence in diverse optimization landscapes.", "configspace": "", "generation": 2, "fitness": 0.3167115203052916, "feedback": "The algorithm RefinedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.28.", "error": "", "parent_id": "3ef5b86c-3af2-4c9a-8eee-32aade25ad1a", "metadata": {"aucs": [0.8883912194903439, 0.8820159689753467, 0.8365042683236117, 0.18292495851941226, 0.863130739774528, 0.8800069065853745, 0.8705116892536416, 0.8959035401187955, 0.8675656114051249, 0.7171769962924825, 0.7488807414755736, 0.7525576957252036, 0.6872029237048645, 0.7327244397551894, 0.7182372492919333, 0.7401249887255649, 0.7370139115995631, 0.6480644151058179, 0.14152646258840795, 0.15914717823004598, 0.09475384669596587, 0.11840163168450601, 0.12412323498747391, 0.1450361338417906, 0.1190435650042595, 0.1021317104281072, 0.1843769274785907, 0.09966600442906692, 0.12354827503375398, 0.13004743230886984, 0.0963478410869657, 0.0696611017411819, 0.14222982349775104, 0.15289031980429812, 0.08890551877704178, 0.11328785226319449, 0.9766336870854069, 0.9701566263089519, 0.9638860204431117, 0.9756197494095402, 0.9811342102938786, 0.9778724124373082, 0.9857735971113315, 0.9740402207483229, 0.9805808071015114, 0.6639318160558312, 0.05955041244776893, 0.7333725246377576, 0.7589395509202785, 0.7038326843050582, 0.15386584013732607, 0.7001523143040431, 0.08883733358824597, 0.6954513457952123, 0.2298976249438196, 0.22992262480160053, 0.1406921231955297, 0.19408327519767055, 0.3827938875219342, 0.38587466628108313, 0.24375176974348867, 0.21912226649100852, 0.18000967985970895, 0.24061577747498508, 0.13294080047719858, 0.13271495747656303, 0.27234787236152047, 0.25950645015857576, 0.25025180096284527, 0.3138497032684925, 0.13384529663775757, 0.23370661349714072, 0.2135175058405252, 0.2550526416747694, 0.18886787459534593, 0.13355291777545408, 0.2967215617235258, 0.26770462271254714, 0.2871946010998877, 0.26071606461017593, 0.2822284430228228, 0.0032517033830384845, 0.058054021541522394, 0.0017274633232194914, 0.009731117807758705, 0.009250185720334092, 0.03696169203436617, 0.0043929582557595825, 0.011030447110446984, 0.04242495001177704, 0.1482434803981505, 0.07789033093196107, 0.08460972247296228, 0.06806568447766803, 0.0523069764732359, 0.042679313777486794, 0.1320654528975891, 0.06561837704817786, 0.09242720009043737, 0.10253237466703413, 0.07263016469803496, 0.07811912673682786, 0.07627904389686024, 0.13913845577852058, 0.19565932974742795, 0.09685805858158869, 0.2512306871595178, 0.1028304571377675, 0.10131072513946893, 0.05396226139263394, 0.3941595613190152, 0.174368926469456, 0.05360878255183976, 9.999999999998899e-05, 0.08268504336340776, 0.04958721905105956, 0.09397705235266529, 0.549698099320204, 0.5760189443619288, 0.5581738541637575, 0.6000111727388778, 0.5787204352736178, 0.5464520091398433, 0.5646328081770908, 0.5718921240469242, 0.5714743997096134, 0.09955509944379137, 0.11187937536060344, 0.12304022858452501, 0.11713919955696162, 0.1405899129458128, 0.15798072975718647, 0.09524677662111303, 0.13576888545456145, 0.14040662346034682, 0.1449498602718875, 0.6541571813044318, 0.23739763457725271, 0.1680000619081935, 0.36034246629473754, 0.20990839136518502, 0.3181279442151409, 0.3555608592484084, 0.18609113194344062, 0.6039573374580124, 0.5319675488173816, 0.24223647287281036, 0.32833420382302914, 0.28780407561941546, 0.36572803067168247, 0.4932755929154633, 0.5905368649053206, 0.24577905099158515, 0.2656852693349986, 0.32225201624643396, 0.2403454114390039, 0.3165318970397146, 0.24393063615094257, 0.27280546690042773, 0.3314061217206248, 0.2661998988365296, 0.20087180808940774, 0.24844599410947443, 0.23163479589452185, 0.20610212070430078, 0.2720883672696024, 0.22908960911309428, 0.2581970492612411, 0.3126079753182536, 0.206771306782235, 0.20131172396094987, 0.19925201140808868, 0.20436531404079727, 0.19508020030376716, 0.2296076869185374, 0.7620971678350165, 0.20832435423483298, 0.18985016422438572, 0.1986650762830786, 0.19731743347741681, 0.9095632024299874, 0.17751029922733885, 0.16196417884837122, 0.1877919358006136, 0.20059722736694474, 0.925882990302967, 0.12269735236343582, 0.16963341287373424, 0.1679616359376741, 0.8368859086092035, 0.705218645894958, 0.7649902562736793, 0.8004058050389701, 0.16907445844659708, 0.8581398951332457, 0.10514474544220997, 0.15567996205147316, 0.1679598116399309, 0.19747530024457294, 0.19767747638953603, 0.1976528196073456, 0.19471290036608024, 0.18261763203071468, 0.1822744458668789, 0.20209924734373386, 0.19457413819362845, 0.19703828354805564, 0.09471419956941951, 0.10288267102119553, 0.09485947882443124, 0.08669511499152538, 0.10241773487266781, 0.09193419323860219, 0.1070217718850337, 0.11093166043903524, 0.09238928127184098]}, "mutation_prompt": null}
{"id": "9c751e1d-a049-41ae-b327-2b58f66e4104", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.7  # inertia weight for PSO\n        self.c1 = 2.0  # cognitive coefficient for PSO\n        self.c2 = 2.0  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5  # diversity threshold for adaptive learning\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            # Apply DE operator\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                mutant = self.particles[a] + self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Check diversity for adaptive PSO\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.95  # adapt inertia weight\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedAdaptiveDEPSO", "description": "A refined hybrid algorithm combining Differential Evolution and Particle Swarm Optimization with dynamic parameter adaptation to enhance exploration and exploitation capabilities for diverse optimization problems.", "configspace": "", "generation": 3, "fitness": 0.2580549587240957, "feedback": "The algorithm EnhancedAdaptiveDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.22.", "error": "", "parent_id": "3ef5b86c-3af2-4c9a-8eee-32aade25ad1a", "metadata": {"aucs": [0.5516173788399623, 0.5581646910526181, 0.5804929158866252, 0.5550564113180241, 0.46971246613680917, 0.5174220058677859, 0.5826758809539698, 0.5965809210150155, 0.4578547298789015, 0.18319888749935076, 0.15710333042657387, 0.18345984170510943, 0.2586604437631852, 0.2453438647904863, 0.1536213841903471, 0.2763223960930141, 0.24683166146145263, 0.1830977585452669, 0.1302900017462031, 0.12450382282249006, 0.10518028479237995, 0.15626028359540356, 0.11985477957711932, 0.15380455702362272, 0.14312566824295392, 0.1478658034633007, 0.1778483489329068, 0.11244053993592118, 0.12068786593339609, 0.13297073195833453, 0.14145882149705613, 0.12141423819922459, 0.10692117319223637, 0.10618786317709128, 0.12168137935712275, 0.12651459841171486, 0.9784109396626012, 0.9636539517567331, 0.9697194164057122, 0.9838663377169924, 0.9807026355790093, 0.982112071946038, 0.9874099603828322, 0.9783010704240431, 0.9862793721307402, 0.37460697182385994, 0.05988802189498843, 0.3427784874556985, 0.385702087211671, 0.3053774283178661, 0.3311270747523025, 0.329705172628457, 0.3068453098324808, 0.34297491569766014, 0.46507749315598435, 0.7162151231435228, 0.502489938824817, 0.23083618790628357, 0.35538541885071084, 0.3502734858821981, 0.5190177939178352, 0.5188486969999249, 0.38072604764517315, 0.13558422889378652, 0.1577614077354843, 0.17841076882675388, 0.18116498471092768, 0.19836225205122615, 0.24657335529760382, 0.3603660410839039, 0.13357284230683586, 0.21451620532771432, 0.19704980263216976, 0.1621817814789811, 0.174679136588214, 0.18149800549196327, 0.12853731009871117, 0.20736188794146393, 0.175032815604797, 0.12268486928659372, 0.16143865127712742, 0.02048925436627247, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06996186547496486, 0.10730359301354497, 0.03462843453410713, 0.14298957982723637, 0.1277145005668181, 0.10358067538252913, 0.016684479123967533, 0.018210655849655977, 0.06489321913537971, 0.18317655743653927, 0.12671636298431765, 0.0634717372469038, 0.042336937241160943, 0.03349268768468738, 0.03659710863329524, 0.0365241208907493, 0.055119508741214296, 0.048983883741112955, 0.16465610865383118, 0.06214502273963429, 0.013754306947329487, 0.1633156461908053, 0.11121080727292743, 0.08951741203234065, 0.1319542405136077, 0.2081482932419828, 0.16851541233834855, 0.0864800766749726, 0.048818067226685136, 0.07729352899254538, 0.4756578957478279, 0.4499231760583249, 0.4447634193416534, 0.44936217609618223, 0.4627466239100938, 0.44912391090395554, 0.4665347875300788, 0.4543992435129399, 0.4403286811795649, 0.1509539220210352, 0.13727318168835423, 0.17412317207872807, 0.1333460653558397, 0.15194057661707372, 0.11728506956060936, 0.11839624672318527, 0.12111924176442312, 0.09519527412031492, 0.345984544943568, 0.1815350768620596, 0.24730437119268145, 0.23437573082417418, 0.24252451446785295, 0.2491045435657958, 0.1844761255674353, 0.214826671007473, 0.22647402284025464, 0.3221894181700994, 0.3100344481027276, 0.3053756950707549, 0.32602770749161547, 0.22935840153819487, 0.2850900465527396, 0.22742062185323797, 0.33775663984779025, 0.31402104636974815, 0.2253602766552809, 0.22730377820678027, 0.19570815071553294, 0.1674314203490994, 0.221595851467708, 0.19379393066430906, 0.2765831451464835, 0.2642488788347981, 0.18441910098513936, 0.22505423841461303, 0.21533352689833196, 0.24067011401810257, 0.27181375311778555, 0.22278409700711677, 0.217787164904923, 0.22631553677340355, 0.22172756674050997, 0.2141575624501324, 0.23049254917356643, 0.24240238601960018, 0.21111545300636758, 0.22703509274820421, 0.1959971504805369, 0.20796126085840883, 0.21744984406016388, 0.22130525401986179, 0.19649824305253216, 0.17628641150373692, 0.16839521127117096, 0.1752108680003397, 0.8455366007626162, 0.20057393000296675, 0.1479947346130671, 0.1000435281921167, 0.8269360958468381, 0.760874988644534, 0.46610765213913086, 0.21149633141306579, 0.4452440982652406, 0.20889018951411276, 0.4198810767367761, 0.7027254435002674, 0.11278542693754567, 0.1985190467181499, 0.1681408660111161, 0.19069485498459415, 0.19305711497377365, 0.20764024427916006, 0.19803567804383593, 0.20800303545170273, 0.2153312848492227, 0.19491516927723784, 0.21280317949680883, 0.19585033116731632, 0.1082849790134951, 0.09196586797236017, 0.092951451983729, 0.10062492995457029, 0.08563262448790632, 0.10020881005933224, 0.08729192005748554, 0.08311104762799915, 0.08860886884082542]}, "mutation_prompt": null}
{"id": "e88393bc-bb7e-486e-bd5b-f7ce6498570c", "solution": "import numpy as np\n\nclass AdvancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5  # diversity threshold for adaptive learning\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            # Apply DE operator\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                mutant = self.particles[a] + self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Check diversity for adaptive PSO\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9  # adapt inertia weight\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "AdvancedHybridDEPSO", "description": "An advanced hybrid approach integrating Differential Evolution, Particle Swarm Optimization, and adaptive learning to enhance convergence speed and solution accuracy in diverse optimization landscapes.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "3ef5b86c-3af2-4c9a-8eee-32aade25ad1a", "metadata": {"aucs": [0.9111671634088075, 0.9131451943353056, 0.9255458854056, 0.9080122357346663, 0.9094559080304299, 0.9172445817437981, 0.9145163603411455, 0.9259497558932204, 0.9146587915505511, 0.8101621400259534, 0.8168549070823822, 0.7903581394833029, 0.7966728825285446, 0.8286205925870541, 0.8107824461917078, 0.8157799063137245, 0.8085430258635509, 0.8151248805326197, 0.14285115144011595, 0.1325894023446781, 0.09270884879253571, 0.13457332797023103, 0.13481855045299684, 0.14542898521429193, 0.14703580463925936, 0.11892595839356801, 0.1156811520285459, 0.17717043918630804, 0.08303399845658621, 0.1339919622186484, 0.14514893904389847, 0.0956575186901133, 0.11054469334823624, 0.14661649659128784, 0.08052401437218848, 0.11102297919645499, 0.9784159322775751, 0.9658090402324563, 0.9632936052267986, 0.984751528501409, 0.9809645705318761, 0.9787844889803349, 0.9859297327016984, 0.9783229444812245, 0.98371800000141, 0.8099295652500718, 0.8211245485386591, 0.8150342508289312, 0.8195343690437298, 0.7911790978662144, 0.7818602995278601, 0.08894778567662798, 0.7832896890004528, 0.8105934325759209, 0.3997670932054269, 0.22935832249187038, 0.21380614518815033, 0.2224262098467742, 0.19335091685301886, 0.2783486612213639, 0.17940669974563805, 0.39510326530093964, 0.9288236218218956, 0.274714276233462, 0.2567092674090372, 0.2888863825437036, 0.285585227342003, 0.2858525797078242, 0.3903256476929361, 0.3002895576830724, 0.1341210030882778, 0.31393748468412563, 0.2732625106774037, 0.2729488361967741, 0.2151622706023537, 0.31527599105399406, 0.30414435346353663, 0.3272464874894925, 0.3035884953158393, 0.3043787494304526, 0.31032995578681954, 0.01118322273000083, 0.03867522107624133, 0.003142693264613028, 9.999999999998899e-05, 9.999999999998899e-05, 0.06313372272485651, 0.04179319496781886, 0.01460784712994978, 9.999999999998899e-05, 0.07146379686700566, 0.16434292877049905, 0.1596287792279527, 0.17052860085547272, 0.049163716730877605, 0.028519534587570172, 0.2673345291121938, 0.08775993627820022, 0.07283812266485479, 0.06722545951049053, 0.06969303705664165, 0.049009284194444946, 0.08040441193400238, 0.12246758714057238, 0.4082643449022111, 0.09942137980727783, 0.10455341976538657, 0.11952046110330172, 0.146156973343457, 0.08233808905789974, 0.14661976649177633, 0.06671822970286267, 0.21212539083691906, 0.3592911328045638, 0.3666877723072215, 0.34713810023018377, 0.08452857920811907, 0.5692637978646483, 0.5771004036526453, 0.6199707596107583, 0.5934513198104745, 0.6191551564095095, 0.5792014858723108, 0.6161234557540658, 0.5891730249620946, 0.6248540751851932, 0.09662793871587327, 0.15636932710691276, 0.18330672558269556, 0.16135461407596663, 0.11088672343791806, 0.11645150487758582, 0.13044903036756272, 0.13298773177018341, 0.08640156156381129, 0.27186516418935625, 0.26553639440067245, 0.26949371466285776, 0.2566782874751029, 0.23874113151669585, 0.17625600999502333, 0.2615305013067456, 0.32345854355205317, 0.22579089997039736, 0.4525342499316979, 0.3883892537322631, 0.3429303061813298, 0.4174538031015883, 0.2372123989823558, 0.4725843055639206, 0.5487476328469583, 0.5733429529884178, 0.2505716895104255, 0.22147460239647287, 0.35175311390257136, 0.17389759816019468, 0.2263795949845444, 0.2835740147611415, 0.3009765590587511, 0.22811116492443284, 0.2707445144615708, 0.21776032923941635, 0.2195403200515118, 0.22206755336781248, 0.25415514563707764, 0.27694840547322586, 0.22141647679661436, 0.24073433139181288, 0.22044856742353747, 0.2156926608882629, 0.22726311543660238, 0.22743248938405702, 0.22792940002893292, 0.19002279325790672, 0.21115765430600253, 0.21137801210085205, 0.19244396283119314, 0.22553877311996873, 0.20878079954353368, 0.21059975683644494, 0.18823165236482076, 0.18827555214745761, 0.1539093643203825, 0.17278902935755136, 0.20157919753871278, 0.1486685662050653, 0.10003091421465526, 0.9384214834734638, 0.15897617417144883, 0.8655260131025424, 0.21282326613787872, 0.8076298134747878, 0.21220819793564127, 0.08314325647451914, 0.9064233195287974, 0.10529982772678437, 0.16860093478239246, 0.16740817366833394, 0.2007530010733224, 0.1891678309568563, 0.2010543902452312, 0.21206937582534802, 0.19848777592093725, 0.20624506645998475, 0.20219997675065904, 0.18742044640015687, 0.20477268226141565, 0.16635009588326644, 0.07897866422258815, 0.08601726771705631, 0.09012673775880153, 0.10370934176699831, 0.09212141606675939, 0.08576004348954958, 0.09681302843857209, 0.11073613891826739]}, "mutation_prompt": null}
{"id": "741132f6-4f41-4a43-9879-df16e94cd97c", "solution": "import numpy as np\n\nclass ChaoticHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.85  # DE scaling factor, slightly increased for more exploration\n        self.cr = 0.95  # DE crossover probability, slightly increased for better crossover\n        self.w = 0.6  # inertia weight for PSO, increased for faster convergence\n        self.c1 = 1.7  # cognitive coefficient for PSO, slightly increased for more personal influence\n        self.c2 = 1.3  # social coefficient for PSO, slightly decreased for less global influence\n        self.vel_max = 1.0  # maximum velocity for PSO\n        # Chaotic initialization using logistic map\n        self.particles = self.lb + (self.ub - self.lb) * self.logistic_map(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-4  # diversity threshold for adaptive learning, increased for sensitivity\n\n    def logistic_map(self, size, dim):\n        x = 0.7  # initial value in chaotic system\n        r = 3.9  # parameter for logistic map to ensure chaotic behavior\n        chaotic_seq = np.zeros((size, dim))\n        for i in range(size):\n            for j in range(dim):\n                x = r * x * (1 - x)\n                chaotic_seq[i, j] = x\n        return chaotic_seq\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n\n        while evaluations < self.budget:\n            # Apply DE operator\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                mutant = self.particles[a] + self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Check diversity for adaptive PSO\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.95  # adapt inertia weight, slightly more aggressive\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "ChaoticHybridDEPSO", "description": "A novel combination of Differential Evolution and Particle Swarm Optimization enhanced with adaptive parameters and chaotic initialization to improve exploration and exploitation in diverse optimization scenarios.", "configspace": "", "generation": 5, "fitness": 0.3260473066426791, "feedback": "The algorithm ChaoticHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.29.", "error": "", "parent_id": "3ef5b86c-3af2-4c9a-8eee-32aade25ad1a", "metadata": {"aucs": [0.8616355127001816, 0.8629463591027144, 0.8741874633720541, 0.8862524208929173, 0.8742555647612476, 0.8618920915966509, 0.8739733106408191, 0.8880048726387579, 0.8658669285399403, 0.6518921347087748, 0.6960121333636611, 0.7765705263013614, 0.7493452486939136, 0.7367664892427924, 0.6679412332529386, 0.7441629984184004, 0.7561089743051663, 0.7658934727317797, 0.11603970154461984, 0.16108453678685253, 0.12502935647870383, 0.12330825949315549, 0.13195528074324026, 0.1428379795888408, 0.1596562220806752, 0.09440969282868605, 0.132662435580171, 0.11332460085974327, 0.11308624461640016, 0.13005744882778458, 0.1448261402409009, 0.1310321784060119, 0.10941103836753263, 0.12019733784358355, 0.1784769429979427, 0.14023251028464345, 0.9654979333446779, 0.9773999614399879, 0.9708652835934632, 0.9897851991576073, 0.9808348772671961, 0.9768898529513143, 0.9770636477429513, 0.9641335093830794, 0.9820004656409288, 0.7511161674874102, 0.7318119781578041, 0.7182483773248058, 0.7349622412174424, 0.6999361489934823, 0.7214993967244813, 0.0889883905678327, 0.08790277503344823, 0.7101710517948383, 0.884235836055288, 0.8819663176255821, 0.2247009624562959, 0.3786890092124632, 0.27480279565075505, 0.20703088306728923, 0.8589578997086421, 0.17888196581607008, 0.8821253697007162, 0.2019084972096703, 0.24315206999631733, 0.2529898449370883, 0.11347279786819964, 0.11757982293809877, 0.11659779221264233, 0.13428714924075613, 0.2876908643562458, 0.13481098037359185, 0.25080575052966636, 0.2546880682777999, 0.2656588523103742, 0.13526988926864048, 0.2725836401290471, 0.29459366111590735, 0.290856045021355, 0.28819267856591946, 0.2643883501155111, 0.07375433008124277, 0.02475743216278148, 0.00011949347543227518, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08416158340524094, 0.09285749967311807, 0.02975065008747113, 0.10178020333208515, 0.061126547032305245, 0.08149773102716484, 0.04729513479656822, 0.10096445862886072, 0.11782845831837507, 0.05684065328232735, 0.08166206876776672, 0.09998205457644671, 0.04814171425608893, 0.1487713382033664, 0.17920050003282217, 0.07379151251168714, 0.0794636857126616, 0.07804495690152147, 0.09941575906050948, 0.21177387457434083, 0.1382618406460302, 0.08330405978976085, 0.01177067307685542, 0.24114675243175043, 0.36371711499110604, 0.038497358591046416, 0.006603189529830855, 0.04961439051033356, 0.10978150771536144, 0.08465863174542976, 0.6404744586504671, 0.5848820958025418, 0.5716418680578659, 0.5981768639903384, 0.5556738578768401, 0.6173929869789916, 0.6159632853992665, 0.628367409425032, 0.5789864598679798, 0.1255814176260639, 0.11263448977732382, 0.13342127368567158, 0.108841932402157, 0.15988197362268508, 0.12161381135829374, 0.15941447802809694, 0.17621211868085151, 0.12895877271926692, 0.19641490759991465, 0.3523102695011622, 0.18955418584245765, 0.18955359473912126, 0.18234935935915708, 0.23781394013638868, 0.3420749960780739, 0.5144878866962235, 0.19122220646146848, 0.48092581311500626, 0.3281314284167073, 0.3570285718619324, 0.5904988442700078, 0.20241561425251664, 0.34946820790773026, 0.6876974384592944, 0.511415129476522, 0.2681904565667206, 0.21876758861440337, 0.28630591877303646, 0.3354130097680119, 0.2539078506462773, 0.22817411579615898, 0.25113897020118126, 0.21653045677323102, 0.2491340573723183, 0.39231651789227784, 0.22734020060696092, 0.22870185891864991, 0.2517333855846745, 0.22147957965155218, 0.2516843461637326, 0.2382453076975828, 0.1927505367944894, 0.21667374062236544, 0.22459056020417478, 0.253218711551779, 0.19059065476659354, 0.2537148093472652, 0.1821136520272405, 0.19775621978779212, 0.2027384027105139, 0.21587115198067786, 0.22079951406785658, 0.24605234537674892, 0.16667517581038105, 0.9029918304330724, 0.1881037021522305, 0.14763539982818363, 0.17279770244847747, 0.16880442160029563, 0.9230622267890632, 0.9168747117763549, 0.1698907753026757, 0.16900210047114705, 0.1684896215754217, 0.16818175509466038, 0.16982227404749006, 0.16932825212466363, 0.8958373567628366, 0.20924419887786805, 0.1693217129646215, 0.1570810862846962, 0.19844793510817205, 0.1896648827502545, 0.20270438999427887, 0.18940363053391118, 0.19030400364588962, 0.1980343125070272, 0.19782107218577272, 0.18552481511831853, 0.1904781922735871, 0.09302551385533775, 0.08362194933746869, 0.10446390223862767, 0.09482854895481796, 0.07147257828756026, 0.08667306524631602, 0.10129203630903738, 0.09510629245357483, 0.10079308794298669]}, "mutation_prompt": null}
{"id": "a33cb1b4-59cb-4d24-99f4-e5bdc57691ed", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.9  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.7  # inertia weight for PSO\n        self.c1 = 1.6  # cognitive coefficient for PSO\n        self.c2 = 1.4  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5  # diversity threshold for adaptive learning\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            # Apply DE operator with adaptive scaling factor\n            adaptive_f = self.f * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                mutant = self.particles[a] + adaptive_f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Check diversity for adaptive PSO\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.95  # adapt inertia weight\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "AdaptiveHybridDEPSO", "description": "An adaptive hybrid optimization algorithm that combines Differential Evolution with Particle Swarm Optimization, enhancing convergence speed through dynamic diversity control and learning mechanisms.", "configspace": "", "generation": 6, "fitness": 0.3158294204881563, "feedback": "The algorithm AdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.26.", "error": "", "parent_id": "3ef5b86c-3af2-4c9a-8eee-32aade25ad1a", "metadata": {"aucs": [0.7912483814660657, 0.7692565235347754, 0.8351846439060736, 0.7943974857459917, 0.7691044957733826, 0.812376223345908, 0.7691320946877555, 0.8222456107268068, 0.7375329294728852, 0.5221015907820246, 0.5397647812530249, 0.5247735093794754, 0.6769343288114291, 0.4886618052463563, 0.5833857455063785, 0.5706774014168754, 0.6067624601386945, 0.5007206720922438, 0.1332033403699181, 0.1500333213436068, 0.13077615890320304, 0.18062249145302978, 0.1714750672932296, 0.15080915790534422, 0.1535609450019001, 0.17884092864147916, 0.11679817045807717, 0.1389210013077925, 0.11126501318546311, 0.11424760196189532, 0.12960884158721075, 0.1431204667148599, 0.1122845467318373, 0.11346283120523115, 0.10535859220062471, 0.14309926224477476, 0.9791169587957075, 0.9770947625138928, 0.96942034167616, 0.9840959631082524, 0.9760996573326763, 0.9837338979336001, 0.9847244945834017, 0.9713746631018714, 0.983880764456358, 0.629219150982387, 0.059651986302765025, 0.6160072323668118, 0.6285575861587132, 0.626805738715186, 0.5633208035325877, 0.08874791668991222, 0.543795632458457, 0.5940382701195099, 0.8130781533082807, 0.7164906682934404, 0.862662561402654, 0.2708308352600506, 0.2784831868877986, 0.37112117411787604, 0.7849892495727089, 0.34078952541066687, 0.7131903114719478, 0.1654897922604277, 0.2606300625904022, 0.23188722020043206, 0.13000050881840286, 0.221619944773775, 0.13114238871945783, 0.22671335814577587, 0.13189094053845352, 0.21409707155487145, 0.13076316551826916, 0.23613490387005198, 0.22633390816938248, 0.2533078180521138, 0.2376855319712935, 0.255526150023763, 0.3137241788081018, 0.12382717903358875, 0.23812007642719113, 0.1391166544858039, 0.05130177389557011, 0.008836451689580138, 0.04302373775513968, 9.999999999998899e-05, 9.999999999998899e-05, 0.062335145606636444, 9.999999999998899e-05, 9.999999999998899e-05, 0.11817147167545372, 0.13757563962617292, 0.07038806526996522, 0.12392373697334769, 0.03395268906322835, 0.032983960692596015, 0.06870232793824727, 0.12330058073079853, 0.06378292856304124, 0.11854080453772298, 0.0722792883410115, 0.0895052546275672, 0.07319782425497434, 0.06874422692541071, 0.21813340468009934, 0.08151746618772615, 0.08315738899183489, 0.19565556578155063, 0.14469330985376205, 0.06977256832196277, 0.0965954791861211, 0.1556882314333241, 0.38766665786512544, 0.09920123222408272, 0.11079803124842824, 0.10564050678553905, 0.10586076450689874, 0.5203781216034387, 0.49020849957061374, 0.5130816509036505, 0.5354588952913817, 0.5874220747513736, 0.556014155754702, 0.5057937119929209, 0.5590366698016611, 0.4976175411501196, 0.07694939406076651, 0.13685973904001492, 0.11838138826689137, 0.1249708390609372, 0.13917865234928928, 0.14959414636222323, 0.13348605812422043, 0.1398505027563739, 0.10932606881529916, 0.311892937992609, 0.27358138254420905, 0.3812068813199616, 0.3303046329552066, 0.4258164737218917, 0.23579731555234806, 0.26719795222690257, 0.2799594580606787, 0.2728545303775861, 0.2945467334791051, 0.48292750704569676, 0.40320866103701036, 0.41477706264513303, 0.3512452741479558, 0.38644116717380494, 0.4660378654262768, 0.4539200243506417, 0.4128953693036207, 0.3747377105577211, 0.32726828305577305, 0.2288257155872513, 0.29805804776888345, 0.32822096036860715, 0.23849119234464589, 0.19519703412937106, 0.40318311403997753, 0.21131203800657272, 0.2486879677095899, 0.1777042001892154, 0.230266188092346, 0.24912512502850992, 0.2071748212735094, 0.20446873739164761, 0.22972411783499724, 0.22650635973862632, 0.2357600933106221, 0.20576834986421255, 0.6607806334759256, 0.20080379082683486, 0.19785390514740064, 0.6521513083984456, 0.1936795230993824, 0.19934491030262624, 0.6285240874884217, 0.22492405461541498, 0.18743380371499574, 0.16803980538048524, 0.17687138537320313, 0.16955847402861235, 0.2003062687878836, 0.8609978364382012, 0.0999886554474606, 0.8986622969298783, 0.16824196572560157, 0.6810982821893306, 0.21142726319402505, 0.6456623551469649, 0.11286923866597098, 0.16921228386897058, 0.21049349467026346, 0.11300254013424638, 0.21101089787148208, 0.21333336880641973, 0.18792809921554743, 0.18261323594197576, 0.18531848351846025, 0.20587562378130297, 0.17803762626292885, 0.19032256517893742, 0.20282669210236803, 0.1824506221861909, 0.20921251432290855, 0.09830945303564276, 0.0967379878054051, 0.08054214434187612, 0.09027395654047354, 0.11790433460349614, 0.11485699254042958, 0.08888515441945333, 0.10446066948623778, 0.10121956757732042]}, "mutation_prompt": null}
{"id": "39bc378e-7e44-4bd1-aa5b-fd0003feeb52", "solution": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.85  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.6  # inertia weight for PSO\n        self.c1 = 1.4  # cognitive coefficient for PSO\n        self.c2 = 1.6  # social coefficient for PSO\n        self.vel_max = 1.2  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5  # diversity threshold for adaptive learning\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            # Apply DE operator\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                mutant = self.particles[a] + self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Check diversity for adaptive PSO\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.95  # adapt inertia weight\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "RefinedHybridDEPSO", "description": "A refined hybrid algorithm combining Differential Evolution, Particle Swarm Optimization, and dynamic parameter adaptation for enhanced performance in diverse optimization tasks.", "configspace": "", "generation": 7, "fitness": 0.3250801340060843, "feedback": "The algorithm RefinedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.28.", "error": "", "parent_id": "3ef5b86c-3af2-4c9a-8eee-32aade25ad1a", "metadata": {"aucs": [0.864715748960044, 0.8223337712087468, 0.8561346032373569, 0.8639921797595149, 0.8397338171034744, 0.8405958157678761, 0.8651705407807375, 0.8646191215953402, 0.8649397940821507, 0.7541063945617072, 0.6879976963186195, 0.7216181797994508, 0.7053312950293718, 0.743878101294102, 0.699207721482406, 0.6609247087154103, 0.7211770700388715, 0.6466510635415075, 0.11867487577731539, 0.11473598876411084, 0.1277272865786535, 0.12746364398682852, 0.1491054780981298, 0.11868097535603939, 0.1450668982271638, 0.7208222500374932, 0.15689859187218258, 0.12383523505112026, 0.07846065855646522, 0.15523835120902896, 0.11498683697201928, 0.12934467402354, 0.1436028566853651, 0.12177730543026521, 0.11160281410574935, 0.1619380658487546, 0.9759006869571741, 0.9738488856791757, 0.9732604737717881, 0.9832075955969914, 0.9798292855222158, 0.9828124858070736, 0.9882066893509247, 0.9828513052742975, 0.9854545094549867, 0.6690357527469994, 0.05971776248231764, 0.7287529116332754, 0.6272213728705023, 0.15328419664070303, 0.6915723219307626, 0.08887621951784785, 0.0883940838626609, 0.7307005417133079, 0.22773158246272363, 0.8285434014991809, 0.8702591771692068, 0.20987039563337173, 0.7967171304714534, 0.22118661928466898, 0.15211566276238042, 0.15125497001168697, 0.23821970661618241, 0.12231867690213949, 0.11597785763650503, 0.24523227364269073, 0.24212780761432828, 0.26445129858605365, 0.21976510725004095, 0.26179554914480907, 0.24296819412592863, 0.24334126854816596, 0.22665289941399758, 0.02241606495422588, 0.24573299051380526, 0.2554832315615544, 0.2704434939237452, 0.1331722879245797, 0.2638508650656203, 0.11657054637433362, 0.27314556132433143, 0.013139800666212453, 0.06351413629551139, 0.03653490259943881, 0.05485960490268116, 0.00867679982911762, 0.030414111346858452, 0.04956196220642939, 9.999999999998899e-05, 0.036120545198313425, 0.12146109016178985, 0.16262706830798124, 0.10804397597420934, 0.06401153527398806, 0.04372161857189172, 0.045506268594845856, 0.1705943530544004, 0.10591446434248342, 0.11645207187913142, 0.12404699833137112, 0.11972884391056016, 0.30042152264088995, 0.07283199048474875, 0.07485080786839449, 0.07789570515118815, 0.27714925050904105, 0.09373053196663295, 0.25338907217357454, 0.2293021125569703, 0.10997608736901221, 0.23928699601152204, 0.10270891375890567, 0.14905817091034657, 0.06803954403469192, 0.04974434305343334, 0.18332313039955128, 0.10283723443405501, 0.5991453433520649, 0.579731799376148, 0.5642538246568898, 0.593906750421674, 0.6184013735459841, 0.6015299530975542, 0.6149576821870011, 0.5808263164927999, 0.5537820818571196, 0.12916757507471188, 0.14036362527434576, 0.11401440737376156, 0.15877212418283237, 0.1226527047188185, 0.13203399793992943, 0.1587416313743406, 0.105218590349341, 0.11144787257187183, 0.1543894881290584, 0.21951633873635967, 0.17302802336777656, 0.4314382246529478, 0.210628860770131, 0.21694661255968217, 0.4088310581123745, 0.178421103757066, 0.5387135657948692, 0.40468043421201516, 0.499565283601792, 0.3599193218409439, 0.23530569864105932, 0.407052193965433, 0.5302678351008455, 0.5287802859459578, 0.5185733666465027, 0.22421255040022237, 0.16793247233011754, 0.24282723626202174, 0.19746313883913724, 0.21525521755292798, 0.33211111251521097, 0.3067273994946671, 0.20135761543918362, 0.4195628060932206, 0.2543774476780496, 0.25434472585169343, 0.25248485526033515, 0.24381306556590832, 0.2739114051670456, 0.22548036172577945, 0.2297462819729702, 0.2554026610912331, 0.21236332379354483, 0.1967605865940747, 0.2459964952035596, 0.20605920946348166, 0.2284268034566418, 0.7553951468115833, 0.2417692141218699, 0.22413700389863178, 0.22952660310213024, 0.7506412103459936, 0.20707184858423755, 0.1882501475736683, 0.1684206241796039, 0.15344096354974168, 0.19941366604603195, 0.2010100449427713, 0.17025039750619486, 0.09997669429120581, 0.9142735650604541, 0.1618557492794338, 0.6818935122218805, 0.21238556517308438, 0.6983145138318481, 0.8397307617539549, 0.2235597592144043, 0.868936342319835, 0.12820793944755637, 0.1669811271071696, 0.19998608108002258, 0.19279953336976252, 0.1918694764973481, 0.1923091689417934, 0.1983188572454454, 0.19272780945485624, 0.22004944737513543, 0.2381200049299239, 0.21168479641907, 0.21852018048368693, 0.10025106440912845, 0.10033531886717195, 0.0856754317230809, 0.0858725370991571, 0.080243829708462, 0.14637051693481318, 0.08228086305108595, 0.09194627187698423, 0.09394555819316952]}, "mutation_prompt": null}
{"id": "66f88077-85d1-4958-95e1-198565b7ca0f", "solution": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5  # diversity threshold for adaptive learning\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            # Apply DE operator\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                mutant = self.particles[a] + self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr + 0.05:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Check diversity for adaptive PSO\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9  # adapt inertia weight\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "RefinedHybridDEPSO", "description": "A refined hybrid strategy combining Differential Evolution, Particle Swarm Optimization, and adaptive mutation to improve performance across varied optimization problems.", "configspace": "", "generation": 8, "fitness": 0.3323024848528949, "feedback": "The algorithm RefinedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.29.", "error": "", "parent_id": "3ef5b86c-3af2-4c9a-8eee-32aade25ad1a", "metadata": {"aucs": [0.9158505428820519, 0.9158806261523752, 0.9123310353163208, 0.8935395454276234, 0.9024272714945971, 0.9193797304324863, 0.908221884015705, 0.9118481232216761, 0.9072733445211794, 0.7658905399011326, 0.8286969688974726, 0.8036527241596065, 0.830208496348914, 0.8094679282609467, 0.8230399819099093, 0.7892931723620386, 0.8048194376245547, 0.812053420959722, 0.15990541478656484, 0.10526424487821273, 0.08031971817443462, 0.1457635244865464, 0.11749266163848227, 0.1625405063525983, 0.10951218793231765, 0.15823674624407358, 0.19096926325256935, 0.0947566157369103, 0.1238622382066813, 0.06355520992299823, 0.14395803485293202, 0.10601023002064192, 0.08666958047037532, 0.09746580385352077, 0.1452240285091313, 0.14026916688424973, 0.9774200642306038, 0.9696381027456392, 0.9622881054623945, 0.9701243924673175, 0.9855838933601433, 0.981142748925454, 0.9780055952139121, 0.9764259796411336, 0.9804065120407107, 0.8288425225725851, 0.8126286298486134, 0.7973702346391636, 0.8215820308854109, 0.8114156104311602, 0.15398888694837765, 0.7802119819447522, 0.8147313802729658, 0.803765476764958, 0.23101427222686, 0.39825947032417275, 0.17092496259691636, 0.28154584493161117, 0.19350604756777734, 0.3817065404188186, 0.17931822577975742, 0.13611438277987165, 0.40846542467912694, 0.2965277589044213, 0.22437556182519547, 0.28560566386207553, 0.3032091200443283, 0.2913123517526198, 0.2631642395159568, 0.290690723144711, 0.2912512391248754, 0.29416832027025475, 0.1356630776611173, 0.2707836749409003, 0.224071617906898, 0.3208932107087612, 0.30034452906349374, 0.1279960782750903, 0.3179856234087499, 0.29565544921434816, 0.2929855315374701, 0.01881040078590701, 0.009876256307848386, 0.06803506505759893, 9.999999999998899e-05, 9.999999999998899e-05, 0.12920197902610997, 0.038238834358233165, 0.012870053030196171, 0.01745099536720318, 0.21330555176387112, 0.13393287607255588, 0.1447810139501593, 0.0948208891844079, 0.0153453550478726, 0.03708172110000074, 0.07440853083613796, 0.17143303786744968, 0.05590310186801839, 0.1481363472643894, 0.07559633468136728, 0.20954308358923612, 0.08059689715022467, 0.10341549860358012, 0.34149410627313215, 0.1521497915065727, 0.10232310627961738, 0.07491472117363718, 0.07649719850799752, 0.08881658248006641, 0.1772136605767497, 0.0066994580983186225, 0.2562928945773777, 0.1650892552196468, 0.09888962071655127, 0.10223476034744294, 0.08570931131721482, 0.6003765657017407, 0.5697710367750918, 0.5956285578129271, 0.5838360659122492, 0.5990643574996665, 0.6644797285683788, 0.5978485467917165, 0.5973790195650135, 0.608560767230847, 0.1140008900761712, 0.11316535071718481, 0.06952096827455223, 0.1434202229642607, 0.062093416929918877, 0.1629023311222736, 0.16345933834269877, 0.14643457853165398, 0.17947694277431236, 0.35243519539657764, 0.3975977981305632, 0.14531531502359718, 0.19395638278825822, 0.3499605757547034, 0.8209832203958933, 0.330548368551577, 0.2697135716290089, 0.20326384371445638, 0.36794791867361176, 0.6023761439675155, 0.4323760818447444, 0.5723522410265499, 0.24164752563899317, 0.29581897088766196, 0.4268756405935341, 0.5295452308802708, 0.5911658744489414, 0.3279937107577079, 0.32910757087737397, 0.2636302093532782, 0.16423168237575814, 0.23168098498118572, 0.2707134764798358, 0.2842339263601128, 0.26402561306942085, 0.23121289542261825, 0.20313650198558897, 0.2223690696334042, 0.22895467020998206, 0.21130810844660297, 0.22400113123983545, 0.21016287523997623, 0.22737705570762223, 0.262509721242846, 0.21069826164337668, 0.19162123556328925, 0.2268469354438496, 0.20048995337851105, 0.19249637223435, 0.22649318021078824, 0.1878678942506905, 0.21164220141998535, 0.17309623997645363, 0.19535412838167288, 0.1681074026060394, 0.9255386385222651, 0.15343618461482056, 0.17267867161639627, 0.20167749648644562, 0.148514223990873, 0.13640084392267837, 0.9398261639959765, 0.1616529403137179, 0.8068939136480827, 0.2133055496763312, 0.21169993229212725, 0.2112907163219292, 0.21182634452588822, 0.21067115174663864, 0.1051666330812443, 0.16856817522403322, 0.2102084306910258, 0.20376732735711822, 0.2121852642928468, 0.2015654238891369, 0.19975366811379636, 0.18749531463832148, 0.19777241259786693, 0.18576210061241605, 0.19068939442556343, 0.24790340812862288, 0.08762592484482556, 0.08297998315345922, 0.07927088711774832, 0.10928547155938084, 0.08146194435354026, 0.09696813651447023, 0.09726014195276489, 0.11347184659297405, 0.09603114304097449]}, "mutation_prompt": null}
{"id": "534392ab-e15c-4c3a-96c7-400f3f7685af", "solution": "import numpy as np\n\nclass AdvancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5  # diversity threshold for adaptive learning\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            # Apply DE operator\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                mutant = self.particles[a] + self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Check diversity for adaptive PSO\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9  # adapt inertia weight\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "AdvancedHybridDEPSO", "description": "An advanced hybrid approach integrating Differential Evolution, Particle Swarm Optimization, and adaptive learning to enhance convergence speed and solution accuracy in diverse optimization landscapes.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "3ef5b86c-3af2-4c9a-8eee-32aade25ad1a", "metadata": {"aucs": [0.9111671634088075, 0.9131451943353056, 0.9255458854056, 0.9080122357346663, 0.9094559080304299, 0.9172445817437981, 0.9145163603411455, 0.9259497558932204, 0.9146587915505511, 0.8101621400259534, 0.8168549070823822, 0.7903581394833029, 0.7966728825285446, 0.8286205925870541, 0.8107824461917078, 0.8157799063137245, 0.8085430258635509, 0.8151248805326197, 0.14285115144011595, 0.1325894023446781, 0.09270884879253571, 0.13457332797023103, 0.13481855045299684, 0.14542898521429193, 0.14703580463925936, 0.11892595839356801, 0.1156811520285459, 0.17717043918630804, 0.08303399845658621, 0.1339919622186484, 0.14514893904389847, 0.0956575186901133, 0.11054469334823624, 0.14661649659128784, 0.08052401437218848, 0.11102297919645499, 0.9784159322775751, 0.9658090402324563, 0.9632936052267986, 0.984751528501409, 0.9809645705318761, 0.9787844889803349, 0.9859297327016984, 0.9783229444812245, 0.98371800000141, 0.8099295652500718, 0.8211245485386591, 0.8150342508289312, 0.8195343690437298, 0.7911790978662144, 0.7818602995278601, 0.08894778567662798, 0.7832896890004528, 0.8105934325759209, 0.3997670932054269, 0.22935832249187038, 0.21380614518815033, 0.2224262098467742, 0.19335091685301886, 0.2783486612213639, 0.17940669974563805, 0.39510326530093964, 0.9288236218218956, 0.274714276233462, 0.2567092674090372, 0.2888863825437036, 0.285585227342003, 0.2858525797078242, 0.3903256476929361, 0.3002895576830724, 0.1341210030882778, 0.31393748468412563, 0.2732625106774037, 0.2729488361967741, 0.2151622706023537, 0.31527599105399406, 0.30414435346353663, 0.3272464874894925, 0.3035884953158393, 0.3043787494304526, 0.31032995578681954, 0.01118322273000083, 0.03867522107624133, 0.003142693264613028, 9.999999999998899e-05, 9.999999999998899e-05, 0.06313372272485651, 0.04179319496781886, 0.01460784712994978, 9.999999999998899e-05, 0.07146379686700566, 0.16434292877049905, 0.1596287792279527, 0.17052860085547272, 0.049163716730877605, 0.028519534587570172, 0.2673345291121938, 0.08775993627820022, 0.07283812266485479, 0.06722545951049053, 0.06969303705664165, 0.049009284194444946, 0.08040441193400238, 0.12246758714057238, 0.4082643449022111, 0.09942137980727783, 0.10455341976538657, 0.11952046110330172, 0.146156973343457, 0.08233808905789974, 0.14661976649177633, 0.06671822970286267, 0.21212539083691906, 0.3592911328045638, 0.3666877723072215, 0.34713810023018377, 0.08452857920811907, 0.5692637978646483, 0.5771004036526453, 0.6199707596107583, 0.5934513198104745, 0.6191551564095095, 0.5792014858723108, 0.6161234557540658, 0.5891730249620946, 0.6248540751851932, 0.09662793871587327, 0.15636932710691276, 0.18330672558269556, 0.16135461407596663, 0.11088672343791806, 0.11645150487758582, 0.13044903036756272, 0.13298773177018341, 0.08640156156381129, 0.27186516418935625, 0.26553639440067245, 0.26949371466285776, 0.2566782874751029, 0.23874113151669585, 0.17625600999502333, 0.2615305013067456, 0.32345854355205317, 0.22579089997039736, 0.4525342499316979, 0.3883892537322631, 0.3429303061813298, 0.4174538031015883, 0.2372123989823558, 0.4725843055639206, 0.5487476328469583, 0.5733429529884178, 0.2505716895104255, 0.22147460239647287, 0.35175311390257136, 0.17389759816019468, 0.2263795949845444, 0.2835740147611415, 0.3009765590587511, 0.22811116492443284, 0.2707445144615708, 0.21776032923941635, 0.2195403200515118, 0.22206755336781248, 0.25415514563707764, 0.27694840547322586, 0.22141647679661436, 0.24073433139181288, 0.22044856742353747, 0.2156926608882629, 0.22726311543660238, 0.22743248938405702, 0.22792940002893292, 0.19002279325790672, 0.21115765430600253, 0.21137801210085205, 0.19244396283119314, 0.22553877311996873, 0.20878079954353368, 0.21059975683644494, 0.18823165236482076, 0.18827555214745761, 0.1539093643203825, 0.17278902935755136, 0.20157919753871278, 0.1486685662050653, 0.10003091421465526, 0.9384214834734638, 0.15897617417144883, 0.8655260131025424, 0.21282326613787872, 0.8076298134747878, 0.21220819793564127, 0.08314325647451914, 0.9064233195287974, 0.10529982772678437, 0.16860093478239246, 0.16740817366833394, 0.2007530010733224, 0.1891678309568563, 0.2010543902452312, 0.21206937582534802, 0.19848777592093725, 0.20624506645998475, 0.20219997675065904, 0.18742044640015687, 0.20477268226141565, 0.16635009588326644, 0.07897866422258815, 0.08601726771705631, 0.09012673775880153, 0.10370934176699831, 0.09212141606675939, 0.08576004348954958, 0.09681302843857209, 0.11073613891826739]}, "mutation_prompt": null}
{"id": "fe89c01d-c88b-40ba-8efe-b42d83f1431a", "solution": "import numpy as np\n\nclass AdvancedHybridDEPSOImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.9  # DE scaling factor\n        self.cr = 0.8  # DE crossover probability\n        self.w = 0.7  # inertia weight for PSO\n        self.c1 = 1.6  # cognitive coefficient for PSO\n        self.c2 = 1.4  # social coefficient for PSO\n        self.vel_max = 1.2  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-4  # updated diversity threshold for adaptive learning\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            # Apply DE operator\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                mutant = self.particles[a] + self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Check diversity for adaptive PSO\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.85  # adapt inertia weight\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "AdvancedHybridDEPSOImproved", "description": "A sophisticated synergy of Differential Evolution and Particle Swarm Optimization enhanced with adaptive strategies for improved convergence in complex search spaces.", "configspace": "", "generation": 10, "fitness": 0.30171415152910935, "feedback": "The algorithm AdvancedHybridDEPSOImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.25.", "error": "", "parent_id": "3ef5b86c-3af2-4c9a-8eee-32aade25ad1a", "metadata": {"aucs": [0.7671714838683688, 0.8333049379658539, 0.7308359680900844, 0.7727765876686132, 0.7083858515176228, 0.7908643579533143, 0.780530908295104, 0.7398819898538195, 0.7354771811838652, 0.5215593916646838, 0.5379821557642332, 0.6069720170188961, 0.47033614249951994, 0.5349381001410747, 0.5777781503689206, 0.41304239570611445, 0.44459185599410234, 0.39283773167072167, 0.14260350207397277, 0.11030717896397924, 0.13248569409352784, 0.14248120321381352, 0.1473070487334609, 0.14230513374735143, 0.12245119594764764, 0.1309474572665178, 0.13482144555674458, 0.14404129505049446, 0.16679360927532927, 0.13589690068357252, 0.14011832496057575, 0.1370309171312496, 0.110318610913965, 0.16138858290932367, 0.16649717102647932, 0.11980818637546886, 0.9820489376018325, 0.9756505724672102, 0.9757439219539762, 0.9827410864644028, 0.9754199623591822, 0.980281532111365, 0.9842975105289511, 0.980535015120393, 0.9847168597394634, 0.5936577291145012, 0.059752859606889475, 0.5765933181595748, 0.4893870083120876, 0.48497678204459116, 0.5200275464660319, 0.08829445042283945, 0.08859569454677962, 0.5278137097873108, 0.6470047963562204, 0.225518879775213, 0.2259522621897977, 0.19337332476139846, 0.779668700207212, 0.2786294020397303, 0.22679405153770116, 0.23172162420883646, 0.826039252959801, 0.16726315337243525, 0.2505763146133414, 0.22002729552794553, 0.12883877752403272, 0.13376548327516524, 0.19791941985948946, 0.2278443708894018, 0.19505373761908684, 0.20538683712728512, 0.20542176764580877, 0.15156072926202802, 0.19929748615131315, 0.22814945074791781, 0.2315450305669633, 0.23333129574567846, 0.2186723644455979, 0.21566677931705347, 0.23005216149388075, 0.04066738052729302, 0.055861451724574684, 0.0020172051461094798, 0.038313150851978395, 0.0062297849863865995, 0.01221265059588894, 0.01170651071566553, 0.028632941023779668, 0.0011868841039167632, 0.06232675081164196, 0.07333395697932044, 0.15140808499246672, 0.07208191829820265, 0.05208476940986806, 0.03611293580457675, 0.11541403326685062, 0.09981610600238999, 0.012617837382050134, 0.08771233619959462, 0.07594776134713921, 0.04026607127509885, 0.09471073585622891, 0.08161223119612282, 0.08308966839222087, 0.09947791884417256, 0.06545282942212238, 0.13934233508403848, 0.16118980764788848, 0.08627055351472268, 0.10546951775838387, 0.1664203468173706, 0.24609503583987802, 0.04028847059915042, 0.10321200862985991, 0.08233084830066195, 0.09172187890624861, 0.5147573960255766, 0.513823678010607, 0.5338022837596528, 0.527742865542628, 0.5643739055696839, 0.5151703251226287, 0.5303379484926902, 0.5100526556101713, 0.5480263295577886, 0.11373649457841606, 0.17284274536697541, 0.0755364925602815, 0.13425137731506476, 0.11580373960489176, 0.13033199811802443, 0.13320760294653877, 0.15188188335502129, 0.14068990701803685, 0.15642040321548956, 0.25605798972426086, 0.4355182459215655, 0.2696589284387071, 0.23882043889346238, 0.18617103166788784, 0.31329299944684663, 0.2002804021104182, 0.28320410744563873, 0.3984560243912698, 0.41382402564130305, 0.36751182217115663, 0.2817946832145036, 0.2622893697685217, 0.33748264450395093, 0.44415102418457586, 0.4732111651296197, 0.42826450127867643, 0.2514836956856078, 0.336629027067362, 0.22157066774289247, 0.28251199209826794, 0.2601415882798971, 0.3225019060662381, 0.27002582131743325, 0.3282518323611875, 0.2772772430519106, 0.22141320084677585, 0.22526895973968286, 0.21564952973193263, 0.17372901820576758, 0.20678478809490997, 0.22456392087236765, 0.22310790725468677, 0.26016372111781016, 0.21679846877291387, 0.18459326064333514, 0.24369039001288118, 0.2225535476644388, 0.387507478633748, 0.5826320872203847, 0.19533621194085649, 0.19342635471343705, 0.20420773140023663, 0.2153780447899113, 0.8981023583566492, 0.18825501372971465, 0.15335224188896113, 0.8788118300431556, 0.2001599530910967, 0.8282618838974007, 0.09977888087284414, 0.16921187398050663, 0.8547479280460315, 0.7302082638040894, 0.21135120052366196, 0.4599026883217251, 0.6986309523459293, 0.16898837829797664, 0.20981716267850947, 0.7203254001129286, 0.10451650591087314, 0.16782517134432384, 0.2227004449048232, 0.23767574113257783, 0.2155476077942583, 0.2177231154417093, 0.21256412996660035, 0.19084530950718692, 0.19059350951563458, 0.1891204361717258, 0.22107590423327905, 0.08679542463032452, 0.08683626489413931, 0.09797513284699688, 0.09472847013945052, 0.09070678801948484, 0.09553149964446128, 0.08587330552855843, 0.09541135101729525, 0.08121215719336361]}, "mutation_prompt": null}
{"id": "1ebd7d3c-14fe-4e27-95b7-06b0c3a950df", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.9  # DE scaling factor\n        self.cr = 0.85  # DE crossover probability\n        self.w = 0.6  # inertia weight for PSO\n        self.c1 = 1.7  # cognitive coefficient for PSO\n        self.c2 = 1.3  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-4  # diversity threshold for adaptive learning\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            # Apply DE operator\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                mutant = self.particles[a] + self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Check diversity for adaptive PSO\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 1.05  # adapt inertia weight\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A novel hybridization of Differential Evolution and Particle Swarm Optimization with enhanced adaptive mechanisms for diversity control and convergence acceleration.", "configspace": "", "generation": 11, "fitness": 0.33592673543115065, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.28.", "error": "", "parent_id": "3ef5b86c-3af2-4c9a-8eee-32aade25ad1a", "metadata": {"aucs": [0.8870353114051117, 0.8765784695360236, 0.8962947874166854, 0.8810061415172493, 0.8844171993922084, 0.8859155811627686, 0.8777666127325852, 0.8832680783267053, 0.8714146105364814, 0.7519529032053933, 0.7387421461658609, 0.6863984911642103, 0.7489327254813865, 0.6990899738324807, 0.7365973283748761, 0.7293296731678094, 0.6946962021206805, 0.655668935220733, 0.14454719424554952, 0.13516985926687453, 0.10968541023193334, 0.14431847261007458, 0.16127633638270744, 0.12080544222253287, 0.1807447123440875, 0.1374120313351268, 0.14970883321012063, 0.151986129230947, 0.14571443233158388, 0.12338359953870681, 0.14339681845047414, 0.08370573337795317, 0.15164974978826995, 0.1200014451445961, 0.11790001402523154, 0.124134792305854, 0.9771624396132331, 0.9732725607862875, 0.9716841268141624, 0.9734117245088713, 0.9805833693054268, 0.9763583670593443, 0.9859798055817327, 0.977249049233042, 0.9805532799696823, 0.7148216152649486, 0.05942861913506681, 0.684926587110238, 0.666437725009182, 0.15154599587751016, 0.7028360088009579, 0.6637035577513137, 0.6507699880957789, 0.7022642637260802, 0.9057725234206423, 0.22792687805543532, 0.8131261822976974, 0.3844629711329475, 0.20500958038413564, 0.3843584059145372, 0.23400680777506933, 0.22323610299668795, 0.23857860379700757, 0.2518389902177469, 0.24608133330727833, 0.22985473039997728, 0.13103383613594455, 0.24266596894017411, 0.24572351204551135, 0.25193929241499724, 0.1333726198046088, 0.2352826642972412, 0.2735097175875175, 0.2351307470135373, 0.23812684038314136, 0.13356767543764092, 0.2660818263358391, 0.2864469822685153, 0.28361807734249755, 0.27670932970200024, 0.30060938836555495, 0.044172629147696485, 0.012704938975238056, 0.03806278442668276, 0.03396913330868223, 0.015757956682685648, 0.14430518780550539, 0.07832196362885313, 0.05887106056814595, 0.07704967132722196, 0.13925219365382457, 0.15203496154695895, 0.1511575726812483, 0.09181339927673193, 0.06643954206373315, 0.030162962629509238, 0.15043228032536937, 0.07202509981117367, 0.027658627778145872, 0.06665635848214646, 0.05570519972880972, 0.12740284304612726, 0.07640401517417195, 0.07356971042906735, 0.09164980678018497, 0.208925297001335, 0.11487056562472231, 0.09917023537335368, 0.08708881876278518, 0.0887163548468538, 0.19728602483862856, 0.03941994084247491, 0.10423297541350385, 0.13688147340939127, 0.08418177745825983, 0.20436641758532081, 0.08386296545724181, 0.5805742071974945, 0.5362829521280216, 0.5521650086470914, 0.5938369362322734, 0.5901558428757985, 0.5708926739670244, 0.59746625030934, 0.5932198795257029, 0.5857310463020382, 0.09939499713642996, 0.15861567555951028, 0.13030286107886369, 0.1504858124743832, 0.1162020965049202, 0.14803058180046613, 0.15850390288172644, 0.11378132904325344, 0.10489906143151617, 0.31131350597268315, 0.21361269716766207, 0.2689856639544451, 0.20464483639766562, 0.34173758449636615, 0.3387060393496504, 0.18796426402168476, 0.1753812179729839, 0.5872216767902618, 0.33915580423815483, 0.55336398330531, 0.37075533069890954, 0.25769160475698283, 0.37148927567485934, 0.4856582230791683, 0.38355177729357137, 0.5329277459803906, 0.22824108057569337, 0.2519941067473366, 0.36880820883215226, 0.26878014703242714, 0.34481086801017624, 0.20006519826390845, 0.29360911567965353, 0.3200320360246751, 0.2813741701131578, 0.21881722607510412, 0.21351715674868166, 0.2511913022363338, 0.2221331326756868, 0.20860495190394635, 0.23336486816104773, 0.1958073888116948, 0.22983748617736677, 0.2331939569189584, 0.2521803456925591, 0.21491629386662847, 0.24198607323705634, 0.2099944442094236, 0.7685810861229844, 0.8008975993291909, 0.22098567357569487, 0.20782923262941266, 0.19808945060358418, 0.2209673672583643, 0.9262762777923444, 0.18805253907356, 0.11554125060287279, 0.18810312633458826, 0.20093010330556704, 0.9365927695451564, 0.12269566148204591, 0.1699912096107311, 0.15893495594413176, 0.8716840285990353, 0.1622626829502165, 0.8109327428436917, 0.8694643545933572, 0.16863882186471468, 0.21040100902604664, 0.7779736747095585, 0.8395316546717889, 0.16853853758088022, 0.187568157293019, 0.2233015759173128, 0.18909210170286828, 0.20048511257562363, 0.20189540219716684, 0.2088230975262636, 0.2128162664388764, 0.19660112139746766, 0.18921402559750955, 0.09506035144422165, 0.08110646716291703, 0.09393528864135992, 0.09793692118516029, 0.10269053365286596, 0.08831327746076345, 0.09639249930478477, 0.08704370387059102, 0.08975164135958258]}, "mutation_prompt": null}
{"id": "2f645cc7-036c-4f40-bcc0-92f7604a4f90", "solution": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5  # diversity threshold for adaptive learning\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            # Apply DE operator\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                mutant = self.particles[a] + self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Check diversity for adaptive PSO\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.95  # adapt inertia weight\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "RefinedHybridDEPSO", "description": "A refined hybrid strategy combining Differential Evolution, Particle Swarm Optimization, and dynamic diversity control to improve solution quality and adaptability across varying optimization scenarios.", "configspace": "", "generation": 12, "fitness": 0.3369587270057455, "feedback": "The algorithm RefinedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.", "error": "", "parent_id": "3ef5b86c-3af2-4c9a-8eee-32aade25ad1a", "metadata": {"aucs": [0.9111671634088075, 0.9131451943353056, 0.9255458854056, 0.9080122357346663, 0.9094559080304299, 0.9172445817437981, 0.9145163603411455, 0.9259497558932204, 0.9146587915505511, 0.8101621400259534, 0.8168549070823822, 0.7903581394833029, 0.7966728825285446, 0.8286205925870541, 0.8107824461917078, 0.8157799063137245, 0.8085430258635509, 0.8151248805326197, 0.14285115144151983, 0.13258940234442584, 0.09270884879238761, 0.1345733279701834, 0.13481855045290125, 0.14542898521084646, 0.1470358046389434, 0.118925958393296, 0.11568115202818263, 0.17717043918964936, 0.08303399845658277, 0.1339919622181318, 0.1451489390435574, 0.09565751868984329, 0.11054469334792061, 0.146616496591232, 0.08052401437212042, 0.1110229791960965, 0.9784159322775751, 0.9658090402324563, 0.9632936052267986, 0.984751528501409, 0.9809645705318761, 0.9787844889803349, 0.9859297327016984, 0.9783229444812245, 0.98371800000141, 0.8099295652500718, 0.8211245485386591, 0.8150342508289312, 0.8195343690437298, 0.7911790978662144, 0.7818640630517628, 0.08894778567662798, 0.7832896890004528, 0.8105934325759209, 0.3997670932054269, 0.22935832249187038, 0.21380614518815033, 0.2224262098467742, 0.19335091685301886, 0.2783486612213639, 0.17940669974563805, 0.39510326530093964, 0.9288236218218956, 0.274714276233462, 0.2567092674090372, 0.2888863825437036, 0.285585227342003, 0.2858525797078242, 0.3903256476929361, 0.3002895576830724, 0.1341210030882778, 0.31393748468412563, 0.2732625106774037, 0.2729488361967741, 0.2151622706023537, 0.31527599105399406, 0.30414435346353663, 0.3272464874894925, 0.3035884953158393, 0.3043787494304526, 0.31032995578681954, 0.01118322273000083, 0.03867522107624133, 0.003142693264613028, 9.999999999998899e-05, 9.999999999998899e-05, 0.06313372272485651, 0.04179319496781886, 0.01460784712994978, 9.999999999998899e-05, 0.07146379686700566, 0.16434292877049905, 0.1596287792279527, 0.17052860085547272, 0.049163716730877605, 0.028519534587570172, 0.2673345291121938, 0.08775993627820022, 0.07283812266485479, 0.06722545951049053, 0.06969303705664165, 0.04900928419620543, 0.08041782025925859, 0.12247619345449745, 0.4082745207589461, 0.09942137932098527, 0.10455796224728187, 0.11953050930211717, 0.14615696078242413, 0.0823382006277521, 0.1466201005886898, 0.06671820569752474, 0.21212479444838905, 0.35927270968720704, 0.3666875610131306, 0.34713224664384934, 0.08452798449347587, 0.5692637978646483, 0.5771004036526453, 0.6199707596107583, 0.5934513198104745, 0.6191551564095095, 0.5792014858723108, 0.6161234557540658, 0.5891730249620946, 0.6248540751851932, 0.09662793871587205, 0.15636932711127904, 0.1833067255794174, 0.16135461402387374, 0.11088672343636408, 0.116451504876939, 0.13044903036621358, 0.1329877317676622, 0.0864015615638456, 0.27186594420441823, 0.2655364199946525, 0.26949331812669997, 0.25667813405966233, 0.23874112521243873, 0.17625599621330423, 0.2615304149403581, 0.323457305540502, 0.2258017960490014, 0.4527437198205171, 0.3880963623518454, 0.34300247073447354, 0.4174886805459156, 0.23721015646625, 0.4723596773069296, 0.5472630223340124, 0.5751078148102645, 0.25042398421192413, 0.22147413922282755, 0.35175029462806073, 0.17389791115316888, 0.22645928602830012, 0.2834156097171818, 0.3009900678206453, 0.22811023802156682, 0.2706183722652431, 0.21774944692311315, 0.2195403200515118, 0.22206755336781248, 0.25415514563707764, 0.27694840547322586, 0.22141647679661436, 0.24073433139181288, 0.22044856742353747, 0.2156926608882629, 0.22726311543660238, 0.2274324893838754, 0.22792940002900997, 0.19002279325786686, 0.21115765430597544, 0.2113780121003025, 0.19244396283109, 0.22553877312014659, 0.20878079954348827, 0.21059975683639354, 0.18823165236482986, 0.18827555214745628, 0.15390936432038105, 0.17278902935753104, 0.20157919753872477, 0.14866856620502533, 0.10003091421465837, 0.9384214834734638, 0.15897617417145282, 0.8655260131025424, 0.21282326613787594, 0.8076298134747878, 0.2122081979356235, 0.08314325647452392, 0.9064233195287974, 0.10529982772678648, 0.16860093478239246, 0.16740817366832383, 0.2007530010733224, 0.1891678309568563, 0.2010543902452312, 0.21206937582534802, 0.19848777592093725, 0.20624506645998475, 0.20219997675065904, 0.18742044640015687, 0.20477268226141565, 0.1663500958814882, 0.07897866423122613, 0.0860172677184553, 0.09012673774249602, 0.10370934176699831, 0.09212141604633273, 0.08576004348954958, 0.09681302843857209, 0.11073613891526679]}, "mutation_prompt": null}
{"id": "a32ed674-1471-4421-a5b8-c2dfa593e599", "solution": "import numpy as np\n\nclass EvolvedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 25  # Adjusted population size\n        self.f = 0.9  # DE scaling factor\n        self.cr = 0.8  # DE crossover probability\n        self.w = 0.7  # inertia weight for PSO\n        self.c1 = 1.6  # cognitive coefficient for PSO\n        self.c2 = 1.4  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-4  # Adjusted diversity threshold\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            # Apply DE operator with adaptive crossover\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                mutant = self.particles[a] + self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == np.random.randint(self.dim):\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Check diversity for adaptive PSO\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.95  # adapt inertia weight\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EvolvedHybridDEPSO", "description": "An evolved hybrid algorithm combining Differential Evolution, Particle Swarm Optimization, with adaptive inertia and crossover strategies for enhanced exploration and exploitation.", "configspace": "", "generation": 13, "fitness": 0.2953838114633089, "feedback": "The algorithm EvolvedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.24.", "error": "", "parent_id": "3ef5b86c-3af2-4c9a-8eee-32aade25ad1a", "metadata": {"aucs": [0.7143123377152485, 0.7315117160222976, 0.7293584502177781, 0.6841778718565008, 0.79013294550238, 0.8062953519115431, 0.7974341162069875, 0.7409306363850257, 0.7173225351772945, 0.37397687485401987, 0.45167242963204424, 0.5130770189465901, 0.38514251719056547, 0.42191168742904284, 0.46636699945355575, 0.23203489379239084, 0.33986064495346047, 0.4326649592422638, 0.1633900562750712, 0.15500037174924342, 0.334385888875643, 0.15409989558947013, 0.1345645858252883, 0.1549225140176964, 0.09452465756071537, 0.1528278222198911, 0.12146344776705953, 0.10887069554427076, 0.23119428043550894, 0.10532324264416693, 0.113784899208621, 0.1329752538035175, 0.11857779555410686, 0.1286127971967489, 0.13190909148633256, 0.13197379615309324, 0.9664109606203375, 0.9793946893291194, 0.9733282402255923, 0.9697058139311345, 0.9696603968570133, 0.9607482524286665, 0.9851975810855957, 0.9719554889576327, 0.980753806529045, 0.428403638318263, 0.3990964646824964, 0.4182936582921447, 0.398761947000672, 0.47567142891125436, 0.4489202874429158, 0.08602791053779968, 0.4331659097736198, 0.5627721768466301, 0.3498984168324726, 0.225071188636914, 0.7738871143703194, 0.20285381039646067, 0.37093278763493986, 0.27061076025304065, 0.2235893351998488, 0.6439459016844027, 0.8002162123609348, 0.18492617531081634, 0.19102428020472229, 0.1843178813100349, 0.18237679713865562, 0.18233536652184856, 0.1880653714409679, 0.17353788452752017, 0.19241861063016064, 0.19309825868072739, 0.20718261380714853, 0.12756972180081738, 0.13058388478657412, 0.1867340582297936, 0.17819862381034468, 0.1843183638164999, 0.12521089066156033, 0.21035984415069775, 0.25816325684906927, 0.04239717825232581, 9.999999999998899e-05, 0.034627763625618146, 0.04460194556781916, 0.059185575658393996, 9.999999999998899e-05, 0.007061358604632417, 9.999999999998899e-05, 0.010613491683157172, 0.18528236402990528, 0.094777354552948, 0.163715260466208, 0.18504939660020614, 0.10775380984361105, 0.07426756679871438, 0.17378470406336788, 0.10876847850833071, 0.0600036794430151, 0.040016966158251344, 0.07343492895254389, 0.02756689481659047, 0.0388378232620733, 0.17900567905457299, 0.10330756194193491, 0.0831599883432671, 0.23678055674276766, 0.05595285287153018, 0.15471263503535615, 0.0646518962829612, 0.22098402479065693, 0.14687926003703233, 0.08967413963703108, 0.15869805686735594, 0.08110289667090276, 0.07998692441451016, 0.14577491923808317, 0.48205755416546425, 0.537564534685349, 0.5098172363588308, 0.531692141518075, 0.5434790836146848, 0.5142421535696113, 0.5234188746308812, 0.492306310571491, 0.5633423548759944, 0.12301994308303033, 0.12060993388916774, 0.12792188629292067, 0.10609332883297451, 0.1424889846854841, 0.13766607978527068, 0.14926037759229493, 0.1023627583756821, 0.12612409423266746, 0.23680986857910868, 0.23433669411168523, 0.42010948068094156, 0.22161993323448792, 0.40038850431075335, 0.1644180123549811, 0.21688966875252658, 0.18794268609088316, 0.2695603068889263, 0.36067584959987165, 0.399260233879415, 0.4061919423248188, 0.37480241911358514, 0.36059188065376546, 0.389083415440159, 0.41539909002670816, 0.3826162079278881, 0.41964743365292445, 0.2954023782082994, 0.24378098132084847, 0.2939628774648049, 0.25723033330322764, 0.3050296828462101, 0.2724967241555978, 0.3495728459881954, 0.2895738318909634, 0.2612894095698737, 0.21589086670657476, 0.22036471036328953, 0.21871350769470743, 0.22758684863703316, 0.24154718049558588, 0.23152217833610977, 0.2015687542604554, 0.20626406317801327, 0.21608964027419708, 0.21723715666952104, 0.23446483194548595, 0.22056109578931105, 0.48945551106942153, 0.5917742330259823, 0.18278510470878961, 0.22977300105909104, 0.4150603352916207, 0.2169622291519211, 0.19583623898463431, 0.18706102468011387, 0.15279144413526724, 0.829480097388804, 0.19997618913899062, 0.8503166934889782, 0.16109591892937003, 0.8519480372154707, 0.17747918904711546, 0.7297608205939523, 0.1559264927202918, 0.21078296313943534, 0.20965819175949796, 0.1556748475374794, 0.6454877902147252, 0.156461131324376, 0.21222732924408927, 0.1544602230136698, 0.17550307812236565, 0.19005353701440686, 0.17469101066374804, 0.20451201651910111, 0.19356654168408927, 0.19963243518704887, 0.18342750907922278, 0.2151395886979337, 0.22265192357692531, 0.09324702860716405, 0.12166831987749793, 0.09933023990737733, 0.09021493007026127, 0.0930690812687297, 0.10268975448102469, 0.09461345667170207, 0.09389547176093016, 0.09980208451216399]}, "mutation_prompt": null}
{"id": "80bf75d9-21fd-4ce2-8780-4994a9c377c9", "solution": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5  # diversity threshold for adaptive learning\n        self.iteration = 0  # added to track the number of iterations\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1  # increment iteration count\n\n            # Dynamic parameter tuning for DE\n            self.f = 0.5 + 0.3 * np.sin(self.iteration / 50.0)  # dynamic scaling factor\n\n            # Apply DE operator\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                mutant = self.particles[a] + self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Check diversity for adaptive PSO\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9  # adapt inertia weight\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)  # dynamic cognitive coefficient\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)  # dynamic social coefficient\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "RefinedHybridDEPSO", "description": "A refined hybrid optimizer integrating Differential Evolution, Particle Swarm Optimization, and adaptive learning, enhanced by dynamic parameter tuning for improved convergence efficiency across diverse optimization landscapes.", "configspace": "", "generation": 14, "fitness": 0.3390697776847431, "feedback": "The algorithm RefinedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.28.", "error": "", "parent_id": "3ef5b86c-3af2-4c9a-8eee-32aade25ad1a", "metadata": {"aucs": [0.8947016142336115, 0.9075571749555161, 0.892365122275347, 0.8952689007655426, 0.867547045310646, 0.8808343271241403, 0.8985260546436188, 0.8978153827101025, 0.8935806257973806, 0.7869913444998626, 0.7612361335181197, 0.7082052639363383, 0.7666211897128203, 0.7672267543803447, 0.8037803379218081, 0.7741725707783326, 0.7478276046777996, 0.7824130925943027, 0.13289008210711195, 0.15804978851734253, 0.09242629670240676, 0.14464615831831473, 0.16008656968460888, 0.11792251287341038, 0.1245695742677051, 0.09525976591478191, 0.17974867885984147, 0.14182622933833589, 0.0871431880671596, 0.11429811658180022, 0.12052407412999133, 0.11023055980089447, 0.15123313459615706, 0.12923499984201559, 0.18025014140540063, 0.11567316700329089, 0.9704976229138544, 0.9625081673947278, 0.9687554167626394, 0.9720836005120299, 0.9694935404344984, 0.9642716574278738, 0.9774389828080023, 0.9752246390480531, 0.9710794280318983, 0.7367958443711152, 0.06021020673580402, 0.7634344647439943, 0.7215432283472742, 0.6135382130273703, 0.7315653030804783, 0.7130690631726188, 0.7535213418398397, 0.7101376624421485, 0.17229827086773564, 0.22558591806518435, 0.8510965370226291, 0.38065714525046956, 0.28103327293726077, 0.28000334317856224, 0.3846135509285168, 0.1791544230815354, 0.8454253309619899, 0.2365916546190372, 0.24908282832838535, 0.2699683737889612, 0.25009593233532323, 0.261988295831565, 0.20822208942146303, 0.2561170532027609, 0.1348645319511388, 0.26951129991286127, 0.25890026430160895, 0.2565223793382545, 0.13337533998043238, 0.2927072107020299, 0.3006411206612385, 0.33102959048237546, 0.2829845448895474, 0.31730926183886454, 0.2883721578035313, 0.07533353281395505, 0.08469155151479768, 0.011425958278145298, 0.014594842606613923, 0.04420921968505753, 9.999999999998899e-05, 0.006649640678131785, 0.04354115308935691, 0.08423945015737644, 0.19484018318874774, 0.10381368758779896, 0.08479540127366358, 0.08227410731910334, 0.04828580488617751, 0.04769229205726788, 0.1316002572443825, 0.12719968767277512, 0.1329340984420263, 0.09013681431809806, 0.22446679116902357, 0.16423062567649505, 0.07512145992425645, 0.07839391251179517, 0.21664934424372562, 0.1484341983921127, 0.09818057316743856, 0.07362293259619546, 0.21707170280427657, 0.06528070252382245, 0.0819561582507149, 0.18514220637653722, 0.22589091009412055, 0.006863101507811886, 0.2131005166199138, 0.16517304910777186, 0.08473441605541598, 0.5979573238426678, 0.5508662800467821, 0.5677041565653729, 0.5843944490696931, 0.6533340024777918, 0.5969506976270632, 0.6070242842069391, 0.6417222845376018, 0.5900667457497197, 0.08475540951882543, 0.08548181514305087, 0.08206902747296341, 0.13294228082814408, 0.10482646653047378, 0.11595287329529147, 0.1273103002718835, 0.1065831109307197, 0.10533641656024406, 0.19769598462397353, 0.4303625689480919, 0.1645950228266727, 0.5896215687813693, 0.22921400797641156, 0.3204670773143946, 0.3620770191979994, 0.33004547182317123, 0.7296050848068807, 0.3509877903286912, 0.4939032025790093, 0.3548506572946134, 0.4827757266245234, 0.38809955889545733, 0.317082172036545, 0.43602553842452907, 0.6104494205643127, 0.45296934791340604, 0.2616723641068667, 0.399783883512313, 0.17701066110790253, 0.3052676417779673, 0.22524354403114144, 0.35622046637975235, 0.21845789411859418, 0.2915991135703392, 0.2656593741761457, 0.23736868576845904, 0.24890925546816567, 0.21957885041307645, 0.24185887009702078, 0.20338592764174923, 0.32821453926873656, 0.3109088494260047, 0.29127138995601876, 0.21283808442580787, 0.22744733471861467, 0.22291926566841191, 0.2507306412544742, 0.19180559201715275, 0.21371092694384441, 0.21124710669711144, 0.20508405118354167, 0.21137453033536135, 0.20904411049512472, 0.16547548847808558, 0.930875596971671, 0.11324957236785882, 0.939185624394731, 0.20136000258354925, 0.20178623499937154, 0.17387358395848174, 0.1704134806483789, 0.1691172305935772, 0.8060671104248257, 0.21348045736743682, 0.1567190828378976, 0.2129993676960793, 0.16937783881480628, 0.8647344155864094, 0.10524210830829284, 0.786956154702804, 0.1675965469619488, 0.22294884136968862, 0.19597819064753652, 0.2011174210129888, 0.18821797100286264, 0.21377153220195888, 0.20335330916285643, 0.17748658047053611, 0.1862046815962104, 0.2066906673382265, 0.08259234736884469, 0.09428227655447097, 0.07207611626960675, 0.0957870887413852, 0.10729851266906842, 0.10082932058480454, 0.08641463089612167, 0.09701019331104632, 0.09511033435652372]}, "mutation_prompt": null}
{"id": "371f7ab9-b78a-4cbe-8335-b4baa8516bd8", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5  # diversity threshold for adaptive learning\n        self.diversity_probability = 0.05  # probability to reset diversity\n        self.iteration = 0  # added to track the number of iterations\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1  # increment iteration count\n\n            # Dynamic parameter tuning for DE\n            self.f = 0.5 + 0.3 * np.sin(self.iteration / 50.0)  # dynamic scaling factor\n\n            # Apply DE operator\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                mutant = self.particles[a] + self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Check diversity for adaptive PSO\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold and np.random.rand() < self.diversity_probability:\n                self.w *= 0.9  # adapt inertia weight\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)  # dynamic cognitive coefficient\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)  # dynamic social coefficient\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "An enhanced hybrid optimizer fusing Differential Evolution, Particle Swarm Optimization, and adaptive parameter adjustment, fortified with probabilistic diversity management for robust performance across varied optimization challenges.", "configspace": "", "generation": 15, "fitness": 0.3393564991057691, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.28.", "error": "", "parent_id": "80bf75d9-21fd-4ce2-8780-4994a9c377c9", "metadata": {"aucs": [0.8947016142336115, 0.9075571749555161, 0.892365122275347, 0.8952689007655426, 0.867547045310646, 0.8808343271241403, 0.8985260546436188, 0.8978153827101025, 0.8935806257973806, 0.7869913444998626, 0.7612361335181197, 0.7082052639363383, 0.7666211897128203, 0.7672267543803447, 0.8037803379218081, 0.7741725707783326, 0.7478276046777996, 0.7824130925943027, 0.13289008210898978, 0.15804978851659124, 0.0924262967022953, 0.14464615831865613, 0.16008656968386548, 0.1179225128727015, 0.1245695742685663, 0.09525976591360852, 0.17974867884284085, 0.1418262293339423, 0.08714318806717114, 0.11429811658184152, 0.12052407412995891, 0.11023055979953056, 0.15123313458594823, 0.12923499984635256, 0.18025014140185303, 0.1156731670031993, 0.9704976229138544, 0.9625081673947278, 0.9687554167626394, 0.9720836005120299, 0.9694935404344984, 0.9642716574278738, 0.9774389828080023, 0.9752246390480531, 0.9710794280318983, 0.736842313940393, 0.060210206736050154, 0.7634344647439943, 0.7215432283472742, 0.6131712386503106, 0.7315653030804783, 0.7130690631726188, 0.7535213418398397, 0.7101376624421485, 0.17229827086773564, 0.22558591806518435, 0.8510965370226291, 0.38065714525046956, 0.28103327293726077, 0.28000334317856224, 0.3846135509285168, 0.1791544230815354, 0.8454253309619899, 0.2365916546190372, 0.24908282832838535, 0.2699683737889612, 0.25009593233532323, 0.261988295831565, 0.20822208942146303, 0.2561170532027609, 0.1348645319511388, 0.26951129991286127, 0.25890026430160895, 0.2565223793382545, 0.13337533998043238, 0.2927072107020299, 0.3006411206612385, 0.3310318313901469, 0.2829845448895474, 0.31730926183886454, 0.2883721578035313, 0.07533603200224281, 0.08469160514544294, 0.011425958278145298, 0.014594842606613923, 0.04421097607500868, 9.999999999998899e-05, 0.006649640678131785, 0.04354115308935691, 0.08423945015737644, 0.19484018318874774, 0.10381368758779896, 0.08479540127366358, 0.08227410731910334, 0.04828580488617751, 0.04769229205726788, 0.1316002572443825, 0.12719968767277512, 0.1329340984420263, 0.09014183215827509, 0.22447431758611391, 0.1643212449692233, 0.07514723498303977, 0.07840278084522856, 0.2166593625239437, 0.14844587782824892, 0.0981805728431735, 0.07362293217612548, 0.2170706932679205, 0.06528087013984751, 0.08195612547783804, 0.18514242445116058, 0.22589411784843794, 0.006863099423130015, 0.21310002565097153, 0.1651729016422554, 0.08473439988677323, 0.5982717390314076, 0.5508939558628132, 0.5678585674015333, 0.5849340104385414, 0.654542181214266, 0.5969819509542651, 0.6071267738702352, 0.6421030176128504, 0.5905238168245719, 0.08475540951834026, 0.08548181514276443, 0.08206902747240963, 0.1329422808269053, 0.10482646652784644, 0.11595287329533799, 0.12731030029984935, 0.10658311092993167, 0.10533641656616877, 0.19769437102631993, 0.4303448511250536, 0.1645968134921434, 0.589638375078342, 0.22921378215815114, 0.3204675869064775, 0.3620744157192942, 0.3300509911112074, 0.7296050848068807, 0.35105063882461396, 0.4950205603322215, 0.35483866130873165, 0.48556232169973756, 0.38746693606070315, 0.3168288190299072, 0.4360763927054915, 0.6656269170337676, 0.45292048015816333, 0.2616729458078745, 0.399716896841974, 0.17701310736314313, 0.3052480592655584, 0.22524989612325785, 0.356611437542392, 0.21845585596464956, 0.29178565450469207, 0.2657749544402779, 0.23736868576845904, 0.24890925546816567, 0.21957885041307645, 0.24185887009702078, 0.20338592764174923, 0.32821846520509657, 0.31090887426750125, 0.29127138995601876, 0.21283808442580787, 0.22744733471667422, 0.22291926566904596, 0.25073064125416544, 0.19180559201714364, 0.21371092694353422, 0.2112471066964099, 0.205084051182721, 0.21137453033429643, 0.2090441104946824, 0.16547548847808158, 0.930875596971671, 0.11324957236785849, 0.939185624394731, 0.20136000258353937, 0.20178623499928694, 0.17387358395848695, 0.17041348064838202, 0.16911723059357353, 0.8060671104248257, 0.21348045736736432, 0.1567190828378895, 0.21299936769605177, 0.16937783881480628, 0.8647344155864094, 0.10524210830831393, 0.786956154702804, 0.16759654696194481, 0.22294884136968862, 0.19597819064753652, 0.2011174210129888, 0.18821797100286264, 0.21377153220195888, 0.20335330916285643, 0.17748658047053611, 0.1862046815962104, 0.2066906673382265, 0.08259234731951615, 0.09428227668996259, 0.07207611625228294, 0.0957870887413852, 0.10729851266888979, 0.10082932121036936, 0.08641463089612167, 0.09701019333527616, 0.09511033436356608]}, "mutation_prompt": null}
{"id": "b91c7bcb-6958-4d8d-bb09-e5e24f03ed62", "solution": "import numpy as np\n\nclass AdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5  # diversity threshold for adaptive learning\n        self.diversity_probability = 0.05  # probability to reset diversity\n        self.iteration = 0  # added to track the number of iterations\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1  # increment iteration count\n\n            # Dynamic parameter tuning for DE\n            self.f = 0.5 + 0.3 * np.cos(self.iteration / 50.0)  # dynamic scaling factor\n\n            # Apply DE operator\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                mutant = self.particles[a] + self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Check diversity for adaptive PSO\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold and np.random.rand() < self.diversity_probability:\n                self.w *= 0.9  # adapt inertia weight\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.sin(self.iteration / 40.0)  # dynamic cognitive coefficient\n            self.c2 = 1.5 + 0.5 * np.cos(self.iteration / 40.0)  # dynamic social coefficient\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "AdaptiveHybridOptimizer", "description": "An adaptive hybrid optimizer combining Differential Evolution and Particle Swarm Optimization with dynamic parameter tuning and learning mechanisms to tackle diverse optimization challenges.", "configspace": "", "generation": 16, "fitness": 0.3315769619771661, "feedback": "The algorithm AdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.28.", "error": "", "parent_id": "371f7ab9-b78a-4cbe-8335-b4baa8516bd8", "metadata": {"aucs": [0.8695029994338257, 0.8759639862191428, 0.8733517624187285, 0.8717319700503519, 0.8664014440037304, 0.8961787173978673, 0.8755061024875422, 0.8896913857711612, 0.8563111155743082, 0.7629268775686485, 0.7640372259463512, 0.7725212081033725, 0.7469211566960157, 0.7743601905343829, 0.7708002622053758, 0.7618788038066513, 0.7686370338270833, 0.731045384102539, 0.08835443135850618, 0.13850082564534238, 0.09996843977675585, 0.1512996890823044, 0.15801440956195767, 0.1465962308192369, 0.16137241651862566, 0.1531003637895192, 0.14477600099802024, 0.09364763933542763, 0.08897335680998764, 0.13254623964573276, 0.1742049592422138, 0.10574691371214195, 0.15721154993639352, 0.10619174709231005, 0.11717186847147154, 0.1082963200626531, 0.9788723141339924, 0.9718527254280305, 0.9610330545534513, 0.9847255432569386, 0.982444497174825, 0.9790746180531206, 0.9874648482476752, 0.977327803883146, 0.9836491791124383, 0.7378738300506948, 0.05993135782733039, 0.7297007632641281, 0.732312236117286, 0.7784658695184331, 0.783029531416723, 0.08885558939393523, 0.0890629897881432, 0.7459663224056148, 0.39354017056222057, 0.22994327740692655, 0.22852740863166798, 0.2139798697148123, 0.11360061682714495, 0.8909853185548549, 0.23122354104330523, 0.23193997089420604, 0.9101306923477056, 0.19043553373836997, 0.2599222006153993, 0.25120095754782035, 0.3036202528955215, 0.28821086685637387, 0.30073681145992837, 0.28675158723448735, 0.13412061917938067, 0.26548585443651784, 0.2690185300425417, 0.2869923907588836, 0.22345024911521916, 0.2866197013989461, 0.2857799283417203, 0.3310338698920794, 0.3151251757528658, 0.12485745189107056, 0.2892102794020921, 9.999999999998899e-05, 0.12927783507203894, 0.07060350669649229, 0.03391087529464698, 9.999999999998899e-05, 0.048457647990260755, 0.05377334169420023, 0.007885160813584813, 0.01758155070735079, 0.13490652006313886, 0.12582858086423587, 0.16398964728050558, 0.10338558109194729, 0.010964360297146758, 0.04592328689983771, 0.12626788173668613, 0.061998334140268896, 0.08585159474453852, 0.0950398935969834, 0.04314643752170466, 0.0778162657303163, 0.07559943580610906, 0.09262160665449137, 0.07758667120353324, 0.16105932857169503, 0.09973840073529572, 0.15432562055323362, 0.2957543723912429, 0.04359853385956214, 0.14799995786454712, 0.054861365502511084, 0.2358649424748973, 0.1157828189582839, 0.22062154671709733, 0.12932504402757672, 0.08363530993938106, 0.573667827591267, 0.5711402860616104, 0.5435465953880733, 0.5654493032963688, 0.5919396892997595, 0.5981311270061775, 0.5768105588747949, 0.5570694258371856, 0.5512035098524853, 0.1215602449989801, 0.13605976334276915, 0.175772339596313, 0.12243941162957195, 0.07262755704119372, 0.13310781401374627, 0.1548120240738553, 0.1458138278022596, 0.1838679981663408, 0.46957014956059007, 0.2546430460433874, 0.16358230555494213, 0.2746547117049979, 0.6228272142566216, 0.24336493736234133, 0.2344057461088216, 0.4677827788471389, 0.21564315833660108, 0.5373912632805302, 0.42443097630105253, 0.24880803211670377, 0.4393108582513351, 0.2995290610415464, 0.4498632884561321, 0.432318681705419, 0.5365709043144247, 0.5897510721801267, 0.27616497638017246, 0.23241321851753827, 0.2895699434702257, 0.24191825705267467, 0.24002737387571227, 0.25134184401645343, 0.3710545578381321, 0.17501854855044752, 0.2647180480193464, 0.25809800311347264, 0.20027904393417506, 0.2620293645254831, 0.20981084457684818, 0.21192292965084936, 0.2144144613217056, 0.2615320324723579, 0.24663523789875652, 0.24979819161099004, 0.20992944259891955, 0.7767179285481696, 0.7593426868340887, 0.22777376086174173, 0.2117587658193565, 0.21118420980098618, 0.20349455508990932, 0.22505800547539412, 0.18512263332673484, 0.188176566162493, 0.17789133122339373, 0.17592686235363475, 0.9295926940159235, 0.20131507813873672, 0.16689213818753668, 0.12172206520103723, 0.9151266953223279, 0.16264811071793117, 0.8100593869005561, 0.21280277163661332, 0.21155783714908183, 0.2124966356130743, 0.16806676443511004, 0.9056327245884158, 0.10520180433294624, 0.20909767028717574, 0.16767595491065745, 0.18596884733665175, 0.1801034960820702, 0.1954716343689049, 0.20011103557903676, 0.20030271763800422, 0.19825421391478282, 0.20109255905243795, 0.21294534465407067, 0.20403155874143764, 0.0998014148218137, 0.09343652589411289, 0.07755710917963787, 0.09904526553022586, 0.10706078626629145, 0.11344425926406387, 0.0957737285576914, 0.10345167710692826, 0.09728168175796403]}, "mutation_prompt": null}
{"id": "cc353724-1729-40cd-aa9b-9953714e80ae", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A refined hybrid optimizer incorporating adaptive chaotic maps in DEPSO for enhanced exploration and convergence.", "configspace": "", "generation": 17, "fitness": 0.3513507498892743, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.29.", "error": "", "parent_id": "371f7ab9-b78a-4cbe-8335-b4baa8516bd8", "metadata": {"aucs": [0.8865276906432433, 0.9020532548803202, 0.8929687050976703, 0.9069966467491789, 0.8983603223003787, 0.9022140074472543, 0.8838639783889877, 0.8886653828703049, 0.889752534826144, 0.7567698703303883, 0.784578368098034, 0.8076249809202548, 0.7611720006041811, 0.7986347352301275, 0.8050952302753023, 0.7936777043904858, 0.8107862909162267, 0.7638655686477411, 0.14306028296887274, 0.18771148863225673, 0.09076269380504487, 0.14472904467535863, 0.18827718037504793, 0.14600008067707715, 0.18654152199131935, 0.11161280818292418, 0.11200366762783509, 0.13393502172957683, 0.14641399913557107, 0.1432167792015192, 0.11181421186718143, 0.09209417505561412, 0.11938418806199658, 0.11206983601831055, 0.11095636186680169, 0.10912525701701048, 0.9717271359469163, 0.9628507846149675, 0.9377341630520235, 0.9810288407887259, 0.9785915503130439, 0.9770423747813494, 0.9783473338829307, 0.9712621930647505, 0.9787075504592555, 0.7607315187580301, 0.7749069267760285, 0.7630288578874603, 0.7507532481153396, 0.6554370351125884, 0.7762723104136083, 0.7499504173558014, 0.6968283959747328, 0.7389586451693928, 0.1721225825938858, 0.22891630584450517, 0.11324758049764427, 0.3549737812815622, 0.2807957237653095, 0.28145549322917607, 0.18018767969655092, 0.2386988483653335, 0.9395469978455472, 0.2720537562684263, 0.1357109215500677, 0.288515417628357, 0.27358595508171457, 0.28033933355072405, 0.3483295090039492, 0.29980271067857245, 0.13457278726329025, 0.31624018099324525, 0.28347106445129555, 0.27653913969396915, 0.2892909131254505, 0.32904479577095047, 0.30792895015902, 0.3267380918354402, 0.3033156492629593, 0.2088685743639237, 0.2906120113344278, 0.004881953303818798, 0.08432094844164972, 0.01040324864575648, 0.08307057080589308, 0.0631748299553836, 0.031141171943307566, 0.038932547461408507, 0.021942713170019723, 0.09321589178997347, 0.14820762824482314, 0.14111157929981544, 0.09939347465031478, 0.07351212675576657, 0.14911297504852605, 0.02739581001833591, 0.11477783328277313, 0.09375370099990121, 0.12437319484907039, 0.07875046545806708, 0.12463510807347011, 0.14210128121458188, 0.07919284437097684, 0.0801485337679555, 0.13337703281066082, 0.19524821804991244, 0.10442299933492127, 0.07342327849013242, 0.16578167026123625, 0.1853016315404299, 0.1189542819871422, 0.1574945670012905, 0.18360986723287642, 0.2558817728796652, 0.12448657793629136, 0.25405459307747846, 0.1254414517844874, 0.5407077538029146, 0.6006067397749144, 0.5396897498932287, 0.5489927270360135, 0.5891834596503931, 0.5459801886932765, 0.5877025571595188, 0.58912009886935, 0.5796039758319813, 0.07975439706166598, 0.10110173168052605, 0.0755122787624074, 0.16076138881367696, 0.10587421420661025, 0.09908423757627094, 0.11384860622149795, 0.14412899438570692, 0.10610491466439798, 0.22279569248288034, 0.6592237296261918, 0.22467227789135458, 0.27264975790467794, 0.42228702264236595, 0.4427009503531557, 0.5283272114477804, 0.21131508909474783, 0.3463028054853772, 0.5602848907432856, 0.5870043317671049, 0.24980633166770938, 0.37827330003298987, 0.3159543684158136, 0.3948951692827499, 0.5338080159903202, 0.6386237352364159, 0.19094651398173923, 0.2682466646833648, 0.24944249579405708, 0.20048413900667417, 0.3126123000671225, 0.19508244130654495, 0.2440464616149688, 0.2746657038803456, 0.2758095868983087, 0.1718425074209099, 0.24221577925087046, 0.24277264917923613, 0.22753707311652804, 0.21621523555871425, 0.23220195984323055, 0.2121859746984508, 0.22233176434332813, 0.19428032015735874, 0.2940143940691601, 0.18346601962379372, 0.2507595245585167, 0.2074744620231186, 0.2296346173180046, 0.7839070787440949, 0.18887893138201983, 0.19948332275076253, 0.2261375176508097, 0.19661374747919813, 0.9185297033957897, 0.17730516387770456, 0.11326657578340704, 0.17278331750195008, 0.9190619999789291, 0.2007124882642538, 0.0996663158636657, 0.16991723780351253, 0.16271709766976927, 0.8243727383661772, 0.8166819556788825, 0.7311027166633209, 0.9133133255502286, 0.8484364245717022, 0.7770450456081295, 0.10514634504197418, 0.1699183301713061, 0.16636178423956227, 0.19554443874623362, 0.24430239869142467, 0.21100720171394982, 0.1973610633324807, 0.25121027229113, 0.19102423719310313, 0.2563067934359131, 0.23300659057012685, 0.22269509176237645, 0.08892873400730372, 0.07113752042749677, 0.11154483811644855, 0.0966630146129761, 0.0829219834948779, 0.14774202050214513, 0.10337404775080683, 0.10543583486427055, 0.09783716494350791]}, "mutation_prompt": null}
{"id": "9c817bfd-ec54-4b8a-b3f7-f625996b75fe", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Adjust population size dynamically\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, self.initial_population_size - int((evaluations / self.budget) * self.initial_population_size))\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A refined hybrid optimizer incorporating adaptive chaotic maps in DEPSO with variable population size for enhanced exploration and convergence.", "configspace": "", "generation": 18, "fitness": 0.34868538738072447, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.29.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.8865276906432433, 0.9020532548803202, 0.8929687050976703, 0.9069966467491789, 0.8983603223003787, 0.9022140074472543, 0.8838639783889877, 0.8886653828703049, 0.889752534826144, 0.7567698703303883, 0.784578368098034, 0.8076249809202548, 0.7611720006041811, 0.7986347352301275, 0.8050952302753023, 0.7936777043904858, 0.8107862909162267, 0.7638655686477411, 0.14306028296887274, 0.18771148863181808, 0.09076269380504487, 0.14472904467535863, 0.18827718037504793, 0.14600008067707715, 0.18654152199131935, 0.11161280818292418, 0.11200366762783509, 0.13393502172957683, 0.14641399913557107, 0.1432167792015192, 0.11181421186718143, 0.09209417505561412, 0.11938418806199658, 0.11206983601831055, 0.11095636186680169, 0.10912525701701048, 0.9717271359469163, 0.9628507846149675, 0.9377341630520235, 0.9810288407887259, 0.9785915503130439, 0.9770423747813494, 0.9783473338829307, 0.9712621930647505, 0.9787075504592555, 0.7600445805753058, 0.7749312067634847, 0.7632869756975216, 0.7508382815461009, 0.6599692410298303, 0.7762723104136083, 0.7503856289772064, 0.7021945935369135, 0.7395674245226367, 0.1721225825938858, 0.22891630584450517, 0.11324758049764427, 0.3549737812815622, 0.2807957237653095, 0.28145549322917607, 0.18018767969655092, 0.2386988483653335, 0.9395469978455472, 0.25408033637794625, 0.1356713692894771, 0.2579568439843183, 0.2235431677036287, 0.2420318033620078, 0.3219919337759607, 0.25928203230736735, 0.13457280255371074, 0.29807566568612953, 0.2630549237249975, 0.2545551204948151, 0.27311896563737015, 0.28408598819431186, 0.2853599979510252, 0.29619461023760996, 0.28940188166401726, 0.2049863946762981, 0.26650453226642146, 0.00035513626664174236, 0.08254685426021657, 0.008842752719843916, 0.08114979042287473, 0.0620733880154436, 0.03110175904135626, 0.03814081563049476, 0.015556645064009889, 0.0920430262521098, 0.14724368994716674, 0.1395542848087291, 0.09999367242020474, 0.07405581869797861, 0.15044633474836833, 0.025273076899300806, 0.12076353345000812, 0.09354686016355207, 0.12345364357749788, 0.07866988854734824, 0.12460131507948102, 0.14208976110903526, 0.07919284437097684, 0.0801485337679555, 0.13337644449619745, 0.1952458770708364, 0.10442299933492127, 0.07342327849013242, 0.16578167026050084, 0.18530163107908193, 0.11895428198628832, 0.1574945670012905, 0.18360986723255124, 0.2558817723929825, 0.12448657791480744, 0.254054593077479, 0.1254414501776684, 0.5370395115585356, 0.5992457840152958, 0.5351873637805195, 0.5474342636009021, 0.5911604801423029, 0.5424760604937322, 0.5900055897511232, 0.5832742609031472, 0.5814850005414671, 0.07975439706166598, 0.10110173168052605, 0.07551227875960265, 0.16076138881367696, 0.10587421420661025, 0.09908423757627094, 0.11384860622149795, 0.14412899438570692, 0.10610491466439798, 0.22282422483356246, 0.5929140431769372, 0.2246718408609868, 0.2726482141315024, 0.42228165231264914, 0.4420311509279533, 0.5272883479607362, 0.21125020652727433, 0.34630279152476673, 0.5609893281262213, 0.5804167745631591, 0.24980642891464844, 0.378273383956673, 0.3159018185482171, 0.39487792776516994, 0.5334476419862886, 0.6386524196853691, 0.19094259097663968, 0.268246684224569, 0.24944359544534522, 0.20048485841728503, 0.31243715509226655, 0.19508241867801002, 0.24403179118960439, 0.2746652947280118, 0.27584877124187335, 0.1718422826336149, 0.23705799624357582, 0.23604730166874743, 0.22534553107249444, 0.2097341992972711, 0.23977630202735178, 0.21086343722689194, 0.22219792029413277, 0.19428032015735874, 0.2836187389691891, 0.18346601962379372, 0.2507595245585167, 0.2074744620231186, 0.2296346173180046, 0.7839070787440949, 0.18887893138201983, 0.19948332275076253, 0.2261375176508097, 0.19661374747919813, 0.9185297033957897, 0.1773051638773555, 0.11326657578340704, 0.17278331750195008, 0.9190619999789291, 0.2007124882642538, 0.0996663158636657, 0.16991723780351253, 0.16271709766976927, 0.8243727383661772, 0.8167211257284931, 0.7145357049290744, 0.9133133255502286, 0.8484364245717022, 0.7763400435674486, 0.10514634504197418, 0.16991833017130498, 0.16636178423960246, 0.19534369630858195, 0.2454609204902075, 0.20282465559286733, 0.19745813147069802, 0.25228542146060073, 0.19252369237352118, 0.25131657152266695, 0.2346701260947318, 0.21211072214904547, 0.08892873401938428, 0.07113766828227686, 0.111544763538302, 0.0966810589718865, 0.08292198934646289, 0.14774202041571594, 0.10337408147811489, 0.10558706210623892, 0.09783711098295811]}, "mutation_prompt": null}
{"id": "ff5ae46e-2bb2-4803-84cc-ad77c9407283", "solution": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x * 0.6 + 0.5, 1.0)  # Modified chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 50.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.95  # Slightly adjusted inertia reduction\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.4 + 0.6 * np.cos(self.iteration / 60.0)  # Adjusted modulation\n            self.c2 = 1.6 + 0.4 * np.sin(self.iteration / 60.0)  # Adjusted modulation\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "RefinedHybridDEPSO", "description": "A hybrid optimizer fusing chaotic DEPSO with adaptive inertia and randomized mutation for diversity-driven convergence.", "configspace": "", "generation": 19, "fitness": 0.34281492490954113, "feedback": "The algorithm RefinedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.8761656352707496, 0.8912957697840529, 0.8963983444904536, 0.8885864799675729, 0.8840692394180227, 0.8980071689155126, 0.8911019559729472, 0.8970905004037273, 0.8989834326064038, 0.7641391715220882, 0.787917276485713, 0.761896480700291, 0.7803427224566242, 0.7825910113986563, 0.07034001214016683, 0.808281826439786, 0.7537048823277143, 0.761778149094511, 0.0685072655540675, 0.14769772840237927, 0.09755564523289628, 0.11652585733410126, 0.10125932627863798, 0.1463833047093176, 0.14357732237875676, 0.18684674899854237, 0.12117851410934777, 0.1175163397669261, 0.056280255137628576, 0.10046199607317574, 0.11167191939739607, 0.11316914005434442, 0.1613556007257172, 0.09767649296399561, 0.15959543923326613, 0.11603972978806831, 0.9743163282665791, 0.9564180846800764, 0.965208795328565, 0.9608414873758685, 0.9711107772881122, 0.9709320344111214, 0.9676472100590715, 0.9677115866085071, 0.970047088646909, 0.7662002921058693, 0.7267024585001867, 0.7279787318660385, 0.7755001682361471, 0.7803148091165403, 0.7304469969880918, 0.7209723509831154, 0.7200327600475841, 0.7110312524053726, 0.8060121405136654, 0.8216796363128118, 0.13926748278718348, 0.28241512092543886, 0.3738281504303368, 0.8985161930576249, 0.22429144677069857, 0.2371516825812049, 0.8625174251274148, 0.13455613409335565, 0.28492476422794066, 0.13539350363334357, 0.3060808202402344, 0.2607348063991719, 0.16944774524354056, 0.3067248791060533, 0.277103129317956, 0.2867982176382903, 0.26532170771972263, 0.2805135206796767, 0.1896041418415897, 0.33811878572168697, 0.269967594839838, 0.13188172979351898, 0.3164825548131911, 0.13576268507696054, 0.2808476733028983, 0.03862625657251906, 0.080067534274193, 9.999999999998899e-05, 0.0011836067678202555, 0.05347263032044247, 0.04674906064064421, 0.06077018847585636, 0.020496046012178026, 0.03689382318446954, 0.06174371141002066, 0.0652293820006482, 0.05816157193956073, 0.0846684698971536, 0.03763686876509997, 0.03506646046951478, 0.10029803969139772, 0.07912618301770913, 0.1337345349325043, 0.2595048272134528, 0.06504453106687647, 0.11874972885810553, 0.08144030374287381, 0.07782834405701655, 0.09941343910204559, 0.09730566276564045, 0.10114090124042163, 0.07407541191271738, 0.1357799541526551, 0.2691910341337064, 0.1915344771179105, 0.13870589031532177, 0.3026271478556337, 0.11444024586578638, 0.15970334408629572, 0.05001751355772699, 0.08462514348439931, 0.5768235623092562, 0.5582757726658021, 0.554338931714403, 0.5609732163723238, 0.6113443599963477, 0.5752733192268278, 0.587671516372164, 0.5934860919485346, 0.5912230947800019, 0.16092707473130818, 0.11078287576422552, 0.11022111290187875, 0.09363193046481533, 0.07929735430079221, 0.11876711219096725, 0.14703212297376833, 0.1507554336857615, 0.11319334822731031, 0.35043543377605324, 0.37676881459495404, 0.21493830300405148, 0.26989352871262406, 0.3533598744764771, 0.18031753442621357, 0.2812552336661531, 0.4175488803754205, 0.20090289887540225, 0.5649528596125474, 0.5746019732312061, 0.20066322987631913, 0.5269741880118277, 0.42880136369174104, 0.303292568459153, 0.26670087128739883, 0.4883838423826754, 0.3213651575480867, 0.38729810133394715, 0.2871351975302482, 0.20315519911069657, 0.2992404605207486, 0.2926670920691872, 0.1470811575458072, 0.48954752616443264, 0.34262206325698585, 0.17045346843017217, 0.24237338853584356, 0.25884339513080457, 0.22541405598596276, 0.25421018650121663, 0.23235509628188633, 0.20084647119090482, 0.2588927223176746, 0.22427654440840816, 0.26488041488417013, 0.25383849208481135, 0.18844188075158164, 0.199032770763785, 0.20483956572323614, 0.7791825727425817, 0.19820380592427322, 0.24956479710681057, 0.20880893887039786, 0.2225081715140792, 0.17707590266979334, 0.9323537781956583, 0.15355159078964042, 0.17304090659046378, 0.2016300207611723, 0.929445645919941, 0.1228743879263906, 0.17051353691171567, 0.15391012745281063, 0.8279275416306371, 0.7847412496610875, 0.8264737694934261, 0.2119315736580728, 0.16932713484697814, 0.8101925453558708, 0.10531663239020672, 0.1687509026302063, 0.166829368725526, 0.24468715733136848, 0.18932769994884024, 0.21971578899427713, 0.17984864404544265, 0.18404564079504293, 0.2242465942755486, 0.19955772440030173, 0.2599023036849071, 0.20686718708906027, 0.10138898915109074, 0.06824267222305314, 0.10533232536038961, 0.08231391063909432, 0.10607767850824001, 0.12367339969279423, 0.10303776288113609, 0.10295575182808536, 0.10952977114417661]}, "mutation_prompt": null}
{"id": "424801d5-31d6-487a-ad04-c74f713c9454", "solution": "import numpy as np\n\nclass AdaptiveFractalDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.population_growth_rate = 0.1  # Allows for dynamic population resizing\n        self.f = 0.8\n        self.cr = 0.9\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.vel_max = 1.0\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def fractal_map(self, x):\n        return (np.sin(x * np.pi) + 1) / 2  # Fractal-inspired transformation\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with fractal map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                fractal_factor = self.fractal_map(self.iteration / 100.0)\n                mutant = self.particles[a] + fractal_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Dynamic population resizing\n            if np.random.rand() < self.population_growth_rate:\n                new_individuals = np.random.uniform(self.lb, self.ub, (2, self.dim))\n                new_fitness = np.array([func(ind) for ind in new_individuals])\n                evaluations += 2\n                self.particles = np.vstack((self.particles, new_individuals))\n                fitness = np.append(fitness, new_fitness)\n                personal_best_fitness = np.append(personal_best_fitness, new_fitness)\n                self.personal_best = np.vstack((self.personal_best, new_individuals))\n                self.population_size += 2\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "AdaptiveFractalDEPSO", "description": "An improved adaptive DEPSO model incorporates fractal-inspired velocity adjustments and dynamic population resizing for enhanced adaptability.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 20 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 20 is out of bounds for axis 0 with size 20')", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {}, "mutation_prompt": null}
{"id": "651ba1b7-4017-4a43-93ed-03cad7ead991", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A refined hybrid optimizer incorporating adaptive chaotic maps in DEPSO for enhanced exploration and convergence.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.8865276906432433, 0.9020532548803202, 0.8929687050976703, 0.9069966467491789, 0.8983603223003787, 0.9022140074472543, 0.8838639783889877, 0.8886653828703049, 0.889752534826144, 0.7567698703303883, 0.784578368098034, 0.8076249809202548, 0.7611720006041811, 0.7986347352301275, 0.8050952302753023, 0.7936777043904858, 0.8107862909162267, 0.7638655686477411, 0.14306028296887274, 0.18771148863225673, 0.09076269380504487, 0.14472904467535863, 0.18827718037504793, 0.14600008067707715, 0.18654152199131935, 0.11161280818292418, 0.11200366762783509, 0.13393502172957683, 0.14641399913557107, 0.1432167792015192, 0.11181421186718143, 0.09209417505561412, 0.11938418806199658, 0.11206983601831055, 0.11095636186680169, 0.10912525701701048, 0.9717271359469163, 0.9628507846149675, 0.9377341630520235, 0.9810288407887259, 0.9785915503130439, 0.9770423747813494, 0.9783473338829307, 0.9712621930647505, 0.9787075504592555, 0.7607315187580301, 0.7749069267760285, 0.7630288578874603, 0.7507532481153396, 0.6554370351125884, 0.7762723104136083, 0.7499504173558014, 0.6968283959747328, 0.7389586451693928, 0.1721225825938858, 0.22891630584450517, 0.11324758049764427, 0.3549737812815622, 0.2807957237653095, 0.28145549322917607, 0.18018767969655092, 0.2386988483653335, 0.9395469978455472, 0.2720537562684263, 0.1357109215500677, 0.288515417628357, 0.27358595508171457, 0.28033933355072405, 0.3483295090039492, 0.29980271067857245, 0.13457278726329025, 0.31624018099324525, 0.28347106445129555, 0.27653913969396915, 0.2892909131254505, 0.32904479577095047, 0.30792895015902, 0.3267380918354402, 0.3033156492629593, 0.2088685743639237, 0.2906120113344278, 0.004881953303818798, 0.08432094844164972, 0.01040324864575648, 0.08307057080589308, 0.0631748299553836, 0.031141171943307566, 0.038932547461408507, 0.021942713170019723, 0.09321589178997347, 0.14820762824482314, 0.14111157929981544, 0.09939347465031478, 0.07351212675576657, 0.14911297504852605, 0.02739581001833591, 0.11477783328277313, 0.09375370099990121, 0.12437319484907039, 0.07875046545806708, 0.12463510807347011, 0.14210128121458188, 0.07919284437097684, 0.0801485337679555, 0.13337703281066082, 0.19524821804991244, 0.10442299933492127, 0.07342327849013242, 0.16578167026123625, 0.1853016315404299, 0.1189542819871422, 0.1574945670012905, 0.18360986723287642, 0.2558817728796652, 0.12448657793629136, 0.25405459307747846, 0.1254414517844874, 0.5407077538029146, 0.6006067397749144, 0.5396897498932287, 0.5489927270360135, 0.5891834596503931, 0.5459801886932765, 0.5877025571595188, 0.58912009886935, 0.5796039758319813, 0.07975439706166598, 0.10110173168052605, 0.0755122787624074, 0.16076138881367696, 0.10587421420661025, 0.09908423757627094, 0.11384860622149795, 0.14412899438570692, 0.10610491466439798, 0.22279569248288034, 0.6592237296261918, 0.22467227789135458, 0.27264975790467794, 0.42228702264236595, 0.4427009503531557, 0.5283272114477804, 0.21131508909474783, 0.3463028054853772, 0.5602848907432856, 0.5870043317671049, 0.24980633166770938, 0.37827330003298987, 0.3159543684158136, 0.3948951692827499, 0.5338080159903202, 0.6386237352364159, 0.19094651398173923, 0.2682466646833648, 0.24944249579405708, 0.20048413900667417, 0.3126123000671225, 0.19508244130654495, 0.2440464616149688, 0.2746657038803456, 0.2758095868983087, 0.1718425074209099, 0.24221577925087046, 0.24277264917923613, 0.22753707311652804, 0.21621523555871425, 0.23220195984323055, 0.2121859746984508, 0.22233176434332813, 0.19428032015735874, 0.2940143940691601, 0.18346601962379372, 0.2507595245585167, 0.2074744620231186, 0.2296346173180046, 0.7839070787440949, 0.18887893138201983, 0.19948332275076253, 0.2261375176508097, 0.19661374747919813, 0.9185297033957897, 0.17730516387770456, 0.11326657578340704, 0.17278331750195008, 0.9190619999789291, 0.2007124882642538, 0.0996663158636657, 0.16991723780351253, 0.16271709766976927, 0.8243727383661772, 0.8166819556788825, 0.7311027166633209, 0.9133133255502286, 0.8484364245717022, 0.7770450456081295, 0.10514634504197418, 0.1699183301713061, 0.16636178423956227, 0.19554443874623362, 0.24430239869142467, 0.21100720171394982, 0.1973610633324807, 0.25121027229113, 0.19102423719310313, 0.2563067934359131, 0.23300659057012685, 0.22269509176237645, 0.08892873400730372, 0.07113752042749677, 0.11154483811644855, 0.0966630146129761, 0.0829219834948779, 0.14774202050214513, 0.10337404775080683, 0.10543583486427055, 0.09783716494350791]}, "mutation_prompt": null}
{"id": "088b367c-7e87-4c31-b05c-c6a3d5cd61d6", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n        self.learning_rate = 0.1  # Initial learning rate for adaptive adjustments\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def stochastic_perturbation(self, vector):\n        return vector + np.random.normal(0, 0.1, vector.shape)\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial = self.stochastic_perturbation(trial)\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n            self.learning_rate = 0.1 + 0.1 * np.sin(self.iteration / 25.0)  # Adjust learning rate dynamically\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.learning_rate * self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "AdaptiveHybridDEPSO", "description": "An adaptive hybrid optimizer integrating dynamic learning rates and stochastic perturbation in DEPSO for improved balance between exploration and exploitation.", "configspace": "", "generation": 22, "fitness": 0.2562974426566203, "feedback": "The algorithm AdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.22.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.5177410848351227, 0.6992247322746968, 0.7275208065023283, 0.6065368169394376, 0.7908025678930823, 0.660861890033565, 0.6590936503545672, 0.6069695088879443, 0.6442314603617576, 0.30219876668654966, 0.17595554746668318, 9.999999999998899e-05, 0.008190109148246139, 0.1672183740722174, 0.1394839156012191, 0.02043529273109268, 0.2235703591585454, 0.18333686402085225, 0.12020208962029932, 0.16026643615712177, 0.1600024129431098, 0.11600963525179453, 0.13979167680324012, 0.15690397539554668, 0.13409718155955086, 0.1239688829469544, 0.14115892362468763, 0.09352150537533377, 0.10220161687040596, 0.09829442757815288, 0.09520522372146711, 0.08787242132312689, 0.08103807924735862, 0.11464509515482535, 0.12170719497679816, 0.11373026775507422, 0.9123217112559706, 0.9092548034062448, 0.932316915684813, 0.9340837364286669, 0.9382456829102038, 0.9294485804020555, 0.9568538166625888, 0.948177857437213, 0.9358036383804085, 0.33209125553127383, 0.3233024125531251, 0.3457193363393689, 0.3320124011859398, 0.3218147341014266, 0.3368736883609007, 0.319836095709353, 0.3104761890401254, 0.3429193745117043, 0.665353451421208, 0.9040666810953931, 0.16007195884989756, 0.8869232720228178, 0.27993417742586735, 0.47097566768737675, 0.39574213435757943, 0.17611074561661988, 0.3818067207812943, 0.16102300167577954, 0.24964557506127272, 0.13161559077463536, 0.1589551808390166, 0.13985727258636094, 0.1702041508718265, 0.19990058048851922, 0.1680843831749711, 0.16614104963815024, 0.15483905421050037, 0.16398894938065678, 0.11921445036700407, 0.17228086959650113, 0.1507113991519563, 0.14433217398037634, 0.1665877290483717, 0.13119264010941445, 0.12421954870663499, 9.999999999998899e-05, 0.14875918419180978, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.047431056253505965, 9.999999999998899e-05, 0.010934862944571022, 0.0847731080156856, 0.051090248553583684, 0.0662768963244389, 0.05166122768666903, 0.180833934284655, 0.05298011828695126, 0.09412630575254388, 0.09460948328400609, 0.1259277340648165, 0.06509208624179519, 0.005477970725732528, 0.1226865718168958, 0.0839759586124581, 0.1138238429483781, 0.2731131659051843, 0.09791454534054433, 0.202306938562819, 0.07971519455461074, 0.0767401517288756, 0.15781326121735895, 0.16011908562027144, 0.1632622486002543, 0.04853382375393134, 0.07767463856377022, 0.1396290486024434, 0.281369574507332, 0.21779820921886817, 0.4774949623320932, 0.47985871649068135, 0.510753990193278, 0.45102838931549283, 0.428924293108929, 0.44103660349470564, 0.4406494536891311, 0.5240039158510806, 0.48865218116525355, 0.12341568244456302, 0.0890038313624596, 0.15150177573009294, 0.1316628890231537, 0.10519875494639586, 0.14073779691554833, 0.12073962978282105, 0.15437075453127724, 0.07969532249345157, 0.29555222827813155, 0.20906787878673638, 0.24081192533392448, 0.22239622728935082, 0.16751246987501367, 0.24193127984389862, 0.18961988049221445, 0.2488066090852109, 0.18883226730233682, 0.3040582954297204, 0.30134881644627365, 0.2890610578486674, 0.31810626415771226, 0.2091747064833438, 0.2551218181680983, 0.32934958146201965, 0.28824950951442474, 0.38178413643948506, 0.20199667184738623, 0.2697233913759164, 0.21238220240340966, 0.2207953723550079, 0.21260090943550114, 0.26706355213996147, 0.1289389132275166, 0.25861176637197514, 0.2454740289907853, 0.22477990510661972, 0.196681788601347, 0.24811430627398667, 0.21709276942873434, 0.26828032004316515, 0.2360000354244115, 0.26827168816090596, 0.2603440699278853, 0.20066169367632025, 0.19732635838741708, 0.17674252714616612, 0.19014622081866872, 0.2058133447199192, 0.19230294520826474, 0.18020144201493726, 0.19060067701379746, 0.22543852461726266, 0.18861061936277745, 0.19772073799067524, 0.17083177592367937, 0.1844533694794016, 0.17628499949151533, 0.1973309640199582, 0.8583170971203963, 0.16189956600574973, 0.16825414296039054, 0.1728116459746568, 0.15592968365198212, 0.47120332359905714, 0.5229440749935508, 0.20823683097126466, 0.20662256553563885, 0.5074938390170112, 0.42454232478816134, 0.6414756102443635, 0.21115281594065816, 0.18364978477304572, 0.22343397474935933, 0.20424905620130962, 0.18667535976081218, 0.17313308212161738, 0.17876578271123778, 0.20322426781470992, 0.18207116590107408, 0.1906216357526569, 0.10466068892358382, 0.10263698556146106, 0.08903221787639082, 0.08805766101372736, 0.09579612228309542, 0.10976065218193798, 0.08139410728307228, 0.10663064647246068, 0.08796920729440805]}, "mutation_prompt": null}
{"id": "af85a5fa-877b-4f92-bdc1-16d5afcb936b", "solution": "import numpy as np\n\nclass AdvancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x * 0.9 + 0.4, 1.0)  # Adjusted chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.95  # Slightly increased diversity control\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 30.0)  # Adjusted dynamic tuning\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 30.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "AdvancedHybridDEPSO", "description": "An advanced hybrid optimizer leveraging adaptive chaotic maps and dynamic parameter tuning to enhance exploration and convergence in DEPSO with improved diversity control.", "configspace": "", "generation": 23, "fitness": 0.32941180236677825, "feedback": "The algorithm AdvancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.28.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.9157214719311197, 0.8867659147080851, 0.8850732873081417, 0.8952125026313759, 0.8992684588963562, 0.9143316136197817, 0.8805380543013007, 0.9002427402015353, 0.8970081117861527, 0.7723647915557748, 0.8003172597817375, 0.8095714214740385, 0.7682601618141757, 0.0482645684951265, 0.7664290887348253, 0.7835908748754158, 0.7808870103645582, 0.78447890081215, 0.18359695502791207, 0.1624892764141994, 0.09729262324127397, 0.09565900374556968, 0.14172360359058023, 0.1595362002516444, 0.08664315325568428, 0.09476003671812472, 0.18594967508611193, 0.12098964601005113, 0.06253849891008156, 0.10131252888180664, 0.14310689588727432, 0.11654429698167712, 0.08316479447930647, 0.11182156367206275, 0.15748789346303038, 0.09777347848849716, 0.9766367864937254, 0.9628208736207959, 0.9670049970457367, 0.9592096189740107, 0.9641182547429406, 0.963849461552977, 0.9674521284556636, 0.9533727089112652, 0.9607064507429663, 0.7868166932253484, 0.7577854483450405, 0.774058581753827, 0.7982958502581263, 0.7786841935482824, 0.7709435417777589, 0.7678610134676325, 0.08826265601722205, 0.7632420981734703, 0.17168058406404763, 0.38560240563685266, 0.1396052583066476, 0.3938837699373424, 0.21455397228094442, 0.3417454701079722, 0.2376367159080892, 0.15319161135598058, 0.23901059036157923, 0.1308823011904202, 0.2945363991094234, 0.3080049461471833, 0.274591574653965, 0.30522560224526984, 0.315895153626485, 0.31592206497434594, 0.2789152914016635, 0.36774801989179473, 0.27630535394880695, 0.27253350209571425, 0.28789178561142126, 0.3084758564078163, 0.3752305850875115, 0.31817728635462705, 0.13692583003367886, 0.31442517383782587, 0.3094964802702572, 0.05210495003870108, 0.0001484492597144671, 0.010958379332865809, 9.999999999998899e-05, 0.11323208738130575, 9.999999999998899e-05, 0.009714932918046704, 9.999999999998899e-05, 0.00010452213291123336, 0.1866767902425881, 0.05069988964926908, 0.08725362613260246, 0.1444904746080109, 0.025523705325387502, 0.030346512712190687, 0.20025002101965494, 0.11037664152981252, 0.08591296636056722, 0.22636744320058078, 0.18219007751514504, 0.1812262226882223, 0.09816016380983206, 0.08030941390264301, 0.16354801361089244, 0.09911125141885646, 0.10280479551973964, 0.07530048741569739, 0.3414334627860066, 0.19672252492939124, 0.1439057050983078, 0.08449751515619286, 0.12386652563268596, 0.006834584310465686, 0.19457071187215402, 0.049968047448112896, 0.08408584090194093, 0.5568881990550922, 0.5379067966683706, 0.5697820952353371, 0.5744765798593314, 0.5781764165487947, 0.582491426180086, 0.5766083084376821, 0.6352586406881222, 0.5867684842316481, 0.0645029241755668, 0.06749991590524829, 0.09207021456142506, 0.1354118776818738, 0.13872565536248427, 0.06674695472250602, 0.08035398961259599, 0.14322835804028278, 0.08275084084725381, 0.47468305529758836, 0.1661079336088953, 0.33439954222568236, 0.4293256482059604, 0.7436493908334225, 0.21225455071478205, 0.1923395777560264, 0.5888971688905063, 0.22303532270841064, 0.24074445774016018, 0.3492407114495991, 0.27140335390500314, 0.27635113121969523, 0.24141393747722306, 0.3665500954769634, 0.4034740102809592, 0.38752000771535144, 0.22148414493995916, 0.3256437581067544, 0.2977015468844315, 0.22497244397203298, 0.2424142075587704, 0.2832920870849053, 0.30651884756563685, 0.20575578037868358, 0.1949218548153543, 0.34844934390660864, 0.242783319201628, 0.3056353549112487, 0.2950978686617738, 0.23104748995040325, 0.2181768374287808, 0.2208640633308746, 0.2617960311597708, 0.2203255634534511, 0.20939986449611347, 0.20680626690445458, 0.21191195409717278, 0.17870165567755325, 0.18258632827583765, 0.1926661953200295, 0.21141064135316012, 0.2031490169670659, 0.2134638280344957, 0.19826340052391, 0.15899756207638205, 0.17898147892301908, 0.1536604914603129, 0.17223072876380974, 0.20202781924883462, 0.20065571483558042, 0.12274973381567522, 0.9564576813523212, 0.1687069027035656, 0.7686296610915043, 0.8168666076130471, 0.8705096076720564, 0.8458653967108483, 0.1695715375143918, 0.21246346432947572, 0.10422748810041305, 0.1684259492771587, 0.7998764485241902, 0.19609262724377363, 0.19830608054147214, 0.2377185069881682, 0.20791417407414592, 0.2289788039945576, 0.2702075570566198, 0.23625909996704964, 0.2129215280764224, 0.19865214180743485, 0.10236068626551187, 0.07436054171836382, 0.09823784108540023, 0.09762984740410519, 0.10503121751076305, 0.12718083477770892, 0.09054372318199055, 0.11417391139707544, 0.09627061062867492]}, "mutation_prompt": null}
{"id": "9565066f-72ad-40a9-9ca9-2a1714b148b6", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.8, 1.0)  # Adjusted chaotic map for enhanced diversity\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 80.0)  # Different iteration scaling\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.95  # Slightly less aggressive inertia weight reduction\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.6 + 0.4 * np.cos(self.iteration / 30.0)  # Modified parameter dynamics\n            self.c2 = 1.4 + 0.6 * np.sin(self.iteration / 30.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedAdaptiveDEPSO", "description": "A hybrid optimizer employing adaptive chaotic DE and PSO with dynamic velocity controls for balanced exploration and exploitation.", "configspace": "", "generation": 24, "fitness": 0.3464880722506515, "feedback": "The algorithm EnhancedAdaptiveDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.30.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.9073925298714176, 0.9045838769392612, 0.9067679777244497, 0.8796975004537946, 0.9048803365029539, 0.9151881918144504, 0.8921809306640662, 0.8980804206861029, 0.8966884191203188, 0.7931828986583779, 0.8119806953557467, 0.7934125031854599, 0.8073742042493741, 0.7966718489269837, 0.7877905473366793, 0.7933203274778097, 0.764321659480129, 0.8053160779724671, 0.08830434969965795, 0.667082643266312, 0.09635264399063037, 0.1621822172794749, 0.15955570391489549, 0.10701365943057206, 0.14751841975860058, 0.1169062166355701, 0.18453955573726044, 0.07490318976685995, 0.09633635677539132, 0.09261753758071822, 0.11600638603842617, 0.09643120015038298, 0.11518832554428404, 0.1349468440727244, 0.1257110952866316, 0.12247917910547057, 0.9741361285186537, 0.9688859350547179, 0.9521061140903122, 0.9874657903056875, 0.9807350662975841, 0.9767961861838497, 0.9810275643901716, 0.9753007324378126, 0.9830881670335981, 0.7960888736048397, 0.7609423440584268, 0.7924283434383059, 0.783456294890883, 0.7878689206945851, 0.737288748443591, 0.7775565998150102, 0.7509150420379367, 0.7747830420883571, 0.23047244953148738, 0.17210779772850238, 0.22587627607687677, 0.2222978545591695, 0.38014724947114464, 0.8857960751432306, 0.3635502397158885, 0.23603121334920074, 0.24923755109696444, 0.28650470101583025, 0.30007267813184724, 0.13460899087374, 0.31162620054627266, 0.2920063406537029, 0.3621688549422213, 0.2664188105019635, 0.26498067657341273, 0.36868932463213755, 0.1351462171843303, 0.2566385922672304, 0.23082733598782856, 0.27740311203205836, 0.29097352677043287, 0.2584695023724801, 0.2837474625055446, 0.28272604011854896, 0.2829842626832588, 0.0681098817314938, 0.0014440932131452033, 0.12957370341037022, 0.012417287364771212, 9.999999999998899e-05, 9.999999999998899e-05, 0.04769464063276463, 9.999999999998899e-05, 0.0605077335712354, 0.08856827569861159, 0.07200678909902347, 0.07264885045342473, 0.019897101837345277, 0.06751224626896513, 0.027154699286419448, 0.10115002597732636, 0.10556561312624313, 0.13625294249573094, 0.06843427748735287, 0.2692473378526685, 0.05473267718707264, 0.07771504996655587, 0.08105428208913257, 0.13786765913867183, 0.3867829213802124, 0.10216601940188375, 0.07441176887430323, 0.24599238118530264, 0.17168638608587894, 0.05884662877009028, 0.10653157241705324, 0.1708584138059943, 0.04472458751348407, 0.14646803469496628, 0.094731487301287, 0.14914810322012273, 0.6106132489830158, 0.5626881720315335, 0.5336003928044728, 0.5568399401815003, 0.5535555512046949, 0.5289225354127617, 0.5959559020191447, 0.5968493171574298, 0.6311433640385096, 0.10840158312700932, 0.12493125951711515, 0.11182963234597265, 0.10099113389116265, 0.08425059331688844, 0.1189387108344836, 0.08735902813631768, 0.14186618617412328, 0.14007829105372493, 0.5251119701230395, 0.24863506625314302, 0.7631825590890454, 0.7455501848646251, 0.2703263285277122, 0.20499289782361552, 0.1878452187504811, 0.26014990862597454, 0.19862721478655587, 0.31700735679265657, 0.25223217645034024, 0.47452215303769485, 0.41368868743094334, 0.48132872241025004, 0.34388761889069186, 0.2664568861778328, 0.5045408691322149, 0.4618601522581336, 0.2982135840503817, 0.2437957106852603, 0.2492245566998571, 0.2709467324494498, 0.21743896192456025, 0.204653510285553, 0.2280049487788186, 0.32078270625467775, 0.13802855940791436, 0.2219353007058632, 0.29935102895737387, 0.23706764425292992, 0.24994796329772073, 0.23354989273069682, 0.21372380298100957, 0.25118292934968744, 0.23564151811219713, 0.2593452599510985, 0.22937020247712725, 0.20225276226371414, 0.22606186642217707, 0.20069617297825693, 0.18056687040506536, 0.20466028643191714, 0.203385571788952, 0.17568773890391454, 0.18562242062339984, 0.16539878141503617, 0.12701069771800777, 0.15381996289747057, 0.9302898739612809, 0.9365217116306942, 0.9310955962715628, 0.1000276518534059, 0.1696049767799621, 0.15912370264733167, 0.8331996880749658, 0.21322906266037522, 0.11278637104152545, 0.772413711557628, 0.8721511104299128, 0.8621381535810314, 0.10514144913690748, 0.15712225136763502, 0.2091480187302368, 0.20661953121054877, 0.21847401328386484, 0.1854172646972233, 0.18960154762727277, 0.20718571728059587, 0.22278415704495214, 0.2023520280630987, 0.2047683416080427, 0.20847010235819163, 0.10087285661145251, 0.08907651124080751, 0.09325895155556863, 0.08234823587267326, 0.10779862382014127, 0.13132360868424187, 0.07846549239782652, 0.10836796654044378, 0.09662739482218963]}, "mutation_prompt": null}
{"id": "19fdcc7c-2df8-46de-819a-7bf8e9f12c3b", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A refined hybrid optimizer incorporating adaptive chaotic maps in DEPSO for enhanced exploration and convergence.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.8865276906432433, 0.9020532548803202, 0.8929687050976703, 0.9069966467491789, 0.8983603223003787, 0.9022140074472543, 0.8838639783889877, 0.8886653828703049, 0.889752534826144, 0.7567698703303883, 0.784578368098034, 0.8076249809202548, 0.7611720006041811, 0.7986347352301275, 0.8050952302753023, 0.7936777043904858, 0.8107862909162267, 0.7638655686477411, 0.14306028296887274, 0.18771148863225673, 0.09076269380504487, 0.14472904467535863, 0.18827718037504793, 0.14600008067707715, 0.18654152199131935, 0.11161280818292418, 0.11200366762783509, 0.13393502172957683, 0.14641399913557107, 0.1432167792015192, 0.11181421186718143, 0.09209417505561412, 0.11938418806199658, 0.11206983601831055, 0.11095636186680169, 0.10912525701701048, 0.9717271359469163, 0.9628507846149675, 0.9377341630520235, 0.9810288407887259, 0.9785915503130439, 0.9770423747813494, 0.9783473338829307, 0.9712621930647505, 0.9787075504592555, 0.7607315187580301, 0.7749069267760285, 0.7630288578874603, 0.7507532481153396, 0.6554370351125884, 0.7762723104136083, 0.7499504173558014, 0.6968283959747328, 0.7389586451693928, 0.1721225825938858, 0.22891630584450517, 0.11324758049764427, 0.3549737812815622, 0.2807957237653095, 0.28145549322917607, 0.18018767969655092, 0.2386988483653335, 0.9395469978455472, 0.2720537562684263, 0.1357109215500677, 0.288515417628357, 0.27358595508171457, 0.28033933355072405, 0.3483295090039492, 0.29980271067857245, 0.13457278726329025, 0.31624018099324525, 0.28347106445129555, 0.27653913969396915, 0.2892909131254505, 0.32904479577095047, 0.30792895015902, 0.3267380918354402, 0.3033156492629593, 0.2088685743639237, 0.2906120113344278, 0.004881953303818798, 0.08432094844164972, 0.01040324864575648, 0.08307057080589308, 0.0631748299553836, 0.031141171943307566, 0.038932547461408507, 0.021942713170019723, 0.09321589178997347, 0.14820762824482314, 0.14111157929981544, 0.09939347465031478, 0.07351212675576657, 0.14911297504852605, 0.02739581001833591, 0.11477783328277313, 0.09375370099990121, 0.12437319484907039, 0.07875046545806708, 0.12463510807347011, 0.14210128121458188, 0.07919284437097684, 0.0801485337679555, 0.13337703281066082, 0.19524821804991244, 0.10442299933492127, 0.07342327849013242, 0.16578167026123625, 0.1853016315404299, 0.1189542819871422, 0.1574945670012905, 0.18360986723287642, 0.2558817728796652, 0.12448657793629136, 0.25405459307747846, 0.1254414517844874, 0.5407077538029146, 0.6006067397749144, 0.5396897498932287, 0.5489927270360135, 0.5891834596503931, 0.5459801886932765, 0.5877025571595188, 0.58912009886935, 0.5796039758319813, 0.07975439706166598, 0.10110173168052605, 0.0755122787624074, 0.16076138881367696, 0.10587421420661025, 0.09908423757627094, 0.11384860622149795, 0.14412899438570692, 0.10610491466439798, 0.22279569248288034, 0.6592237296261918, 0.22467227789135458, 0.27264975790467794, 0.42228702264236595, 0.4427009503531557, 0.5283272114477804, 0.21131508909474783, 0.3463028054853772, 0.5602848907432856, 0.5870043317671049, 0.24980633166770938, 0.37827330003298987, 0.3159543684158136, 0.3948951692827499, 0.5338080159903202, 0.6386237352364159, 0.19094651398173923, 0.2682466646833648, 0.24944249579405708, 0.20048413900667417, 0.3126123000671225, 0.19508244130654495, 0.2440464616149688, 0.2746657038803456, 0.2758095868983087, 0.1718425074209099, 0.24221577925087046, 0.24277264917923613, 0.22753707311652804, 0.21621523555871425, 0.23220195984323055, 0.2121859746984508, 0.22233176434332813, 0.19428032015735874, 0.2940143940691601, 0.18346601962379372, 0.2507595245585167, 0.2074744620231186, 0.2296346173180046, 0.7839070787440949, 0.18887893138201983, 0.19948332275076253, 0.2261375176508097, 0.19661374747919813, 0.9185297033957897, 0.17730516387770456, 0.11326657578340704, 0.17278331750195008, 0.9190619999789291, 0.2007124882642538, 0.0996663158636657, 0.16991723780351253, 0.16271709766976927, 0.8243727383661772, 0.8166819556788825, 0.7311027166633209, 0.9133133255502286, 0.8484364245717022, 0.7770450456081295, 0.10514634504197418, 0.1699183301713061, 0.16636178423956227, 0.19554443874623362, 0.24430239869142467, 0.21100720171394982, 0.1973610633324807, 0.25121027229113, 0.19102423719310313, 0.2563067934359131, 0.23300659057012685, 0.22269509176237645, 0.08892873400730372, 0.07113752042749677, 0.11154483811644855, 0.0966630146129761, 0.0829219834948779, 0.14774202050214513, 0.10337404775080683, 0.10543583486427055, 0.09783716494350791]}, "mutation_prompt": null}
{"id": "c986d184-38d9-41f0-98bc-5d6cb98e7ffd", "solution": "import numpy as np\n\nclass SelfAdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.vel_max = 1.0\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x * (1 - x) * 3.8, 1.0)\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "SelfAdaptiveHybridDEPSO", "description": "A self-adaptive hybrid optimizer blending DE and PSO with dynamic chaotic maps for robust black-box optimization.", "configspace": "", "generation": 26, "fitness": 0.3230663555383589, "feedback": "The algorithm SelfAdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.28.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.9057901665769789, 0.8992788856844421, 0.8740932234937548, 0.8728514995710013, 0.8964254237431771, 0.902631588632548, 0.8827497113832007, 0.1830231473632682, 0.8886922947994991, 0.75759989541351, 0.7923206485172751, 0.7673784872065663, 0.765510406658722, 0.7247116886282793, 0.7873555263672408, 0.7320025437245533, 0.7955429669140175, 0.7678522654142155, 0.11230360524043403, 0.13428741395566646, 0.11026010363626026, 0.18221408257726046, 0.13325602485036891, 0.12256392048308262, 0.1467319481072653, 0.18158456426400993, 0.15844864053667007, 0.11274110285277217, 0.056589383515115665, 0.08934803987645579, 0.11511048644457056, 0.1037225562767784, 0.05043805712010885, 0.10157227157485982, 0.08950931755439673, 0.12454496485855848, 0.9715383770356018, 0.9556382975911354, 0.9706353399289371, 0.9637339283175664, 0.9638881169245299, 0.9709290875204177, 0.9709535528808341, 0.9608205549271699, 0.9643535820147853, 0.7650102879841673, 0.05974354915134794, 0.7474072751346772, 0.7476798714606725, 0.7156289952962396, 0.75134350397915, 0.12857874007974168, 0.7094108180571903, 0.7228999383359478, 0.2133018752756629, 0.17132600017445254, 0.08500633222891141, 0.19474714167299167, 0.3778593907044113, 0.8704848593328156, 0.1779957525515803, 0.1793434368978749, 0.9374909609729659, 0.3011750315690358, 0.13469780800060382, 0.277636515544999, 0.2768876680680814, 0.27093150558166856, 0.27963546059444666, 0.334745993131915, 0.28343199842855116, 0.2888454140849679, 0.2631772724594347, 0.2784902666201625, 0.28674842935341927, 0.26961893107124046, 0.31097842456323166, 0.3190676040835624, 0.3103563662825295, 0.2535698557179402, 0.13406807561232925, 0.005162999702923332, 0.05980826988584376, 0.008724585950796948, 0.12336123842595903, 0.011190384538314668, 0.1065271167172206, 0.015783467177406085, 0.038169277725136785, 0.006941419601310006, 0.10561490540888407, 0.049958833221695365, 0.13773524415390948, 0.07178792005125012, 0.01506662051046348, 0.04731990438454481, 0.177640402976043, 0.1524231956983183, 0.06352691950134137, 0.07483705128966667, 0.3789341487941753, 0.14896089251953548, 0.08214306655093206, 0.08254856472050232, 0.10155879361706444, 0.17776760301723715, 0.15504564250832686, 0.07236700299631682, 0.11635628536377773, 0.11609881266460376, 0.25031248560928876, 0.14354824818436884, 0.11222042346959338, 0.1821030392762416, 0.08464789913809345, 0.047666580953550364, 0.08523029581462671, 0.5458930240471587, 0.6205074903481989, 0.6147961737343823, 0.6549084724440509, 0.5701023428697747, 0.5871943376527097, 0.6075230594669241, 0.6256119279954159, 0.6510550043699804, 0.11535029265342256, 0.060828787749333646, 0.14806298929665918, 0.09001683736132904, 0.08514795291472488, 0.07390280842861086, 0.1065835392036677, 0.09591939281178308, 0.08116063194260636, 0.17871751888599807, 0.27655411075714453, 0.34901106163921747, 0.4807657351348228, 0.29973165535493274, 0.21858137736853567, 0.42522774949605213, 0.5664787200504617, 0.35293963985795074, 0.47590870839952715, 0.4428413107785323, 0.2509864540764477, 0.25763253448512147, 0.23255061603163496, 0.41821517443704004, 0.1764888621289441, 0.5570868962547404, 0.16355671938425675, 0.25763077189839756, 0.21871838444197533, 0.23384613780482766, 0.1763942052331109, 0.22815256048978116, 0.2552280745129748, 0.2654182689532836, 0.3976072869837042, 0.1173588446610131, 0.23645755750210873, 0.25621213416054867, 0.2306489065765137, 0.2299043573888827, 0.21916416063370603, 0.21243230098354626, 0.23129540162154683, 0.24433533500151983, 0.22734900003414482, 0.2005645457101125, 0.19284384655582454, 0.21381875324659294, 0.18885911603862937, 0.19001369669459678, 0.18885286654186062, 0.222601018887835, 0.22662212708250018, 0.18403031526407887, 0.18838601855982517, 0.12741191185908773, 0.15448046723986042, 0.17356353439094796, 0.20193162325293557, 0.9357436637820645, 0.1315441516173107, 0.17033487633764688, 0.15409239058394086, 0.8599582933965046, 0.8235886551158635, 0.7896674772447494, 0.21148664500161973, 0.15607749286534034, 0.2123762540948263, 0.10526044837966675, 0.10483705285993095, 0.8404179449004139, 0.19905503491870402, 0.21409492503359218, 0.22902742546556043, 0.20490757248014035, 0.20301584684457608, 0.23820896309541018, 0.21507144131479727, 0.21294843064001867, 0.22281369050577882, 0.12011384764331179, 0.12745252833018295, 0.07885880458423633, 0.09525285569736641, 0.10680651112239414, 0.15437554476269377, 0.0757519594324062, 0.09965661796945191, 0.08762342711060733]}, "mutation_prompt": null}
{"id": "6bd3455c-fd8a-4b21-b188-a8ba89f57f52", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.vel_max = 1.0\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A refined optimizer combining differential evolution and particle swarm with chaotic mutation and dynamic inertia for improved convergence.", "configspace": "", "generation": 27, "fitness": 0.3513507498892743, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.29.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.8865276906432433, 0.9020532548803202, 0.8929687050976703, 0.9069966467491789, 0.8983603223003787, 0.9022140074472543, 0.8838639783889877, 0.8886653828703049, 0.889752534826144, 0.7567698703303883, 0.784578368098034, 0.8076249809202548, 0.7611720006041811, 0.7986347352301275, 0.8050952302753023, 0.7936777043904858, 0.8107862909162267, 0.7638655686477411, 0.14306028296887274, 0.18771148863225673, 0.09076269380504487, 0.14472904467535863, 0.18827718037504793, 0.14600008067707715, 0.18654152199131935, 0.11161280818292418, 0.11200366762783509, 0.13393502172957683, 0.14641399913557107, 0.1432167792015192, 0.11181421186718143, 0.09209417505561412, 0.11938418806199658, 0.11206983601831055, 0.11095636186680169, 0.10912525701701048, 0.9717271359469163, 0.9628507846149675, 0.9377341630520235, 0.9810288407887259, 0.9785915503130439, 0.9770423747813494, 0.9783473338829307, 0.9712621930647505, 0.9787075504592555, 0.7607315187580301, 0.7749069267760285, 0.7630288578874603, 0.7507532481153396, 0.6554370351125884, 0.7762723104136083, 0.7499504173558014, 0.6968283959747328, 0.7389586451693928, 0.1721225825938858, 0.22891630584450517, 0.11324758049764427, 0.3549737812815622, 0.2807957237653095, 0.28145549322917607, 0.18018767969655092, 0.2386988483653335, 0.9395469978455472, 0.2720537562684263, 0.1357109215500677, 0.288515417628357, 0.27358595508171457, 0.28033933355072405, 0.3483295090039492, 0.29980271067857245, 0.13457278726329025, 0.31624018099324525, 0.28347106445129555, 0.27653913969396915, 0.2892909131254505, 0.32904479577095047, 0.30792895015902, 0.3267380918354402, 0.3033156492629593, 0.2088685743639237, 0.2906120113344278, 0.004881953303818798, 0.08432094844164972, 0.01040324864575648, 0.08307057080589308, 0.0631748299553836, 0.031141171943307566, 0.038932547461408507, 0.021942713170019723, 0.09321589178997347, 0.14820762824482314, 0.14111157929981544, 0.09939347465031478, 0.07351212675576657, 0.14911297504852605, 0.02739581001833591, 0.11477783328277313, 0.09375370099990121, 0.12437319484907039, 0.07875046545806708, 0.12463510807347011, 0.14210128121458188, 0.07919284437097684, 0.0801485337679555, 0.13337703281066082, 0.19524821804991244, 0.10442299933492127, 0.07342327849013242, 0.16578167026123625, 0.1853016315404299, 0.1189542819871422, 0.1574945670012905, 0.18360986723287642, 0.2558817728796652, 0.12448657793629136, 0.25405459307747846, 0.1254414517844874, 0.5407077538029146, 0.6006067397749144, 0.5396897498932287, 0.5489927270360135, 0.5891834596503931, 0.5459801886932765, 0.5877025571595188, 0.58912009886935, 0.5796039758319813, 0.07975439706166598, 0.10110173168052605, 0.0755122787624074, 0.16076138881367696, 0.10587421420661025, 0.09908423757627094, 0.11384860622149795, 0.14412899438570692, 0.10610491466439798, 0.22279569248288034, 0.6592237296261918, 0.22467227789135458, 0.27264975790467794, 0.42228702264236595, 0.4427009503531557, 0.5283272114477804, 0.21131508909474783, 0.3463028054853772, 0.5602848907432856, 0.5870043317671049, 0.24980633166770938, 0.37827330003298987, 0.3159543684158136, 0.3948951692827499, 0.5338080159903202, 0.6386237352364159, 0.19094651398173923, 0.2682466646833648, 0.24944249579405708, 0.20048413900667417, 0.3126123000671225, 0.19508244130654495, 0.2440464616149688, 0.2746657038803456, 0.2758095868983087, 0.1718425074209099, 0.24221577925087046, 0.24277264917923613, 0.22753707311652804, 0.21621523555871425, 0.23220195984323055, 0.2121859746984508, 0.22233176434332813, 0.19428032015735874, 0.2940143940691601, 0.18346601962379372, 0.2507595245585167, 0.2074744620231186, 0.2296346173180046, 0.7839070787440949, 0.18887893138201983, 0.19948332275076253, 0.2261375176508097, 0.19661374747919813, 0.9185297033957897, 0.17730516387770456, 0.11326657578340704, 0.17278331750195008, 0.9190619999789291, 0.2007124882642538, 0.0996663158636657, 0.16991723780351253, 0.16271709766976927, 0.8243727383661772, 0.8166819556788825, 0.7311027166633209, 0.9133133255502286, 0.8484364245717022, 0.7770450456081295, 0.10514634504197418, 0.1699183301713061, 0.16636178423956227, 0.19554443874623362, 0.24430239869142467, 0.21100720171394982, 0.1973610633324807, 0.25121027229113, 0.19102423719310313, 0.2563067934359131, 0.23300659057012685, 0.22269509176237645, 0.08892873400730372, 0.07113752042749677, 0.11154483811644855, 0.0966630146129761, 0.0829219834948779, 0.14774202050214513, 0.10337404775080683, 0.10543583486427055, 0.09783716494350791]}, "mutation_prompt": null}
{"id": "4d5862cc-1421-4909-b6b4-41f8e69f4b6d", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.7  # DE scaling factor\n        self.cr = 0.85  # DE crossover probability\n        self.w = 0.6  # inertia weight for PSO\n        self.c1 = 1.4  # cognitive coefficient for PSO\n        self.c2 = 1.7  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-6\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.618, 1.0)  # Modified chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.95\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.4 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.4 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A modified hybrid optimizer using chaotic maps in DEPSO with adaptive parameters for better convergence.", "configspace": "", "generation": 28, "fitness": 0.32322762203110805, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.28.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.8617120908784437, 0.8089064812013953, 0.8672384173743652, 0.8814691557653286, 0.866155997878038, 0.8825273707303296, 0.8856573109871113, 0.8697524881475487, 0.8599951661788561, 0.6725124138582222, 0.7221548887649172, 0.7193075613579873, 0.634487254834005, 0.6417865490087482, 0.7319910530208906, 0.7286801233632921, 0.7291793161281674, 0.7087459902217285, 0.15604702872677334, 0.13387276802950487, 0.11403446390820626, 0.15808754360145538, 0.15770209301982652, 0.12116020429222352, 0.15033336143055043, 0.15952312617562803, 0.17546575294736466, 0.11018039176634287, 0.05524712417322175, 0.12065023763249305, 0.11373650608185404, 0.111208671249872, 0.14417032276090447, 0.08148068946469689, 0.11331250561870276, 0.08973143173274711, 0.9756433220307907, 0.9559515281527026, 0.9554905851036016, 0.9641284105011746, 0.9677220829006079, 0.973409051558528, 0.9589595956587366, 0.9699915105314317, 0.9744685254017678, 0.6776698997845534, 0.0601435695927377, 0.7369014038578152, 0.6841104139933327, 0.6673590528496149, 0.6971196192849934, 0.7108098216999224, 0.08877557071129072, 0.7416854270030566, 0.23007677925410186, 0.38188615541386084, 0.22610507349389752, 0.21518213473068348, 0.2147160053245578, 0.2794661296652231, 0.23261892457827782, 0.2223930268655775, 0.8350130390072, 0.2514683511692315, 0.13202719034328148, 0.24588414546776372, 0.26105722332800674, 0.2565358261585663, 0.20399485425967612, 0.27977126763966564, 0.25325333661542626, 0.32049054490453177, 0.2202388461627589, 0.13427052952929897, 0.26124481475288863, 0.26057348444488604, 0.2904042454179918, 0.2757602607145644, 0.2594740205929631, 0.28098135101933597, 0.29969388658539997, 0.12460498468097081, 9.999999999998899e-05, 0.04470556526580205, 0.04789458632501031, 0.14427022451760674, 0.021599969948655984, 0.01394733503700385, 0.007805806807814952, 0.017765048321682353, 0.1798942184167106, 0.0931980033092128, 0.03920442283094783, 0.06005141178170725, 0.02623398406342292, 0.06921000576496827, 0.1250848258511369, 0.07882082619840913, 0.0831513047275948, 0.04705223020680238, 0.10570187962172073, 0.1067736877461688, 0.07470422751494021, 0.1092452587118461, 0.1596830328196447, 0.10085012470664312, 0.09450181707773286, 0.06461729499094815, 0.10437991546474246, 0.1477463805035215, 0.1486117609112334, 0.0869779024073225, 0.27521085239869825, 0.12545337234595821, 0.23889206696173038, 0.26978983195495765, 0.08221380288111269, 0.5317123891746718, 0.5189663704564671, 0.5594187951885212, 0.6275341399977267, 0.5688707311549672, 0.6398700431832451, 0.5878843612911389, 0.6016486445212612, 0.5808760119420567, 0.1404574905276209, 0.10264274379040694, 0.1290694183922373, 0.1605018618617936, 0.06574687352632214, 0.13397546441850394, 0.11687371181021067, 0.0999884071515389, 0.1070102687548331, 0.22510989301412354, 0.17684385302671324, 0.13088660051922796, 0.20265492314585498, 0.22297963325953218, 0.33754119718309317, 0.2703402365118416, 0.31649668370288764, 0.31984650736342357, 0.609309564596709, 0.4892770577414116, 0.2776269302147861, 0.3684233592828904, 0.3942158560022825, 0.4691331310130158, 0.2747241006864528, 0.3607177256783203, 0.49641760605069096, 0.30036596583809705, 0.286622710586769, 0.2576338144491128, 0.18236132774725633, 0.1795369466871629, 0.12888520324528074, 0.3921821680851938, 0.26250054809188283, 0.10740058821913101, 0.21478418216041406, 0.2719617994300253, 0.23837543376864, 0.23250280478601393, 0.23150558567258472, 0.2539371982276174, 0.2615670887516356, 0.24581093090745687, 0.21526120274782734, 0.20143830849665378, 0.22662515549512974, 0.1873463752949024, 0.2524782941002147, 0.19074748152619758, 0.21144023409719204, 0.2477139773445346, 0.22946843771027803, 0.22137811539083319, 0.907108826164019, 0.17800704098022324, 0.14832499733000326, 0.1894745702641757, 0.20162343804756033, 0.9349604770888756, 0.1423548537613668, 0.17050101927700856, 0.15367212310305278, 0.8262208860813922, 0.11301439953074022, 0.7643241829333363, 0.8880014404016983, 0.9072853205971767, 0.052112002409503866, 0.1053362204555981, 0.16851639047728095, 0.7899620580783189, 0.18890233826322678, 0.20209932414569143, 0.20457874953126542, 0.21112354503873287, 0.23092055387279609, 0.18788842561752095, 0.21079282581504633, 0.24580829654799918, 0.20771222037730275, 0.09490958384576986, 0.08487643454371041, 0.10751272086845798, 0.09787084274483915, 0.09219347910594666, 0.14668336942414062, 0.0941199292797219, 0.0834781964458694, 0.09439815783274297]}, "mutation_prompt": null}
{"id": "724de515-988b-47c7-a0e8-5e34c9ae20fb", "solution": "import numpy as np\n\nclass ImprovedAdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n        self.perturbation_frequency = 100  # Frequency of random perturbations\n\n    def chaotic_map(self, x):\n        return np.mod(x * 4.0 * (1 - x), 1.0)  # Logistic map for more chaos\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Periodic random perturbations to escape local minima\n            if self.iteration % self.perturbation_frequency == 0:\n                perturbation = np.random.uniform(-0.1, 0.1, self.particles.shape)\n                self.particles = np.clip(self.particles + perturbation, self.lb, self.ub)\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 2.0 - 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "ImprovedAdaptiveHybridDEPSO", "description": "A novel hybrid optimizer that combines adaptive chaotic maps with DEPSO, incorporating periodic perturbations and improved diversity management for robust convergence.", "configspace": "", "generation": 29, "fitness": 0.30573646454410897, "feedback": "The algorithm ImprovedAdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.27.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.9114747713581064, 0.9063927843405581, 0.9046770698359584, 0.8850160216590601, 0.8864692301537294, 0.90266649909044, 0.9157001540112539, 0.2902396970520962, 0.9193687679052476, 0.7412250235901071, 0.7850635801645149, 0.773827649299543, 0.6923247655462719, 0.7589772459520253, 0.7973982895603446, 0.6990106909193394, 0.6465863100507603, 0.7363971231908248, 0.0810687669478588, 0.11796638225780676, 0.11618829686147092, 0.12286632582977997, 0.19316838255668567, 0.11142249048804465, 0.11201711496097655, 0.11809141470941198, 0.14781873938514778, 0.11052969770159304, 0.09402975503395083, 0.0822308886856834, 0.11841765665978388, 0.0737112774360652, 0.044042443972695744, 0.11641914395085717, 0.07620597839473575, 0.05235552125767229, 0.9716952504668066, 0.9541097029193185, 0.9706328887113602, 0.9637338463537252, 0.9646768079994552, 0.9709114601933846, 0.9680506338445205, 0.9625528596459518, 0.9645234714355194, 0.7487494186353958, 0.5994642578233922, 0.6037843979777998, 0.6577793520573795, 0.6756761434160913, 0.5289532367866964, 0.6177634146418264, 0.5664158590525612, 0.5826639317217464, 0.17209032071343044, 0.14120951795187497, 0.22550218042828807, 0.16250184527547695, 0.27573648516616034, 0.19646470994681653, 0.1789449862696425, 0.16425336016315084, 0.24956936257653284, 0.1988501595682316, 0.13553026308507232, 0.24945975330057457, 0.2258078172992346, 0.2338825477691242, 0.202689006801423, 0.29422209322697535, 0.23581589533486869, 0.21477739690565134, 0.23808906242248928, 0.23634194733483083, 0.24344935343516383, 0.2498440482274109, 0.1370095351457956, 0.26016811703727594, 0.2640481717199352, 0.1855900461812986, 0.27317302035530333, 9.999999999998899e-05, 0.002467975837545433, 9.999999999998899e-05, 9.999999999998899e-05, 0.10914690601323185, 0.13002763804719453, 0.00019939798094181782, 9.999999999998899e-05, 0.002229964635165338, 0.18142669554573987, 0.07683714194006608, 0.10527477584120082, 0.08921541462912064, 0.008290582640749888, 0.0413622688631049, 0.2238241204411222, 0.08900992917734385, 0.05710531302295008, 0.08715668536818844, 0.16734739757367734, 0.24444951323327002, 0.08098155402303164, 0.08238757705265343, 0.12432194014610343, 0.18149001002862342, 0.2798578164021588, 0.07624784036752152, 0.19875767234273267, 0.12254122920805044, 0.18903233157189214, 0.2563102271429537, 0.12218184532084309, 0.09328925364393759, 0.11020795369002734, 0.010268783418865723, 0.08592006611717329, 0.6442400317215771, 0.5543861560183934, 0.6258454289962052, 0.6358003610399403, 0.6166067538101339, 0.5795135638952057, 0.5732727800449893, 0.5995385795777038, 0.5689992338561192, 0.06172379880929857, 0.1012389331906487, 0.03898555231503831, 0.12578654568154857, 0.07076587935250189, 0.09690424281062537, 0.1479461556867978, 0.08344771164634546, 0.07117120644646024, 0.16969962499529834, 0.5400528861906775, 0.5271254951643458, 0.1816483490759223, 0.44147357108518026, 0.2111312549527714, 0.284306746807803, 0.2313900704905455, 0.3035278108314141, 0.23276084773922656, 0.2899961826516877, 0.27067182845928983, 0.267402614621726, 0.22472812154149302, 0.17538382004237396, 0.250825557729516, 0.5561766219297588, 0.45258825455983165, 0.22768590979121017, 0.28086433557358614, 0.22475463040954613, 0.17867184645993806, 0.20595939147650666, 0.1544503151399047, 0.10133283858533271, 0.15665526431090826, 0.111374925865248, 0.2228999566369949, 0.2530715454448127, 0.23345667083967048, 0.2506700767322372, 0.20160147929600458, 0.24647194121332472, 0.2092615642789033, 0.21079092962373902, 0.24273287705498736, 0.21107427055067796, 0.2202475539813462, 0.1856272854854656, 0.19161119597807397, 0.1994090622750745, 0.25464057149982144, 0.19067388920811557, 0.231224516299378, 0.19234414898905128, 0.18837198098566965, 0.12723807471667348, 0.15446851340841494, 0.17354526235589962, 0.20202861488445845, 0.9529531747738991, 0.13230992197514602, 0.170334914330733, 0.15433925736398302, 0.6450751051502025, 0.8726309455808661, 0.7576697981135729, 0.10483958212007238, 0.15627308939419216, 0.2127172131873678, 0.10518885437293835, 0.10481795483088263, 0.8098322268154621, 0.20969953233058047, 0.19450622693963282, 0.19255722588505397, 0.21671033270363227, 0.18343856593238017, 0.20448426268872055, 0.23391586173437817, 0.2729798371344664, 0.2521488219234165, 0.07451766894563994, 0.0855344654733532, 0.08256441983739038, 0.09489171134569241, 0.11707378216354314, 0.13553314517344328, 0.08207375328418332, 0.10878743437515481, 0.08831153316564466]}, "mutation_prompt": null}
{"id": "87136620-9670-49a7-8d25-9671e20e7a90", "solution": "import numpy as np\n\nclass PredatorPreyHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.iteration = 0\n        self.predator_factor = 0.3  # new parameter for predator-prey interaction\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Introduce predator-prey dynamics\n            if np.random.rand() < self.predator_factor:\n                prey_index = np.argmax(fitness)\n                predator_index = np.argmin(fitness)\n                self.particles[prey_index] = self.global_best  # move prey to predator's position\n                fitness[prey_index] = global_best_fitness\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "PredatorPreyHybridDEPSO", "description": "A refined hybrid optimizer utilizing the predator-prey model in DEPSO for improved adaptability and convergence.", "configspace": "", "generation": 30, "fitness": 0.33060939200823425, "feedback": "The algorithm PredatorPreyHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.28.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.9050322939802145, 0.8987729304294086, 0.888207427320858, 0.8763043418544411, 0.8981899050466108, 0.9105852684976066, 0.9014662849458184, 0.890411263117121, 0.8977007901735659, 0.795871421983995, 0.7578593034312482, 0.7719586001404557, 0.790799971841259, 0.789267176329726, 0.7701481162323647, 0.7578177117264617, 0.7837496901097446, 0.8037567504697775, 0.08911699650122173, 0.15458574396190783, 0.11333833231429324, 0.12439703987572615, 0.11271014471722063, 0.1452935569022069, 0.16364173304019292, 0.14359690228620803, 0.1259994062343036, 0.1088340765578889, 0.08811667083612751, 0.07999656881587902, 0.14284177849758506, 0.13927702037821132, 0.0842956876057186, 0.10500501607837998, 0.15833068985816645, 0.12406951178639414, 0.9762092151043688, 0.9667992053996018, 0.9631402430592755, 0.9776599267168168, 0.9681243552031235, 0.9584769027235112, 0.9788854615101951, 0.9675907524613913, 0.9781724172361594, 0.765320912448672, 0.7232514357435031, 0.06010704336800832, 0.7161779459750872, 0.7372722833389129, 0.7226804946733651, 0.6629906944712268, 0.7001137061672124, 0.7791165295838012, 0.3936138509735362, 0.39547788174712006, 0.17010523321418147, 0.28240818162421766, 0.8849695165886823, 0.3801964476048252, 0.23715176967242357, 0.22773727935717236, 0.24751797191207436, 0.2835654613380566, 0.2738731135795591, 0.24973603104241004, 0.2618344258060906, 0.27863569365728513, 0.27067773185628285, 0.27125256496696704, 0.1362431130143552, 0.24824395176672664, 0.27827778576107876, 0.2622868662449368, 0.1452640225078663, 0.258918634651359, 0.28150010158996264, 0.13538848675372772, 0.30597378077531423, 0.20704128379069742, 0.29117657495271454, 9.999999999998899e-05, 9.999999999998899e-05, 0.004887333426846663, 0.05781659548274165, 0.048406549337540294, 9.999999999998899e-05, 0.011967325650256488, 0.10000566832238655, 0.005994991487478396, 0.10772836209323355, 0.08081189432507363, 0.14809246583871827, 0.058848900262157056, 0.0854523296241505, 0.03696100571761618, 0.22136715158755849, 0.09236639873079111, 0.0698352381934686, 0.08837932277251948, 0.051553066259232394, 0.1762542457065852, 0.13284890842434527, 0.10949994529887297, 0.08090951457031337, 0.22465310304566732, 0.10376092422964789, 0.12022402340192007, 0.156223186827379, 0.011709919887339493, 0.15455314579261736, 0.07182353154759713, 0.10718989930672329, 0.08714669905423089, 0.15577177995012004, 0.13086653715541707, 0.0844961848821646, 0.5557139540156069, 0.5864716188063874, 0.5426274176604671, 0.6190467149241613, 0.5766709942443747, 0.574155417184774, 0.6147605970468613, 0.6021557032967155, 0.5890277715752088, 0.08288667288370088, 0.09939553561981607, 0.11243695407169019, 0.15651789959452722, 0.11455073086619505, 0.11192234609499085, 0.13197569177064705, 0.12380181062277684, 0.13193226994505858, 0.30204296494825467, 0.3166834661836663, 0.15843511310196012, 0.5271828688714677, 0.33982678221103024, 0.22010899542104545, 0.2767670487994428, 0.27471373597141435, 0.3742486729985586, 0.3474475340796558, 0.3835174495404742, 0.21850092746490313, 0.49729991267209384, 0.26932082858217843, 0.30756465102829056, 0.3876797080504649, 0.5244486862301887, 0.6541180520948994, 0.22641819963823573, 0.2903416120747424, 0.22389352380165306, 0.2713309340416208, 0.1902918342750971, 0.24367596831679683, 0.20576638243465417, 0.2619719158986923, 0.4072450781377328, 0.25506719328222716, 0.23866788345024448, 0.20047631806302246, 0.23035959983938392, 0.2647651137496013, 0.19972159615775142, 0.22331963086764028, 0.23312355496844228, 0.26205045880881106, 0.19034589390861822, 0.22261946935425136, 0.21066468416680206, 0.194790688043608, 0.19249043888664308, 0.2305723132440125, 0.18678667389569825, 0.18611061418732555, 0.19119260604867672, 0.12677613811159827, 0.17818474151176378, 0.18786673761007755, 0.20018686177221456, 0.20120316216884437, 0.9199858691564323, 0.8676215742669053, 0.17007303482330483, 0.15436755314764283, 0.16905185065007622, 0.21315158238252174, 0.8063860171804347, 0.7903879978768708, 0.15595303019215367, 0.7687826955205426, 0.1054094568199977, 0.8387906319089755, 0.1367373658310609, 0.20570250385630484, 0.20363629888950763, 0.19235332511025294, 0.19687551446776774, 0.1917071757958495, 0.2136813729553566, 0.2044220598184554, 0.19642839792315991, 0.2028796032892618, 0.09849335069382448, 0.08985902809886936, 0.11141982714501353, 0.08658103717065257, 0.10061826882556124, 0.13612685716267803, 0.09231456912418967, 0.12345111339342985, 0.10293483710623563]}, "mutation_prompt": null}
{"id": "d1eaab18-2a6d-4091-bf0c-db522eacb2df", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def proximity_selection(self, indices, n=3):\n        selected_indices = []\n        while len(selected_indices) < n:\n            idx = np.random.choice(indices)\n            if idx not in selected_indices:\n                selected_indices.append(idx)\n        return selected_indices\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = self.proximity_selection(candidates)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A refined hybrid optimizer using adaptive chaotic maps and proximity-based selection in DEPSO for improved robustness and convergence.", "configspace": "", "generation": 31, "fitness": 0.3316633096290061, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.29.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.8950864977198911, 0.8996877360402185, 0.8972822324322742, 0.8995341822407521, 0.8836470859233057, 0.8971882931768704, 0.9175005393563815, 0.8904740445088387, 0.8874895260884414, 0.7335661261120072, 0.8139656883589607, 0.7526209893570903, 0.7998262054417696, 0.8098836910377835, 0.8211728897561479, 0.7968731802557969, 0.7875211397349402, 0.7636429477426345, 0.10805125599790122, 0.14284265292888298, 0.10136093746093044, 0.14712289124764977, 0.11636507611502389, 0.14379917168291245, 0.13164546716803394, 0.18587090077728485, 0.13383851476890285, 0.134773669982576, 0.07115391326457299, 0.08253565588639244, 0.1316358132525398, 0.0919686716814263, 0.06771167318318838, 0.1050928718364228, 0.09302142844766625, 0.11501515209806623, 0.9769468891452487, 0.9703693823326021, 0.9707639840566399, 0.9680246545423521, 0.9851568748204339, 0.9635122835308606, 0.9762307167184776, 0.9707224976871325, 0.9543628885870419, 0.7346822583443163, 0.7177286971284695, 0.7595171058455765, 0.7418405688432903, 0.7477756018638471, 0.15263499145995196, 0.7868458086536472, 0.7040497228856355, 0.7619257477685056, 0.23089824426335492, 0.8891450882923861, 0.22980313578707723, 0.1938592280116863, 0.19282986078561903, 0.28243205759402346, 0.15197568684585783, 0.8814220089942462, 0.36349335125965276, 0.2789015022881226, 0.2695668648857056, 0.2694066354677883, 0.3735950428672724, 0.27563434799450237, 0.3817677658211647, 0.2865894088085199, 0.2779069709466335, 0.1352238001247026, 0.28048755962777583, 0.26955749767853465, 0.13592366730045014, 0.32653821521105164, 0.32059304448220427, 0.3422154089881112, 0.3107280773605181, 0.132124562291853, 0.2931480813471724, 0.004084322956736108, 0.012410685106144959, 0.0821203183957192, 0.003226403825049795, 9.999999999998899e-05, 0.04702633011443902, 0.017892948544167897, 0.007421546396096157, 9.999999999998899e-05, 0.14696649995580446, 0.08118072215819516, 0.13209559176248709, 0.13143455584035713, 0.03533601135131703, 0.033032008483398045, 0.07736379595593768, 0.10862327143541606, 0.05289873870572137, 0.23713126847257682, 0.09969982321866322, 0.13913289600144485, 0.08022794523259091, 0.10684089985186696, 0.18906610932487378, 0.17143155152523215, 0.10306954430916904, 0.07209279450777872, 0.09128622401689213, 0.17237998647070452, 0.240796901569729, 0.0066288348309957446, 0.18299848781047956, 0.24426930853647866, 0.09370473610536678, 0.09970446301871294, 0.08482487925509774, 0.5518396285638774, 0.5942282741650675, 0.5973385971590972, 0.6364885809977225, 0.5768129556891968, 0.2094833323803056, 0.5654708853995237, 0.585397449725932, 0.600339191346626, 0.07151953469176364, 0.11087808097984597, 0.10760946815272654, 0.1411053626309705, 0.11639583089550976, 0.13188858622132849, 0.1408684066494863, 0.08512597103156605, 0.12225587267722782, 0.2562664464114959, 0.7124310164722676, 0.2655764839522483, 0.26294332487438243, 0.2702143318744753, 0.2751355811609224, 0.25557988710693336, 0.199521173163836, 0.27541974667917435, 0.33912680684679264, 0.5347057124456479, 0.5479390032362716, 0.31234525123460843, 0.254074776023815, 0.38809148476320066, 0.2488818019543927, 0.47640688560595124, 0.24658247305217185, 0.29517853759040935, 0.1739890175654606, 0.22862623795590586, 0.3101964942297427, 0.2199490245165805, 0.2828421047580032, 0.26267149562563563, 0.23415104601357717, 0.24328248046769207, 0.2110273538229943, 0.2036706340524964, 0.27491507018162686, 0.21319813424020717, 0.2229817873690646, 0.2575508089486692, 0.25178736757793674, 0.2588280131959263, 0.2748173998438618, 0.18450251476159907, 0.22958629207089787, 0.18198131133045403, 0.21011981712558758, 0.25253453698847583, 0.19953746072158685, 0.1996679186383412, 0.20801223685535208, 0.2030792458026015, 0.1886276989480642, 0.932889499796664, 0.15388248366769386, 0.17348107109747923, 0.20094473960640102, 0.9128200790487851, 0.9372077205125439, 0.1701653582419902, 0.16380970492129, 0.8074685425460032, 0.21264300258776858, 0.15695654985450402, 0.2110984215781434, 0.21144799531259806, 0.16890637322235924, 0.10506163208135877, 0.15724494243255938, 0.7681092813414037, 0.19594114087777603, 0.19805783752909722, 0.20261882355106542, 0.2048435543208128, 0.25474277424476144, 0.19981259099993764, 0.195870349346411, 0.20243448587362578, 0.24878844620934504, 0.10581302186184405, 0.09131988980662442, 0.10548329327458883, 0.08175229218533242, 0.09016927052254597, 0.10953026271782784, 0.10818399681413193, 0.0843195641717508, 0.11362874264304357]}, "mutation_prompt": null}
{"id": "5dee52e7-291d-4f5a-bd96-a67b5ba5242a", "solution": "import numpy as np\n\nclass EvolvingHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def dynamic_f(self):\n        return 0.5 + self.chaotic_map(self.iteration / 200.0) * 0.5\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.dynamic_f() * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EvolvingHybridDEPSO", "description": "Evolving Hybrid DEPSO with dynamic parameter adaptation and chaotic maps for robust exploration and exploitation.", "configspace": "", "generation": 32, "fitness": 0.3411524844220703, "feedback": "The algorithm EvolvingHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.8852116556063374, 0.902680951624778, 0.8936990028497489, 0.890206369678944, 0.8996835776608595, 0.8678944988216907, 0.8907167770362496, 0.9090865852228411, 0.8904265579000894, 0.7928344573709888, 0.7913816860553733, 0.7386160335980355, 0.8001124226706323, 0.7708365141104541, 0.7816577529897535, 0.7852286371764299, 0.7706245635542726, 0.7895208599850709, 0.1820630107633957, 0.14666617187664766, 0.09526255934339156, 0.14342674728175386, 0.09620977015642862, 0.1834951868768988, 0.1435773355744866, 0.10163309354817263, 0.16219338903444747, 0.096121615985435, 0.07725654186918507, 0.10115010273993552, 0.14566737515479022, 0.09964067691817657, 0.11428827508923134, 0.10018070549405023, 0.11639229769708948, 0.10461406663951367, 0.9726597856017339, 0.9632681805449779, 0.9395880809324136, 0.9843106775580747, 0.9641419987192209, 0.9762184232025801, 0.9767009808590171, 0.9793117404018475, 0.9801831551892776, 0.7436474076586063, 0.06028830195534951, 0.7687917425985384, 0.7235172674018568, 0.7463305612952911, 0.7904260692534162, 0.7528105528586585, 0.7696916862989129, 0.7590348692056228, 0.2290347417430587, 0.2294515239249032, 0.2107243318604376, 0.2812305522548326, 0.27788272429698424, 0.8965328866155083, 0.23557640940462987, 0.17934479172842333, 0.39396874254772085, 0.28813814236018975, 0.13333748846656435, 0.34275600376471715, 0.29146874974587245, 0.13521544998466328, 0.3481802935842989, 0.2999280234129206, 0.13603438137997403, 0.4343696628563747, 0.28994661509997144, 0.26534801054529666, 0.3272836880999427, 0.28713855822808354, 0.35206241595172516, 0.30388549677119026, 0.3044528713338085, 0.1416714348191912, 0.28889494952456596, 0.09754712216112038, 0.08027104838369592, 0.006026541668507135, 0.09077997982200126, 9.999999999998899e-05, 0.011590076988480025, 0.009374424875401965, 0.00010063384117164897, 0.12707866652692157, 0.0702977424243707, 0.11383747070297578, 0.11062300378520062, 0.0718803352919476, 0.03854970157996318, 0.13989414650184684, 0.07345829827376316, 0.08464086886630429, 0.13452242656841196, 0.17475937508686545, 0.13494682163472949, 0.11345831800768624, 0.08012715069252208, 0.07993047025894606, 0.21385850713637278, 0.26546461063984583, 0.10223062697559304, 0.07151886365373628, 0.17235275016043705, 0.15222620143806365, 0.12967299636872853, 0.25506812431638326, 0.12405639612789165, 0.09311364288771251, 0.08352538708758106, 0.08440459907841447, 0.22218400501681956, 0.6327908434432827, 0.5551744235287634, 0.5488424822488913, 0.5608601199617872, 0.5577833120351152, 0.5727915879646805, 0.6106033785538548, 0.6115399663555725, 0.575341175556118, 0.08587494313271804, 0.1145452687974785, 0.12234809138333769, 0.09989788889094364, 0.09769711398111014, 0.11025051532288832, 0.13421600106416465, 0.16177848129764638, 0.11073363772960965, 0.2171213135173955, 0.18715847020875176, 0.1840443133119456, 0.2890195788089308, 0.33119116390118974, 0.22624875569895353, 0.47502392648257397, 0.5753076388973393, 0.3085421567201261, 0.32547876124410346, 0.3396601218178493, 0.4717413118469661, 0.5241806298808669, 0.27755400023385457, 0.3044638784056063, 0.5589598025352791, 0.5731997686826875, 0.23058592745672213, 0.0935711978563395, 0.2133621364838163, 0.26950057577161135, 0.35068207112234806, 0.2263148274546839, 0.21509992039605297, 0.22698499819613072, 0.33545589203112747, 0.11791802470944113, 0.24212234762350304, 0.23326216863237348, 0.22469642862748962, 0.24064589907346945, 0.20580892761225, 0.20531130738721626, 0.2621306789425102, 0.23335039740864327, 0.26054708346525235, 0.19437090776570298, 0.25056378728366735, 0.2234939626371215, 0.22957749484387013, 0.19563419827097472, 0.18972975701479278, 0.22190267935140306, 0.22530135228063763, 0.2031695108978061, 0.9188253465855563, 0.12700135532417223, 0.15329099356223685, 0.17322123054977967, 0.8915572845170955, 0.9372659318000733, 0.12262170138254769, 0.170021121258631, 0.15356888206480968, 0.887665120258687, 0.7810442893432777, 0.7625310674368493, 0.8675160355900806, 0.21156344364108204, 0.911092843425247, 0.10512224899915712, 0.08306426677069334, 0.10459650647221808, 0.23935482658558271, 0.19373720234456737, 0.24736887271529118, 0.22147946862507384, 0.22691830920005063, 0.1897006977552964, 0.21088847330780547, 0.2082397872260846, 0.1963809340024152, 0.08931307330204818, 0.09551488759286841, 0.08611880103289082, 0.0871828054212227, 0.09851512477229085, 0.09095823498218447, 0.07152745148106754, 0.09907833917791398, 0.09352080999374868]}, "mutation_prompt": null}
{"id": "3d285007-d55c-414a-91a5-247f324b4a22", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(4 * x * (1 - x), 1.0)  # Logistic chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity and randomness\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold or np.random.rand() < self.diversity_probability:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 100.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 100.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A refined hybrid optimizer utilizing adaptive chaotic maps in DEPSO for enhanced exploration and convergence, with improved diversity handling and dynamic parameter tuning.", "configspace": "", "generation": 33, "fitness": 0.31642054260609126, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.29.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.9339961675042082, 0.9332593298885404, 0.9260285935487316, 0.1828534760844277, 0.9114201281436957, 0.9049139660308585, 0.9349649741640538, 0.1828041804841658, 0.9170003474101462, 0.8717259333575594, 0.8468323699671477, 0.8413370833130056, 0.8651421508591464, 0.8394100112168547, 0.815654436946774, 0.8550632385230262, 0.825869892961217, 0.8272329357445151, 0.08058930475690484, 0.11827508896850902, 0.0929305465265452, 0.06490813887354197, 0.14765247920169966, 0.11034848667558361, 0.1270451569975437, 0.09720263105334559, 0.09363700785870765, 0.11745563472661269, 0.06421151414000703, 0.09490007094000663, 0.10684135826944696, 0.04614016246975994, 0.09777992065117946, 0.09691476077791794, 0.08054299084294703, 0.049150120748255754, 0.9742335343737017, 0.9520029996788488, 0.9744958938059721, 0.9637444689160015, 0.9657483535916543, 0.9665324001194556, 0.9752108469384563, 0.9669809018942778, 0.9600980129715233, 0.795161444354737, 0.7830272047156956, 0.059715719714446114, 0.8405034748057685, 0.7837094298880332, 0.7567639634517819, 0.8006701365683869, 0.7544064049336804, 0.794148254729749, 0.225983951812061, 0.1713434801536372, 0.17130756697959737, 0.2832796646702912, 0.38980449057954025, 0.3886210096801497, 0.17916043609043486, 0.13120382498689653, 0.22086586357250848, 0.25851340082966867, 0.13662963925771143, 0.26031984655654583, 0.27210226264165627, 0.2575733374203242, 0.25464243117387364, 0.2819824272457274, 0.29233083649100644, 0.13603202045690954, 0.271857092199533, 0.13556179758597808, 0.26021624829535883, 0.39290597095571345, 0.2976301956323143, 0.3049253620285469, 0.2867215887314296, 0.24174705621370685, 0.1323795503077161, 0.0004287932310413911, 0.02277905727281193, 0.0045632602465705, 0.07562436614666035, 0.002778925794634457, 0.154047257959399, 0.10614674792445145, 0.0032044274313364207, 0.011052027680288457, 0.06222223793618065, 0.06589089773640266, 0.1073926582822693, 0.07248889045313422, 0.01732659424173455, 0.04942686573241806, 0.21300046459583133, 0.09094633022891596, 0.12498308045400885, 0.2578912871930388, 0.18756402008043682, 0.14060983221288992, 0.08285834633213274, 0.09239873777770158, 0.10730120781430308, 0.1783277848775222, 0.22043096573588827, 0.07657470792797227, 0.13180550064005292, 0.13291636045003763, 0.1132052877523343, 0.12323656408252359, 0.09352707254850989, 0.09232472236192768, 0.08556627620717294, 0.23015903921365832, 0.08598810075763175, 0.6103542771301549, 0.5741177057057627, 0.6107151273751721, 0.5630254709379312, 0.591092196654178, 0.5605756792599329, 0.5899454715296846, 0.6050350718819908, 0.6273216316456327, 0.057726172643162266, 0.09640116588753589, 0.12531888721322726, 0.1189980511882035, 0.0791580934126137, 0.10134670730826834, 0.1630936485913751, 0.11220093518396246, 0.08120750750233019, 0.18030483892689286, 0.33467426232741726, 0.4916195561186004, 0.18835481483858874, 0.623697899106292, 0.7234279923376011, 0.26569528631649764, 0.2888021229075606, 0.13579933965626623, 0.2495932767887612, 0.39845230460417447, 0.18810859769840305, 0.2974838721523375, 0.22267092049843173, 0.4119512233152053, 0.19336648790498956, 0.5051318923888014, 0.15963833282555062, 0.2309428627161344, 0.25470336988440734, 0.21633319695729814, 0.1317548909825782, 0.17953699896844577, 0.14075114268499145, 0.1225005208738712, 0.30707373053163833, 0.1095745154371951, 0.20253251393950422, 0.23164215932155274, 0.25333614285235484, 0.20522666623890673, 0.34714636854706216, 0.2536462324666311, 0.22394231863762548, 0.22637210821651144, 0.24154842479407002, 0.19770104835922697, 0.2561188746058287, 0.20208593940565522, 0.19197420494521844, 0.21348648835987682, 0.18226119847932154, 0.20099187139579022, 0.22959761035798298, 0.1856821949334151, 0.2005409459069709, 0.12735599943782383, 0.12473333105738815, 0.13684136142009828, 0.20209115547400558, 0.9336078537963896, 0.13232385600987395, 0.1704052903000105, 0.1544652201987039, 0.9476313991976509, 0.8538936975270928, 0.7663689619772016, 0.2129474802344995, 0.15546243252114766, 0.21334526404508491, 0.10530085112148513, 0.1042743721959587, 0.7929412832937208, 0.2051671457732719, 0.18609495972700274, 0.20694368364875604, 0.23307640762088644, 0.19874414738113222, 0.17702005629595863, 0.20185402167269906, 0.22602721961142225, 0.18957871076229138, 0.125320105482844, 0.09231769414236746, 0.1044499265626666, 0.10007601439821134, 0.10141743915343127, 0.12726515364104285, 0.07242427419605701, 0.10441695086597447, 0.07342403366657035]}, "mutation_prompt": null}
{"id": "538fef8c-90ed-4bb0-8933-92ad1cb478bd", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A refined hybrid optimizer incorporating adaptive chaotic maps in DEPSO for enhanced exploration and convergence.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.8865276906432433, 0.9020532548803202, 0.8929687050976703, 0.9069966467491789, 0.8983603223003787, 0.9022140074472543, 0.8838639783889877, 0.8886653828703049, 0.889752534826144, 0.7567698703303883, 0.784578368098034, 0.8076249809202548, 0.7611720006041811, 0.7986347352301275, 0.8050952302753023, 0.7936777043904858, 0.8107862909162267, 0.7638655686477411, 0.14306028296887274, 0.18771148863225673, 0.09076269380504487, 0.14472904467535863, 0.18827718037504793, 0.14600008067707715, 0.18654152199131935, 0.11161280818292418, 0.11200366762783509, 0.13393502172957683, 0.14641399913557107, 0.1432167792015192, 0.11181421186718143, 0.09209417505561412, 0.11938418806199658, 0.11206983601831055, 0.11095636186680169, 0.10912525701701048, 0.9717271359469163, 0.9628507846149675, 0.9377341630520235, 0.9810288407887259, 0.9785915503130439, 0.9770423747813494, 0.9783473338829307, 0.9712621930647505, 0.9787075504592555, 0.7607315187580301, 0.7749069267760285, 0.7630288578874603, 0.7507532481153396, 0.6554370351125884, 0.7762723104136083, 0.7499504173558014, 0.6968283959747328, 0.7389586451693928, 0.1721225825938858, 0.22891630584450517, 0.11324758049764427, 0.3549737812815622, 0.2807957237653095, 0.28145549322917607, 0.18018767969655092, 0.2386988483653335, 0.9395469978455472, 0.2720537562684263, 0.1357109215500677, 0.288515417628357, 0.27358595508171457, 0.28033933355072405, 0.3483295090039492, 0.29980271067857245, 0.13457278726329025, 0.31624018099324525, 0.28347106445129555, 0.27653913969396915, 0.2892909131254505, 0.32904479577095047, 0.30792895015902, 0.3267380918354402, 0.3033156492629593, 0.2088685743639237, 0.2906120113344278, 0.004881953303818798, 0.08432094844164972, 0.01040324864575648, 0.08307057080589308, 0.0631748299553836, 0.031141171943307566, 0.038932547461408507, 0.021942713170019723, 0.09321589178997347, 0.14820762824482314, 0.14111157929981544, 0.09939347465031478, 0.07351212675576657, 0.14911297504852605, 0.02739581001833591, 0.11477783328277313, 0.09375370099990121, 0.12437319484907039, 0.07875046545806708, 0.12463510807347011, 0.14210128121458188, 0.07919284437097684, 0.0801485337679555, 0.13337703281066082, 0.19524821804991244, 0.10442299933492127, 0.07342327849013242, 0.16578167026123625, 0.1853016315404299, 0.1189542819871422, 0.1574945670012905, 0.18360986723287642, 0.2558817728796652, 0.12448657793629136, 0.25405459307747846, 0.1254414517844874, 0.5407077538029146, 0.6006067397749144, 0.5396897498932287, 0.5489927270360135, 0.5891834596503931, 0.5459801886932765, 0.5877025571595188, 0.58912009886935, 0.5796039758319813, 0.07975439706166598, 0.10110173168052605, 0.0755122787624074, 0.16076138881367696, 0.10587421420661025, 0.09908423757627094, 0.11384860622149795, 0.14412899438570692, 0.10610491466439798, 0.22279569248288034, 0.6592237296261918, 0.22467227789135458, 0.27264975790467794, 0.42228702264236595, 0.4427009503531557, 0.5283272114477804, 0.21131508909474783, 0.3463028054853772, 0.5602848907432856, 0.5870043317671049, 0.24980633166770938, 0.37827330003298987, 0.3159543684158136, 0.3948951692827499, 0.5338080159903202, 0.6386237352364159, 0.19094651398173923, 0.2682466646833648, 0.24944249579405708, 0.20048413900667417, 0.3126123000671225, 0.19508244130654495, 0.2440464616149688, 0.2746657038803456, 0.2758095868983087, 0.1718425074209099, 0.24221577925087046, 0.24277264917923613, 0.22753707311652804, 0.21621523555871425, 0.23220195984323055, 0.2121859746984508, 0.22233176434332813, 0.19428032015735874, 0.2940143940691601, 0.18346601962379372, 0.2507595245585167, 0.2074744620231186, 0.2296346173180046, 0.7839070787440949, 0.18887893138201983, 0.19948332275076253, 0.2261375176508097, 0.19661374747919813, 0.9185297033957897, 0.17730516387770456, 0.11326657578340704, 0.17278331750195008, 0.9190619999789291, 0.2007124882642538, 0.0996663158636657, 0.16991723780351253, 0.16271709766976927, 0.8243727383661772, 0.8166819556788825, 0.7311027166633209, 0.9133133255502286, 0.8484364245717022, 0.7770450456081295, 0.10514634504197418, 0.1699183301713061, 0.16636178423956227, 0.19554443874623362, 0.24430239869142467, 0.21100720171394982, 0.1973610633324807, 0.25121027229113, 0.19102423719310313, 0.2563067934359131, 0.23300659057012685, 0.22269509176237645, 0.08892873400730372, 0.07113752042749677, 0.11154483811644855, 0.0966630146129761, 0.0829219834948779, 0.14774202050214513, 0.10337404775080683, 0.10543583486427055, 0.09783716494350791]}, "mutation_prompt": null}
{"id": "a013ddfd-0fa3-4522-806d-316097320e4a", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A refined hybrid optimizer incorporating adaptive chaotic maps in DEPSO for enhanced exploration and convergence.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.8865276906432433, 0.9020532548803202, 0.8929687050976703, 0.9069966467491789, 0.8983603223003787, 0.9022140074472543, 0.8838639783889877, 0.8886653828703049, 0.889752534826144, 0.7567698703303883, 0.784578368098034, 0.8076249809202548, 0.7611720006041811, 0.7986347352301275, 0.8050952302753023, 0.7936777043904858, 0.8107862909162267, 0.7638655686477411, 0.14306028296887274, 0.18771148863225673, 0.09076269380504487, 0.14472904467535863, 0.18827718037504793, 0.14600008067707715, 0.18654152199131935, 0.11161280818292418, 0.11200366762783509, 0.13393502172957683, 0.14641399913557107, 0.1432167792015192, 0.11181421186718143, 0.09209417505561412, 0.11938418806199658, 0.11206983601831055, 0.11095636186680169, 0.10912525701701048, 0.9717271359469163, 0.9628507846149675, 0.9377341630520235, 0.9810288407887259, 0.9785915503130439, 0.9770423747813494, 0.9783473338829307, 0.9712621930647505, 0.9787075504592555, 0.7607315187580301, 0.7749069267760285, 0.7630288578874603, 0.7507532481153396, 0.6554370351125884, 0.7762723104136083, 0.7499504173558014, 0.6968283959747328, 0.7389586451693928, 0.1721225825938858, 0.22891630584450517, 0.11324758049764427, 0.3549737812815622, 0.2807957237653095, 0.28145549322917607, 0.18018767969655092, 0.2386988483653335, 0.9395469978455472, 0.2720537562684263, 0.1357109215500677, 0.288515417628357, 0.27358595508171457, 0.28033933355072405, 0.3483295090039492, 0.29980271067857245, 0.13457278726329025, 0.31624018099324525, 0.28347106445129555, 0.27653913969396915, 0.2892909131254505, 0.32904479577095047, 0.30792895015902, 0.3267380918354402, 0.3033156492629593, 0.2088685743639237, 0.2906120113344278, 0.004881953303818798, 0.08432094844164972, 0.01040324864575648, 0.08307057080589308, 0.0631748299553836, 0.031141171943307566, 0.038932547461408507, 0.021942713170019723, 0.09321589178997347, 0.14820762824482314, 0.14111157929981544, 0.09939347465031478, 0.07351212675576657, 0.14911297504852605, 0.02739581001833591, 0.11477783328277313, 0.09375370099990121, 0.12437319484907039, 0.07875046545806708, 0.12463510807347011, 0.14210128121458188, 0.07919284437097684, 0.0801485337679555, 0.13337703281066082, 0.19524821804991244, 0.10442299933492127, 0.07342327849013242, 0.16578167026123625, 0.1853016315404299, 0.1189542819871422, 0.1574945670012905, 0.18360986723287642, 0.2558817728796652, 0.12448657793629136, 0.25405459307747846, 0.1254414517844874, 0.5407077538029146, 0.6006067397749144, 0.5396897498932287, 0.5489927270360135, 0.5891834596503931, 0.5459801886932765, 0.5877025571595188, 0.58912009886935, 0.5796039758319813, 0.07975439706166598, 0.10110173168052605, 0.0755122787624074, 0.16076138881367696, 0.10587421420661025, 0.09908423757627094, 0.11384860622149795, 0.14412899438570692, 0.10610491466439798, 0.22279569248288034, 0.6592237296261918, 0.22467227789135458, 0.27264975790467794, 0.42228702264236595, 0.4427009503531557, 0.5283272114477804, 0.21131508909474783, 0.3463028054853772, 0.5602848907432856, 0.5870043317671049, 0.24980633166770938, 0.37827330003298987, 0.3159543684158136, 0.3948951692827499, 0.5338080159903202, 0.6386237352364159, 0.19094651398173923, 0.2682466646833648, 0.24944249579405708, 0.20048413900667417, 0.3126123000671225, 0.19508244130654495, 0.2440464616149688, 0.2746657038803456, 0.2758095868983087, 0.1718425074209099, 0.24221577925087046, 0.24277264917923613, 0.22753707311652804, 0.21621523555871425, 0.23220195984323055, 0.2121859746984508, 0.22233176434332813, 0.19428032015735874, 0.2940143940691601, 0.18346601962379372, 0.2507595245585167, 0.2074744620231186, 0.2296346173180046, 0.7839070787440949, 0.18887893138201983, 0.19948332275076253, 0.2261375176508097, 0.19661374747919813, 0.9185297033957897, 0.17730516387770456, 0.11326657578340704, 0.17278331750195008, 0.9190619999789291, 0.2007124882642538, 0.0996663158636657, 0.16991723780351253, 0.16271709766976927, 0.8243727383661772, 0.8166819556788825, 0.7311027166633209, 0.9133133255502286, 0.8484364245717022, 0.7770450456081295, 0.10514634504197418, 0.1699183301713061, 0.16636178423956227, 0.19554443874623362, 0.24430239869142467, 0.21100720171394982, 0.1973610633324807, 0.25121027229113, 0.19102423719310313, 0.2563067934359131, 0.23300659057012685, 0.22269509176237645, 0.08892873400730372, 0.07113752042749677, 0.11154483811644855, 0.0966630146129761, 0.0829219834948779, 0.14774202050214513, 0.10337404775080683, 0.10543583486427055, 0.09783716494350791]}, "mutation_prompt": null}
{"id": "384e967b-7988-4440-a3d9-f07d9f1998ed", "solution": "import numpy as np\n\nclass AdvancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.5  # DE scaling factor, made adaptive\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def levy_flight(self, L):\n        u = np.random.normal(0, 1, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / (np.abs(v) ** (1/L))\n        return step\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with time-varying parameters\n            self.f = 0.5 * (1 - np.cos(self.iteration / self.budget * np.pi))\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                mutant = self.particles[a] + self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator with Lévy flights\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i])) + self.levy_flight(1.5)\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "AdvancedHybridDEPSO", "description": "Integration of Lévy flights and time-varying DE parameters into DEPSO for enhanced exploration and convergence.", "configspace": "", "generation": 36, "fitness": 0.16963592543998357, "feedback": "The algorithm AdvancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.18.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.31160364845103516, 0.273187909794955, 0.3215678116899354, 0.2918572666568382, 0.28373810457056703, 0.29432261310626195, 0.29531767006482734, 0.29621623954984433, 0.31339988642650085, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10681224230603548, 0.08242260805444368, 0.10348338793117351, 0.12262853985448186, 0.09911035166937476, 0.08952241542378236, 0.08780597562237558, 0.07773173616121509, 0.09172742387206179, 0.0875711237348421, 0.06288381497248197, 0.07872915101731182, 0.07499055248344244, 0.07769001836726952, 0.07403444742417653, 0.08221818630119848, 0.07632276526159709, 0.09833545711533442, 0.9578629780339764, 0.9372428686392086, 0.9346324052603088, 0.9069333682434146, 0.8889745588953888, 0.9454276150941241, 0.9310635895016808, 0.9598371251729061, 0.9366616810146537, 0.17701293908124693, 0.17350816317594253, 0.1731151895363311, 0.18117638062630592, 0.17827393359039945, 0.16968705573092724, 0.1727279750184365, 0.17236564040282154, 0.18026898613629783, 0.20855513560928918, 0.20740462555939887, 0.19690501111716974, 0.2278458773072457, 0.21746042277616195, 0.22785868588373104, 0.22390219423617386, 0.2036138804871468, 0.2378452389831115, 0.08337150286147155, 0.08484477904411103, 0.09913171633327789, 0.09099877580597115, 0.10785212214832396, 0.06987687933062514, 0.09709513817300919, 0.09108520122581121, 0.08593787359015803, 0.09743328491686276, 0.09881244020763713, 0.1051806015624217, 0.0925674453007812, 0.13558508823720317, 0.09474789221145075, 0.08289543194769777, 0.10403686611135488, 0.0697807128685648, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10641101669451158, 0.08395302814607564, 0.0962838474829194, 0.11305727918572062, 0.014401503264203752, 0.034871361926690936, 0.05617458862975999, 0.09948228461113451, 0.06768549203325924, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03692721797810228, 0.02515314360120935, 0.03066526415370885, 0.02855538423600612, 0.043499030693794905, 0.03720048812966792, 0.04291697153665697, 0.03345470798930328, 0.041035450524908756, 0.28988447881444657, 0.2833719968267576, 0.30681806510014575, 0.29507129540711863, 0.3252986504845994, 0.3063039980810668, 0.304426115797675, 0.30719903660125714, 0.2891189995272816, 0.08828790151466148, 0.08521588276845482, 0.08335750104795714, 0.08282791440143777, 0.09029193484549902, 0.07589643937838464, 0.09614302158084098, 0.10692035931661192, 0.08492562262587067, 0.1333017547698051, 0.12139747622072883, 0.14789303504055373, 0.16575731429965967, 0.16242368594841083, 0.15811057671339512, 0.1613265531892525, 0.13147893438390312, 0.12633967681817326, 0.22017960348402943, 0.23161243733697778, 0.20839960780719524, 0.19641513551081435, 0.22824662447916755, 0.21635342295423277, 0.22665445741118717, 0.24287725066681243, 0.2302715951536788, 0.16622703410859174, 0.1616231136135735, 0.16671427232213953, 0.15465305903413662, 0.1711687786306071, 0.17844891869649304, 0.15762592451869206, 0.16153026012577465, 0.15932542796376092, 0.22543964184095167, 0.19459914623115993, 0.20961648769500485, 0.2193079252318456, 0.2706651521654653, 0.21526460304742145, 0.22391034817456767, 0.19553562173904426, 0.2032438639755716, 0.1790813778203374, 0.17466093702156982, 0.17736732545649814, 0.16611232108516483, 0.17623324543445984, 0.17913213215253232, 0.18300997385754658, 0.1895258854053683, 0.17441347845749078, 0.19113079497798102, 0.18079270545189685, 0.14730580542417826, 0.1620101581040353, 0.18800755603836694, 0.18697285768954142, 0.1273013522518287, 0.16729425192901382, 0.14867367338584647, 0.31166643813351325, 0.18833534372197824, 0.34747422499754266, 0.19214545799494576, 0.1672055507450736, 0.1914233886973531, 0.10374003572877022, 0.14599364900891465, 0.3788095688786278, 0.17638263241926377, 0.19188781599162863, 0.19066727627432023, 0.18258571450645067, 0.18908534233945007, 0.17133812156995754, 0.1878656189152561, 0.18757922669646465, 0.18077313377839854, 0.08947218934347623, 0.09740218495860031, 0.08096152830200354, 0.0823447654226166, 0.07666363372529972, 0.07896768911437224, 0.07475176202913403, 0.07987229769330284, 0.08258485099169899]}, "mutation_prompt": null}
{"id": "fe587eb2-1957-4b2f-8dde-f858e4fd4024", "solution": "import numpy as np\n\nclass AdvancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Dynamic mutation scaling based on iteration\n            self.f = 0.5 + 0.5 * np.abs(np.cos(self.iteration / 50.0))\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                if np.random.rand() < self.diversity_probability:\n                    continue\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "AdvancedHybridDEPSO", "description": "An advanced hybrid optimizer integrating adaptive chaotic dynamics with DEPSO, leveraging dynamic mutation scaling for improved exploration and convergence.", "configspace": "", "generation": 37, "fitness": 0.3340165482538044, "feedback": "The algorithm AdvancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.28.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.8834362920531883, 0.9047620238891794, 0.9077746483360519, 0.8823507507842036, 0.9057391015332141, 0.8724266838838864, 0.8845483926271183, 0.9081916958227546, 0.886818667429842, 0.7558199025522943, 0.825799412185253, 0.7534137427582128, 0.7944915300979664, 0.8020765599173348, 0.7574281728957502, 0.7706931908819215, 0.7673727925613469, 0.799404159611903, 0.13030445324100548, 0.12540572169575792, 0.1433723272310088, 0.13410964183658813, 0.1563985494633061, 0.15887940306212678, 0.10981241241095174, 0.11107380135239364, 0.1441743381772541, 0.14561817253268616, 0.11458497062342066, 0.13303998917902826, 0.11627467784060885, 0.14354399522868078, 0.09647642936104062, 0.11606629559735171, 0.12328127542994605, 0.12482137007309135, 0.9894109906786599, 0.9658160575759177, 0.9674939456574285, 0.9594822192291383, 0.9724370406790436, 0.9816919702990202, 0.9718033102303134, 0.9756944442774423, 0.9864111739664065, 0.755479929188893, 0.7915792042084353, 0.7214900335178281, 0.7722394130240491, 0.7875778033530076, 0.74530290353606, 0.7470261098434179, 0.7644820585057828, 0.7525294492437258, 0.23062496098569463, 0.38337723751116237, 0.22876101033237628, 0.36218002534893023, 0.2798690029567974, 0.19437207336935924, 0.23712213209728772, 0.17800112965016612, 0.22254065726025984, 0.2940833344241006, 0.3356656503464639, 0.27922516598419445, 0.26677004342794997, 0.13583119146723444, 0.32948528607958094, 0.3121645840413394, 0.2987419783997196, 0.28776988447400675, 0.2744929358499725, 0.15404602981671955, 0.2746217832753598, 0.1344307743562092, 0.31171666323200575, 0.3006509956854485, 0.2965707205270556, 0.34568564349188013, 0.3035413571066524, 0.04498561403368717, 0.009000382490779835, 0.011115285639718975, 0.1073967136734918, 0.011169315064286978, 0.06161352744956128, 0.01956190680699188, 0.006954109897946759, 0.08228966802311766, 0.11157125522098432, 0.04510090858683413, 0.051273475745154395, 0.0880626836130346, 0.03832453043230166, 0.0256809938791277, 0.15282429263543895, 0.1404052236688802, 0.058141518994655916, 0.08799873518379753, 0.0814284412496179, 0.04993569070338566, 0.08018119964567194, 0.14734964959021635, 0.17133393512771922, 0.18085217725157232, 0.26958200070941585, 0.08054931543128863, 0.13778160740717416, 0.13679261187308223, 0.3353207539487637, 0.25620035620403336, 0.12099775572731764, 0.24498386468325606, 0.20673020792435437, 0.12188416069816066, 0.10028380727893016, 0.5646349876371775, 0.5509964384857675, 0.5710420462553536, 0.6351618791542079, 0.5518754320876713, 0.5630832256947595, 0.5750320569764158, 0.6075961875504095, 0.5730542600321545, 0.0907759022281911, 0.15535021575587182, 0.09916393450825511, 0.08569051581516707, 0.1139652510529151, 0.1436012538722936, 0.16439144504062386, 0.11007018032276905, 0.08742096018286816, 0.21910933225112816, 0.34670855671365564, 0.3114531859588713, 0.35532015736738665, 0.35071768608332854, 0.23163839142174536, 0.19594704248514638, 0.15934162988156186, 0.2601429982100826, 0.4202739883611465, 0.31268807565887413, 0.40333679355050156, 0.5223851801125156, 0.4435724584685471, 0.6384886500148454, 0.2559741835612859, 0.4560127789195584, 0.21895423368392508, 0.08124782370599681, 0.30233425770761146, 0.1949547299876655, 0.28716609585004926, 0.2734396701797859, 0.4009370310593203, 0.22535978285985703, 0.17772084396242172, 0.33911117047569017, 0.21811969215117544, 0.24114658790999, 0.1981961533780836, 0.21501383615583236, 0.25774025376660925, 0.2674724704981525, 0.24164474914017986, 0.22299794909689652, 0.235069258620062, 0.19879306055395707, 0.19598050338742456, 0.22872868617060582, 0.25006563482969557, 0.2254757853860725, 0.17679172407677457, 0.2532560524588334, 0.22922413602502634, 0.21120497536307337, 0.9207975080745785, 0.14716578667383784, 0.1539221772738667, 0.17030492127315044, 0.2011515401965066, 0.1796025515616544, 0.10797979812495306, 0.170162636343984, 0.17642995401158512, 0.8762157139105315, 0.16941870480620436, 0.8727564547964843, 0.21289695778750828, 0.16911893614712847, 0.8617578636224948, 0.10521359923918028, 0.15676657873378685, 0.8163330812067052, 0.22948977441388008, 0.2142934225177715, 0.21701199209523048, 0.21677197436634577, 0.20527493147614506, 0.18442177502593637, 0.23166142185813043, 0.20913514219432527, 0.2050991010624441, 0.07664717548015598, 0.1173926674354987, 0.10338842788880742, 0.09769930011258299, 0.10518805315052393, 0.14698852163034193, 0.09980487578805441, 0.10219728842972742, 0.09721587483397576]}, "mutation_prompt": null}
{"id": "f1ce8a2f-2502-4f0b-b55e-baad5a800add", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A refined hybrid optimizer incorporating adaptive chaotic maps in DEPSO for enhanced exploration and convergence.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.8865276906432433, 0.9020532548803202, 0.8929687050976703, 0.9069966467491789, 0.8983603223003787, 0.9022140074472543, 0.8838639783889877, 0.8886653828703049, 0.889752534826144, 0.7567698703303883, 0.784578368098034, 0.8076249809202548, 0.7611720006041811, 0.7986347352301275, 0.8050952302753023, 0.7936777043904858, 0.8107862909162267, 0.7638655686477411, 0.14306028296887274, 0.18771148863225673, 0.09076269380504487, 0.14472904467535863, 0.18827718037504793, 0.14600008067707715, 0.18654152199131935, 0.11161280818292418, 0.11200366762783509, 0.13393502172957683, 0.14641399913557107, 0.1432167792015192, 0.11181421186718143, 0.09209417505561412, 0.11938418806199658, 0.11206983601831055, 0.11095636186680169, 0.10912525701701048, 0.9717271359469163, 0.9628507846149675, 0.9377341630520235, 0.9810288407887259, 0.9785915503130439, 0.9770423747813494, 0.9783473338829307, 0.9712621930647505, 0.9787075504592555, 0.7607315187580301, 0.7749069267760285, 0.7630288578874603, 0.7507532481153396, 0.6554370351125884, 0.7762723104136083, 0.7499504173558014, 0.6968283959747328, 0.7389586451693928, 0.1721225825938858, 0.22891630584450517, 0.11324758049764427, 0.3549737812815622, 0.2807957237653095, 0.28145549322917607, 0.18018767969655092, 0.2386988483653335, 0.9395469978455472, 0.2720537562684263, 0.1357109215500677, 0.288515417628357, 0.27358595508171457, 0.28033933355072405, 0.3483295090039492, 0.29980271067857245, 0.13457278726329025, 0.31624018099324525, 0.28347106445129555, 0.27653913969396915, 0.2892909131254505, 0.32904479577095047, 0.30792895015902, 0.3267380918354402, 0.3033156492629593, 0.2088685743639237, 0.2906120113344278, 0.004881953303818798, 0.08432094844164972, 0.01040324864575648, 0.08307057080589308, 0.0631748299553836, 0.031141171943307566, 0.038932547461408507, 0.021942713170019723, 0.09321589178997347, 0.14820762824482314, 0.14111157929981544, 0.09939347465031478, 0.07351212675576657, 0.14911297504852605, 0.02739581001833591, 0.11477783328277313, 0.09375370099990121, 0.12437319484907039, 0.07875046545806708, 0.12463510807347011, 0.14210128121458188, 0.07919284437097684, 0.0801485337679555, 0.13337703281066082, 0.19524821804991244, 0.10442299933492127, 0.07342327849013242, 0.16578167026123625, 0.1853016315404299, 0.1189542819871422, 0.1574945670012905, 0.18360986723287642, 0.2558817728796652, 0.12448657793629136, 0.25405459307747846, 0.1254414517844874, 0.5407077538029146, 0.6006067397749144, 0.5396897498932287, 0.5489927270360135, 0.5891834596503931, 0.5459801886932765, 0.5877025571595188, 0.58912009886935, 0.5796039758319813, 0.07975439706166598, 0.10110173168052605, 0.0755122787624074, 0.16076138881367696, 0.10587421420661025, 0.09908423757627094, 0.11384860622149795, 0.14412899438570692, 0.10610491466439798, 0.22279569248288034, 0.6592237296261918, 0.22467227789135458, 0.27264975790467794, 0.42228702264236595, 0.4427009503531557, 0.5283272114477804, 0.21131508909474783, 0.3463028054853772, 0.5602848907432856, 0.5870043317671049, 0.24980633166770938, 0.37827330003298987, 0.3159543684158136, 0.3948951692827499, 0.5338080159903202, 0.6386237352364159, 0.19094651398173923, 0.2682466646833648, 0.24944249579405708, 0.20048413900667417, 0.3126123000671225, 0.19508244130654495, 0.2440464616149688, 0.2746657038803456, 0.2758095868983087, 0.1718425074209099, 0.24221577925087046, 0.24277264917923613, 0.22753707311652804, 0.21621523555871425, 0.23220195984323055, 0.2121859746984508, 0.22233176434332813, 0.19428032015735874, 0.2940143940691601, 0.18346601962379372, 0.2507595245585167, 0.2074744620231186, 0.2296346173180046, 0.7839070787440949, 0.18887893138201983, 0.19948332275076253, 0.2261375176508097, 0.19661374747919813, 0.9185297033957897, 0.17730516387770456, 0.11326657578340704, 0.17278331750195008, 0.9190619999789291, 0.2007124882642538, 0.0996663158636657, 0.16991723780351253, 0.16271709766976927, 0.8243727383661772, 0.8166819556788825, 0.7311027166633209, 0.9133133255502286, 0.8484364245717022, 0.7770450456081295, 0.10514634504197418, 0.1699183301713061, 0.16636178423956227, 0.19554443874623362, 0.24430239869142467, 0.21100720171394982, 0.1973610633324807, 0.25121027229113, 0.19102423719310313, 0.2563067934359131, 0.23300659057012685, 0.22269509176237645, 0.08892873400730372, 0.07113752042749677, 0.11154483811644855, 0.0966630146129761, 0.0829219834948779, 0.14774202050214513, 0.10337404775080683, 0.10543583486427055, 0.09783716494350791]}, "mutation_prompt": null}
{"id": "28bd0816-26ac-4777-9156-4b2dfcfc7006", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.721, 1.0)  # Slightly modified chaotic map for enhanced dynamics\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n\n        while evaluations < self.budget:\n            self.iteration += 1\n            \n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                if np.random.rand() < self.diversity_probability:\n                    self.particles[i] = np.random.uniform(self.lb, self.ub, self.dim)\n                    continue\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.85  # Adjusted inertia weight for improved convergence\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.7 + 0.3 * np.cos(self.iteration / 25.0)  # Adjusted cognitive coefficient\n            self.c2 = 1.7 + 0.3 * np.sin(self.iteration / 25.0)  # Adjusted social coefficient\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "An enhanced hybrid optimization algorithm using adaptive chaotic maps in DEPSO with dynamic parameter tuning for exploration and convergence.", "configspace": "", "generation": 39, "fitness": 0.2622787315338405, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.22.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.7583151133148623, 0.5907082348986801, 0.6472262174592174, 0.5919836862666239, 0.6268830699922769, 0.5343480245077303, 0.6525707472793331, 0.4954234769542297, 0.720630995160781, 0.11935951081244223, 0.22414715994861867, 0.1928539811746769, 0.12414263466900666, 0.32694816321410725, 0.1830315494703636, 0.22176087435191771, 0.18303516571747191, 0.20770932773155248, 0.08739390962851035, 0.11311469873271052, 0.09852566331055312, 0.11460050445561809, 0.14710649933095132, 0.12338297143815613, 0.12481433990727275, 0.13590688335893553, 0.15219195414209175, 0.10982327256890945, 0.1360648108110537, 0.09947630371635319, 0.10598688549218327, 0.12080518021997033, 0.09046193976420547, 0.09476072694108406, 0.07950601489429787, 0.11689636217109, 0.9835169561774193, 0.9740773740412048, 0.9773003700588188, 0.9730252098167665, 0.9763948033572004, 0.9459672397790726, 0.9818776891425048, 0.9792831406509821, 0.9843457257989248, 0.3276036760798431, 0.3925194584772115, 0.3585798424963722, 0.40875519181178943, 0.4279161436584592, 0.363341518156322, 0.39202244808432474, 0.3917435441165603, 0.37506170402417605, 0.33549084749175073, 0.27374935638576003, 0.2077797878419434, 0.26985385954878316, 0.28233214403700346, 0.19082584342807518, 0.23779104891253477, 0.3736153986993245, 0.8047956213766749, 0.13131738452770225, 0.12328586775438544, 0.20295671010396432, 0.18929035281965534, 0.135314518455649, 0.16355171857858986, 0.1719974980578789, 0.17528462956076674, 0.1757961818086785, 0.17767572653331754, 0.17763555347712223, 0.1748199912798657, 0.16138764877594092, 0.17877534542685114, 0.1747712009190695, 0.2229155724993932, 0.08250987476311633, 0.17453169774807575, 9.999999999998899e-05, 0.0955154616844851, 0.00474954124748872, 0.058398936944834556, 9.999999999998899e-05, 0.022083751498864546, 9.999999999998899e-05, 0.03935573642053547, 0.03159945340677228, 0.08309449820737613, 0.11358640940996079, 0.1048220870649117, 0.10873300765015825, 0.03460622137971536, 0.07571425336402005, 0.08470890711207213, 0.08873890686849661, 0.09812425918708245, 0.08945577831610552, 0.011967604517400643, 0.07644060793315244, 0.043732443779640695, 0.10457353032782468, 0.06752405955691632, 0.0773925574918558, 0.1162886071528757, 0.09569362196684505, 0.1762388467921019, 0.175550418692757, 0.12042146194482994, 0.1480162382377408, 0.24737889550967107, 0.1665133418180903, 0.12225093318399904, 0.18022428543187086, 0.08762761718449474, 0.46356582993249007, 0.5299456452971636, 0.47273926509844655, 0.4793070321027606, 0.45823316803079506, 0.4731580493445997, 0.4757302706670089, 0.46725916763534725, 0.5013350000310521, 0.08100278986883946, 0.15638883752401056, 0.06969503467259697, 0.1374073330329766, 0.13176474444597097, 0.13571936692302278, 0.1306591369204798, 0.11977614174799733, 0.15424790381380027, 0.1907490593607699, 0.32256268177215874, 0.2834770998370122, 0.26085837499615805, 0.2743314694982508, 0.18876633893522599, 0.1820654086599619, 0.38788548698799774, 0.1856712483471833, 0.29692776935383103, 0.24213860727540282, 0.22373747565512847, 0.33918572544141423, 0.24324667407500744, 0.3299435214541583, 0.33751989173183006, 0.36958697711837385, 0.3798571818022739, 0.22292548391472444, 0.2484742499320216, 0.1559359963125455, 0.21698748220219966, 0.2458890210648219, 0.2669754084881799, 0.1921355150695928, 0.23642632066806057, 0.23954526868665493, 0.2906121108846712, 0.24151808938477048, 0.22799585003710354, 0.24179327567606734, 0.24620264855558516, 0.23863256360850282, 0.25257343864082893, 0.22086733202153785, 0.2229577414612972, 0.2064448746742379, 0.22432925765446754, 0.20518234938637991, 0.1853106037941611, 0.19329796897877172, 0.2077301824395319, 0.2036848413471064, 0.24634930038645197, 0.19029102423565347, 0.1937213565978102, 0.17693446486636766, 0.18851073002320073, 0.7795810353370752, 0.5023039898505697, 0.672030760979196, 0.16283657568492094, 0.2868802378873382, 0.28622961867857655, 0.5768863765099361, 0.21156589952269633, 0.6393549903288507, 0.20841335342079326, 0.17520603299722648, 0.5708926784484126, 0.6173278272857572, 0.1688304071060156, 0.16845796356304577, 0.1820453496401474, 0.21297245337997983, 0.19654940418296796, 0.18788464887968492, 0.18098522510971038, 0.20107529314980543, 0.19373662035872363, 0.21135768074395744, 0.20402704470516342, 0.1154722687769909, 0.10894447635434956, 0.09310469095840612, 0.0916896595045017, 0.09442167176584004, 0.14794372096435493, 0.1334604239924747, 0.09173821671520999, 0.08461640250945546]}, "mutation_prompt": null}
{"id": "7e651002-5d80-421a-a475-d5a99626a6af", "solution": "import numpy as np\n\nclass ImprovedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.9  # DE scaling factor adjusted for experiment\n        self.cr = 0.85  # DE crossover probability slightly adjusted\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.6  # cognitive coefficient for PSO adapted\n        self.c2 = 1.4  # social coefficient for PSO adapted\n        self.vel_max = 1.5  # maximum velocity for PSO adjusted\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.6, 1.0)  # Slightly adjusted chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.8  # Slightly increased reduction factor\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.6 + 0.4 * np.cos(self.iteration / 40.0)\n            self.c2 = 1.4 + 0.4 * np.sin(self.iteration / 60.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "ImprovedHybridDEPSO", "description": "A refined hybrid optimizer utilizing adaptive chaotic maps and diversity-based parameter tuning in DEPSO for enhanced exploration and convergence.  ", "configspace": "", "generation": 40, "fitness": 0.3462065869303481, "feedback": "The algorithm ImprovedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.29.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.9004292582360892, 0.9060624228980796, 0.9006501589611835, 0.8863966564631288, 0.9146269352881381, 0.8985875960309039, 0.903245073542126, 0.9235205803210508, 0.9050485867351957, 0.8157696259983053, 0.8020220078395419, 0.7892347581411273, 0.8038513466628014, 0.8068206111341816, 0.7950487275810153, 0.802215300113944, 0.8026765804511208, 0.819555137081557, 0.15793582959445707, 0.11948294013367067, 0.08796687913475487, 0.11631989608873794, 0.11735633101716525, 0.18630453016222415, 0.10873995559367577, 0.14267529787683364, 0.11828921750150789, 0.11622682416920538, 0.10857288099995299, 0.1136992368023162, 0.11170978323197323, 0.18304932347115688, 0.08769600803824962, 0.13532338597753368, 0.0780494038355759, 0.1328652342091753, 0.9758477977884574, 0.9672482444798308, 0.9745170846301983, 0.974230252838962, 0.9749611909798103, 0.9796050380085182, 0.9846980093974742, 0.9789727096834674, 0.9805002098248161, 0.8008561812561839, 0.7441051086600963, 0.7889029843422365, 0.8017853619541971, 0.8007300865990445, 0.7257734718356047, 0.7821801927823147, 0.08870770386118931, 0.7972316411448067, 0.8377911530988263, 0.2519394763458277, 0.315094227219324, 0.38832718597541194, 0.3886085407562738, 0.278686246502555, 0.333581457022466, 0.3782320198720096, 0.23761487042753693, 0.2642035038997592, 0.13338502193388835, 0.29555643839686385, 0.252311255676973, 0.28756779076006245, 0.2688900532338184, 0.3021198604442378, 0.2841294902435202, 0.4463188432732601, 0.270807910083518, 0.2703606750582912, 0.22980724032918087, 0.32755167591373846, 0.3229623124989224, 0.32657591648744466, 0.2672404469464297, 0.3172612637867125, 0.31067443920735827, 0.07456527006031555, 0.013399987525203327, 0.02235993070097153, 0.059827859959606045, 0.014356521901762287, 0.046817577394033805, 0.06341641723409286, 0.004802616969582951, 0.11163964179036123, 0.14027633449657173, 0.08326968042253646, 0.08773278993967959, 0.11576030902932866, 0.07064119962776982, 0.0860257490011822, 0.10707421222076352, 0.10189510525337686, 0.06490578814005243, 0.1725462202238579, 0.18403621566893014, 0.12083586823404369, 0.12667478232566243, 0.13760930730227372, 0.1501961221081789, 0.10330262039406313, 0.10007639132140189, 0.07181387698897501, 0.4032687199966315, 0.2586919954536905, 0.1776629833931651, 0.14102821655683673, 0.11691797642176294, 0.0216120633668877, 0.14915036478134458, 0.19391482901667123, 0.096805983745051, 0.5846315305649505, 0.6094246590931873, 0.5842959974524149, 0.5665574642005218, 0.6024069998057641, 0.626103185447441, 0.5842043579677934, 0.5997147970152723, 0.6165737898811912, 0.11948892488331952, 0.1446957040799962, 0.15707720329602015, 0.09537997160508005, 0.07899906231425124, 0.11606853747709467, 0.12963533948662698, 0.08194913778023494, 0.06794125177150401, 0.7556202049547205, 0.2790190554127596, 0.5214496979610124, 0.45553366364390757, 0.24771063374434843, 0.20595161082561353, 0.4165405500949838, 0.25736881914434284, 0.2701565597462472, 0.3132395502407699, 0.48421003365143434, 0.4976378677896365, 0.41294877286350173, 0.26819382872433517, 0.4002711435632065, 0.23941842048094764, 0.34504170743024176, 0.29367033728605874, 0.3354611971910776, 0.18535602785254168, 0.30600839437702787, 0.35357191393289233, 0.36142020277761955, 0.19223999947390125, 0.16614261841516054, 0.26590708403516106, 0.2697926708227857, 0.2961593723761079, 0.2592282173680689, 0.20963225562405663, 0.3268769883556263, 0.2593240145473166, 0.2088271926153472, 0.2204257138560478, 0.23663484258735745, 0.24918083027329152, 0.2082629801114545, 0.1996746868346213, 0.20920416477764137, 0.25481026298288123, 0.21274126731059173, 0.24910705283440826, 0.20348857344670612, 0.8378408607422154, 0.2023779939796717, 0.9339989693867109, 0.17885764429399642, 0.11311447665388441, 0.18963649072778632, 0.20108756864000388, 0.2010996805136942, 0.09971824835176213, 0.1703432130529251, 0.16718761918866964, 0.7422007241808557, 0.21404049532862013, 0.7995907625933282, 0.2120060970707397, 0.8182782459834388, 0.21142228899922988, 0.10490904740574114, 0.16971602785960005, 0.8766684184224963, 0.18449922998765755, 0.20832486421007457, 0.18739828288436589, 0.20285085470080666, 0.2078690191037864, 0.20307339016576686, 0.20471252340950985, 0.19004732413408043, 0.20108008126546661, 0.11801570252287585, 0.09485197653848243, 0.09352133814471053, 0.102050158405804, 0.14703603312612978, 0.11731521392900268, 0.10280449479159193, 0.10161448645893723, 0.09946559759467166]}, "mutation_prompt": null}
{"id": "a0aacf62-6a61-4e53-8d84-4470f417e19a", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A refined hybrid optimizer incorporating adaptive chaotic maps in DEPSO for enhanced exploration and convergence.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.8865276906432433, 0.9020532548803202, 0.8929687050976703, 0.9069966467491789, 0.8983603223003787, 0.9022140074472543, 0.8838639783889877, 0.8886653828703049, 0.889752534826144, 0.7567698703303883, 0.784578368098034, 0.8076249809202548, 0.7611720006041811, 0.7986347352301275, 0.8050952302753023, 0.7936777043904858, 0.8107862909162267, 0.7638655686477411, 0.14306028296887274, 0.18771148863225673, 0.09076269380504487, 0.14472904467535863, 0.18827718037504793, 0.14600008067707715, 0.18654152199131935, 0.11161280818292418, 0.11200366762783509, 0.13393502172957683, 0.14641399913557107, 0.1432167792015192, 0.11181421186718143, 0.09209417505561412, 0.11938418806199658, 0.11206983601831055, 0.11095636186680169, 0.10912525701701048, 0.9717271359469163, 0.9628507846149675, 0.9377341630520235, 0.9810288407887259, 0.9785915503130439, 0.9770423747813494, 0.9783473338829307, 0.9712621930647505, 0.9787075504592555, 0.7607315187580301, 0.7749069267760285, 0.7630288578874603, 0.7507532481153396, 0.6554370351125884, 0.7762723104136083, 0.7499504173558014, 0.6968283959747328, 0.7389586451693928, 0.1721225825938858, 0.22891630584450517, 0.11324758049764427, 0.3549737812815622, 0.2807957237653095, 0.28145549322917607, 0.18018767969655092, 0.2386988483653335, 0.9395469978455472, 0.2720537562684263, 0.1357109215500677, 0.288515417628357, 0.27358595508171457, 0.28033933355072405, 0.3483295090039492, 0.29980271067857245, 0.13457278726329025, 0.31624018099324525, 0.28347106445129555, 0.27653913969396915, 0.2892909131254505, 0.32904479577095047, 0.30792895015902, 0.3267380918354402, 0.3033156492629593, 0.2088685743639237, 0.2906120113344278, 0.004881953303818798, 0.08432094844164972, 0.01040324864575648, 0.08307057080589308, 0.0631748299553836, 0.031141171943307566, 0.038932547461408507, 0.021942713170019723, 0.09321589178997347, 0.14820762824482314, 0.14111157929981544, 0.09939347465031478, 0.07351212675576657, 0.14911297504852605, 0.02739581001833591, 0.11477783328277313, 0.09375370099990121, 0.12437319484907039, 0.07875046545806708, 0.12463510807347011, 0.14210128121458188, 0.07919284437097684, 0.0801485337679555, 0.13337703281066082, 0.19524821804991244, 0.10442299933492127, 0.07342327849013242, 0.16578167026123625, 0.1853016315404299, 0.1189542819871422, 0.1574945670012905, 0.18360986723287642, 0.2558817728796652, 0.12448657793629136, 0.25405459307747846, 0.1254414517844874, 0.5407077538029146, 0.6006067397749144, 0.5396897498932287, 0.5489927270360135, 0.5891834596503931, 0.5459801886932765, 0.5877025571595188, 0.58912009886935, 0.5796039758319813, 0.07975439706166598, 0.10110173168052605, 0.0755122787624074, 0.16076138881367696, 0.10587421420661025, 0.09908423757627094, 0.11384860622149795, 0.14412899438570692, 0.10610491466439798, 0.22279569248288034, 0.6592237296261918, 0.22467227789135458, 0.27264975790467794, 0.42228702264236595, 0.4427009503531557, 0.5283272114477804, 0.21131508909474783, 0.3463028054853772, 0.5602848907432856, 0.5870043317671049, 0.24980633166770938, 0.37827330003298987, 0.3159543684158136, 0.3948951692827499, 0.5338080159903202, 0.6386237352364159, 0.19094651398173923, 0.2682466646833648, 0.24944249579405708, 0.20048413900667417, 0.3126123000671225, 0.19508244130654495, 0.2440464616149688, 0.2746657038803456, 0.2758095868983087, 0.1718425074209099, 0.24221577925087046, 0.24277264917923613, 0.22753707311652804, 0.21621523555871425, 0.23220195984323055, 0.2121859746984508, 0.22233176434332813, 0.19428032015735874, 0.2940143940691601, 0.18346601962379372, 0.2507595245585167, 0.2074744620231186, 0.2296346173180046, 0.7839070787440949, 0.18887893138201983, 0.19948332275076253, 0.2261375176508097, 0.19661374747919813, 0.9185297033957897, 0.17730516387770456, 0.11326657578340704, 0.17278331750195008, 0.9190619999789291, 0.2007124882642538, 0.0996663158636657, 0.16991723780351253, 0.16271709766976927, 0.8243727383661772, 0.8166819556788825, 0.7311027166633209, 0.9133133255502286, 0.8484364245717022, 0.7770450456081295, 0.10514634504197418, 0.1699183301713061, 0.16636178423956227, 0.19554443874623362, 0.24430239869142467, 0.21100720171394982, 0.1973610633324807, 0.25121027229113, 0.19102423719310313, 0.2563067934359131, 0.23300659057012685, 0.22269509176237645, 0.08892873400730372, 0.07113752042749677, 0.11154483811644855, 0.0966630146129761, 0.0829219834948779, 0.14774202050214513, 0.10337404775080683, 0.10543583486427055, 0.09783716494350791]}, "mutation_prompt": null}
{"id": "499ca78e-300d-4a88-93d8-6b8810246ca0", "solution": "import numpy as np\n\nclass AdaptiveNoisyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.noise_intensity = 0.1  # noise intensity for perturbation\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map and noise influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                noise = self.noise_intensity * np.random.randn(self.dim)\n                mutant = np.clip(mutant + noise, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "AdaptiveNoisyDEPSO", "description": "A novel hybrid optimizer that introduces adaptive noise perturbation in DEPSO for enhanced robustness and convergence in diverse landscapes.", "configspace": "", "generation": 42, "fitness": 0.3327343891929899, "feedback": "The algorithm AdaptiveNoisyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.28.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.8834618629734935, 0.8963377358101093, 0.8924565922722482, 0.8598005694300233, 0.8635768444165893, 0.872365675307054, 0.8742106616111308, 0.8769462037461424, 0.8749412561645922, 0.7429373523022492, 0.7551494842250953, 0.7258594671521819, 0.6453674311135638, 0.7268781100941846, 0.7468662571157656, 0.727279109003176, 0.7099132481497746, 0.7176458712451574, 0.11176407012937906, 0.14362011469144598, 0.09653272335019925, 0.11597286371224402, 0.1151188195847126, 0.11758982136713059, 0.15782764019278095, 0.1418550880994366, 0.11796484313807887, 0.1347931562848086, 0.11261925977917076, 0.14588185681042942, 0.18800946202143853, 0.10092923236189633, 0.11885275798695494, 0.13959044464457238, 0.11136009925012569, 0.10904964209816115, 0.9746697984982465, 0.9479225776426342, 0.9743858715486795, 0.9636800229718244, 0.9749608665459651, 0.9744916335616851, 0.9652377534829142, 0.9702075771229213, 0.9824040624660219, 0.6529912308116077, 0.6275573536242791, 0.6727116110538001, 0.6133252121342707, 0.6204152404084435, 0.6613151132681208, 0.7070266835918803, 0.7030825813706343, 0.7030216766081805, 0.23129264140317773, 0.8247254869207946, 0.9345834323294391, 0.3749607506841445, 0.2141414341587452, 0.21325509714256063, 0.17835022677199053, 0.6854452982688568, 0.23746159723402438, 0.4090190591430318, 0.23390883313000366, 0.23218064697159457, 0.22073410946255367, 0.20949013397717176, 0.17571386950740286, 0.22603994539043148, 0.21944326325636054, 0.2235556478293016, 0.24105999812841905, 0.22699367704057072, 0.2576989803047631, 0.22377594520594024, 0.25592706549592237, 0.1353736833012379, 0.24488687091451744, 0.15602494966052616, 0.26645865769509014, 0.018644129956004285, 9.999999999998899e-05, 0.0358531635534477, 0.029426149535425994, 0.24185376742138953, 0.03886217291074934, 0.1665221714832682, 9.999999999998899e-05, 9.999999999998899e-05, 0.098309919945064, 0.13236931079909153, 0.11236219758007915, 0.06685554747321654, 0.07846375086625812, 0.025169722304967612, 0.05191416629411849, 0.07780058784794253, 0.044420520700557575, 0.29726207038153585, 0.2415680076475324, 0.1270984048786835, 0.31109390093509204, 0.09742359903312703, 0.27077595638513796, 0.2690447716379296, 0.19457588727645814, 0.0748018955183497, 0.15651572385287604, 0.1633290004016128, 0.15619267837484663, 0.14963878109322026, 0.11234034640714596, 0.10672359486135852, 0.18274301690080452, 0.057580270242590825, 0.10248542494160306, 0.5263119309101916, 0.5445147702380766, 0.5684587868316902, 0.5564153391573914, 0.5604770659941156, 0.5635957530529903, 0.5755401544478642, 0.5847858569235408, 0.5513368218253565, 0.07272775116007946, 0.15348746395022206, 0.11472647599455554, 0.11646158654537486, 0.10341844165180714, 0.08826561822157442, 0.125597136658529, 0.1432853091145243, 0.09623423188686775, 0.20371544192660418, 0.215715214849596, 0.21127152732140098, 0.27062356803286214, 0.3549573414131514, 0.36760755886456475, 0.2511116965393796, 0.5288706441025421, 0.3329171645970589, 0.3372225266473584, 0.2320384573434482, 0.1921285656424352, 0.26343375904857624, 0.3396383562429558, 0.5413443093862318, 0.2470384561587632, 0.38180626639997495, 0.22727567837578588, 0.23918933709236345, 0.33283621155777987, 0.21868628253947842, 0.210885150903537, 0.42631666633251053, 0.35571834275006375, 0.27009347411569884, 0.18441033561614284, 0.09714002151594725, 0.21921643758071396, 0.23462563407294457, 0.220658653291395, 0.2517910084536812, 0.19789844786133404, 0.23708246142336586, 0.23275535829275262, 0.24083195124394874, 0.30239170378664637, 0.18004897501509298, 0.22677344386198606, 0.20325105126227372, 0.208806130758867, 0.24833050959937675, 0.22755138342265258, 0.18655478431631356, 0.21132019255341816, 0.21147771387736924, 0.11269905762703725, 0.18736559979502287, 0.17819318672120332, 0.17965175487762863, 0.20075369541446708, 0.8727621132545702, 0.09983152809459461, 0.8925146344383613, 0.1666048771368701, 0.9003933405573966, 0.21222670562841772, 0.7421164057641614, 0.8063184989611596, 0.16937993277697805, 0.7991511083411003, 0.10505575394137234, 0.8825185103255347, 0.10530738907256965, 0.19482087696303085, 0.19309125502647329, 0.21638123153397615, 0.19606144287189609, 0.18684243721196103, 0.18315577424021268, 0.20925519552612837, 0.1991886130201901, 0.19793644200428606, 0.10244240463969312, 0.09546613143608407, 0.08900201000095098, 0.09419404085912575, 0.09642797968860939, 0.10340356991119448, 0.10211362841037863, 0.08133411855088835, 0.09211372538953]}, "mutation_prompt": null}
{"id": "b06b313d-8add-420b-b754-2baf6d6ce61f", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.9, 1.0)  # Adjusted chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.95\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 40.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 40.0)\n\n            # Dynamic topology adaptation\n            topology_prob = np.random.rand()\n            if topology_prob < 0.05:\n                self.global_best = self.particles[np.random.choice(self.population_size)]\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A refined hybrid optimizer incorporating adaptive chaotic maps in DEPSO with dynamic topology adaptation for enhanced exploration and convergence.", "configspace": "", "generation": 43, "fitness": 0.31810692983952343, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.28.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.8932560565853072, 0.9004936902654609, 0.8828601769311663, 0.8596392577785286, 0.8786005793815627, 0.8398132945990486, 0.8738389819071972, 0.8673503051512956, 0.8726553472817444, 0.7514624264775902, 0.7042189861710839, 0.7468024563966205, 0.6977230554891339, 0.7407994405768956, 0.7622461539784098, 0.6995674827426801, 0.7503883630939887, 0.7639715014408153, 0.12241100000296157, 0.11143286210747883, 0.07689998230426331, 0.185450412934708, 0.1572588473959824, 0.13270609525410304, 0.10651312632810694, 0.13274310356579955, 0.14345613090499432, 0.10108426269987336, 0.08669814216133087, 0.07183654614649748, 0.14138813734708078, 0.1106026722963035, 0.13696314959091438, 0.09303969429119152, 0.11641104258819268, 0.09342010736935513, 0.95921392153786, 0.9603679497955175, 0.9740959686529626, 0.97952635424037, 0.9480994891553901, 0.9728091325917431, 0.9792825730183023, 0.9443786086558781, 0.9759418974480016, 0.7320853187319614, 0.7517799280206587, 0.6388377132400405, 0.7388398420325744, 0.15209322142125514, 0.5841232314019406, 0.7424354684186164, 0.08855113908998502, 0.6645369354593564, 0.3881417284331917, 0.22933602728605784, 0.3527155336374631, 0.21492221907346887, 0.21020889247186259, 0.2808499303857943, 0.8521184065458395, 0.22539475436881518, 0.24956350863202492, 0.20947470401588908, 0.2678941041665276, 0.25599082037867793, 0.24393177500147112, 0.2507549236357278, 0.12242839107646464, 0.269293865445299, 0.2610756267775941, 0.2020597547825691, 0.2675783465944692, 0.23109144786035007, 0.24791372837357872, 0.31458331968204256, 0.26659366342491064, 0.28844570363709066, 0.26626922341082115, 0.10474675163943103, 0.22182726775640427, 0.012057101211836008, 0.0001867496825481707, 9.999999999998899e-05, 0.0001033710671702881, 0.004190789393277328, 9.999999999998899e-05, 0.05774190930450751, 0.17964167133387277, 9.999999999998899e-05, 0.0800307145332737, 0.06521661713945637, 0.08407337396846104, 0.0677050655821666, 0.035801856201312376, 0.12360537800403038, 0.11044309107654648, 0.14296506988628077, 0.04633696617504135, 0.09988386938412164, 0.08485946133077449, 0.07971980071911788, 0.07928972330623596, 0.07573048170176211, 0.08216328006143137, 0.23426314645847612, 0.10166164782106657, 0.07004341458441266, 0.13727563937787168, 0.20287098471402998, 0.22159196087473954, 0.3549520319157171, 0.04601133728308526, 0.18059156783738783, 0.1120285676056283, 0.18173305807770523, 0.08805470451110209, 0.5778707348888723, 0.5316808375891457, 0.5375645977677677, 0.5961020431766384, 0.5369310167732719, 0.590779619849573, 0.5431159123266521, 0.567734038693948, 0.5780993022414747, 0.1337482470207647, 0.13876156096412817, 0.05177693610411205, 0.08055917346089414, 0.09426221758428432, 0.13604042495433932, 0.17010525930884923, 0.1890296334702095, 0.12913927009144577, 0.21082833276537216, 0.21923003244420436, 0.20656338254205753, 0.2458597198728063, 0.2158047627617793, 0.27616791694901854, 0.2693313403857174, 0.3190820866979671, 0.1968312112981161, 0.24399953744694125, 0.3696389184996165, 0.2148752657351919, 0.5766727231275257, 0.2404871777708445, 0.490059902919288, 0.6377371224319153, 0.541828985749141, 0.23828703392997885, 0.34742660089630295, 0.3050222150632661, 0.1493421982486297, 0.23548751663002332, 0.19164136784007335, 0.24305215610418274, 0.21490224941654335, 0.23046704947633345, 0.177959222045301, 0.2283696038777111, 0.21565726313262068, 0.21837073078529645, 0.2756079668021384, 0.20808651563611424, 0.2267561544184188, 0.22445589695807633, 0.1833018861225142, 0.22942732632664486, 0.2010191159514677, 0.24494062898097402, 0.18339202499780893, 0.2044279381269043, 0.17733019734813338, 0.18991468094769592, 0.22348741564279717, 0.25024005268386373, 0.20606561731099604, 0.9191219520319176, 0.18822490569577977, 0.1540513275342419, 0.9249102014074161, 0.1998374002915917, 0.9264495084872704, 0.12203796595448346, 0.16999685833524636, 0.1671266317284653, 0.21297968908314713, 0.16949550204760722, 0.8436339665831684, 0.5396699650361466, 0.16868978355646047, 0.8178674102023884, 0.10515390898957067, 0.16857885332063327, 0.20904229278878128, 0.2111977804193107, 0.19737574690613247, 0.18301380610637374, 0.20120640224975672, 0.1870360559722467, 0.19095429650838747, 0.18265045107152833, 0.21186231803934086, 0.18331627464955524, 0.10160176771415386, 0.10111844697391914, 0.11709270550466322, 0.09590063667667925, 0.09146092737791145, 0.16066223796624401, 0.08767932167690284, 0.09603148480613255, 0.08999980521046402]}, "mutation_prompt": null}
{"id": "0179b4fc-eea4-4ea4-acd8-2299c5eebea5", "solution": "import numpy as np\n\nclass AdaptiveChaoticDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return (np.sin(np.pi * x) + 1) / 2  # Updated chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 50.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "AdaptiveChaoticDEPSO", "description": "An adaptive DEPSO algorithm using chaotic maps and dynamic parameter tuning for enhanced convergence.", "configspace": "", "generation": 44, "fitness": 0.33067530458368327, "feedback": "The algorithm AdaptiveChaoticDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.28.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.8927172735327054, 0.8890640168646139, 0.8952467627712944, 0.8926110171882561, 0.9016538097317108, 0.9036313688890186, 0.9030704032417562, 0.8991681764967032, 0.8830668461132423, 0.7878342103467633, 0.7540729981503008, 0.7883188748178803, 0.80337792681455, 0.048738767039334774, 0.771353339494533, 0.7640856567795797, 0.7623885561137469, 0.7725469542298198, 0.15593424398916067, 0.15683412976501154, 0.08251836554140135, 0.10855064336992659, 0.18836901810734785, 0.11676880844334059, 0.11888556574717768, 0.12471910277022413, 0.10858462910080657, 0.12753153622251956, 0.05344685031278584, 0.1163699879441743, 0.09237753647171465, 0.14499705281945063, 0.09588379415502679, 0.116542902269409, 0.0953979088802247, 0.0797738196480755, 0.9749623744259621, 0.9632214683568301, 0.9669168508207251, 0.957288621464812, 0.9726389531249153, 0.974656543437042, 0.9781636731124542, 0.9639695954594132, 0.967792381515727, 0.7382940087364591, 0.7376390703460114, 0.7518920792041943, 0.7513720071950555, 0.7722367109418329, 0.7499580944177426, 0.7606584176682255, 0.7108126435521268, 0.7646944649442173, 0.24173375306413492, 0.3895960185303303, 0.14063153810704643, 0.2844170470763041, 0.2812305202389702, 0.37023209913054056, 0.24428697559115298, 0.2354591371090442, 0.2385599476141156, 0.2834431428635671, 0.26464554172476984, 0.267545059998737, 0.2835805715746925, 0.26871461607267755, 0.48577964533428275, 0.27696224621204635, 0.2754522141542115, 0.2921457370486883, 0.2769338474957237, 0.13433737128895284, 0.19753102840868153, 0.33300272355294924, 0.13530308565622418, 0.12952573844747606, 0.3471932368110924, 0.27540911475294994, 0.3058038911399844, 0.08829490984413768, 0.060826379759391425, 9.999999999998899e-05, 0.0022242206916309737, 0.003939783454640189, 0.0293817932367314, 0.012455656007597682, 9.999999999998899e-05, 0.05485987347620136, 0.12382548784145742, 0.06323605832647428, 0.08948648052299357, 0.10124944986199391, 0.014779329395178675, 0.05639223025947304, 0.10184807183648503, 0.1050333854791472, 0.07313439296126256, 0.22493772015925573, 0.0715516709935613, 0.11181845884515496, 0.08065179190903604, 0.08133552342455042, 0.36274022636403336, 0.09799499214791851, 0.10174788470934559, 0.07496175584257436, 0.16745537376596098, 0.15522773190003114, 0.1798268676842577, 0.0817792714943858, 0.11037532973424169, 0.026472845573143222, 0.132186958751925, 0.17431333103993307, 0.0876613117653231, 0.560154209864073, 0.5362966937458629, 0.5679684608111122, 0.6108269372778568, 0.5667082948493984, 0.6119342476116695, 0.6000645447714312, 0.6006153160695918, 0.6542475574243927, 0.10320069439937085, 0.11083777098994518, 0.1306364496951108, 0.09331857350472561, 0.11718325869116797, 0.11433633232256002, 0.14898630198895102, 0.18133439982884259, 0.1842727667244154, 0.2662143203184498, 0.41967991407484606, 0.2739419934183067, 0.23663827981218366, 0.3222569400359251, 0.20213768418586198, 0.20321457083227734, 0.23448751670307288, 0.3288810393879851, 0.35123798228167935, 0.4047475798604576, 0.2580051639157158, 0.43480026831373153, 0.2558931354571423, 0.46831110507390805, 0.5311266967941959, 0.5035207869585943, 0.2540627949873099, 0.2831791526722316, 0.24366981099540763, 0.2910933937593734, 0.3390189392624319, 0.22544316285920218, 0.33615352113670194, 0.23962717944850187, 0.2594223726951186, 0.2823141171697433, 0.22911982277588328, 0.2216195499290109, 0.23734654337947791, 0.26722641296185645, 0.24654087544893832, 0.21475314604206086, 0.2228574038283626, 0.2773035639884821, 0.25219594745300133, 0.19784979243517842, 0.22451760504396667, 0.19343270493641662, 0.2534830571268276, 0.22643395764475682, 0.19096926643017753, 0.20904287932482313, 0.22613568535929318, 0.20829274838014789, 0.12565841361079877, 0.9334044173318734, 0.18823016483254096, 0.17320767542198723, 0.2015103980096571, 0.9288347870601926, 0.12267235324514802, 0.17050938312438702, 0.15399735275818072, 0.8374443249708359, 0.7335695351569367, 0.15609251254320677, 0.21219563792555152, 0.16935132160883937, 0.8899816232393247, 0.1052478978814434, 0.16913064459672533, 0.8240293373980571, 0.2103717695787165, 0.1825019764553686, 0.2578488087595814, 0.19367493694337112, 0.23429203285497335, 0.20999837419018963, 0.19682152235480732, 0.2281791425256774, 0.2269859074486802, 0.08327845219190932, 0.09902667567537993, 0.09393261884539117, 0.10841729259585442, 0.11174274466168932, 0.10759442008244846, 0.11328015980165096, 0.11335988046965162, 0.10110488749895796]}, "mutation_prompt": null}
{"id": "b5f53569-e7d4-4883-b71f-0cd5ed7ee5f6", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO_SR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def stochastic_resonance(self, x):\n        noise_intensity = 0.1\n        return x + noise_intensity * np.random.normal(size=x.shape)\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                self.particles[i] = self.stochastic_resonance(self.particles[i])\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO_SR", "description": "An adaptive hybrid optimizer utilizing stochastic resonance and chaotic perturbations in DEPSO for enhanced performance and convergence.", "configspace": "", "generation": 45, "fitness": 0.22188567780661045, "feedback": "The algorithm EnhancedHybridDEPSO_SR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.20.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.3844770305174766, 0.40118592792337826, 0.4277290205511758, 0.4110179175759715, 0.4361825324695595, 0.4141996048495703, 0.42524580263515754, 0.42477432788710057, 0.40698977266960457, 0.013927378490700137, 0.04737863712686252, 9.999999999998899e-05, 0.04530534020963517, 0.023894260461403083, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12036372893019742, 0.13622027807637482, 0.07696914048677772, 0.11147375022641426, 0.11921472085410312, 0.10876044095766357, 0.10940754408756015, 0.09691350393357767, 0.14149594179383163, 0.09654569716195038, 0.10521197623019074, 0.10182914623027717, 0.10582769171649398, 0.09068073475519811, 0.1016063607779435, 0.08886719431441648, 0.0989931864973852, 0.10795841894502467, 0.9760956071595797, 0.9444472346179597, 0.9699518751046847, 0.9600964524691475, 0.9699455976188003, 0.9712166864022757, 0.9505700533973723, 0.9606328617381009, 0.9833208641559722, 0.2699038891672363, 0.2902922334351081, 0.28513788345718305, 0.3236543387622688, 0.2835072718642395, 0.2920148462218144, 0.2752992613680699, 0.26119640599639715, 0.2685248380531239, 0.35005984260232903, 0.2220063280391562, 0.2184920063035758, 0.3022480052445744, 0.22023153207914248, 0.2802120547109128, 0.29848676661634277, 0.22648385495026857, 0.3302039147714988, 0.18225269066576755, 0.11951348848316934, 0.15712593485043258, 0.1482307053589189, 0.16097250310494815, 0.13724076431310572, 0.14871002460216354, 0.15875144637268312, 0.18894695264620454, 0.1303150162189579, 0.182453147684423, 0.15487990651942096, 0.174537257815096, 0.12337326267155235, 0.1193292988396295, 0.2014621559514751, 0.17469695055672396, 0.16005303281592265, 0.036446872731999425, 0.04246197641533367, 9.999999999998899e-05, 0.006754743576808719, 0.01158297114142004, 0.013556454579170318, 0.014144299236824143, 0.027183890797728982, 0.018985977821014632, 0.1479140684940914, 0.04444931120065554, 0.09389500953953323, 0.08604230713878769, 0.0649805197620471, 0.04834315109593135, 0.16534532619082398, 0.12542836356667664, 0.0944073117084463, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10213624479559347, 0.0872566196864375, 0.11492280575040081, 0.09457919668619574, 0.0674795706045419, 0.11630006153843131, 0.1016241940257896, 0.09607210933832722, 0.10707102008519975, 0.38965935057206247, 0.41962383207944876, 0.4121959235288165, 0.3971795830327264, 0.37027598059060096, 0.3908241112137123, 0.385165985662271, 0.3920984126375069, 0.39601790695340033, 0.1060456217028557, 0.1093765322840462, 0.09220172417520223, 0.13187198760535646, 0.11079829817250852, 0.1371227490917114, 0.1403968787415426, 0.14362742759319624, 0.1316217711887142, 0.23835855046116672, 0.20330043399448172, 0.18698528078822962, 0.21261934931784776, 0.2548817371265558, 0.21222788895211242, 0.27201966834255187, 0.229216832505731, 0.23892584448050702, 0.2755941797908471, 0.2917147431406738, 0.28059410454878275, 0.27654337691543673, 0.28801854400628424, 0.28582756508355855, 0.29803221358077514, 0.2898344537813836, 0.28616953458832795, 0.21255277490302638, 0.2200330221557968, 0.22704632366342103, 0.20954822272769624, 0.18069977955164052, 0.212152307801465, 0.18196118622340496, 0.22365982771538861, 0.1936103488580655, 0.21579056362946725, 0.23580155794184565, 0.20815128079690948, 0.228801939963303, 0.22610149843000005, 0.2041217867440266, 0.22216356372344237, 0.23045629440639714, 0.23364638441610586, 0.19588482331244106, 0.20990810230050927, 0.1908021722277523, 0.20230634263642877, 0.1921281564595264, 0.19320331291934034, 0.20558318323997293, 0.19715432657091392, 0.1973464910196433, 0.5924875697026497, 0.18519009963356692, 0.15411033152265374, 0.6539692963251453, 0.6188433075679778, 0.6006431344603715, 0.09986015975798623, 0.1698469188883397, 0.16812543834731275, 0.5747299667835041, 0.21237199802217266, 0.5334089965462674, 0.21139201214629932, 0.5362037238090878, 0.5035166980647597, 0.10487923414178735, 0.16945182681218718, 0.16656065388591323, 0.17998555123740845, 0.17552371370958952, 0.18330146360078048, 0.18263697212210395, 0.19405701854438173, 0.1855449918658011, 0.1876709891777737, 0.18427218078066654, 0.19779406772618835, 0.09953323577289463, 0.0907161305590467, 0.07889267949589107, 0.11137908603870639, 0.0995652464701774, 0.10411864633837342, 0.09132928156794529, 0.0846958237295019, 0.09452557587486354]}, "mutation_prompt": null}
{"id": "a4a95bf0-01d7-4442-b10b-4d32c402ec9f", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSORefined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x * (3.57 - x), 1.0)  # Logistic map for better chaotic behavior\n\n    def adaptive_mutation_control(self, current_eval, total_eval):\n        return 0.8 + 0.2 * (1 - current_eval / total_eval)  # Adaptive control based on evaluations\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            f_current = self.adaptive_mutation_control(evaluations, self.budget)\n\n            # Apply DE operator with adaptive mutation influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * f_current * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSORefined", "description": "An improved hybrid optimizer integrating adaptive mutation control in DEPSO with enhanced chaotic influence for better exploration and convergence.", "configspace": "", "generation": 46, "fitness": 0.31557612760655657, "feedback": "The algorithm EnhancedHybridDEPSORefined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.28.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.9050954891944307, 0.9009233161169109, 0.8901857780019933, 0.8900613734896393, 0.8976237816810781, 0.9036147702282137, 0.8919275251807105, 0.1830387309057976, 0.9039185769951205, 0.7803720867996149, 0.7836550106557365, 0.774600457494791, 0.7522770256691412, 0.7543830003986439, 0.7522943146507354, 0.7326887678582978, 0.7955417824295956, 0.7810060657928656, 0.13572118556337787, 0.12647709277246832, 0.1333897741427752, 0.12094294902506386, 0.09769128373280112, 0.1309005776224671, 0.12272967488270592, 0.08656483478227162, 0.11085749263154032, 0.09679479272969771, 0.0709027083529078, 0.08608909978556545, 0.0956086999536867, 0.09522316639024941, 0.09049123449815943, 0.11738658710767791, 0.07003944426505171, 0.08835930959898253, 0.9744714019926959, 0.9558857182378072, 0.9706487283187812, 0.9663116447092588, 0.9597710495037, 0.9715177058407638, 0.9744864629710499, 0.9634274200647931, 0.9626389955286256, 0.7606462576870858, 0.7187880697747617, 0.7299630740944993, 0.6918776355742764, 0.7127096904326489, 0.15404244148113466, 0.6277323526997611, 0.7733856749622643, 0.7414113359109882, 0.22925274404085327, 0.1718331072939221, 0.11266711815186081, 0.2135726041728251, 0.2128123706425381, 0.19618494809134368, 0.17901116645697568, 0.7886131925840113, 0.17945250449084016, 0.2591504482328906, 0.1365376231895543, 0.29733760814651555, 0.2854723281947711, 0.288616134892432, 0.2143953717651932, 0.3265810213000495, 0.27386674071712913, 0.28422800748921284, 0.26203592080718896, 0.13317039489965687, 0.2707737958562665, 0.28464992143290446, 0.1361147132028513, 0.2772981622671198, 0.29738155329090454, 0.3098316580414011, 0.3080662674216289, 0.1836886727326641, 0.00010819781514270765, 9.999999999998899e-05, 0.05680959372355032, 0.0473883369981577, 0.07640460671523563, 0.007078954437225948, 0.018412576949768167, 0.007101888685782987, 0.11994257620489135, 0.051855167047583195, 0.08108389431180507, 0.0767865368948134, 0.01574364172568643, 0.039167400952672904, 0.10141521971772127, 0.15105052159045607, 0.07779643644168632, 0.14430108050238466, 0.19322759685447877, 0.29519369035418863, 0.08175228090895492, 0.07909195656508416, 0.10573656602971182, 0.17862261094790033, 0.22979304054988392, 0.07183576456973839, 0.12903744616509316, 0.12230224528279798, 0.18916991829359064, 0.12755030899875341, 0.02937624137113981, 0.1256846244339347, 0.08478999012731692, 9.999999999998899e-05, 0.08599410095845683, 0.6292942865386834, 0.5446134565372636, 0.5836770826342482, 0.5655275085537734, 0.5508856555864075, 0.592068888735993, 0.6068889278636209, 0.5751094642771503, 0.6055134464726821, 0.06244062556292451, 0.09495983923047024, 0.10476270858247683, 0.08586877885915967, 0.13066447971961292, 0.11768891846710627, 0.09722232219650073, 0.13308577450361114, 0.07979147865672187, 0.16367498786520263, 0.29445559429699886, 0.4319327361421158, 0.5112364531754279, 0.4283146862257199, 0.2582540915664858, 0.2205654080808367, 0.4161203164132937, 0.231658078799431, 0.3521955689643317, 0.6388043797544899, 0.2579731838136634, 0.30254179540474346, 0.2501611013454379, 0.26517822332869034, 0.23481259273803234, 0.56530907538532, 0.15867825803214441, 0.2254178183544301, 0.20808140142533116, 0.24315338367304962, 0.19062004208040895, 0.24494467643070605, 0.26533666826340474, 0.10974225902344625, 0.17928709426230927, 0.0968778288339418, 0.4830993514929923, 0.21280008212909451, 0.2537708939512263, 0.23669102590502844, 0.2004799027493548, 0.198661182483318, 0.2548385970270618, 0.24684851715293632, 0.2198283073813162, 0.2217588498723485, 0.18545689643924002, 0.2121644058180434, 0.18272718104873686, 0.22122702664472527, 0.20849499858578713, 0.22529001900240642, 0.1910502807841883, 0.18814672346130634, 0.18825523358722973, 0.127172662009309, 0.154500826735272, 0.1735662356973937, 0.2019981328039907, 0.9394176960993427, 0.1323079184223177, 0.17035300859244684, 0.15394973889215813, 0.7707691010903777, 0.8273775805847315, 0.7801900647507207, 0.2116621181596161, 0.1564191247336898, 0.2122453140291346, 0.1052612806561759, 0.10484170529666137, 0.809493448578791, 0.19310572368816514, 0.18557821521066808, 0.22912709630744732, 0.25286206663593025, 0.2190718978421401, 0.1897535262980813, 0.19427914744317276, 0.22369010458202965, 0.23230182161149515, 0.09639716811706345, 0.1040416637357564, 0.09489715841778235, 0.10198295843746674, 0.10199264530492114, 0.12862426542880112, 0.06903675634785666, 0.1025666328905005, 0.10313340131391746]}, "mutation_prompt": null}
{"id": "05356b94-fd7f-42c8-baef-7621eaacf21f", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.6  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n        self.stochastic_perturbation_prob = 0.1  # Probability for stochastic perturbation\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def stochastic_perturbation(self, particle):\n        perturbation = np.random.uniform(-0.1, 0.1, self.dim)\n        return np.clip(particle + perturbation, self.lb, self.ub)\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Stochastic perturbation for exploration\n            for i in range(self.population_size):\n                if np.random.rand() < self.stochastic_perturbation_prob:\n                    self.particles[i] = self.stochastic_perturbation(self.particles[i])\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A refined hybrid optimizer incorporating adaptive chaotic maps in DEPSO with stochastic perturbation for improved exploration and convergence.", "configspace": "", "generation": 47, "fitness": 0.27617307432705174, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.23.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.6534209798173938, 0.6425419983045173, 0.6366901571971204, 0.6654851849335683, 0.6766876808518583, 0.7901404565392349, 0.6318722080101311, 0.6620147676475272, 0.6135502632585794, 0.16979972817986477, 0.118186478166734, 0.05530833907413513, 0.20048038143034763, 0.1987430722407948, 0.21354795838172635, 0.2801054654607331, 0.12775876421719345, 0.11952181613164048, 0.17232588404386384, 0.13207557191332708, 0.1778647473735867, 0.1527480770642462, 0.14344331859162163, 0.12548057175187477, 0.12474340805545103, 0.08963994428258815, 0.1588669831893128, 0.1589363579558698, 0.11986280060877708, 0.1015836634191013, 0.12811815440449859, 0.13978976911233598, 0.11426819690526313, 0.15224218119974697, 0.12035530082821477, 0.11042424466555767, 0.9835097672810728, 0.9549089078058564, 0.9695297750468675, 0.9705429894152007, 0.9673682154764013, 0.9699790472491389, 0.9810730931688448, 0.9704318589575903, 0.9729446788505228, 0.4756553986162363, 0.42903359838340094, 0.4121042958573107, 0.43930223554537695, 0.3896493997477284, 0.4374182185687516, 0.46346702543957685, 0.38063070677029875, 0.4205155448946488, 0.7559730536432372, 0.3812165634795872, 0.2233270680615448, 0.27947368661519445, 0.21412101930743643, 0.2160163038840729, 0.6559882124264653, 0.23763103167213973, 0.726944606766639, 0.2822584217168501, 0.1756139842054114, 0.2178743097817918, 0.19602171086532527, 0.2300405611833457, 0.1647514009448534, 0.22932206066605965, 0.12789265894624313, 0.196338864233233, 0.21636774768430067, 0.23781987557504436, 0.12721404985039442, 0.22452017384219114, 0.22377714161476525, 0.13253503453289073, 0.22431288058560916, 0.18441787861302184, 0.13045189416390768, 0.03173350814791975, 0.12033988043321808, 0.002932079530882037, 0.004052757099923143, 0.06290976863024478, 0.002643798975950684, 0.009020295596992911, 0.013511930544989448, 0.10653977564707529, 0.08415164453891089, 0.06759972408951764, 0.11823955861580704, 0.03501235224102761, 0.1411727331276188, 0.026413544176542403, 0.145871082099311, 0.09871801732751206, 0.13909828744688768, 0.20148425382612745, 0.08571625595734311, 0.08261646948208512, 0.05459957873384269, 0.0744330809677225, 0.0869074483917428, 0.10082191626797232, 0.057992057743238234, 0.05016469906377641, 0.09423216222072117, 0.16013530005866128, 0.16612264567087276, 0.07378748407844993, 0.17548439472813238, 0.06514674587747582, 0.17609454474239306, 0.05706915770873677, 0.08230687120268199, 0.4994160551737631, 0.5111481416839367, 0.5349262507775288, 0.4631072884402553, 0.5075031377319166, 0.47037237048095215, 0.5016979212364414, 0.5246574193075975, 0.5030713564793557, 0.10841119937351829, 0.12075307927820145, 0.10922822459315851, 0.13345655805359424, 0.1476513770334965, 0.14242490891676185, 0.10902963075912864, 0.1504677557916715, 0.11597369913342115, 0.19812807358329232, 0.20610497482250556, 0.39463954585331196, 0.4095055422358853, 0.25493930466496917, 0.31629712198947413, 0.20051624316009364, 0.20262142792715077, 0.15289778828279554, 0.3643892987475362, 0.3324341324285077, 0.3380844828181595, 0.3821762212690365, 0.36247049259205855, 0.34348122925231217, 0.37550813387746074, 0.39773951527985774, 0.24245524081254666, 0.13407762021136282, 0.26667172388013893, 0.28016087546226043, 0.29800995565763866, 0.21696780572358787, 0.1996695396858369, 0.21419698098545092, 0.2776614944430228, 0.2182987364921578, 0.25513594856768274, 0.23751997673542946, 0.22964607673827742, 0.2549494375253386, 0.2579731867068549, 0.21356108055150302, 0.239623298259255, 0.1953332876373447, 0.23741933449186536, 0.20069507001375697, 0.21020992232499225, 0.22367585243563093, 0.175440484503261, 0.20184769966572924, 0.20293909154444634, 0.19868414219178698, 0.2278976867883693, 0.24502166032708506, 0.906823276430591, 0.1777042252221529, 0.17708967437297218, 0.17346088381563063, 0.8654255207702208, 0.20064812359113637, 0.8718509540252501, 0.17005117713587548, 0.1540990455808553, 0.8386057540930968, 0.21285154622972557, 0.6359473007793166, 0.21072355421586542, 0.16845004961258125, 0.713766393774923, 0.16777182980300986, 0.16958375153667016, 0.16792716509702899, 0.19585469838461744, 0.2088327184881289, 0.20447056994685398, 0.20011232783967214, 0.21224525061215105, 0.18938325156232771, 0.20479537869147557, 0.20045592812583057, 0.20130411739770138, 0.08411460082174727, 0.07632328925902931, 0.08379543278832968, 0.09437326975209892, 0.11840313392349233, 0.13552872447899567, 0.08858360320309089, 0.08275801093429258, 0.11430877681769303]}, "mutation_prompt": null}
{"id": "17f9eeee-0246-4a77-a337-d6095675c2b2", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n        self.migration_chance = 0.05  # Probability of triggering migration\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def migrate(self):\n        # Randomly move some particles to a new position\n        for i in range(self.population_size):\n            if np.random.rand() < self.migration_chance:\n                self.particles[i] = np.random.uniform(self.lb, self.ub, self.dim)\n                self.velocities[i] = np.random.uniform(-self.vel_max, self.vel_max, self.dim)\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n            # Trigger migration with certain probability\n            if np.random.rand() < self.migration_chance:\n                self.migrate()\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A refined hybrid optimizer incorporating adaptive chaotic maps in DEPSO with diversity-adaptive parameters and random migration for enhanced exploration and convergence.", "configspace": "", "generation": 48, "fitness": 0.3454243878448039, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.29.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.9109431392968543, 0.8794458547361161, 0.8865300578419311, 0.8964748195273611, 0.8819491034849889, 0.9121291399387852, 0.912067620552523, 0.9006094156038645, 0.8994146458401754, 0.8075812755069339, 0.7843534200665487, 0.782034104354244, 0.7644793880406762, 0.7522266880744224, 0.7921910392869682, 0.8002485114172331, 0.7705418932819142, 0.7786850358024592, 0.12239808955712905, 0.18355212577745916, 0.06811794908028457, 0.13257560043016603, 0.6354477409772851, 0.17871175664018957, 0.15358977757938896, 0.13660500271566633, 0.12697455000753666, 0.15880326892688756, 0.09609957257476232, 0.11383285717443237, 0.12276032352682009, 0.1429884395245845, 0.11631523139196909, 0.10893414343851804, 0.14170209868811523, 0.116405985562133, 0.9750542043144468, 0.9621800113890011, 0.968522307595069, 0.9827595839929223, 0.9543298487439723, 0.96060058490463, 0.9785942470496783, 0.9696838829601064, 0.974731002699449, 0.7638921589548142, 0.7344376539687751, 0.7878092390328061, 0.7706171530574328, 0.727957472185534, 0.7511890563148227, 0.7361047125790197, 0.7443315059613103, 0.7539203233499705, 0.3888309293258354, 0.4363996386649073, 0.22498488760090984, 0.19432988609586832, 0.7972996135293013, 0.9018076171294495, 0.23731378485690025, 0.2934963164429387, 0.39679409589827497, 0.3859931808188779, 0.1361240265201371, 0.13523615908204212, 0.3155871996571149, 0.2666928176658093, 0.251588056287423, 0.13349766170188881, 0.25054867374614653, 0.26194354576346013, 0.2809068848960733, 0.23954729509193984, 0.13306138794240485, 0.33718132173014737, 0.2701961419738411, 0.3310307664921086, 0.29080728409038015, 0.25064031929076513, 0.1208127363700745, 9.999999999998899e-05, 9.999999999998899e-05, 0.04799802305046319, 0.14231603660797032, 0.09077855078734898, 0.051006760310456256, 0.04420794147888918, 0.011580969465222912, 0.06110671263788203, 0.1994787085603229, 0.05964143101975716, 0.09679224551477694, 0.09138204798072713, 0.11514006480230432, 0.02544371506574028, 0.1381153253355376, 0.10585557154198888, 0.0987845526286435, 0.016013505322784116, 0.11070234513639132, 0.055611929325687925, 0.07722464485482539, 0.07758438466611772, 0.1083956573146424, 0.11674468615248279, 0.11063294900968246, 0.07556186454516023, 0.15553789187050948, 0.07110764253575819, 0.1450478763341031, 0.12360682326364625, 0.15326019209757813, 0.01928590410410924, 0.08512898455576157, 0.22708090511820156, 0.0854113125599153, 0.5366720751910047, 0.577180670944391, 0.5928134363805544, 0.6003925761591091, 0.623396668760827, 0.5887769263433502, 0.5832530202229906, 0.601509596463986, 0.5988346752043134, 0.1166319247685591, 0.100754442988785, 0.08746300035302179, 0.1311879001526155, 0.11078637567481675, 0.09422972275930552, 0.11030069573309342, 0.1421908069718425, 0.1011158601225901, 0.21777091714322683, 0.26420355385492356, 0.2070004701608581, 0.27852187023606334, 0.27361310940752936, 0.2160028617399976, 0.35888651688283546, 0.34203448757919763, 0.30527162640090655, 0.4266460722920705, 0.4025281921968963, 0.27589250076252014, 0.5736407101555546, 0.3352375089598164, 0.37133003544582943, 0.4366062865647312, 0.5024812917697977, 0.5040767684560119, 0.2840143078967843, 0.21790763286746206, 0.21582442348810338, 0.34510669228868296, 0.21769262118260535, 0.23287757042011947, 0.23884801988181792, 0.2728961368766304, 0.45035269394842403, 0.24391301398505172, 0.234750691157104, 0.2281197873606744, 0.22111519497676746, 0.2998000163069672, 0.21919539064128757, 0.21939708398129842, 0.21624986848532313, 0.2645181297280055, 0.22298202532302314, 0.22421684192284186, 0.2527074119756261, 0.21210343537263787, 0.816632311674651, 0.2132318946398689, 0.19032834987332692, 0.19750515423904524, 0.18934537761901016, 0.9257167103451222, 0.17788051620231926, 0.15439098102547866, 0.17280373588869935, 0.916654374933648, 0.20153407224178388, 0.09982975029543484, 0.16996494265484197, 0.16225326423652497, 0.8480368390403484, 0.7861888160442569, 0.7711455630104438, 0.21257470420149183, 0.2122938114581696, 0.7801313370565538, 0.10520175378275165, 0.16989918337759502, 0.16724748336616047, 0.23722037183495026, 0.25255813599917787, 0.18707934254740477, 0.19222281707240962, 0.23501725402583806, 0.20339612236590987, 0.19778018819787224, 0.2304686059492138, 0.23217427280165304, 0.11021227899475616, 0.08996459355929398, 0.0905106798272931, 0.09617695578665642, 0.0922739851854043, 0.1722927023072387, 0.10464977271705211, 0.09707388008329532, 0.10512574324203072]}, "mutation_prompt": null}
{"id": "8fbcfa83-47a3-4478-a548-7d98b4996a06", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.9  # DE scaling factor adjusted for better exploration\n        self.cr = 0.85  # DE crossover probability slightly reduced\n        self.w = 0.6  # inertia weight for PSO increased for stability\n        self.c1 = 1.7  # cognitive coefficient for PSO slightly increased\n        self.c2 = 1.3  # social coefficient for PSO slightly decreased\n        self.vel_max = 0.8  # maximum velocity for PSO slightly lowered\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x * 3.57, 1.0)  # Adjusted chaotic map for better diversity\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.95  # More moderate reduction in inertia\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.7 + 0.3 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.3 + 0.3 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A refined hybrid optimizer enhancing DEPSO with adaptive mutations and chaotic maps for exploration and convergence.", "configspace": "", "generation": 49, "fitness": 0.3190431071114364, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.28.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.8832805526096449, 0.8888321104565189, 0.8817082667030469, 0.8828484259118207, 0.8517627832365953, 0.8879042697483658, 0.8664199225159395, 0.18293212163942318, 0.8439045227136515, 0.761364375748314, 0.7189624562199792, 0.701583625015053, 0.7307831970283325, 0.6552179502459259, 0.7376517525002021, 0.7618017220531806, 0.7400271726059126, 0.7464794566909352, 0.06973531724963666, 0.10214098016576734, 0.08903805231963102, 0.13145576961875372, 0.12185710477982847, 0.15231250321694856, 0.11453290157724882, 0.12136981106384714, 0.11552641426071786, 0.11548956254801501, 0.06871709297047912, 0.08823509627137205, 0.11770565824207568, 0.1112359026827966, 0.0681122487595911, 0.14462242178856433, 0.07332209153489244, 0.08568480411698942, 0.9643807766032017, 0.9492577591760089, 0.9706749046810172, 0.9636465459894914, 0.9590410952361443, 0.963936670589657, 0.963467785273392, 0.9569972074836345, 0.9562951498362623, 0.7107177998308378, 0.7096861539057985, 0.7086184823698518, 0.6868741572849661, 0.6987343508568878, 0.15414080098368355, 0.12868353157758305, 0.5933039960774469, 0.7356990119268532, 0.16701686984381026, 0.23114606073538457, 0.16574641887489738, 0.3866815644251085, 0.38146135866673225, 0.18876316051688435, 0.17668421351313612, 0.23799085260504393, 0.3763697978672097, 0.23418894583691563, 0.13533606604307502, 0.26383528003998324, 0.2713235737334371, 0.13507054751099745, 0.3230166158512281, 0.2922725331627687, 0.28199152420513907, 0.30420964285919305, 0.2655387087342137, 0.13255502895970406, 0.36484169395043575, 0.24055375977944582, 0.13322631288597953, 0.2770236747126884, 0.29153029807562614, 0.06771635384836394, 0.3094250502811856, 0.062393542166910954, 9.999999999998899e-05, 0.09693346618251086, 0.0062093792282137406, 9.999999999998899e-05, 0.010376687056436462, 0.0034965730255522853, 0.007273003346987439, 0.004858384460969534, 0.11071632062017667, 0.10147865922101207, 0.06656174228085987, 0.08321382054254922, 0.03437701688949424, 0.028606128425249122, 0.2544393644024415, 0.1017952962737716, 0.07979927532105013, 0.04997562666029298, 0.10047779755591923, 0.15886960875113998, 0.09506600378068453, 0.464008478190053, 0.1055082732980831, 0.23314931488762536, 0.19908745965041685, 0.07029459258285387, 0.14947642165508768, 0.18584360386844645, 0.26407836880846136, 0.11696144828651556, 0.08465475064015848, 0.20044278592872478, 0.12307022152241265, 0.049966989515448756, 0.08559760580822862, 0.5803161907990575, 0.6419638328360819, 0.5687773562708649, 0.61560146408117, 0.5401089700395654, 0.5847539577352898, 0.597031786232905, 0.5878804670933002, 0.5630080610576909, 0.1031839676365982, 0.11067495092700919, 0.09590050296767172, 0.14457919249549978, 0.06848742885251136, 0.08613405829812948, 0.13351479596279092, 0.09679845119135955, 0.08026275123266347, 0.17394213809984138, 0.6036301116850242, 0.5551319666106003, 0.4196820205923174, 0.4964188724470723, 0.25442929694170435, 0.20591725739296185, 0.20134091331620307, 0.4356734566493832, 0.28746234802688964, 0.521853185840933, 0.3013153291033914, 0.19798558879336747, 0.22125664059961014, 0.25955096368896213, 0.2620313095597071, 0.5599810137619083, 0.15732740152210523, 0.2743904309831664, 0.3035177256741435, 0.27696246214028175, 0.1660319089754576, 0.1622340827825125, 0.12394525685553248, 0.16478019775349895, 0.20173343013602152, 0.20498891293618604, 0.2199079303191651, 0.21195923808172812, 0.2513757256474882, 0.21393824403663075, 0.1811908087992553, 0.19859135577049902, 0.2331861769008109, 0.30292811675444886, 0.23985976226699302, 0.21000615911951515, 0.22497537496818654, 0.1879638626668919, 0.22891750980152004, 0.21147081058372486, 0.190799197689956, 0.19972848705568413, 0.19502617888132956, 0.2241221511887005, 0.9344711659009015, 0.12708233869916985, 0.18910564427554966, 0.1731848918283636, 0.2015364895751618, 0.9366101461016918, 0.1319041818890584, 0.1702941946312816, 0.16816937899440132, 0.8213878222104264, 0.7556032091634016, 0.7709872313883032, 0.8054609456615198, 0.1538233955617494, 0.21196337769849882, 0.8674236416230109, 0.15631781887873808, 0.7814831693410687, 0.20639172676455186, 0.1954538313581451, 0.1962644105236524, 0.18968467465244165, 0.18694213985787578, 0.1890463120451087, 0.18020429884139466, 0.19397370263276947, 0.18582073519155173, 0.09712030458465959, 0.11759924803572541, 0.08192109397257319, 0.11237481798895299, 0.0994333607116128, 0.11487174248524246, 0.09120105844940973, 0.08141168792260378, 0.1048589326721805]}, "mutation_prompt": null}
{"id": "b9da675f-f63b-4511-a1a1-740f1f003d22", "solution": "import numpy as np\n\nclass EnhancedStochasticResonanceDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor, unchanged\n        self.cr = 0.9  # DE crossover probability, unchanged\n        self.w = 0.5  # inertia weight for PSO, unchanged\n        self.c1 = 1.5  # cognitive coefficient for PSO, unchanged\n        self.c2 = 1.5  # social coefficient for PSO, unchanged\n        self.vel_max = 1.0  # maximum velocity for PSO, unchanged\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5  # unchanged\n        self.diversity_probability = 0.05  # unchanged\n        self.iteration = 0\n\n    def stochastic_resonance_factor(self, x):\n        return 0.5 * np.sin(5 * x) + 0.5  # Introduce stochastic resonance\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with stochastic resonance influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                resonance_factor = self.stochastic_resonance_factor(self.iteration / 100.0)\n                mutant = self.particles[a] + resonance_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)  # unchanged\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)  # unchanged\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedStochasticResonanceDEPSO", "description": "A novel hybrid optimizer that adapts exploration and exploitation dynamics by integrating stochastic resonance into DEPSO.", "configspace": "", "generation": 50, "fitness": 0.3415056832445213, "feedback": "The algorithm EnhancedStochasticResonanceDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.8910467875833675, 0.9064294769198445, 0.9111308314902679, 0.8837002159209121, 0.8946732872142766, 0.8766081391669599, 0.881095322670219, 0.890473994852331, 0.8928653861246886, 0.7575012590518083, 0.7589758377526088, 0.759937363735791, 0.754358132843309, 0.7524591083547714, 0.7520794685711569, 0.7625205681137829, 0.7519509146237153, 0.7719647300439882, 0.0983300087192025, 0.18719733073300393, 0.09257375033949666, 0.18134200970501047, 0.14257764526306782, 0.17779366422283838, 0.0953256690927603, 0.10413180344292194, 0.1411450187584543, 0.1282725091066237, 0.10624480946470705, 0.15857497340369897, 0.12350797131702185, 0.11114899557578051, 0.1226109889517295, 0.15527755926814113, 0.11573404139414212, 0.09424234064041082, 0.9740975601990971, 0.9633397264175866, 0.9636767996591291, 0.9575118352693195, 0.972244044374533, 0.9714448436973708, 0.9680115478972844, 0.9635710753352008, 0.9677627134108294, 0.7761375689321753, 0.7319223715474005, 0.7457679907938379, 0.7715601515454911, 0.7776955686466177, 0.7822328552756291, 0.7307656976106662, 0.762361128208428, 0.7505559050380297, 0.1722000933638046, 0.8741806764453868, 0.1706967880155491, 0.21570567183341915, 0.281901120876597, 0.2101796154548028, 0.21766414223311037, 0.1793713581059525, 0.839720693208758, 0.28381182025730745, 0.2689236053874744, 0.28004249236289047, 0.2650835167804264, 0.2670063820506342, 0.4030095545812118, 0.3196718525794081, 0.2825929446630421, 0.29763386323266827, 0.13561913955602523, 0.28053063935944256, 0.18347754551327466, 0.3151397417393538, 0.3120739236331601, 0.13429476833356369, 0.32089777711880596, 0.29854601539949577, 0.2823859657679907, 0.04335562893219336, 0.05304008712790853, 9.999999999998899e-05, 0.0011480868224788, 0.0053724413908743385, 0.028668805408160414, 0.08600054081457342, 0.0020877432581004607, 0.013569531703690463, 0.15719597138530828, 0.08756379583158724, 0.1485909503002244, 0.04463944290599664, 0.03928852543907746, 0.028233945066596378, 0.04664037093394491, 0.12688414503206336, 0.10325930374567127, 0.20079676676456326, 0.07782535898366261, 0.2583925592905806, 0.08124542326335138, 0.08272905571713596, 0.35212251723678456, 0.10056849759549258, 0.10194307826921101, 0.07486948616926015, 0.11050325134408756, 0.13027687734896387, 0.1416954685362698, 0.09703602577261494, 0.17493291471311478, 0.006742456820519549, 0.1414597255875708, 0.13655336546304186, 0.08468805801959645, 0.5489166312306006, 0.5412939692940483, 0.5690444191017048, 0.5346798289031869, 0.5804140878114714, 0.6152875098535069, 0.5921873953355777, 0.6108199403968195, 0.652943834371018, 0.105908719216122, 0.08478561265401185, 0.12275955077980671, 0.15278742935774303, 0.11079969245101207, 0.11639024334065684, 0.12579682172634588, 0.08532799827271598, 0.6037378149513006, 0.4682748542592444, 0.14299532986511299, 0.2280020267866103, 0.24686324817407912, 0.2680472350393691, 0.18598327500854028, 0.23426107879541413, 0.22573995716707684, 0.20617838631902174, 0.21581442075957635, 0.24183836092194555, 0.2687424900043699, 0.31107510153090256, 0.4340923530957822, 0.4611442178553875, 0.4225254323950107, 0.5513827369373403, 0.432650657914626, 0.36895173792661295, 0.2874644602738514, 0.2507742524044406, 0.2886057038960551, 0.26010032176454356, 0.14618128087641657, 0.24961278934676157, 0.37799634096686063, 0.39874743788900613, 0.2176782036048237, 0.25370562295409926, 0.2852163454390173, 0.23920546549619326, 0.2769461755382545, 0.19409809691727586, 0.21545584884040359, 0.2750283674814945, 0.25543193176957124, 0.2069872527749621, 0.2514457551535143, 0.18583854317532666, 0.224550980692251, 0.7595421339792476, 0.21856246730391982, 0.25191964435389436, 0.22256491514726018, 0.20916322683480904, 0.12508736974111412, 0.9188445005911154, 0.18806310891907507, 0.17309223244994587, 0.2013204122912331, 0.9421740551974527, 0.09986494918436295, 0.17034510401180503, 0.15379358191982595, 0.7773430638010494, 0.7212970847230902, 0.7310740880443689, 0.2122055953787294, 0.16936022526101302, 0.8279185293598512, 0.10525127977196758, 0.1689013152666774, 0.19783722242837254, 0.386076756349624, 0.207400840665522, 0.2091935642094942, 0.19768943698228048, 0.2906477461598299, 0.21154674523686112, 0.20141086827150045, 0.22309399222367488, 0.2146266618739956, 0.10347087314404257, 0.08511214489121666, 0.13358009238068935, 0.09287496069197365, 0.09904652440532713, 0.1036848017968256, 0.0846455672513794, 0.10182531007406126, 0.08541580205006072]}, "mutation_prompt": null}
{"id": "8e5b6401-953e-493a-bd1d-0a180d60f98c", "solution": "import numpy as np\n\nclass AdaptiveChaoticDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.7  # inertia weight for PSO\n        self.c1 = 1.8  # cognitive coefficient for PSO\n        self.c2 = 1.8  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x * 3.57 * (1 - x), 1.0)  # Logistic chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.8\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.6 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.6 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "AdaptiveChaoticDEPSO", "description": "An adaptive blend of DE and PSO with dynamic parameter adjustment and chaotic mapping for robust optimization across various landscapes.", "configspace": "", "generation": 51, "fitness": 0.27803137458940846, "feedback": "The algorithm AdaptiveChaoticDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.24.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.8003019062913211, 0.7222432435347219, 0.726712993836556, 0.6951400547476934, 0.7263798788022662, 0.7415736131899787, 0.7323547743380826, 0.18289253347339862, 0.7249011671046406, 0.4574965580623296, 0.42542935959268413, 0.4535222457071112, 0.41897478802637556, 0.3185727527514064, 0.24407912998246362, 0.6017969980282032, 0.48242162447383696, 0.4954636683036263, 0.08058064099199003, 0.17044387170541353, 0.1250299825777662, 0.13680969992101277, 0.1614059504474471, 0.1601941921689759, 0.142889079980982, 0.13827980819452246, 0.1263971181259289, 0.13360695096488706, 0.10280480871739872, 0.10679837074115495, 0.1097839352346125, 0.1260219245174159, 0.11702606889709954, 0.11269452823400539, 0.08506182062717216, 0.10138218436898228, 0.9744366264072256, 0.9567134724157212, 0.9740226362622487, 0.9675111574629539, 0.967572814765628, 0.971698847908834, 0.9749201475560612, 0.9666718667945082, 0.9680330336551267, 0.5516094177821379, 0.059751867053212115, 0.5276211537899922, 0.5517376729406396, 0.4974724003601835, 0.15267534355225287, 0.5043904621514073, 0.08871486291080655, 0.5800670425670525, 0.742826596124192, 0.3957725014996061, 0.14017479013890555, 0.19492846869278635, 0.20777807680500449, 0.32550505835551535, 0.23235941104427582, 0.7912120703218442, 0.23678772433489914, 0.19172905038601096, 0.30243366868318333, 0.13192133692515495, 0.21934842298969393, 0.2372604245086909, 0.17376020450121266, 0.2126894405897749, 0.22842540943287148, 0.2068935915696879, 0.25191468370488534, 0.201910283702464, 0.22024749866211946, 0.25037767985077886, 0.1337013321081968, 0.279765027983517, 0.26435070774378466, 0.042459579418522075, 0.1358607414500681, 9.999999999998899e-05, 0.0012445357613529717, 0.0343223628096021, 0.038833379239238464, 0.0009158215731156494, 0.0272309297568174, 0.056791545657520315, 0.0016778820140008754, 0.022511057496247266, 0.12735739844158034, 0.07656987698730178, 0.10968732425178696, 0.10072815097851995, 0.013781149399066495, 0.02650849397034183, 0.1434494699780613, 0.13783021001465678, 0.05301276553490464, 0.04166903744921624, 0.05123986502934619, 0.09351227173491339, 0.060151077206992865, 0.055321050764139734, 0.05084979005626633, 0.08767462194602682, 0.13501104652118812, 0.049290184175669105, 0.14255372629352459, 0.05474504435268479, 0.14161907611510738, 0.23870425619972635, 0.17630544889223698, 0.10082498788446792, 0.08064595576838562, 9.999999999998899e-05, 0.08209015156370081, 0.5413454455403339, 0.505499216179917, 0.5437780549470573, 0.5393770766574817, 0.5264897832236988, 0.5211988507291325, 0.5171794767932018, 0.5443855337702936, 0.5266683239390217, 0.0944783633325933, 0.12204806322497042, 0.09382041902775695, 0.14164953847880646, 0.11776820276032773, 0.10910265729828661, 0.10511845564277633, 0.10950345872287037, 0.07278859358015866, 0.1856994647224518, 0.20760733416479138, 0.4350130820661461, 0.338491147742881, 0.2541615456934665, 0.2961006733879814, 0.19707104266662323, 0.45857240087374374, 0.15979469609119046, 0.34573704616064493, 0.41306954457275946, 0.3030992841936727, 0.24628286014896328, 0.40857417921693173, 0.3519890540620386, 0.22504350073955326, 0.40668081389044963, 0.4086271147764875, 0.19519888593961832, 0.214163535282475, 0.3060276841920607, 0.2090242799459363, 0.2015351366846161, 0.273649006521707, 0.23877271619935347, 0.23537283690474486, 0.31098349690722316, 0.2287952462050704, 0.2306301738781924, 0.2169112681359826, 0.3965962506489885, 0.18542730133126373, 0.2653009921739161, 0.19913189579080515, 0.24165288485426528, 0.21475800651527532, 0.22001000056899833, 0.24200350147979655, 0.2367876285648446, 0.2391474767030205, 0.19524635962678338, 0.18928566436761685, 0.20191185491970287, 0.18600343170492728, 0.20294154696256606, 0.18725951956554499, 0.12723816237860663, 0.15449274625261566, 0.17351628490631632, 0.2011202503030396, 0.8787856421277134, 0.13140192154228714, 0.17029700702166317, 0.16862276328406445, 0.6585253031163867, 0.6757336617796905, 0.6865888906474367, 0.21151156697922247, 0.1562982510054446, 0.2106619388013654, 0.10507855280854272, 0.1046540652930198, 0.6645228706266446, 0.18101536560162346, 0.20623015760475216, 0.20350385781256564, 0.22834652618775342, 0.2197795771352592, 0.2235311116238391, 0.19125243490750066, 0.21993627699125595, 0.19885859983367993, 0.08961722205584988, 0.09263241097758679, 0.08255751300750525, 0.10334442565403368, 0.08568165339173317, 0.09221806748700434, 0.10570042950137282, 0.09546987727888245, 0.12736586344640943]}, "mutation_prompt": null}
{"id": "6dd2c6a9-dbfd-4a5b-b21c-98b05291899f", "solution": "import numpy as np\n\nclass StochasticChaoticHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(np.tanh(x) + 0.7, 1.0)  # Modified chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= np.random.uniform(0.85, 0.95)  # Stochastic inertia adjustment\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "StochasticChaoticHybridOptimizer", "description": "A hybrid optimizer integrating adaptive stochastic dynamics and chaotic maps for enhanced exploration and convergence control.", "configspace": "", "generation": 52, "fitness": 0.3498949649806492, "feedback": "The algorithm StochasticChaoticHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.29.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.8978078107370561, 0.9097456896193203, 0.8900253437559899, 0.9027832398960547, 0.8987839817990225, 0.9075512731013669, 0.8908530997837395, 0.8895675277079836, 0.8921457281003968, 0.8009158005983015, 0.7680238782025918, 0.8003069481360789, 0.7876876182536436, 0.7895925042705066, 0.8143002720902153, 0.7740551322738451, 0.8082691328584533, 0.7571265457874023, 0.15818590610022942, 0.18750052815793894, 0.09409057729986148, 0.14474615436362148, 0.18823056466238564, 0.1459598684279747, 0.1852401893434148, 0.11161259999495254, 0.11198635882667474, 0.14482955890102933, 0.1464189582746671, 0.14342385061270202, 0.11181848769803016, 0.18361944673677433, 0.10599283150271877, 0.11206905089125596, 0.11095247880105108, 0.1153142810175114, 0.9717270748865414, 0.962850701515567, 0.937729045135584, 0.9810288227958766, 0.9785913987653232, 0.9770423808446949, 0.9783473429453489, 0.9712618012153998, 0.9787075016911991, 0.754531147011784, 0.7951265515788639, 0.7667745036846267, 0.7413566267308225, 0.6728238506334159, 0.7610311013520447, 0.7205757448322418, 0.705192356627036, 0.7571242389192089, 0.1721225825938858, 0.2289309759825776, 0.11324758049764427, 0.335949693872886, 0.2807957237653095, 0.2809275043391408, 0.18018767969655092, 0.2386988483653335, 0.9026855417209535, 0.2803552805974344, 0.1356760312984463, 0.277036244521226, 0.2687997788723344, 0.2737724884666297, 0.33291039306023196, 0.3189418002667277, 0.13480996710238558, 0.3174154725735018, 0.2867069197236839, 0.2721845768259302, 0.34425314562930787, 0.3318771035069956, 0.3377283545792227, 0.33550983651148614, 0.32219076641420574, 0.21084171052157197, 0.32269875890796995, 0.03765300354021306, 0.08610417998442987, 0.009462714343317358, 0.08537673304266102, 0.08837564342303794, 0.03326724843851914, 0.04576875372555733, 0.04715334325152687, 0.10125866943006445, 0.1431123906252011, 0.12973987268806575, 0.09915979916347728, 0.08181348389034448, 0.19058359768281674, 0.020292395557098608, 0.14317689911078557, 0.09450315301678891, 0.11684928545381135, 0.07898894710539717, 0.13112746952603282, 0.14478926516366175, 0.07950557939652192, 0.08041858273092262, 0.13782334254788475, 0.19823561376242738, 0.10217259218000907, 0.07253301360202258, 0.16082780303007327, 0.1558184504568353, 0.11550809536569939, 0.15708895551403113, 0.18319877533961482, 0.23491834566014713, 0.1228721430113241, 0.2600549320769163, 0.1286423827346853, 0.5832764551432947, 0.5788897123271102, 0.5903608297873717, 0.6044733041486241, 0.5619578644326755, 0.5583247890235541, 0.5652115051598787, 0.5754724948259716, 0.6122866908040614, 0.07976745821209985, 0.10109851637356171, 0.07571599251278238, 0.16072100821404456, 0.10587998307802393, 0.09932044729565404, 0.15674495597338012, 0.14414790478039563, 0.10614654844244198, 0.17865027678291312, 0.7090926232602248, 0.20374761416880216, 0.23614444077767638, 0.43026803719607265, 0.1990628537724477, 0.36071897187845414, 0.2666702273135815, 0.34319519319894487, 0.3457792639608529, 0.4623179426882873, 0.24914585812472456, 0.3900681169845497, 0.3180137955454859, 0.38473325932892777, 0.5263082238273395, 0.43020915472042476, 0.2810082197607906, 0.2701454093217396, 0.28306470549114626, 0.20345213026942277, 0.3031279732682055, 0.199082874728842, 0.20891366299392689, 0.273330237263573, 0.2619198635867257, 0.18028355579216293, 0.30124137493418324, 0.24105654839536206, 0.3264190895149498, 0.2332594542537184, 0.21939150346965675, 0.1978198395442432, 0.19883076560436186, 0.2037091855380584, 0.2250472141075175, 0.18351006081680066, 0.25054978747234713, 0.2073044076609749, 0.22953555024046668, 0.7687639299233077, 0.18885100531908228, 0.19943089186614205, 0.20079006510672548, 0.19636076294570326, 0.918627429909815, 0.1773821656572021, 0.11326659168935294, 0.17278344441574733, 0.9203831012542808, 0.2007109563463848, 0.09966447172404547, 0.16991724214138082, 0.16271686656116235, 0.8231809277417738, 0.7941086626838151, 0.8175683130793834, 0.9156222829876375, 0.8285408684326097, 0.7928006463621609, 0.10514634593182781, 0.16991876504540981, 0.1663370192077317, 0.19642103424613278, 0.22732285555410559, 0.2012200744537601, 0.2346645749176307, 0.2517945859400118, 0.19158027648713727, 0.20491393020698023, 0.19220233462782066, 0.22302866971622148, 0.10181278814998773, 0.0829453429422532, 0.11227414491290733, 0.10143477527207756, 0.09560125409010212, 0.14708154977679855, 0.1021476009983373, 0.10667297215456328, 0.09660956141106658]}, "mutation_prompt": null}
{"id": "4dcbfee6-c53e-4f38-9cc3-364492987e9c", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                if np.random.rand() < 0.05:\n                    mutant += np.random.normal(0, 0.1, self.dim)  # Random perturbation\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.95  # Adjust inertia weight\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                if np.random.rand() < 0.05:\n                    self.velocities[i] += np.random.normal(0, 0.05, self.dim)  # Random perturbation in velocity\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A robust hybrid optimizer integrating adaptive chaotic maps and random perturbations to enhance exploration and stability in DEPSO.", "configspace": "", "generation": 53, "fitness": 0.3117775304499517, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.25.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.8132815559918645, 0.8946062196849581, 0.823052216633515, 0.8036600020299656, 0.8294762649531846, 0.8373586356786678, 0.8168980026372408, 0.8588701737064097, 0.8322807584761194, 0.3691332036295131, 0.4435788903605151, 0.43833758289233415, 0.41230842413131197, 0.5432945185112351, 0.36315589365469436, 0.32492065365585776, 0.5841283864689729, 0.5684859972039158, 0.1424491013626481, 0.16050087906897992, 0.09248803089454483, 0.14249042926551592, 0.1142400992489796, 0.18391884283021764, 0.11510968853930759, 0.18878978391241197, 0.1564353776707168, 0.10045259315738642, 0.04391651191351298, 0.0628360138041828, 0.12235997803944121, 0.11202108481731976, 0.07898118186570335, 0.10780170989228077, 0.10284449948359031, 0.11641290361616152, 0.982825190444334, 0.9772770605665492, 0.9667463812615693, 0.9749303294041243, 0.9706195233955256, 0.962114432677205, 0.9716418423217839, 0.969843317060882, 0.9733146179901777, 0.5757856604577125, 0.6140002970853459, 0.5725323658305026, 0.5377822092588753, 0.5478111523538753, 0.6023147707553053, 0.5365904671268957, 0.5747677996879621, 0.5389874045887186, 0.3859916932290357, 0.13870836881259674, 0.2418808368660521, 0.7736489156694957, 0.278476908525518, 0.27860851159192956, 0.12664897124205343, 0.21988210389929508, 0.3996297460287307, 0.33250992658344225, 0.25572642652906474, 0.2656948945184614, 0.23352294742585977, 0.23473568273895717, 0.2618540833645622, 0.24476651164881935, 0.253762128087194, 0.23163972269451882, 0.23865485116320484, 0.21823390057731018, 0.4682791733260795, 0.2468508965523193, 0.26664549400110993, 0.13338968124432538, 0.26479648054561356, 0.2500498918877956, 0.25013056239535214, 0.037004047025520626, 0.05402729666146766, 0.08831063851163978, 0.0517474183540253, 9.999999999998899e-05, 0.025758009882096977, 0.016582551023466063, 9.999999999998899e-05, 9.999999999998899e-05, 0.2065465219958854, 0.1449108693198663, 0.13194860046614754, 0.15261870075430473, 0.022763565708262323, 0.030444118631569705, 0.1570210817285388, 0.11846413061950367, 0.05934165997097429, 0.3050740785338609, 0.26955909018972135, 0.09451235330245822, 0.09311682968340973, 0.2561675095879461, 0.21280696132211585, 0.11162330006225651, 0.3056493803565766, 0.0716329411728921, 0.19089062888125485, 0.15861758564856032, 0.31307547533538727, 0.1580060375949217, 0.05436012009723268, 0.21706853275125038, 0.2845233158752343, 0.12240050351670129, 0.08525414596140712, 0.5460565594306532, 0.5503849157912806, 0.5486364498679589, 0.5739194286299233, 0.5569277957363278, 0.5385685549131849, 0.5338882611011833, 0.5615046317250281, 0.5464291603122132, 0.09196346071070405, 0.12325211482606735, 0.08806709958713821, 0.13101778673060893, 0.13131888935937353, 0.18946782683039287, 0.11821280534993406, 0.11814399319374602, 0.15612510318180306, 0.2057321168904872, 0.3194699424313827, 0.4721026888127955, 0.28257075993297764, 0.35905138576221074, 0.2707241062248915, 0.27005898448258026, 0.20189347118467194, 0.22570347771591526, 0.3581367389830471, 0.38825069119333344, 0.3907603798628787, 0.41211176838395835, 0.24862542945801147, 0.45946201511825946, 0.4566073698162797, 0.47294299114890004, 0.4144263444962011, 0.25071991939692917, 0.2592064724758024, 0.2576037488113252, 0.19818524092805245, 0.2265335476074838, 0.31869061421894795, 0.2135286340844631, 0.313614944035863, 0.2423217892149091, 0.2280200189466549, 0.20750578272080145, 0.2702807299509331, 0.21919541980825696, 0.2183225449066476, 0.23433593804687858, 0.2596522918698886, 0.20406699385104954, 0.24432531901003884, 0.20350514056426194, 0.6732965716177102, 0.2025232030632369, 0.2537954442306338, 0.2555172493966126, 0.21041737438084196, 0.2001602073479316, 0.21086355340532803, 0.20862525866343462, 0.9367159775537205, 0.1681244315757816, 0.15428752575660787, 0.17909925124005954, 0.910936771265352, 0.17982953274603874, 0.15399051057871382, 0.13726642695766822, 0.16713227542916687, 0.7875747617791647, 0.2119527084048105, 0.8808474457824423, 0.21170994331962478, 0.1681772310527, 0.1562178701328779, 0.12870863231192653, 0.10504790287372856, 0.21300394799745226, 0.19553979182962833, 0.21533927011567322, 0.17987821183243502, 0.19361685670638518, 0.2048504583431522, 0.19825005418010477, 0.20187590330794458, 0.18690111003670362, 0.19828692198393705, 0.09608949426565339, 0.0939861166400795, 0.13890685885221432, 0.1003032743190514, 0.09144019582264717, 0.17554964659185956, 0.08850376562333495, 0.09172222763906179, 0.09734559698497836]}, "mutation_prompt": null}
{"id": "b1bc7991-ecb0-4e07-9893-7cac1d13b97c", "solution": "import numpy as np\n\nclass AdaptiveVelocityDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.vel_max = 1.0\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n        self.restart_threshold = 0.2 * self.budget\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n            if evaluations < self.restart_threshold and global_best_fitness < self.diversity_threshold:\n                self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n                self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n                evaluations += self.population_size\n\n        return self.global_best", "name": "AdaptiveVelocityDEPSO", "description": "Introducing adaptive velocity control and strategic restart mechanisms in DEPSO for superior convergence and robustness.", "configspace": "", "generation": 54, "fitness": 0.34557211507301855, "feedback": "The algorithm AdaptiveVelocityDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.28.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.8865276906432433, 0.9020532548803202, 0.8929687050976703, 0.9069966467491789, 0.8983603223003787, 0.9022140074472543, 0.8120348074670385, 0.8018712998055806, 0.771997857902402, 0.6157098397688421, 0.659063530876983, 0.6097779289458561, 0.6507439368181258, 0.6478889905331984, 0.6376255959625627, 0.631960386535247, 0.6361647565233346, 0.6412403942557114, 0.10438349012411163, 0.1442145870935455, 0.14024211495074523, 0.14472904467535863, 0.18827718037504793, 0.14600008067707715, 0.18654152199131935, 0.11161280818292418, 0.11200366762783509, 0.11963739171211873, 0.1123620934594799, 0.07290121538095296, 0.11181421186718143, 0.09209417505561412, 0.11938418806199658, 0.11206983601831055, 0.11095636186680169, 0.10912525701701048, 0.8510436563792365, 0.8452904629656669, 0.8171909485839239, 0.9810288407887259, 0.9785915503130439, 0.9770423747813494, 0.9783473338829307, 0.9712621930647505, 0.9787075504592555, 0.7607315187580301, 0.7749069267760285, 0.7630288578874603, 0.7507532481153396, 0.6554370351125884, 0.7762723104136083, 0.6694158116894484, 0.5685981376136138, 0.6508124375510418, 0.1721225825938858, 0.22891630584450517, 0.11324758049764427, 0.3549737812815622, 0.2807957237653095, 0.28145549322917607, 0.18018767969655092, 0.2386988483653335, 0.9395469978455472, 0.2720537562684263, 0.1357109215500677, 0.288515417628357, 0.11860186647740645, 0.2415327690740332, 0.22653879730293447, 0.29980271067857245, 0.13457278726329025, 0.31624018099324525, 0.28347106445129555, 0.27653913969396915, 0.2892909131254505, 0.32904479577095047, 0.30792895015902, 0.3267380918354402, 0.3033156492629593, 0.2088685743639237, 0.2906120113344278, 0.004881953303818798, 0.08125027695295306, 0.01040324864575648, 0.08307057080589308, 0.0631748299553836, 0.031141171943307566, 0.04654370896227589, 0.01040740580263222, 0.07219263740920923, 0.14820762824482314, 0.14111157929981544, 0.09939347465031478, 0.07011557728613427, 0.13017562154375395, 0.02739581001833591, 0.11477783328277313, 0.09375370099990121, 0.12437319484907039, 0.06539670377016282, 0.10365020737503783, 0.12682995906375327, 0.0670621617915449, 0.06756330948575029, 0.1154341001287228, 0.19524821804991244, 0.10442299933492127, 0.07342327849013242, 0.16578167026123625, 0.1853016315404299, 0.1189542819871422, 0.1760557186056767, 0.14800088478028517, 0.2644656424279026, 0.10600128540319498, 0.25544402726507165, 0.07290604173988191, 0.49822605895712024, 0.5220403499869686, 0.5388699190324628, 0.5465427298370038, 0.5465701099998022, 0.5122090086062301, 0.5877025571595188, 0.58912009886935, 0.5796039758319813, 0.07975439706166598, 0.10110173168052605, 0.0755122787624074, 0.16076138881367696, 0.10587421420661025, 0.09908423757627094, 0.07865892608900371, 0.13049114849194032, 0.09456073095859086, 0.22279569248288034, 0.6592237296261918, 0.22467227789135458, 0.2718496247532789, 0.22207476171540286, 0.30323212921527287, 0.5283272114477804, 0.21131508909474783, 0.3463028054853772, 0.34988146333530534, 0.33204957538298585, 0.29932566431835717, 0.37827330003298987, 0.3159543684158136, 0.3948951692827499, 0.5338080159903202, 0.6386237352364159, 0.19094651398173923, 0.25404997826201414, 0.20626921594087833, 0.21963600000022532, 0.3126123000671225, 0.19508244130654495, 0.2440464616149688, 0.2746657038803456, 0.2758095868983087, 0.1718425074209099, 0.24362018854364076, 0.22032523907451307, 0.21307803166605543, 0.21621523555871425, 0.23220195984323055, 0.2121859746984508, 0.22233176434332813, 0.19428032015735874, 0.2940143940691601, 0.1704981117950869, 0.23498612033718613, 0.17444238796138467, 0.2296346173180046, 0.7839070787440949, 0.18887893138201983, 0.19948332275076253, 0.2261375176508097, 0.19661374747919813, 0.9185297033957897, 0.17730516387770456, 0.11326657578340704, 0.17278331750195008, 0.8439605065428506, 0.19805143259064506, 0.8298877100167994, 0.8616959632922251, 0.8296207690264185, 0.6803599797332431, 0.6731319647335998, 0.7638772213967201, 0.9133133255502286, 0.8484364245717022, 0.7770450456081295, 0.717057152982274, 0.16584412656663972, 0.8126617855407264, 0.19554443874623362, 0.24430239869142467, 0.21100720171394982, 0.1973610633324807, 0.25121027229113, 0.19102423719310313, 0.20519317095312672, 0.19542103505648467, 0.1773694723921806, 0.08892873400730372, 0.07113752042749677, 0.11154483811644855, 0.0966630146129761, 0.0829219834948779, 0.14774202050214513, 0.10337404775080683, 0.10543583486427055, 0.09783716494350791]}, "mutation_prompt": null}
{"id": "ff2728bd-e130-4eb9-88ec-11540443209d", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7 * np.sin(np.pi * x), 1.0)  # Enhanced chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.85  # More aggressive reduction\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.7 + 0.5 * np.cos(self.iteration / 30.0)\n            self.c2 = 1.3 + 0.5 * np.sin(self.iteration / 30.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A refined hybrid optimizer integrating adaptive chaotic maps and dynamic inertia in DEPSO for enhanced exploration and convergence.", "configspace": "", "generation": 55, "fitness": 0.31158336209269843, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.28.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.9212663697047928, 0.8981966606608629, 0.9120881647161508, 0.8939905527642813, 0.8687392214534735, 0.9066337335328823, 0.9003517017429593, 0.1830030947855007, 0.9104510503305633, 0.8187704501189411, 0.792829663866718, 0.7966925562786831, 0.800947898662932, 0.782052595468057, 0.8177084580540127, 0.8184968304975295, 0.7968496022401172, 0.8193979584136919, 0.1143768526064296, 0.11860364379330657, 0.1076636804980422, 0.10101183146696002, 0.1214396406953443, 0.12638326030815805, 0.16124227685591797, 0.08362014508943882, 0.15722652470575726, 0.10987636104005027, 0.027602772041458445, 0.09708609543367952, 0.13158699449321898, 0.0851543071401355, 0.0882590307858041, 0.10725132845436458, 0.07928236681764156, 0.05125789561552452, 0.9744834341317582, 0.9555623866185777, 0.9706771060420848, 0.9639276052025767, 0.9639196572694917, 0.9669181330069645, 0.9717179702351781, 0.9608047229413811, 0.9674451848281088, 0.8025524698174458, 0.7524153663979603, 0.7215398237057918, 0.6435349246190172, 0.7143255716810046, 0.1535517043204896, 0.12845432466922302, 0.08865388555936804, 0.7900632939346732, 0.228228619472293, 0.22952533945196296, 0.3820721002212263, 0.19447740921364065, 0.945468837512459, 0.1968873259794348, 0.17871582869145097, 0.1782378312668469, 0.2489089684958371, 0.3399225736021444, 0.136072441482755, 0.379610204933333, 0.26343493541020635, 0.2659924906743517, 0.22323877402823933, 0.3139658777369684, 0.2844546273612013, 0.3096008874508389, 0.2631582909277408, 0.28156563507380683, 0.2701011302484918, 0.31363938708428596, 0.1357450959101083, 0.33061611072621777, 0.33410457158759344, 0.13901593374009813, 0.2874574092228258, 0.06794232389880728, 0.04777954684168695, 0.005530516339715019, 0.04580261591339785, 0.01640129336893792, 0.09272965772425235, 0.0016084829666719314, 0.05162967709935129, 9.999999999998899e-05, 0.08862518767003891, 0.043879176243774576, 0.05896992527334677, 0.05646415512598246, 0.023526749702235783, 0.03192463551985292, 0.23024380548617018, 0.15508436372495382, 0.0536807306549828, 0.13211710343349714, 0.1479958916666947, 0.26505249747702186, 0.07883398026936717, 0.08330247403184143, 0.08044783483641771, 0.14849582134205686, 0.2005337539727483, 0.0733571316391175, 0.15524481891825503, 0.07863928622472272, 0.1672961960537761, 0.11694079716900052, 0.1234970744506334, 0.30544459258816226, 0.10093019661754354, 9.999999999998899e-05, 0.08536104991379656, 0.5516071346509355, 0.5962883447865827, 0.5844101014334464, 0.5952403451044435, 0.5762465465450528, 0.5579422409190311, 0.5773602647110141, 0.5974408184022908, 0.5812013850473372, 0.06612595261404408, 0.06432690524020979, 0.08873067865332884, 0.18254261177948794, 0.08250210206674657, 0.10097840451735374, 0.1388567865231367, 0.1111181169955362, 0.10632117734154434, 0.16144681320271792, 0.28090407129789197, 0.2921013832669226, 0.264518549901272, 0.26426142591893764, 0.16432467554003383, 0.27610346798403385, 0.22899041750823335, 0.20134687703124854, 0.15901148536247145, 0.3523000400903925, 0.24111872312943305, 0.25858218784758824, 0.25019982670814034, 0.2577189675599403, 0.172623182502049, 0.43687296037636814, 0.14437556094852844, 0.1100404734593945, 0.19919650172297354, 0.240253631203178, 0.17966436227128402, 0.1977492127539292, 0.3933305601537834, 0.27682345344216364, 0.2754869847128063, 0.10504472503162343, 0.23289946991266353, 0.28163913295468745, 0.33196548980681717, 0.24744472562292963, 0.15454081396744734, 0.21176027941136055, 0.23346222035803843, 0.22582317019612042, 0.2561728486509902, 0.197901012719502, 0.1921292573175578, 0.21225561913943503, 0.2500900165173817, 0.18020335611642824, 0.17942526454697472, 0.18833214620184768, 0.21221094278790575, 0.19700632956453112, 0.18846575554661538, 0.1273927012219721, 0.15454135176010875, 0.173574033337069, 0.2018578705915839, 0.9499861447051655, 0.13149673503172798, 0.17022356323689114, 0.1545648113975736, 0.8837376165169502, 0.7940645654561708, 0.8279751509774735, 0.8549380412699185, 0.15564831794192102, 0.21232309076471423, 0.10512283069381012, 0.10481401346279562, 0.8309302114949751, 0.2046623829195211, 0.20389302702265477, 0.1978232908177442, 0.18947921909385446, 0.20878172647901294, 0.23066549528867264, 0.21372810416702437, 0.18905252531959782, 0.1922960333572601, 0.09165571274042017, 0.08751138809981329, 0.12999126673002992, 0.09098413799403116, 0.10844470549103058, 0.10462529800671294, 0.07226333368470117, 0.0900888995243675, 0.07783920804784938]}, "mutation_prompt": null}
{"id": "8f2c730f-6bc9-4cb4-a391-38df196e19fd", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A refined hybrid optimizer incorporating adaptive chaotic maps in DEPSO for enhanced exploration and convergence.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.8865276906432433, 0.9020532548803202, 0.8929687050976703, 0.9069966467491789, 0.8983603223003787, 0.9022140074472543, 0.8838639783889877, 0.8886653828703049, 0.889752534826144, 0.7567698703303883, 0.784578368098034, 0.8076249809202548, 0.7611720006041811, 0.7986347352301275, 0.8050952302753023, 0.7936777043904858, 0.8107862909162267, 0.7638655686477411, 0.14306028296887274, 0.18771148863225673, 0.09076269380504487, 0.14472904467535863, 0.18827718037504793, 0.14600008067707715, 0.18654152199131935, 0.11161280818292418, 0.11200366762783509, 0.13393502172957683, 0.14641399913557107, 0.1432167792015192, 0.11181421186718143, 0.09209417505561412, 0.11938418806199658, 0.11206983601831055, 0.11095636186680169, 0.10912525701701048, 0.9717271359469163, 0.9628507846149675, 0.9377341630520235, 0.9810288407887259, 0.9785915503130439, 0.9770423747813494, 0.9783473338829307, 0.9712621930647505, 0.9787075504592555, 0.7607315187580301, 0.7749069267760285, 0.7630288578874603, 0.7507532481153396, 0.6554370351125884, 0.7762723104136083, 0.7499504173558014, 0.6968283959747328, 0.7389586451693928, 0.1721225825938858, 0.22891630584450517, 0.11324758049764427, 0.3549737812815622, 0.2807957237653095, 0.28145549322917607, 0.18018767969655092, 0.2386988483653335, 0.9395469978455472, 0.2720537562684263, 0.1357109215500677, 0.288515417628357, 0.27358595508171457, 0.28033933355072405, 0.3483295090039492, 0.29980271067857245, 0.13457278726329025, 0.31624018099324525, 0.28347106445129555, 0.27653913969396915, 0.2892909131254505, 0.32904479577095047, 0.30792895015902, 0.3267380918354402, 0.3033156492629593, 0.2088685743639237, 0.2906120113344278, 0.004881953303818798, 0.08432094844164972, 0.01040324864575648, 0.08307057080589308, 0.0631748299553836, 0.031141171943307566, 0.038932547461408507, 0.021942713170019723, 0.09321589178997347, 0.14820762824482314, 0.14111157929981544, 0.09939347465031478, 0.07351212675576657, 0.14911297504852605, 0.02739581001833591, 0.11477783328277313, 0.09375370099990121, 0.12437319484907039, 0.07875046545806708, 0.12463510807347011, 0.14210128121458188, 0.07919284437097684, 0.0801485337679555, 0.13337703281066082, 0.19524821804991244, 0.10442299933492127, 0.07342327849013242, 0.16578167026123625, 0.1853016315404299, 0.1189542819871422, 0.1574945670012905, 0.18360986723287642, 0.2558817728796652, 0.12448657793629136, 0.25405459307747846, 0.1254414517844874, 0.5407077538029146, 0.6006067397749144, 0.5396897498932287, 0.5489927270360135, 0.5891834596503931, 0.5459801886932765, 0.5877025571595188, 0.58912009886935, 0.5796039758319813, 0.07975439706166598, 0.10110173168052605, 0.0755122787624074, 0.16076138881367696, 0.10587421420661025, 0.09908423757627094, 0.11384860622149795, 0.14412899438570692, 0.10610491466439798, 0.22279569248288034, 0.6592237296261918, 0.22467227789135458, 0.27264975790467794, 0.42228702264236595, 0.4427009503531557, 0.5283272114477804, 0.21131508909474783, 0.3463028054853772, 0.5602848907432856, 0.5870043317671049, 0.24980633166770938, 0.37827330003298987, 0.3159543684158136, 0.3948951692827499, 0.5338080159903202, 0.6386237352364159, 0.19094651398173923, 0.2682466646833648, 0.24944249579405708, 0.20048413900667417, 0.3126123000671225, 0.19508244130654495, 0.2440464616149688, 0.2746657038803456, 0.2758095868983087, 0.1718425074209099, 0.24221577925087046, 0.24277264917923613, 0.22753707311652804, 0.21621523555871425, 0.23220195984323055, 0.2121859746984508, 0.22233176434332813, 0.19428032015735874, 0.2940143940691601, 0.18346601962379372, 0.2507595245585167, 0.2074744620231186, 0.2296346173180046, 0.7839070787440949, 0.18887893138201983, 0.19948332275076253, 0.2261375176508097, 0.19661374747919813, 0.9185297033957897, 0.17730516387770456, 0.11326657578340704, 0.17278331750195008, 0.9190619999789291, 0.2007124882642538, 0.0996663158636657, 0.16991723780351253, 0.16271709766976927, 0.8243727383661772, 0.8166819556788825, 0.7311027166633209, 0.9133133255502286, 0.8484364245717022, 0.7770450456081295, 0.10514634504197418, 0.1699183301713061, 0.16636178423956227, 0.19554443874623362, 0.24430239869142467, 0.21100720171394982, 0.1973610633324807, 0.25121027229113, 0.19102423719310313, 0.2563067934359131, 0.23300659057012685, 0.22269509176237645, 0.08892873400730372, 0.07113752042749677, 0.11154483811644855, 0.0966630146129761, 0.0829219834948779, 0.14774202050214513, 0.10337404775080683, 0.10543583486427055, 0.09783716494350791]}, "mutation_prompt": null}
{"id": "1c600ea3-354d-491c-81c9-34fcb15dfdc4", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A refined hybrid optimizer incorporating adaptive chaotic maps in DEPSO for enhanced exploration and convergence.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.8865276906432433, 0.9020532548803202, 0.8929687050976703, 0.9069966467491789, 0.8983603223003787, 0.9022140074472543, 0.8838639783889877, 0.8886653828703049, 0.889752534826144, 0.7567698703303883, 0.784578368098034, 0.8076249809202548, 0.7611720006041811, 0.7986347352301275, 0.8050952302753023, 0.7936777043904858, 0.8107862909162267, 0.7638655686477411, 0.14306028296887274, 0.18771148863225673, 0.09076269380504487, 0.14472904467535863, 0.18827718037504793, 0.14600008067707715, 0.18654152199131935, 0.11161280818292418, 0.11200366762783509, 0.13393502172957683, 0.14641399913557107, 0.1432167792015192, 0.11181421186718143, 0.09209417505561412, 0.11938418806199658, 0.11206983601831055, 0.11095636186680169, 0.10912525701701048, 0.9717271359469163, 0.9628507846149675, 0.9377341630520235, 0.9810288407887259, 0.9785915503130439, 0.9770423747813494, 0.9783473338829307, 0.9712621930647505, 0.9787075504592555, 0.7607315187580301, 0.7749069267760285, 0.7630288578874603, 0.7507532481153396, 0.6554370351125884, 0.7762723104136083, 0.7499504173558014, 0.6968283959747328, 0.7389586451693928, 0.1721225825938858, 0.22891630584450517, 0.11324758049764427, 0.3549737812815622, 0.2807957237653095, 0.28145549322917607, 0.18018767969655092, 0.2386988483653335, 0.9395469978455472, 0.2720537562684263, 0.1357109215500677, 0.288515417628357, 0.27358595508171457, 0.28033933355072405, 0.3483295090039492, 0.29980271067857245, 0.13457278726329025, 0.31624018099324525, 0.28347106445129555, 0.27653913969396915, 0.2892909131254505, 0.32904479577095047, 0.30792895015902, 0.3267380918354402, 0.3033156492629593, 0.2088685743639237, 0.2906120113344278, 0.004881953303818798, 0.08432094844164972, 0.01040324864575648, 0.08307057080589308, 0.0631748299553836, 0.031141171943307566, 0.038932547461408507, 0.021942713170019723, 0.09321589178997347, 0.14820762824482314, 0.14111157929981544, 0.09939347465031478, 0.07351212675576657, 0.14911297504852605, 0.02739581001833591, 0.11477783328277313, 0.09375370099990121, 0.12437319484907039, 0.07875046545806708, 0.12463510807347011, 0.14210128121458188, 0.07919284437097684, 0.0801485337679555, 0.13337703281066082, 0.19524821804991244, 0.10442299933492127, 0.07342327849013242, 0.16578167026123625, 0.1853016315404299, 0.1189542819871422, 0.1574945670012905, 0.18360986723287642, 0.2558817728796652, 0.12448657793629136, 0.25405459307747846, 0.1254414517844874, 0.5407077538029146, 0.6006067397749144, 0.5396897498932287, 0.5489927270360135, 0.5891834596503931, 0.5459801886932765, 0.5877025571595188, 0.58912009886935, 0.5796039758319813, 0.07975439706166598, 0.10110173168052605, 0.0755122787624074, 0.16076138881367696, 0.10587421420661025, 0.09908423757627094, 0.11384860622149795, 0.14412899438570692, 0.10610491466439798, 0.22279569248288034, 0.6592237296261918, 0.22467227789135458, 0.27264975790467794, 0.42228702264236595, 0.4427009503531557, 0.5283272114477804, 0.21131508909474783, 0.3463028054853772, 0.5602848907432856, 0.5870043317671049, 0.24980633166770938, 0.37827330003298987, 0.3159543684158136, 0.3948951692827499, 0.5338080159903202, 0.6386237352364159, 0.19094651398173923, 0.2682466646833648, 0.24944249579405708, 0.20048413900667417, 0.3126123000671225, 0.19508244130654495, 0.2440464616149688, 0.2746657038803456, 0.2758095868983087, 0.1718425074209099, 0.24221577925087046, 0.24277264917923613, 0.22753707311652804, 0.21621523555871425, 0.23220195984323055, 0.2121859746984508, 0.22233176434332813, 0.19428032015735874, 0.2940143940691601, 0.18346601962379372, 0.2507595245585167, 0.2074744620231186, 0.2296346173180046, 0.7839070787440949, 0.18887893138201983, 0.19948332275076253, 0.2261375176508097, 0.19661374747919813, 0.9185297033957897, 0.17730516387770456, 0.11326657578340704, 0.17278331750195008, 0.9190619999789291, 0.2007124882642538, 0.0996663158636657, 0.16991723780351253, 0.16271709766976927, 0.8243727383661772, 0.8166819556788825, 0.7311027166633209, 0.9133133255502286, 0.8484364245717022, 0.7770450456081295, 0.10514634504197418, 0.1699183301713061, 0.16636178423956227, 0.19554443874623362, 0.24430239869142467, 0.21100720171394982, 0.1973610633324807, 0.25121027229113, 0.19102423719310313, 0.2563067934359131, 0.23300659057012685, 0.22269509176237645, 0.08892873400730372, 0.07113752042749677, 0.11154483811644855, 0.0966630146129761, 0.0829219834948779, 0.14774202050214513, 0.10337404775080683, 0.10543583486427055, 0.09783716494350791]}, "mutation_prompt": null}
{"id": "882589d4-71a8-475b-b00e-a645c2b0e1dc", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO_V2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n        self.adaptive_memory_factor = 0.9\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= self.adaptive_memory_factor\n\n            # Dynamic parameter tuning for PSO\n            if np.random.rand() < self.diversity_probability:\n                self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n                self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO_V2", "description": "An enhanced hybrid optimizer using adaptive particle memory and stochastic control parameters for improved search efficiency.", "configspace": "", "generation": 58, "fitness": 0.3384853468180528, "feedback": "The algorithm EnhancedHybridDEPSO_V2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.8932634831868937, 0.9199125853066551, 0.9196373100839159, 0.8873586880350743, 0.877282748599775, 0.9128874419118456, 0.8659497679996071, 0.9173762797724944, 0.9067611668108218, 0.7702827428944415, 0.8022667270231423, 0.7959871468625944, 0.8069771770128348, 0.7547033746553502, 0.7855403087186934, 0.7954062222468781, 0.7841009141395867, 0.8033073532239636, 0.12352440268338383, 0.11779424116032677, 0.1157671189618068, 0.14456160880475677, 0.1615993194055172, 0.12486636170879795, 0.11759978930995896, 0.13394283225077874, 0.1876029245448032, 0.13977936045515893, 0.06559545998050398, 0.07675946170200443, 0.1601802669296576, 0.1260109013690942, 0.14436963142866643, 0.11643451644778557, 0.1417750018143028, 0.11765124887943279, 0.9751394739174806, 0.9550363302091825, 0.9695287159448399, 0.9775420014888848, 0.967344880089788, 0.9657757383280806, 0.9808537023540911, 0.9677750185028201, 0.9780595799867107, 0.7688060093231383, 0.7410143661552125, 0.05997681194107296, 0.7167185928623419, 0.7372853312076253, 0.7318442002045993, 0.7328566049839524, 0.7398279156668637, 0.7572909568030408, 0.33794305429741445, 0.9029892397215727, 0.2110108429167309, 0.21574478604566916, 0.21492934636371963, 0.28201350060639974, 0.23630937178075473, 0.8848634622205774, 0.2387230402130046, 0.2783121340777086, 0.28841911746141535, 0.2632892985555607, 0.2738188824468861, 0.2846808729119553, 0.3129123383905946, 0.321764100319869, 0.28802296051741916, 0.30562790722067723, 0.13544895881066876, 0.2847683578771314, 0.27687743586094005, 0.30881403052414835, 0.13457785464182326, 0.3050079506675294, 0.31347088687918234, 0.25217906824825553, 0.29093530200341433, 0.0032964379399430532, 0.05909904637246888, 9.999999999998899e-05, 0.003639392157079091, 0.06132357197884453, 9.999999999998899e-05, 0.07967997189659182, 0.013209835158267236, 0.010594427045968025, 0.17571920819643105, 0.06706981107693433, 0.07916249640766126, 0.05736227917971337, 0.06884982679068985, 0.023714499596816152, 0.16680367652618877, 0.14163361603799185, 0.057665693916610916, 0.2188764889301683, 0.07804378308708548, 0.11207188525865386, 0.3130033236506128, 0.08368726045189501, 0.08029326655876301, 0.1297698755892538, 0.10115405174289605, 0.07432649245924239, 0.211271180093065, 0.08741128149080102, 0.11688463515802305, 0.08126264526661742, 0.31665057576488875, 0.09128561820879855, 0.09632690664569199, 0.20606708567740228, 0.08506749356303733, 0.5699198126105471, 0.5470017188813958, 0.6002755638699049, 0.5806676174414445, 0.5572545087406027, 0.5783340467591691, 0.6615358156092752, 0.5929550521213038, 0.5903842116932759, 0.14454617594790076, 0.10626281384289737, 0.06230287773268084, 0.10710977407960365, 0.10556055832026578, 0.141747181719581, 0.11872728937971366, 0.0973996641902588, 0.0907831259022438, 0.23245645980719631, 0.21411147065344138, 0.22834610154026613, 0.37268646806469485, 0.14632893475077513, 0.17087602935935298, 0.17452689394124443, 0.7364146123194203, 0.29703693697115063, 0.30131662048560426, 0.3997934623679906, 0.23027962086853815, 0.3960484440987362, 0.2704629485640526, 0.37253419230084894, 0.3694869304098197, 0.6275665518147213, 0.17828801478339085, 0.25650497786041027, 0.24686785698848612, 0.2388602030628677, 0.32849949854817373, 0.21542403479943673, 0.2152854109833695, 0.23737550247521955, 0.35119411376196685, 0.32601593249959215, 0.215364120123531, 0.22781255697462222, 0.22458164546430892, 0.232233186262789, 0.24250331569954464, 0.19476947496533714, 0.2431381257612365, 0.24743037622838826, 0.25002749784184775, 0.20208561358983823, 0.8297115215725479, 0.1905849668337799, 0.1771895998008255, 0.20370248450166195, 0.19451922158642443, 0.19212733063534637, 0.1974622862819564, 0.1789196646576342, 0.9149776016875628, 0.17828160962774642, 0.15404559748837032, 0.16939442531895887, 0.20115296600559773, 0.9506461839204025, 0.0998147006428508, 0.16993547739205173, 0.15448571012348034, 0.8932391582054786, 0.21285777258695426, 0.7467209802765855, 0.9190455790850146, 0.2125653842133538, 0.7633403074677974, 0.10522789400244748, 0.1691016596393975, 0.1676670897673621, 0.21839910183812128, 0.18853439357849366, 0.21559974653067815, 0.21578934946796047, 0.23727922197636953, 0.21091714535827277, 0.2153860652833851, 0.1994071413272097, 0.2792676726879457, 0.10682628062086952, 0.09528927472254833, 0.08809235784954672, 0.07350404588572179, 0.0893439896079482, 0.1345856844514396, 0.09943101557027423, 0.08890630552409162, 0.10883314351552686]}, "mutation_prompt": null}
{"id": "d3c05fb0-8f6d-4967-ad87-8240a5150fde", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Adjust population size dynamically\n            if evaluations % 50 == 0 and self.population_size < 50:\n                self.population_size += 1\n                new_particle = np.random.uniform(self.lb, self.ub, (1, self.dim))\n                new_velocity = np.random.uniform(-self.vel_max, self.vel_max, (1, self.dim))\n                self.particles = np.vstack((self.particles, new_particle))\n                self.velocities = np.vstack((self.velocities, new_velocity))\n                new_fitness = func(new_particle[0])\n                evaluations += 1\n                fitness = np.append(fitness, new_fitness)\n                self.personal_best = np.vstack((self.personal_best, new_particle))\n                personal_best_fitness = np.append(personal_best_fitness, new_fitness)\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    self.global_best = new_particle[0]\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A refined hybrid optimizer incorporating adaptive chaotic maps in DEPSO for enhanced exploration and convergence, with dynamic population size adjustment for improved adaptability.", "configspace": "", "generation": 59, "fitness": 0.3371691077775664, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.28.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.9056691068752222, 0.8793038774843231, 0.8690887514493219, 0.8905524389715249, 0.9039096964789416, 0.9135327263209011, 0.897392600093226, 0.893217525172849, 0.8902214301693004, 0.7808937246281618, 0.7780323567713885, 0.7954361378844207, 0.7449565444178435, 0.7818135420947094, 0.734096819944987, 0.8008630165073699, 0.7567573462076423, 0.7731418614401069, 0.15842663245199784, 0.14120631074856815, 0.09364484929639472, 0.18523966437894035, 0.1176125489400549, 0.18232394885000036, 0.18413418203336696, 0.1259343474735326, 0.1531614234316525, 0.09173576033910136, 0.14349499934122922, 0.09180636999541147, 0.11485116989192612, 0.11587404558351866, 0.12527366491065628, 0.10478409367903063, 0.0925135967013524, 0.11310169365464862, 0.9835512443955704, 0.9630436198525658, 0.9551271402321124, 0.966641348250987, 0.9653091199868011, 0.9733931586728816, 0.9804627485990559, 0.9654312251701256, 0.9683246402690651, 0.7504734771219589, 0.6984211832842904, 0.760827172417524, 0.7497618448699219, 0.7751825760743501, 0.7353463370186799, 0.7246730711880223, 0.7255742182775164, 0.7687731855172347, 0.38645082029543987, 0.17215681104622205, 0.22080047153426197, 0.2826475709531535, 0.2136995329545427, 0.21371110391185044, 0.23787516128925412, 0.17911210342373785, 0.36121489704055854, 0.27558885973807723, 0.13515969960270646, 0.2851879619316352, 0.2969462114353615, 0.295066877948445, 0.24652636739848444, 0.30446141797775084, 0.13390635620580893, 0.45367038635217705, 0.2534405307769717, 0.13500872085357585, 0.21329822646102437, 0.30846449990989144, 0.27141193340913083, 0.3104633311622357, 0.3364231804640262, 0.28679229977748355, 0.3158813308680979, 0.06508621511313373, 0.007349665375194658, 0.0030419517040755073, 0.05739474337880712, 0.10482985059893546, 9.999999999998899e-05, 0.01459445378141666, 0.020603422648501124, 0.020881729764516965, 0.1263184001012676, 0.06498687173843498, 0.1257725469321831, 0.11977153682208086, 0.11310481989132115, 0.07557820807993743, 0.19496859051686, 0.13266644662058824, 0.11222893374002818, 0.07108955987957943, 0.10526282311766078, 0.1623401798402998, 0.07749372657551235, 0.08131707448958492, 0.10038037288355195, 0.10223929557174438, 0.09980810773600957, 0.0763990792077428, 0.19148688701321448, 0.11231115357687027, 0.15283268530106364, 0.006685271713482321, 0.12231588228086332, 0.0678195899002445, 0.08544077657258164, 0.14171828697466937, 0.13952387748616368, 0.5792056157343418, 0.571055977526606, 0.5402463037395906, 0.5745154856057926, 0.5651729202688678, 0.5773815130744053, 0.6038898556255461, 0.591977131525385, 0.5955664487473944, 0.12192381277101882, 0.12218739404968126, 0.09208571115467434, 0.1914717597477562, 0.13585525274749377, 0.11274921058742615, 0.10560400322532182, 0.15770543158273598, 0.08319144163514613, 0.213107010842701, 0.4024487823322789, 0.19011888194807258, 0.35938208365704716, 0.29775110056962695, 0.21894762368030085, 0.26613112436397324, 0.5107997874185355, 0.2859543418358559, 0.5154860637266481, 0.40601012147031046, 0.49893221469881377, 0.3907467758782338, 0.4868466463076022, 0.388395307689513, 0.5496332920541016, 0.48868331086513495, 0.3031811695779175, 0.4184893678610314, 0.24746083770099192, 0.29209251765168465, 0.3245895673508409, 0.17725123345963711, 0.2795800130206417, 0.32790575485427775, 0.2529913744037161, 0.32647843995435666, 0.23808540869913075, 0.2412790160462942, 0.2830014548189538, 0.2099965921468394, 0.2512811752292915, 0.2760379115183469, 0.23970661751770916, 0.2296459108043103, 0.2220826226709124, 0.20355412923935856, 0.18641451121701735, 0.25563804439272564, 0.20228335448460122, 0.7875251544676246, 0.25131573539317054, 0.19842010254037423, 0.25260536133024447, 0.2119870517895731, 0.9271793848175082, 0.17745186061065032, 0.11324191867154076, 0.17262697608443345, 0.2015838403250798, 0.14853138268047683, 0.1357944840368538, 0.17002866289990437, 0.1540932955592269, 0.8880802609637266, 0.7661158449180667, 0.12787151814049758, 0.8940912619101061, 0.21113921477544806, 0.8580256755819784, 0.10511435543584813, 0.16983708880405424, 0.16816629706370712, 0.19793889071282134, 0.19951093220788985, 0.20085267457046485, 0.1918683117251887, 0.19603228653820393, 0.23097059379679563, 0.2340237996309964, 0.21084091063292598, 0.25654381880196064, 0.10083109407234692, 0.11467934548359571, 0.09476156466176877, 0.09807368232501446, 0.10382931714980537, 0.13128731209770883, 0.0903013578345555, 0.089428561678776, 0.100313536462593]}, "mutation_prompt": null}
{"id": "4893cb41-3774-4c4a-8421-e4fd14d4478b", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Stochastic parameter tuning for PSO\n            if np.random.rand() < 0.05:\n                self.c1 = 1.5 + 0.5 * np.random.rand()\n                self.c2 = 1.5 + 0.5 * np.random.rand()\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A refined hybrid optimizer using adaptive chaotic maps in DEPSO with stochastic parameter adjustments for improved exploration and convergence.", "configspace": "", "generation": 60, "fitness": 0.33082286795635935, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.29.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.8993443541615529, 0.9092925067359913, 0.9166604555549005, 0.8941949950440268, 0.8938237854038023, 0.9143608895693672, 0.9085349718498741, 0.9141212551110367, 0.899612629224576, 0.8005775929760277, 0.7452418911487894, 0.7927800676985743, 0.7963458041401896, 0.8042064079932116, 0.7781089475163028, 0.7967603313044247, 0.7670696326272939, 0.7878755254933099, 0.13421290772299854, 0.11798137298802447, 0.11401462378758676, 0.19090683193307167, 0.749044181130834, 0.12376137834340029, 0.1167771881880797, 0.14197965956812442, 0.18766182097262918, 0.06888995360980077, 0.05573265841257691, 0.07894946881905818, 0.11795135224633979, 0.18284487290774076, 0.15689197492066398, 0.11692797372335062, 0.13303632928378561, 0.11161578708705833, 0.9752261449346711, 0.9559850486971636, 0.9695287159448399, 0.9790196668042357, 0.9673389415413445, 0.9657757383280806, 0.9810591397215709, 0.9677371551947509, 0.9780595799867107, 0.8056593504538566, 0.6855523755842077, 0.0599726619643185, 0.7586972839875941, 0.7390971817273078, 0.7651457758997804, 0.7663942632338385, 0.7493032040342262, 0.7718395959661134, 0.22998835497205405, 0.3888704230395983, 0.1624432690063643, 0.2151273295370788, 0.28216133867210924, 0.2822598436699103, 0.3810214073597813, 0.23800188992929883, 0.23873951825478723, 0.27966519818295943, 0.2669164736998907, 0.25930420990553615, 0.2783704091187842, 0.1347406203925935, 0.278510030831257, 0.29614048547519334, 0.2699304722118011, 0.2922348964922544, 0.24818017360611333, 0.26264408623639834, 0.2589030582546694, 0.3250219913555299, 0.29887542199811257, 0.27172971802179113, 0.18949598389535327, 0.32338450400198504, 0.2721715211564416, 9.999999999998899e-05, 0.08140362327060724, 0.005047400670594282, 0.012175305829483452, 0.13828888352483404, 9.999999999998899e-05, 0.010852702463122865, 0.06334928812122975, 0.012742283803579113, 0.18853669617927782, 0.096665775726133, 0.10778044189957803, 0.05397225631520397, 0.12484351291307616, 0.027284752851995497, 0.13407933716846798, 0.1507516800899501, 0.07802864218325645, 0.26822334639255885, 0.09112949487988009, 0.11532026195477296, 0.09696032771439334, 0.07923369176902029, 0.08052530369395605, 0.14829544385750637, 0.09749215105108011, 0.07350538546132923, 0.11958570836248383, 0.13128922710522728, 0.14122171677337447, 0.006734287052872268, 0.276078202592993, 0.0712402288453331, 0.10287335482833093, 0.1684206823320208, 0.0847280809223615, 0.556884183648556, 0.5616450937596257, 0.5625646654162207, 0.5978117923856046, 0.20913548267356596, 0.6107520130565514, 0.5602961832497344, 0.6188961277594653, 0.6093816394292246, 0.13207206763891777, 0.11545553839414058, 0.0694125715378987, 0.08689720664097744, 0.13382074188822302, 0.11509203428374004, 0.09695406427809161, 0.11148239610479194, 0.09081392085581452, 0.2199736820800544, 0.5262765741477022, 0.23494533223915237, 0.3867301338365223, 0.2223727592892183, 0.27796126786946995, 0.20331558068606914, 0.20017632293049714, 0.4229644298674138, 0.6078474230990267, 0.39217837514876086, 0.21666102988564173, 0.538583349515865, 0.2506984131981391, 0.5032904403345131, 0.592566931622128, 0.5699866384569081, 0.1782550307089572, 0.23509901497869523, 0.18895763405728394, 0.2652772771995394, 0.24706326652296018, 0.2164958457496592, 0.2259322903261456, 0.21990920574037742, 0.23650485483290418, 0.30521302805353456, 0.24473879874196802, 0.2363922614573264, 0.22144269706554154, 0.2034111392943102, 0.2305144875645465, 0.188613023303414, 0.28475102072659364, 0.2217140226719394, 0.25165409549080564, 0.20048933025960747, 0.18305557683087315, 0.24963267398417743, 0.20073785281658363, 0.18935447042264675, 0.20229324545039418, 0.2527551118477942, 0.19354847841748202, 0.18892249939033967, 0.9045510907348544, 0.1786405920604408, 0.15405739954811193, 0.1695420400387715, 0.20112906020552945, 0.9376332057852922, 0.09989830516553444, 0.17002303506000904, 0.1544517730455931, 0.1688345904475398, 0.21354020392701256, 0.8450932691335428, 0.9164535105195304, 0.21281478231250894, 0.8459194472168517, 0.10527506518899388, 0.16911213783184065, 0.16750174632467862, 0.20332755746700126, 0.18728500698518924, 0.21401191858742963, 0.19953779571062102, 0.22029387414710933, 0.19902849666466227, 0.24596068502525092, 0.2082133133631764, 0.2197913000890559, 0.10527664265611802, 0.09331074879798384, 0.08335600078547378, 0.0839942913145556, 0.07983965226024425, 0.09447263181508458, 0.10791896441175908, 0.09830043077726858, 0.10754796097385555]}, "mutation_prompt": null}
{"id": "3263c9fc-adb3-471b-990f-b430ed64c002", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO_Wavelet:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.7  # inertia weight for PSO\n        self.c1 = 1.7  # cognitive coefficient for PSO\n        self.c2 = 1.3  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.8, 1.0)  # Modified chaotic map\n\n    def discrete_wavelet_transform(self, x):\n        return np.sin(x * np.pi)  # Stochastic transformation using simple wave\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n\n        while evaluations < self.budget:\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator with wavelet transformation\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                self.particles[i] = self.discrete_wavelet_transform(self.particles[i])\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n            self.iteration += 1\n\n        return self.global_best", "name": "EnhancedHybridDEPSO_Wavelet", "description": "An improved hybrid optimizer enhancing DEPSO with adaptive chaotic maps and stochastic discrete wavelet transformations for superior diversity and convergence.", "configspace": "", "generation": 61, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"'EnhancedHybridDEPSO_Wavelet' object has no attribute 'iteration'\").", "error": "AttributeError(\"'EnhancedHybridDEPSO_Wavelet' object has no attribute 'iteration'\")", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {}, "mutation_prompt": null}
{"id": "b9358f42-aadc-4dcc-b452-569ed4f6010e", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def adapt_parameters(self):\n        # Introduce dynamic adaptation for scaling and crossover\n        self.f = 0.5 + 0.3 * np.sin(self.iteration / 25.0)\n        self.cr = 0.9 - 0.2 * np.cos(self.iteration / 30.0)\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n            self.adapt_parameters()\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A refined hybrid optimizer incorporating dynamic adaptation in DEPSO for improved exploration and convergence.", "configspace": "", "generation": 62, "fitness": 0.34253309455547254, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.9020226142551024, 0.9130476196014461, 0.8706199449451413, 0.9034716681669314, 0.8817404787036021, 0.8982841867591331, 0.8858196654708665, 0.8905369061598887, 0.8917540937613535, 0.8014809945360074, 0.8151233308594897, 0.7783417449850086, 0.8060671416015721, 0.8125380912552244, 0.8141089905788018, 0.7655542836014106, 0.7162912857483335, 0.7933904108292164, 0.16157343420488046, 0.14098112670385, 0.08177956778966344, 0.1441130973449839, 0.14550001544754831, 0.11130392118619092, 0.11200340649462082, 0.18543308494602484, 0.16125099236914453, 0.09099299804898908, 0.06977284451264609, 0.11920754127716737, 0.11685056737077537, 0.10064024412842354, 0.0718840676407817, 0.10006607972595705, 0.16212309762245347, 0.12487856730237856, 0.9808696236307675, 0.9752932294296462, 0.9642347155012576, 0.957425912475737, 0.9664293093819202, 0.9788549534510637, 0.9681466268473964, 0.9691682972575555, 0.9792972601530562, 0.7893277214520343, 0.7295668171582876, 0.7832690149253103, 0.7535328293244888, 0.7568989096150417, 0.7837755942601126, 0.7714553396304091, 0.08849951715782167, 0.792155032760889, 0.877269905682027, 0.14136885084803053, 0.22894661156424523, 0.2786886153917725, 0.2820437359054939, 0.386960827797057, 0.23785718023383506, 0.3861806677287738, 0.24446526965407334, 0.13266261160795856, 0.4254113167199687, 0.1338988442632253, 0.3024570644036355, 0.3685303752446768, 0.43680567261587855, 0.29805026563620063, 0.2985808785830998, 0.300610526464973, 0.28822632366314027, 0.13504047635393768, 0.29863931705525815, 0.29192312566887335, 0.28159347240622445, 0.29920124524140923, 0.29107170934864424, 0.3041211673407769, 0.30181986360600244, 0.0566406585958974, 0.15216099530791816, 0.05968874516466294, 0.04468502367718463, 0.05012008126838685, 9.999999999998899e-05, 0.010121119942631984, 0.06383007276967712, 0.0003658279098653905, 0.13138671921428557, 0.20006757117381857, 0.08109942075378362, 0.05547706588743162, 0.023628845701064716, 0.039137516566790875, 0.09161540373284682, 0.12258159216512599, 0.12393869997471607, 0.1374353927019698, 0.06535909900328407, 0.09040518298849143, 0.12351496300353648, 0.1413235116081023, 0.17431882073471316, 0.2175951039411076, 0.22885094640858983, 0.18972330486719835, 0.3121789937937003, 0.16612639695307774, 0.1752015121901883, 0.06796153395077986, 0.25640002828939923, 0.22645539765220057, 0.08426775602931358, 0.06259828733168638, 0.12109389570555817, 0.5575233859172021, 0.5536125724240861, 0.5609555852464457, 0.5985738347943642, 0.5920409396920889, 0.6015397004367549, 0.5906198836284433, 0.6057720173084601, 0.6427818577095858, 0.07991526336013743, 0.1621473103848311, 0.0837233411871875, 0.16007522715681932, 0.06398648457283129, 0.17917055764280798, 0.12328177975941113, 0.14788367767605415, 0.10519515853094419, 0.17107676836516783, 0.17771498508059136, 0.49968785307545815, 0.3356081550217317, 0.43158475298919485, 0.21031517007528755, 0.21442102398126683, 0.38328858096073115, 0.22566305029682177, 0.620377192437747, 0.45915902418322563, 0.32759383649626617, 0.3489430975550952, 0.19885215056987715, 0.3775716408955093, 0.5784142924860405, 0.31690147284584, 0.37972196202930186, 0.39037263154492463, 0.3150665846242302, 0.22049545695386563, 0.2181345311145445, 0.1803537463188868, 0.24546745403940295, 0.17543964703531578, 0.25261260883341985, 0.19723724676901488, 0.22227373666123884, 0.21999644953612896, 0.2032430064446743, 0.198495697719983, 0.23815275797895774, 0.23484696152789708, 0.2594502569469751, 0.23737396805711874, 0.1905546175823346, 0.19894234690498191, 0.2264049630248639, 0.22762823597332438, 0.22692138658260141, 0.19240667268732803, 0.19984647505636466, 0.20883565378339997, 0.19838591076803969, 0.1902600828317108, 0.17799729928025299, 0.1880562397473401, 0.15422679147246632, 0.17283076252130647, 0.20192839240474736, 0.20109345256451294, 0.15334500125215766, 0.16988482110587555, 0.9508162315577039, 0.8087396416987331, 0.8709180024061646, 0.7887176133076175, 0.7769391337882319, 0.7920525102953757, 0.78501463116648, 0.10520896276278069, 0.10522455328670133, 0.10528919341944964, 0.2276414287531502, 0.3513928867706513, 0.1955946316181667, 0.20438145849837197, 0.21881736270453755, 0.19905529768568764, 0.23470398564871142, 0.22394807362876035, 0.23928562842669499, 0.11288571946499282, 0.10091589064207751, 0.07767160278739849, 0.10118040273213136, 0.1133591203124884, 0.131704676056427, 0.09583481596679844, 0.08753553821732984, 0.09943377761867656]}, "mutation_prompt": null}
{"id": "f95b67e1-b72d-4f93-b759-46695110da47", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.75, 1.0)  # Adjusted chaotic map for better exploration\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.85  # Adjusted inertia weight reduction factor\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.6 + 0.4 * np.cos(self.iteration / 50.0)  # Slightly increased cognitive coefficient range\n            self.c2 = 1.4 + 0.6 * np.sin(self.iteration / 50.0)  # Slightly increased social coefficient range\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A dual-phase optimizer leveraging chaotic maps and adaptive parameter control in DEPSO for improved search efficiency and convergence.", "configspace": "", "generation": 63, "fitness": 0.3462223290651194, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.29.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.9007353835382533, 0.9043659752519595, 0.9171681966744403, 0.8854022548624849, 0.9108089357909017, 0.9027330208204966, 0.9150195849298327, 0.906197404466813, 0.8956627107438717, 0.8174741005920751, 0.7670861785973532, 0.788040490470904, 0.7973715719410654, 0.7776804209935193, 0.7926025096947931, 0.8148984852860409, 0.8123513336364921, 0.8413516322040782, 0.1570436893238062, 0.11167945243072319, 0.12945543850823482, 0.15636295990508242, 0.11092326260771057, 0.1627343682143899, 0.1861871712017119, 0.1395526054441103, 0.15521315008155634, 0.11121532970561654, 0.0845473952341319, 0.11011409643721615, 0.11012560176369823, 0.08620085472005845, 0.15209684173011917, 0.129271884027634, 0.10969944837843992, 0.0643598840145101, 0.972887442677802, 0.9588234667395279, 0.9529819206462868, 0.9842880074089589, 0.9774917736584738, 0.9756245419286562, 0.981847407593757, 0.9727553868464949, 0.9812010720854372, 0.7711936152481853, 0.06029095505067383, 0.6895605186148726, 0.7127769582196348, 0.7449793669027529, 0.7386831776184186, 0.7294161226932425, 0.7425142479700036, 0.7910870286278355, 0.17233116996950215, 0.22967185422535374, 0.1390192523889795, 0.1945693945198962, 0.22189440699198426, 0.35767474586285974, 0.2337898655692151, 0.8807477774486612, 0.4076967445003976, 0.26050449650822516, 0.26418583869489864, 0.29171085157209253, 0.324076872464086, 0.2727123018484533, 0.27957334113214716, 0.2822712280885371, 0.13233671079670095, 0.3486016531569569, 0.2677018701075834, 0.27946025438074884, 0.2392753898039891, 0.2908831996678105, 0.32422090633710354, 0.30900495790254523, 0.3197401736315857, 0.11810543208010205, 0.2994610292420343, 0.08154615418100475, 0.022769113889668735, 0.061931204585157884, 0.05894215254638713, 9.999999999998899e-05, 9.999999999998899e-05, 0.0023579237473353443, 0.006031505818408722, 0.08205373866519616, 0.11681857041685673, 0.18435100626963807, 0.09357964780750883, 0.07149874171424542, 0.11045368304374192, 0.03558589036590942, 0.0817513356947035, 0.10011172946648206, 0.11146230148274494, 0.23248134816771604, 0.1468902368540025, 0.050608213618539066, 0.07883606982826064, 0.07947554064171758, 0.12551982406874962, 0.18905197200732482, 0.10322921673918994, 0.08244362890998613, 0.12641611333642921, 0.047610642773542766, 0.10550635634863992, 0.4307165334372822, 0.2795195248349178, 0.028357534136147278, 0.1239197229675919, 0.19042647067753793, 0.10968622725221189, 0.5585366802769789, 0.5579036156385561, 0.5779498030279401, 0.6245844168793381, 0.6164482219618495, 0.641352321908202, 0.6247172191655331, 0.6256970376856559, 0.699268766174393, 0.12921713225079712, 0.1443708438951764, 0.11425627032878727, 0.09972705432857198, 0.10895831297084246, 0.12283075541700639, 0.09621397826552402, 0.12563841155481825, 0.13326778142658913, 0.5315607277622485, 0.7039831873340223, 0.21269026086508003, 0.27621195549407185, 0.27164013626738315, 0.21922745350925643, 0.26844385117804803, 0.3431847915559453, 0.1959358135689564, 0.4727005301151389, 0.36751364035103073, 0.4709112575742309, 0.5727270979743699, 0.4655991381998209, 0.4010430343203578, 0.2691947616857917, 0.34801062634382984, 0.2233557096504123, 0.3764817236319259, 0.23207599194945505, 0.24529400888460617, 0.328084249613388, 0.19300791439785203, 0.1559007214171526, 0.1778169393277267, 0.2961793907274052, 0.2783830382533633, 0.3181708105144455, 0.24387895809091387, 0.21399145406195152, 0.23512651872858092, 0.25285605562862534, 0.2170936770035815, 0.2579673084779801, 0.22321055142699098, 0.2210665330958138, 0.18471127787961017, 0.22609071677174386, 0.19807619138490296, 0.8378317755392019, 0.24920778895260154, 0.19888756559317344, 0.22350870660138178, 0.17066265596431096, 0.1957938310131886, 0.9264919629164056, 0.17632248915558635, 0.15341577963932762, 0.9364773957152945, 0.9425213686381922, 0.929227879012052, 0.13660807366437278, 0.17000246604538294, 0.15324708846757562, 0.8664501730355164, 0.8024487650559402, 0.11268642720710087, 0.8688836911334203, 0.2105791034506832, 0.2935194664523857, 0.10513653008623536, 0.0831293606491803, 0.16682646411099755, 0.1861594355154973, 0.21072599103972967, 0.20362177028900907, 0.18678981997483235, 0.1839852770560002, 0.190947709225747, 0.1974497277709446, 0.2291541376159385, 0.20269516871498638, 0.12039082934279466, 0.11103642989028872, 0.09261013384556938, 0.09774883630680398, 0.10997089319979603, 0.11817836715551444, 0.0938470959191654, 0.0968559555141223, 0.1061538334726091]}, "mutation_prompt": null}
{"id": "61167fd5-650f-447f-b36c-d769b04f0e92", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A refined hybrid optimizer incorporating adaptive chaotic maps in DEPSO for enhanced exploration and convergence.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.8865276906432433, 0.9020532548803202, 0.8929687050976703, 0.9069966467491789, 0.8983603223003787, 0.9022140074472543, 0.8838639783889877, 0.8886653828703049, 0.889752534826144, 0.7567698703303883, 0.784578368098034, 0.8076249809202548, 0.7611720006041811, 0.7986347352301275, 0.8050952302753023, 0.7936777043904858, 0.8107862909162267, 0.7638655686477411, 0.14306028296887274, 0.18771148863225673, 0.09076269380504487, 0.14472904467535863, 0.18827718037504793, 0.14600008067707715, 0.18654152199131935, 0.11161280818292418, 0.11200366762783509, 0.13393502172957683, 0.14641399913557107, 0.1432167792015192, 0.11181421186718143, 0.09209417505561412, 0.11938418806199658, 0.11206983601831055, 0.11095636186680169, 0.10912525701701048, 0.9717271359469163, 0.9628507846149675, 0.9377341630520235, 0.9810288407887259, 0.9785915503130439, 0.9770423747813494, 0.9783473338829307, 0.9712621930647505, 0.9787075504592555, 0.7607315187580301, 0.7749069267760285, 0.7630288578874603, 0.7507532481153396, 0.6554370351125884, 0.7762723104136083, 0.7499504173558014, 0.6968283959747328, 0.7389586451693928, 0.1721225825938858, 0.22891630584450517, 0.11324758049764427, 0.3549737812815622, 0.2807957237653095, 0.28145549322917607, 0.18018767969655092, 0.2386988483653335, 0.9395469978455472, 0.2720537562684263, 0.1357109215500677, 0.288515417628357, 0.27358595508171457, 0.28033933355072405, 0.3483295090039492, 0.29980271067857245, 0.13457278726329025, 0.31624018099324525, 0.28347106445129555, 0.27653913969396915, 0.2892909131254505, 0.32904479577095047, 0.30792895015902, 0.3267380918354402, 0.3033156492629593, 0.2088685743639237, 0.2906120113344278, 0.004881953303818798, 0.08432094844164972, 0.01040324864575648, 0.08307057080589308, 0.0631748299553836, 0.031141171943307566, 0.038932547461408507, 0.021942713170019723, 0.09321589178997347, 0.14820762824482314, 0.14111157929981544, 0.09939347465031478, 0.07351212675576657, 0.14911297504852605, 0.02739581001833591, 0.11477783328277313, 0.09375370099990121, 0.12437319484907039, 0.07875046545806708, 0.12463510807347011, 0.14210128121458188, 0.07919284437097684, 0.0801485337679555, 0.13337703281066082, 0.19524821804991244, 0.10442299933492127, 0.07342327849013242, 0.16578167026123625, 0.1853016315404299, 0.1189542819871422, 0.1574945670012905, 0.18360986723287642, 0.2558817728796652, 0.12448657793629136, 0.25405459307747846, 0.1254414517844874, 0.5407077538029146, 0.6006067397749144, 0.5396897498932287, 0.5489927270360135, 0.5891834596503931, 0.5459801886932765, 0.5877025571595188, 0.58912009886935, 0.5796039758319813, 0.07975439706166598, 0.10110173168052605, 0.0755122787624074, 0.16076138881367696, 0.10587421420661025, 0.09908423757627094, 0.11384860622149795, 0.14412899438570692, 0.10610491466439798, 0.22279569248288034, 0.6592237296261918, 0.22467227789135458, 0.27264975790467794, 0.42228702264236595, 0.4427009503531557, 0.5283272114477804, 0.21131508909474783, 0.3463028054853772, 0.5602848907432856, 0.5870043317671049, 0.24980633166770938, 0.37827330003298987, 0.3159543684158136, 0.3948951692827499, 0.5338080159903202, 0.6386237352364159, 0.19094651398173923, 0.2682466646833648, 0.24944249579405708, 0.20048413900667417, 0.3126123000671225, 0.19508244130654495, 0.2440464616149688, 0.2746657038803456, 0.2758095868983087, 0.1718425074209099, 0.24221577925087046, 0.24277264917923613, 0.22753707311652804, 0.21621523555871425, 0.23220195984323055, 0.2121859746984508, 0.22233176434332813, 0.19428032015735874, 0.2940143940691601, 0.18346601962379372, 0.2507595245585167, 0.2074744620231186, 0.2296346173180046, 0.7839070787440949, 0.18887893138201983, 0.19948332275076253, 0.2261375176508097, 0.19661374747919813, 0.9185297033957897, 0.17730516387770456, 0.11326657578340704, 0.17278331750195008, 0.9190619999789291, 0.2007124882642538, 0.0996663158636657, 0.16991723780351253, 0.16271709766976927, 0.8243727383661772, 0.8166819556788825, 0.7311027166633209, 0.9133133255502286, 0.8484364245717022, 0.7770450456081295, 0.10514634504197418, 0.1699183301713061, 0.16636178423956227, 0.19554443874623362, 0.24430239869142467, 0.21100720171394982, 0.1973610633324807, 0.25121027229113, 0.19102423719310313, 0.2563067934359131, 0.23300659057012685, 0.22269509176237645, 0.08892873400730372, 0.07113752042749677, 0.11154483811644855, 0.0966630146129761, 0.0829219834948779, 0.14774202050214513, 0.10337404775080683, 0.10543583486427055, 0.09783716494350791]}, "mutation_prompt": null}
{"id": "e8e99987-ee32-470d-941b-200d1c439246", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f_base = 0.8  # Base DE scaling factor\n        self.cr_base = 0.9  # Base DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Dynamic DE parameters\n            self.f = self.f_base + 0.1 * np.sin(self.iteration / 100.0)\n            self.cr = self.cr_base + 0.05 * np.cos(self.iteration / 100.0)\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A refined hybrid optimizer incorporating adaptive chaotic maps in DEPSO with dynamic scaling and crossover for enhanced adaptability.", "configspace": "", "generation": 65, "fitness": 0.34028208347265604, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.8974402987372474, 0.9264973219914425, 0.8907612323271448, 0.8929249320648185, 0.8913155456115409, 0.9072089523077165, 0.8915217450861688, 0.8968217182302771, 0.8796280256355922, 0.8006248507007105, 0.8040413372570907, 0.7885672809662452, 0.7724767725452574, 0.7826843767657895, 0.7914037889246619, 0.7691674506508386, 0.7703793516379999, 0.7818159722035468, 0.14354586446793638, 0.12961144403303915, 0.11065979277027127, 0.15704112365634848, 0.13375213511303374, 0.18998694606592648, 0.1100800302301459, 0.12214694331063569, 0.19074515706749595, 0.13529861689732847, 0.08505597250045394, 0.09646283029646563, 0.1439216369033569, 0.09550220676920251, 0.06908353151067936, 0.055487558385767244, 0.08882752044307451, 0.12223282694801751, 0.9700078985984791, 0.9667003860937678, 0.9660387575401531, 0.959941744101995, 0.9696433878845981, 0.974039560427888, 0.9665962256631784, 0.9702826161000513, 0.9646690093587313, 0.7572442748198938, 0.7260375626196456, 0.7090747162802965, 0.7573384157531493, 0.15426808687520188, 0.15308503992998013, 0.7573732911965647, 0.7273729405072507, 0.7451867618094036, 0.217438846801567, 0.8846360187691498, 0.13654804836204293, 0.21369949071007188, 0.19507903338096877, 0.3789783931410152, 0.2377305106951081, 0.23826469645864068, 0.8769426059687732, 0.28496896780344716, 0.19603786146137459, 0.27004095149814866, 0.26499981054313193, 0.27685853153503215, 0.2502745581714354, 0.30208106411906865, 0.13705116129177208, 0.2247884840438953, 0.2734320368030835, 0.2672906061074002, 0.27512959023805894, 0.33415737215250185, 0.3042262461098981, 0.13549439643258865, 0.30368532467804843, 0.29016884120547726, 0.3039073427887401, 0.00260390005796729, 0.12138852438003289, 0.016669767309671624, 0.015256224852248867, 0.08227503650581836, 0.02460464821347763, 0.0004200285119427827, 0.02034603462958784, 0.0674388213928987, 0.11847547411529669, 0.10443370066922708, 0.11480086667618394, 0.08104122459297158, 0.13910124064656815, 0.04764076501122583, 0.22691083559031888, 0.097387644467405, 0.11950882119957262, 0.10805720294381949, 0.10551083456445687, 0.07455478306837338, 0.25463712737051025, 0.07916528374462473, 0.20279962614301217, 0.21297495617656503, 0.17194817993260092, 0.07346469173065506, 0.25872535157211696, 0.2640253280828757, 0.2137649956958959, 0.16976505584761126, 0.07861571761048458, 0.11395543978812073, 0.08437302235388866, 0.10881212481831737, 0.08537130100082047, 0.5624365359756234, 0.6164927850213541, 0.553503783323883, 0.5602957977581116, 0.6223885993924495, 0.5583750622284553, 0.5774881880442255, 0.5698150162366037, 0.6325262839403281, 0.09108496922183495, 0.09612252320458303, 0.13235384297671626, 0.13060532614089404, 0.06855294406697576, 0.10033472100101348, 0.08517663778520468, 0.11583905986138221, 0.1256122208746263, 0.2316423450171765, 0.21404412071447543, 0.20610203283011375, 0.2783826237849718, 0.6584790016030033, 0.23487191848667388, 0.4062534969573147, 0.21255788574472856, 0.349282614697774, 0.40545029326629023, 0.3608485424445429, 0.5206934970289034, 0.5711237728075544, 0.3339023981475542, 0.43463879857264875, 0.5903658578178548, 0.6703421947172687, 0.43760144648069776, 0.36887242918879815, 0.19258514571452934, 0.23266748289715156, 0.32268893266082455, 0.2368644397906875, 0.2511253339318055, 0.2634108341634117, 0.3715801124151721, 0.30013786750589055, 0.22754963853570342, 0.21098724820057857, 0.25547157430049916, 0.2707666859846938, 0.22646601470212646, 0.19352342534518552, 0.23876958901082412, 0.21595412050654827, 0.2124990667807216, 0.18607332726798154, 0.21154986067480763, 0.18580161847796317, 0.24979880513244512, 0.25045963292935003, 0.20319587119531912, 0.18844680340744102, 0.2107209086339329, 0.1891530330940293, 0.9483749153186617, 0.17764361573166443, 0.18847251642532348, 0.9212486036648654, 0.9312368437178514, 0.20134672287636213, 0.12299982676133603, 0.16997055995995614, 0.14855403599425665, 0.8223280385663907, 0.16987507888582953, 0.8108614085038629, 0.8585320393472538, 0.21246170870214398, 0.21133644343524316, 0.10528931128755525, 0.16992579152892817, 0.10481025721452075, 0.20712303456017822, 0.21245638117542398, 0.18481442040689877, 0.2153324226936324, 0.2078107834593924, 0.20330021743745474, 0.21069457019267013, 0.21781372569503366, 0.2412170403023125, 0.08752848877996844, 0.10071801488328924, 0.09454128520366956, 0.10354037903052216, 0.10605298906711591, 0.1355495119749861, 0.08639859227222457, 0.08825343463458979, 0.0954509406690004]}, "mutation_prompt": null}
{"id": "21ec8021-89ae-46b2-9e49-7983c5156604", "solution": "import numpy as np\n\nclass AdaptiveDiversityHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-4\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.var(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 30.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 30.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "AdaptiveDiversityHybridDEPSO", "description": "An adaptive, diversity-driven hybrid optimizer using chaotic maps in DEPSO with dynamic parameter adjustments for efficient exploration and exploitation.", "configspace": "", "generation": 66, "fitness": 0.33683638126112647, "feedback": "The algorithm AdaptiveDiversityHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.28.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.8981090599776032, 0.9002073915311983, 0.9101927693578651, 0.9046630248706935, 0.9058347258789635, 0.9099291898528022, 0.8958058608862549, 0.9162334128000933, 0.9163939125099676, 0.8096641762158743, 0.8114418030449941, 0.8162208248896216, 0.8131731781065806, 0.8026661904758912, 0.7704623956919989, 0.7916247902197556, 0.8127471170408632, 0.7822461543116146, 0.11467814267106202, 0.12678194764691852, 0.13183138639611247, 0.15826966822046284, 0.11109212865176155, 0.18652091131655069, 0.1434118547865586, 0.11371150836749933, 0.12957934675509108, 0.11055175188409616, 0.11171241607883331, 0.15815523278013877, 0.11033744891766528, 0.11454247725395494, 0.13226230402500572, 0.11601667715006858, 0.12342082304402668, 0.0783840819256828, 0.9717277309866341, 0.9630241043936779, 0.939175468218838, 0.9810273581480964, 0.9785896692878397, 0.977077347353066, 0.9784155540794035, 0.9712628525791438, 0.9787113282700965, 0.7239035845623072, 0.6591332643577064, 0.6050770997823621, 0.804844678984606, 0.15363156204406792, 0.6231160172962249, 0.6470171062535519, 0.7053717198264143, 0.810833190922201, 0.35389134200487427, 0.22981503484866028, 0.16841303455294, 0.19369177741741328, 0.2149338396577789, 0.28120584445544305, 0.2387003776118719, 0.23880420539733682, 0.9212916649016913, 0.2210077095552102, 0.21604451060742957, 0.21825147410938972, 0.22314313784887208, 0.20679282835133095, 0.2967743981964607, 0.2500996970584287, 0.13421562927128383, 0.2192952299040477, 0.2069451469188781, 0.2184549665814035, 0.24188615478992503, 0.25033769113528426, 0.26243740507800817, 0.13103205711509214, 0.23545021756781992, 0.25555578111325217, 0.2563797008554901, 9.999999999998899e-05, 0.037281309541305596, 9.999999999998899e-05, 0.0798517805762915, 0.08796008968718239, 9.999999999998899e-05, 0.010973947172896792, 0.16398654320811934, 0.014120849608493913, 0.1434481931162238, 0.08907766477697765, 0.08391034586768398, 0.07153378965466439, 0.09329242271023463, 0.09221421351771986, 0.13958401979320134, 0.10694741959288034, 0.10510395540248141, 0.0629373148252762, 0.0992574918959479, 0.27814429240394467, 0.07950760800562351, 0.07958383377674494, 0.21952143277377734, 0.24969318132514606, 0.10095992541517951, 0.07707613873358732, 0.13968036811249107, 0.14625638764923277, 0.14199304213912578, 0.1380393680090115, 0.19251825772666897, 0.3788243895142679, 0.24475390463379687, 0.23792375676220545, 0.12933755657558543, 0.5206730406813136, 0.5607220290653234, 0.6082453288021852, 0.5873288761759554, 0.5997907298784877, 0.56378112617289, 0.5550229402540112, 0.5259608970209901, 0.5655065105737882, 0.08227694752215098, 0.0861899414279289, 0.10149554461919774, 0.18287263822570798, 0.116126966520402, 0.08249033510100945, 0.1152790553779447, 0.1573371699378877, 0.10167549920561691, 0.28138281883525973, 0.2649205083590347, 0.15551608251583382, 0.34072076276610264, 0.34764408876774733, 0.2653812234475105, 0.25932535203904095, 0.2015295576223739, 0.2732757696900976, 0.36540676810662365, 0.4732199217290286, 0.48675178673471287, 0.4735317241671755, 0.5118754358356257, 0.301421629876657, 0.3564664503594247, 0.4308027951575144, 0.29717820841978515, 0.19197686659148339, 0.2941215942215546, 0.2134370202253959, 0.32757196806516775, 0.2078291743675018, 0.2504867800787207, 0.2078144089486189, 0.20380768939153082, 0.27552048608214463, 0.23584981614740075, 0.24144143841653387, 0.2309277322708374, 0.23561263164600965, 0.2491750448191974, 0.222623795814902, 0.20805282080886, 0.25469067333824247, 0.2455706676325522, 0.19901712029947727, 0.1775112977362534, 0.251991595093098, 0.21216940632876846, 0.229540341786035, 0.22716071654512415, 0.22200630643964192, 0.19463862689159628, 0.18791766982190783, 0.9126377051338429, 0.1778119214078573, 0.11326592106938582, 0.17276141051334148, 0.9342574418752437, 0.20043367737735007, 0.09963269959951848, 0.16992280321758824, 0.16233920741077967, 0.7483060056602839, 0.7478341339069114, 0.919612561898695, 0.8087589012312162, 0.7411185095450334, 0.8370913112836049, 0.10512718110021646, 0.16991829512967505, 0.1672047130417783, 0.20432005549027177, 0.2118424026972462, 0.18991293970855538, 0.21058039988375454, 0.22037512476218213, 0.21016327724738626, 0.18846194007267547, 0.22582502197635657, 0.23095047867255347, 0.11862917590001454, 0.09772292374022051, 0.11770371396180312, 0.10959730698476555, 0.1010125636543886, 0.13827218017345955, 0.09824134263077344, 0.08622328651202293, 0.09993829284171629]}, "mutation_prompt": null}
{"id": "4fc9d3b5-2827-4e55-bdef-93143dd4fbbd", "solution": "import numpy as np\n\nclass FractalChaoticHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.9  # DE scaling factor\n        self.cr = 0.8  # DE crossover probability\n        self.w = 0.4  # inertia weight for PSO\n        self.c1 = 2.0  # cognitive coefficient for PSO\n        self.c2 = 1.7  # social coefficient for PSO\n        self.vel_max = 1.2  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-6\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.8, 1.0)  # Slightly modified chaotic map\n\n    def fractal_perturbation(self, x):\n        return x + np.random.normal(0, 0.1, x.shape) * np.abs(x)\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence and fractal perturbation\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial = self.fractal_perturbation(trial)\n                trial = np.clip(trial, self.lb, self.ub)\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.95\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 2.0 + 0.3 * np.cos(self.iteration / 100.0)\n            self.c2 = 1.7 + 0.3 * np.sin(self.iteration / 100.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "FractalChaoticHybridOptimizer", "description": "A tailored hybrid optimizer combining stochastic fractal search with chaotic maps for diversified exploration and convergence.", "configspace": "", "generation": 67, "fitness": 0.3306758725661186, "feedback": "The algorithm FractalChaoticHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.27.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.8636493584762535, 0.8758937070843354, 0.9085887471700533, 0.9019788811837832, 0.867929438458579, 0.8967572582338368, 0.8990715580728453, 0.904251544262158, 0.8952061576659811, 0.7437712060549094, 0.6816619307184085, 0.7693182909331335, 0.7331970193844372, 0.732650997982885, 0.741098885962894, 0.6832489725725118, 0.699680037175165, 0.7557817920892227, 0.17674856846013953, 0.18706609455726342, 0.1496024127550465, 0.1578975797375871, 0.10098414629883978, 0.1537841902213679, 0.1276952546428829, 0.12387389174587593, 0.14795993449201583, 0.1402578166683054, 0.09477359151411424, 0.12472943216601107, 0.11484872639738009, 0.10812921683740406, 0.13972890272075145, 0.1164137302266387, 0.13840222465545426, 0.12248474064430337, 0.9779138555554879, 0.9625932777789892, 0.9600016981504792, 0.9735378162081968, 0.9605785098136722, 0.9816370943091203, 0.9704021493205637, 0.9678311684562001, 0.966769037632847, 0.5050039619856213, 0.6317861850127384, 0.5979202972782087, 0.587274220395108, 0.5668321944927545, 0.562903561864486, 0.5426064767411194, 0.5227740138047972, 0.5767090355730233, 0.8307892804300879, 0.22852058931011954, 0.7600689259914789, 0.2783089435502172, 0.3630641139856753, 0.9221266883400191, 0.23370318358577113, 0.23620787702827828, 0.8879384130339414, 0.13156272265168356, 0.18912843799590917, 0.1890667855711966, 0.19840170478347785, 0.20066832775868215, 0.20932590603620616, 0.3395958460498315, 0.1892150983866443, 0.20787746972686771, 0.22411182231587312, 0.20907056988350892, 0.22836628013493332, 0.20477337501479342, 0.2217621215637401, 0.2144097275442205, 0.24968679016075457, 0.3501868980578098, 0.1291031004460823, 9.999999999998899e-05, 0.03208344438800137, 0.03905668507652804, 0.01571885075700208, 0.0068087912649045235, 0.05983008813429447, 0.0507778684947805, 0.13467107193352257, 0.13345956718380347, 0.21492366230996818, 0.08109176222554049, 0.1189703233936571, 0.08121839810175147, 0.08723387829282692, 0.024462398659538698, 0.0578282591656456, 0.11082149572569633, 0.06955619022095183, 0.08365138863248844, 0.18185398391395002, 0.33513433797733383, 0.0805938328396234, 0.1191279012244455, 0.14327248491410283, 0.11610962383145484, 0.21705373116748228, 0.23442947401154002, 0.11875818187507337, 0.24304007072932143, 0.19984832887188564, 0.23839892303361043, 0.0395639000938921, 0.07823421635329719, 0.13382616921548285, 0.08264094443889047, 0.35425664876543494, 0.5385773094109993, 0.5156528400802753, 0.6105543577012056, 0.6129168276677954, 0.5492044095642928, 0.5382622864110912, 0.5549407872103373, 0.5268252846526206, 0.5623320650518963, 0.15634013926552892, 0.13729675377618167, 0.12165298091122145, 0.08298659994645619, 0.16156017668417133, 0.09853588380600686, 0.1515788627645991, 0.1712500612825104, 0.083074957037919, 0.19309212768774586, 0.36450304485600316, 0.27254904997995755, 0.26048480405259966, 0.25014935750267553, 0.2080712436581691, 0.257510495389942, 0.4336250889303298, 0.31664878668195784, 0.40111901392471294, 0.43299368554098605, 0.37767314669650753, 0.38942871185910755, 0.45789143412518474, 0.2563957822298186, 0.37173997942310577, 0.3200134969350633, 0.41646204905787987, 0.17635556039761868, 0.3219416285724257, 0.1631585375220217, 0.21895027297215408, 0.3314914749613843, 0.21224150883485493, 0.18122893002948215, 0.2875671340770156, 0.2697932224982478, 0.2481456539302318, 0.2175347519888936, 0.21258178624576873, 0.2080696462299111, 0.20682243039489845, 0.23287328957972298, 0.21306029616939093, 0.30119864496414095, 0.28636008544938507, 0.1901780127382382, 0.7757600598377894, 0.21221545604841108, 0.23025959664548945, 0.2100244817976149, 0.47490374217684617, 0.19021426039552436, 0.1831166607783583, 0.1851884445311267, 0.1594324799739043, 0.13117425938703475, 0.1538139705948688, 0.9258411007858973, 0.20123708446835198, 0.9099024506366524, 0.099914348530865, 0.17037362929615152, 0.15353684221718977, 0.5857949133365504, 0.213862648929112, 0.15483594996046846, 0.8431456941955909, 0.1693654986152232, 0.16984021807750882, 0.10533059223021068, 0.1562559914705942, 0.6760116008837704, 0.21174540416585375, 0.19249518611065863, 0.20575514098449488, 0.21995297049403228, 0.18627673107505682, 0.19508052817049026, 0.19635939618100906, 0.1803129050319261, 0.19479136492457405, 0.09556275825688587, 0.07644451138753561, 0.0813032249638369, 0.07754218439117866, 0.09285497940995924, 0.11981884081349903, 0.09247103403026435, 0.09216615829663932, 0.10061776132825584]}, "mutation_prompt": null}
{"id": "7e2cb3b6-122b-4ae6-9ec7-4131b195529b", "solution": "import numpy as np\n\nclass RefinedChaoticHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.85  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.7  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7 + 0.05 * np.sin(x * np.pi), 1.0)  # Enhanced chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity more dynamically\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n            else:\n                self.w = max(0.4, self.w * 1.01)\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "RefinedChaoticHybridDEPSO", "description": "A hybrid optimizer integrating adaptive chaotic maps with DEPSO and improved diversity control for enhanced global search.", "configspace": "", "generation": 68, "fitness": 0.18459693026725912, "feedback": "The algorithm RefinedChaoticHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.19.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.3020862032540875, 0.3001027123409644, 0.3366261493968289, 0.3502268585859599, 0.34435901558632953, 0.3266847005168262, 0.3478706524779587, 0.33453632002173905, 0.34207287118665364, 9.999999999998899e-05, 9.999999999998899e-05, 0.0034131993318263776, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08668455812496412, 0.10696035090763567, 0.10859594023753982, 0.07751998035873298, 0.09982949893821569, 0.09671072705534078, 0.1019490601551517, 0.0893798189171775, 0.11002527192373524, 0.08997114166067366, 0.07618585831814384, 0.0790790141482185, 0.10652298508153402, 0.08878623088250936, 0.08437807683894094, 0.08936027814600911, 0.07293357681534762, 0.07202274807022802, 0.974393234416978, 0.9596729716877234, 0.9627637685547304, 0.9850362225790784, 0.9789196765862789, 0.975914135417521, 0.978781447136786, 0.9786807507014097, 0.9806717607291826, 0.2129532540305511, 0.23392212194211404, 0.25593996489825743, 0.2050524354701584, 0.18383533811515995, 0.2045180609725904, 0.19532120647082807, 0.1563246332911875, 0.2058122562276431, 0.1722180141100027, 0.2525789086809763, 0.2039164811637164, 0.2528695286808138, 0.26239825839195396, 0.21943306611672697, 0.289804848858883, 0.22029934191690426, 0.22457007678629726, 0.10955122913015258, 0.1416649209629941, 0.11138967519273157, 0.11231082094785783, 0.09542327450401245, 0.0981243175265527, 0.11595824753821216, 0.1115668125367294, 0.13310363826013327, 0.12722767254879852, 0.13651280168688495, 0.1360746596106026, 0.13304513361266923, 0.10842588901627181, 0.12183802993099235, 0.11257445076157857, 0.10025673318940842, 0.10443218831593382, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10000653736459897, 0.02466566567484585, 0.0768847460347315, 0.0574002226325927, 0.041117756830460706, 0.06994999444916561, 0.01595085192301593, 0.1238960332714385, 0.07297970286769506, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05627689354515786, 0.027921668586675885, 0.05142792414300057, 0.07716230576519123, 0.046016310717636455, 0.0425581548630084, 0.04932403895900661, 0.06028021560527852, 0.07429276148075692, 0.35164154796430636, 0.32750352843942643, 0.3101697752614996, 0.3622972310361935, 0.3080357424784763, 0.36036017198416026, 0.3023665199429224, 0.28640824804911413, 0.33990852761766777, 0.07820693593645334, 0.08748766393994356, 0.08304500930185199, 0.09980339878371525, 0.09048099471211057, 0.10766515565934553, 0.09380002953412536, 0.09174268376673556, 0.08765532459505498, 0.17639328989497427, 0.1448161102918617, 0.13427063946588402, 0.21831960170654163, 0.16896240886428682, 0.14728082445352975, 0.1814263995331714, 0.14620175943894442, 0.15877409139664378, 0.2634989765762771, 0.22988243970786448, 0.2566487853564656, 0.24447572757927027, 0.24246445228465974, 0.2191762747263405, 0.23002860773350153, 0.2327721981076395, 0.19651164914630603, 0.15103772371474755, 0.15560128041384014, 0.15139004271420198, 0.18069886203178853, 0.1787787087825944, 0.15351502294158237, 0.2392677967588024, 0.170717342799936, 0.17669468151078582, 0.18297409432196943, 0.20647559305191354, 0.20904624080093115, 0.2150723541628352, 0.2033768298851485, 0.19189879366189344, 0.20442666909257967, 0.1888500302716346, 0.25527173656667235, 0.1766709065030182, 0.1825707989314791, 0.1816362770931993, 0.18387838114315402, 0.18244403864369774, 0.17801236012249888, 0.17577549479908305, 0.1928488834348745, 0.1811799031961081, 0.1827944300720873, 0.17210488491229137, 0.15281141203131698, 0.5047841928606439, 0.48575667351404295, 0.38367133056031355, 0.11891751838774411, 0.1694781497731057, 0.15084872854432818, 0.16827289768409914, 0.29096512355289617, 0.3781064732853112, 0.3220081889192169, 0.20793418220333992, 0.2678053584330299, 0.12746523378950947, 0.12563981113040523, 0.2768116876597959, 0.19148892606584456, 0.1938736629190978, 0.18995817855670072, 0.17764255016036656, 0.18272714741905793, 0.18101423220028356, 0.18161648440276046, 0.20897863753379697, 0.18482050770299663, 0.08565349317386173, 0.09094853270708392, 0.07380669908265314, 0.073663336059822, 0.07805504666853247, 0.10118006239967803, 0.08994004921949761, 0.07307104038934942, 0.0860606579343779]}, "mutation_prompt": null}
{"id": "971c99c3-d92d-486f-adcb-b312d5f46fdc", "solution": "import numpy as np\n\nclass AdvancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.vel_max = 2.0  # Adjusted maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-4  # Adjusted diversity threshold\n        self.iteration = 0\n        self.dynamic_map_factor = 0.5\n\n    def multifactorial_map(self, x):\n        # New multifactorial dynamic map for better diversity\n        return np.sin(np.pi * x) * np.cos(np.pi * x)\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.multifactorial_map(self.iteration * self.dynamic_map_factor / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.95\n\n            self.c1 = 1.5 + 0.6 * np.cos(self.iteration / 60.0)\n            self.c2 = 1.5 + 0.6 * np.sin(self.iteration / 60.0)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "AdvancedHybridDEPSO", "description": "A hybrid adaptive DEPSO optimizer using multifactorial dynamic mapping for enhanced convergence and robustness.", "configspace": "", "generation": 69, "fitness": 0.33500016797908994, "feedback": "The algorithm AdvancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.9133534061297709, 0.9153520289653532, 0.8947417412496714, 0.9010575250652565, 0.9057497659395986, 0.8766706102097602, 0.893862865679652, 0.8888074179764447, 0.8942203003070456, 0.7510226468690331, 0.8045241958074791, 0.7903167969300051, 0.7793586185644354, 0.7783492330083851, 0.775666318496184, 0.7708008413791042, 0.7451523337907798, 0.7787373470376978, 0.08300822961633425, 0.11905052827746532, 0.7293383393261532, 0.09931499578451652, 0.18958458746145523, 0.12980952193948947, 0.14615250130189594, 0.11173450626200998, 0.09676762164916508, 0.188562310231555, 0.0977361230671644, 0.12280098403126194, 0.11272278651484902, 0.1175737404920022, 0.09269746248220634, 0.14854074570346676, 0.0830352547534261, 0.07040403647029603, 0.9807794600068812, 0.9779213323007462, 0.9784864596995609, 0.9803858447578099, 0.9772701091116137, 0.9814157496629745, 0.9838055825947176, 0.9733808156958051, 0.9802394243310882, 0.7086079714098461, 0.7276146850180372, 0.7274519996556095, 0.7081335938502009, 0.7514394794756756, 0.7034037978390828, 0.7472249167728776, 0.08896288133253782, 0.7172889335919005, 0.40261244422274045, 0.2293570411500312, 0.37390191797784256, 0.38004264616225203, 0.8404312367766911, 0.19241206895254226, 0.23359200325693819, 0.1790777908560136, 0.24384490634668798, 0.27520013255182574, 0.13438583041818986, 0.2701361268725936, 0.287985618814512, 0.2624631710084021, 0.20202623297296762, 0.27135602457390906, 0.26125663864194404, 0.2515087392549673, 0.27436242817979395, 0.13599386124436785, 0.28960363963777, 0.2877522448590044, 0.32399224672710725, 0.3154686202567266, 0.2806680548145205, 0.32260988088882225, 0.27912883657041665, 0.0026630360967948574, 0.06856259674904996, 0.042047791520579136, 9.999999999998899e-05, 0.06372590414085333, 0.048749376661968546, 0.023126417296859603, 0.030626150246707562, 0.0006405582454819259, 0.09127781219394893, 0.07562465448797762, 0.0661545370653075, 0.1023539907516362, 0.04595326443925574, 0.08476071640911198, 0.08585380748712146, 0.12174945558476935, 0.05430194363819851, 0.05202033430947273, 0.09856832566608609, 0.15924028795458767, 0.09375815157182987, 0.07954872340495422, 0.17178538272635957, 0.09428458334077716, 0.22463801694727392, 0.07479112695998158, 0.17902844709648202, 0.05368020193937251, 0.2661770736776453, 0.09301843158141054, 0.12489222375228692, 0.1989911682562251, 0.09608271278845915, 0.08397804854255553, 0.08429027689701796, 0.5418495159353429, 0.5840486382339354, 0.5291869640271982, 0.5480451417309908, 0.6201794189287776, 0.5945767328299029, 0.6095168497312992, 0.559045449922575, 0.5975713392578957, 0.10957047553225274, 0.11527482844596504, 0.07682900409182347, 0.09319145960441566, 0.11857296463731959, 0.13838119776650837, 0.1167756504573898, 0.10550185480479501, 0.097027430629819, 0.36579340429926444, 0.27208561627581507, 0.20507010167604245, 0.36816943724506956, 0.3394116701854406, 0.28652549918506576, 0.28157818718152017, 0.4170879910792682, 0.2521601809277465, 0.4816585774161646, 0.5207381150842338, 0.3593393751556113, 0.3004492069297525, 0.5096472571344857, 0.2818435181299145, 0.4854511472669113, 0.4884782194003612, 0.1580344305010314, 0.30055198414097917, 0.18891444569265503, 0.2568579486499586, 0.20425136558629564, 0.21274136899925056, 0.22137735490151578, 0.18409942293824688, 0.3805408046941322, 0.2624029048339699, 0.19049707081525524, 0.21146525184323595, 0.21987855290370728, 0.19241263776576578, 0.21326335215523273, 0.21837342974285534, 0.20475010873160016, 0.2278126216970111, 0.25918004808927164, 0.20716069416159621, 0.19835020017727079, 0.22810492178368613, 0.2493036716397038, 0.2026379025064876, 0.1954176638383368, 0.19934322618499678, 0.25402942360872904, 0.19558216748474933, 0.18865249145163332, 0.1887650386516121, 0.15471485608530766, 0.9366825784146585, 0.2010892398217634, 0.17024977033716804, 0.13134220862472923, 0.17041756733689306, 0.1689213503471625, 0.8903983387052529, 0.8737071358469233, 0.9277721868266944, 0.21215172774636182, 0.6985371285698281, 0.21194701670638216, 0.10522027684149982, 0.15656128287435622, 0.8572488282434825, 0.21071761485544527, 0.19200796081382843, 0.18647390737353264, 0.22623201223444944, 0.19912212916917238, 0.19143641803121225, 0.2653530250751639, 0.23176833329605329, 0.22611205550082403, 0.11405898122092273, 0.11129787011077419, 0.08306601506998756, 0.10395596422829478, 0.17760706568260853, 0.11851355318269563, 0.10130172022244155, 0.09965894737514114, 0.1403990691054562]}, "mutation_prompt": null}
{"id": "0565f10f-7c90-4bc7-bce4-ac76278f0359", "solution": "import numpy as np\n\nclass AdaptiveChaoticDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.8, 1.0)  # Slightly modified chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.85  # Slight adjustment in inertia weight decrement\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.4 * np.cos(self.iteration / 50.0)  # Minor tweak in parameter oscillation\n            self.c2 = 1.5 + 0.4 * np.sin(self.iteration / 50.0)  # Minor tweak in parameter oscillation\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "AdaptiveChaoticDEPSO", "description": "A hybrid optimizer combining adaptive chaotic maps with DEPSO and dynamic diversity-based parameter adjustments for enhanced exploration and convergence.", "configspace": "", "generation": 70, "fitness": 0.34769564077329, "feedback": "The algorithm AdaptiveChaoticDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.29.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.9069452910566723, 0.905843371198699, 0.9026185785520447, 0.8958202880768666, 0.9096158834823445, 0.9152283884023369, 0.9166948057070926, 0.9130058084953392, 0.9048601141947514, 0.7988566154897042, 0.7780559170055601, 0.8064480142277197, 0.7932453134572344, 0.7725858470147033, 0.8168591428946269, 0.770420994554496, 0.8128568069300504, 0.8280378969329094, 0.1426508719420494, 0.11727249900939607, 0.0966784055556893, 0.1607874867764686, 0.11124169258378169, 0.1875812587707928, 0.11776803511265332, 0.10959955735218285, 0.11677976458149164, 0.10775792953830166, 0.06965536337545564, 0.13047446310166377, 0.11154369095849814, 0.11570722209517081, 0.07179467824173558, 0.15593334277583637, 0.13367732030325463, 0.13754005350360932, 0.9767052391444624, 0.9688295554303454, 0.9552161365803994, 0.9842776407119208, 0.98064243274254, 0.9756439443704136, 0.9821619432293667, 0.9751257439836296, 0.9812811733208008, 0.8018679797954442, 0.7643652654640425, 0.7395310382248232, 0.7651069638950583, 0.779958469982761, 0.7884883916823494, 0.7790917473455752, 0.674218790764739, 0.7990244568600845, 0.39621816493715956, 0.21742226883591897, 0.3223673390105738, 0.23894115124860715, 0.3806829717095639, 0.38651997093118107, 0.17914014776937126, 0.8841342978124846, 0.23895751509043228, 0.2667854171623648, 0.3014204805482765, 0.13314292248843052, 0.31102127698183846, 0.13557185541110206, 0.281804756479489, 0.2914193649509601, 0.28925263030670134, 0.297121811774112, 0.286866617196047, 0.2686187425756734, 0.19951701370439834, 0.36034244931210124, 0.27160301954434773, 0.2772206346755691, 0.4446583761000934, 0.13417489674385996, 0.1351042682478002, 0.16214656778375358, 0.08276440566499621, 0.041819385669151776, 0.008529606939817636, 9.999999999998899e-05, 9.999999999998899e-05, 0.002508775080705572, 0.064624561604126, 0.017748026416731233, 0.0970851941996691, 0.04759608778808144, 0.1037993573268231, 0.09522341740471096, 0.03091205036619593, 0.02650437793833793, 0.07906182782708748, 0.14554925400569974, 0.09038025866579724, 0.05621825135815339, 0.39634040686677063, 0.051351310974198205, 0.07979238883234774, 0.079148253122859, 0.08029662286691996, 0.28101646912733935, 0.10037931704669678, 0.3051199322436582, 0.1267927065233695, 0.13259948390946685, 0.0583629952425212, 0.1319789620048446, 0.17023959522194332, 0.09569069027668442, 0.0836935697830613, 0.12443713447615357, 0.1172912405383637, 0.5666907718073821, 0.5560344772531502, 0.5786844165231391, 0.5688787380606232, 0.5930920867132948, 0.5812191780305462, 0.5994777712983745, 0.6101636019474194, 0.5881131743494463, 0.10076383335743666, 0.14480667574618888, 0.08840458082183411, 0.13997319701608035, 0.07027540934019105, 0.13308518381076717, 0.16282051819986587, 0.08413043265447173, 0.1429580891701151, 0.3691109023633846, 0.32602012987567064, 0.36091135030691923, 0.34359879794903514, 0.3406933407096776, 0.1450048351839356, 0.19874263392462832, 0.25681652536467936, 0.23801873187354217, 0.4334203580678371, 0.4817965520162776, 0.1995855022886035, 0.4545001268266059, 0.40655771401602714, 0.394008911464526, 0.5323828315294468, 0.34727604245855725, 0.4678546547100221, 0.3353429478151112, 0.31574221975922623, 0.15206028688966944, 0.35764807782529284, 0.23400275452472663, 0.23296745793107843, 0.2302996763221603, 0.25597880231886894, 0.18882917538878996, 0.25093817464547497, 0.2344387983501992, 0.22546632479803097, 0.38994331429274043, 0.24259721190990158, 0.23676714591217418, 0.2860889171326956, 0.2154974815649563, 0.22463932888809646, 0.1889606053163777, 0.22308069001047492, 0.2265397604221846, 0.8600029013653089, 0.18196668680512995, 0.2110685566495637, 0.21235949520753572, 0.1790422020793887, 0.18918668554326512, 0.16548785908233732, 0.12700455867209381, 0.1538213028338523, 0.1727910574047301, 0.9400977267052276, 0.9360606168274307, 0.099992801364431, 0.1694455605114874, 0.15902960679789135, 0.8625271713541484, 0.2137259968158538, 0.8223649016352249, 0.8965686034713138, 0.8204308041077062, 0.8517426461225571, 0.10409888519175514, 0.15712752597901403, 0.20286127817643906, 0.18802393790115424, 0.19310666873473925, 0.18611913168272232, 0.20441782718776902, 0.19247523484175721, 0.3160890673551281, 0.21441224594625363, 0.22243377520883545, 0.22752907336991546, 0.09014815335443782, 0.11235949720204286, 0.12494077374712653, 0.08363773685695575, 0.10618454655025256, 0.07389681352844546, 0.09562265075624177, 0.10657400180306453, 0.11056813782675368]}, "mutation_prompt": null}
{"id": "9a5d0fda-43ee-4b37-926b-6c0c73b2ee50", "solution": "import numpy as np\n\nclass AdaptiveChaoticDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.7  # Adjusted inertia weight for PSO\n        self.c1 = 1.7  # Adjusted cognitive coefficient for PSO\n        self.c2 = 1.3  # Adjusted social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(3.7 * x * (1 - x), 1.0)  # Logistic chaotic map for enhanced chaos\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(np.random.rand())\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.95  # Slightly adjusted reduction factor\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.7 + 0.4 * np.cos(self.iteration / 60.0)  # Adjusted oscillation pattern\n            self.c2 = 1.3 + 0.4 * np.sin(self.iteration / 60.0)  # Adjusted oscillation pattern\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "AdaptiveChaoticDEPSO", "description": "An adaptive hybrid DEPSO optimizer enhanced with chaotic maps and diversity-based parameter tuning for improved convergence and robustness.", "configspace": "", "generation": 71, "fitness": 0.29141495121077593, "feedback": "The algorithm AdaptiveChaoticDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.24.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.779396131025993, 0.7467996316027286, 0.6800277730006932, 0.8169305711465338, 0.1910035083893481, 0.7756047191922512, 0.7338688808008405, 0.7418967153476137, 0.672339602443491, 0.5001770716157043, 0.29078766245587817, 0.5167826678743341, 0.38109429525688365, 0.5978818767946266, 0.47358075899238194, 0.455103425544094, 0.5806936815117063, 0.509722485663586, 0.14613132717251698, 0.12619818869684274, 0.09025880921899809, 0.17840857665070742, 0.13034421034899601, 0.13472578317412587, 0.16208599898213893, 0.09454426847153086, 0.10985407985783424, 0.11237775515244608, 0.12088675922270598, 0.1330705658709408, 0.10811849988891353, 0.09096112436157633, 0.15544758607503517, 0.1404688739145855, 0.09079894725386417, 0.13328885863109863, 0.9743693425295435, 0.9779700209101859, 0.970520831780058, 0.974229159910388, 0.9720681864013054, 0.9804442572422027, 0.9709353040488921, 0.9817668698338515, 0.9651658342147501, 0.5247520938603424, 0.44518596944442446, 0.4718406577365575, 0.493856795214189, 0.575605832735422, 0.47138091055874776, 0.48338134407040045, 0.43971055422549965, 0.44668739716888806, 0.22676186934846498, 0.226627048743687, 0.14015685422664081, 0.2198383358697078, 0.2794482810707256, 0.7585309707634385, 0.38140307146955044, 0.3346849024528433, 0.7909195139679358, 0.23388804384697603, 0.2031652821767408, 0.19348390005669258, 0.13349714133468693, 0.24226396915297632, 0.22003256965240803, 0.2222610064825239, 0.20669018017568175, 0.21836255426506046, 0.21871989513165613, 0.20733599036456063, 0.21647641763589076, 0.21233665444754746, 0.21573770474402332, 0.22135641015978313, 0.22360821228803562, 0.26677551701228785, 0.215428243654054, 9.999999999998899e-05, 0.06611935418747361, 0.07419266470367325, 0.07090237232748697, 9.999999999998899e-05, 0.052447930415266075, 0.011464954183283749, 0.00270001828478994, 0.009515124696830801, 0.07023182854349885, 0.05872030680854823, 0.1757766634055279, 0.07252403336030255, 0.03095665485571586, 0.017054112794039566, 0.100676820916201, 0.1578521083094242, 0.08493369803904571, 0.09574215962477572, 0.03426396107973817, 0.050340402879093915, 0.057625096019155886, 0.06265103775746428, 0.08241981007839294, 0.07965123689112896, 0.15065992278833218, 0.06075503738336685, 0.11191271472584807, 0.1987969378694534, 0.16649117723991513, 0.09914836063830412, 0.10507625054674807, 0.18185443120416533, 0.04942321376847836, 0.11324478030228202, 0.0959016860279246, 0.533351503064978, 0.49628246786926955, 0.5169687840495407, 0.5126758176708761, 0.49114659030604557, 0.47343357474939907, 0.5204728477943856, 0.511006595498279, 0.525185335907271, 0.11329830647334205, 0.0942817283134082, 0.11610955873273887, 0.11111828131327983, 0.517831841377393, 0.1290613297385489, 0.14129706085861493, 0.13513603281337216, 0.10652472563736015, 0.5532898777383135, 0.3455228763803909, 0.24012211052979815, 0.42464973249852356, 0.48053316993040185, 0.32058453565354195, 0.28541753206025144, 0.3311599414772899, 0.15286042622360296, 0.39248071658501504, 0.2772841244955695, 0.3238928423617141, 0.20784820430787554, 0.46068295740844734, 0.36598903087278567, 0.39910163135952337, 0.43578391396182503, 0.35179965749241027, 0.20733002629535136, 0.24252729257408168, 0.28866079113057763, 0.24084668779932472, 0.21604493227918742, 0.30037339903711346, 0.2233546027869091, 0.2286647730428908, 0.24676768155317463, 0.21827499283634, 0.22204759242992334, 0.2167180921661227, 0.219325624053483, 0.23226146247702195, 0.25016833590769916, 0.21310404782870085, 0.22163626565489258, 0.22801968452508525, 0.20981026692165627, 0.2174956663019595, 0.24648162214554836, 0.19506745934196135, 0.4747514333341769, 0.22412868126330754, 0.20459925929061906, 0.22008356528123907, 0.1976232992618574, 0.18842606411873586, 0.18633387424518455, 0.1883687041341735, 0.8953234192001996, 0.20072056667678895, 0.17844134072989604, 0.16235991876324074, 0.1698773496605518, 0.8625317256903942, 0.7214659143559605, 0.2114939902886963, 0.6391734121544201, 0.21248422440675463, 0.11299030276990074, 0.21156702318490328, 0.1283959188303161, 0.1567117266412219, 0.2120717147086557, 0.18175274882743087, 0.19755889585822428, 0.1977059764882345, 0.19517898793849808, 0.187098119807368, 0.18799711111388184, 0.22046186580517757, 0.1802517101300205, 0.1986658044338554, 0.1038088764388625, 0.09554665913813731, 0.0849548576810204, 0.09245114087601436, 0.09592782881985218, 0.10992871769497647, 0.10571786948594741, 0.08620152962517091, 0.08177993313989995]}, "mutation_prompt": null}
{"id": "94c7bdee-f2e2-48c3-bdd7-5595a6ef201a", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A refined hybrid optimizer incorporating adaptive chaotic maps in DEPSO for enhanced exploration and convergence.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.8865276906432433, 0.9020532548803202, 0.8929687050976703, 0.9069966467491789, 0.8983603223003787, 0.9022140074472543, 0.8838639783889877, 0.8886653828703049, 0.889752534826144, 0.7567698703303883, 0.784578368098034, 0.8076249809202548, 0.7611720006041811, 0.7986347352301275, 0.8050952302753023, 0.7936777043904858, 0.8107862909162267, 0.7638655686477411, 0.14306028296887274, 0.18771148863225673, 0.09076269380504487, 0.14472904467535863, 0.18827718037504793, 0.14600008067707715, 0.18654152199131935, 0.11161280818292418, 0.11200366762783509, 0.13393502172957683, 0.14641399913557107, 0.1432167792015192, 0.11181421186718143, 0.09209417505561412, 0.11938418806199658, 0.11206983601831055, 0.11095636186680169, 0.10912525701701048, 0.9717271359469163, 0.9628507846149675, 0.9377341630520235, 0.9810288407887259, 0.9785915503130439, 0.9770423747813494, 0.9783473338829307, 0.9712621930647505, 0.9787075504592555, 0.7607315187580301, 0.7749069267760285, 0.7630288578874603, 0.7507532481153396, 0.6554370351125884, 0.7762723104136083, 0.7499504173558014, 0.6968283959747328, 0.7389586451693928, 0.1721225825938858, 0.22891630584450517, 0.11324758049764427, 0.3549737812815622, 0.2807957237653095, 0.28145549322917607, 0.18018767969655092, 0.2386988483653335, 0.9395469978455472, 0.2720537562684263, 0.1357109215500677, 0.288515417628357, 0.27358595508171457, 0.28033933355072405, 0.3483295090039492, 0.29980271067857245, 0.13457278726329025, 0.31624018099324525, 0.28347106445129555, 0.27653913969396915, 0.2892909131254505, 0.32904479577095047, 0.30792895015902, 0.3267380918354402, 0.3033156492629593, 0.2088685743639237, 0.2906120113344278, 0.004881953303818798, 0.08432094844164972, 0.01040324864575648, 0.08307057080589308, 0.0631748299553836, 0.031141171943307566, 0.038932547461408507, 0.021942713170019723, 0.09321589178997347, 0.14820762824482314, 0.14111157929981544, 0.09939347465031478, 0.07351212675576657, 0.14911297504852605, 0.02739581001833591, 0.11477783328277313, 0.09375370099990121, 0.12437319484907039, 0.07875046545806708, 0.12463510807347011, 0.14210128121458188, 0.07919284437097684, 0.0801485337679555, 0.13337703281066082, 0.19524821804991244, 0.10442299933492127, 0.07342327849013242, 0.16578167026123625, 0.1853016315404299, 0.1189542819871422, 0.1574945670012905, 0.18360986723287642, 0.2558817728796652, 0.12448657793629136, 0.25405459307747846, 0.1254414517844874, 0.5407077538029146, 0.6006067397749144, 0.5396897498932287, 0.5489927270360135, 0.5891834596503931, 0.5459801886932765, 0.5877025571595188, 0.58912009886935, 0.5796039758319813, 0.07975439706166598, 0.10110173168052605, 0.0755122787624074, 0.16076138881367696, 0.10587421420661025, 0.09908423757627094, 0.11384860622149795, 0.14412899438570692, 0.10610491466439798, 0.22279569248288034, 0.6592237296261918, 0.22467227789135458, 0.27264975790467794, 0.42228702264236595, 0.4427009503531557, 0.5283272114477804, 0.21131508909474783, 0.3463028054853772, 0.5602848907432856, 0.5870043317671049, 0.24980633166770938, 0.37827330003298987, 0.3159543684158136, 0.3948951692827499, 0.5338080159903202, 0.6386237352364159, 0.19094651398173923, 0.2682466646833648, 0.24944249579405708, 0.20048413900667417, 0.3126123000671225, 0.19508244130654495, 0.2440464616149688, 0.2746657038803456, 0.2758095868983087, 0.1718425074209099, 0.24221577925087046, 0.24277264917923613, 0.22753707311652804, 0.21621523555871425, 0.23220195984323055, 0.2121859746984508, 0.22233176434332813, 0.19428032015735874, 0.2940143940691601, 0.18346601962379372, 0.2507595245585167, 0.2074744620231186, 0.2296346173180046, 0.7839070787440949, 0.18887893138201983, 0.19948332275076253, 0.2261375176508097, 0.19661374747919813, 0.9185297033957897, 0.17730516387770456, 0.11326657578340704, 0.17278331750195008, 0.9190619999789291, 0.2007124882642538, 0.0996663158636657, 0.16991723780351253, 0.16271709766976927, 0.8243727383661772, 0.8166819556788825, 0.7311027166633209, 0.9133133255502286, 0.8484364245717022, 0.7770450456081295, 0.10514634504197418, 0.1699183301713061, 0.16636178423956227, 0.19554443874623362, 0.24430239869142467, 0.21100720171394982, 0.1973610633324807, 0.25121027229113, 0.19102423719310313, 0.2563067934359131, 0.23300659057012685, 0.22269509176237645, 0.08892873400730372, 0.07113752042749677, 0.11154483811644855, 0.0966630146129761, 0.0829219834948779, 0.14774202050214513, 0.10337404775080683, 0.10543583486427055, 0.09783716494350791]}, "mutation_prompt": null}
{"id": "f033da5e-bd63-4b59-8cbe-964c8071c612", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A refined hybrid optimizer incorporating adaptive chaotic maps in DEPSO for enhanced exploration and convergence.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.8865276906432433, 0.9020532548803202, 0.8929687050976703, 0.9069966467491789, 0.8983603223003787, 0.9022140074472543, 0.8838639783889877, 0.8886653828703049, 0.889752534826144, 0.7567698703303883, 0.784578368098034, 0.8076249809202548, 0.7611720006041811, 0.7986347352301275, 0.8050952302753023, 0.7936777043904858, 0.8107862909162267, 0.7638655686477411, 0.14306028296887274, 0.18771148863225673, 0.09076269380504487, 0.14472904467535863, 0.18827718037504793, 0.14600008067707715, 0.18654152199131935, 0.11161280818292418, 0.11200366762783509, 0.13393502172957683, 0.14641399913557107, 0.1432167792015192, 0.11181421186718143, 0.09209417505561412, 0.11938418806199658, 0.11206983601831055, 0.11095636186680169, 0.10912525701701048, 0.9717271359469163, 0.9628507846149675, 0.9377341630520235, 0.9810288407887259, 0.9785915503130439, 0.9770423747813494, 0.9783473338829307, 0.9712621930647505, 0.9787075504592555, 0.7607315187580301, 0.7749069267760285, 0.7630288578874603, 0.7507532481153396, 0.6554370351125884, 0.7762723104136083, 0.7499504173558014, 0.6968283959747328, 0.7389586451693928, 0.1721225825938858, 0.22891630584450517, 0.11324758049764427, 0.3549737812815622, 0.2807957237653095, 0.28145549322917607, 0.18018767969655092, 0.2386988483653335, 0.9395469978455472, 0.2720537562684263, 0.1357109215500677, 0.288515417628357, 0.27358595508171457, 0.28033933355072405, 0.3483295090039492, 0.29980271067857245, 0.13457278726329025, 0.31624018099324525, 0.28347106445129555, 0.27653913969396915, 0.2892909131254505, 0.32904479577095047, 0.30792895015902, 0.3267380918354402, 0.3033156492629593, 0.2088685743639237, 0.2906120113344278, 0.004881953303818798, 0.08432094844164972, 0.01040324864575648, 0.08307057080589308, 0.0631748299553836, 0.031141171943307566, 0.038932547461408507, 0.021942713170019723, 0.09321589178997347, 0.14820762824482314, 0.14111157929981544, 0.09939347465031478, 0.07351212675576657, 0.14911297504852605, 0.02739581001833591, 0.11477783328277313, 0.09375370099990121, 0.12437319484907039, 0.07875046545806708, 0.12463510807347011, 0.14210128121458188, 0.07919284437097684, 0.0801485337679555, 0.13337703281066082, 0.19524821804991244, 0.10442299933492127, 0.07342327849013242, 0.16578167026123625, 0.1853016315404299, 0.1189542819871422, 0.1574945670012905, 0.18360986723287642, 0.2558817728796652, 0.12448657793629136, 0.25405459307747846, 0.1254414517844874, 0.5407077538029146, 0.6006067397749144, 0.5396897498932287, 0.5489927270360135, 0.5891834596503931, 0.5459801886932765, 0.5877025571595188, 0.58912009886935, 0.5796039758319813, 0.07975439706166598, 0.10110173168052605, 0.0755122787624074, 0.16076138881367696, 0.10587421420661025, 0.09908423757627094, 0.11384860622149795, 0.14412899438570692, 0.10610491466439798, 0.22279569248288034, 0.6592237296261918, 0.22467227789135458, 0.27264975790467794, 0.42228702264236595, 0.4427009503531557, 0.5283272114477804, 0.21131508909474783, 0.3463028054853772, 0.5602848907432856, 0.5870043317671049, 0.24980633166770938, 0.37827330003298987, 0.3159543684158136, 0.3948951692827499, 0.5338080159903202, 0.6386237352364159, 0.19094651398173923, 0.2682466646833648, 0.24944249579405708, 0.20048413900667417, 0.3126123000671225, 0.19508244130654495, 0.2440464616149688, 0.2746657038803456, 0.2758095868983087, 0.1718425074209099, 0.24221577925087046, 0.24277264917923613, 0.22753707311652804, 0.21621523555871425, 0.23220195984323055, 0.2121859746984508, 0.22233176434332813, 0.19428032015735874, 0.2940143940691601, 0.18346601962379372, 0.2507595245585167, 0.2074744620231186, 0.2296346173180046, 0.7839070787440949, 0.18887893138201983, 0.19948332275076253, 0.2261375176508097, 0.19661374747919813, 0.9185297033957897, 0.17730516387770456, 0.11326657578340704, 0.17278331750195008, 0.9190619999789291, 0.2007124882642538, 0.0996663158636657, 0.16991723780351253, 0.16271709766976927, 0.8243727383661772, 0.8166819556788825, 0.7311027166633209, 0.9133133255502286, 0.8484364245717022, 0.7770450456081295, 0.10514634504197418, 0.1699183301713061, 0.16636178423956227, 0.19554443874623362, 0.24430239869142467, 0.21100720171394982, 0.1973610633324807, 0.25121027229113, 0.19102423719310313, 0.2563067934359131, 0.23300659057012685, 0.22269509176237645, 0.08892873400730372, 0.07113752042749677, 0.11154483811644855, 0.0966630146129761, 0.0829219834948779, 0.14774202050214513, 0.10337404775080683, 0.10543583486427055, 0.09783716494350791]}, "mutation_prompt": null}
{"id": "7ad286d1-5bed-4462-a1b6-5276bf3a37f2", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A refined hybrid optimizer incorporating adaptive chaotic maps in DEPSO for enhanced exploration and convergence.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.8865276906432433, 0.9020532548803202, 0.8929687050976703, 0.9069966467491789, 0.8983603223003787, 0.9022140074472543, 0.8838639783889877, 0.8886653828703049, 0.889752534826144, 0.7567698703303883, 0.784578368098034, 0.8076249809202548, 0.7611720006041811, 0.7986347352301275, 0.8050952302753023, 0.7936777043904858, 0.8107862909162267, 0.7638655686477411, 0.14306028296887274, 0.18771148863225673, 0.09076269380504487, 0.14472904467535863, 0.18827718037504793, 0.14600008067707715, 0.18654152199131935, 0.11161280818292418, 0.11200366762783509, 0.13393502172957683, 0.14641399913557107, 0.1432167792015192, 0.11181421186718143, 0.09209417505561412, 0.11938418806199658, 0.11206983601831055, 0.11095636186680169, 0.10912525701701048, 0.9717271359469163, 0.9628507846149675, 0.9377341630520235, 0.9810288407887259, 0.9785915503130439, 0.9770423747813494, 0.9783473338829307, 0.9712621930647505, 0.9787075504592555, 0.7607315187580301, 0.7749069267760285, 0.7630288578874603, 0.7507532481153396, 0.6554370351125884, 0.7762723104136083, 0.7499504173558014, 0.6968283959747328, 0.7389586451693928, 0.1721225825938858, 0.22891630584450517, 0.11324758049764427, 0.3549737812815622, 0.2807957237653095, 0.28145549322917607, 0.18018767969655092, 0.2386988483653335, 0.9395469978455472, 0.2720537562684263, 0.1357109215500677, 0.288515417628357, 0.27358595508171457, 0.28033933355072405, 0.3483295090039492, 0.29980271067857245, 0.13457278726329025, 0.31624018099324525, 0.28347106445129555, 0.27653913969396915, 0.2892909131254505, 0.32904479577095047, 0.30792895015902, 0.3267380918354402, 0.3033156492629593, 0.2088685743639237, 0.2906120113344278, 0.004881953303818798, 0.08432094844164972, 0.01040324864575648, 0.08307057080589308, 0.0631748299553836, 0.031141171943307566, 0.038932547461408507, 0.021942713170019723, 0.09321589178997347, 0.14820762824482314, 0.14111157929981544, 0.09939347465031478, 0.07351212675576657, 0.14911297504852605, 0.02739581001833591, 0.11477783328277313, 0.09375370099990121, 0.12437319484907039, 0.07875046545806708, 0.12463510807347011, 0.14210128121458188, 0.07919284437097684, 0.0801485337679555, 0.13337703281066082, 0.19524821804991244, 0.10442299933492127, 0.07342327849013242, 0.16578167026123625, 0.1853016315404299, 0.1189542819871422, 0.1574945670012905, 0.18360986723287642, 0.2558817728796652, 0.12448657793629136, 0.25405459307747846, 0.1254414517844874, 0.5407077538029146, 0.6006067397749144, 0.5396897498932287, 0.5489927270360135, 0.5891834596503931, 0.5459801886932765, 0.5877025571595188, 0.58912009886935, 0.5796039758319813, 0.07975439706166598, 0.10110173168052605, 0.0755122787624074, 0.16076138881367696, 0.10587421420661025, 0.09908423757627094, 0.11384860622149795, 0.14412899438570692, 0.10610491466439798, 0.22279569248288034, 0.6592237296261918, 0.22467227789135458, 0.27264975790467794, 0.42228702264236595, 0.4427009503531557, 0.5283272114477804, 0.21131508909474783, 0.3463028054853772, 0.5602848907432856, 0.5870043317671049, 0.24980633166770938, 0.37827330003298987, 0.3159543684158136, 0.3948951692827499, 0.5338080159903202, 0.6386237352364159, 0.19094651398173923, 0.2682466646833648, 0.24944249579405708, 0.20048413900667417, 0.3126123000671225, 0.19508244130654495, 0.2440464616149688, 0.2746657038803456, 0.2758095868983087, 0.1718425074209099, 0.24221577925087046, 0.24277264917923613, 0.22753707311652804, 0.21621523555871425, 0.23220195984323055, 0.2121859746984508, 0.22233176434332813, 0.19428032015735874, 0.2940143940691601, 0.18346601962379372, 0.2507595245585167, 0.2074744620231186, 0.2296346173180046, 0.7839070787440949, 0.18887893138201983, 0.19948332275076253, 0.2261375176508097, 0.19661374747919813, 0.9185297033957897, 0.17730516387770456, 0.11326657578340704, 0.17278331750195008, 0.9190619999789291, 0.2007124882642538, 0.0996663158636657, 0.16991723780351253, 0.16271709766976927, 0.8243727383661772, 0.8166819556788825, 0.7311027166633209, 0.9133133255502286, 0.8484364245717022, 0.7770450456081295, 0.10514634504197418, 0.1699183301713061, 0.16636178423956227, 0.19554443874623362, 0.24430239869142467, 0.21100720171394982, 0.1973610633324807, 0.25121027229113, 0.19102423719310313, 0.2563067934359131, 0.23300659057012685, 0.22269509176237645, 0.08892873400730372, 0.07113752042749677, 0.11154483811644855, 0.0966630146129761, 0.0829219834948779, 0.14774202050214513, 0.10337404775080683, 0.10543583486427055, 0.09783716494350791]}, "mutation_prompt": null}
{"id": "057f2810-04cd-46d6-b16e-c7b7f0b436e5", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n        self.perturbation_factor = 0.1\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.8, 1.0)  # Adjusted chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n\n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight and apply perturbation based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n                for i in range(self.population_size):\n                    if np.random.rand() < self.diversity_probability:\n                        self.particles[i] += np.random.uniform(-self.perturbation_factor, self.perturbation_factor, self.dim)\n                        self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "AdaptiveHybridDEPSO", "description": "An enhanced adaptive hybrid optimizer blending chaotic maps with DEPSO and stochastic perturbations for improved exploration and convergence.", "configspace": "", "generation": 75, "fitness": 0.3425002081406714, "feedback": "The algorithm AdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.9072615312787861, 0.8988431403650802, 0.9054877041306454, 0.908929458247563, 0.9067193205633515, 0.9042251507733527, 0.8894957286322299, 0.8968080364001689, 0.892616183538682, 0.7850437901025346, 0.7879840750018635, 0.7257657045760322, 0.7788362710705258, 0.788763931126309, 0.774702308548292, 0.7755231638095954, 0.7862104304514344, 0.8084338392356074, 0.11023204900843664, 0.17765562713653305, 0.09691386209672892, 0.1435313824158495, 0.11649098962905446, 0.11177176589186877, 0.1461661973959948, 0.10071315190544716, 0.1422837838107478, 0.09066027278628319, 0.06607258250475845, 0.10959037033879526, 0.11133933843787802, 0.0998645771225809, 0.1136187157587174, 0.11564780582428302, 0.11787702727678717, 0.13208752510918365, 0.9767073497326598, 0.9659747941950932, 0.9555283266446735, 0.9842787503008033, 0.980642818220327, 0.9756369189126456, 0.9821621011358299, 0.9751229240054539, 0.9812705621935328, 0.788153404704624, 0.7338970594416396, 0.7392066365382273, 0.7481723376582121, 0.7790680849815684, 0.7007525523886807, 0.7111572954704828, 0.08867091952059014, 0.7369509411734279, 0.2305644289116362, 0.23027896423583039, 0.8667410757267732, 0.28200194202376927, 0.21453445624806589, 0.3873591295111537, 0.3958206470248704, 0.8880661609780192, 0.23711008654818222, 0.3795658382106075, 0.3314720048814066, 0.29378695100249264, 0.13548001560418454, 0.26274082698723855, 0.2377001761491534, 0.30724598073316634, 0.13527539105527753, 0.28395973189751644, 0.24740689017638573, 0.2752998822125883, 0.20166795050657405, 0.3362682749749418, 0.303718352750468, 0.3073869328440756, 0.34958225775184315, 0.2996003881202447, 0.2796272486680129, 0.1215242082087512, 0.09318211461681347, 0.06384474638874393, 0.05638428753908897, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.001013509650648614, 0.06716931577274776, 0.12619738093652144, 0.0833436704182986, 0.10824159788943344, 0.09046107631077682, 0.0559935278464504, 0.03654654470676433, 0.09065610968769833, 0.15583245977151383, 0.10293537308340817, 0.058682368578454436, 0.15284159559775057, 0.06058491787121312, 0.0804511658556587, 0.0782470934114865, 0.08080744797974126, 0.2302695052239866, 0.1019922170874461, 0.22824379002459216, 0.15089811082050852, 0.13155456793299292, 0.22157405490623316, 0.17548146085631522, 0.11461355850164456, 0.04716684741907118, 0.08421439230194228, 0.09505905627913414, 0.12537125966399054, 0.5859882094717335, 0.582842492303089, 0.5465673788219494, 0.5912710505219991, 0.6152754605432331, 0.5793161303311587, 0.6070084931599857, 0.5976777346455064, 0.5897050488995224, 0.1254872883627942, 0.15893238448324043, 0.15534006192869476, 0.11786106417921494, 0.0965144777630339, 0.09785750597831944, 0.08037635403977528, 0.08407895600664872, 0.10169984745124527, 0.16708058547575289, 0.5013964444885611, 0.1747992592646368, 0.34452987372077437, 0.3447670556013639, 0.21233781004403307, 0.20039180139271917, 0.19795959701535404, 0.33591188008598205, 0.4401490659515761, 0.4720637142438482, 0.24435910162204355, 0.4313749334094721, 0.4296192641952079, 0.39837948712273297, 0.7191520619599407, 0.503474831551884, 0.6014477616439069, 0.4025907561573526, 0.3029929515629881, 0.34645289671241897, 0.45710114255411327, 0.1814529481060113, 0.23576598175245944, 0.2795190642943248, 0.26878159723900386, 0.2055813832583584, 0.23115500035267356, 0.2280161963304903, 0.22908871017248722, 0.2679002829244229, 0.22706801639971075, 0.32172626760598966, 0.2614507224856899, 0.22301815968110084, 0.2612380067254253, 0.22595522799817103, 0.19867734174863638, 0.22640275069472382, 0.2540542672018723, 0.2120478959180263, 0.2107436009990291, 0.19389852127845064, 0.2086038513070606, 0.20971434798941768, 0.1771055854779492, 0.12702094548245035, 0.15384134098553603, 0.17278606092415738, 0.931562676015131, 0.9400614175290778, 0.09999290852659504, 0.16964543626084383, 0.15900223222482468, 0.8353968889398445, 0.21356684586942276, 0.10968307078039885, 0.8896314830129541, 0.7342431049902475, 0.8398459366745833, 0.10429394408341108, 0.1571102904545405, 0.20326668295229144, 0.2334943261892778, 0.20295540542762125, 0.2057220036925531, 0.2731984552772524, 0.19864782503937306, 0.2047067290967024, 0.23795593622816458, 0.20679001202596714, 0.22264484641411342, 0.09764366195339458, 0.08887864803462964, 0.08180917561379208, 0.0677730315117544, 0.08965269164625, 0.12339108323564141, 0.10356997683841795, 0.11141403473580813, 0.10828601871394661]}, "mutation_prompt": null}
{"id": "6e6a18bf-d505-4c05-bb13-acff88164a30", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0)\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0)\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i] + self.levy_flight(self.dim)\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSOLevy", "description": "An innovative optimizer combining adaptive chaotic maps in DEPSO with enhanced exploitation through Lévy flights for improved convergence.", "configspace": "", "generation": 76, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {}, "mutation_prompt": null}
{"id": "50ede7e5-2e50-42a4-a770-60f776374540", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO with diversity influence\n            diversity_influence = np.clip(diversity / 0.1, 0.0, 1.0)  # New dynamic influence\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0) * diversity_influence\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0) * diversity_influence\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A refined hybrid optimizer using adaptive chaotic maps in DEPSO with dynamic diversity handling for improved exploration and convergence.", "configspace": "", "generation": 77, "fitness": 0.3565642169096091, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.30.", "error": "", "parent_id": "cc353724-1729-40cd-aa9b-9953714e80ae", "metadata": {"aucs": [0.909001623550968, 0.9134329217720056, 0.8993943779859668, 0.9158118554562988, 0.9013589829086934, 0.9150114765801967, 0.9021174597877144, 0.9138156670046205, 0.9125744964877528, 0.8053156827059855, 0.812933161404119, 0.8427683446328783, 0.7781348046359788, 0.8274522102635543, 0.828173424832739, 0.793219326094488, 0.824438421402234, 0.807396704056346, 0.14307856490968585, 0.1877007390154648, 0.09076342173665886, 0.1591964583304123, 0.18831861632874847, 0.14601053240840012, 0.18654139144744886, 0.11701393588099107, 0.11200295781326008, 0.13396848432302944, 0.14644153775306945, 0.14339728904875682, 0.11180968840087713, 0.09210701640445917, 0.11938455295453443, 0.11206762360979172, 0.1109543262015037, 0.10913140775636909, 0.9717271359469163, 0.9628494159769669, 0.9377212443281838, 0.9810288407887259, 0.9785915503130439, 0.9770423747813494, 0.9783473338829307, 0.9712614510731488, 0.9787075504592555, 0.8400751997050477, 0.8195775155076079, 0.7881844282312709, 0.8069615774854371, 0.6647351094176812, 0.8128780388709002, 0.7612286322176006, 0.7588271737425852, 0.8022987100833393, 0.1721225825938858, 0.22891630584450517, 0.11324758049764427, 0.3549846662771695, 0.2807957237653095, 0.28145549322917607, 0.18018767969655092, 0.2386988483653335, 0.9395469978455472, 0.2997175666775681, 0.13586662398711447, 0.3211070174887374, 0.30914890736930933, 0.2976754184947398, 0.3753418046063097, 0.3033239602168375, 0.13454826076976845, 0.33685734603098483, 0.2855770542165944, 0.29120995093888746, 0.3008429981206525, 0.3672405168291414, 0.34373280443664067, 0.3578761578521632, 0.34181385559198785, 0.21016117222284347, 0.3115571058923854, 0.008727263917975292, 0.08405164954335087, 0.011850008464092898, 0.08318211192036928, 0.07217735139935322, 0.03142619455841433, 0.04249344742194738, 0.025945981813413677, 0.09877842365536249, 0.1474919909201995, 0.141424992338533, 0.10026151620075452, 0.0743538479383109, 0.1574587084945428, 0.025851253849927147, 0.11186001170601811, 0.09280097636767337, 0.1259968055351952, 0.07767230228498723, 0.125700215669862, 0.14837587801063767, 0.07870400003360734, 0.08187488224500394, 0.13824893561798346, 0.20742707829110663, 0.10455436376687322, 0.07516878362234314, 0.16371204613017887, 0.17734513841698796, 0.1130997564449634, 0.15378399216657745, 0.18209434842377636, 0.3417765465751007, 0.12180265509212573, 0.2533156932791293, 0.12740470136058157, 0.5819335199298167, 0.6313484977267598, 0.5578846315167447, 0.5675966336331973, 0.6799789016998201, 0.6049326971772399, 0.5911486760862344, 0.580885195385775, 0.598043750011304, 0.07975460775792109, 0.1011111842861161, 0.07552750669347386, 0.16077690683898838, 0.10588349774705907, 0.09912511857108985, 0.11381727276782971, 0.14416034740706962, 0.10610711934398476, 0.21734862004612598, 0.33923697374688966, 0.22495475767554407, 0.280533557148542, 0.47464323252920537, 0.3197150873271738, 0.5860861304255904, 0.21109682521114592, 0.3094983026206324, 0.4205334895981335, 0.4518994289447642, 0.2472168505177742, 0.5188342035664053, 0.3198040425626848, 0.5553825593531537, 0.49120441312897245, 0.3949912876407873, 0.1914962937954372, 0.3036021477043075, 0.2489684388194079, 0.20181638951509895, 0.32429487625029674, 0.1973023536598133, 0.24838788207350626, 0.2569341450765401, 0.2680332522799035, 0.17284697234167834, 0.24221577925087046, 0.24261914374082905, 0.22661527401643466, 0.21621523555871425, 0.23220195984323055, 0.2121859746984508, 0.22233176434332813, 0.19428032015735874, 0.2939974916905508, 0.183487209346463, 0.2507320722375961, 0.20750258869604155, 0.22962367216205004, 0.8156527533966519, 0.18887850620055235, 0.19948653489031232, 0.2261229111774895, 0.19660724644923688, 0.9186498515751226, 0.1773002007066008, 0.11326659663798577, 0.17278315101148478, 0.9213299666235599, 0.20071979040917576, 0.09964906490722802, 0.1699169308750712, 0.1627177906678935, 0.8646748104763389, 0.8047439807740762, 0.7774456621310986, 0.9244609999809484, 0.8581326776386955, 0.8425766490198829, 0.10514649497698247, 0.16991868188429704, 0.16636172125525261, 0.19794976969146916, 0.24297119069175488, 0.21100720171394982, 0.19740091513709368, 0.25121027229113, 0.19102423719310313, 0.2521876131625387, 0.2327495132079318, 0.22259688316861492, 0.0888611108833085, 0.07113528606779584, 0.11154311319513621, 0.09666703924322662, 0.08292524730122819, 0.14774519369036387, 0.10332744390907811, 0.10547157291197706, 0.09783618943502193]}, "mutation_prompt": null}
{"id": "ff6b5af3-96d6-4903-bf67-507e01374aad", "solution": "import numpy as np\n\nclass ChaoticDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.vel_max = 1.0\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n    \n    def chaotic_map(self, x):\n        return np.mod(np.sin(10 * x), 1.0)\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.95\n            \n            # Dynamic parameter tuning for PSO with diversity influence\n            diversity_influence = np.clip(diversity / 0.1, 0.0, 1.0)\n            self.c1 = 1.5 + 0.3 * np.cos(self.iteration / 50.0) * diversity_influence\n            self.c2 = 1.5 + 0.4 * np.sin(self.iteration / 50.0) * diversity_influence\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "ChaoticDEPSO", "description": "A hybrid optimizer combining chaotic differential evolution with diversity-adaptive PSO, enhancing exploration-convergence balance using dynamic parameter tuning and selective mutation.", "configspace": "", "generation": 78, "fitness": 0.3503156155471044, "feedback": "The algorithm ChaoticDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.30.", "error": "", "parent_id": "50ede7e5-2e50-42a4-a770-60f776374540", "metadata": {"aucs": [0.9195060966206805, 0.9141489984697401, 0.9175730736810672, 0.9043340288081873, 0.9194286136595645, 0.8972437409385048, 0.9112852524888578, 0.9124103826243057, 0.9188493209884581, 0.8366915222890734, 0.8305790329259218, 0.8290033012463586, 0.8109510477248891, 0.8264692834354104, 0.8066396439197611, 0.05410593303329336, 0.8185336536531618, 0.8334630149551542, 0.12272136243921761, 0.12602196188975268, 0.09651891341125629, 0.11172011613475841, 0.7688451064490105, 0.16027421771405226, 0.11836389969067784, 0.10901951018368305, 0.1346005656297633, 0.1253846327922492, 0.11310841329436372, 0.09274701221729242, 0.14267426766172409, 0.08993034215653262, 0.08213222329738257, 0.12610807736857765, 0.07941038386385424, 0.06425253445314938, 0.9704387585944005, 0.9520793035332211, 0.9706749057157221, 0.965307757320271, 0.9640951204213115, 0.9731799348694765, 0.9759914692233131, 0.9598799244635057, 0.96382815793981, 0.8190970818650939, 0.78992326017468, 0.8006312782387078, 0.8142610729754473, 0.7663548768308812, 0.8099309622165547, 0.7752062610299515, 0.8108492165488805, 0.7730234046532981, 0.4018867641100563, 0.1184509814921656, 0.08167400999788921, 0.214991596920037, 0.28312971848452406, 0.38449134655521466, 0.22360424538556378, 0.15195663560693284, 0.23810213142875136, 0.23584243793022963, 0.2808900435706122, 0.29275720392527815, 0.3007761246437519, 0.29846803577615866, 0.2527792444356993, 0.3360560174696873, 0.306907529175112, 0.31009499550434594, 0.2812017522733118, 0.25696915997449743, 0.2839153362589458, 0.3486675807681433, 0.3337208313764365, 0.3184117088778926, 0.3198654294658161, 0.2743816747486091, 0.32449952613620425, 0.04880515047824718, 9.999999999998899e-05, 0.00650968466690971, 0.06055584193664143, 0.010843520010166086, 0.05316581107066065, 0.08475213251824754, 0.008485628675906631, 0.03492404790347281, 0.10636026558321987, 0.08666120382753195, 0.11714664962621735, 0.08670940859346699, 0.04470274340729319, 0.03161699844219401, 0.15940014499485355, 0.10884064018153383, 0.05284021659125826, 0.1490655305135944, 0.18891201795007673, 0.050155414455167024, 0.0835763701103247, 0.08622946544747279, 0.08048345835948911, 0.10383965484621571, 0.10023027921015526, 0.07433966027602124, 0.21306257547170115, 0.03299643373480199, 0.10147767204457636, 0.3086360942062858, 0.07246889924597255, 0.12947994063406076, 0.1075032321887256, 0.04841505105393806, 0.08555829730842068, 0.5707297173545538, 0.5951785818803667, 0.6684821474705895, 0.6272797119366667, 0.5896388714542182, 0.5684882886790574, 0.5889427560048406, 0.6343268025797407, 0.6080701445408865, 0.10401607524157463, 0.05914583158809872, 0.09496942149108423, 0.11521605308538874, 0.07157068811354061, 0.1182362374655207, 0.09365575072981214, 0.14659977962481952, 0.09793218338726162, 0.5047714759769112, 0.5000208946906204, 0.21933133483226852, 0.4343049606127841, 0.27025514645645676, 0.19921665201966265, 0.19784854446217726, 0.17971964886783975, 0.32462660679413324, 0.5189393958490522, 0.39357011148087817, 0.24659415132916274, 0.23306917153682194, 0.42481209827655053, 0.28235390572422125, 0.23818290606875658, 0.6666851876053935, 0.2742424973062756, 0.10919977230088385, 0.2561682970360767, 0.23153036682445105, 0.18384939013921353, 0.24993969104463076, 0.3207599965700676, 0.2613837153301428, 0.4132613307998686, 0.11952050479501375, 0.2062515486701768, 0.25933587604886066, 0.2641754183532442, 0.20899997761306732, 0.20780429104763154, 0.3263696143010013, 0.24711515984677845, 0.3049151636684284, 0.2797570641488186, 0.19028503800465446, 0.22904379790305218, 0.21447526435780195, 0.8266594428573534, 0.22769667895544987, 0.22744373781432337, 0.18149939670803583, 0.19151681891147232, 0.19702121373579018, 0.1785517986532339, 0.9262210132565749, 0.9432263518581983, 0.17336186294113798, 0.201853129333613, 0.9401307323813137, 0.13221142045869128, 0.17055000656159103, 0.1545382918073841, 0.8426539061793892, 0.7669976214788021, 0.8148376861744473, 0.8452185537697251, 0.15626985513751934, 0.21266371203195644, 0.10520642339523856, 0.8728341769103608, 0.8415328361130376, 0.2502499104095063, 0.21470398637936927, 0.20358433702305978, 0.2745184198693431, 0.25589764987113517, 0.20338898879482825, 0.24971006679638863, 0.20572165730800596, 0.2469771042942812, 0.1310937336549568, 0.09513847723994273, 0.09254718356400171, 0.10000425223565379, 0.10014383517951642, 0.15042583600447856, 0.08278193025486524, 0.08166935304904055, 0.10061013091879101]}, "mutation_prompt": null}
{"id": "8c904e10-cbe1-447e-b781-2c69db084b93", "solution": "import numpy as np\n\nclass ChaoticHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.w = 0.7  # Increased inertia weight for exploration\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.vel_max = 1.0\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.9, 1.0)  # Modified chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.95  # Adjusted inertia reduction\n\n            diversity_influence = np.clip(diversity / 0.1, 0.0, 1.0)\n            self.c1 = 1.5 + 0.4 * np.cos(self.iteration / 40.0) * diversity_influence\n            self.c2 = 1.5 + 0.4 * np.sin(self.iteration / 40.0) * diversity_influence\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "ChaoticHybridOptimizer", "description": "A chaotic hybrid optimizer utilizing adaptive exploration-exploitation balance with diversity-driven parameter adjustment for robust convergence.", "configspace": "", "generation": 79, "fitness": 0.3033850778457954, "feedback": "The algorithm ChaoticHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.25.", "error": "", "parent_id": "50ede7e5-2e50-42a4-a770-60f776374540", "metadata": {"aucs": [0.7801046895233319, 0.8392650711683514, 0.816427248256447, 0.824751680759988, 0.7981170941996105, 0.7725441523776715, 0.7304433460700275, 0.8359924853326471, 0.7583118933671407, 0.5423752139149738, 0.5428761843411878, 0.4984658371742665, 0.5296201803625069, 0.6048775905513771, 0.36924460869696585, 0.5398921152696214, 0.05660987930551331, 0.4973179272768382, 0.17558314565503264, 0.1774855043287087, 0.11863873061015473, 0.5627840379184281, 0.10864485490312092, 0.459376302344899, 0.1789991926901393, 0.15067517236617367, 0.09064297188774251, 0.13422400083273334, 0.07157369296510152, 0.16804932086654512, 0.16995673967377278, 0.11276438691655544, 0.11769530592727462, 0.13957693069873278, 0.11342203268419815, 0.15587687452019328, 0.9779367173823545, 0.9627793456366419, 0.9736231639426371, 0.9874912858734279, 0.9856998272665924, 0.97855573601657, 0.9842814766391953, 0.983767856373798, 0.9792566470182165, 0.5022220841070206, 0.5895976768481235, 0.5901228166588138, 0.6160982556140593, 0.5832898977277741, 0.1527037342576758, 0.5933289790328882, 0.572897364496837, 0.5665016203993096, 0.22939930837593658, 0.22755198004807697, 0.2279745218668685, 0.21841511887605325, 0.2059470647923095, 0.2101499613999459, 0.23677927521189002, 0.23187303834480755, 0.2386750634941066, 0.12492689278367886, 0.20857594598771334, 0.2221338361433456, 0.1313369576019453, 0.22835481784288492, 0.28707427652857964, 0.23345152615425335, 0.19676949684638922, 0.23593504340592464, 0.2467034167660167, 0.2267655123580985, 0.1308999757772935, 0.21629650947931822, 0.21272373297128777, 0.23755040930005156, 0.2377911162106876, 0.2739726700459677, 0.13438184015219046, 0.01565678886599431, 0.05494486085339578, 9.999999999998899e-05, 0.03231784643044644, 9.999999999998899e-05, 0.02568572464875618, 0.008278919732278123, 0.0077269151338323905, 0.015670143625832522, 0.1326209220209552, 0.0834580117366378, 0.13915726712439713, 0.16619882482290582, 0.024801592930639327, 0.1350744740906925, 0.11316563432099103, 0.12695244500014236, 0.06871383315675883, 0.031117767509944882, 0.033784394101636694, 0.04718644016758533, 0.07198433370820001, 0.06302511051785809, 0.07419809932335353, 0.18789254272170397, 0.08469709445230111, 0.1401962683544371, 0.11932906006445176, 0.16787561974370968, 0.1701995091169367, 0.09869509690474354, 0.09132433026323505, 0.044570868490040216, 0.08326030148079244, 0.3134166964881038, 0.08122351956575935, 0.5559386428773123, 0.5842295940635789, 0.5199462448903186, 0.5118172319978855, 0.5366114423365809, 0.5568167173829854, 0.5274721421232631, 0.520060984630036, 0.5263620241940395, 0.09758059933568297, 0.42683810649027154, 0.12180534740740345, 0.14305389797225143, 0.14101902278589262, 0.11264272091659022, 0.09276171641012765, 0.1186642831907413, 0.14284367975898182, 0.2218179566291889, 0.2531465256958578, 0.4780212786891651, 0.2694929361641615, 0.5771620318828248, 0.45561358502684646, 0.2795965995648647, 0.31300871483113857, 0.21801954633104847, 0.3455310685233727, 0.3724507772562472, 0.23110701813784384, 0.4542068378563464, 0.47753128337912076, 0.359744914018319, 0.27352636807007136, 0.5095987537566049, 0.3859385332024001, 0.30345144225295184, 0.38091502204552863, 0.26449718349000273, 0.16922006648222399, 0.21441560851008035, 0.2695479572129238, 0.29195495653280246, 0.3637156610656177, 0.18287486853864865, 0.21838475086650921, 0.22184640860953764, 0.34225421781848886, 0.2362760340031297, 0.245484563423375, 0.21187363574876694, 0.23462336080131718, 0.21074389295042217, 0.24023322770674216, 0.24895952959650447, 0.24601382638673142, 0.20326083287701635, 0.24754234917083706, 0.7535748356681843, 0.23988225531919505, 0.21060689178262892, 0.1970535221962063, 0.22268189060482424, 0.16587765367970386, 0.18759403578127154, 0.15390672774978686, 0.8800977568640234, 0.1864727643604549, 0.8754593050730822, 0.1669187927699628, 0.16951981680762096, 0.1535259125303584, 0.1690921148458514, 0.6480379533910692, 0.21016735543192488, 0.21123131227597547, 0.1682145784326996, 0.6145327501702964, 0.10501901379755019, 0.16810551051090172, 0.7512763888624296, 0.18635704905317363, 0.19631078705575067, 0.19288223649630887, 0.17563898018464408, 0.1984078635409806, 0.17996790249408479, 0.2005361498767413, 0.1960700165628878, 0.22527013372402294, 0.08855592302435489, 0.09508492154219927, 0.12258562609884882, 0.08698841340676955, 0.0777588112386366, 0.14330794008121717, 0.0907053770316727, 0.10893979924902775, 0.10651977398997858]}, "mutation_prompt": null}
{"id": "e7898a14-acd4-40d9-9e21-2c78251d480d", "solution": "import numpy as np\n\nclass AdaptiveChaoticDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + np.sin(x), 1.0)  # Modified chaotic map for more variability\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 50.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.95  # Slightly slower reduction to prevent early convergence\n\n            # Dynamic parameter tuning for PSO with diversity influence\n            diversity_influence = np.clip(diversity / 0.05, 0.0, 1.0)  # More pronounced dynamic influence\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 30.0) * diversity_influence\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 30.0) * diversity_influence\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "AdaptiveChaoticDEPSO", "description": "An adaptive differential evolution with dynamic PSO, leveraging chaotic maps and stochastic perturbations for enhanced convergence and diversity control.", "configspace": "", "generation": 80, "fitness": 0.3255444759414331, "feedback": "The algorithm AdaptiveChaoticDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.29.", "error": "", "parent_id": "50ede7e5-2e50-42a4-a770-60f776374540", "metadata": {"aucs": [0.9233112092042074, 0.9166383269376237, 0.9321953669379838, 0.1826476323556976, 0.9108950105073216, 0.9185351779688168, 0.9076433278287206, 0.18303375134336952, 0.9146887819474894, 0.7974183318992119, 0.8232940537454643, 0.7666479573763099, 0.7898167700479478, 0.7646135331450694, 0.7881055265876415, 0.7549708935631475, 0.8072047865061598, 0.7771465696461197, 0.08752256287512883, 0.1347402099300502, 0.10607482826038028, 0.12945114690061454, 0.15368858413649011, 0.09765864278269432, 0.11756222511989223, 0.08830444139456284, 0.12365489590616197, 0.1242890397049814, 0.09071673568714866, 0.10053696767122933, 0.10494249283958412, 0.09269027197849844, 0.077150440936817, 0.10255568061928844, 0.0815110798831229, 0.05597846452135202, 0.9738889161090325, 0.9555042038609918, 0.9706532885516383, 0.9642823829278768, 0.9599353852170417, 0.9708716626242012, 0.970966731281786, 0.9609158477266224, 0.9646994664211472, 0.8044293410987923, 0.711228398460652, 0.7913988322005636, 0.819098133803547, 0.8084006610043534, 0.7999804819606872, 0.12878898216126766, 0.7655321261709073, 0.7714464023918437, 0.8170754384482359, 0.17147398034930195, 0.11813565227207656, 0.2150913340594407, 0.2130765646495283, 0.2812047496150937, 0.22296502491340087, 0.15300790546812748, 0.4029956815941418, 0.2999855329143557, 0.13730043094160627, 0.30589174627928195, 0.31362102825201565, 0.32358820997075055, 0.30650445604909726, 0.33050609675792275, 0.3000218471779966, 0.30032306877869075, 0.2837829977718218, 0.2995785168822127, 0.2875397421955066, 0.32937594306551277, 0.3404447275070307, 0.35566481615965717, 0.312490138894836, 0.26277601568815645, 0.3266548216013786, 0.014961954597403015, 0.04418767669475643, 0.00301666872153894, 0.12230313782627622, 0.0002969158147534401, 0.00569137157953703, 0.02508758444022896, 0.0035999055041177064, 0.006196015021263324, 0.12430760049447853, 0.03218708397587866, 0.057644326302255244, 0.06819704835555263, 0.015206994526715811, 0.025055166733764955, 0.22161123374582958, 0.10792340197578343, 0.04974458518429059, 0.07436967304472697, 0.18848005737168294, 0.1501899835513104, 0.08154091408996411, 0.0818982386380207, 0.24309170838837257, 0.15232328316905608, 0.31811646349178846, 0.07731706287914908, 0.10234808458627853, 0.06249457660475877, 0.17531083044591977, 0.11834786786548523, 0.22493993668196555, 0.10493752467478301, 0.08422081892076838, 0.11054721802444534, 0.08601218162938562, 0.5807918205644775, 0.5688117725387885, 0.6019384973006974, 0.5569274609802694, 0.5662093545397966, 0.6209901449872084, 0.5809427640963525, 0.6298919496977115, 0.620882288889044, 0.06181184012113772, 0.1223679823523085, 0.13222082678197533, 0.09484725041033015, 0.11624660175875523, 0.0927186659580691, 0.1104246436091656, 0.1569671915477796, 0.100878467662889, 0.16374497309960623, 0.28118061013890083, 0.28444835284075387, 0.5146349380374877, 0.4475718711928204, 0.427401565607161, 0.23060941788764178, 0.20134736755262927, 0.4271508950950046, 0.494113344540525, 0.41499050455840747, 0.28643736312410906, 0.42078514050497284, 0.31910151380031193, 0.2130837470651069, 0.2493164715197823, 0.4288834611657961, 0.40451612180400975, 0.19631676542184284, 0.27252196059641565, 0.23029545124689055, 0.17984989480832358, 0.22459145456261476, 0.2114415785148468, 0.11193472964582685, 0.43029466689469675, 0.10610490954799423, 0.25560381118768083, 0.24013885057466655, 0.21796399901256358, 0.22299809399990322, 0.19904991620492796, 0.24148332500544223, 0.2374352623941478, 0.24438714494558533, 0.2209789183522548, 0.18982840623800024, 0.23047616874107657, 0.18057583112116882, 0.18312974046994546, 0.18182667669034724, 0.19331190878663473, 0.1903273097997007, 0.8512658493850809, 0.22167182858111, 0.188450356347169, 0.12711163711722584, 0.15450625081472302, 0.17356621148953455, 0.2019943346166131, 0.9472563342725691, 0.13230860279688605, 0.17035659357150212, 0.1543502643336354, 0.8824765610507828, 0.7997667252338367, 0.8005300884660108, 0.21123703373910374, 0.15651764319124428, 0.21265042473857199, 0.10526224461415601, 0.10485818132127456, 0.8265905362651459, 0.21481478375503893, 0.21630148792111215, 0.2166417949122046, 0.23129081478515934, 0.20916519958310553, 0.2337598244130853, 0.26732536409875574, 0.220588794553082, 0.19833848681010402, 0.08383814896155928, 0.0687312546533505, 0.08190404558165809, 0.09035310084943193, 0.078327975898287, 0.13320924928135225, 0.07812713095317525, 0.07020877924241464, 0.08926038057649222]}, "mutation_prompt": null}
{"id": "55adf307-a9dd-4059-b3f1-3b83cd5ce13c", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO with diversity influence\n            diversity_influence = np.clip(diversity / 0.1, 0.0, 1.0)  # New dynamic influence\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0) * diversity_influence\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0) * diversity_influence\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A refined hybrid optimizer using adaptive chaotic maps in DEPSO with dynamic diversity handling for improved exploration and convergence.", "configspace": "", "generation": 78, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "50ede7e5-2e50-42a4-a770-60f776374540", "metadata": {"aucs": [0.909001623550968, 0.9134329217720056, 0.8993943779859668, 0.9158118554562988, 0.9013589829086934, 0.9150114765801967, 0.9021174597877144, 0.9138156670046205, 0.9125744964877528, 0.8053156827059855, 0.812933161404119, 0.8427683446328783, 0.7781348046359788, 0.8274522102635543, 0.828173424832739, 0.793219326094488, 0.824438421402234, 0.807396704056346, 0.14307856490968585, 0.1877007390154648, 0.09076342173665886, 0.1591964583304123, 0.18831861632874847, 0.14601053240840012, 0.18654139144744886, 0.11701393588099107, 0.11200295781326008, 0.13396848432302944, 0.14644153775306945, 0.14339728904875682, 0.11180968840087713, 0.09210701640445917, 0.11938455295453443, 0.11206762360979172, 0.1109543262015037, 0.10913140775636909, 0.9717271359469163, 0.9628494159769669, 0.9377212443281838, 0.9810288407887259, 0.9785915503130439, 0.9770423747813494, 0.9783473338829307, 0.9712614510731488, 0.9787075504592555, 0.8400751997050477, 0.8195775155076079, 0.7881844282312709, 0.8069615774854371, 0.6647351094176812, 0.8128780388709002, 0.7612286322176006, 0.7588271737425852, 0.8022987100833393, 0.1721225825938858, 0.22891630584450517, 0.11324758049764427, 0.3549846662771695, 0.2807957237653095, 0.28145549322917607, 0.18018767969655092, 0.2386988483653335, 0.9395469978455472, 0.2997175666775681, 0.13586662398711447, 0.3211070174887374, 0.30914890736930933, 0.2976754184947398, 0.3753418046063097, 0.3033239602168375, 0.13454826076976845, 0.33685734603098483, 0.2855770542165944, 0.29120995093888746, 0.3008429981206525, 0.3672405168291414, 0.34373280443664067, 0.3578761578521632, 0.34181385559198785, 0.21016117222284347, 0.3115571058923854, 0.008727263917975292, 0.08405164954335087, 0.011850008464092898, 0.08318211192036928, 0.07217735139935322, 0.03142619455841433, 0.04249344742194738, 0.025945981813413677, 0.09877842365536249, 0.1474919909201995, 0.141424992338533, 0.10026151620075452, 0.0743538479383109, 0.1574587084945428, 0.025851253849927147, 0.11186001170601811, 0.09280097636767337, 0.1259968055351952, 0.07767230228498723, 0.125700215669862, 0.14837587801063767, 0.07870400003360734, 0.08187488224500394, 0.13824893561798346, 0.20742707829110663, 0.10455436376687322, 0.07516878362234314, 0.16371204613017887, 0.17734513841698796, 0.1130997564449634, 0.15378399216657745, 0.18209434842377636, 0.3417765465751007, 0.12180265509212573, 0.2533156932791293, 0.12740470136058157, 0.5819335199298167, 0.6313484977267598, 0.5578846315167447, 0.5675966336331973, 0.6799789016998201, 0.6049326971772399, 0.5911486760862344, 0.580885195385775, 0.598043750011304, 0.07975460775792109, 0.1011111842861161, 0.07552750669347386, 0.16077690683898838, 0.10588349774705907, 0.09912511857108985, 0.11381727276782971, 0.14416034740706962, 0.10610711934398476, 0.21734862004612598, 0.33923697374688966, 0.22495475767554407, 0.280533557148542, 0.47464323252920537, 0.3197150873271738, 0.5860861304255904, 0.21109682521114592, 0.3094983026206324, 0.4205334895981335, 0.4518994289447642, 0.2472168505177742, 0.5188342035664053, 0.3198040425626848, 0.5553825593531537, 0.49120441312897245, 0.3949912876407873, 0.1914962937954372, 0.3036021477043075, 0.2489684388194079, 0.20181638951509895, 0.32429487625029674, 0.1973023536598133, 0.24838788207350626, 0.2569341450765401, 0.2680332522799035, 0.17284697234167834, 0.24221577925087046, 0.24261914374082905, 0.22661527401643466, 0.21621523555871425, 0.23220195984323055, 0.2121859746984508, 0.22233176434332813, 0.19428032015735874, 0.2939974916905508, 0.183487209346463, 0.2507320722375961, 0.20750258869604155, 0.22962367216205004, 0.8156527533966519, 0.18887850620055235, 0.19948653489031232, 0.2261229111774895, 0.19660724644923688, 0.9186498515751226, 0.1773002007066008, 0.11326659663798577, 0.17278315101148478, 0.9213299666235599, 0.20071979040917576, 0.09964906490722802, 0.1699169308750712, 0.1627177906678935, 0.8646748104763389, 0.8047439807740762, 0.7774456621310986, 0.9244609999809484, 0.8581326776386955, 0.8425766490198829, 0.10514649497698247, 0.16991868188429704, 0.16636172125525261, 0.19794976969146916, 0.24297119069175488, 0.21100720171394982, 0.19740091513709368, 0.25121027229113, 0.19102423719310313, 0.2521876131625387, 0.2327495132079318, 0.22259688316861492, 0.0888611108833085, 0.07113528606779584, 0.11154311319513621, 0.09666703924322662, 0.08292524730122819, 0.14774519369036387, 0.10332744390907811, 0.10547157291197706, 0.09783618943502193]}, "mutation_prompt": null}
{"id": "0f71afa4-8306-4cc0-93ab-0057bb0ec9ef", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO with diversity influence\n            diversity_influence = np.clip(diversity / 0.1, 0.0, 1.0)  # New dynamic influence\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0) * diversity_influence\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0) * diversity_influence\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "An enhanced hybrid optimizer using adaptive chaotic maps and diversity-aware parameter tuning for improved exploration and convergence.", "configspace": "", "generation": 82, "fitness": 0.3565642169096091, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.30.", "error": "", "parent_id": "50ede7e5-2e50-42a4-a770-60f776374540", "metadata": {"aucs": [0.909001623550968, 0.9134329217720056, 0.8993943779859668, 0.9158118554562988, 0.9013589829086934, 0.9150114765801967, 0.9021174597877144, 0.9138156670046205, 0.9125744964877528, 0.8053156827059855, 0.812933161404119, 0.8427683446328783, 0.7781348046359788, 0.8274522102635543, 0.828173424832739, 0.793219326094488, 0.824438421402234, 0.807396704056346, 0.14307856490968585, 0.1877007390154648, 0.09076342173665886, 0.1591964583304123, 0.18831861632874847, 0.14601053240840012, 0.18654139144744886, 0.11701393588099107, 0.11200295781326008, 0.13396848432302944, 0.14644153775306945, 0.14339728904875682, 0.11180968840087713, 0.09210701640445917, 0.11938455295453443, 0.11206762360979172, 0.1109543262015037, 0.10913140775636909, 0.9717271359469163, 0.9628494159769669, 0.9377212443281838, 0.9810288407887259, 0.9785915503130439, 0.9770423747813494, 0.9783473338829307, 0.9712614510731488, 0.9787075504592555, 0.8400751997050477, 0.8195775155076079, 0.7881844282312709, 0.8069615774854371, 0.6647351094176812, 0.8128780388709002, 0.7612286322176006, 0.7588271737425852, 0.8022987100833393, 0.1721225825938858, 0.22891630584450517, 0.11324758049764427, 0.3549846662771695, 0.2807957237653095, 0.28145549322917607, 0.18018767969655092, 0.2386988483653335, 0.9395469978455472, 0.2997175666775681, 0.13586662398711447, 0.3211070174887374, 0.30914890736930933, 0.2976754184947398, 0.3753418046063097, 0.3033239602168375, 0.13454826076976845, 0.33685734603098483, 0.2855770542165944, 0.29120995093888746, 0.3008429981206525, 0.3672405168291414, 0.34373280443664067, 0.3578761578521632, 0.34181385559198785, 0.21016117222284347, 0.3115571058923854, 0.008727263917975292, 0.08405164954335087, 0.011850008464092898, 0.08318211192036928, 0.07217735139935322, 0.03142619455841433, 0.04249344742194738, 0.025945981813413677, 0.09877842365536249, 0.1474919909201995, 0.141424992338533, 0.10026151620075452, 0.0743538479383109, 0.1574587084945428, 0.025851253849927147, 0.11186001170601811, 0.09280097636767337, 0.1259968055351952, 0.07767230228498723, 0.125700215669862, 0.14837587801063767, 0.07870400003360734, 0.08187488224500394, 0.13824893561798346, 0.20742707829110663, 0.10455436376687322, 0.07516878362234314, 0.16371204613017887, 0.17734513841698796, 0.1130997564449634, 0.15378399216657745, 0.18209434842377636, 0.3417765465751007, 0.12180265509212573, 0.2533156932791293, 0.12740470136058157, 0.5819335199298167, 0.6313484977267598, 0.5578846315167447, 0.5675966336331973, 0.6799789016998201, 0.6049326971772399, 0.5911486760862344, 0.580885195385775, 0.598043750011304, 0.07975460775792109, 0.1011111842861161, 0.07552750669347386, 0.16077690683898838, 0.10588349774705907, 0.09912511857108985, 0.11381727276782971, 0.14416034740706962, 0.10610711934398476, 0.21734862004612598, 0.33923697374688966, 0.22495475767554407, 0.280533557148542, 0.47464323252920537, 0.3197150873271738, 0.5860861304255904, 0.21109682521114592, 0.3094983026206324, 0.4205334895981335, 0.4518994289447642, 0.2472168505177742, 0.5188342035664053, 0.3198040425626848, 0.5553825593531537, 0.49120441312897245, 0.3949912876407873, 0.1914962937954372, 0.3036021477043075, 0.2489684388194079, 0.20181638951509895, 0.32429487625029674, 0.1973023536598133, 0.24838788207350626, 0.2569341450765401, 0.2680332522799035, 0.17284697234167834, 0.24221577925087046, 0.24261914374082905, 0.22661527401643466, 0.21621523555871425, 0.23220195984323055, 0.2121859746984508, 0.22233176434332813, 0.19428032015735874, 0.2939974916905508, 0.183487209346463, 0.2507320722375961, 0.20750258869604155, 0.22962367216205004, 0.8156527533966519, 0.18887850620055235, 0.19948653489031232, 0.2261229111774895, 0.19660724644923688, 0.9186498515751226, 0.1773002007066008, 0.11326659663798577, 0.17278315101148478, 0.9213299666235599, 0.20071979040917576, 0.09964906490722802, 0.1699169308750712, 0.1627177906678935, 0.8646748104763389, 0.8047439807740762, 0.7774456621310986, 0.9244609999809484, 0.8581326776386955, 0.8425766490198829, 0.10514649497698247, 0.16991868188429704, 0.16636172125525261, 0.19794976969146916, 0.24297119069175488, 0.21100720171394982, 0.19740091513709368, 0.25121027229113, 0.19102423719310313, 0.2521876131625387, 0.2327495132079318, 0.22259688316861492, 0.0888611108833085, 0.07113528606779584, 0.11154311319513621, 0.09666703924322662, 0.08292524730122819, 0.14774519369036387, 0.10332744390907811, 0.10547157291197706, 0.09783618943502193]}, "mutation_prompt": null}
{"id": "4512f351-f075-43f5-a0fe-27e4652a5bc4", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if np.random.rand() < self.diversity_probability and diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO with diversity influence\n            diversity_influence = np.clip(diversity / 0.1, 0.0, 1.0)  # New dynamic influence\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0) * diversity_influence\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0) * diversity_influence\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A hybrid optimizer combining DEPSO with adaptive chaotic maps and dynamic diversity strategies, enhanced with stochastic influence for improved exploration and stability.", "configspace": "", "generation": 83, "fitness": 0.33909390147047275, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.", "error": "", "parent_id": "50ede7e5-2e50-42a4-a770-60f776374540", "metadata": {"aucs": [0.9092475863133456, 0.9135620241100434, 0.9076968908018705, 0.9004882828188208, 0.9011585514613664, 0.9121186743353593, 0.9187881354714225, 0.9194248416230568, 0.9229079173695619, 0.8147750242129724, 0.8045704438556519, 0.8160048864795368, 0.8053408260329127, 0.8285511446030892, 0.7826025117953997, 0.7998402089495051, 0.8222003396817573, 0.807250514939658, 0.13190861914779473, 0.14415854872702516, 0.1572848948404426, 0.7872744017455066, 0.14570287581281538, 0.11160141077915453, 0.11666582094621003, 0.16104239135031728, 0.11670130871789897, 0.05349162243917782, 0.0783492236850154, 0.12897587771682828, 0.12428079373694967, 0.1104697426162291, 0.1435930754040422, 0.14258578732297122, 0.11656107676089, 0.12005382280772914, 0.9751431842519613, 0.9520051127182892, 0.9691922179457932, 0.9775415504993196, 0.9673497532326539, 0.9614678757887042, 0.9808550405425054, 0.9681765328537765, 0.9780770028806784, 0.7931055995784297, 0.7815242420662196, 0.059976224959373714, 0.8155039528007627, 0.15438188725191015, 0.7897801131322111, 0.8017402114429305, 0.7621560150381945, 0.8207280035309452, 0.22942662322750973, 0.2286033820413036, 0.17104475898418825, 0.21483513652303365, 0.21471502313228852, 0.2797835261799315, 0.17821557084354012, 0.2474546323931197, 0.3409787786841195, 0.30116771683459675, 0.3198406968703026, 0.30243412696821437, 0.3305693605125367, 0.13535932815689522, 0.3061238878009782, 0.33365071036005123, 0.32503998640924825, 0.3177756307232439, 0.2964357814997477, 0.31630345183363406, 0.2957695992219951, 0.3593429360183462, 0.3279679218216385, 0.32335326607618464, 0.30964931749815483, 0.5566423746349136, 0.3192370838849147, 0.0606275072686685, 0.06252383501791059, 9.999999999998899e-05, 0.05057501248068452, 0.04961459339425056, 9.999999999998899e-05, 0.03737161004116463, 0.0068892469478538665, 0.01632892741283143, 0.18465983329034208, 0.0702163457829218, 0.1244218074713852, 0.06698745307182818, 0.0560861373934296, 0.06780235783474231, 0.14055412373298382, 0.09084389313363295, 0.07202295240093992, 0.22645717765668438, 0.08495054556323178, 0.14153785498383153, 0.30662063347667246, 0.07931320774446415, 0.08216826431449686, 0.1826079355249821, 0.12866294764478448, 0.07524688431316795, 0.11011444591108754, 0.20896172197955398, 0.1271465613581957, 0.13841735309924952, 0.20319104456985038, 0.14615354979389283, 0.12064359702319849, 0.4058160730977808, 0.08507541691103948, 0.5348181954810367, 0.5378637547613749, 0.5376959683251384, 0.5891772472983741, 0.6096668567078956, 0.5711595363913784, 0.6369268890516377, 0.5948926782339667, 0.5929388589017967, 0.14492715492705754, 0.12388674383797571, 0.061513835933922345, 0.10104762670274448, 0.14310765415094606, 0.15797961805739758, 0.1622232451233926, 0.08975404348427396, 0.13575419158231394, 0.32727201789126337, 0.238203980946608, 0.6135187804732701, 0.25171232085982265, 0.275294386532993, 0.2703788610630439, 0.19630384438219395, 0.22015380097251225, 0.2703766234320373, 0.25518513168910717, 0.21378431868336178, 0.22564062048704658, 0.43849809364298753, 0.3194627629660898, 0.3286385418112229, 0.5845768617111654, 0.3929680987629044, 0.27040485751541066, 0.23516275320296076, 0.20547236803088142, 0.38906338916655514, 0.1919814636162973, 0.20679264919021378, 0.21031138820102402, 0.1912290556978231, 0.3008931235178376, 0.276667072885351, 0.2879607092252263, 0.27394311306269625, 0.22851172888742421, 0.24226792832387456, 0.24960777331257833, 0.23656218013434327, 0.25243341024127364, 0.20958184743526964, 0.24944950006915012, 0.20247192010913895, 0.22637892606705667, 0.20457321727554223, 0.2027597637654931, 0.2501161323186628, 0.20860020765380838, 0.18149804864702546, 0.17903145562825562, 0.18775277427186288, 0.19933698153455104, 0.17852165974540735, 0.15403817843607126, 0.1695050862917884, 0.20102257903869258, 0.933386259671362, 0.12248242235279472, 0.17007486245593828, 0.15451473510177494, 0.8592574398917057, 0.21325504799983241, 0.7846661493484879, 0.8778590108004347, 0.21264649695392523, 0.879843516767816, 0.10521261229109846, 0.8500868365321695, 0.16803979596027363, 0.20807294581065028, 0.22139416638197595, 0.21882109102656988, 0.21901071272755013, 0.23970430700970113, 0.19947935770001235, 0.2236332468542942, 0.22829853438078285, 0.22252086753911182, 0.10343605422841451, 0.11755193013772025, 0.06868988982586599, 0.10660291228319185, 0.10557291141329805, 0.14575353240975875, 0.09481812154526126, 0.09689245023357884, 0.1130320315236053]}, "mutation_prompt": null}
{"id": "807311d4-640b-4f0c-8720-982499198cf6", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO with diversity influence\n            diversity_influence = np.clip(diversity / 0.1, 0.0, 1.0)  # New dynamic influence\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0) * diversity_influence\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0) * diversity_influence\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A refined hybrid optimizer with adaptive chaotic maps in DEPSO and dynamic diversity handling to enhance exploration and exploitation balance.", "configspace": "", "generation": 84, "fitness": 0.3565642169096091, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.30.", "error": "", "parent_id": "50ede7e5-2e50-42a4-a770-60f776374540", "metadata": {"aucs": [0.909001623550968, 0.9134329217720056, 0.8993943779859668, 0.9158118554562988, 0.9013589829086934, 0.9150114765801967, 0.9021174597877144, 0.9138156670046205, 0.9125744964877528, 0.8053156827059855, 0.812933161404119, 0.8427683446328783, 0.7781348046359788, 0.8274522102635543, 0.828173424832739, 0.793219326094488, 0.824438421402234, 0.807396704056346, 0.14307856490968585, 0.1877007390154648, 0.09076342173665886, 0.1591964583304123, 0.18831861632874847, 0.14601053240840012, 0.18654139144744886, 0.11701393588099107, 0.11200295781326008, 0.13396848432302944, 0.14644153775306945, 0.14339728904875682, 0.11180968840087713, 0.09210701640445917, 0.11938455295453443, 0.11206762360979172, 0.1109543262015037, 0.10913140775636909, 0.9717271359469163, 0.9628494159769669, 0.9377212443281838, 0.9810288407887259, 0.9785915503130439, 0.9770423747813494, 0.9783473338829307, 0.9712614510731488, 0.9787075504592555, 0.8400751997050477, 0.8195775155076079, 0.7881844282312709, 0.8069615774854371, 0.6647351094176812, 0.8128780388709002, 0.7612286322176006, 0.7588271737425852, 0.8022987100833393, 0.1721225825938858, 0.22891630584450517, 0.11324758049764427, 0.3549846662771695, 0.2807957237653095, 0.28145549322917607, 0.18018767969655092, 0.2386988483653335, 0.9395469978455472, 0.2997175666775681, 0.13586662398711447, 0.3211070174887374, 0.30914890736930933, 0.2976754184947398, 0.3753418046063097, 0.3033239602168375, 0.13454826076976845, 0.33685734603098483, 0.2855770542165944, 0.29120995093888746, 0.3008429981206525, 0.3672405168291414, 0.34373280443664067, 0.3578761578521632, 0.34181385559198785, 0.21016117222284347, 0.3115571058923854, 0.008727263917975292, 0.08405164954335087, 0.011850008464092898, 0.08318211192036928, 0.07217735139935322, 0.03142619455841433, 0.04249344742194738, 0.025945981813413677, 0.09877842365536249, 0.1474919909201995, 0.141424992338533, 0.10026151620075452, 0.0743538479383109, 0.1574587084945428, 0.025851253849927147, 0.11186001170601811, 0.09280097636767337, 0.1259968055351952, 0.07767230228498723, 0.125700215669862, 0.14837587801063767, 0.07870400003360734, 0.08187488224500394, 0.13824893561798346, 0.20742707829110663, 0.10455436376687322, 0.07516878362234314, 0.16371204613017887, 0.17734513841698796, 0.1130997564449634, 0.15378399216657745, 0.18209434842377636, 0.3417765465751007, 0.12180265509212573, 0.2533156932791293, 0.12740470136058157, 0.5819335199298167, 0.6313484977267598, 0.5578846315167447, 0.5675966336331973, 0.6799789016998201, 0.6049326971772399, 0.5911486760862344, 0.580885195385775, 0.598043750011304, 0.07975460775792109, 0.1011111842861161, 0.07552750669347386, 0.16077690683898838, 0.10588349774705907, 0.09912511857108985, 0.11381727276782971, 0.14416034740706962, 0.10610711934398476, 0.21734862004612598, 0.33923697374688966, 0.22495475767554407, 0.280533557148542, 0.47464323252920537, 0.3197150873271738, 0.5860861304255904, 0.21109682521114592, 0.3094983026206324, 0.4205334895981335, 0.4518994289447642, 0.2472168505177742, 0.5188342035664053, 0.3198040425626848, 0.5553825593531537, 0.49120441312897245, 0.3949912876407873, 0.1914962937954372, 0.3036021477043075, 0.2489684388194079, 0.20181638951509895, 0.32429487625029674, 0.1973023536598133, 0.24838788207350626, 0.2569341450765401, 0.2680332522799035, 0.17284697234167834, 0.24221577925087046, 0.24261914374082905, 0.22661527401643466, 0.21621523555871425, 0.23220195984323055, 0.2121859746984508, 0.22233176434332813, 0.19428032015735874, 0.2939974916905508, 0.183487209346463, 0.2507320722375961, 0.20750258869604155, 0.22962367216205004, 0.8156527533966519, 0.18887850620055235, 0.19948653489031232, 0.2261229111774895, 0.19660724644923688, 0.9186498515751226, 0.1773002007066008, 0.11326659663798577, 0.17278315101148478, 0.9213299666235599, 0.20071979040917576, 0.09964906490722802, 0.1699169308750712, 0.1627177906678935, 0.8646748104763389, 0.8047439807740762, 0.7774456621310986, 0.9244609999809484, 0.8581326776386955, 0.8425766490198829, 0.10514649497698247, 0.16991868188429704, 0.16636172125525261, 0.19794976969146916, 0.24297119069175488, 0.21100720171394982, 0.19740091513709368, 0.25121027229113, 0.19102423719310313, 0.2521876131625387, 0.2327495132079318, 0.22259688316861492, 0.0888611108833085, 0.07113528606779584, 0.11154311319513621, 0.09666703924322662, 0.08292524730122819, 0.14774519369036387, 0.10332744390907811, 0.10547157291197706, 0.09783618943502193]}, "mutation_prompt": null}
{"id": "8163231f-e990-4231-b62f-5e88dfc5851b", "solution": "import numpy as np\n\nclass AdvancedAdaptiveChaoticDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.9  # DE scaling factor\n        self.cr = 0.85  # DE crossover probability\n        self.w = 0.4  # inertia weight for PSO\n        self.c1 = 1.6  # cognitive coefficient for PSO\n        self.c2 = 1.4  # social coefficient for PSO\n        self.vel_max = 0.8  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-6\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.8, 1.0)  # Enhanced chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 75.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.95\n\n            # Dynamic parameter tuning for PSO with diversity influence\n            diversity_influence = np.clip(diversity / 0.05, 0.0, 1.0)\n            self.c1 = 1.4 + 0.6 * np.cos(self.iteration / 30.0) * diversity_influence\n            self.c2 = 1.6 + 0.4 * np.sin(self.iteration / 30.0) * diversity_influence\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "AdvancedAdaptiveChaoticDEPSO", "description": "An adaptive chaotic DEPSO with improved diversity dynamics and enriched parameter control for robust convergence.", "configspace": "", "generation": 85, "fitness": 0.33725354569766824, "feedback": "The algorithm AdvancedAdaptiveChaoticDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.30.", "error": "", "parent_id": "50ede7e5-2e50-42a4-a770-60f776374540", "metadata": {"aucs": [0.9348332966095717, 0.9306214302243846, 0.9239980325593797, 0.9320957875926518, 0.9384899127197487, 0.9213461979214407, 0.9317001299916645, 0.9357651044492048, 0.9298830537425394, 0.8711344264641723, 0.8319541528737222, 0.8558945673547596, 0.8620248177456498, 0.8340468284880367, 0.8507976531800595, 0.8736642870356319, 0.8389924894506899, 0.8398059071431349, 0.10084860711655275, 0.13668868853071747, 0.06420805124534212, 0.1249681974412018, 0.10491486326973809, 0.1472463291516629, 0.13544148739013728, 0.1443699850893354, 0.1610288901618998, 0.13306234445967147, 0.09936227292346755, 0.10632463740975595, 0.08996041977742897, 0.10197406834206335, 0.11457225514256275, 0.08901818672157857, 0.11151356477400076, 0.1343783594994824, 0.9737215952631183, 0.9673061874409319, 0.9679975716574604, 0.9684899476453488, 0.9648491641293091, 0.9686187460578757, 0.9773260996645121, 0.972067669267969, 0.9803077796910225, 0.8572537687188548, 0.05988368695385904, 0.8178840637701685, 0.8332095825123976, 0.825283899103818, 0.8316081262397954, 0.8284401759615099, 0.8210307439459976, 0.8159458172174698, 0.17137076229275205, 0.23007148288244839, 0.1400971539413255, 0.2143902910068448, 0.22129399335458055, 0.2799177229062616, 0.2239552635781391, 0.23734589607891232, 0.40195649531285105, 0.3116357651321505, 0.4917765737531524, 0.3182130402253238, 0.3095658508055158, 0.13662548811131892, 0.3148748932478208, 0.3239737786110548, 0.3541838340338368, 0.3569454880786814, 0.2892576858830471, 0.285426341336512, 0.2864547404814458, 0.1363380784163477, 0.2947490598363607, 0.3425770921710761, 0.3071796318291308, 0.31323057326703185, 0.13203404436996713, 0.005955176210140634, 0.13663963700925308, 0.06817916653260525, 0.06512079243543578, 9.999999999998899e-05, 9.999999999998899e-05, 0.038504180856817394, 0.06359448519420097, 0.012292477305518523, 0.1054162241889024, 0.09900861064027122, 0.06355924746182229, 0.06681275896843619, 0.07207498921565225, 0.08228630515110003, 0.07735545286064893, 0.1416274254524722, 0.018052629655296415, 0.13804734175165645, 0.15997430500315335, 0.15491828861370138, 0.08100815646878312, 0.08217894821054483, 0.22515360833182507, 0.2705777826875567, 0.17630864195979923, 0.07679355403950827, 0.29983911745782477, 0.09726387033068717, 0.11499530255282475, 0.19886302369572517, 0.08458933046782036, 9.999999999998899e-05, 0.0843108878147043, 0.11380737701807031, 0.09704626628138757, 0.557110085708237, 0.6074920539626362, 0.5718772534640559, 0.5715658362040981, 0.5840280555073544, 0.5536796792314838, 0.5906394351062147, 0.586253608623519, 0.6265469423734413, 0.1011354725321788, 0.09588627088080215, 0.1607999074373625, 0.13327038482868703, 0.11213740074776901, 0.12660651786848343, 0.11270024408763368, 0.14451600888498428, 0.0938004356819847, 0.16172938104467072, 0.17436212550464147, 0.22445030529262955, 0.2801811454426667, 0.2929280921679077, 0.20220937172495357, 0.2962115543890552, 0.30438528478664717, 0.23874034274906086, 0.39381385579789563, 0.2524130427949344, 0.15753804490351975, 0.26511977085725014, 0.4951852298088878, 0.2870887917311703, 0.5959091554077942, 0.5330635164116164, 0.2296488281151795, 0.2462489837247812, 0.2623721943986441, 0.24529760117273536, 0.36166657845706085, 0.2370220590620037, 0.2316100883328438, 0.34698055136741657, 0.25117239289238247, 0.2430389516123289, 0.22244170736532287, 0.20986841654268995, 0.20800685115577622, 0.24049654356397154, 0.259795338685719, 0.28110119748473716, 0.28844368305839374, 0.256830021300844, 0.22383324627080958, 0.1840689988932449, 0.2540052958220236, 0.22725115710916755, 0.20441935938155142, 0.21101194078488517, 0.17388883127749954, 0.19365147539304994, 0.17854920628275817, 0.18481062909404555, 0.938961521046233, 0.18640509377890058, 0.15333704618660304, 0.1882291301994271, 0.2012719695741373, 0.9409700252335871, 0.19891101085073348, 0.16997275273778356, 0.16817589674717492, 0.7778536015104285, 0.1697165766250397, 0.8600199787313825, 0.9014672020847255, 0.2112682318175937, 0.9234700257599665, 0.10520189182661766, 0.16924477378627567, 0.10510081079327394, 0.21070947459807587, 0.19398771336727028, 0.19485607927164283, 0.19674257060380274, 0.19707874089793598, 0.20638075664989708, 0.21630109875342252, 0.1965567421947082, 0.19935490152306778, 0.09511321358415392, 0.11114426638073727, 0.11463350084359536, 0.1100821457003478, 0.10148033690545322, 0.13287754132899188, 0.09077473438530648, 0.09582869056454879, 0.10432879930290406]}, "mutation_prompt": null}
{"id": "6ec64f8c-8328-49fc-a479-9b111610d918", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO with diversity influence\n            diversity_influence = np.clip(diversity / 0.1, 0.0, 1.0)  # New dynamic influence\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0) * diversity_influence\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0) * diversity_influence\n\n            # Apply PSO operator with stochastic velocity adjustments\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if np.random.rand() < self.diversity_probability:  # Randomly adjust velocities\n                    self.velocities[i] += np.random.normal(0, 0.1, self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A novel hybrid optimizer using adaptive chaotic maps in DEPSO with dynamic diversity handling and stochastic velocity adjustments for improved exploration and convergence.", "configspace": "", "generation": 86, "fitness": 0.3134218993989188, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.27.", "error": "", "parent_id": "50ede7e5-2e50-42a4-a770-60f776374540", "metadata": {"aucs": [0.8905421890411217, 0.8542049674625047, 0.882456212954537, 0.8818129352666839, 0.9015497977640551, 0.8632945137184059, 0.888641543717736, 0.8380443605751505, 0.8935259625951861, 0.4258619293059873, 0.47448426064270555, 0.44903441943754974, 0.41208336682102975, 0.5808700885486283, 0.550223163442833, 0.40554321605804744, 0.5631862921717095, 0.3163198924640833, 0.14476075433794322, 0.13201614038664156, 0.08118340524577417, 0.18699541451365953, 0.11808970405773289, 0.11816243854656039, 0.0984577361712079, 0.1150843253252215, 0.13491681234934205, 0.13150481885975618, 0.10696704232498666, 0.11319384570355995, 0.10604408818014255, 0.12329168079615516, 0.11138322981036586, 0.0875460079725845, 0.10903591668764745, 0.08817300939331219, 0.9664416866709913, 0.9625959915139661, 0.9644570435305434, 0.9633403525098039, 0.9669783254407296, 0.9775984729936656, 0.981994258233035, 0.9603163267256112, 0.9808002411781648, 0.6684195039275731, 0.5221030171415628, 0.6265719904542476, 0.625272412777901, 0.7194355664051344, 0.6864923667983422, 0.5680780050065268, 0.6263029171201906, 0.7079901857193968, 0.8713818437939564, 0.21344075103259985, 0.209468874824839, 0.2153446126826527, 0.21526243005732393, 0.2801838614574167, 0.8708009500837902, 0.23815208248622466, 0.9070861140331272, 0.2771008884259968, 0.11764611060236907, 0.27801608970970015, 0.2495255035693993, 0.13402676445484407, 0.2847993173121205, 0.1330709670189565, 0.13301063482046904, 0.2402232774452927, 0.23773385211217557, 0.23755029148384244, 0.270003169345867, 0.24919443710864964, 0.24901491893057282, 0.2835453710815239, 0.2715185287558616, 0.13545079158847673, 0.1796790466321596, 0.08251187091337164, 0.054458642485823106, 0.00019790169512468037, 0.04648818109557795, 0.06076218738534567, 9.999999999998899e-05, 9.999999999998899e-05, 0.05270624806425461, 0.0101475352414363, 0.1148934862858052, 0.2234669260770189, 0.10070936213559978, 0.07751766991058906, 0.07316885204760526, 0.04206483151988816, 0.0922377559112958, 0.09236939828996316, 0.11750102814429686, 0.22401916587975257, 0.25983476271842165, 0.09432318497670422, 0.09737568048999035, 0.08062488122842948, 0.1511174712561476, 0.255060459703646, 0.2005640004507686, 0.0757889348249311, 0.20095494120322943, 0.12371450777924142, 0.10142472277907622, 0.014770940884141437, 0.08192762959891131, 0.15267791283425036, 0.058324638973347054, 0.19979929624501946, 0.10363920416212136, 0.535591228495607, 0.5187857995475905, 0.5730744790994904, 0.5903384763015977, 0.5683032259512681, 0.5543406748080983, 0.60015424530753, 0.5337699021271951, 0.5999266849698908, 0.09948353640700336, 0.08902030012222895, 0.11273911810444603, 0.15430321553086235, 0.11098225420090435, 0.09720587295248184, 0.08464988636648574, 0.09830327471979472, 0.12285180282088226, 0.2135751316788269, 0.3276999524017158, 0.20699066920546938, 0.3362039012682486, 0.2613550316191098, 0.1959773813171105, 0.26001201280905295, 0.2809006198748534, 0.2658866907136559, 0.4645972791430688, 0.435124591208776, 0.46112867983812134, 0.29326228080392114, 0.23871647350570613, 0.2604112551224187, 0.4897458468818784, 0.4870329319997825, 0.31181120595201717, 0.3742195188985187, 0.22093551060619077, 0.2562916651773317, 0.2430606603679486, 0.16213602082709733, 0.3301968451325521, 0.2640247165007852, 0.296403303294392, 0.11477041781916975, 0.26678502265562165, 0.21089153575866337, 0.2071096050499326, 0.22465548751640152, 0.22351698008715415, 0.2313879095155278, 0.26500484499316423, 0.17353244414156266, 0.2251070247338698, 0.22634218614234092, 0.20514937364591856, 0.22561776131381184, 0.19467932710344338, 0.1973215074159208, 0.19735188355016198, 0.19643001043258224, 0.22677704848431668, 0.20856892847161845, 0.9168201033517162, 0.17751240645750277, 0.18811046152365885, 0.9278692077418278, 0.9194779412188027, 0.20096462261552905, 0.1421297737110383, 0.17023700450655466, 0.1543384165159294, 0.8094812412599532, 0.2134571983674325, 0.11267936947970558, 0.21278773611728696, 0.16960981282918508, 0.21176753131189752, 0.10494411935746739, 0.16987505806992031, 0.766835714762241, 0.1976865352709578, 0.2045985633476055, 0.20353571532268566, 0.21632329121244387, 0.19013468892860397, 0.18574038304133078, 0.20248214627919692, 0.2114656271506411, 0.2149351855487458, 0.11704153954281515, 0.09414129208699629, 0.10130382454274744, 0.09073861639696057, 0.10555878956959608, 0.1424569637728902, 0.09575511178100782, 0.10250850270649248, 0.09805248081474094]}, "mutation_prompt": null}
{"id": "74203eda-ee13-4b13-8453-288ed15a9200", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO with diversity influence\n            diversity_influence = np.clip(diversity / 0.1, 0.0, 1.0)  # New dynamic influence\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0) * diversity_influence\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0) * diversity_influence\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "An enhanced hybrid optimizer integrating chaotic maps in DEPSO with adaptive diversity measures and dynamic PSO parameters for robust exploration and exploitation.", "configspace": "", "generation": 87, "fitness": 0.3565642169096091, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.30.", "error": "", "parent_id": "50ede7e5-2e50-42a4-a770-60f776374540", "metadata": {"aucs": [0.909001623550968, 0.9134329217720056, 0.8993943779859668, 0.9158118554562988, 0.9013589829086934, 0.9150114765801967, 0.9021174597877144, 0.9138156670046205, 0.9125744964877528, 0.8053156827059855, 0.812933161404119, 0.8427683446328783, 0.7781348046359788, 0.8274522102635543, 0.828173424832739, 0.793219326094488, 0.824438421402234, 0.807396704056346, 0.14307856490968585, 0.1877007390154648, 0.09076342173665886, 0.1591964583304123, 0.18831861632874847, 0.14601053240840012, 0.18654139144744886, 0.11701393588099107, 0.11200295781326008, 0.13396848432302944, 0.14644153775306945, 0.14339728904875682, 0.11180968840087713, 0.09210701640445917, 0.11938455295453443, 0.11206762360979172, 0.1109543262015037, 0.10913140775636909, 0.9717271359469163, 0.9628494159769669, 0.9377212443281838, 0.9810288407887259, 0.9785915503130439, 0.9770423747813494, 0.9783473338829307, 0.9712614510731488, 0.9787075504592555, 0.8400751997050477, 0.8195775155076079, 0.7881844282312709, 0.8069615774854371, 0.6647351094176812, 0.8128780388709002, 0.7612286322176006, 0.7588271737425852, 0.8022987100833393, 0.1721225825938858, 0.22891630584450517, 0.11324758049764427, 0.3549846662771695, 0.2807957237653095, 0.28145549322917607, 0.18018767969655092, 0.2386988483653335, 0.9395469978455472, 0.2997175666775681, 0.13586662398711447, 0.3211070174887374, 0.30914890736930933, 0.2976754184947398, 0.3753418046063097, 0.3033239602168375, 0.13454826076976845, 0.33685734603098483, 0.2855770542165944, 0.29120995093888746, 0.3008429981206525, 0.3672405168291414, 0.34373280443664067, 0.3578761578521632, 0.34181385559198785, 0.21016117222284347, 0.3115571058923854, 0.008727263917975292, 0.08405164954335087, 0.011850008464092898, 0.08318211192036928, 0.07217735139935322, 0.03142619455841433, 0.04249344742194738, 0.025945981813413677, 0.09877842365536249, 0.1474919909201995, 0.141424992338533, 0.10026151620075452, 0.0743538479383109, 0.1574587084945428, 0.025851253849927147, 0.11186001170601811, 0.09280097636767337, 0.1259968055351952, 0.07767230228498723, 0.125700215669862, 0.14837587801063767, 0.07870400003360734, 0.08187488224500394, 0.13824893561798346, 0.20742707829110663, 0.10455436376687322, 0.07516878362234314, 0.16371204613017887, 0.17734513841698796, 0.1130997564449634, 0.15378399216657745, 0.18209434842377636, 0.3417765465751007, 0.12180265509212573, 0.2533156932791293, 0.12740470136058157, 0.5819335199298167, 0.6313484977267598, 0.5578846315167447, 0.5675966336331973, 0.6799789016998201, 0.6049326971772399, 0.5911486760862344, 0.580885195385775, 0.598043750011304, 0.07975460775792109, 0.1011111842861161, 0.07552750669347386, 0.16077690683898838, 0.10588349774705907, 0.09912511857108985, 0.11381727276782971, 0.14416034740706962, 0.10610711934398476, 0.21734862004612598, 0.33923697374688966, 0.22495475767554407, 0.280533557148542, 0.47464323252920537, 0.3197150873271738, 0.5860861304255904, 0.21109682521114592, 0.3094983026206324, 0.4205334895981335, 0.4518994289447642, 0.2472168505177742, 0.5188342035664053, 0.3198040425626848, 0.5553825593531537, 0.49120441312897245, 0.3949912876407873, 0.1914962937954372, 0.3036021477043075, 0.2489684388194079, 0.20181638951509895, 0.32429487625029674, 0.1973023536598133, 0.24838788207350626, 0.2569341450765401, 0.2680332522799035, 0.17284697234167834, 0.24221577925087046, 0.24261914374082905, 0.22661527401643466, 0.21621523555871425, 0.23220195984323055, 0.2121859746984508, 0.22233176434332813, 0.19428032015735874, 0.2939974916905508, 0.183487209346463, 0.2507320722375961, 0.20750258869604155, 0.22962367216205004, 0.8156527533966519, 0.18887850620055235, 0.19948653489031232, 0.2261229111774895, 0.19660724644923688, 0.9186498515751226, 0.1773002007066008, 0.11326659663798577, 0.17278315101148478, 0.9213299666235599, 0.20071979040917576, 0.09964906490722802, 0.1699169308750712, 0.1627177906678935, 0.8646748104763389, 0.8047439807740762, 0.7774456621310986, 0.9244609999809484, 0.8581326776386955, 0.8425766490198829, 0.10514649497698247, 0.16991868188429704, 0.16636172125525261, 0.19794976969146916, 0.24297119069175488, 0.21100720171394982, 0.19740091513709368, 0.25121027229113, 0.19102423719310313, 0.2521876131625387, 0.2327495132079318, 0.22259688316861492, 0.0888611108833085, 0.07113528606779584, 0.11154311319513621, 0.09666703924322662, 0.08292524730122819, 0.14774519369036387, 0.10332744390907811, 0.10547157291197706, 0.09783618943502193]}, "mutation_prompt": null}
{"id": "3734bfb2-4725-4489-a699-942c37c6ab11", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n        self.velocity_reset_interval = 50  # Added parameter for velocity reset\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Periodic velocity reset for better escape from local minima\n            if self.iteration % self.velocity_reset_interval == 0:\n                self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n\n            # Dynamic parameter tuning for PSO with diversity influence\n            diversity_influence = np.clip(diversity / 0.1, 0.0, 1.0)  # New dynamic influence\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0) * diversity_influence\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0) * diversity_influence\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A refined hybrid optimizer using adaptive chaotic maps in DEPSO with dynamic diversity handling and periodic velocity reset for improved exploration and convergence.", "configspace": "", "generation": 88, "fitness": 0.3379191863214996, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.28.", "error": "", "parent_id": "50ede7e5-2e50-42a4-a770-60f776374540", "metadata": {"aucs": [0.8989899705566312, 0.9183455739941243, 0.9154240448281761, 0.9174754226919007, 0.9172313522299714, 0.9184481262949202, 0.9253513927501492, 0.8909066915632962, 0.8991750478450872, 0.6496884969558097, 0.6555760290568082, 0.6864014349963192, 0.6639993351612157, 0.04916287494113547, 0.6947833531034233, 0.6528206709419053, 0.6117862369115552, 0.666123807255687, 0.14523102700818147, 0.15811496391682467, 0.11465309611837182, 0.18379757513020445, 0.12600590982976279, 0.13293298427862532, 0.1319865134756084, 0.12325850131308758, 0.14070599498070535, 0.11564547016262527, 0.053590312141318486, 0.11180875174992522, 0.1386771905891102, 0.11085432306180976, 0.11674144349348203, 0.1115124040547888, 0.07765259716468553, 0.08668769976091406, 0.9711306009286694, 0.9687717881190946, 0.9737835936472278, 0.9631245965446181, 0.9638555715641449, 0.9599552083710199, 0.9599745151494478, 0.970726539976182, 0.9738478934519056, 0.6952686381251044, 0.7328911068653936, 0.6928482636990523, 0.7331126133416599, 0.7322536907493933, 0.6817554063246765, 0.7350223018751376, 0.6712703043633466, 0.6384965327631349, 0.3942888422718639, 0.17127393323202122, 0.22810076747092922, 0.2820313451954013, 0.21428290047688348, 0.2155018532549018, 0.2267773007680668, 0.36875912909536723, 0.45903416977016565, 0.20093675750500173, 0.26775779431346514, 0.25385324326317127, 0.2484758514169494, 0.26277239777485806, 0.30756986354597715, 0.2700339487089527, 0.2582985086638362, 0.26903931106970347, 0.24558565898183526, 0.18436386765058188, 0.2582646233983148, 0.22554907192386386, 0.29998769261047253, 0.29380133962552224, 0.2777183381326138, 0.26346972013588354, 0.28152045826767513, 0.002159729654681697, 0.153611623086797, 0.03529957389945726, 0.004628276122401798, 9.999999999998899e-05, 0.00029677958151586026, 9.999999999998899e-05, 0.10536729261967981, 0.11498549915862788, 0.14266457678787703, 0.05302225295768548, 0.2132618819479174, 0.0803521230157237, 0.06304663268438015, 0.020564218941495516, 0.0773025885339641, 0.07014922324314699, 0.06035843274815944, 0.09667361800863383, 0.14613001356873956, 0.22872757025506585, 0.09638409982394225, 0.18752518892086267, 0.08714964133993364, 0.136285522529903, 0.10953320102337671, 0.07448326277368211, 0.05391831222372834, 0.20791446923746748, 0.09842547253231082, 0.12426949432288659, 0.15928716160748624, 0.03637753581980652, 0.282219645826716, 0.08368482722567061, 0.08580307946935262, 0.5523287362931562, 0.5333497459672529, 0.5569891168429228, 0.6404518441119524, 0.5991505011680065, 0.5682570294176201, 0.5630068955499936, 0.5699813724293543, 0.599773866065518, 0.06793307454874065, 0.1317163900261379, 0.09140375732276429, 0.14389842241475181, 0.08555555912306734, 0.1553754833926434, 0.1564962239575911, 0.11656243429991431, 0.10940417927018609, 0.1991573009569645, 0.2240580639882852, 0.23820056351579844, 0.20412443403912606, 0.35494109289965337, 0.1855657023314481, 0.43818685389097445, 0.22570354806976733, 0.4846968729611355, 0.33659366339037033, 0.32574272381651415, 0.2647921089516885, 0.39066082569437643, 0.42278422171572094, 0.4763327257472574, 0.2579991347324817, 0.5435877521004788, 0.2772200667738153, 0.23054223403148721, 0.259979128890656, 0.17743712632095265, 0.34171238838550666, 0.2598948071100108, 0.1814727920175997, 0.3187774724827752, 0.2313009004059814, 0.24980019961313715, 0.23234296281379263, 0.2279622064402509, 0.2051624731980498, 0.21804533764771916, 0.20219185336496115, 0.24598735471626076, 0.22891162163303758, 0.2430385760543995, 0.25344498367399415, 0.2115814191052181, 0.2001789874222012, 0.8030132875587168, 0.21916248078338163, 0.20227945351884058, 0.19281843389118536, 0.18224084565377263, 0.25281122912774534, 0.1953382983595887, 0.12651821139419572, 0.18842562894894221, 0.15443844462121492, 0.9444260034921181, 0.20173594216959911, 0.9300498198785091, 0.15935537817788936, 0.9326485509291186, 0.169134241159279, 0.8170856687782264, 0.21282534555391763, 0.8225244300093665, 0.7781607777564714, 0.1686379036487755, 0.7925361318205637, 0.8103047501308636, 0.853509382568796, 0.783353943153676, 0.20738468439824032, 0.18747231332495162, 0.24385431108603284, 0.2126724593892273, 0.20692123190299583, 0.19627943574736495, 0.21108014977228762, 0.19279939938525892, 0.20416781866138167, 0.1013419827521217, 0.10846726742220547, 0.11215722435150177, 0.08498650170836353, 0.11518811463711032, 0.1432786667511069, 0.10969212449926913, 0.10411379991851355, 0.09285776736109386]}, "mutation_prompt": null}
{"id": "9c28255a-8667-49f1-ae48-92e371f2cd68", "solution": "import numpy as np\n\nclass AdvancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # initial inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(4 * x * (1 - x), 1.0)  # Logistic map for chaos\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(np.random.rand())\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w = np.random.uniform(0.4, 0.9)  # Randomize inertia weight for exploration\n\n            # Dynamic parameter tuning for PSO with diversity influence\n            diversity_influence = np.clip(diversity / 0.1, 0.0, 1.0)\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 25.0) * diversity_influence\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 25.0) * diversity_influence\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "AdvancedHybridDEPSO", "description": "AdvancedHybridDEPSO: Integrates adaptive inertia weights with a stochastic chaotic map and dynamic scaling to improve convergence balance between exploration and exploitation.", "configspace": "", "generation": 89, "fitness": 0.33537179630762465, "feedback": "The algorithm AdvancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.", "error": "", "parent_id": "50ede7e5-2e50-42a4-a770-60f776374540", "metadata": {"aucs": [0.8989313187482371, 0.913891623789685, 0.8940974315713827, 0.9010098282099808, 0.19096554483844397, 0.904584663968029, 0.9285479613648179, 0.9142464437495418, 0.9091495089220515, 0.7617285105265585, 0.7811642085667283, 0.793611161493478, 0.7817238150111614, 0.7775448307978239, 0.813419182484807, 0.7814004053675899, 0.8311508649607665, 0.791525987766011, 0.14228716133593045, 0.12514409478604105, 0.812883061930708, 0.11009503616523875, 0.1341201922989974, 0.11656970149404222, 0.11813882868793446, 0.10938046392970302, 0.11563355655907692, 0.11802122396087511, 0.10796960300357461, 0.110527800705855, 0.11627982799598047, 0.11744492937876017, 0.10714052379265449, 0.1066607757872523, 0.1392827241113146, 0.11132278048267397, 0.9778769088557119, 0.9829452519310141, 0.9696273166078241, 0.9640331351167616, 0.9722758920636082, 0.9790137266448868, 0.9683501174050818, 0.9780870557883493, 0.9666707453223707, 0.7737782505061882, 0.7598456062221979, 0.8090307546794115, 0.8150011712058525, 0.2799534682924806, 0.15485732091146542, 0.8090957405756536, 0.7650644721289074, 0.803892794687981, 0.35322327626328365, 0.24360429383850135, 0.14096125505495094, 0.19482157383574317, 0.2766603410629268, 0.9305064943110157, 0.8503839234419901, 0.903634246841744, 0.35632761535990365, 0.45956652264626197, 0.30909594571165566, 0.28955479551735985, 0.3092985700038966, 0.3234706065123061, 0.36410475588771474, 0.2857462096403599, 0.13574153802072397, 0.30688088125322244, 0.2804865979861523, 0.28698623642379006, 0.12985175397292803, 0.33884815731848694, 0.30601538185396115, 0.32450086112363774, 0.3357693247781661, 0.3238448649785908, 0.3167872210808118, 9.999999999998899e-05, 0.003546900013214893, 0.06357464920595157, 0.15440735513283688, 9.999999999998899e-05, 0.0545853257350587, 0.043388465741581395, 0.004056204399449204, 0.06403004564575387, 0.09473819357091395, 0.09783226136833256, 0.19004280432956167, 0.11230722988509301, 0.03449027708144581, 0.02993265766265707, 0.0940229321346534, 0.0899737938213162, 0.09169898783679997, 0.046940936173776926, 0.11091581567880215, 0.23428750346117677, 0.08194837999325444, 0.08787763617830147, 0.1280371669791559, 0.13683046135222643, 0.12934723231884182, 0.08724302033180442, 0.12244601541920386, 0.28869110753927985, 0.15574964811876857, 0.03901996076728831, 0.2247321964841562, 0.11460514165781699, 0.23687980190792957, 0.08436244996101194, 0.08553408812147612, 0.5698209234720878, 0.5948523606660387, 0.5921777567842305, 0.5934341341743393, 0.5785427145770385, 0.6326291794131912, 0.5600186951308349, 0.5982052624587109, 0.6137694632060897, 0.12992826584723005, 0.12462430035843441, 0.08174793075313447, 0.10653157659026424, 0.14216980817865954, 0.10854563994892963, 0.12314460079275691, 0.12345490391557867, 0.13064669440749854, 0.16886835458066507, 0.2614404293990392, 0.15965946937813114, 0.40879102963865066, 0.33404045289690076, 0.26867095784319994, 0.27243455925016447, 0.22377069535466376, 0.2617892583019532, 0.4034003642107534, 0.34040367951795114, 0.37210131753912523, 0.42786602079175073, 0.3091847171733437, 0.3703368321231023, 0.5966821991411341, 0.4256482556675333, 0.18484453683558755, 0.21336729804285692, 0.4083924425459612, 0.31814411918692054, 0.26072360975942155, 0.18712462277513153, 0.21682930532234113, 0.23289909226869498, 0.4673758140276172, 0.13170180903302497, 0.20697220546521133, 0.21539976180392195, 0.22582239381274405, 0.2257371889999521, 0.26153944652551286, 0.2271967668562499, 0.2091210342371197, 0.21667909532422314, 0.23720782142629027, 0.1795840068080372, 0.2242855879046468, 0.18936223316453604, 0.227151312357474, 0.20952738593134623, 0.17438291474918555, 0.2099503009487439, 0.20945817150951096, 0.19896381099055827, 0.9479952238687613, 0.18790190211782676, 0.17287331656959215, 0.17303782391305178, 0.2009942741594476, 0.17902729963323583, 0.1681995663720982, 0.9474587527919646, 0.1535794914206885, 0.8142460514605304, 0.2118834902207053, 0.8147196411080109, 0.21316987526388897, 0.11306114281128299, 0.15652754764166565, 0.12869050788109504, 0.1562259778732885, 0.10482691625694462, 0.2175072366015941, 0.22257298937446146, 0.17780629170319384, 0.19735650288251805, 0.21006157564247008, 0.2274904145378166, 0.19877361663450088, 0.20105133779688444, 0.22394822868381703, 0.1056654287126566, 0.10223284123431786, 0.07895309430432773, 0.08906513171048569, 0.0984441501365676, 0.07071034147408084, 0.08910352012621692, 0.09963221091822894, 0.09449219829435329]}, "mutation_prompt": null}
{"id": "b3e8ecb0-b5cb-4d7c-9d5c-c326a531ac58", "solution": "import numpy as np\n\nclass RefinedChaoticDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.iteration = 0\n        self.mutation_probability = 0.05\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with time-varying chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                if np.random.rand() < self.mutation_probability:\n                    trial = np.random.uniform(self.lb, self.ub, self.dim)  # Random reset with a small probability\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity with a time-varying strategy\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO with diversity influence\n            diversity_influence = np.clip(diversity / 0.1, 0.0, 1.0)  # New dynamic influence\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0) * diversity_influence\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0) * diversity_influence\n\n            # Apply PSO operator with additional strategy adjustments\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "RefinedChaoticDEPSO", "description": "A strategically refined DEPSO optimizer using adaptive chaotic maps with time-varying probability-based strategy adjustments for enhanced robustness.", "configspace": "", "generation": 90, "fitness": 0.337373541863857, "feedback": "The algorithm RefinedChaoticDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.", "error": "", "parent_id": "50ede7e5-2e50-42a4-a770-60f776374540", "metadata": {"aucs": [0.9175876330773947, 0.8974627811361992, 0.9181145872727375, 0.9183258912085099, 0.9070094103507358, 0.9022846050650599, 0.9093598236153989, 0.9196701806015043, 0.915247517971898, 0.7919461292486616, 0.805514027345364, 0.8361725959673909, 0.7525605621996803, 0.7692851925892337, 0.8121321102385604, 0.8230457301413385, 0.7993673977994052, 0.8185812944259319, 0.14355141550785233, 0.15823373530424611, 0.09203199774162008, 0.12401101396822889, 0.13186426260945827, 0.11375702976905488, 0.12531920733093316, 0.15012568722662634, 0.12070663451062158, 0.08410991174370774, 0.10134936954682472, 0.08504929431287345, 0.12495219286505854, 0.09607896502287627, 0.13101043773880194, 0.09196803007574905, 0.07839698505194825, 0.14189958121958446, 0.9851667598839599, 0.9745402430027563, 0.964620283359631, 0.9708906101376785, 0.9782670307758605, 0.9743214643597936, 0.963576571498154, 0.974928389021827, 0.9565949959385948, 0.8007729633968365, 0.7813677122671812, 0.7997594713938367, 0.7869086789985246, 0.8104124085210307, 0.7493041629539274, 0.800886546672295, 0.7889348130531203, 0.7785628689445347, 0.9312504546437923, 0.39564132889033576, 0.17031269885661782, 0.2099973650258551, 0.1947351290590673, 0.9121028585649839, 0.23102277580656105, 0.3915205182483462, 0.2379809724472589, 0.30444004625793775, 0.135860463828687, 0.28869594242749685, 0.26419505917596253, 0.29547375354754624, 0.27775430151879776, 0.301495804028137, 0.2806070827670698, 0.3320072777660361, 0.285688571312516, 0.2738327412456367, 0.33527362685167594, 0.33392037756216486, 0.38259070306916665, 0.34388255034789583, 0.30026089296665914, 0.31160731078718495, 0.3534090040410163, 0.0005495900024025113, 0.06520269582461224, 0.21542048439838368, 0.04175727886208913, 0.031048131823210867, 0.037879183391525295, 0.0064693562338173916, 0.003419465564243551, 0.04096202687721939, 0.16512853759962987, 0.10748768160178601, 0.18955880444572315, 0.12977116145077816, 0.025814123037305348, 0.07243541703256784, 0.07523017678649235, 0.07140234330769402, 0.05847009814791271, 0.14281465072368538, 0.09701060462721, 0.40136737550969015, 0.08101689040979476, 0.12930930303342558, 0.14182195628223748, 0.1043700698376373, 0.12910878829090777, 0.34403577463546275, 0.2323893176046964, 0.22413984915275753, 0.08868934572676024, 0.19238015173035694, 0.11873263404395107, 0.08744536483905818, 0.12236437410344492, 0.26457309375324867, 0.08460208537115399, 0.537837921600654, 0.5592806976074939, 0.6084158080854412, 0.5474535886485916, 0.5724357767350081, 0.5475803057048378, 0.5833680685839051, 0.5856347356376846, 0.5974744589494023, 0.07024095437564226, 0.1242663551055313, 0.11980881719253356, 0.11586638607546351, 0.15629193048645706, 0.11117682699233611, 0.10852040310578193, 0.13232345748250096, 0.14388955480228194, 0.21577503875039505, 0.2638303970429384, 0.1671329635843667, 0.19933579595041095, 0.4665533336745016, 0.20605269645969515, 0.21908711683128346, 0.16981667007364598, 0.4153236801335869, 0.2705428505779123, 0.33608617246983563, 0.2139052182903315, 0.3426613333756482, 0.2580276467460988, 0.5522162461998962, 0.5769391943189047, 0.41333081753202117, 0.2392962263127526, 0.2636793293764709, 0.2021421777754464, 0.23695276504098273, 0.1840738244808101, 0.19843825129008608, 0.283151826181681, 0.2278589822359507, 0.24143944019660013, 0.26050367497820326, 0.24869867582198568, 0.22142522543661358, 0.2653408408832123, 0.25490766619321115, 0.21275945223201986, 0.23120800006309616, 0.22027281583312308, 0.235916600425235, 0.24393119473484826, 0.18881839312659143, 0.19853291849632215, 0.2003798670685163, 0.20474075937193592, 0.189029767057874, 0.21051777882964307, 0.223763768846296, 0.24779965233275347, 0.22467430724662485, 0.9311850230632898, 0.1687370305980277, 0.17211805591545448, 0.91997579711062, 0.20103865876087346, 0.17961078525046448, 0.16691589914744542, 0.1703689404894312, 0.17845517850479498, 0.8527026337070431, 0.2121773631645837, 0.2120975306729168, 0.21319231220079105, 0.2130659760649386, 0.21269742117957302, 0.0944942908259947, 0.16937136656006857, 0.16942051181266948, 0.19096426400467104, 0.2114971967119884, 0.2330132362526599, 0.2104598179970043, 0.21704610272715796, 0.188712423626459, 0.2062695714855326, 0.19189437076283822, 0.21730377282535374, 0.0875836122596162, 0.10498889532766753, 0.09661122573627345, 0.10194410546928179, 0.10223306908943663, 0.10263344384831197, 0.10891614631111757, 0.10468859374306394, 0.14192602524588294]}, "mutation_prompt": null}
{"id": "9ba2fa2b-443c-4ebe-a311-ab011ca359b7", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSOV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO with diversity influence\n            diversity_influence = np.clip(diversity / 0.1, 0.0, 1.0)\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0) * diversity_influence\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0) * diversity_influence\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSOV2", "description": "A novel hybrid optimizer leveraging adaptive chaotic maps and dynamic diversity handling in DEPSO for optimal exploration and convergence.", "configspace": "", "generation": 91, "fitness": 0.3565642169096091, "feedback": "The algorithm EnhancedHybridDEPSOV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.30.", "error": "", "parent_id": "50ede7e5-2e50-42a4-a770-60f776374540", "metadata": {"aucs": [0.909001623550968, 0.9134329217720056, 0.8993943779859668, 0.9158118554562988, 0.9013589829086934, 0.9150114765801967, 0.9021174597877144, 0.9138156670046205, 0.9125744964877528, 0.8053156827059855, 0.812933161404119, 0.8427683446328783, 0.7781348046359788, 0.8274522102635543, 0.828173424832739, 0.793219326094488, 0.824438421402234, 0.807396704056346, 0.14307856490968585, 0.1877007390154648, 0.09076342173665886, 0.1591964583304123, 0.18831861632874847, 0.14601053240840012, 0.18654139144744886, 0.11701393588099107, 0.11200295781326008, 0.13396848432302944, 0.14644153775306945, 0.14339728904875682, 0.11180968840087713, 0.09210701640445917, 0.11938455295453443, 0.11206762360979172, 0.1109543262015037, 0.10913140775636909, 0.9717271359469163, 0.9628494159769669, 0.9377212443281838, 0.9810288407887259, 0.9785915503130439, 0.9770423747813494, 0.9783473338829307, 0.9712614510731488, 0.9787075504592555, 0.8400751997050477, 0.8195775155076079, 0.7881844282312709, 0.8069615774854371, 0.6647351094176812, 0.8128780388709002, 0.7612286322176006, 0.7588271737425852, 0.8022987100833393, 0.1721225825938858, 0.22891630584450517, 0.11324758049764427, 0.3549846662771695, 0.2807957237653095, 0.28145549322917607, 0.18018767969655092, 0.2386988483653335, 0.9395469978455472, 0.2997175666775681, 0.13586662398711447, 0.3211070174887374, 0.30914890736930933, 0.2976754184947398, 0.3753418046063097, 0.3033239602168375, 0.13454826076976845, 0.33685734603098483, 0.2855770542165944, 0.29120995093888746, 0.3008429981206525, 0.3672405168291414, 0.34373280443664067, 0.3578761578521632, 0.34181385559198785, 0.21016117222284347, 0.3115571058923854, 0.008727263917975292, 0.08405164954335087, 0.011850008464092898, 0.08318211192036928, 0.07217735139935322, 0.03142619455841433, 0.04249344742194738, 0.025945981813413677, 0.09877842365536249, 0.1474919909201995, 0.141424992338533, 0.10026151620075452, 0.0743538479383109, 0.1574587084945428, 0.025851253849927147, 0.11186001170601811, 0.09280097636767337, 0.1259968055351952, 0.07767230228498723, 0.125700215669862, 0.14837587801063767, 0.07870400003360734, 0.08187488224500394, 0.13824893561798346, 0.20742707829110663, 0.10455436376687322, 0.07516878362234314, 0.16371204613017887, 0.17734513841698796, 0.1130997564449634, 0.15378399216657745, 0.18209434842377636, 0.3417765465751007, 0.12180265509212573, 0.2533156932791293, 0.12740470136058157, 0.5819335199298167, 0.6313484977267598, 0.5578846315167447, 0.5675966336331973, 0.6799789016998201, 0.6049326971772399, 0.5911486760862344, 0.580885195385775, 0.598043750011304, 0.07975460775792109, 0.1011111842861161, 0.07552750669347386, 0.16077690683898838, 0.10588349774705907, 0.09912511857108985, 0.11381727276782971, 0.14416034740706962, 0.10610711934398476, 0.21734862004612598, 0.33923697374688966, 0.22495475767554407, 0.280533557148542, 0.47464323252920537, 0.3197150873271738, 0.5860861304255904, 0.21109682521114592, 0.3094983026206324, 0.4205334895981335, 0.4518994289447642, 0.2472168505177742, 0.5188342035664053, 0.3198040425626848, 0.5553825593531537, 0.49120441312897245, 0.3949912876407873, 0.1914962937954372, 0.3036021477043075, 0.2489684388194079, 0.20181638951509895, 0.32429487625029674, 0.1973023536598133, 0.24838788207350626, 0.2569341450765401, 0.2680332522799035, 0.17284697234167834, 0.24221577925087046, 0.24261914374082905, 0.22661527401643466, 0.21621523555871425, 0.23220195984323055, 0.2121859746984508, 0.22233176434332813, 0.19428032015735874, 0.2939974916905508, 0.183487209346463, 0.2507320722375961, 0.20750258869604155, 0.22962367216205004, 0.8156527533966519, 0.18887850620055235, 0.19948653489031232, 0.2261229111774895, 0.19660724644923688, 0.9186498515751226, 0.1773002007066008, 0.11326659663798577, 0.17278315101148478, 0.9213299666235599, 0.20071979040917576, 0.09964906490722802, 0.1699169308750712, 0.1627177906678935, 0.8646748104763389, 0.8047439807740762, 0.7774456621310986, 0.9244609999809484, 0.8581326776386955, 0.8425766490198829, 0.10514649497698247, 0.16991868188429704, 0.16636172125525261, 0.19794976969146916, 0.24297119069175488, 0.21100720171394982, 0.19740091513709368, 0.25121027229113, 0.19102423719310313, 0.2521876131625387, 0.2327495132079318, 0.22259688316861492, 0.0888611108833085, 0.07113528606779584, 0.11154311319513621, 0.09666703924322662, 0.08292524730122819, 0.14774519369036387, 0.10332744390907811, 0.10547157291197706, 0.09783618943502193]}, "mutation_prompt": null}
{"id": "52fefbaf-4b9e-40f7-b274-06bc27a4f46b", "solution": "import numpy as np\n\nclass ChaoticallyDrivenAdaptiveDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.9  # DE scaling factor\n        self.cr = 0.8  # DE crossover probability\n        self.w = 0.6  # inertia weight for PSO\n        self.c1 = 1.4  # cognitive coefficient for PSO\n        self.c2 = 1.6  # social coefficient for PSO\n        self.vel_max = 1.5  # increased maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.9, 1.0)  # Chaotic map with higher impact\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.95\n\n            # Dynamic parameter tuning for PSO with stochastic influence\n            stochastic_factor = np.random.uniform(0, 1)\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0) * stochastic_factor\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0) * stochastic_factor\n\n            # Apply PSO operator with stochastic velocity clamping\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                vel_clamp = self.vel_max * stochastic_factor\n                self.velocities[i] = np.clip(self.velocities[i], -vel_clamp, vel_clamp)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "ChaoticallyDrivenAdaptiveDEPSO", "description": "Chaotically Driven Adaptive DEPSO with Stochastic Velocity Clamping for diverse exploration and dynamic convergence.", "configspace": "", "generation": 92, "fitness": 0.32534371598702017, "feedback": "The algorithm ChaoticallyDrivenAdaptiveDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.28.", "error": "", "parent_id": "50ede7e5-2e50-42a4-a770-60f776374540", "metadata": {"aucs": [0.8874055573827424, 0.9088194163256018, 0.9131915794049158, 0.8767563096161034, 0.8981384511515695, 0.8879464665275807, 0.8962508000331615, 0.915751100735847, 0.9212581337572519, 0.7906797707485729, 0.7541305423022914, 0.7134422707508549, 0.7554704684747394, 0.7653781854092983, 0.7747788806205258, 0.7771064374682687, 0.7158455011898618, 0.7694128587879618, 0.14521364876419207, 0.162184004903562, 0.13486138213770138, 0.16106049583500337, 0.13362206765129336, 0.15978460519728965, 0.11857100958874345, 0.19087925539318595, 0.1453456659714255, 0.0699277494593935, 0.0656647164125016, 0.06792389733312976, 0.08632396786161467, 0.1002964529819268, 0.10549020893648231, 0.09886531715675906, 0.09336274398321875, 0.0823001975208354, 0.9616356839267319, 0.9667353662246743, 0.973090637547135, 0.9685678614170725, 0.971165152004685, 0.9756343007511709, 0.959714970703522, 0.9686492876359665, 0.982916793868408, 0.7032307575786494, 0.7591739787323304, 0.7480486185526474, 0.7598851324874458, 0.75316130157632, 0.663218346332219, 0.7287415614661326, 0.7483885621084235, 0.7357722208459008, 0.9300851667385442, 0.35765314558323724, 0.16063324173724047, 0.17511642242236702, 0.2806028615621735, 0.2809042226890761, 0.21698978069533492, 0.17816799560030738, 0.22281958716988914, 0.2731410378571162, 0.3796648792725469, 0.25365431046572184, 0.13353976521291788, 0.27843369067533463, 0.21273953785776822, 0.3099236715238025, 0.2733335915977402, 0.3005766363849771, 0.2654517639480938, 0.2607497208221212, 0.269331539384711, 0.2655398026794784, 0.13509061068967165, 0.13433026759764288, 0.3030591866495276, 0.12366100443721317, 0.27967303733403925, 0.013763651209572125, 0.07918830791977993, 0.1312320371845157, 0.048214700777485464, 0.01885023544353137, 9.999999999998899e-05, 0.002081268731878083, 0.0013606158654527745, 0.005762651782554529, 0.19312693200266517, 0.03554715654366869, 0.1531922020540991, 0.06434705048867362, 0.029977656188853286, 0.031519251988094354, 0.14110157614648688, 0.07331748639768398, 0.021555985916422604, 0.11568239142029413, 0.05438317871775922, 0.09196591312135949, 0.20219835443447076, 0.08253320864694602, 0.267828948511569, 0.11887822568461182, 0.21815961259527228, 0.08590306628921096, 0.11532219347226402, 0.04395660177280136, 0.19355308542886773, 0.17811534647003757, 0.04768871746703751, 0.11473337930577421, 0.25666696920628074, 0.1303695273209865, 0.2644974517051072, 0.6211131081569601, 0.5912032519957823, 0.5462832025979695, 0.5708773389299268, 0.5955070101041601, 0.5641514402707283, 0.6070605137557694, 0.655617828784242, 0.6036538105188956, 0.11670075398283664, 0.11751838936291314, 0.11106809057561817, 0.09562553518637829, 0.11653089540932038, 0.1055628238260422, 0.14589491291075884, 0.1610362575161267, 0.18947039515638386, 0.23653758630165522, 0.279072816752326, 0.23267450294289294, 0.19513689727530714, 0.382327511931404, 0.17401552676133436, 0.41697162067908133, 0.2087882577601039, 0.22758728140086293, 0.4182243853467923, 0.22959423629172293, 0.20169187833941193, 0.4020873852017802, 0.40338567686815374, 0.329795717523946, 0.2606325370341972, 0.504032089878503, 0.24170897199281272, 0.24118440043285705, 0.23597977406475157, 0.3104330029470843, 0.19237453528972592, 0.18470296784053708, 0.21546827377979416, 0.16307766113182165, 0.2699350625696806, 0.278664502831681, 0.2442315741703439, 0.21695257172178584, 0.23661597676591062, 0.29223534364447634, 0.2109652113220606, 0.23363336029973392, 0.2323030786953878, 0.26177673091832065, 0.22675210481838726, 0.1833315553635162, 0.21685214376869377, 0.16939313225414676, 0.20036690162322845, 0.17210283595034037, 0.19926507208880817, 0.18357726958390674, 0.20354944074448633, 0.16256052458505432, 0.15804546481534287, 0.17667748343319922, 0.1545536231907716, 0.15296951634851153, 0.20015758249431048, 0.16585771813560946, 0.16512878394513641, 0.17038884809059096, 0.9418529808389524, 0.16878322566919812, 0.16951407956964382, 0.8094073953867026, 0.20803936721249683, 0.16822388351401674, 0.8901443445669962, 0.10428712762990511, 0.7973344754436174, 0.8587551403077087, 0.19206569584570166, 0.19973844126048734, 0.22874185347546427, 0.19150938211807, 0.19162952091801633, 0.2035606237202312, 0.252162220444375, 0.2125208043005562, 0.21630333762942533, 0.08444480566714319, 0.1027252759078836, 0.10634758692592472, 0.10183208298795365, 0.09461834609275777, 0.08201184752818003, 0.1136389769829429, 0.07611877443111592, 0.11401451950228425]}, "mutation_prompt": null}
{"id": "96f1113a-d6aa-491e-a691-efa33c2d2444", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)  # Simple chaotic map\n\n    def stochastic_perturbation(self, solution):\n        # Stochastic perturbation with 0.05 probability\n        if np.random.rand() < 0.05:\n            perturbation_strength = 0.1\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, solution.shape)\n            solution += perturbation\n            solution = np.clip(solution, self.lb, self.ub)\n        return solution\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n\n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = self.stochastic_perturbation(mutant)\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO with diversity influence\n            diversity_influence = np.clip(diversity / 0.1, 0.0, 1.0)\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0) * diversity_influence\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0) * diversity_influence\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = self.stochastic_perturbation(self.particles[i])\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "A refined hybrid optimizer using adaptive chaotic maps in DEPSO with dynamic diversity handling and stochastic perturbations for improved exploration and convergence.", "configspace": "", "generation": 93, "fitness": 0.3101390019712195, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.26.", "error": "", "parent_id": "50ede7e5-2e50-42a4-a770-60f776374540", "metadata": {"aucs": [0.8822578575433463, 0.8657978742493367, 0.8958123238373511, 0.8087828373512542, 0.9230654827726643, 0.9018979155392288, 0.8437509128116559, 0.9128690224089786, 0.9077013731924876, 0.6709363201010665, 0.3279527817814366, 0.365298548591073, 0.5172555131153127, 0.6027377497412112, 0.5092400666190801, 0.6532993515948115, 0.4226630375457022, 0.41084319281983694, 0.1865756010293913, 0.16284910455866974, 0.16098260791661634, 0.10166404298136111, 0.18101780236141152, 0.13295808108028273, 0.08328501919798637, 0.16044483321287517, 0.16186108658378529, 0.10949703826870971, 0.11781530476961, 0.07566509126911347, 0.12792630891416557, 0.11565993105657013, 0.132890682129004, 0.11121605433763726, 0.11512127350741264, 0.1333798831773596, 0.9813137702516933, 0.9709638222907707, 0.9661589933860226, 0.971325045406649, 0.9682030915115654, 0.964500351278626, 0.9691936142455957, 0.9741772932950695, 0.9682944846637002, 0.5033066075778602, 0.5459423918105883, 0.5984775001870103, 0.6212077630745119, 0.6066235602017804, 0.5156810005913799, 0.5578047752845462, 0.6189633684416963, 0.6376074766718046, 0.23083018995659188, 0.2204771890752555, 0.22735583959414774, 0.28182293067102904, 0.22052621009783246, 0.733541054605005, 0.13939323953606586, 0.12667389852509336, 0.398120018431131, 0.18312812534288214, 0.2546037680145571, 0.2371661497514831, 0.23030976316972307, 0.22905584635250154, 0.22106734704808673, 0.2618840249928893, 0.24915975778122568, 0.2437763953647769, 0.2302403155070405, 0.24514353193667526, 0.2559572212341683, 0.27536836993349434, 0.24363982418988994, 0.13581674684305922, 0.27234967057328874, 0.2664716423817014, 0.22003330047103387, 0.01205761389419635, 9.999999999998899e-05, 0.0074554731380348516, 0.05998819949830814, 9.999999999998899e-05, 0.01194350088459828, 0.007155753732714043, 0.0005555160004354631, 0.0004345665075932148, 0.07415561698462736, 0.06454063040976965, 0.08445279647713144, 0.06203979584209518, 0.03361984799720086, 0.03316074670858671, 0.19111795285845545, 0.04590353358779342, 0.07820956903460696, 0.18806659203711162, 0.051444667015508316, 0.07866976253083846, 0.08400794665290956, 0.13370391473642196, 0.13329366236038132, 0.19318061481091287, 0.09751819376901916, 0.13051533851372588, 0.10194848084181207, 0.13096403696208292, 0.1938938235914186, 0.1456912920866471, 0.1090674274752993, 0.17505569008694855, 0.058030797146559565, 0.08287343324465568, 0.09126123951039189, 0.5737239491225387, 0.556573219793618, 0.5226573021156374, 0.5613290995463367, 0.5560342340667785, 0.5881069011539322, 0.6086993935206356, 0.573485744787605, 0.5741388734097461, 0.09595940147635051, 0.1635851267836782, 0.13353044688901883, 0.1197307137137994, 0.11619724625527483, 0.1310425681925903, 0.12635032925034573, 0.11174935244307582, 0.11430229012421622, 0.20013285794783264, 0.24807891982892605, 0.3407202196061063, 0.28100333370046215, 0.17406590042458647, 0.20472481851343716, 0.259098147203384, 0.38372260090731336, 0.32745087323911226, 0.3323800814181974, 0.40695221017007666, 0.4629199097144642, 0.43128787915583544, 0.27297234371063384, 0.33035729432388994, 0.26286607690966757, 0.4240347939764635, 0.2480400791710773, 0.2502857004505711, 0.3815750447007751, 0.38409205403504043, 0.2363196937097486, 0.20682684326988043, 0.2758904115690237, 0.23809709913154997, 0.34894911714720445, 0.21206739022223797, 0.23390599668667145, 0.22976715164872996, 0.21551810474912003, 0.25579062050681756, 0.2943853951949895, 0.23541506043739213, 0.2609970207664436, 0.1997708019641492, 0.24899544092197834, 0.21193762277487227, 0.1803081273995396, 0.1901407580467388, 0.25348058075024893, 0.21322762767715253, 0.21293941927334736, 0.22173040682084943, 0.19511657268138183, 0.21569669525337654, 0.9379703002112244, 0.16948140760088592, 0.18847824147618975, 0.1791518461679985, 0.2009884008689935, 0.9425883563045906, 0.1542463877346112, 0.13702972539814762, 0.16610195014377582, 0.8077186615561058, 0.21254567433853921, 0.8675457262467394, 0.21300687193648649, 0.08311258554901235, 0.1539574984121742, 0.12878554589433278, 0.8405578971843364, 0.8345733600423373, 0.20453148188492565, 0.20079627953566825, 0.19115451236531522, 0.2074046421834812, 0.19119962767511622, 0.20449831651799932, 0.262814412919007, 0.22755545895221196, 0.2356474070218797, 0.09462377585936321, 0.08773432555031246, 0.0770682668670083, 0.10444430933986859, 0.10100482579623205, 0.138172807749263, 0.10836919372095921, 0.10422649659373706, 0.09689934138002432]}, "mutation_prompt": null}
{"id": "6292be54-ca4f-4f28-8e78-319d716d4a93", "solution": "import numpy as np\n\nclass EnhancedLevyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.diversity_probability = 0.05\n        self.iteration = 0\n\n    def levy_flight(self, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.7, 1.0)\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence and levy flight\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                mutant += self.levy_flight()  # Levy flight perturbation\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity and iterations\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n\n            # Dynamic parameter tuning for PSO with diversity influence\n            diversity_influence = np.clip(diversity / 0.1, 0.0, 1.0)\n            self.c1 = 1.5 + 0.5 * np.cos(self.iteration / 50.0) * diversity_influence\n            self.c2 = 1.5 + 0.5 * np.sin(self.iteration / 50.0) * diversity_influence\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedLevyDEPSO", "description": "Hybrid optimizer combining DEPSO with Levy flight perturbation and adaptive inertia for enhanced exploration and convergence.", "configspace": "", "generation": 94, "fitness": 0.27306012314938594, "feedback": "The algorithm EnhancedLevyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.23.", "error": "", "parent_id": "50ede7e5-2e50-42a4-a770-60f776374540", "metadata": {"aucs": [0.6530600740292803, 0.6600059334464617, 0.6253121574659612, 0.6363523724613087, 0.6338398547593519, 0.6885966207018448, 0.634799519075665, 0.6185411850611866, 0.6417299502352471, 0.13647513626393792, 0.3882862481854126, 0.3277160088625747, 0.38450513602067105, 0.3487252351797555, 0.21147522058176627, 0.35618157105415604, 0.3637649913537754, 0.31007271367403655, 0.11998531930301037, 0.11080789310311445, 0.1553389052483446, 0.13239982276737916, 0.15578117990498463, 0.12656331320389036, 0.14976417341863923, 0.10777235413846697, 0.12280047705901176, 0.11631844434721461, 0.11051514806297347, 0.11942874844643525, 0.1175685261344861, 0.12966876786565829, 0.09629057074440228, 0.12051076807773042, 0.11566916170505392, 0.11651018972882898, 0.984501277645643, 0.9773213850540646, 0.9858643150374155, 0.9711129926162568, 0.9815928047586644, 0.9683045596870806, 0.9775057067251128, 0.9731575274215616, 0.9749528286543379, 0.4197599799540912, 0.42062619935956147, 0.38382364247282064, 0.35335010852838566, 0.4464997929395196, 0.4040871397172834, 0.44271011822431605, 0.41400147297475975, 0.4316623768834402, 0.6191873495670333, 0.35216106905811706, 0.29740858280107785, 0.6176040233430313, 0.24174758955119624, 0.2076392990915259, 0.3481689601312693, 0.28476711865500015, 0.32329533637567653, 0.1219945083333358, 0.17121807128804356, 0.16360017477526345, 0.17309949527064528, 0.15960177432231848, 0.10223503061278183, 0.21927951486354247, 0.1799771992491196, 0.16180335436403093, 0.16582831545094867, 0.1781795357178123, 0.17701359055548727, 0.12709814534444108, 0.12876074139715132, 0.1679107657336384, 0.1636392877522681, 0.17500826027520455, 0.19027644344369232, 9.999999999998899e-05, 0.03511678976453114, 0.10887891889264589, 0.0566830577657258, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12389296298982844, 0.095926213128673, 0.08931836876415888, 0.08011161884028228, 0.03820132977135837, 0.05334987590641227, 0.10832198792944148, 0.10788237752259378, 0.07846414100611288, 0.11162522349915927, 0.06145178355936154, 0.06978689959103412, 0.08712116671634973, 0.04666587814407519, 0.10353309954029888, 0.11178297719884156, 0.04962324744105773, 0.04365298600125189, 0.14820424339100513, 0.1298448501841869, 0.1061774992719191, 0.1009256173730968, 0.15352878178009577, 0.03259929207477763, 0.0714941846849515, 0.05924575061033743, 0.0676384462038011, 0.4691302406743547, 0.4701693607429661, 0.44083446062452625, 0.43186441998024316, 0.4664315964752249, 0.4511081067906595, 0.41943847793315503, 0.49601292992167234, 0.47683720065104207, 0.09989300618877839, 0.12332365719879113, 0.07820622167106173, 0.14071099381902819, 0.09535949544941391, 0.11101560774980046, 0.1037246631540063, 0.09836047619946653, 0.13593238884227343, 0.2275896922235845, 0.3652056018769346, 0.351853129179058, 0.2988008217784627, 0.17529548952349816, 0.16760580115367207, 0.16789723572944293, 0.1649965165446049, 0.21018451237281777, 0.32819174981965504, 0.30746762887687884, 0.3301099309750105, 0.33258192015683263, 0.32545127813939057, 0.3668658084536168, 0.33319501362210435, 0.34367257759148173, 0.3738332829405001, 0.24786396351161644, 0.27277199339823055, 0.23468253395267857, 0.19480896839687079, 0.1721276965457037, 0.19592357871376131, 0.19409102682739743, 0.2658273054423128, 0.20867317445219036, 0.22959029670010156, 0.22621441162089906, 0.26192717789251696, 0.21423653756760985, 0.2056078468284498, 0.20380337659110748, 0.22595421594697007, 0.24186457330950129, 0.20411453998560514, 0.1819969633883458, 0.23093063515915924, 0.22796041302659098, 0.19059722629132936, 0.2086661773000601, 0.49943123974900194, 0.18823353596064163, 0.19114329402728403, 0.2255017127906893, 0.7295102525092558, 0.16535395698016075, 0.1861107363953871, 0.7105923791085129, 0.19844815779516078, 0.7189600255151029, 0.7761699291468427, 0.2057205884999488, 0.7426288954536941, 0.20668711833715947, 0.16848247433943275, 0.4984322083897986, 0.20646529240819056, 0.21009857073681382, 0.6547509902768978, 0.6275610972482302, 0.577517963005274, 0.31262946903867406, 0.1947988970973452, 0.19278432041822802, 0.2091205060623904, 0.20421602916018444, 0.18743529775618162, 0.20222391345699142, 0.196880619017758, 0.20056258608544464, 0.18380361976047488, 0.0988312650606129, 0.09002010832950613, 0.08564696132959781, 0.0895680638783144, 0.08851245107354755, 0.08503885505420572, 0.07424364412473916, 0.08632719596527805, 0.08703542385403817]}, "mutation_prompt": null}
{"id": "6a22ffaf-9764-434c-9048-32105f44da31", "solution": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.9  # DE scaling factor\n        self.cr = 0.85  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.6  # cognitive coefficient for PSO\n        self.c2 = 1.4  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.65, 1.0)  # Modified chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO with diversity influence\n            diversity_influence = np.clip(diversity / 0.1, 0.0, 1.0)\n            self.c1 = 1.6 + 0.4 * np.cos(self.iteration / 50.0) * diversity_influence\n            self.c2 = 1.4 + 0.6 * np.sin(self.iteration / 50.0) * diversity_influence\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "RefinedHybridDEPSO", "description": "A refined hybrid optimizer leveraging adaptive chaotic maps in DEPSO with dynamic parameter tuning and mutation strategies for robust exploration and swift convergence.", "configspace": "", "generation": 95, "fitness": 0.3636022840070253, "feedback": "The algorithm RefinedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.31.", "error": "", "parent_id": "50ede7e5-2e50-42a4-a770-60f776374540", "metadata": {"aucs": [0.9106591392470551, 0.9151362273799442, 0.9211458352651359, 0.9018533913251037, 0.9147667813441753, 0.913079187941077, 0.9126821188709977, 0.914743003210577, 0.9121956892279315, 0.829769294858656, 0.8279243545706415, 0.8312266512575383, 0.8211510289678186, 0.8147201060603015, 0.8000301941169908, 0.7760241830021479, 0.8042718411949789, 0.8166524486487081, 0.15935952341855752, 0.1862463591848056, 0.08941230170219694, 0.1241066524158807, 0.12207854518694661, 0.13969672038685732, 0.1293264245429978, 0.10220479240883829, 0.15841697239310304, 0.09769206250725115, 0.08927569806715097, 0.11704450811418587, 0.11673368088833269, 0.11839128355228479, 0.1612092922127678, 0.09912941030207822, 0.12410849881192754, 0.10397589771574334, 0.9734832478940764, 0.9672967241695916, 0.9663640019712644, 0.9586861221583975, 0.9701304199297195, 0.9711787143856033, 0.9795241682988146, 0.97142693568625, 0.9731946275653333, 0.8236892452576684, 0.8129934633900419, 0.823528614992999, 0.801954855268249, 0.7577911129757786, 0.7826320673487039, 0.08872619695269712, 0.7934960988074276, 0.8098420997267256, 0.885627601556623, 0.140852282115966, 0.13888403651866577, 0.280058752600319, 0.2150471926427675, 0.3803162881634867, 0.8454021719879076, 0.22630665310474418, 0.40067875790010965, 0.1279348694667033, 0.29268084373390346, 0.2776366661160652, 0.29713471954593185, 0.1353684385065459, 0.24091490117617353, 0.13620313320350852, 0.13562637363134744, 0.38402537593497854, 0.29791029888464104, 0.13676130313419876, 0.12847434867110352, 0.33343165556481313, 0.32985993307757366, 0.3326203333383182, 0.3234761655952513, 0.3259986306909407, 0.1077215796516019, 0.003298781642471438, 0.013684726572799621, 0.10161558262856685, 0.0016307934691125459, 0.13422334555308046, 0.056385741962564184, 0.03868364463549301, 0.04328042005386201, 0.024965908742265674, 0.10478324675492512, 0.07371643100059955, 0.07328044637049747, 0.09466253027226523, 0.0404915337285322, 0.12127605135179187, 0.06711656914541986, 0.06607630390339914, 0.06808606518901994, 0.05119633913125232, 0.12496222400573298, 0.08598373376761792, 0.07850145075694692, 0.08290159511493234, 0.16735785236840894, 0.10291119219656542, 0.10205522555970126, 0.07665283135025436, 0.1471313171130847, 0.15581916143363617, 0.11701593643611363, 0.4655681736461841, 0.16048904356507576, 0.1161503499456028, 0.23575995075966283, 0.13048340761389043, 0.08462292517523651, 0.6093966874649663, 0.5916832512707859, 0.5732670966007901, 0.5642896427839403, 0.5652514503658282, 0.5913635594701611, 0.6063043080946147, 0.5726382139055012, 0.597461355197041, 0.14119978761330654, 0.11775730864341671, 0.10936799041912404, 0.1467011598430651, 0.08904649800022924, 0.11099236402631263, 0.15934110553891245, 0.11547928814310815, 0.10861957171910686, 0.21174236037542882, 0.3097311410590605, 0.32342089622366244, 0.30206366918625505, 0.23292514426207145, 0.20792557745187046, 0.6674803141055125, 0.34691742347853227, 0.2297513046562133, 0.512570758435337, 0.4282019135564711, 0.42952731787249576, 0.3650960477338392, 0.22589340923389256, 0.3688130553570155, 0.5417674561188213, 0.694732516473082, 0.2381887902252513, 0.3765252435857578, 0.2404998042489519, 0.33773746447841635, 0.29624475530659833, 0.2138099723044713, 0.25058084842062034, 0.2583220844797627, 0.23757409104150284, 0.23530258141921867, 0.20080485695287775, 0.24169248300938195, 0.28308504883265895, 0.23583026561015963, 0.24634006927843788, 0.20727644836064563, 0.2276203030157644, 0.2153768686790296, 0.20304851377718136, 0.2475045941028866, 0.22368416966946358, 0.22443251059265534, 0.8303189018401445, 0.8500513785565419, 0.22407023119004676, 0.8336437574956065, 0.8188835636258109, 0.20869854404601806, 0.9098537675849655, 0.1650019017273655, 0.1878158094512703, 0.18922153442275025, 0.9102849221718736, 0.9489292964233885, 0.13600845325368427, 0.16959981021831205, 0.15324301400526508, 0.8803505744942954, 0.8044522469734348, 0.773797009813603, 0.831562799292085, 0.21314624644698776, 0.8877506207389676, 0.10530227928810965, 0.16834853784410642, 0.8349341188375318, 0.19120701501873927, 0.19400254113607684, 0.20722000552059372, 0.23097592373142328, 0.21408888444628305, 0.20467353272982036, 0.20638044346961792, 0.1951226475537995, 0.2249999740959273, 0.09460384758903506, 0.09552474417614154, 0.13440215265925648, 0.10086867433765112, 0.10077393306963367, 0.1046649580796215, 0.1073444245170353, 0.10144134663168147, 0.11217330842971585]}, "mutation_prompt": null}
{"id": "85a36f85-9d3a-4221-b263-ef7280990509", "solution": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.9  # DE scaling factor\n        self.cr = 0.85  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.6  # cognitive coefficient for PSO\n        self.c2 = 1.4  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.65, 1.0)  # Modified chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO with diversity influence\n            diversity_influence = np.clip(diversity / 0.1, 0.0, 1.0)\n            self.c1 = 1.6 + 0.4 * np.cos(self.iteration / 50.0) * diversity_influence\n            self.c2 = 1.4 + 0.6 * np.sin(self.iteration / 50.0) * diversity_influence\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "RefinedHybridDEPSO", "description": "A refined hybrid optimizer leveraging adaptive chaotic maps in DEPSO with dynamic parameter tuning and mutation strategies for robust exploration and swift convergence.", "configspace": "", "generation": 96, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "6a22ffaf-9764-434c-9048-32105f44da31", "metadata": {"aucs": [0.9106591392470551, 0.9151362273799442, 0.9211458352651359, 0.9018533913251037, 0.9147667813441753, 0.913079187941077, 0.9126821188709977, 0.914743003210577, 0.9121956892279315, 0.829769294858656, 0.8279243545706415, 0.8312266512575383, 0.8211510289678186, 0.8147201060603015, 0.8000301941169908, 0.7760241830021479, 0.8042718411949789, 0.8166524486487081, 0.15935952341855752, 0.1862463591848056, 0.08941230170219694, 0.1241066524158807, 0.12207854518694661, 0.13969672038685732, 0.1293264245429978, 0.10220479240883829, 0.15841697239310304, 0.09769206250725115, 0.08927569806715097, 0.11704450811418587, 0.11673368088833269, 0.11839128355228479, 0.1612092922127678, 0.09912941030207822, 0.12410849881192754, 0.10397589771574334, 0.9734832478940764, 0.9672967241695916, 0.9663640019712644, 0.9586861221583975, 0.9701304199297195, 0.9711787143856033, 0.9795241682988146, 0.97142693568625, 0.9731946275653333, 0.8236892452576684, 0.8129934633900419, 0.823528614992999, 0.801954855268249, 0.7577911129757786, 0.7826320673487039, 0.08872619695269712, 0.7934960988074276, 0.8098420997267256, 0.885627601556623, 0.140852282115966, 0.13888403651866577, 0.280058752600319, 0.2150471926427675, 0.3803162881634867, 0.8454021719879076, 0.22630665310474418, 0.40067875790010965, 0.1279348694667033, 0.29268084373390346, 0.2776366661160652, 0.29713471954593185, 0.1353684385065459, 0.24091490117617353, 0.13620313320350852, 0.13562637363134744, 0.38402537593497854, 0.29791029888464104, 0.13676130313419876, 0.12847434867110352, 0.33343165556481313, 0.32985993307757366, 0.3326203333383182, 0.3234761655952513, 0.3259986306909407, 0.1077215796516019, 0.003298781642471438, 0.013684726572799621, 0.10161558262856685, 0.0016307934691125459, 0.13422334555308046, 0.056385741962564184, 0.03868364463549301, 0.04328042005386201, 0.024965908742265674, 0.10478324675492512, 0.07371643100059955, 0.07328044637049747, 0.09466253027226523, 0.0404915337285322, 0.12127605135179187, 0.06711656914541986, 0.06607630390339914, 0.06808606518901994, 0.05119633913125232, 0.12496222400573298, 0.08598373376761792, 0.07850145075694692, 0.08290159511493234, 0.16735785236840894, 0.10291119219656542, 0.10205522555970126, 0.07665283135025436, 0.1471313171130847, 0.15581916143363617, 0.11701593643611363, 0.4655681736461841, 0.16048904356507576, 0.1161503499456028, 0.23575995075966283, 0.13048340761389043, 0.08462292517523651, 0.6093966874649663, 0.5916832512707859, 0.5732670966007901, 0.5642896427839403, 0.5652514503658282, 0.5913635594701611, 0.6063043080946147, 0.5726382139055012, 0.597461355197041, 0.14119978761330654, 0.11775730864341671, 0.10936799041912404, 0.1467011598430651, 0.08904649800022924, 0.11099236402631263, 0.15934110553891245, 0.11547928814310815, 0.10861957171910686, 0.21174236037542882, 0.3097311410590605, 0.32342089622366244, 0.30206366918625505, 0.23292514426207145, 0.20792557745187046, 0.6674803141055125, 0.34691742347853227, 0.2297513046562133, 0.512570758435337, 0.4282019135564711, 0.42952731787249576, 0.3650960477338392, 0.22589340923389256, 0.3688130553570155, 0.5417674561188213, 0.694732516473082, 0.2381887902252513, 0.3765252435857578, 0.2404998042489519, 0.33773746447841635, 0.29624475530659833, 0.2138099723044713, 0.25058084842062034, 0.2583220844797627, 0.23757409104150284, 0.23530258141921867, 0.20080485695287775, 0.24169248300938195, 0.28308504883265895, 0.23583026561015963, 0.24634006927843788, 0.20727644836064563, 0.2276203030157644, 0.2153768686790296, 0.20304851377718136, 0.2475045941028866, 0.22368416966946358, 0.22443251059265534, 0.8303189018401445, 0.8500513785565419, 0.22407023119004676, 0.8336437574956065, 0.8188835636258109, 0.20869854404601806, 0.9098537675849655, 0.1650019017273655, 0.1878158094512703, 0.18922153442275025, 0.9102849221718736, 0.9489292964233885, 0.13600845325368427, 0.16959981021831205, 0.15324301400526508, 0.8803505744942954, 0.8044522469734348, 0.773797009813603, 0.831562799292085, 0.21314624644698776, 0.8877506207389676, 0.10530227928810965, 0.16834853784410642, 0.8349341188375318, 0.19120701501873927, 0.19400254113607684, 0.20722000552059372, 0.23097592373142328, 0.21408888444628305, 0.20467353272982036, 0.20638044346961792, 0.1951226475537995, 0.2249999740959273, 0.09460384758903506, 0.09552474417614154, 0.13440215265925648, 0.10086867433765112, 0.10077393306963367, 0.1046649580796215, 0.1073444245170353, 0.10144134663168147, 0.11217330842971585]}, "mutation_prompt": null}
{"id": "4c924592-60a7-481a-be7b-1c4490183801", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.6  # inertia weight for PSO\n        self.c1 = 1.7  # cognitive coefficient for PSO\n        self.c2 = 1.3  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.sin(x * np.pi)  # Sinusoidal chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.95\n\n            # Dynamic parameter tuning for PSO with diversity influence\n            diversity_influence = np.clip(diversity / 0.1, 0.0, 1.0)\n            self.c1 = 1.7 + 0.3 * np.cos(self.iteration / 50.0) * diversity_influence\n            self.c2 = 1.3 + 0.5 * np.sin(self.iteration / 50.0) * diversity_influence\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "An enhanced hybrid optimizer employing sinusoidal chaotic maps in DEPSO with dynamic inertia adjustment and adaptive parameter strategies for improved exploration and convergence.", "configspace": "", "generation": 97, "fitness": 0.3278247931242421, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.28.", "error": "", "parent_id": "6a22ffaf-9764-434c-9048-32105f44da31", "metadata": {"aucs": [0.8877994213679212, 0.8931664232324983, 0.88275333393194, 0.8640612948639426, 0.8631793226585167, 0.907367235249355, 0.8824800043007972, 0.18291514452775026, 0.8831273303615838, 0.7015419160375158, 0.6935036303877868, 0.7700347515450435, 0.6809038297947151, 0.7256646517844694, 0.7426453928219998, 0.7310379621745615, 0.7254324426140709, 0.7050088741064451, 0.08618254655450741, 0.12260487613753013, 0.09426046774664443, 0.07144971480036233, 0.17453083136014047, 0.11610737579880026, 0.15060479601500376, 0.11506532134020342, 0.09571869381737419, 0.10539085866360942, 0.12158520635967873, 0.09272059056275772, 0.13373638536910348, 0.10831107937875772, 0.08700565190273246, 0.11713577255165342, 0.09451303527810373, 0.10560029657785652, 0.9734629752976978, 0.9277000177010535, 0.9710607083516346, 0.9662270062362203, 0.9671187648523951, 0.9632027768685987, 0.9749197221224194, 0.9605141902683848, 0.967801675294149, 0.7322375718385531, 0.05946663081810566, 0.6944482078839027, 0.7463104801303497, 0.7679604830017364, 0.561863076937722, 0.1288555704362494, 0.7548220556731268, 0.7069520228096104, 0.23073175608539676, 0.16922377920920917, 0.8381702520659695, 0.36558976783058517, 0.28253210952994134, 0.8581496793962431, 0.778868379884824, 0.15217775512630705, 0.8622807061868359, 0.27215680558340904, 0.2640366502481001, 0.2345807095882212, 0.28393231372513006, 0.26917228702644136, 0.24174590697214748, 0.2684981011292099, 0.26685491279774254, 0.2543038154953903, 0.2641611007198871, 0.25935860863608573, 0.3273951396432281, 0.3138941447998771, 0.2592929109902863, 0.28539307239623724, 0.29381319918140325, 0.04866125283603473, 0.31084713256748475, 0.012100789080361163, 0.046371418033311795, 0.10146187919743532, 0.04950979244163922, 0.010259511780774333, 0.0063025125081128675, 0.004229158251871534, 9.999999999998899e-05, 9.999999999998899e-05, 0.14174953754322528, 0.0598669285884853, 0.0898776794906142, 0.06519887522214163, 0.022569276483925038, 0.03900588723464915, 0.11593698235011529, 0.0933886724802816, 0.06422054358676121, 0.09808330537700638, 0.10774671370926059, 0.2453114555478022, 0.07753517606506444, 0.08100150330401334, 0.21184957257436243, 0.15694319892080877, 0.09780118872942822, 0.0713432204095037, 0.1878651740755416, 0.05815289752186015, 0.11891838855507997, 0.20693488477590283, 0.20767311165947377, 0.17841360464841416, 0.24625986705767522, 0.04996459816182364, 0.08462857378972055, 0.5775298690993784, 0.5427654231445435, 0.5624547475638082, 0.551006263325837, 0.58922968258005, 0.5660408399374859, 0.5779668751535034, 0.5631891417974686, 0.6417085376206979, 0.12240286597607497, 0.1100191103171907, 0.11056292156746239, 0.1141833611574381, 0.12087388308833902, 0.09293820371756778, 0.11773070702714628, 0.13143756307178323, 0.1459663072605608, 0.16975342403951077, 0.6500338963621546, 0.6110561891867141, 0.26451622014721266, 0.49876216661373984, 0.17834927233240938, 0.7455756513067888, 0.32622970307088095, 0.1792861394109837, 0.3952460581359032, 0.391509653860738, 0.36919419257376396, 0.26957944289163016, 0.23762734995636625, 0.26794522200443005, 0.17873376718120015, 0.4288894622485344, 0.16564270895022548, 0.3207034474827922, 0.2963960537231931, 0.1899938033458226, 0.2351818000465461, 0.178805764100459, 0.28835951954395744, 0.11740771862931165, 0.31859872394034416, 0.4628013671405491, 0.25748475074281585, 0.2332461296835413, 0.2492310537701572, 0.22249244311811567, 0.20456783902418152, 0.2233760509208973, 0.22232446243002002, 0.23570095079830422, 0.27910719571839737, 0.2539086776401114, 0.2067600089947652, 0.2215232981573827, 0.2267417809581227, 0.222761688546958, 0.1860024460899855, 0.2270554615356034, 0.19579927865206548, 0.18567994448472325, 0.18821262818490125, 0.12704150851360063, 0.15454196028721123, 0.17349789052907216, 0.2017451413683954, 0.9427719769855749, 0.13229860290196593, 0.17027732810183738, 0.16844337573822454, 0.8523939189803696, 0.764453289445172, 0.789405758982799, 0.7494569531141899, 0.15648953861441173, 0.21289095713437878, 0.1051383885288788, 0.10472905033274094, 0.8178973408575805, 0.18817728116757504, 0.1829070141854452, 0.23707826824350853, 0.24100114751054935, 0.18780318711369148, 0.1964749238628054, 0.20065842571817138, 0.19607837982741605, 0.21056413518126116, 0.09945045070394576, 0.08045167703807288, 0.09217073044727875, 0.09615711415159367, 0.1006384875195836, 0.11794606006024244, 0.0856647752732499, 0.1056402450847076, 0.14709039294153026]}, "mutation_prompt": null}
{"id": "bb223117-9cb5-4265-9d24-bf364734c49f", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.w = 0.6  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x * 3.9 * (1 - x), 1.0)  # Logistic chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.95\n\n            # Stochastic parameter adaptation for PSO\n            self.c1 = 1.5 + 0.3 * np.random.rand()\n            self.c2 = 1.5 + 0.3 * np.random.rand()\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "EnhancedHybridDEPSO", "description": "An enhanced hybrid optimizer utilizing chaotic maps in DEPSO with stochastic parameter adaptation and diverse mutation strategies for effective exploration and rapid convergence.", "configspace": "", "generation": 98, "fitness": 0.3142109894780252, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.28.", "error": "", "parent_id": "6a22ffaf-9764-434c-9048-32105f44da31", "metadata": {"aucs": [0.821979146206177, 0.8654440444080052, 0.869913698489845, 0.8486143706538104, 0.8786907228579345, 0.8638133913455622, 0.8809318095478824, 0.18299744904949555, 0.8759179684552948, 0.7386725156517, 0.6972065648527654, 0.7147702705952905, 0.7303351996636804, 0.7250549976870675, 9.999999999998899e-05, 0.7269502920990505, 0.7761082560505147, 0.7036907234100105, 0.09328978475577587, 0.15687488349965728, 0.1297310564658214, 0.15610385055420262, 0.12221866003413129, 0.12094369522487336, 0.11831882678345751, 0.12335089514902742, 0.1582685723464332, 0.11619417517151232, 0.06824753636267888, 0.07694020645736988, 0.1431567035740514, 0.11098268507444842, 0.08124505569580942, 0.056676993142672494, 0.08226460338037, 0.05450316735563243, 0.9774928329850007, 0.9658763948610088, 0.9742383279870158, 0.9592947796746392, 0.9641076068537017, 0.9402257037138225, 0.9642112691309508, 0.969644456301677, 0.9703722269840879, 0.7626482588277528, 0.6566933733207736, 0.7045883425507602, 0.6577770987483449, 0.7238276630686395, 0.6621540491940917, 0.6717090281847482, 0.6804559783010105, 0.6658808614113596, 0.22904412703780375, 0.14097220676165867, 0.17093989500596163, 0.28263439128916656, 0.20828447815619333, 0.8435455774536353, 0.23771992255843488, 0.5577922623897813, 0.3985353775403937, 0.20525864527851345, 0.13454310465436625, 0.2704456859785713, 0.23070646653653815, 0.25882845852074576, 0.3139754087186658, 0.25737725676448153, 0.25811985810012406, 0.13336539052395058, 0.2547725324142107, 0.2755971093027739, 0.13325080917012566, 0.27001583107119, 0.2604089066051051, 0.2937131278209544, 0.13358292944839267, 9.999999999998899e-05, 0.2824684429041693, 9.999999999998899e-05, 0.07644529612989004, 0.00016858001932851252, 0.05649661580289378, 0.014913269279802854, 0.05520518411880038, 0.005094787406126899, 9.999999999998899e-05, 0.0021481190249978965, 0.05335507142332607, 0.06690846174632425, 0.11504392611266212, 0.05561499844023143, 0.024848258377899057, 0.046470411395264644, 0.23157025323466596, 0.12207133221349575, 0.068832654195772, 0.0501950349927629, 0.10892734714865326, 0.049122149456091946, 0.14134125659837904, 0.11113302780817069, 0.11344401002267368, 0.17432357937915055, 0.22316686092003724, 0.07360047946545778, 0.11871978432141861, 0.09820750631366282, 0.2952103730841139, 0.11347717513425248, 0.12301173311474578, 0.0802548376975667, 0.0837757980066639, 0.0667259027466014, 0.0837670884905749, 0.613681548451769, 0.6209521310747922, 0.5955651830375223, 0.5555993425274988, 0.5960375964604425, 0.5839951026816412, 0.5892297150875944, 0.6293809388285168, 0.5766866365202583, 0.06482429542679802, 0.06993421653078791, 0.11957505790005818, 0.12079947232226973, 0.07997188232160202, 0.11086987033516849, 0.17994413670271947, 0.1383917135397562, 0.09790869756943976, 0.1580021764879027, 0.5687810067378821, 0.3450310827224998, 0.7043020262678887, 0.2833159610688242, 0.15898544867479236, 0.2760656194582847, 0.2649079705013073, 0.32357948389025926, 0.4090199212720158, 0.5582278121549805, 0.1535993217987105, 0.45112196992650877, 0.35517293158050833, 0.5484647247528505, 0.16918770548871453, 0.4726099249633623, 0.15701542858774065, 0.23172822163096884, 0.24304205707324922, 0.15697780053957489, 0.24292584567339537, 0.17265702298306462, 0.13836843959306044, 0.2249149491701079, 0.26719424559942795, 0.26988520763061175, 0.22235120787434948, 0.28254914162135647, 0.2446529220061454, 0.22094701305454068, 0.22278338051515356, 0.23694263052599018, 0.25146653991627976, 0.2566189916296655, 0.23923542414510002, 0.2263622799253009, 0.191946996678801, 0.24789676341538158, 0.20162977470043775, 0.2542052387306927, 0.18894823866060007, 0.227363259698382, 0.2085470925581332, 0.2083390524330755, 0.19897929456260655, 0.18875868225558212, 0.1544280775083644, 0.17345914064177836, 0.2022799673528607, 0.9278982440139358, 0.13228229565707628, 0.1704625394996956, 0.15382443169587656, 0.837790879991694, 0.21389363520897753, 0.807486009732796, 0.11276068103580161, 0.8940554524574285, 0.2125442404615272, 0.10512926087491048, 0.10466219324603354, 0.8155215938137264, 0.21110782202074252, 0.20901478017745045, 0.224861642628032, 0.19442052416462186, 0.22988179392272146, 0.21366670118728703, 0.21011988212490573, 0.2176894154269603, 0.20092201016540634, 0.10394617206755863, 0.096143412566711, 0.09835230280287033, 0.10699083555130018, 0.07868267239573612, 0.1312309363609867, 0.07531008660630178, 0.09897026691313038, 0.09933766874378858]}, "mutation_prompt": null}
{"id": "9ec6abc2-9580-48b0-a686-8cac1514d436", "solution": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 20\n        self.f = 0.9  # DE scaling factor\n        self.cr = 0.85  # DE crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.6  # cognitive coefficient for PSO\n        self.c2 = 1.4  # social coefficient for PSO\n        self.vel_max = 1.0  # maximum velocity for PSO\n        self.particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_max, self.vel_max, (self.population_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.global_best = self.particles[np.random.choice(self.population_size)]\n        self.diversity_threshold = 1e-5\n        self.iteration = 0\n\n    def chaotic_map(self, x):\n        return np.mod(x + 0.65, 1.0)  # Modified chaotic map\n\n    def __call__(self, func):\n        evaluations = 0\n        fitness = np.array([func(ind) for ind in self.particles])\n        personal_best_fitness = fitness.copy()\n        global_best_fitness = np.min(fitness)\n        self.global_best = self.particles[np.argmin(fitness)]\n        evaluations += self.population_size\n        \n        while evaluations < self.budget:\n            self.iteration += 1\n\n            # Apply DE operator with chaotic map influence\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                chaotic_factor = self.chaotic_map(self.iteration / 100.0)\n                mutant = self.particles[a] + chaotic_factor * self.f * (self.particles[b] - self.particles[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        trial[j] = mutant[j]\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.particles[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = trial_fitness\n                        self.personal_best[i] = trial\n                        if trial_fitness < global_best_fitness:\n                            global_best_fitness = trial_fitness\n                            self.global_best = trial\n\n            # Adjust inertia weight based on diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                self.w *= 0.9\n\n            # Dynamic parameter tuning for PSO with diversity influence\n            diversity_influence = np.clip(diversity / 0.1, 0.0, 1.0)\n            self.c1 = 1.6 + 0.4 * np.cos(self.iteration / 50.0) * diversity_influence\n            self.c2 = 1.4 + 0.6 * np.sin(self.iteration / 50.0) * diversity_influence\n\n            # Apply PSO operator\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best - self.particles[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                current_fitness = func(self.particles[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = current_fitness\n                        self.personal_best[i] = self.particles[i]\n                        if current_fitness < global_best_fitness:\n                            global_best_fitness = current_fitness\n                            self.global_best = self.particles[i]\n\n        return self.global_best", "name": "RefinedHybridDEPSO", "description": "A refined hybrid optimizer leveraging adaptive chaotic maps in DEPSO with dynamic parameter tuning and mutation strategies for robust exploration and swift convergence.", "configspace": "", "generation": 96, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "6a22ffaf-9764-434c-9048-32105f44da31", "metadata": {"aucs": [0.9106591392470551, 0.9151362273799442, 0.9211458352651359, 0.9018533913251037, 0.9147667813441753, 0.913079187941077, 0.9126821188709977, 0.914743003210577, 0.9121956892279315, 0.829769294858656, 0.8279243545706415, 0.8312266512575383, 0.8211510289678186, 0.8147201060603015, 0.8000301941169908, 0.7760241830021479, 0.8042718411949789, 0.8166524486487081, 0.15935952341855752, 0.1862463591848056, 0.08941230170219694, 0.1241066524158807, 0.12207854518694661, 0.13969672038685732, 0.1293264245429978, 0.10220479240883829, 0.15841697239310304, 0.09769206250725115, 0.08927569806715097, 0.11704450811418587, 0.11673368088833269, 0.11839128355228479, 0.1612092922127678, 0.09912941030207822, 0.12410849881192754, 0.10397589771574334, 0.9734832478940764, 0.9672967241695916, 0.9663640019712644, 0.9586861221583975, 0.9701304199297195, 0.9711787143856033, 0.9795241682988146, 0.97142693568625, 0.9731946275653333, 0.8236892452576684, 0.8129934633900419, 0.823528614992999, 0.801954855268249, 0.7577911129757786, 0.7826320673487039, 0.08872619695269712, 0.7934960988074276, 0.8098420997267256, 0.885627601556623, 0.140852282115966, 0.13888403651866577, 0.280058752600319, 0.2150471926427675, 0.3803162881634867, 0.8454021719879076, 0.22630665310474418, 0.40067875790010965, 0.1279348694667033, 0.29268084373390346, 0.2776366661160652, 0.29713471954593185, 0.1353684385065459, 0.24091490117617353, 0.13620313320350852, 0.13562637363134744, 0.38402537593497854, 0.29791029888464104, 0.13676130313419876, 0.12847434867110352, 0.33343165556481313, 0.32985993307757366, 0.3326203333383182, 0.3234761655952513, 0.3259986306909407, 0.1077215796516019, 0.003298781642471438, 0.013684726572799621, 0.10161558262856685, 0.0016307934691125459, 0.13422334555308046, 0.056385741962564184, 0.03868364463549301, 0.04328042005386201, 0.024965908742265674, 0.10478324675492512, 0.07371643100059955, 0.07328044637049747, 0.09466253027226523, 0.0404915337285322, 0.12127605135179187, 0.06711656914541986, 0.06607630390339914, 0.06808606518901994, 0.05119633913125232, 0.12496222400573298, 0.08598373376761792, 0.07850145075694692, 0.08290159511493234, 0.16735785236840894, 0.10291119219656542, 0.10205522555970126, 0.07665283135025436, 0.1471313171130847, 0.15581916143363617, 0.11701593643611363, 0.4655681736461841, 0.16048904356507576, 0.1161503499456028, 0.23575995075966283, 0.13048340761389043, 0.08462292517523651, 0.6093966874649663, 0.5916832512707859, 0.5732670966007901, 0.5642896427839403, 0.5652514503658282, 0.5913635594701611, 0.6063043080946147, 0.5726382139055012, 0.597461355197041, 0.14119978761330654, 0.11775730864341671, 0.10936799041912404, 0.1467011598430651, 0.08904649800022924, 0.11099236402631263, 0.15934110553891245, 0.11547928814310815, 0.10861957171910686, 0.21174236037542882, 0.3097311410590605, 0.32342089622366244, 0.30206366918625505, 0.23292514426207145, 0.20792557745187046, 0.6674803141055125, 0.34691742347853227, 0.2297513046562133, 0.512570758435337, 0.4282019135564711, 0.42952731787249576, 0.3650960477338392, 0.22589340923389256, 0.3688130553570155, 0.5417674561188213, 0.694732516473082, 0.2381887902252513, 0.3765252435857578, 0.2404998042489519, 0.33773746447841635, 0.29624475530659833, 0.2138099723044713, 0.25058084842062034, 0.2583220844797627, 0.23757409104150284, 0.23530258141921867, 0.20080485695287775, 0.24169248300938195, 0.28308504883265895, 0.23583026561015963, 0.24634006927843788, 0.20727644836064563, 0.2276203030157644, 0.2153768686790296, 0.20304851377718136, 0.2475045941028866, 0.22368416966946358, 0.22443251059265534, 0.8303189018401445, 0.8500513785565419, 0.22407023119004676, 0.8336437574956065, 0.8188835636258109, 0.20869854404601806, 0.9098537675849655, 0.1650019017273655, 0.1878158094512703, 0.18922153442275025, 0.9102849221718736, 0.9489292964233885, 0.13600845325368427, 0.16959981021831205, 0.15324301400526508, 0.8803505744942954, 0.8044522469734348, 0.773797009813603, 0.831562799292085, 0.21314624644698776, 0.8877506207389676, 0.10530227928810965, 0.16834853784410642, 0.8349341188375318, 0.19120701501873927, 0.19400254113607684, 0.20722000552059372, 0.23097592373142328, 0.21408888444628305, 0.20467353272982036, 0.20638044346961792, 0.1951226475537995, 0.2249999740959273, 0.09460384758903506, 0.09552474417614154, 0.13440215265925648, 0.10086867433765112, 0.10077393306963367, 0.1046649580796215, 0.1073444245170353, 0.10144134663168147, 0.11217330842971585]}, "mutation_prompt": null}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLaMEA AutoML example\n",
    "\n",
    "This notebook shows a simple usage of LLaMEA to automatically generate and refine a Python-based machine learning pipelines for a given task and dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "import os\n",
    "import numpy as np\n",
    "from llamea import LLaMEA, Gemini_LLM\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Set up the LLM\n",
    "\n",
    "If you haven't already, set your OpenAI or other API key in your environment variables, e.g.,\n",
    "`export OPENAI_API_KEY=\"...\"` or `export GEMINI_API_KEY=\"....\"`\n",
    "\n",
    "You can also use Gemini in most countries for free."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "llm = Gemini_LLM(api_key, \"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Define an evaluation function for LLaMEA\n",
    "\n",
    "- The function must accept a \"solution\" argument, which contains code, a name, etc.\n",
    "- You parse solution.code (the raw code), dynamically load it, and run it on your problem(s).\n",
    "- You then set_scores() to record how well it did.\n",
    "\n",
    "We'll define a simple example on the breast cancer dataset.\n",
    "We'll ask the solution code to build a machine learning model that can predict the test set.\n",
    "We'll then return a score based on the accuracy of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the data set\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "(\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    ") = train_test_split(X, y, random_state=1)\n",
    "\n",
    "def evaluate(solution, explogger=None):\n",
    "        \"\"\"\n",
    "        Evaluates a solution on the breast cancer dataset.\n",
    "        \"\"\"\n",
    "        code = solution.code\n",
    "        algorithm_name = solution.name\n",
    "        safe_globals = {\n",
    "            \"sklearn\": sklearn,\n",
    "            \"math\": math,\n",
    "            \"random\": random,\n",
    "            \"np\": np,\n",
    "            \"pd\": pd,\n",
    "        }\n",
    "\n",
    "        exec(code, globals())\n",
    "\n",
    "        algorithm = None\n",
    "\n",
    "        # Final validation\n",
    "        algorithm = globals()[algorithm_name](X_train, y_train)\n",
    "        y_pred = algorithm(X_test)\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        solution.set_scores(\n",
    "            score,\n",
    "            f\"The algorithm {algorithm_name} scored {score:.3f} on accuracy (higher is better, 1.0 is the best).\",\n",
    "        )\n",
    "\n",
    "        return solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3 - define the instructions\n",
    "\n",
    "Now we define the instructions that LLamEA will provide to the LLM.\n",
    "The instructions are split into the following parts:\n",
    "- task_prompt: the main task description with a general overview of the task.\n",
    "- example_prompt: one or more code examples to guide the search in the beginning.\n",
    "- output_format_prompt: how the LLM should generate the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_prompt = f\"\"\"\n",
    "You are a highly skilled computer scientist in the field machine learning. Your task is to design novel machine learning pipelines for a given dataset and task.\n",
    "The pipeline in this case should handle a breast cancer classification task. Your task is to write the Python code. The code should contain an `__init__(self, X, y)` function that trains a machine learning model and the function `def __call__(self, X)`, which should predict the samples in X and return the predictions.\n",
    "The training data X has shape {X_train.shape} and y has shape {y_train.shape}.\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = \"\"\"\n",
    "An example code structure is as follows:\n",
    "```python\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "class AlgorithmName:\n",
    "    \"Template for a ML pipeline\"\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.train(X, y)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        # Standardize the feature data\n",
    "        scaler = sklearn.preprocessing.StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        # Let's create and train a logistic regression model\n",
    "        lr_model = sklearn.linear_model.LogisticRegression()\n",
    "        lr_model.fit(X_train, y_train)\n",
    "        self.model = lr_model\n",
    "        \n",
    "    def __call__(self, X):\n",
    "        # predict using the trained model\n",
    "        return self.model.predict(X)\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "output_format_prompt = \"\"\"\n",
    "Give an excellent and novel ML pipeline to solve this task and also give it a one-line description, describing the main idea. Give the response in the format:\n",
    "# Description: <short-description>\n",
    "# Code: \n",
    "```python\n",
    "<code>\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Create and run the LLaMEA search\n",
    "\n",
    "Now just simply run LLaMEA and see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use a small number of iterations for demonstration\n",
    "es = LLaMEA(\n",
    "    evaluate,\n",
    "    n_parents=1,\n",
    "    n_offspring=1,\n",
    "    llm=llm,\n",
    "    task_prompt=task_prompt,\n",
    "    example_prompt=example_prompt,\n",
    "    output_format_prompt=output_format_prompt,\n",
    "    experiment_name=\"AutoML-example\",\n",
    "    elitism=True,\n",
    "    HPO=False,\n",
    "    budget=10,\n",
    ")\n",
    "\n",
    "best_solution = es.run()\n",
    "print(f\"Best found solution: {best_solution.name}, Score={best_solution.fitness:.4f}\")\n",
    "print(f\"Generated code:\\n{best_solution.solution}\")\n",
    "print(f\"Additional feedback: {best_solution.feedback}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamea-84rNYHzd-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
